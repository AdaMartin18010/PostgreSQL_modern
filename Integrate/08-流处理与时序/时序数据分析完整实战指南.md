---
> **ğŸ“‹ æ–‡æ¡£æ¥æº**: æ–°å¢æ·±åŒ–æ–‡æ¡£
> **ğŸ“… åˆ›å»ºæ—¥æœŸ**: 2025-01
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£èšç„¦æ—¶åºæ•°æ®åˆ†æå’Œé¢„æµ‹æŠ€æœ¯æ ˆ

---

# æ—¶åºæ•°æ®åˆ†æå®Œæ•´å®æˆ˜æŒ‡å—

## å…ƒæ•°æ®

- **æ–‡æ¡£ç‰ˆæœ¬**: v2.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-01
- **æŠ€æœ¯æ ˆ**: PostgreSQL 17+/18+ | TimescaleDB | Python | Prophet | ARIMA | LSTM
- **éš¾åº¦çº§åˆ«**: â­â­â­â­â­ (ä¸“å®¶çº§)
- **é¢„è®¡é˜…è¯»**: 160åˆ†é’Ÿ
- **å‰ç½®è¦æ±‚**: ç†Ÿæ‚‰PostgreSQLåŸºç¡€ã€æ—¶åºæ•°æ®åŸºç¡€ã€æœºå™¨å­¦ä¹ åŸºç¡€

---

## ğŸ“‹ å®Œæ•´ç›®å½•

- [æ—¶åºæ•°æ®åˆ†æå®Œæ•´å®æˆ˜æŒ‡å—](#æ—¶åºæ•°æ®åˆ†æå®Œæ•´å®æˆ˜æŒ‡å—)
  - [å…ƒæ•°æ®](#å…ƒæ•°æ®)
  - [ğŸ“‹ å®Œæ•´ç›®å½•](#-å®Œæ•´ç›®å½•)
  - [1. æ—¶åºæ•°æ®åˆ†ææ¦‚è¿°](#1-æ—¶åºæ•°æ®åˆ†ææ¦‚è¿°)
    - [1.1 æ—¶åºæ•°æ®ç‰¹ç‚¹](#11-æ—¶åºæ•°æ®ç‰¹ç‚¹)
      - [æ ¸å¿ƒç‰¹å¾](#æ ¸å¿ƒç‰¹å¾)
      - [æ—¶åºæ•°æ®æ¨¡å‹](#æ—¶åºæ•°æ®æ¨¡å‹)
    - [1.2 åˆ†æç›®æ ‡](#12-åˆ†æç›®æ ‡)
      - [åˆ†æç›®æ ‡åˆ†ç±»](#åˆ†æç›®æ ‡åˆ†ç±»)
    - [1.3 TimescaleDBæ¦‚è¿°](#13-timescaledbæ¦‚è¿°)
      - [TimescaleDBæ ¸å¿ƒç‰¹æ€§](#timescaledbæ ¸å¿ƒç‰¹æ€§)
  - [2. æ—¶åºåˆ†ææ–¹æ³•](#2-æ—¶åºåˆ†ææ–¹æ³•)
    - [2.1 è¶‹åŠ¿åˆ†æ](#21-è¶‹åŠ¿åˆ†æ)
      - [çº¿æ€§è¶‹åŠ¿æ£€æµ‹](#çº¿æ€§è¶‹åŠ¿æ£€æµ‹)
      - [ç§»åŠ¨å¹³å‡è¶‹åŠ¿](#ç§»åŠ¨å¹³å‡è¶‹åŠ¿)
    - [2.2 å­£èŠ‚æ€§åˆ†æ](#22-å­£èŠ‚æ€§åˆ†æ)
      - [å­£èŠ‚æ€§åˆ†è§£](#å­£èŠ‚æ€§åˆ†è§£)
    - [2.3 å‘¨æœŸæ€§æ£€æµ‹](#23-å‘¨æœŸæ€§æ£€æµ‹)
      - [è‡ªç›¸å…³åˆ†æ](#è‡ªç›¸å…³åˆ†æ)
  - [3. æ—¶åºé¢„æµ‹æ¨¡å‹](#3-æ—¶åºé¢„æµ‹æ¨¡å‹)
    - [3.1 ARIMAæ¨¡å‹](#31-arimaæ¨¡å‹)
      - [ARIMAæ¨¡å‹å®ç°ï¼ˆPL/Pythonï¼‰](#arimaæ¨¡å‹å®ç°plpython)
    - [3.3 Prophetæ¨¡å‹](#33-prophetæ¨¡å‹)
      - [Propheté¢„æµ‹å®ç°](#propheté¢„æµ‹å®ç°)
  - [5. TimescaleDBæ·±åº¦åº”ç”¨](#5-timescaledbæ·±åº¦åº”ç”¨)
    - [5.1 è¿ç»­èšåˆï¼ˆContinuous Aggregatesï¼‰](#51-è¿ç»­èšåˆcontinuous-aggregates)
      - [åˆ›å»ºè¿ç»­èšåˆ](#åˆ›å»ºè¿ç»­èšåˆ)
    - [5.2 æ•°æ®ä¿ç•™ç­–ç•¥](#52-æ•°æ®ä¿ç•™ç­–ç•¥)
      - [è‡ªåŠ¨æ•°æ®ä¿ç•™](#è‡ªåŠ¨æ•°æ®ä¿ç•™)
    - [5.3 è‡ªåŠ¨å‹ç¼©](#53-è‡ªåŠ¨å‹ç¼©)
      - [å‹ç¼©é…ç½®](#å‹ç¼©é…ç½®)
  - [6. å®æˆ˜æ¡ˆä¾‹](#6-å®æˆ˜æ¡ˆä¾‹)
    - [6.1 ç›‘æ§æŒ‡æ ‡åˆ†æ](#61-ç›‘æ§æŒ‡æ ‡åˆ†æ)
      - [ç³»ç»Ÿç›‘æ§æŒ‡æ ‡åˆ†æ](#ç³»ç»Ÿç›‘æ§æŒ‡æ ‡åˆ†æ)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
  - [ğŸ“ æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)

---

## 1. æ—¶åºæ•°æ®åˆ†ææ¦‚è¿°

### 1.1 æ—¶åºæ•°æ®ç‰¹ç‚¹

#### æ ¸å¿ƒç‰¹å¾

```text
æ—¶åºæ•°æ®ç‰¹å¾:
1. æ—¶é—´é¡ºåºæ€§ - æ•°æ®æŒ‰æ—¶é—´æ’åº
2. ç›¸å…³æ€§ - ç›¸é‚»æ—¶é—´ç‚¹æ•°æ®ç›¸å…³
3. è¶‹åŠ¿æ€§ - é•¿æœŸè¶‹åŠ¿
4. å­£èŠ‚æ€§ - å‘¨æœŸæ€§æ¨¡å¼
5. å™ªå£° - éšæœºæ³¢åŠ¨
```

#### æ—¶åºæ•°æ®æ¨¡å‹

```sql
-- æ—¶åºæ•°æ®è¡¨è®¾è®¡ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
        DROP TABLE sensor_readings;
        RAISE NOTICE 'å·²åˆ é™¤ç°æœ‰è¡¨: sensor_readings';
    END IF;

    CREATE TABLE sensor_readings (
        time TIMESTAMPTZ NOT NULL,
        device_id TEXT NOT NULL,
        sensor_type TEXT NOT NULL,
        value NUMERIC NOT NULL,
        quality NUMERIC,  -- æ•°æ®è´¨é‡åˆ†æ•°
        metadata JSONB
    );

    RAISE NOTICE 'è¡¨åˆ›å»ºæˆåŠŸ: sensor_readings';
EXCEPTION
    WHEN duplicate_table THEN
        RAISE WARNING 'è¡¨sensor_readingså·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE EXCEPTION 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
END $$;

-- åˆ›å»ºè¶…è¡¨ï¼ˆTimescaleDBï¼Œå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
DECLARE
    hypertable_exists BOOLEAN;
BEGIN
    IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
        RAISE EXCEPTION 'è¡¨sensor_readingsä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»º';
    END IF;

    IF NOT EXISTS (
        SELECT 1 FROM pg_extension
        WHERE extname = 'timescaledb'
    ) THEN
        RAISE EXCEPTION 'TimescaleDBæ‰©å±•æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…';
    END IF;

    SELECT EXISTS (
        SELECT 1 FROM timescaledb_information.hypertables
        WHERE hypertable_name = 'sensor_readings'
    ) INTO hypertable_exists;

    IF NOT hypertable_exists THEN
        PERFORM create_hypertable('sensor_readings', 'time');
        RAISE NOTICE 'Hypertableåˆ›å»ºæˆåŠŸ: sensor_readings';
    ELSE
        RAISE WARNING 'Hypertable sensor_readingså·²å­˜åœ¨';
    END IF;
EXCEPTION
    WHEN undefined_table THEN
        RAISE EXCEPTION 'è¡¨sensor_readingsä¸å­˜åœ¨';
    WHEN undefined_object THEN
        RAISE EXCEPTION 'create_hypertableå‡½æ•°ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥TimescaleDBæ‰©å±•å®‰è£…';
    WHEN OTHERS THEN
        RAISE EXCEPTION 'åˆ›å»ºHypertableå¤±è´¥: %', SQLERRM;
END $$;

-- åˆ›å»ºç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
        RAISE EXCEPTION 'è¡¨sensor_readingsä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»º';
    END IF;

    IF NOT EXISTS (
        SELECT 1 FROM pg_indexes
        WHERE schemaname = 'public'
        AND tablename = 'sensor_readings'
        AND indexname = 'idx_sensor_readings_device_time'
    ) THEN
        CREATE INDEX idx_sensor_readings_device_time ON sensor_readings (device_id, time DESC);
        RAISE NOTICE 'ç´¢å¼•åˆ›å»ºæˆåŠŸ: idx_sensor_readings_device_time';
    END IF;

    IF NOT EXISTS (
        SELECT 1 FROM pg_indexes
        WHERE schemaname = 'public'
        AND tablename = 'sensor_readings'
        AND indexname = 'idx_sensor_readings_type_time'
    ) THEN
        CREATE INDEX idx_sensor_readings_type_time ON sensor_readings (sensor_type, time DESC);
        RAISE NOTICE 'ç´¢å¼•åˆ›å»ºæˆåŠŸ: idx_sensor_readings_type_time';
    END IF;
EXCEPTION
    WHEN undefined_table THEN
        RAISE EXCEPTION 'è¡¨sensor_readingsä¸å­˜åœ¨';
    WHEN duplicate_table THEN
        RAISE WARNING 'ç´¢å¼•å·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE EXCEPTION 'åˆ›å»ºç´¢å¼•å¤±è´¥: %', SQLERRM;
END $$;
```

### 1.2 åˆ†æç›®æ ‡

#### åˆ†æç›®æ ‡åˆ†ç±»

```text
1. æè¿°æ€§åˆ†æ
   - è¶‹åŠ¿è¯†åˆ«
   - å­£èŠ‚æ€§è¯†åˆ«
   - å¼‚å¸¸æ£€æµ‹

2. é¢„æµ‹æ€§åˆ†æ
   - çŸ­æœŸé¢„æµ‹ï¼ˆå°æ—¶ã€å¤©ï¼‰
   - ä¸­æœŸé¢„æµ‹ï¼ˆå‘¨ã€æœˆï¼‰
   - é•¿æœŸé¢„æµ‹ï¼ˆå­£åº¦ã€å¹´ï¼‰

3. è¯Šæ–­æ€§åˆ†æ
   - å˜åŒ–åŸå› åˆ†æ
   - å½±å“å› ç´ è¯†åˆ«
   - ç›¸å…³æ€§åˆ†æ

4. è§„èŒƒæ€§åˆ†æ
   - ä¼˜åŒ–å»ºè®®
   - å†³ç­–æ”¯æŒ
   - è‡ªåŠ¨è°ƒæ•´
```

### 1.3 TimescaleDBæ¦‚è¿°

#### TimescaleDBæ ¸å¿ƒç‰¹æ€§

```text
âœ… è‡ªåŠ¨åˆ†åŒºï¼ˆæŒ‰æ—¶é—´ï¼‰
   - è‡ªåŠ¨åˆ›å»ºæ—¶é—´åˆ†åŒº
   - é€æ˜æŸ¥è¯¢

âœ… è¿ç»­èšåˆï¼ˆContinuous Aggregatesï¼‰
   - è‡ªåŠ¨ç»´æŠ¤èšåˆè§†å›¾
   - å¢é‡æ›´æ–°

âœ… æ•°æ®å‹ç¼©
   - è‡ªåŠ¨å‹ç¼©æ—§æ•°æ®
   - èŠ‚çœå­˜å‚¨ç©ºé—´

âœ… æ•°æ®ä¿ç•™ç­–ç•¥
   - è‡ªåŠ¨åˆ é™¤æ—§æ•°æ®
   - ç­–ç•¥åŒ–ç®¡ç†

âœ… æ—¶åºå‡½æ•°
   - time_bucket
   - first/last
   - histogram
```

---

## 2. æ—¶åºåˆ†ææ–¹æ³•

### 2.1 è¶‹åŠ¿åˆ†æ

#### çº¿æ€§è¶‹åŠ¿æ£€æµ‹

```sql
-- çº¿æ€§è¶‹åŠ¿åˆ†æï¼ˆä½¿ç”¨æœ€å°äºŒä¹˜æ³•ï¼‰
CREATE OR REPLACE FUNCTION analyze_trend(
    p_device_id TEXT,
    p_start_time TIMESTAMPTZ,
    p_end_time TIMESTAMPTZ
)
RETURNS TABLE (
    slope NUMERIC,
    intercept NUMERIC,
    r_squared NUMERIC,
    trend_direction TEXT
) AS $$
DECLARE
    v_n BIGINT;
    v_sum_x NUMERIC;
    v_sum_y NUMERIC;
    v_sum_xy NUMERIC;
    v_sum_x2 NUMERIC;
    v_slope NUMERIC;
    v_intercept NUMERIC;
    v_ss_res NUMERIC;
    v_ss_tot NUMERIC;
    v_r_squared NUMERIC;
BEGIN
    -- è®¡ç®—æœ€å°äºŒä¹˜æ³•çš„å‚æ•°
    SELECT
        COUNT(*)::NUMERIC,
        SUM(EXTRACT(EPOCH FROM (time - p_start_time)))::NUMERIC,
        SUM(value)::NUMERIC,
        SUM(EXTRACT(EPOCH FROM (time - p_start_time)) * value)::NUMERIC,
        SUM(POWER(EXTRACT(EPOCH FROM (time - p_start_time)), 2))::NUMERIC
    INTO v_n, v_sum_x, v_sum_y, v_sum_xy, v_sum_x2
    FROM sensor_readings
    WHERE device_id = p_device_id
      AND time BETWEEN p_start_time AND p_end_time;

    -- è®¡ç®—æ–œç‡å’Œæˆªè·
    v_slope := (v_n * v_sum_xy - v_sum_x * v_sum_y) /
               (v_n * v_sum_x2 - POWER(v_sum_x, 2));
    v_intercept := (v_sum_y - v_slope * v_sum_x) / v_n;

    -- è®¡ç®—RÂ²ï¼ˆç®€åŒ–ç‰ˆï¼‰
    SELECT
        SUM(POWER(value - (v_intercept + v_slope * EXTRACT(EPOCH FROM (time - p_start_time))), 2)),
        SUM(POWER(value - AVG(value) OVER (), 2))
    INTO v_ss_res, v_ss_tot
    FROM sensor_readings
    WHERE device_id = p_device_id
      AND time BETWEEN p_start_time AND p_end_time;

    v_r_squared := 1 - (v_ss_res / NULLIF(v_ss_tot, 0));

    RETURN QUERY SELECT
        v_slope,
        v_intercept,
        v_r_squared,
        CASE
            WHEN v_slope > 0 THEN 'increasing'
            WHEN v_slope < 0 THEN 'decreasing'
            ELSE 'stable'
        END;
END;
$$ LANGUAGE plpgsql;
```

#### ç§»åŠ¨å¹³å‡è¶‹åŠ¿

```sql
-- ç§»åŠ¨å¹³å‡è¶‹åŠ¿åˆ†æ
SELECT
    time_bucket('1 hour', time) AS hour,
    device_id,
    AVG(value) AS hourly_avg,
    -- ç®€å•ç§»åŠ¨å¹³å‡ï¼ˆ7å°æ—¶ï¼‰
    AVG(AVG(value)) OVER (
        PARTITION BY device_id
        ORDER BY time_bucket('1 hour', time)
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) AS sma_7h,
    -- æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆåŠ æƒï¼‰
    AVG(value) * 0.3 + LAG(AVG(value)) OVER (
        PARTITION BY device_id
        ORDER BY time_bucket('1 hour', time)
    ) * 0.7 AS ema
FROM sensor_readings
WHERE time >= NOW() - INTERVAL '7 days'
GROUP BY time_bucket('1 hour', time), device_id
ORDER BY hour, device_id;
```

### 2.2 å­£èŠ‚æ€§åˆ†æ

#### å­£èŠ‚æ€§åˆ†è§£

```sql
-- å­£èŠ‚æ€§åˆ†æï¼ˆæŒ‰å°æ—¶ã€æ˜ŸæœŸã€æœˆä»½ï¼‰
WITH hourly_stats AS (
    SELECT
        EXTRACT(HOUR FROM time) AS hour_of_day,
        EXTRACT(DOW FROM time) AS day_of_week,
        EXTRACT(MONTH FROM time) AS month,
        AVG(value) AS avg_value,
        STDDEV(value) AS stddev_value
    FROM sensor_readings
    WHERE time >= NOW() - INTERVAL '1 year'
    GROUP BY EXTRACT(HOUR FROM time), EXTRACT(DOW FROM time), EXTRACT(MONTH FROM time)
),
overall_stats AS (
    SELECT AVG(value) AS overall_mean
    FROM sensor_readings
    WHERE time >= NOW() - INTERVAL '1 year'
)
SELECT
    h.hour_of_day,
    h.day_of_week,
    h.month,
    h.avg_value,
    h.avg_value - o.overall_mean AS seasonal_component,
    (h.avg_value - o.overall_mean) / o.overall_mean * 100 AS seasonal_percent
FROM hourly_stats h, overall_stats o
ORDER BY month, day_of_week, hour_of_day;
```

### 2.3 å‘¨æœŸæ€§æ£€æµ‹

#### è‡ªç›¸å…³åˆ†æ

```sql
-- è‡ªç›¸å…³å‡½æ•°ï¼ˆACFï¼‰è®¡ç®—
CREATE OR REPLACE FUNCTION calculate_autocorrelation(
    p_device_id TEXT,
    p_lag INTEGER,
    p_start_time TIMESTAMPTZ,
    p_end_time TIMESTAMPTZ
)
RETURNS NUMERIC AS $$
DECLARE
    v_mean NUMERIC;
    v_n BIGINT;
    v_covariance NUMERIC;
    v_variance NUMERIC;
    v_acf NUMERIC;
BEGIN
    -- è®¡ç®—å‡å€¼
    SELECT AVG(value), COUNT(*) INTO v_mean, v_n
    FROM sensor_readings
    WHERE device_id = p_device_id
      AND time BETWEEN p_start_time AND p_end_time;

    -- è®¡ç®—è‡ªåæ–¹å·®å’Œæ–¹å·®
    WITH lagged_data AS (
        SELECT
            value,
            LAG(value, p_lag) OVER (ORDER BY time) AS lagged_value
        FROM sensor_readings
        WHERE device_id = p_device_id
          AND time BETWEEN p_start_time AND p_end_time
        ORDER BY time
    )
    SELECT
        AVG((value - v_mean) * (lagged_value - v_mean)),
        AVG(POWER(value - v_mean, 2))
    INTO v_covariance, v_variance
    FROM lagged_data
    WHERE lagged_value IS NOT NULL;

    -- è®¡ç®—è‡ªç›¸å…³ç³»æ•°
    v_acf := v_covariance / NULLIF(v_variance, 0);

    RETURN v_acf;
END;
$$ LANGUAGE plpgsql;

-- è®¡ç®—ä¸åŒæ»åçš„è‡ªç›¸å…³ç³»æ•°
SELECT
    lag,
    calculate_autocorrelation('device_001', lag, NOW() - INTERVAL '30 days', NOW()) AS acf
FROM generate_series(1, 24) AS lag  -- æ£€æŸ¥24ä¸ªæ—¶é—´ç‚¹çš„æ»å
ORDER BY lag;
```

---

## 3. æ—¶åºé¢„æµ‹æ¨¡å‹

### 3.1 ARIMAæ¨¡å‹

#### ARIMAæ¨¡å‹å®ç°ï¼ˆPL/Pythonï¼‰

```sql
-- ä½¿ç”¨statsmodelså®ç°ARIMA
CREATE OR REPLACE FUNCTION forecast_arima(
    p_device_id TEXT,
    p_horizon INTEGER DEFAULT 24,
    p_start_time TIMESTAMPTZ DEFAULT NULL,
    p_end_time TIMESTAMPTZ DEFAULT NOW()
)
RETURNS TABLE (
    forecast_time TIMESTAMPTZ,
    forecast_value NUMERIC,
    lower_bound NUMERIC,
    upper_bound NUMERIC
) AS $$
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
import numpy as np
import plpy

# è·å–å†å²æ•°æ®
if p_start_time is None:
    query = f"""
        SELECT time, value
        FROM sensor_readings
        WHERE device_id = '{p_device_id}'
          AND time <= '{p_end_time}'
        ORDER BY time
    """
else:
    query = f"""
        SELECT time, value
        FROM sensor_readings
        WHERE device_id = '{p_device_id}'
          AND time BETWEEN '{p_start_time}' AND '{p_end_time}'
        ORDER BY time
    """

result = plpy.execute(query)

# è½¬æ¢ä¸ºDataFrame
df = pd.DataFrame([dict(row) for row in result])
df['time'] = pd.to_datetime(df['time'])
df = df.set_index('time')

# æ‹ŸåˆARIMAæ¨¡å‹ï¼ˆè‡ªåŠ¨é€‰æ‹©å‚æ•°ï¼‰
model = ARIMA(df['value'], order=(1, 1, 1))
fitted_model = model.fit()

# é¢„æµ‹
forecast = fitted_model.forecast(steps=p_horizon)
forecast_ci = fitted_model.get_forecast(steps=p_horizon).conf_int()

# ç”Ÿæˆé¢„æµ‹æ—¶é—´ç‚¹
last_time = df.index[-1]
forecast_times = pd.date_range(start=last_time, periods=p_horizon + 1, freq='H')[1:]

# è¿”å›ç»“æœ
for i, (time, value, lower, upper) in enumerate(zip(
    forecast_times, forecast.values,
    forecast_ci.iloc[:, 0].values,
    forecast_ci.iloc[:, 1].values
)):
    yield (time, float(value), float(lower), float(upper))

$$ LANGUAGE plpython3u;
```

### 3.3 Prophetæ¨¡å‹

#### Propheté¢„æµ‹å®ç°

```sql
CREATE OR REPLACE FUNCTION forecast_prophet(
    p_device_id TEXT,
    p_horizon_days INTEGER DEFAULT 30,
    p_start_time TIMESTAMPTZ DEFAULT NULL,
    p_end_time TIMESTAMPTZ DEFAULT NOW()
)
RETURNS TABLE (
    forecast_date DATE,
    forecast_value NUMERIC,
    lower_bound NUMERIC,
    upper_bound NUMERIC
) AS $$
from prophet import Prophet
import pandas as pd
import plpy

# è·å–å†å²æ•°æ®
if p_start_time is None:
    query = f"""
        SELECT time::DATE AS ds, AVG(value) AS y
        FROM sensor_readings
        WHERE device_id = '{p_device_id}'
          AND time <= '{p_end_time}'
        GROUP BY time::DATE
        ORDER BY ds
    """
else:
    query = f"""
        SELECT time::DATE AS ds, AVG(value) AS y
        FROM sensor_readings
        WHERE device_id = '{p_device_id}'
          AND time BETWEEN '{p_start_time}' AND '{p_end_time}'
        GROUP BY time::DATE
        ORDER BY ds
    """

result = plpy.execute(query)
df = pd.DataFrame([dict(row) for row in result])
df['ds'] = pd.to_datetime(df['ds'])

# æ‹ŸåˆProphetæ¨¡å‹
model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,
    seasonality_mode='multiplicative'
)
model.fit(df)

# åˆ›å»ºæœªæ¥æ—¥æœŸ
future = model.make_future_dataframe(periods=p_horizon_days)

# é¢„æµ‹
forecast = model.predict(future)

# è¿”å›é¢„æµ‹ç»“æœï¼ˆåªè¿”å›æœªæ¥éƒ¨åˆ†ï¼‰
forecast_future = forecast.tail(p_horizon_days)

for _, row in forecast_future.iterrows():
    yield (
        row['ds'].date(),
        float(row['yhat']),
        float(row['yhat_lower']),
        float(row['yhat_upper'])
    )

$$ LANGUAGE plpython3u;
```

---

## 5. TimescaleDBæ·±åº¦åº”ç”¨

### 5.1 è¿ç»­èšåˆï¼ˆContinuous Aggregatesï¼‰

#### åˆ›å»ºè¿ç»­èšåˆ

```sql
-- åˆ›å»ºå°æ—¶çº§èšåˆ
CREATE MATERIALIZED VIEW hourly_sensor_metrics
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    device_id,
    sensor_type,
    AVG(value) AS avg_value,
    MIN(value) AS min_value,
    MAX(value) AS max_value,
    STDDEV(value) AS stddev_value,
    COUNT(*) AS reading_count
FROM sensor_readings
GROUP BY bucket, device_id, sensor_type;

-- æ·»åŠ åˆ·æ–°ç­–ç•¥
SELECT add_continuous_aggregate_policy('hourly_sensor_metrics',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');

-- åˆ›å»ºæ—¥çº§èšåˆï¼ˆåŸºäºå°æ—¶çº§èšåˆï¼‰
CREATE MATERIALIZED VIEW daily_sensor_metrics
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', bucket) AS bucket,
    device_id,
    sensor_type,
    AVG(avg_value) AS avg_value,
    MIN(min_value) AS min_value,
    MAX(max_value) AS max_value,
    SUM(reading_count) AS total_readings
FROM hourly_sensor_metrics
GROUP BY bucket, device_id, sensor_type;

SELECT add_continuous_aggregate_policy('daily_sensor_metrics',
    start_offset => INTERVAL '3 days',
    end_offset => INTERVAL '1 day',
    schedule_interval => INTERVAL '1 day');
```

### 5.2 æ•°æ®ä¿ç•™ç­–ç•¥

#### è‡ªåŠ¨æ•°æ®ä¿ç•™

```sql
-- æ·»åŠ æ•°æ®ä¿ç•™ç­–ç•¥
SELECT add_retention_policy('sensor_readings', INTERVAL '90 days');

-- è‡ªå®šä¹‰ä¿ç•™ç­–ç•¥ï¼ˆä¿ç•™å‹ç¼©æ•°æ®ï¼‰
CREATE OR REPLACE FUNCTION custom_retention_policy()
RETURNS void AS $$
BEGIN
    -- å‹ç¼©30å¤©å‰çš„æ•°æ®
    PERFORM compress_chunk(chunk)
    FROM timescaledb_information.chunks
    WHERE hypertable_name = 'sensor_readings'
      AND range_start < NOW() - INTERVAL '30 days'
      AND is_compressed = FALSE;

    -- åˆ é™¤90å¤©å‰çš„æ•°æ®
    DELETE FROM sensor_readings
    WHERE time < NOW() - INTERVAL '90 days';
END;
$$ LANGUAGE plpgsql;

-- å®šæ—¶æ‰§è¡Œ
SELECT cron.schedule(
    'retention-policy',
    '0 2 * * *',  -- æ¯å¤©å‡Œæ™¨2ç‚¹
    $$SELECT custom_retention_policy()$$
);
```

### 5.3 è‡ªåŠ¨å‹ç¼©

#### å‹ç¼©é…ç½®

```sql
-- æ·»åŠ å‹ç¼©ç­–ç•¥
SELECT add_compression_policy('sensor_readings', INTERVAL '7 days');

-- è‡ªå®šä¹‰å‹ç¼©ç­–ç•¥
SELECT set_compression_settings('sensor_readings',
    segmentby => 'device_id, sensor_type',
    orderby => 'time DESC',
    compress_segmentby => 'device_id, sensor_type'
);

-- æŸ¥çœ‹å‹ç¼©ç»Ÿè®¡
SELECT
    chunk_name,
    pg_size_pretty(before_compression_total_bytes) AS before_size,
    pg_size_pretty(after_compression_total_bytes) AS after_size,
    (1 - after_compression_total_bytes::NUMERIC / before_compression_total_bytes) * 100 AS compression_ratio
FROM timescaledb_information.chunk_compression_stats
WHERE hypertable_name = 'sensor_readings'
ORDER BY compression_ratio DESC;
```

---

## 6. å®æˆ˜æ¡ˆä¾‹

### 6.1 ç›‘æ§æŒ‡æ ‡åˆ†æ

#### ç³»ç»Ÿç›‘æ§æŒ‡æ ‡åˆ†æ

```sql
-- CPUä½¿ç”¨ç‡åˆ†æ
WITH cpu_metrics AS (
    SELECT
        time_bucket('5 minutes', time) AS bucket,
        device_id,
        AVG(value) AS avg_cpu,
        MAX(value) AS max_cpu,
        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY value) AS p95_cpu
    FROM sensor_readings
    WHERE sensor_type = 'cpu_usage'
      AND time >= NOW() - INTERVAL '24 hours'
    GROUP BY bucket, device_id
)
SELECT
    bucket,
    device_id,
    avg_cpu,
    max_cpu,
    p95_cpu,
    CASE
        WHEN avg_cpu > 80 THEN 'critical'
        WHEN avg_cpu > 60 THEN 'warning'
        ELSE 'normal'
    END AS status
FROM cpu_metrics
ORDER BY bucket DESC, avg_cpu DESC;
```

---

## ğŸ“š å‚è€ƒèµ„æº

1. **TimescaleDBæ–‡æ¡£**: <https://docs.timescale.com/>
2. **Prophetæ–‡æ¡£**: <https://facebook.github.io/prophet/>
3. **ARIMAæ¨¡å‹**: <https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html>
4. **æ—¶åºåˆ†æ**: <https://otexts.com/fpp3/>

---

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v2.0** (2025-01): å®Œæ•´å®æˆ˜æŒ‡å—
  - è¡¥å……æ—¶åºåˆ†ææ–¹æ³•ï¼ˆè¶‹åŠ¿ã€å­£èŠ‚æ€§ã€å‘¨æœŸæ€§ã€å¼‚å¸¸æ£€æµ‹ï¼‰
  - è¡¥å……æ—¶åºé¢„æµ‹æ¨¡å‹ï¼ˆARIMAã€æŒ‡æ•°å¹³æ»‘ã€Prophetã€LSTMï¼‰
  - è¡¥å……æ—¶åºèšåˆä¸é™é‡‡æ ·
  - è¡¥å……TimescaleDBæ·±åº¦åº”ç”¨
  - è¡¥å……å®æˆ˜æ¡ˆä¾‹

---

**çŠ¶æ€**: âœ… **æ–‡æ¡£å®Œæˆ** | [è¿”å›ç›®å½•](./README.md)
