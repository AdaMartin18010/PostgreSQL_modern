---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL_View\03-Serverlessä¸åˆ†æ”¯\Neonå¹³å°\Neonæ¶æ„è¯¦è§£.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# Neon æ¶æ„è¯¦è§£

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: Neon v3.0+
> **æ–‡æ¡£ç¼–å·**: 03-02-01

## ğŸ“‘ ç›®å½•

- [æ ¸å¿ƒä»·å€¼](#æ ¸å¿ƒä»·å€¼)
- [æŠ€æœ¯äº®ç‚¹](#æŠ€æœ¯äº®ç‚¹)
- [Neon æ¶æ„ä½“ç³»æ€ç»´å¯¼å›¾](#neon-æ¶æ„ä½“ç³»æ€ç»´å¯¼å›¾)
- [æ¶æ„ç»„ä»¶è¯¦è§£](#æ¶æ„ç»„ä»¶è¯¦è§£)
- [1. Scale-to-Zero](#1-scale-to-zero)
- [2. æ•°æ®åº“åˆ†æ”¯ (Branching)](#2-æ•°æ®åº“åˆ†æ”¯-branching)
- [3. å³æ—¶å¿«ç…§ (Instant Snapshots)](#3-å³æ—¶å¿«ç…§-instant-snapshots)
- [1. å¿«é€Ÿå¼€å§‹](#1-å¿«é€Ÿå¼€å§‹)
- [2. åˆ†æ”¯ç®¡ç†](#2-åˆ†æ”¯ç®¡ç†)
- [3. LangChain é›†æˆ](#3-langchain-é›†æˆ)
- [Scale-to-Zero æ€§èƒ½](#scale-to-zero-æ€§èƒ½)
- [åˆ†æ”¯æ“ä½œæ€§èƒ½](#åˆ†æ”¯æ“ä½œæ€§èƒ½)
- [å®é™…åº”ç”¨åœºæ™¯](#å®é™…åº”ç”¨åœºæ™¯)
- [1. åˆ†æ”¯å‘½åè§„èŒƒ](#1-åˆ†æ”¯å‘½åè§„èŒƒ)
- [2. è‡ªåŠ¨æ¸…ç†æ—§åˆ†æ”¯](#2-è‡ªåŠ¨æ¸…ç†æ—§åˆ†æ”¯)
- [3. æˆæœ¬ä¼˜åŒ–ç­–ç•¥](#3-æˆæœ¬ä¼˜åŒ–ç­–ç•¥)
- [4. æ€§èƒ½ä¼˜åŒ–æŠ€å·§](#4-æ€§èƒ½ä¼˜åŒ–æŠ€å·§)
- [5. é«˜çº§ç‰¹æ€§](#5-é«˜çº§ç‰¹æ€§)
- [6. ç›‘æ§ä¸è¿ç»´](#6-ç›‘æ§ä¸è¿ç»´)
- [7. å®é™…åº”ç”¨æ¡ˆä¾‹](#7-å®é™…åº”ç”¨æ¡ˆä¾‹)
- [8. æ•…éšœæ’æŸ¥](#8-æ•…éšœæ’æŸ¥)
- [9. å®‰å…¨æœ€ä½³å®è·µ](#9-å®‰å…¨æœ€ä½³å®è·µ)
- [10. ä¸å…¶ä»–å¹³å°å¯¹æ¯”](#10-ä¸å…¶ä»–å¹³å°å¯¹æ¯”)
- [11. API å‚è€ƒ](#11-api-å‚è€ƒ)
- [12. å¸¸è§é—®é¢˜ FAQ](#12-å¸¸è§é—®é¢˜-faq)
- [13. æˆæœ¬ä¼°ç®—](#13-æˆæœ¬ä¼°ç®—)
- [14. CI/CD é›†æˆ](#14-cicd-é›†æˆ)
- [15. pgvector é›†æˆç¤ºä¾‹](#15-pgvector-é›†æˆç¤ºä¾‹)
- [16. éƒ¨ç½²æœ€ä½³å®è·µ](#16-éƒ¨ç½²æœ€ä½³å®è·µ)
- [17. æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†](#17-æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†)
- [18. æ•…éšœæ¢å¤ä¸ç¾éš¾æ¢å¤](#18-æ•…éšœæ¢å¤ä¸ç¾éš¾æ¢å¤)
- [19. ä¸å…¶ä»–å·¥å…·é›†æˆ](#19-ä¸å…¶ä»–å·¥å…·é›†æˆ)
- [20. è¿ç§»ä¸å‡çº§æŒ‡å—](#20-è¿ç§»ä¸å‡çº§æŒ‡å—)
- [21. é«˜çº§ç›‘æ§ä¸åˆ†æ](#21-é«˜çº§ç›‘æ§ä¸åˆ†æ)
- [22. å®é™…åº”ç”¨åœºæ™¯æ‰©å±•](#22-å®é™…åº”ç”¨åœºæ™¯æ‰©å±•)
- [23. æ•…éšœæ’æŸ¥è¯¦ç»†æŒ‡å—](#23-æ•…éšœæ’æŸ¥è¯¦ç»†æŒ‡å—)
- [24. å®‰å…¨åŠ å›ºæŒ‡å—](#24-å®‰å…¨åŠ å›ºæŒ‡å—)
- [25. æœ€ä½³å®è·µæ€»ç»“](#25-æœ€ä½³å®è·µæ€»ç»“)
- [26. å¿«é€Ÿå‚è€ƒ](#26-å¿«é€Ÿå‚è€ƒ)
- [27. å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ](#27-å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ)
- [28. å®é™…æ¡ˆä¾‹ç ”ç©¶](#28-å®é™…æ¡ˆä¾‹ç ”ç©¶)
- [29. AI å·¥å…·é›†æˆç¤ºä¾‹](#29-ai-å·¥å…·é›†æˆç¤ºä¾‹)
- [30. æ€§èƒ½è°ƒä¼˜æ·±åº¦æŒ‡å—](#30-æ€§èƒ½è°ƒä¼˜æ·±åº¦æŒ‡å—)
- [31. æŠ€æœ¯æ·±åº¦åˆ†æ](#31-æŠ€æœ¯æ·±åº¦åˆ†æ)
- [32. ä¸å…¶ä»– Serverless æ•°æ®åº“æ·±åº¦å¯¹æ¯”](#32-ä¸å…¶ä»–-serverless-æ•°æ®åº“æ·±åº¦å¯¹æ¯”)
- [33. æœªæ¥å‘å±•è¶‹åŠ¿](#33-æœªæ¥å‘å±•è¶‹åŠ¿)
- [34. æ€»ç»“ä¸å»ºè®®](#34-æ€»ç»“ä¸å»ºè®®)
- [35. é«˜çº§åº”ç”¨åœºæ™¯](#35-é«˜çº§åº”ç”¨åœºæ™¯)
- [36. ä¼ä¸šçº§éƒ¨ç½²æ¨¡å¼](#36-ä¼ä¸šçº§éƒ¨ç½²æ¨¡å¼)
- [37. æ€§èƒ½ä¼˜åŒ–é«˜çº§æŠ€å·§](#37-æ€§èƒ½ä¼˜åŒ–é«˜çº§æŠ€å·§)
- [38. ç›‘æ§ä¸å¯è§‚æµ‹æ€§](#38-ç›‘æ§ä¸å¯è§‚æµ‹æ€§)
- [39. æ‰©å±•ä¸æ’ä»¶æ”¯æŒ](#39-æ‰©å±•ä¸æ’ä»¶æ”¯æŒ)
- [40. æ•°æ®è¿ç§»ä¸åŒæ­¥](#40-æ•°æ®è¿ç§»ä¸åŒæ­¥)
- [41. å®‰å…¨æœ€ä½³å®è·µæ‰©å±•](#41-å®‰å…¨æœ€ä½³å®è·µæ‰©å±•)
- [42. æ€§èƒ½ç›‘æ§ä¸è°ƒä¼˜](#42-æ€§èƒ½ç›‘æ§ä¸è°ƒä¼˜)
- [43. æ€»ç»“ä¸å¿«é€Ÿå¼€å§‹](#43-æ€»ç»“ä¸å¿«é€Ÿå¼€å§‹)
- [44. å­¦ä¹ è·¯å¾„ä¸åŸ¹è®­èµ„æº](#44-å­¦ä¹ è·¯å¾„ä¸åŸ¹è®­èµ„æº)
- [44.1 åˆå­¦è€…å­¦ä¹ è·¯å¾„](#441-åˆå­¦è€…å­¦ä¹ è·¯å¾„)
- [45. PostgreSQL å…¨é¢åŸ¹è®­](#45-postgresql-å…¨é¢åŸ¹è®­)
- [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
- [å¼€å‘èµ„æº](#å¼€å‘èµ„æº)
- [ç›¸å…³èµ„æº](#ç›¸å…³èµ„æº)

---

## ğŸ“‹ æ¦‚è¿°

Neon æ˜¯ä¸šç•Œé¢†å…ˆçš„ Serverless PostgreSQL å¹³å°ï¼Œé€šè¿‡ Scale-to-Zero å’Œæ•°æ®åº“åˆ†æ”¯åŠŸèƒ½ï¼Œè®© AI Agent å¯ä»¥
é›¶æˆæœ¬è¿›è¡Œæ•°æ®åº“å®éªŒï¼Œæˆä¸º"æ•°æ® Git"çš„å®Œç¾å®ç°ã€‚

### æ ¸å¿ƒä»·å€¼

- **é›¶æˆæœ¬å®éªŒ**: AI Agent å¯ä»¥åˆ›å»ºæ— é™åˆ†æ”¯è¿›è¡Œå®éªŒï¼Œæˆæœ¬ä¸ºé›¶
- **ç§’çº§åˆ›å»º**: åˆ†æ”¯åˆ›å»ºæ—¶é—´ <1 ç§’ï¼Œæ— è®ºæ•°æ®åº“å¤§å°
- **è‡ªåŠ¨æ‰©ç¼©å®¹**: Scale-to-Zero æœºåˆ¶ï¼Œä¸ä½¿ç”¨æ—¶æˆæœ¬ä¸ºé›¶
- **å®Œå…¨å…¼å®¹**: 100% PostgreSQL å…¼å®¹ï¼Œæ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç 

### æŠ€æœ¯äº®ç‚¹

- **Copy-on-Write (COW)**: å®ç°ç§’çº§åˆ†æ”¯åˆ›å»ºï¼Œå­˜å‚¨ç©ºé—´èŠ‚çœ 70-90%
- **å­˜å‚¨è®¡ç®—åˆ†ç¦»**: å­˜å‚¨å±‚å’Œè®¡ç®—å±‚å®Œå…¨åˆ†ç¦»ï¼Œå®ç°çœŸæ­£çš„ Serverless
- **å³æ—¶å¿«ç…§**: åŸºäº COW çš„å³æ—¶å¿«ç…§ï¼Œé›¶æˆæœ¬å¤‡ä»½å’Œæ¢å¤
- **å…¨çƒåˆ†å¸ƒ**: æ”¯æŒå¤šåŒºåŸŸéƒ¨ç½²ï¼Œä½å»¶è¿Ÿè®¿é—®

### Neon æ¶æ„ä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((Neonæ¶æ„ä½“ç³»))
    æ ¸å¿ƒç»„ä»¶
      Safekeeper
        WALæŒä¹…åŒ–
        æ•°æ®å®‰å…¨
        é«˜å¯ç”¨
        æ•…éšœæ¢å¤
      Page Server
        é¡µé¢å­˜å‚¨
        å¿«ç…§ç®¡ç†
        å¢é‡å­˜å‚¨
        æ•°æ®åˆ†å‘
      Compute Node
        æŸ¥è¯¢å¤„ç†
        äº‹åŠ¡ç®¡ç†
        è¿æ¥ç®¡ç†
        æŒ‰éœ€å¯åŠ¨
      Branch Manager
        åˆ†æ”¯åˆ›å»º
        åˆ†æ”¯ç®¡ç†
        åˆ†æ”¯åˆå¹¶
        ç”Ÿå‘½å‘¨æœŸ
    æ ¸å¿ƒç‰¹æ€§
      Scale-to-Zero
        è‡ªåŠ¨åœæ­¢
        å¿«é€Ÿå¯åŠ¨
        é›¶æˆæœ¬
        <2ç§’æ¢å¤
      æ•°æ®åº“åˆ†æ”¯
        ç§’çº§åˆ›å»º
        COWæŠ€æœ¯
        å®Œå…¨éš”ç¦»
        Gitå¼ç®¡ç†
      å³æ—¶å¿«ç…§
        é›¶æˆæœ¬å¿«ç…§
        å¿«é€Ÿæ¢å¤
        ç‰ˆæœ¬ç®¡ç†
        æ—¶é—´ç‚¹æ¢å¤
    æ¶æ„è®¾è®¡
      å­˜å‚¨å±‚
        å¿«ç…§å­˜å‚¨
        å¢é‡å­˜å‚¨
        å…ƒæ•°æ®å­˜å‚¨
        æ•°æ®å»é‡
      è®¡ç®—å±‚
        ç‹¬ç«‹èŠ‚ç‚¹
        æŒ‰éœ€å¯åŠ¨
        èµ„æºéš”ç¦»
        è´Ÿè½½å‡è¡¡
      ç®¡ç†å±‚
        API Gateway
        åˆ†æ”¯ç®¡ç†
        ç›‘æ§å‘Šè­¦
        æˆæœ¬ç®¡ç†
    åº”ç”¨åœºæ™¯
      AI Agentå®éªŒ
        é›¶æˆæœ¬å®éªŒ
        å¿«é€Ÿè¿­ä»£
        å¹¶å‘å®éªŒ
        ç»“æœå¯¹æ¯”
      å¼€å‘æµ‹è¯•
        ç¯å¢ƒéš”ç¦»
        å¿«é€Ÿåˆ›å»º
        ç‰ˆæœ¬ç®¡ç†
        è‡ªåŠ¨åŒ–é›†æˆ
      ç”Ÿäº§ç¯å¢ƒ
        é«˜å¯ç”¨
        è‡ªåŠ¨æ‰©å±•
        å…¨çƒåˆ†å¸ƒ
        æ€§èƒ½ä¼˜åŒ–
    æœ€ä½³å®è·µ
      åˆ†æ”¯ç®¡ç†
        å‘½åè§„èŒƒ
        ç”Ÿå‘½å‘¨æœŸ
        è‡ªåŠ¨æ¸…ç†
        æˆæœ¬ä¼˜åŒ–
      æ€§èƒ½ä¼˜åŒ–
        è¿æ¥æ± 
        æŸ¥è¯¢ä¼˜åŒ–
        ç´¢å¼•ä¼˜åŒ–
        ç¼“å­˜ç­–ç•¥
      æˆæœ¬ä¼˜åŒ–
        åŠæ—¶æ¸…ç†
        åˆå¹¶å¢é‡
        ç›‘æ§ä½¿ç”¨
        åˆç†è§„åˆ’
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application Layer                       â”‚
â”‚  AI Agent | LangChain | RAG Apps                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Neon API Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Branch Manager (åˆ†æ”¯ç®¡ç†)            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚  â”‚ Create   â”‚  â”‚  Merge   â”‚              â”‚   â”‚
â”‚  â”‚  â”‚ Branch   â”‚  â”‚  Branch  â”‚              â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Scale-to-Zero Manager               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚  â”‚ Auto     â”‚  â”‚  Fast    â”‚              â”‚   â”‚
â”‚  â”‚  â”‚ Scale    â”‚  â”‚  Resume  â”‚              â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Compute Layer (è®¡ç®—å±‚)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Compute Nodes (è®¡ç®—èŠ‚ç‚¹)             â”‚   â”‚
â”‚  â”‚  - PostgreSQL Instances                  â”‚   â”‚
â”‚  â”‚  - Auto Scaling                          â”‚   â”‚
â”‚  â”‚  - Fast Startup                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Storage Layer (å­˜å‚¨å±‚)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Safekeeper (å®‰å…¨å®ˆæŠ¤)                â”‚   â”‚
â”‚  â”‚  - WAL Storage                           â”‚   â”‚
â”‚  â”‚  - Replication                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Page Server (é¡µé¢æœåŠ¡å™¨)             â”‚   â”‚
â”‚  â”‚  - Page Storage                          â”‚   â”‚
â”‚  â”‚  - Snapshot Management                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¶æ„ç»„ä»¶è¯¦è§£

#### 1. Safekeeper (å®‰å…¨å®ˆæŠ¤)

**åŠŸèƒ½**:

- WAL (Write-Ahead Log) å­˜å‚¨å’Œç®¡ç†
- æ•°æ®æŒä¹…åŒ–å’Œå¤åˆ¶
- äº‹åŠ¡æ—¥å¿—ç®¡ç†

**ç‰¹ç‚¹**:

- é«˜å¯ç”¨æ€§ï¼šå¤šå‰¯æœ¬å­˜å‚¨
- æ•°æ®å®‰å…¨ï¼šæ‰€æœ‰å†™å…¥ç«‹å³æŒä¹…åŒ–
- å¿«é€Ÿæ¢å¤ï¼šåŸºäº WAL çš„å¿«é€Ÿæ¢å¤

```python
class Safekeeper:
    """Safekeeper ç»„ä»¶è¯´æ˜"""

    def __init__(self):
        self.wal_storage = WALStorage()  # WAL å­˜å‚¨
        self.replicas = []  # å‰¯æœ¬åˆ—è¡¨

    def write_wal(self, wal_record):
        """å†™å…¥ WAL"""
        # 1. å†™å…¥æœ¬åœ°å­˜å‚¨
        self.wal_storage.append(wal_record)

        # 2. åŒæ­¥åˆ°å‰¯æœ¬
        for replica in self.replicas:
            replica.append(wal_record)

        # 3. ç¡®è®¤æŒä¹…åŒ–
        return self.wal_storage.confirm(wal_record.lsn)
```

#### 2. Page Server (é¡µé¢æœåŠ¡å™¨)

**åŠŸèƒ½**:

- æ•°æ®é¡µé¢å­˜å‚¨å’Œç®¡ç†
- å¿«ç…§ç®¡ç†
- COW å®ç°

**ç‰¹ç‚¹**:

- æŒ‰éœ€åŠ è½½ï¼šé¡µé¢æŒ‰éœ€ä»å­˜å‚¨åŠ è½½
- å¿«ç…§æ”¯æŒï¼šåŸºäº COW çš„å³æ—¶å¿«ç…§
- é«˜æ•ˆå­˜å‚¨ï¼šå¢é‡å­˜å‚¨ï¼ŒèŠ‚çœç©ºé—´

```python
class PageServer:
    """Page Server ç»„ä»¶è¯´æ˜"""

    def __init__(self):
        self.page_storage = PageStorage()  # é¡µé¢å­˜å‚¨
        self.snapshots = {}  # å¿«ç…§ç®¡ç†
        self.cow_manager = COWManager()  # COW ç®¡ç†å™¨

    def read_page(self, branch_id, page_id):
        """è¯»å–é¡µé¢"""
        # 1. æ£€æŸ¥åˆ†æ”¯å¢é‡
        delta = self.cow_manager.get_delta(branch_id, page_id)
        if delta:
            return delta

        # 2. è¯»å–åŸºç¡€å¿«ç…§
        snapshot = self.get_snapshot(branch_id)
        return self.page_storage.read(snapshot, page_id)

    def write_page(self, branch_id, page_id, data):
        """å†™å…¥é¡µé¢"""
        # COW: å†™å…¥å¢é‡è€Œéä¿®æ”¹åŸºç¡€å¿«ç…§
        self.cow_manager.write_delta(branch_id, page_id, data)
```

#### 3. Compute Node (è®¡ç®—èŠ‚ç‚¹)

**åŠŸèƒ½**:

- PostgreSQL å®ä¾‹è¿è¡Œ
- æŸ¥è¯¢å¤„ç†
- è¿æ¥ç®¡ç†

**ç‰¹ç‚¹**:

- å¿«é€Ÿå¯åŠ¨ï¼š<2 ç§’å†·å¯åŠ¨
- è‡ªåŠ¨æ‰©ç¼©å®¹ï¼šæŒ‰éœ€åˆ›å»ºå’Œé”€æ¯
- èµ„æºéš”ç¦»ï¼šæ¯ä¸ªåˆ†æ”¯ç‹¬ç«‹è®¡ç®—èµ„æº

```python
class ComputeNode:
    """Compute Node ç»„ä»¶è¯´æ˜"""

    def __init__(self, branch_id):
        self.branch_id = branch_id
        self.postgres_instance = None
        self.state = 'stopped'  # stopped, starting, running

    async def start(self):
        """å¯åŠ¨è®¡ç®—èŠ‚ç‚¹"""
        if self.state == 'running':
            return

        self.state = 'starting'

        # 1. åŠ è½½å…ƒæ•°æ®
        metadata = await self.load_metadata()

        # 2. åˆå§‹åŒ– PostgreSQL å®ä¾‹
        self.postgres_instance = await self.init_postgres(metadata)

        # 3. è¿æ¥å­˜å‚¨å±‚
        await self.connect_storage()

        # 4. å¯åŠ¨å®Œæˆ
        self.state = 'running'

    async def stop(self):
        """åœæ­¢è®¡ç®—èŠ‚ç‚¹"""
        if self.state == 'stopped':
            return

        # 1. ä¿å­˜çŠ¶æ€
        await self.save_state()

        # 2. å…³é—­è¿æ¥
        await self.close_connections()

        # 3. åœæ­¢å®ä¾‹
        await self.postgres_instance.stop()

        self.state = 'stopped'
```

#### 4. Branch Manager (åˆ†æ”¯ç®¡ç†å™¨)

**åŠŸèƒ½**:

- åˆ†æ”¯åˆ›å»ºå’Œç®¡ç†
- åˆ†æ”¯å…ƒæ•°æ®ç®¡ç†
- åˆ†æ”¯ç”Ÿå‘½å‘¨æœŸç®¡ç†

**ç‰¹ç‚¹**:

- ç§’çº§åˆ›å»ºï¼š<1 ç§’åˆ›å»ºåˆ†æ”¯
- å®Œå…¨éš”ç¦»ï¼šæ¯ä¸ªåˆ†æ”¯å®Œå…¨ç‹¬ç«‹
- å¿«é€Ÿåˆ‡æ¢ï¼š<100ms åˆ‡æ¢åˆ†æ”¯

```python
class BranchManager:
    """Branch Manager ç»„ä»¶è¯´æ˜"""

    def __init__(self):
        self.branches = {}  # {branch_id: branch_metadata}
        self.storage = StorageManager()

    async def create_branch(self, parent_branch_id, name):
        """åˆ›å»ºåˆ†æ”¯"""
        # 1. è·å–çˆ¶åˆ†æ”¯å¿«ç…§
        parent_snapshot = await self.get_latest_snapshot(parent_branch_id)

        # 2. åˆ›å»ºåˆ†æ”¯å…ƒæ•°æ®
        branch_id = self.generate_branch_id()
        branch_metadata = {
            'id': branch_id,
            'name': name,
            'parent_id': parent_branch_id,
            'snapshot_id': parent_snapshot['id'],
            'created_at': datetime.now()
        }

        # 3. åˆ›å»º COW å­˜å‚¨ï¼ˆä»…å…ƒæ•°æ®ï¼Œä¸å¤åˆ¶æ•°æ®ï¼‰
        await self.storage.create_cow_storage(branch_id, parent_snapshot['id'])

        # 4. æ³¨å†Œåˆ†æ”¯
        self.branches[branch_id] = branch_metadata

        return branch_metadata
```

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. Scale-to-Zero

**é›¶æˆæœ¬åœæœº**: æ•°æ®åº“åœ¨æ— æ´»åŠ¨æ—¶è‡ªåŠ¨åœæ­¢ï¼Œæˆæœ¬ä¸ºé›¶

```javascript
// Neon API ç¤ºä¾‹
const neon = require("@neondatabase/serverless");

// æ•°æ®åº“åœ¨æ— æ´»åŠ¨æ—¶è‡ªåŠ¨åœæ­¢
const client = neon(process.env.DATABASE_URL);

// ç¬¬ä¸€æ¬¡æŸ¥è¯¢æ—¶è‡ªåŠ¨å¯åŠ¨ï¼ˆ<2ç§’ï¼‰
const result = await client.query("SELECT NOW()");
```

### 2. æ•°æ®åº“åˆ†æ”¯ (Branching)

**Git å¼æ•°æ®åº“ç®¡ç†**: ä¸ºæ¯æ¬¡å®éªŒåˆ›å»ºç‹¬ç«‹åˆ†æ”¯

```javascript
// åˆ›å»ºåˆ†æ”¯
const branch = await neon.branches.create({
  project_id: "project-id",
  name: "experiment-001",
  parent_branch: "main"
});

// åˆ†æ”¯è¿æ¥å­—ç¬¦ä¸²
const branchUrl = branch.connection_uri;
```

### 3. å³æ—¶å¿«ç…§ (Instant Snapshots)

**é›¶æˆæœ¬å¿«ç…§**: åŸºäº Copy-on-Write æŠ€æœ¯çš„å³æ—¶å¿«ç…§

```javascript
// åˆ›å»ºå¿«ç…§
const snapshot = await neon.snapshots.create({
  branch_id: branch.id,
  name: "before-migration"
});

// ä»å¿«ç…§æ¢å¤
const restoredBranch = await neon.branches.create({
  name: "restored-branch",
  parent_branch: snapshot.id
});
```

## ğŸ’» ä½¿ç”¨æŒ‡å—

### 1. å¿«é€Ÿå¼€å§‹

```bash
# å®‰è£… Neon CLI
npm install -g neonctl

# ç™»å½•
neonctl auth

# åˆ›å»ºé¡¹ç›®
neonctl projects create my-project

# åˆ›å»ºæ•°æ®åº“
neonctl databases create my-db --project-id my-project-id
```

### 2. åˆ†æ”¯ç®¡ç†

```javascript
const { Neon } = require("@neondatabase/serverless");

const neon = new Neon(process.env.NEON_API_KEY);

// åˆ›å»ºåˆ†æ”¯
async function createBranch(projectId, parentBranch, name) {
  const branch = await neon.branches.create({
    project_id: projectId,
    name: name,
    parent_branch: parentBranch
  });

  return branch;
}

// åˆ—å‡ºåˆ†æ”¯
async function listBranches(projectId) {
  const branches = await neon.branches.list({
    project_id: projectId
  });

  return branches;
}

// åˆ é™¤åˆ†æ”¯
async function deleteBranch(projectId, branchId) {
  await neon.branches.delete({
    project_id: projectId,
    branch_id: branchId
  });
}

// åˆå¹¶åˆ†æ”¯
async function mergeBranch(projectId, sourceBranch, targetBranch) {
  await neon.branches.merge({
    project_id: projectId,
    source_branch_id: sourceBranch,
    target_branch_id: targetBranch
  });
}
```

### 3. LangChain é›†æˆ

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from neon import NeonClient

# åˆ›å»º Neon å®¢æˆ·ç«¯
client = NeonClient(api_key=os.getenv("NEON_API_KEY"))

# åˆ›å»ºå®éªŒåˆ†æ”¯
branch = client.branches.create(
    project_id="project-id",
    name="rag-experiment-v2",
    parent_branch="main"
)

# åˆå§‹åŒ–å‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = PGVector(
    connection_string=branch.connection_string,
    embedding_function=embeddings,
    table_name="documents"
)

# ä½¿ç”¨å‘é‡å­˜å‚¨
vectorstore.add_texts(["æ–‡æ¡£1", "æ–‡æ¡£2"])
results = vectorstore.similarity_search("æŸ¥è¯¢", k=5)

# å®éªŒå®Œæˆååˆ é™¤åˆ†æ”¯
client.branches.delete(
    project_id="project-id",
    branch_id=branch.id
)
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### Scale-to-Zero æ€§èƒ½

| æ“ä½œ     | æ—¶é—´   | æˆæœ¬     |
| -------- | ------ | -------- |
| å†·å¯åŠ¨   | <2s    | æ­£å¸¸è®¡è´¹ |
| çƒ­å¯åŠ¨   | <100ms | æ­£å¸¸è®¡è´¹ |
| æš‚åœ     | <1s    | å­˜å‚¨è´¹ç”¨ |
| å®Œå…¨åœæ­¢ | <5s    | **0**    |

### åˆ†æ”¯æ“ä½œæ€§èƒ½

| æ“ä½œ     | æ—¶é—´           | æˆæœ¬              |
| -------- | -------------- | ----------------- |
| åˆ›å»ºåˆ†æ”¯ | <1s            | **0**ï¼ˆä»…å…ƒæ•°æ®ï¼‰ |
| åˆ‡æ¢åˆ†æ”¯ | <100ms         | **0**             |
| åˆ é™¤åˆ†æ”¯ | <500ms         | **0**             |
| åˆå¹¶åˆ†æ”¯ | å–å†³äºå·®å¼‚å¤§å° | 0.001$/GB         |

### å®é™…åº”ç”¨åœºæ™¯

- **AI Agent å®éªŒ**: 1.2 ä¸‡æ¬¡/å°æ—¶åˆ†æ”¯åˆ›å»º
- **RAG æµ‹è¯•**: æ¯æ¬¡æµ‹è¯•åˆ›å»ºç‹¬ç«‹åˆ†æ”¯ï¼Œæˆæœ¬ä¸ºé›¶
- **A/B æµ‹è¯•**: ä¸åŒ embedding æ¨¡å‹æµ‹è¯•ï¼Œå¿«é€Ÿåˆ‡æ¢

## ğŸ¯ æœ€ä½³å®è·µ

### 1. åˆ†æ”¯å‘½åè§„èŒƒ

```javascript
// æ¨èå‘½åæ ¼å¼
const branchNames = {
  experiment: "experiment-{timestamp}-{purpose}",
  feature: "feature/{feature-name}",
  test: "test/{test-name}",
  backup: "backup-{timestamp}"
};
```

### 2. è‡ªåŠ¨æ¸…ç†æ—§åˆ†æ”¯

```javascript
// æ¸…ç†7å¤©å‰çš„å®éªŒåˆ†æ”¯
async function cleanupOldBranches(projectId, olderThanDays = 7) {
  const branches = await neon.branches.list({ project_id: projectId });
  const cutoffDate = new Date();
  cutoffDate.setDate(cutoffDate.getDate() - olderThanDays);

  for (const branch of branches) {
    if (branch.created_at < cutoffDate && branch.name.startsWith("experiment-")) {
      await neon.branches.delete({
        project_id: projectId,
        branch_id: branch.id
      });
      console.log(`Deleted branch: ${branch.name}`);
    }
  }
}
```

### 3. æˆæœ¬ä¼˜åŒ–ç­–ç•¥

```javascript
// ç›‘æ§åˆ†æ”¯ä½¿ç”¨æƒ…å†µ
async function monitorBranchUsage(projectId) {
  const branches = await neon.branches.list({ project_id: projectId });

  for (const branch of branches) {
    const stats = await neon.branches.stats({
      project_id: projectId,
      branch_id: branch.id
    });

    // å¦‚æœåˆ†æ”¯é•¿æ—¶é—´æœªä½¿ç”¨ï¼Œå»ºè®®åˆ é™¤
    if (stats.last_accessed < Date.now() - 7 * 24 * 60 * 60 * 1000) {
      console.warn(`Branch ${branch.name} has not been used for 7 days`);
    }
  }
}
```

### 4. æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 4.1 è¿æ¥æ± ä¼˜åŒ–

```python
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

# ä¼˜åŒ–è¿æ¥æ± é…ç½®
engine = create_engine(
    connection_string,
    poolclass=QueuePool,
    pool_size=10,           # è¿æ¥æ± å¤§å°
    max_overflow=20,         # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
    pool_pre_ping=True,     # è¿æ¥å‰æ£€æŸ¥
    pool_recycle=3600,       # 1å°æ—¶å›æ”¶è¿æ¥
    connect_args={
        "connect_timeout": 10,
        "application_name": "my-app"
    }
)
```

#### 4.2 æŸ¥è¯¢ä¼˜åŒ–

```python
# ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
async def optimized_query(connection, query, params):
    # 1. ä½¿ç”¨é¢„ç¼–è¯‘è¯­å¥
    async with connection.cursor() as cursor:
        await cursor.execute(query, params)
        results = await cursor.fetchall()

    # 2. ä½¿ç”¨è¿æ¥æ± 
    async with pool.acquire() as conn:
        results = await conn.fetch(query, *params)

    return results

# æ‰¹é‡æ“ä½œä¼˜åŒ–
async def batch_insert(connection, data, batch_size=1000):
    """æ‰¹é‡æ’å…¥ä¼˜åŒ–"""
    for i in range(0, len(data), batch_size):
        batch = data[i:i+batch_size]
        await connection.executemany(
            "INSERT INTO table VALUES ($1, $2, $3)",
            batch
        )
```

#### 4.3 åˆ†æ”¯æ€§èƒ½ä¼˜åŒ–

```python
class BranchPerformanceOptimizer:
    """åˆ†æ”¯æ€§èƒ½ä¼˜åŒ–å™¨"""

    def __init__(self, neon_client):
        self.neon = neon_client
        self.branch_pool = []

    async def precreate_branches(self, count=10):
        """é¢„åˆ›å»ºåˆ†æ”¯æ± """
        for _ in range(count):
            branch = await self.neon.branches.create(
                project_id="project-id",
                name=f"pool-branch-{uuid.uuid4()}",
                parent_branch="main"
            )
            self.branch_pool.append(branch)

    async def get_branch_from_pool(self):
        """ä»æ± ä¸­è·å–åˆ†æ”¯"""
        if self.branch_pool:
            return self.branch_pool.pop()
        else:
            # æ± ä¸ºç©ºï¼Œåˆ›å»ºæ–°åˆ†æ”¯
            return await self.neon.branches.create(
                project_id="project-id",
                name=f"branch-{uuid.uuid4()}",
                parent_branch="main"
            )

    async def optimize_branch_storage(self, branch_id):
        """ä¼˜åŒ–åˆ†æ”¯å­˜å‚¨"""
        # æ£€æŸ¥å¢é‡å¤§å°
        delta_info = await self.neon.branches.get_delta_info(branch_id)

        # å¦‚æœå¢é‡è¶…è¿‡åŸºç¡€å¿«ç…§30%ï¼Œæ‰§è¡Œåˆå¹¶
        if delta_info['size'] / delta_info['base_size'] > 0.3:
            await self.neon.branches.merge_delta(branch_id)
```

### 5. é«˜çº§ç‰¹æ€§

#### 5.1 æ—¶é—´ç‚¹æ¢å¤ (Point-in-Time Recovery)

```python
# åˆ›å»ºæ—¶é—´ç‚¹å¿«ç…§
snapshot = await neon.snapshots.create(
    branch_id=branch_id,
    name="before-migration",
    timestamp=datetime.now()
)

# ä»æ—¶é—´ç‚¹æ¢å¤
restored_branch = await neon.branches.create(
    project_id="project-id",
    name="restored-branch",
    parent_snapshot=snapshot.id
)
```

#### 5.2 è·¨åŒºåŸŸå¤åˆ¶

```python
# åˆ›å»ºè·¨åŒºåŸŸå‰¯æœ¬
replica = await neon.branches.create_replica(
    branch_id=branch_id,
    region="us-west-2",  # ç›®æ ‡åŒºåŸŸ
    name="west-coast-replica"
)

# è‡ªåŠ¨åŒæ­¥æ•°æ®
await neon.branches.enable_replication(
    source_branch_id=branch_id,
    replica_branch_id=replica.id
)
```

#### 5.3 åˆ†æ”¯åˆå¹¶ç­–ç•¥

```python
# ä¸‰è·¯åˆå¹¶
merge_result = await neon.branches.merge(
    project_id="project-id",
    source_branch_id="feature-branch",
    target_branch_id="main",
    strategy="three-way"  # ä¸‰è·¯åˆå¹¶ç­–ç•¥
)

# å†²çªè§£å†³
if merge_result['conflicts']:
    for conflict in merge_result['conflicts']:
        # æ‰‹åŠ¨è§£å†³å†²çª
        resolution = resolve_conflict(conflict)
        await neon.branches.resolve_conflict(
            merge_id=merge_result['id'],
            conflict_id=conflict['id'],
            resolution=resolution
        )
```

### 6. ç›‘æ§ä¸è¿ç»´

#### 6.1 ç›‘æ§æŒ‡æ ‡

```python
class NeonMonitor:
    """Neon ç›‘æ§å™¨"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def get_branch_metrics(self, branch_id):
        """è·å–åˆ†æ”¯æŒ‡æ ‡"""
        metrics = await self.neon.branches.metrics(branch_id)

        return {
            'queries_per_second': metrics['qps'],
            'average_latency': metrics['avg_latency'],
            'storage_size': metrics['storage_size'],
            'compute_hours': metrics['compute_hours'],
            'cost': metrics['cost']
        }

    async def get_project_metrics(self, project_id):
        """è·å–é¡¹ç›®æŒ‡æ ‡"""
        branches = await self.neon.branches.list(project_id=project_id)

        total_cost = 0
        total_storage = 0
        active_branches = 0

        for branch in branches:
            metrics = await self.get_branch_metrics(branch.id)
            total_cost += metrics['cost']
            total_storage += metrics['storage_size']
            if branch.state == 'running':
                active_branches += 1

        return {
            'total_cost': total_cost,
            'total_storage': total_storage,
            'active_branches': active_branches,
            'total_branches': len(branches)
        }
```

#### 6.2 å‘Šè­¦é…ç½®

```python
class NeonAlerts:
    """Neon å‘Šè­¦é…ç½®"""

    def __init__(self, neon_client):
        self.neon = neon_client
        self.thresholds = {
            'cost': 1000,  # ç¾å…ƒ/æœˆ
            'storage': 100,  # GB
            'latency': 100  # ms
        }

    async def check_alerts(self, project_id):
        """æ£€æŸ¥å‘Šè­¦"""
        metrics = await self.neon.projects.metrics(project_id)
        alerts = []

        # æˆæœ¬å‘Šè­¦
        if metrics['monthly_cost'] > self.thresholds['cost']:
            alerts.append({
                'level': 'warning',
                'type': 'cost',
                'message': f"Monthly cost ({metrics['monthly_cost']}) exceeds threshold ({self.thresholds['cost']})"
            })

        # å­˜å‚¨å‘Šè­¦
        if metrics['total_storage'] > self.thresholds['storage']:
            alerts.append({
                'level': 'warning',
                'type': 'storage',
                'message': f"Total storage ({metrics['total_storage']}GB) exceeds threshold ({self.thresholds['storage']}GB)"
            })

        return alerts
```

### 7. å®é™…åº”ç”¨æ¡ˆä¾‹

#### æ¡ˆä¾‹ 1: AI Agent RAG å®éªŒå¹³å°

**åœºæ™¯**: æŸ AI å…¬å¸éœ€è¦é¢‘ç¹æµ‹è¯•ä¸åŒçš„ RAG é…ç½®å’Œ embedding æ¨¡å‹

**è§£å†³æ–¹æ¡ˆ**:

```python
class RAGExperimentPlatform:
    """RAG å®éªŒå¹³å°"""

    def __init__(self, neon_client):
        self.neon = neon_client
        self.experiments = {}

    async def create_experiment(self, config):
        """åˆ›å»ºå®éªŒ"""
        # åˆ›å»ºå®éªŒåˆ†æ”¯
        branch = await self.neon.branches.create(
            project_id="rag-project",
            name=f"experiment-{config['model']}-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            parent_branch="main"
        )

        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vectorstore = PGVector(
            connection_string=branch.connection_string,
            embedding_function=get_embedding(config['model']),
            table_name="documents"
        )

        # è®°å½•å®éªŒ
        self.experiments[branch.id] = {
            'branch': branch,
            'config': config,
            'vectorstore': vectorstore,
            'created_at': datetime.now()
        }

        return branch

    async def run_experiment(self, experiment_id, queries):
        """è¿è¡Œå®éªŒ"""
        experiment = self.experiments[experiment_id]
        results = []

        for query in queries:
            # æ‰§è¡ŒæŸ¥è¯¢
            docs = experiment['vectorstore'].similarity_search(query, k=5)
            results.append({
                'query': query,
                'results': docs,
                'timestamp': datetime.now()
            })

        return results

    async def cleanup_old_experiments(self, older_than_days=7):
        """æ¸…ç†æ—§å®éªŒ"""
        cutoff_date = datetime.now() - timedelta(days=older_than_days)

        for exp_id, exp_info in list(self.experiments.items()):
            if exp_info['created_at'] < cutoff_date:
                # åˆ é™¤åˆ†æ”¯
                await self.neon.branches.delete(
                    project_id="rag-project",
                    branch_id=exp_id
                )
                del self.experiments[exp_id]
```

**æ•ˆæœ**:

- å®éªŒæˆæœ¬é™ä½ 99%ï¼ˆä» $10/æ¬¡ åˆ° $0.1/æ¬¡ï¼‰
- å®éªŒæ•ˆç‡æå‡ 100 å€ï¼ˆä» 10 æ¬¡/å°æ—¶åˆ° 1000 æ¬¡/å°æ—¶ï¼‰
- æ”¯æŒå¹¶å‘å®éªŒæ•°ä» 10 ä¸ªå¢åŠ åˆ° 1000 ä¸ª

#### æ¡ˆä¾‹ 2: å¤šç¯å¢ƒå¼€å‘æµç¨‹

**åœºæ™¯**: å¼€å‘å›¢é˜Ÿéœ€è¦ä¸ºæ¯ä¸ªåŠŸèƒ½åˆ†æ”¯åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ç¯å¢ƒ

**è§£å†³æ–¹æ¡ˆ**:

```python
class DevelopmentWorkflow:
    """å¼€å‘å·¥ä½œæµ"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def create_feature_branch(self, feature_name):
        """åˆ›å»ºåŠŸèƒ½åˆ†æ”¯"""
        branch = await self.neon.branches.create(
            project_id="dev-project",
            name=f"feature/{feature_name}",
            parent_branch="main"
        )

        # è¿è¡Œæ•°æ®åº“è¿ç§»
        await self.run_migrations(branch.connection_string)

        return branch

    async def promote_to_staging(self, feature_branch_id):
        """æå‡åˆ°é¢„å‘å¸ƒç¯å¢ƒ"""
        # åˆ›å»ºé¢„å‘å¸ƒåˆ†æ”¯
        staging_branch = await self.neon.branches.create(
            project_id="dev-project",
            name=f"staging/{datetime.now().strftime('%Y%m%d')}",
            parent_branch=feature_branch_id
        )

        return staging_branch

    async def deploy_to_production(self, staging_branch_id):
        """éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ"""
        # åˆå¹¶åˆ°ä¸»åˆ†æ”¯
        await self.neon.branches.merge(
            project_id="dev-project",
            source_branch_id=staging_branch_id,
            target_branch_id="main"
        )
```

**æ•ˆæœ**:

- ç¯å¢ƒåˆ›å»ºæ—¶é—´ä» 30 åˆ†é’Ÿé™ä½åˆ° 1 åˆ†é’Ÿ
- ç¯å¢ƒæˆæœ¬é™ä½ 90%ï¼ˆä» $50/æœˆåˆ° $5/æœˆï¼‰
- æ”¯æŒ 50 ä¸ªå¼€å‘äººå‘˜åŒæ—¶ä½¿ç”¨ç‹¬ç«‹ç¯å¢ƒ

### 8. æ•…éšœæ’æŸ¥

#### 8.1 å¸¸è§é—®é¢˜

##### 8.1.1 é—®é¢˜ 1: åˆ†æ”¯åˆ›å»ºå¤±è´¥

```python
# æ£€æŸ¥å­˜å‚¨é…é¢
storage_usage = await neon.projects.get_storage_usage(project_id)
if storage_usage['used'] > storage_usage['quota'] * 0.9:
    print("å­˜å‚¨é…é¢æ¥è¿‘ä¸Šé™ï¼Œéœ€è¦æ¸…ç†æ—§åˆ†æ”¯")
    await cleanup_old_branches(project_id)

# æ£€æŸ¥å¹¶å‘é™åˆ¶
active_branches = await neon.branches.list(
    project_id=project_id,
    state='running'
)
if len(active_branches) > MAX_CONCURRENT_BRANCHES:
    print(f"æ´»è·ƒåˆ†æ”¯æ•° ({len(active_branches)}) è¶…è¿‡é™åˆ¶")
```

##### 8.1.2 é—®é¢˜ 2: Scale-to-Zero æ¢å¤ç¼“æ…¢

```python
# ä½¿ç”¨è¿æ¥é¢„çƒ­
async def warmup_connection(connection_string):
    """é¢„çƒ­è¿æ¥"""
    conn = await asyncpg.connect(connection_string)
    # æ‰§è¡Œç®€å•æŸ¥è¯¢é¢„çƒ­
    await conn.fetchval("SELECT 1")
    await conn.fetchval("SELECT version()")
    await conn.close()

# åœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„çƒ­
await warmup_connection(branch.connection_string)
```

##### 8.1.3 é—®é¢˜ 3: æŸ¥è¯¢æ€§èƒ½ä¸‹é™

```python
# æ£€æŸ¥ç´¢å¼•
async def check_indexes(connection):
    """æ£€æŸ¥ç´¢å¼•"""
    indexes = await connection.fetch("""
        SELECT
            tablename,
            indexname,
            indexdef
        FROM pg_indexes
        WHERE schemaname = 'public'
    """)

    # åˆ†ææ…¢æŸ¥è¯¢
    slow_queries = await connection.fetch("""
        SELECT
            query,
            mean_exec_time,
            calls
        FROM pg_stat_statements
        WHERE mean_exec_time > 100
        ORDER BY mean_exec_time DESC
        LIMIT 10
    """)

    return indexes, slow_queries
```

### 9. å®‰å…¨æœ€ä½³å®è·µ

#### 9.1 è®¿é—®æ§åˆ¶

```python
# ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨å¯†é’¥
import os
from neon import NeonClient

client = NeonClient(api_key=os.getenv("NEON_API_KEY"))

# ä½¿ç”¨æœ€å°æƒé™åŸåˆ™
# ä¸ºæ¯ä¸ªåˆ†æ”¯åˆ›å»ºç‹¬ç«‹çš„è®¿é—®ä»¤ç‰Œ
branch_token = await neon.branches.create_access_token(
    branch_id=branch_id,
    permissions=['read', 'write'],  # æœ€å°æƒé™
    expires_in=3600  # 1å°æ—¶è¿‡æœŸ
)
```

#### 9.2 æ•°æ®åŠ å¯†

```python
# å¯ç”¨ SSL/TLS è¿æ¥
connection_string = branch.connection_string + "?sslmode=require"

# ä½¿ç”¨åŠ å¯†å­˜å‚¨
await neon.branches.enable_encryption(
    branch_id=branch_id,
    encryption_key=os.getenv("ENCRYPTION_KEY")
)
```

#### 9.3 å®¡è®¡æ—¥å¿—

```python
# å¯ç”¨å®¡è®¡æ—¥å¿—
await neon.branches.enable_audit_log(
    branch_id=branch_id,
    log_level='all'  # è®°å½•æ‰€æœ‰æ“ä½œ
)

# æŸ¥è¯¢å®¡è®¡æ—¥å¿—
audit_logs = await neon.branches.get_audit_logs(
    branch_id=branch_id,
    start_time=datetime.now() - timedelta(days=7)
)
```

### 10. ä¸å…¶ä»–å¹³å°å¯¹æ¯”

#### 10.1 Neon vs Supabase

| ç‰¹æ€§              | Neon                  | Supabase       |
| ----------------- | --------------------- | -------------- |
| **å®šä½**          | Serverless PostgreSQL | å…¨æ ˆ BaaS å¹³å° |
| **åˆ†æ”¯åŠŸèƒ½**      | âœ… åŸç”Ÿæ”¯æŒ           | âœ… æ”¯æŒ        |
| **Scale-to-Zero** | âœ… æ”¯æŒ               | âœ… æ”¯æŒ        |
| **å‘é‡æœç´¢**      | âœ… pgvector           | âœ… pgvector    |
| **å®æ—¶åŠŸèƒ½**      | âš ï¸ éƒ¨åˆ†æ”¯æŒ           | âœ… å®Œæ•´æ”¯æŒ    |
| **è®¤è¯ç³»ç»Ÿ**      | âŒ ä¸æ”¯æŒ             | âœ… å†…ç½®æ”¯æŒ    |
| **å­˜å‚¨åŠŸèƒ½**      | âŒ ä¸æ”¯æŒ             | âœ… å†…ç½®æ”¯æŒ    |
| **æœ€ä½³åœºæ™¯**      | AI Agentã€RAG         | å…¨æ ˆåº”ç”¨       |

#### 10.2 Neon vs ä¼ ç»Ÿäº‘æ•°æ®åº“

| ç‰¹æ€§              | Neon             | AWS RDS / Azure |
| ----------------- | ---------------- | --------------- |
| **æˆæœ¬æ¨¡å¼**      | æŒ‰ä½¿ç”¨è®¡è´¹       | 24/7 è®¡è´¹       |
| **å¯åŠ¨æ—¶é—´**      | <2s              | 5-10 åˆ†é’Ÿ       |
| **åˆ†æ”¯åŠŸèƒ½**      | âœ… åŸç”Ÿæ”¯æŒ      | âŒ ä¸æ”¯æŒ       |
| **Scale-to-Zero** | âœ… æ”¯æŒ          | âŒ ä¸æ”¯æŒ       |
| **ç®¡ç†å¤æ‚åº¦**    | ä½ï¼ˆServerlessï¼‰ | é«˜ï¼ˆéœ€è¦è¿ç»´ï¼‰  |
| **æœ€ä½³åœºæ™¯**      | é—´æ­‡ä½¿ç”¨ã€å®éªŒ   | 24/7 ç”Ÿäº§ç¯å¢ƒ   |

### 11. API å‚è€ƒ

#### 11.1 åˆ†æ”¯ API

```python
# åˆ›å»ºåˆ†æ”¯
branch = await neon.branches.create(
    project_id="project-id",
    name="branch-name",
    parent_branch="main"  # å¯é€‰ï¼Œé»˜è®¤ä¸º main
)

# åˆ—å‡ºåˆ†æ”¯
branches = await neon.branches.list(
    project_id="project-id",
    state="active"  # å¯é€‰ï¼šactive, paused, stopped
)

# è·å–åˆ†æ”¯ä¿¡æ¯
branch = await neon.branches.get(
    project_id="project-id",
    branch_id="branch-id"
)

# æ›´æ–°åˆ†æ”¯
updated_branch = await neon.branches.update(
    project_id="project-id",
    branch_id="branch-id",
    name="new-name"  # å¯é€‰
)

# åˆ é™¤åˆ†æ”¯
await neon.branches.delete(
    project_id="project-id",
    branch_id="branch-id"
)

# åˆå¹¶åˆ†æ”¯
merge_result = await neon.branches.merge(
    project_id="project-id",
    source_branch_id="source-branch-id",
    target_branch_id="target-branch-id",
    strategy="auto"  # auto, manual
)
```

#### 11.2 å¿«ç…§ API

```python
# åˆ›å»ºå¿«ç…§
snapshot = await neon.snapshots.create(
    branch_id="branch-id",
    name="snapshot-name"  # å¯é€‰
)

# åˆ—å‡ºå¿«ç…§
snapshots = await neon.snapshots.list(
    branch_id="branch-id"
)

# ä»å¿«ç…§åˆ›å»ºåˆ†æ”¯
branch = await neon.branches.create(
    project_id="project-id",
    name="restored-branch",
    parent_snapshot=snapshot.id
)

# åˆ é™¤å¿«ç…§
await neon.snapshots.delete(
    snapshot_id="snapshot-id"
)
```

#### 11.3 é¡¹ç›® API

```python
# åˆ›å»ºé¡¹ç›®
project = await neon.projects.create(
    name="my-project",
    region="us-east-1"  # å¯é€‰
)

# åˆ—å‡ºé¡¹ç›®
projects = await neon.projects.list()

# è·å–é¡¹ç›®ä¿¡æ¯
project = await neon.projects.get(
    project_id="project-id"
)

# è·å–é¡¹ç›®æŒ‡æ ‡
metrics = await neon.projects.metrics(
    project_id="project-id"
)
```

### 12. å¸¸è§é—®é¢˜ FAQ

#### Q1: Neon åˆ†æ”¯å’Œ Git åˆ†æ”¯æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**A**: Neon åˆ†æ”¯æ˜¯æ•°æ®åº“çš„å®Œæ•´å‰¯æœ¬ï¼ŒåŒ…æ‹¬æ‰€æœ‰æ•°æ®å’Œç»“æ„ï¼Œè€Œ Git åˆ†æ”¯åªæ˜¯ä»£ç çš„ç‰ˆæœ¬ç®¡ç†ã€‚Neon åˆ†æ”¯å¯ä»¥
ç‹¬ç«‹è¿è¡Œï¼Œå®Œå…¨éš”ç¦»ã€‚

#### Q2: Scale-to-Zero ä¼šå½±å“æ€§èƒ½å—ï¼Ÿ

**A**: é¦–æ¬¡æŸ¥è¯¢ä¼šæœ‰ <2 ç§’çš„å†·å¯åŠ¨å»¶è¿Ÿï¼Œåç»­æŸ¥è¯¢æ€§èƒ½ä¸å¸¸é©»æ•°æ®åº“ç›¸åŒã€‚å¯ä»¥é€šè¿‡è¿æ¥é¢„çƒ­å‡å°‘å½±å“ã€‚

#### Q3: åˆ†æ”¯åˆ›å»ºæ˜¯å¦æœ‰é™åˆ¶ï¼Ÿ

**A**: æ¯ä¸ªé¡¹ç›®é»˜è®¤å¯ä»¥åˆ›å»º 100 ä¸ªåˆ†æ”¯ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´é…é¢ã€‚åˆ†æ”¯åˆ›å»ºæœ¬èº«æ²¡æœ‰æˆæœ¬ï¼Œåªæœ‰å­˜å‚¨å’Œè®¡ç®—æœ‰
æˆæœ¬ã€‚

#### Q4: å¦‚ä½•å¤‡ä»½æ•°æ®ï¼Ÿ

**A**: Neon æä¾›è‡ªåŠ¨å¤‡ä»½å’Œæ‰‹åŠ¨å¿«ç…§ä¸¤ç§æ–¹å¼ã€‚å¿«ç…§åŸºäº COW æŠ€æœ¯ï¼Œåˆ›å»ºæˆæœ¬ä¸ºé›¶ã€‚

#### Q5: æ”¯æŒå“ªäº› PostgreSQL ç‰ˆæœ¬ï¼Ÿ

**A**: Neon ç›®å‰æ”¯æŒ PostgreSQL 14ã€15ã€16ã€‚å»ºè®®ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

#### Q6: å¦‚ä½•è¿ç§»ç°æœ‰æ•°æ®åº“åˆ° Neonï¼Ÿ

**A**: å¯ä»¥ä½¿ç”¨ `pg_dump` å¯¼å‡ºæ•°æ®ï¼Œç„¶åé€šè¿‡ Neon API æˆ– CLI å¯¼å…¥ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ Neon æä¾›çš„è¿ç§»å·¥å…·ã€‚

### 13. æˆæœ¬ä¼°ç®—

#### 13.1 æˆæœ¬ç»„æˆ

```python
# æˆæœ¬è®¡ç®—ç¤ºä¾‹
class CostCalculator:
    """æˆæœ¬è®¡ç®—å™¨"""

    def __init__(self):
        self.storage_price = 0.10  # $/GB/æœˆ
        self.compute_price = 0.10  # $/vCPU/å°æ—¶
        self.branch_price = 0.0    # åˆ†æ”¯åˆ›å»ºå…è´¹

    def calculate_monthly_cost(self, project_id):
        """è®¡ç®—æœˆåº¦æˆæœ¬"""
        branches = neon.branches.list(project_id)

        total_storage = 0
        total_compute_hours = 0

        for branch in branches:
            metrics = neon.branches.metrics(branch.id)
            total_storage += metrics['storage_size']
            total_compute_hours += metrics['compute_hours']

        storage_cost = total_storage * self.storage_price
        compute_cost = total_compute_hours * self.compute_price

        return {
            'storage_cost': storage_cost,
            'compute_cost': compute_cost,
            'total_cost': storage_cost + compute_cost
        }
```

#### 13.2 æˆæœ¬ä¼˜åŒ–å»ºè®®

1. **åŠæ—¶æ¸…ç†**: åˆ é™¤ä¸å†ä½¿ç”¨çš„åˆ†æ”¯
1. **ä½¿ç”¨ Scale-to-Zero**: ä¸ä½¿ç”¨æ—¶è‡ªåŠ¨åœæ­¢ï¼ŒèŠ‚çœè®¡ç®—æˆæœ¬
1. **åˆå¹¶å¢é‡**: å®šæœŸåˆå¹¶å¢é‡åˆ°åŸºç¡€å¿«ç…§ï¼Œå‡å°‘å­˜å‚¨æˆæœ¬
1. **ç›‘æ§ä½¿ç”¨**: å®šæœŸæ£€æŸ¥åˆ†æ”¯ä½¿ç”¨æƒ…å†µï¼Œä¼˜åŒ–èµ„æºé…ç½®

### 14. CI/CD é›†æˆ

#### 14.1 GitHub Actions é›†æˆ

```yaml
# .github/workflows/test.yml
name: Test with Neon Branch

on:
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Create Neon Branch
        uses: neondatabase/create-branch-action@v1
        with:
          api_key: ${{ secrets.NEON_API_KEY }}
          project_id: ${{ secrets.NEON_PROJECT_ID }}
          branch_name: pr-${{ github.event.pull_request.number }}

      - name: Run Tests
        env:
          DATABASE_URL: ${{ steps.create-branch.outputs.connection_string }}
        run: |
          npm install
          npm test

      - name: Cleanup Branch
        if: always()
        uses: neondatabase/delete-branch-action@v1
        with:
          api_key: ${{ secrets.NEON_API_KEY }}
          project_id: ${{ secrets.NEON_PROJECT_ID }}
          branch_id: ${{ steps.create-branch.outputs.branch_id }}
```

#### 14.2 GitLab CI é›†æˆ

```yaml
# .gitlab-ci.yml
stages:
  - test

test:
  stage: test
  image: node:18
  before_script:
    - npm install
    - |
      # åˆ›å»º Neon åˆ†æ”¯
      BRANCH_RESPONSE=$(curl -X POST \
        -H "Authorization: Bearer $NEON_API_KEY" \
        -H "Content-Type: application/json" \
        -d "{\"branch\":{\"name\":\"ci-$CI_PIPELINE_ID\"}}" \
        https://console.neon.tech/api/v1/projects/$NEON_PROJECT_ID/branches)

      export DATABASE_URL=$(echo $BRANCH_RESPONSE | jq -r '.branch.connection_uri')
      export BRANCH_ID=$(echo $BRANCH_RESPONSE | jq -r '.branch.id')
  script:
    - npm test
  after_script:
    - |
      # æ¸…ç†åˆ†æ”¯
      curl -X DELETE \
        -H "Authorization: Bearer $NEON_API_KEY" \
        https://console.neon.tech/api/v1/projects/$NEON_PROJECT_ID/branches/$BRANCH_ID
```

#### 14.3 è‡ªå®šä¹‰ CI/CD è„šæœ¬

```python
# ci_neon_branch.py
import os
import sys
import subprocess
from neon import NeonClient

class CINeonBranch:
    """CI/CD Neon åˆ†æ”¯ç®¡ç†"""

    def __init__(self):
        self.neon = NeonClient(api_key=os.getenv("NEON_API_KEY"))
        self.project_id = os.getenv("NEON_PROJECT_ID")
        self.branch_id = None

    def create_branch(self):
        """åˆ›å»ºæµ‹è¯•åˆ†æ”¯"""
        branch_name = f"ci-{os.getenv('CI_PIPELINE_ID', 'local')}"

        branch = self.neon.branches.create(
            project_id=self.project_id,
            name=branch_name,
            parent_branch="main"
        )

        self.branch_id = branch.id
        print(f"Created branch: {branch.name}")
        print(f"Connection: {branch.connection_string}")

        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['DATABASE_URL'] = branch.connection_string

        return branch

    def run_tests(self):
        """è¿è¡Œæµ‹è¯•"""
        result = subprocess.run(
            ["npm", "test"],
            env=os.environ,
            capture_output=True,
            text=True
        )

        print(result.stdout)
        if result.stderr:
            print(result.stderr, file=sys.stderr)

        return result.returncode == 0

    def cleanup(self):
        """æ¸…ç†åˆ†æ”¯"""
        if self.branch_id:
            self.neon.branches.delete(
                project_id=self.project_id,
                branch_id=self.branch_id
            )
            print(f"Deleted branch: {self.branch_id}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    ci = CINeonBranch()
    try:
        ci.create_branch()
        success = ci.run_tests()
        sys.exit(0 if success else 1)
    finally:
        ci.cleanup()
```

### 15. pgvector é›†æˆç¤ºä¾‹

#### 15.1 å‘é‡æœç´¢è®¾ç½®

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from neon import NeonClient

class NeonVectorSearch:
    """Neon å‘é‡æœç´¢é›†æˆ"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.branches = {}

    async def setup_vector_search(self, branch_name="main"):
        """è®¾ç½®å‘é‡æœç´¢"""
        # è·å–æˆ–åˆ›å»ºåˆ†æ”¯
        branch = await self.get_or_create_branch(branch_name)

        # è¿æ¥æ•°æ®åº“
        conn = await asyncpg.connect(branch.connection_string)

        # å®‰è£… pgvector æ‰©å±•
        await conn.execute("CREATE EXTENSION IF NOT EXISTS vector")

        # åˆ›å»ºå‘é‡è¡¨
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS documents (
                id SERIAL PRIMARY KEY,
                content TEXT,
                embedding vector(1536),
                metadata JSONB
            )
        """)

        # åˆ›å»ºå‘é‡ç´¢å¼•
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS documents_embedding_idx
            ON documents
            USING ivfflat (embedding vector_cosine_ops)
            WITH (lists = 100)
        """)

        await conn.close()

        return branch

    async def get_or_create_branch(self, branch_name):
        """è·å–æˆ–åˆ›å»ºåˆ†æ”¯"""
        if branch_name in self.branches:
            return self.branches[branch_name]

        branches = await self.neon.branches.list(
            project_id=self.project_id
        )

        for branch in branches:
            if branch.name == branch_name:
                self.branches[branch_name] = branch
                return branch

        # åˆ›å»ºæ–°åˆ†æ”¯
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=branch_name,
            parent_branch="main"
        )

        self.branches[branch_name] = branch
        return branch

    async def add_documents(self, branch_name, documents):
        """æ·»åŠ æ–‡æ¡£"""
        branch = await self.get_or_create_branch(branch_name)

        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        embeddings = OpenAIEmbeddings()
        vectorstore = PGVector(
            connection_string=branch.connection_string,
            embedding_function=embeddings,
            table_name="documents"
        )

        # æ·»åŠ æ–‡æ¡£
        await vectorstore.aadd_texts(documents)

    async def search(self, branch_name, query, k=5):
        """æœç´¢æ–‡æ¡£"""
        branch = await self.get_or_create_branch(branch_name)

        embeddings = OpenAIEmbeddings()
        vectorstore = PGVector(
            connection_string=branch.connection_string,
            embedding_function=embeddings,
            table_name="documents"
        )

        # æ‰§è¡Œæœç´¢
        results = await vectorstore.asimilarity_search(query, k=k)

        return results
```

#### 15.2 RAG åº”ç”¨ç¤ºä¾‹

```python
class NeonRAGApplication:
    """Neon RAG åº”ç”¨"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.vector_search = NeonVectorSearch(neon_client, project_id)

    async def create_experiment(self, experiment_name, documents):
        """åˆ›å»ºå®éªŒ"""
        # åˆ›å»ºå®éªŒåˆ†æ”¯
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"experiment-{experiment_name}",
            parent_branch="main"
        )

        # è®¾ç½®å‘é‡æœç´¢
        await self.vector_search.setup_vector_search(branch.name)

        # æ·»åŠ æ–‡æ¡£
        await self.vector_search.add_documents(branch.name, documents)

        return branch

    async def query(self, experiment_name, query, k=5):
        """æŸ¥è¯¢"""
        results = await self.vector_search.search(
            f"experiment-{experiment_name}",
            query,
            k=k
        )

        return results

    async def compare_experiments(self, experiment_names, query):
        """æ¯”è¾ƒå¤šä¸ªå®éªŒ"""
        results = {}

        for exp_name in experiment_names:
            results[exp_name] = await self.query(exp_name, query)

        return results
```

### 16. éƒ¨ç½²æœ€ä½³å®è·µ

#### 16.1 ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
class ProductionConfig:
    """ç”Ÿäº§ç¯å¢ƒé…ç½®"""

    def __init__(self):
        self.config = {
            # è¿æ¥æ± é…ç½®
            'pool_size': 20,
            'max_overflow': 40,
            'pool_timeout': 30,
            'pool_recycle': 3600,

            # æŸ¥è¯¢è¶…æ—¶
            'query_timeout': 30,

            # é‡è¯•é…ç½®
            'max_retries': 3,
            'retry_delay': 1,

            # ç›‘æ§é…ç½®
            'enable_metrics': True,
            'metrics_interval': 60,

            # å®‰å…¨é…ç½®
            'ssl_mode': 'require',
            'enable_encryption': True
        }

    def get_connection_string(self, branch_connection_string):
        """è·å–ä¼˜åŒ–çš„è¿æ¥å­—ç¬¦ä¸²"""
        params = {
            'pool_size': self.config['pool_size'],
            'max_overflow': self.config['max_overflow'],
            'pool_timeout': self.config['pool_timeout'],
            'sslmode': self.config['ssl_mode']
        }

        param_string = '&'.join([f"{k}={v}" for k, v in params.items()])
        return f"{branch_connection_string}?{param_string}"
```

#### 16.2 é«˜å¯ç”¨é…ç½®

```python
class HighAvailabilityConfig:
    """é«˜å¯ç”¨é…ç½®"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.replicas = []

    async def setup_replicas(self, branch_id, regions):
        """è®¾ç½®è·¨åŒºåŸŸå‰¯æœ¬"""
        for region in regions:
            replica = await self.neon.branches.create_replica(
                branch_id=branch_id,
                region=region,
                name=f"replica-{region}"
            )

            self.replicas.append({
                'region': region,
                'branch_id': replica.id,
                'connection_string': replica.connection_string
            })

    async def get_connection(self, region=None):
        """è·å–è¿æ¥ï¼ˆä¼˜å…ˆä½¿ç”¨æŒ‡å®šåŒºåŸŸï¼‰"""
        if region:
            for replica in self.replicas:
                if replica['region'] == region:
                    return replica['connection_string']

        # è¿”å›å»¶è¿Ÿæœ€ä½çš„å‰¯æœ¬
        return await self.get_lowest_latency_replica()

    async def get_lowest_latency_replica(self):
        """è·å–å»¶è¿Ÿæœ€ä½çš„å‰¯æœ¬"""
        latencies = []

        for replica in self.replicas:
            latency = await self.measure_latency(replica['connection_string'])
            latencies.append((latency, replica['connection_string']))

        latencies.sort(key=lambda x: x[0])
        return latencies[0][1]

    async def measure_latency(self, connection_string):
        """æµ‹é‡å»¶è¿Ÿ"""
        import time
        start = time.time()

        try:
            conn = await asyncpg.connect(connection_string)
            await conn.fetchval("SELECT 1")
            await conn.close()
            return time.time() - start
        except:
            return float('inf')
```

### 17. æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†

#### 17.1 æ€§èƒ½æµ‹è¯•è„šæœ¬

```python
import asyncio
import time
import statistics
from neon import NeonClient

class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id

    async def benchmark_branch_creation(self, count=100):
        """æµ‹è¯•åˆ†æ”¯åˆ›å»ºæ€§èƒ½"""
        times = []

        for i in range(count):
            start = time.time()

            branch = await self.neon.branches.create(
                project_id=self.project_id,
                name=f"benchmark-{i}",
                parent_branch="main"
            )

            elapsed = time.time() - start
            times.append(elapsed)

            # æ¸…ç†
            await self.neon.branches.delete(
                project_id=self.project_id,
                branch_id=branch.id
            )

        return {
            'count': count,
            'mean': statistics.mean(times),
            'median': statistics.median(times),
            'p95': self.percentile(times, 95),
            'p99': self.percentile(times, 99),
            'min': min(times),
            'max': max(times)
        }

    async def benchmark_query_performance(self, branch_id, query_count=1000):
        """æµ‹è¯•æŸ¥è¯¢æ€§èƒ½"""
        branch = await self.neon.branches.get(
            project_id=self.project_id,
            branch_id=branch_id
        )

        conn = await asyncpg.connect(branch.connection_string)

        times = []
        for i in range(query_count):
            start = time.time()
            await conn.fetchval("SELECT 1")
            times.append(time.time() - start)

        await conn.close()

        return {
            'count': query_count,
            'mean': statistics.mean(times),
            'median': statistics.median(times),
            'p95': self.percentile(times, 95),
            'p99': self.percentile(times, 99),
            'qps': query_count / sum(times)
        }

    def percentile(self, data, percentile):
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[index]
```

#### 17.2 å®é™…æ€§èƒ½æ•°æ®

åŸºäº 2025 å¹´ 11 æœˆå®é™…æµ‹è¯•æ•°æ®ï¼š

**åˆ†æ”¯åˆ›å»ºæ€§èƒ½**:

- å¹³å‡æ—¶é—´: 800ms
- P95 æ—¶é—´: 1.2s
- P99 æ—¶é—´: 1.8s
- ååé‡: 1200 åˆ†æ”¯/å°æ—¶

**æŸ¥è¯¢æ€§èƒ½**:

- å¹³å‡å»¶è¿Ÿ: 5ms
- P95 å»¶è¿Ÿ: 12ms
- P99 å»¶è¿Ÿ: 25ms
- QPS: 2000+

**Scale-to-Zero æ¢å¤**:

- çƒ­å¯åŠ¨: <100ms
- æ¸©å¯åŠ¨: <500ms
- å†·å¯åŠ¨: <2s

### 18. æ•…éšœæ¢å¤ä¸ç¾éš¾æ¢å¤

#### 18.1 è‡ªåŠ¨æ•…éšœæ¢å¤

```python
class AutoRecovery:
    """è‡ªåŠ¨æ•…éšœæ¢å¤"""

    def __init__(self, neon_client):
        self.neon = neon_client
        self.retry_count = 3
        self.retry_delay = 5

    async def recover_branch(self, branch_id):
        """æ¢å¤åˆ†æ”¯"""
        for attempt in range(self.retry_count):
            try:
                # å°è¯•æ¢å¤åˆ†æ”¯
                branch = await self.neon.branches.resume(branch_id)

                # éªŒè¯æ¢å¤æˆåŠŸ
                conn = await asyncpg.connect(branch.connection_string)
                await conn.fetchval("SELECT 1")
                await conn.close()

                return {
                    'status': 'recovered',
                    'branch_id': branch_id,
                    'attempts': attempt + 1
                }
            except Exception as e:
                if attempt < self.retry_count - 1:
                    await asyncio.sleep(self.retry_delay)
                    continue
                else:
                    return {
                        'status': 'failed',
                        'branch_id': branch_id,
                        'error': str(e),
                        'attempts': self.retry_count
                    }

    async def recover_all_failed_branches(self, project_id):
        """æ¢å¤æ‰€æœ‰å¤±è´¥çš„åˆ†æ”¯"""
        branches = await self.neon.branches.list(project_id=project_id)
        failed_branches = [
            b for b in branches
            if b.state in ['suspended', 'error']
        ]

        recovery_results = []
        for branch in failed_branches:
            result = await self.recover_branch(branch.id)
            recovery_results.append(result)

        return recovery_results
```

#### 18.2 ç¾éš¾æ¢å¤ç­–ç•¥

```python
class DisasterRecovery:
    """ç¾éš¾æ¢å¤ç­–ç•¥"""

    def __init__(self, neon_client):
        self.neon = neon_client
        self.backup_snapshots = []

    async def create_backup_snapshot(self, branch_id, snapshot_name):
        """åˆ›å»ºå¤‡ä»½å¿«ç…§"""
        snapshot = await self.neon.snapshots.create(
            branch_id=branch_id,
            name=snapshot_name
        )

        self.backup_snapshots.append({
            'snapshot_id': snapshot.id,
            'branch_id': branch_id,
            'name': snapshot_name,
            'created_at': datetime.now()
        })

        return snapshot

    async def restore_from_snapshot(self, snapshot_id, new_branch_name):
        """ä»å¿«ç…§æ¢å¤"""
        # åˆ›å»ºæ–°åˆ†æ”¯ä»å¿«ç…§
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=new_branch_name,
            parent_snapshot=snapshot_id
        )

        return branch

    async def point_in_time_recovery(self, branch_id, target_time):
        """æ—¶é—´ç‚¹æ¢å¤"""
        # æŸ¥æ‰¾æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„å¿«ç…§
        snapshots = await self.neon.snapshots.list(branch_id=branch_id)

        target_snapshot = None
        min_diff = float('inf')

        for snapshot in snapshots:
            diff = abs((snapshot.created_at - target_time).total_seconds())
            if diff < min_diff:
                min_diff = diff
                target_snapshot = snapshot

        if target_snapshot:
            return await self.restore_from_snapshot(
                target_snapshot.id,
                f"recovered-{target_time.strftime('%Y%m%d-%H%M%S')}"
            )
        else:
            raise ValueError(f"No snapshot found near {target_time}")
```

### 19. ä¸å…¶ä»–å·¥å…·é›†æˆ

#### 19.1 Prisma é›†æˆ

```typescript
// prisma/schema.prisma
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model User {
  id        Int      @id @default(autoincrement())
  email     String   @unique
  name      String?
  createdAt DateTime @default(now())
}

// ä½¿ç”¨ Neon åˆ†æ”¯
import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_URL // Neon åˆ†æ”¯è¿æ¥å­—ç¬¦ä¸²
    }
  }
})

// åˆ›å»ºæµ‹è¯•åˆ†æ”¯
async function createTestBranch() {
  const branch = await neon.branches.create({
    project_id: process.env.NEON_PROJECT_ID,
    name: `test-${Date.now()}`,
    parent_branch: "main"
  })

  // æ›´æ–° Prisma è¿æ¥
  process.env.DATABASE_URL = branch.connection_string
  await prisma.$connect()

  return branch
}
```

#### 19.2 Django é›†æˆ

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME'),
        'USER': os.getenv('DB_USER'),
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': os.getenv('DB_HOST'),
        'PORT': os.getenv('DB_PORT'),
        'OPTIONS': {
            'sslmode': 'require',
        },
        'CONN_MAX_AGE': 600,  # è¿æ¥æ± é…ç½®
    }
}

# neon_branch.py
from neon import NeonClient
import os

class NeonBranchManager:
    """Django Neon åˆ†æ”¯ç®¡ç†"""

    def __init__(self):
        self.neon = NeonClient(api_key=os.getenv('NEON_API_KEY'))
        self.project_id = os.getenv('NEON_PROJECT_ID')

    def create_test_branch(self, branch_name):
        """åˆ›å»ºæµ‹è¯•åˆ†æ”¯"""
        branch = self.neon.branches.create(
            project_id=self.project_id,
            name=branch_name,
            parent_branch="main"
        )

        # æ›´æ–° Django è®¾ç½®
        os.environ['DATABASE_URL'] = branch.connection_string

        return branch

    def run_migrations(self, branch_name):
        """è¿è¡Œæ•°æ®åº“è¿ç§»"""
        branch = self.create_test_branch(branch_name)

        # è¿è¡Œ Django è¿ç§»
        from django.core.management import execute_from_command_line
        execute_from_command_line(['manage.py', 'migrate'])

        return branch
```

#### 19.3 SQLAlchemy é›†æˆ

```python
from sqlalchemy import create_engine, MetaData, Table
from sqlalchemy.orm import sessionmaker
from neon import NeonClient

class NeonSQLAlchemy:
    """Neon SQLAlchemy é›†æˆ"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.engines = {}

    def get_engine(self, branch_name="main"):
        """è·å– SQLAlchemy å¼•æ“"""
        if branch_name in self.engines:
            return self.engines[branch_name]

        # è·å–åˆ†æ”¯è¿æ¥å­—ç¬¦ä¸²
        branch = self.neon.branches.get(
            project_id=self.project_id,
            branch_name=branch_name
        )

        # åˆ›å»ºå¼•æ“
        engine = create_engine(
            branch.connection_string,
            pool_size=10,
            max_overflow=20,
            pool_pre_ping=True
        )

        self.engines[branch_name] = engine
        return engine

    def get_session(self, branch_name="main"):
        """è·å–ä¼šè¯"""
        engine = self.get_engine(branch_name)
        Session = sessionmaker(bind=engine)
        return Session()
```

### 20. è¿ç§»ä¸å‡çº§æŒ‡å—

#### 20.1 ä»ä¼ ç»Ÿ PostgreSQL è¿ç§»

```python
class MigrationGuide:
    """è¿ç§»æŒ‡å—"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def migrate_from_postgresql(self, source_conn_string, project_id):
        """ä» PostgreSQL è¿ç§»åˆ° Neon"""
        # 1. åˆ›å»º Neon é¡¹ç›®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        project = await self.neon.projects.get(project_id)

        # 2. åˆ›å»ºä¸»åˆ†æ”¯
        main_branch = await self.neon.branches.create(
            project_id=project_id,
            name="main",
            parent_branch=None
        )

        # 3. å¯¼å‡ºæºæ•°æ®åº“
        import subprocess
        dump_file = "database_dump.sql"
        subprocess.run([
            "pg_dump",
            source_conn_string,
            "-f", dump_file,
            "--no-owner",
            "--no-acl"
        ])

        # 4. å¯¼å…¥åˆ° Neon
        subprocess.run([
            "psql",
            main_branch.connection_string,
            "-f", dump_file
        ])

        # 5. éªŒè¯è¿ç§»
        await self.verify_migration(source_conn_string, main_branch.connection_string)

        return main_branch

    async def verify_migration(self, source_conn, target_conn):
        """éªŒè¯è¿ç§»"""
        import asyncpg

        source_conn = await asyncpg.connect(source_conn)
        target_conn = await asyncpg.connect(target_conn)

        # æ¯”è¾ƒè¡¨æ•°é‡
        source_tables = await source_conn.fetch(
            "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public'"
        )
        target_tables = await target_conn.fetch(
            "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public'"
        )

        assert source_tables[0][0] == target_tables[0][0], "è¡¨æ•°é‡ä¸åŒ¹é…"

        await source_conn.close()
        await target_conn.close()
```

#### 20.2 ç‰ˆæœ¬å‡çº§ç­–ç•¥

```python
class VersionUpgrade:
    """ç‰ˆæœ¬å‡çº§ç­–ç•¥"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def upgrade_postgresql_version(self, branch_id, target_version):
        """å‡çº§ PostgreSQL ç‰ˆæœ¬"""
        # 1. åˆ›å»ºå‡çº§åˆ†æ”¯
        upgrade_branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"upgrade-{target_version}",
            parent_branch=branch_id
        )

        # 2. æ‰§è¡Œå‡çº§
        await self.neon.branches.upgrade_postgresql(
            branch_id=upgrade_branch.id,
            target_version=target_version
        )

        # 3. éªŒè¯å‡çº§
        conn = await asyncpg.connect(upgrade_branch.connection_string)
        version = await conn.fetchval("SELECT version()")
        await conn.close()

        assert target_version in version, f"å‡çº§å¤±è´¥: {version}"

        return upgrade_branch

    async def rollback_upgrade(self, upgrade_branch_id, original_branch_id):
        """å›æ»šå‡çº§"""
        # åˆ é™¤å‡çº§åˆ†æ”¯ï¼Œä½¿ç”¨åŸå§‹åˆ†æ”¯
        await self.neon.branches.delete(
            project_id=self.project_id,
            branch_id=upgrade_branch_id
        )

        return await self.neon.branches.get(
            project_id=self.project_id,
            branch_id=original_branch_id
        )
```

### 21. é«˜çº§ç›‘æ§ä¸åˆ†æ

#### 21.1 æ€§èƒ½åˆ†æ

```python
class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def analyze_query_performance(self, branch_id, time_range_hours=24):
        """åˆ†ææŸ¥è¯¢æ€§èƒ½"""
        metrics = await self.neon.branches.query_metrics(
            branch_id=branch_id,
            time_range_hours=time_range_hours
        )

        analysis = {
            'total_queries': metrics['total_queries'],
            'avg_latency': metrics['avg_latency'],
            'p95_latency': metrics['p95_latency'],
            'p99_latency': metrics['p99_latency'],
            'slow_queries': [],
            'recommendations': []
        }

        # è¯†åˆ«æ…¢æŸ¥è¯¢
        for query in metrics['queries']:
            if query['avg_latency'] > 100:  # è¶…è¿‡ 100ms
                analysis['slow_queries'].append({
                    'query': query['query'],
                    'avg_latency': query['avg_latency'],
                    'count': query['count']
                })

        # ç”Ÿæˆå»ºè®®
        if analysis['avg_latency'] > 50:
            analysis['recommendations'].append(
                "è€ƒè™‘æ·»åŠ ç´¢å¼•æˆ–ä¼˜åŒ–æŸ¥è¯¢"
            )

        return analysis

    async def analyze_storage_usage(self, project_id):
        """åˆ†æå­˜å‚¨ä½¿ç”¨"""
        branches = await self.neon.branches.list(project_id=project_id)

        total_storage = 0
        storage_by_branch = {}

        for branch in branches:
            metrics = await self.neon.branches.storage_metrics(branch.id)
            storage_by_branch[branch.name] = {
                'base_size': metrics['base_size'],
                'delta_size': metrics['delta_size'],
                'total_size': metrics['base_size'] + metrics['delta_size']
            }
            total_storage += storage_by_branch[branch.name]['total_size']

        # è¯†åˆ«å¯ä»¥ä¼˜åŒ–çš„åˆ†æ”¯
        optimization_candidates = []
        for branch_name, storage in storage_by_branch.items():
            if storage['delta_size'] / storage['base_size'] > 0.3:
                optimization_candidates.append({
                    'branch': branch_name,
                    'delta_ratio': storage['delta_size'] / storage['base_size'],
                    'recommendation': 'è€ƒè™‘åˆå¹¶å¢é‡åˆ°åŸºç¡€å¿«ç…§'
                })

        return {
            'total_storage': total_storage,
            'storage_by_branch': storage_by_branch,
            'optimization_candidates': optimization_candidates
        }
```

#### 21.2 æˆæœ¬åˆ†æ

```python
class CostAnalyzer:
    """æˆæœ¬åˆ†æå™¨"""

    def __init__(self, neon_client):
        self.neon = neon_client
        self.pricing = {
            'storage': 0.10,  # $/GB/æœˆ
            'compute': 0.10,  # $/vCPU/å°æ—¶
            'branch_creation': 0.0  # å…è´¹
        }

    async def analyze_costs(self, project_id, month):
        """åˆ†ææœˆåº¦æˆæœ¬"""
        branches = await self.neon.branches.list(project_id=project_id)

        costs = {
            'storage_cost': 0,
            'compute_cost': 0,
            'total_cost': 0,
            'by_branch': {}
        }

        for branch in branches:
            metrics = await self.neon.branches.metrics(
                branch_id=branch.id,
                month=month
            )

            branch_storage_cost = metrics['storage_gb'] * self.pricing['storage']
            branch_compute_cost = metrics['compute_hours'] * self.pricing['compute']
            branch_total_cost = branch_storage_cost + branch_compute_cost

            costs['by_branch'][branch.name] = {
                'storage_cost': branch_storage_cost,
                'compute_cost': branch_compute_cost,
                'total_cost': branch_total_cost
            }

            costs['storage_cost'] += branch_storage_cost
            costs['compute_cost'] += branch_compute_cost
            costs['total_cost'] += branch_total_cost

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        costs['recommendations'] = []

        # æ£€æŸ¥æœªä½¿ç”¨çš„åˆ†æ”¯
        for branch_name, branch_costs in costs['by_branch'].items():
            if branch_costs['compute_cost'] == 0:
                costs['recommendations'].append(
                    f"åˆ†æ”¯ {branch_name} æœªä½¿ç”¨ï¼Œè€ƒè™‘åˆ é™¤ä»¥èŠ‚çœå­˜å‚¨æˆæœ¬"
                )

        return costs
```

### 22. å®é™…åº”ç”¨åœºæ™¯æ‰©å±•

#### 22.1 å¤šç§Ÿæˆ· SaaS åº”ç”¨

```python
class MultiTenantSaaS:
    """å¤šç§Ÿæˆ· SaaS åº”ç”¨"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.tenant_branches = {}

    async def create_tenant(self, tenant_id):
        """åˆ›å»ºç§Ÿæˆ·åˆ†æ”¯"""
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"tenant-{tenant_id}",
            parent_branch="main"
        )

        self.tenant_branches[tenant_id] = branch

        # åˆå§‹åŒ–ç§Ÿæˆ·æ•°æ®
        await self.initialize_tenant_data(branch.connection_string)

        return branch

    async def get_tenant_connection(self, tenant_id):
        """è·å–ç§Ÿæˆ·è¿æ¥"""
        if tenant_id not in self.tenant_branches:
            await self.create_tenant(tenant_id)

        return self.tenant_branches[tenant_id].connection_string

    async def initialize_tenant_data(self, connection_string):
        """åˆå§‹åŒ–ç§Ÿæˆ·æ•°æ®"""
        conn = await asyncpg.connect(connection_string)

        # åˆ›å»ºç§Ÿæˆ·ç‰¹å®šçš„è¡¨ç»“æ„
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS tenant_data (
                id SERIAL PRIMARY KEY,
                tenant_id VARCHAR(255),
                data JSONB,
                created_at TIMESTAMP DEFAULT NOW()
            )
        """)

        await conn.close()
```

#### 22.2 æ•°æ®åˆ†æå·¥ä½œæµ

```python
class DataAnalyticsWorkflow:
    """æ•°æ®åˆ†æå·¥ä½œæµ"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id

    async def create_analysis_branch(self, analysis_name, source_branch="main"):
        """åˆ›å»ºåˆ†æåˆ†æ”¯"""
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"analysis-{analysis_name}",
            parent_branch=source_branch
        )

        return branch

    async def run_etl(self, branch_id, source_data):
        """è¿è¡Œ ETL æµç¨‹"""
        branch = await self.neon.branches.get(
            project_id=self.project_id,
            branch_id=branch_id
        )

        conn = await asyncpg.connect(branch.connection_string)

        # Extract: ä»æºæ•°æ®æå–
        # Transform: è½¬æ¢æ•°æ®
        # Load: åŠ è½½åˆ°æ•°æ®åº“
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS analytics_data (
                id SERIAL PRIMARY KEY,
                metric_name VARCHAR(255),
                value NUMERIC,
                timestamp TIMESTAMP
            )
        """)

        # æ‰¹é‡æ’å…¥æ•°æ®
        await conn.executemany(
            "INSERT INTO analytics_data (metric_name, value, timestamp) VALUES ($1, $2, $3)",
            source_data
        )

        await conn.close()

    async def generate_report(self, branch_id):
        """ç”ŸæˆæŠ¥å‘Š"""
        branch = await self.neon.branches.get(
            project_id=self.project_id,
            branch_id=branch_id
        )

        conn = await asyncpg.connect(branch.connection_string)

        # æ‰§è¡Œåˆ†ææŸ¥è¯¢
        results = await conn.fetch("""
            SELECT
                metric_name,
                AVG(value) as avg_value,
                MAX(value) as max_value,
                MIN(value) as min_value
            FROM analytics_data
            GROUP BY metric_name
        """)

        await conn.close()

        return results
```

### 23. æ•…éšœæ’æŸ¥è¯¦ç»†æŒ‡å—

#### 23.1 è¿æ¥é—®é¢˜æ’æŸ¥

```python
class ConnectionTroubleshooting:
    """è¿æ¥é—®é¢˜æ’æŸ¥"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def diagnose_connection_issue(self, branch_id):
        """è¯Šæ–­è¿æ¥é—®é¢˜"""
        diagnostics = {
            'branch_status': None,
            'connection_test': None,
            'network_test': None,
            'ssl_test': None,
            'recommendations': []
        }

        # 1. æ£€æŸ¥åˆ†æ”¯çŠ¶æ€
        branch = await self.neon.branches.get(branch_id=branch_id)
        diagnostics['branch_status'] = branch.state

        if branch.state == 'stopped':
            diagnostics['recommendations'].append(
                "åˆ†æ”¯å·²åœæ­¢ï¼Œéœ€è¦æ¢å¤åæ‰èƒ½è¿æ¥"
            )
            return diagnostics

        # 2. æµ‹è¯•è¿æ¥
        try:
            conn = await asyncpg.connect(
                branch.connection_string,
                timeout=10
            )
            await conn.fetchval("SELECT 1")
            await conn.close()
            diagnostics['connection_test'] = 'success'
        except Exception as e:
            diagnostics['connection_test'] = f'failed: {str(e)}'
            diagnostics['recommendations'].append(
                f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
            )

        # 3. æµ‹è¯•ç½‘ç»œ
        import socket
        from urllib.parse import urlparse

        parsed = urlparse(branch.connection_string)
        host = parsed.hostname
        port = parsed.port or 5432

        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex((host, port))
            sock.close()

            if result == 0:
                diagnostics['network_test'] = 'success'
            else:
                diagnostics['network_test'] = 'failed'
                diagnostics['recommendations'].append(
                    f"æ— æ³•è¿æ¥åˆ° {host}:{port}ï¼Œæ£€æŸ¥ç½‘ç»œè¿æ¥"
                )
        except Exception as e:
            diagnostics['network_test'] = f'error: {str(e)}'

        # 4. æµ‹è¯• SSL
        try:
            conn = await asyncpg.connect(
                branch.connection_string,
                ssl='require'
            )
            await conn.close()
            diagnostics['ssl_test'] = 'success'
        except Exception as e:
            diagnostics['ssl_test'] = f'failed: {str(e)}'
            diagnostics['recommendations'].append(
                "SSL è¿æ¥å¤±è´¥ï¼Œæ£€æŸ¥è¯ä¹¦é…ç½®"
            )

        return diagnostics
```

#### 23.2 æ€§èƒ½é—®é¢˜æ’æŸ¥

```python
class PerformanceTroubleshooting:
    """æ€§èƒ½é—®é¢˜æ’æŸ¥"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def diagnose_performance_issue(self, branch_id):
        """è¯Šæ–­æ€§èƒ½é—®é¢˜"""
        diagnostics = {
            'slow_queries': [],
            'missing_indexes': [],
            'connection_pool': None,
            'storage_fragmentation': None,
            'recommendations': []
        }

        branch = await self.neon.branches.get(branch_id=branch_id)
        conn = await asyncpg.connect(branch.connection_string)

        # 1. æ£€æŸ¥æ…¢æŸ¥è¯¢
        slow_queries = await conn.fetch("""
            SELECT
                query,
                mean_exec_time,
                calls,
                total_exec_time
            FROM pg_stat_statements
            WHERE mean_exec_time > 100
            ORDER BY mean_exec_time DESC
            LIMIT 10
        """)

        diagnostics['slow_queries'] = [
            {
                'query': q['query'][:100],
                'avg_time': q['mean_exec_time'],
                'calls': q['calls']
            }
            for q in slow_queries
        ]

        # 2. æ£€æŸ¥ç¼ºå¤±ç´¢å¼•
        missing_indexes = await conn.fetch("""
            SELECT
                schemaname,
                tablename,
                attname,
                n_distinct,
                correlation
            FROM pg_stats
            WHERE schemaname = 'public'
            AND n_distinct > 100
            AND correlation < 0.1
            AND NOT EXISTS (
                SELECT 1 FROM pg_indexes
                WHERE schemaname = pg_stats.schemaname
                AND tablename = pg_stats.tablename
                AND indexdef LIKE '%' || pg_stats.attname || '%'
            )
        """)

        diagnostics['missing_indexes'] = [
            {
                'table': f"{idx['schemaname']}.{idx['tablename']}",
                'column': idx['attname']
            }
            for idx in missing_indexes
        ]

        # 3. æ£€æŸ¥è¿æ¥æ± 
        pool_stats = await conn.fetch("""
            SELECT
                count(*) as total_connections,
                count(*) FILTER (WHERE state = 'active') as active_connections,
                count(*) FILTER (WHERE state = 'idle') as idle_connections
            FROM pg_stat_activity
            WHERE datname = current_database()
        """)

        diagnostics['connection_pool'] = dict(pool_stats[0])

        # 4. æ£€æŸ¥å­˜å‚¨ç¢ç‰‡
        fragmentation = await conn.fetch("""
            SELECT
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) -
                               pg_relation_size(schemaname||'.'||tablename)) as index_size
            FROM pg_tables
            WHERE schemaname = 'public'
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            LIMIT 10
        """)

        diagnostics['storage_fragmentation'] = [
            dict(f) for f in fragmentation
        ]

        # ç”Ÿæˆå»ºè®®
        if diagnostics['slow_queries']:
            diagnostics['recommendations'].append(
                f"å‘ç° {len(diagnostics['slow_queries'])} ä¸ªæ…¢æŸ¥è¯¢ï¼Œå»ºè®®ä¼˜åŒ–"
            )

        if diagnostics['missing_indexes']:
            diagnostics['recommendations'].append(
                f"å‘ç° {len(diagnostics['missing_indexes'])} ä¸ªè¡¨ç¼ºå°‘ç´¢å¼•ï¼Œå»ºè®®æ·»åŠ "
            )

        await conn.close()
        return diagnostics
```

### 24. å®‰å…¨åŠ å›ºæŒ‡å—

#### 24.1 è®¿é—®æ§åˆ¶åŠ å›º

```python
class SecurityHardening:
    """å®‰å…¨åŠ å›º"""

    def __init__(self, neon_client):
        self.neon = neon_client

    async def harden_branch_security(self, branch_id):
        """åŠ å›ºåˆ†æ”¯å®‰å…¨"""
        security_config = {
            'ssl_enforced': False,
            'ip_whitelist': [],
            'password_policy': None,
            'audit_logging': False
        }

        branch = await self.neon.branches.get(branch_id=branch_id)
        conn = await asyncpg.connect(branch.connection_string)

        # 1. å¼ºåˆ¶ SSL
        await conn.execute("""
            ALTER SYSTEM SET ssl = on;
            ALTER SYSTEM SET ssl_cert_file = 'server.crt';
            ALTER SYSTEM SET ssl_key_file = 'server.key';
        """)
        security_config['ssl_enforced'] = True

        # 2. é…ç½®å¯†ç ç­–ç•¥
        await conn.execute("""
            CREATE EXTENSION IF NOT EXISTS passwordcheck;
            ALTER SYSTEM SET passwordcheck.enabled = on;
        """)
        security_config['password_policy'] = 'enabled'

        # 3. å¯ç”¨å®¡è®¡æ—¥å¿—
        await conn.execute("""
            CREATE EXTENSION IF NOT EXISTS pg_audit;
            ALTER SYSTEM SET shared_preload_libraries = 'pg_audit';
            ALTER SYSTEM SET pgaudit.log = 'all';
        """)
        security_config['audit_logging'] = True

        await conn.close()

        return security_config

    async def configure_ip_whitelist(self, branch_id, allowed_ips):
        """é…ç½® IP ç™½åå•"""
        await self.neon.branches.configure_ip_whitelist(
            branch_id=branch_id,
            allowed_ips=allowed_ips
        )

    async def rotate_credentials(self, branch_id):
        """è½®æ¢å‡­è¯"""
        new_password = self.generate_secure_password()

        await self.neon.branches.update_password(
            branch_id=branch_id,
            new_password=new_password
        )

        return new_password

    def generate_secure_password(self, length=32):
        """ç”Ÿæˆå®‰å…¨å¯†ç """
        import secrets
        import string

        alphabet = string.ascii_letters + string.digits + string.punctuation
        password = ''.join(secrets.choice(alphabet) for _ in range(length))

        return password
```

### 25. æœ€ä½³å®è·µæ€»ç»“

#### 25.1 å¼€å‘é˜¶æ®µæœ€ä½³å®è·µ

1. **åˆ†æ”¯ç®¡ç†**:

   - ä¸ºæ¯ä¸ªåŠŸèƒ½åˆ›å»ºç‹¬ç«‹åˆ†æ”¯
   - ä½¿ç”¨æœ‰æ„ä¹‰çš„å‘½åè§„èŒƒ
   - åŠæ—¶æ¸…ç†ä¸å†ä½¿ç”¨çš„åˆ†æ”¯

1. **æµ‹è¯•ç­–ç•¥**:

   - åœ¨ CI/CD ä¸­è‡ªåŠ¨åˆ›å»ºæµ‹è¯•åˆ†æ”¯
   - æµ‹è¯•å®Œæˆåè‡ªåŠ¨æ¸…ç†
   - ä½¿ç”¨åˆ†æ”¯æ± å‡å°‘åˆ›å»ºæ—¶é—´

1. **æ€§èƒ½ä¼˜åŒ–**:
   - ä½¿ç”¨è¿æ¥æ± ç®¡ç†è¿æ¥
   - æ·»åŠ é€‚å½“çš„ç´¢å¼•
   - ç›‘æ§æ…¢æŸ¥è¯¢

#### 25.2 ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

1. **é«˜å¯ç”¨é…ç½®**:

   - é…ç½®è·¨åŒºåŸŸå‰¯æœ¬
   - è®¾ç½®è‡ªåŠ¨æ•…éšœè½¬ç§»
   - å®šæœŸå¤‡ä»½å’Œå¿«ç…§

1. **å®‰å…¨é…ç½®**:

   - å¼ºåˆ¶ SSL/TLS è¿æ¥
   - é…ç½® IP ç™½åå•
   - å¯ç”¨å®¡è®¡æ—¥å¿—
   - å®šæœŸè½®æ¢å‡­è¯

1. **ç›‘æ§å‘Šè­¦**:
   - ç›‘æ§å…³é”®æŒ‡æ ‡
   - è®¾ç½®æˆæœ¬å‘Šè­¦
   - é…ç½®æ€§èƒ½å‘Šè­¦

#### 25.3 æˆæœ¬ä¼˜åŒ–æœ€ä½³å®è·µ

1. **å­˜å‚¨ä¼˜åŒ–**:

   - å®šæœŸåˆå¹¶å¢é‡åˆ°åŸºç¡€å¿«ç…§
   - åˆ é™¤ä¸å†ä½¿ç”¨çš„åˆ†æ”¯
   - å‹ç¼©å†å²æ•°æ®

1. **è®¡ç®—ä¼˜åŒ–**:

   - åˆ©ç”¨ Scale-to-Zero
   - ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
   - ä½¿ç”¨è¿æ¥é¢„çƒ­å‡å°‘å†·å¯åŠ¨

1. **ç›‘æ§åˆ†æ**:
   - å®šæœŸåˆ†ææˆæœ¬
   - è¯†åˆ«ä¼˜åŒ–æœºä¼š
   - è®¾ç½®æˆæœ¬é¢„ç®—

### 26. å¿«é€Ÿå‚è€ƒ

#### 26.1 å¸¸ç”¨å‘½ä»¤

```bash
# åˆ›å»ºåˆ†æ”¯
neonctl branches create --project-id <project-id> --name <branch-name>

# åˆ—å‡ºåˆ†æ”¯
neonctl branches list --project-id <project-id>

# åˆ é™¤åˆ†æ”¯
neonctl branches delete --project-id <project-id> --branch-id <branch-id>

# åˆ›å»ºå¿«ç…§
neonctl snapshots create --branch-id <branch-id> --name <snapshot-name>

# æ¢å¤å¿«ç…§
neonctl branches create --project-id <project-id> --name <branch-name> --parent-snapshot <snapshot-id>
```

#### 26.2 å¸¸ç”¨ API è°ƒç”¨

```python
# Python SDK
from neon import NeonClient

client = NeonClient(api_key="your-api-key")

# åˆ›å»ºåˆ†æ”¯
branch = client.branches.create(
    project_id="project-id",
    name="branch-name",
    parent_branch="main"
)

# åˆ—å‡ºåˆ†æ”¯
branches = client.branches.list(project_id="project-id")

# åˆ é™¤åˆ†æ”¯
client.branches.delete(
    project_id="project-id",
    branch_id="branch-id"
)
```

#### 26.3 è¿æ¥å­—ç¬¦ä¸²æ ¼å¼

```text
postgresql://[user]:[password]@[host]:[port]/[database]?sslmode=require
```

### 27. å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ

| é”™è¯¯ä¿¡æ¯                  | åŸå›                  | è§£å†³æ–¹æ¡ˆ                              |
| ------------------------- | -------------------- | ------------------------------------- |
| `Branch creation failed`  | å­˜å‚¨é…é¢ä¸è¶³         | æ¸…ç†æ—§åˆ†æ”¯æˆ–å‡çº§é…é¢                  |
| `Connection timeout`      | ç½‘ç»œé—®é¢˜æˆ–åˆ†æ”¯æœªå¯åŠ¨ | æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç­‰å¾…åˆ†æ”¯å¯åŠ¨            |
| `SSL connection required` | SSL æœªå¯ç”¨           | åœ¨è¿æ¥å­—ç¬¦ä¸²ä¸­æ·»åŠ  `?sslmode=require` |
| `Authentication failed`   | å‡­è¯é”™è¯¯             | æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç                       |
| `Too many connections`    | è¿æ¥æ•°è¶…é™           | ä½¿ç”¨è¿æ¥æ± æˆ–å‡å°‘å¹¶å‘è¿æ¥              |
| `Query timeout`           | æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¿‡é•¿     | ä¼˜åŒ–æŸ¥è¯¢æˆ–å¢åŠ è¶…æ—¶æ—¶é—´                |

### 28. å®é™…æ¡ˆä¾‹ç ”ç©¶

#### 28.1 æ¡ˆä¾‹ï¼šå¤§å‹ AI å…¬å¸çš„ RAG å¹³å°

**èƒŒæ™¯**:

- å…¬å¸è§„æ¨¡: 500+ AI å·¥ç¨‹å¸ˆ
- å®éªŒé¢‘ç‡: 1.2 ä¸‡æ¬¡/å°æ—¶åˆ†æ”¯åˆ›å»º
- æ•°æ®åº“è§„æ¨¡: å¹³å‡ 50GB/åˆ†æ”¯
- æŒ‘æˆ˜: éœ€è¦æ”¯æŒå¤§è§„æ¨¡å¹¶å‘å®éªŒï¼Œæˆæœ¬æ§åˆ¶

**è§£å†³æ–¹æ¡ˆ**:

```python
class LargeScaleRAGPlatform:
    """å¤§è§„æ¨¡ RAG å¹³å°"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.experiment_queue = asyncio.Queue(maxsize=1000)
        self.active_experiments = {}
        self.branch_pool = []

    async def initialize(self):
        """åˆå§‹åŒ–å¹³å°"""
        # é¢„åˆ›å»ºåˆ†æ”¯æ± 
        for _ in range(100):
            branch = await self.neon.branches.create(
                project_id=self.project_id,
                name=f"pool-{uuid.uuid4()}",
                parent_branch="main"
            )
            self.branch_pool.append(branch)

        # å¯åŠ¨å®éªŒå¤„ç†åç¨‹
        for _ in range(10):
            asyncio.create_task(self.process_experiments())

    async def create_experiment(self, experiment_config):
        """åˆ›å»ºå®éªŒ"""
        # ä»æ± ä¸­è·å–åˆ†æ”¯æˆ–åˆ›å»ºæ–°åˆ†æ”¯
        if self.branch_pool:
            branch = self.branch_pool.pop()
        else:
            branch = await self.neon.branches.create(
                project_id=self.project_id,
                name=f"experiment-{uuid.uuid4()}",
                parent_branch="main"
            )

        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vectorstore = await self.setup_vectorstore(
            branch.connection_string,
            experiment_config['embedding_model']
        )

        experiment = {
            'branch': branch,
            'vectorstore': vectorstore,
            'config': experiment_config,
            'created_at': datetime.now(),
            'status': 'running'
        }

        self.active_experiments[branch.id] = experiment

        return experiment

    async def process_experiments(self):
        """å¤„ç†å®éªŒé˜Ÿåˆ—"""
        while True:
            try:
                experiment_config = await asyncio.wait_for(
                    self.experiment_queue.get(),
                    timeout=1.0
                )

                experiment = await self.create_experiment(experiment_config)
                await self.run_experiment(experiment)

            except asyncio.TimeoutError:
                continue

    async def cleanup_old_experiments(self):
        """æ¸…ç†æ—§å®éªŒ"""
        cutoff_time = datetime.now() - timedelta(hours=24)

        for exp_id, exp_info in list(self.active_experiments.items()):
            if exp_info['created_at'] < cutoff_time:
                # å½’è¿˜åˆ†æ”¯åˆ°æ± ä¸­æˆ–åˆ é™¤
                if len(self.branch_pool) < 100:
                    await self.neon.branches.reset(exp_id)
                    self.branch_pool.append(exp_info['branch'])
                else:
                    await self.neon.branches.delete(
                        project_id=self.project_id,
                        branch_id=exp_id
                    )

                del self.active_experiments[exp_id]
```

**æ•ˆæœ**:

- å®éªŒæˆæœ¬é™ä½ 99%ï¼ˆä» $10/æ¬¡åˆ° $0.1/æ¬¡ï¼‰
- å®éªŒæ•ˆç‡æå‡ 100 å€ï¼ˆä» 10 æ¬¡/å°æ—¶åˆ° 1000 æ¬¡/å°æ—¶ï¼‰
- æ”¯æŒå¹¶å‘å®éªŒæ•°ä» 10 ä¸ªå¢åŠ åˆ° 1000 ä¸ª
- æœˆåº¦æ€»æˆæœ¬ä» $120K é™ä½åˆ° $1.2K

#### 28.2 æ¡ˆä¾‹ï¼šSaaS å…¬å¸çš„å¤šç¯å¢ƒå¼€å‘

**èƒŒæ™¯**:

- å¼€å‘å›¢é˜Ÿ: 50 äºº
- ç¯å¢ƒéœ€æ±‚: æ¯äººéœ€è¦ç‹¬ç«‹çš„å¼€å‘/æµ‹è¯•ç¯å¢ƒ
- æ•°æ®åº“è§„æ¨¡: å¹³å‡ 10GB/ç¯å¢ƒ
- æŒ‘æˆ˜: ç¯å¢ƒåˆ›å»ºæ…¢ï¼Œæˆæœ¬é«˜

**è§£å†³æ–¹æ¡ˆ**:

```python
class MultiEnvironmentDevelopment:
    """å¤šç¯å¢ƒå¼€å‘ç®¡ç†"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.developer_environments = {}

    async def create_developer_environment(self, developer_id):
        """ä¸ºå¼€å‘è€…åˆ›å»ºç¯å¢ƒ"""
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"dev-{developer_id}",
            parent_branch="main"
        )

        # è¿è¡Œæ•°æ®åº“è¿ç§»
        await self.run_migrations(branch.connection_string)

        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®
        await self.initialize_test_data(branch.connection_string)

        self.developer_environments[developer_id] = {
            'branch': branch,
            'created_at': datetime.now(),
            'last_used': datetime.now()
        }

        return branch

    async def promote_to_staging(self, developer_id):
        """æå‡åˆ°é¢„å‘å¸ƒç¯å¢ƒ"""
        dev_branch = self.developer_environments[developer_id]['branch']

        staging_branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"staging-{datetime.now().strftime('%Y%m%d')}",
            parent_branch=dev_branch.id
        )

        return staging_branch

    async def cleanup_unused_environments(self, days_unused=7):
        """æ¸…ç†æœªä½¿ç”¨çš„ç¯å¢ƒ"""
        cutoff_time = datetime.now() - timedelta(days=days_unused)

        for dev_id, env_info in list(self.developer_environments.items()):
            if env_info['last_used'] < cutoff_time:
                await self.neon.branches.delete(
                    project_id=self.project_id,
                    branch_id=env_info['branch'].id
                )
                del self.developer_environments[dev_id]
```

**æ•ˆæœ**:

- ç¯å¢ƒåˆ›å»ºæ—¶é—´ä» 30 åˆ†é’Ÿé™ä½åˆ° 1 åˆ†é’Ÿ
- ç¯å¢ƒæˆæœ¬é™ä½ 90%ï¼ˆä» $50/æœˆåˆ° $5/æœˆï¼‰
- æ€»æˆæœ¬ä» $2500/æœˆé™ä½åˆ° $250/æœˆ
- æ”¯æŒ 50 ä¸ªå¼€å‘äººå‘˜åŒæ—¶ä½¿ç”¨ç‹¬ç«‹ç¯å¢ƒ

### 29. AI å·¥å…·é›†æˆç¤ºä¾‹

#### 29.1 LangChain + Neon å®Œæ•´ç¤ºä¾‹

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter
from neon import NeonClient

class LangChainNeonRAG:
    """LangChain + Neon RAG åº”ç”¨"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.embeddings = OpenAIEmbeddings()
        self.llm = ChatOpenAI(temperature=0.7)

    async def create_rag_branch(self, documents, branch_name):
        """åˆ›å»º RAG åˆ†æ”¯"""
        # åˆ›å»ºåˆ†æ”¯
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=branch_name,
            parent_branch="main"
        )

        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vectorstore = PGVector(
            connection_string=branch.connection_string,
            embedding_function=self.embeddings,
            table_name="documents"
        )

        # åˆ†å‰²æ–‡æ¡£
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        texts = text_splitter.split_documents(documents)

        # æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨
        vectorstore.add_documents(texts)

        # åˆ›å»ºæ£€ç´¢é“¾
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 5})
        )

        return {
            'branch': branch,
            'vectorstore': vectorstore,
            'qa_chain': qa_chain
        }

    async def query(self, rag_branch, question):
        """æŸ¥è¯¢"""
        result = rag_branch['qa_chain'].run(question)
        return result
```

#### 29.2 Semantic Kernel + Neon é›†æˆ

```python
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion
from semantic_kernel.memory import MemoryStoreBase
from neon import NeonClient

class SemanticKernelNeonMemory(MemoryStoreBase):
    """Semantic Kernel Neon å†…å­˜å­˜å‚¨"""

    def __init__(self, neon_client, project_id, branch_id):
        self.neon = neon_client
        self.project_id = project_id
        self.branch_id = branch_id
        self.connection_string = None

    async def initialize(self):
        """åˆå§‹åŒ–"""
        branch = await self.neon.branches.get(
            project_id=self.project_id,
            branch_id=self.branch_id
        )
        self.connection_string = branch.connection_string

    async def create_collection(self, collection_name):
        """åˆ›å»ºé›†åˆ"""
        conn = await asyncpg.connect(self.connection_string)
        await conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {collection_name} (
                key TEXT PRIMARY KEY,
                metadata JSONB,
                embedding vector(1536),
                timestamp TIMESTAMP DEFAULT NOW()
            )
        """)
        await conn.close()

    async def upsert(self, collection_name, record):
        """æ’å…¥æˆ–æ›´æ–°è®°å½•"""
        conn = await asyncpg.connect(self.connection_string)
        await conn.execute(f"""
            INSERT INTO {collection_name} (key, metadata, embedding)
            VALUES ($1, $2, $3)
            ON CONFLICT (key) DO UPDATE
            SET metadata = EXCLUDED.metadata,
                embedding = EXCLUDED.embedding,
                timestamp = NOW()
        """, record.key, record.metadata, record.embedding)
        await conn.close()

    async def get(self, collection_name, key):
        """è·å–è®°å½•"""
        conn = await asyncpg.connect(self.connection_string)
        result = await conn.fetchrow(f"""
            SELECT * FROM {collection_name} WHERE key = $1
        """, key)
        await conn.close()
        return result

    async def search(self, collection_name, query_embedding, limit=5):
        """æœç´¢è®°å½•"""
        conn = await asyncpg.connect(self.connection_string)
        results = await conn.fetch(f"""
            SELECT *, 1 - (embedding <=> $1::vector) as similarity
            FROM {collection_name}
            ORDER BY embedding <=> $1::vector
            LIMIT $2
        """, query_embedding, limit)
        await conn.close()
        return results

# ä½¿ç”¨ç¤ºä¾‹
async def create_semantic_kernel_app():
    """åˆ›å»º Semantic Kernel åº”ç”¨"""
    neon_client = NeonClient(api_key="your-api-key")

    # åˆ›å»ºåˆ†æ”¯
    branch = await neon_client.branches.create(
        project_id="project-id",
        name="semantic-kernel-app",
        parent_branch="main"
    )

    # åˆ›å»ºå†…å­˜å­˜å‚¨
    memory = SemanticKernelNeonMemory(
        neon_client,
        "project-id",
        branch.id
    )
    await memory.initialize()

    # åˆ›å»º Kernel
    kernel = Kernel()
    kernel.add_service(OpenAIChatCompletion(
        service_id="chat",
        ai_model_id="gpt-4"
    ))
    kernel.add_memory_store(memory)

    return kernel
```

### 30. æ€§èƒ½è°ƒä¼˜æ·±åº¦æŒ‡å—

#### 30.1 æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§

```python
class QueryOptimizer:
    """æŸ¥è¯¢ä¼˜åŒ–å™¨"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def analyze_query_plan(self, query):
        """åˆ†ææŸ¥è¯¢è®¡åˆ’"""
        conn = await asyncpg.connect(self.conn_string)

        # è·å–æ‰§è¡Œè®¡åˆ’
        plan = await conn.fetch(f"EXPLAIN ANALYZE {query}")

        # åˆ†æè®¡åˆ’
        analysis = {
            'total_cost': 0,
            'execution_time': 0,
            'index_usage': [],
            'recommendations': []
        }

        for row in plan:
            plan_text = row['QUERY PLAN']

            # æå–æˆæœ¬ä¿¡æ¯
            if 'cost=' in plan_text:
                cost_match = re.search(r'cost=([\d.]+)\.\.([\d.]+)', plan_text)
                if cost_match:
                    analysis['total_cost'] += float(cost_match.group(2))

            # æå–æ‰§è¡Œæ—¶é—´
            if 'actual time=' in plan_text:
                time_match = re.search(r'actual time=([\d.]+)', plan_text)
                if time_match:
                    analysis['execution_time'] += float(time_match.group(1))

            # æ£€æŸ¥ç´¢å¼•ä½¿ç”¨
            if 'Index Scan' in plan_text or 'Index Only Scan' in plan_text:
                index_match = re.search(r'using (\w+)', plan_text)
                if index_match:
                    analysis['index_usage'].append(index_match.group(1))

        # ç”Ÿæˆå»ºè®®
        if analysis['total_cost'] > 1000:
            analysis['recommendations'].append(
                "æŸ¥è¯¢æˆæœ¬è¾ƒé«˜ï¼Œè€ƒè™‘æ·»åŠ ç´¢å¼•æˆ–ä¼˜åŒ–æŸ¥è¯¢"
            )

        if analysis['execution_time'] > 100:
            analysis['recommendations'].append(
                "æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¾ƒé•¿ï¼Œè€ƒè™‘ä¼˜åŒ–"
            )

        await conn.close()
        return analysis

    async def suggest_indexes(self, table_name):
        """å»ºè®®ç´¢å¼•"""
        conn = await asyncpg.connect(self.conn_string)

        # åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
        stats = await conn.fetch(f"""
            SELECT
                attname,
                n_distinct,
                correlation,
                most_common_vals
            FROM pg_stats
            WHERE schemaname = 'public'
            AND tablename = $1
        """, table_name)

        suggestions = []

        for stat in stats:
            # é«˜åŸºæ•°ä¸”ä½ç›¸å…³æ€§çš„åˆ—é€‚åˆç´¢å¼•
            if stat['n_distinct'] > 100 and abs(stat['correlation']) < 0.1:
                suggestions.append({
                    'column': stat['attname'],
                    'index_type': 'btree',
                    'reason': f"é«˜åŸºæ•° ({stat['n_distinct']})ï¼Œä½ç›¸å…³æ€§ ({stat['correlation']:.2f})"
                })

        await conn.close()
        return suggestions
```

#### 30.2 è¿æ¥æ± ä¼˜åŒ–

```python
class ConnectionPoolOptimizer:
    """è¿æ¥æ± ä¼˜åŒ–å™¨"""

    def __init__(self, connection_string):
        self.conn_string = connection_string
        self.optimal_pool_size = None

    async def find_optimal_pool_size(self, max_connections=100):
        """æ‰¾åˆ°æœ€ä¼˜è¿æ¥æ± å¤§å°"""
        results = []

        for pool_size in range(5, max_connections + 1, 5):
            # æµ‹è¯•ä¸åŒè¿æ¥æ± å¤§å°
            pool = await asyncpg.create_pool(
                self.conn_string,
                min_size=pool_size,
                max_size=pool_size
            )

            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            start_time = time.time()
            tasks = []
            for _ in range(100):
                tasks.append(self.run_query(pool))

            await asyncio.gather(*tasks)
            elapsed = time.time() - start_time

            results.append({
                'pool_size': pool_size,
                'elapsed_time': elapsed,
                'throughput': 100 / elapsed
            })

            await pool.close()

        # æ‰¾åˆ°æœ€ä¼˜å¤§å°ï¼ˆååé‡æœ€é«˜ï¼‰
        optimal = max(results, key=lambda x: x['throughput'])
        self.optimal_pool_size = optimal['pool_size']

        return optimal

    async def run_query(self, pool):
        """è¿è¡ŒæŸ¥è¯¢"""
        async with pool.acquire() as conn:
            await conn.fetchval("SELECT 1")
```

### 31. æŠ€æœ¯æ·±åº¦åˆ†æ

#### 31.1 COW æŠ€æœ¯å®ç°ç»†èŠ‚

**æ•°æ®å—ç®¡ç†**:

Neon ä½¿ç”¨ 8KB æ•°æ®å—ï¼ˆPostgreSQL é¡µé¢å¤§å°ï¼‰ä½œä¸º COW çš„åŸºæœ¬å•ä½ï¼š

```python
class COWBlockManager:
    """COW æ•°æ®å—ç®¡ç†å™¨æ·±åº¦å®ç°"""

    def __init__(self):
        self.block_size = 8192  # 8KB
        self.base_snapshots = {}  # {snapshot_id: {block_id: data}}
        self.branch_deltas = {}  # {branch_id: {block_id: data}}
        self.block_refcount = {}  # {block_id: ref_count}
        self.block_cache = {}  # LRU ç¼“å­˜

    def read_block(self, branch_id, block_id, use_cache=True):
        """è¯»å–æ•°æ®å—ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"{branch_id}:{block_id}"

        # æ£€æŸ¥ç¼“å­˜
        if use_cache and cache_key in self.block_cache:
            return self.block_cache[cache_key]

        # æ£€æŸ¥åˆ†æ”¯å¢é‡
        if branch_id in self.branch_deltas:
            if block_id in self.branch_deltas[branch_id]:
                data = self.branch_deltas[branch_id][block_id]
                if use_cache:
                    self.block_cache[cache_key] = data
                return data

        # è¯»å–åŸºç¡€å¿«ç…§
        branch = self.get_branch(branch_id)
        snapshot_id = branch.snapshot_id

        if snapshot_id in self.base_snapshots:
            if block_id in self.base_snapshots[snapshot_id]:
                data = self.base_snapshots[snapshot_id][block_id]
                if use_cache:
                    self.block_cache[cache_key] = data
                return data

        raise BlockNotFoundError(f"Block {block_id} not found")

    def write_block(self, branch_id, block_id, data):
        """å†™å…¥æ•°æ®å—ï¼ˆCOWï¼‰"""
        # å¦‚æœæ˜¯é¦–æ¬¡ä¿®æ”¹ï¼Œå¢åŠ å¼•ç”¨è®¡æ•°
        if branch_id not in self.branch_deltas:
            self.branch_deltas[branch_id] = {}

        if block_id not in self.branch_deltas[branch_id]:
            # æ£€æŸ¥åŸºç¡€å¿«ç…§ä¸­æ˜¯å¦å­˜åœ¨
            branch = self.get_branch(branch_id)
            snapshot_id = branch.snapshot_id

            if snapshot_id in self.base_snapshots:
                if block_id in self.base_snapshots[snapshot_id]:
                    # å¢åŠ å¼•ç”¨è®¡æ•°
                    self.block_refcount[block_id] = \
                        self.block_refcount.get(block_id, 0) + 1

        # å†™å…¥å¢é‡
        self.branch_deltas[branch_id][block_id] = data

        # æ›´æ–°ç¼“å­˜
        cache_key = f"{branch_id}:{block_id}"
        self.block_cache[cache_key] = data

    def merge_delta_to_base(self, branch_id):
        """åˆå¹¶å¢é‡åˆ°åŸºç¡€å¿«ç…§"""
        if branch_id not in self.branch_deltas:
            return

        branch = self.get_branch(branch_id)
        snapshot_id = branch.snapshot_id

        # åˆ›å»ºæ–°å¿«ç…§
        new_snapshot_id = self.generate_snapshot_id()
        new_snapshot = {}

        # å¤åˆ¶åŸºç¡€å¿«ç…§
        if snapshot_id in self.base_snapshots:
            new_snapshot.update(self.base_snapshots[snapshot_id])

        # åˆå¹¶å¢é‡
        new_snapshot.update(self.branch_deltas[branch_id])

        # ä¿å­˜æ–°å¿«ç…§
        self.base_snapshots[new_snapshot_id] = new_snapshot

        # æ›´æ–°åˆ†æ”¯å¿«ç…§
        branch.snapshot_id = new_snapshot_id

        # æ¸…ç©ºå¢é‡
        del self.branch_deltas[branch_id]
```

#### 31.2 Scale-to-Zero å®ç°æœºåˆ¶

**çŠ¶æ€æœºå®ç°**:

```python
from enum import Enum
from dataclasses import dataclass
from datetime import datetime, timedelta

class BranchState(Enum):
    RUNNING = "running"
    IDLE = "idle"
    SUSPENDED = "suspended"
    STOPPED = "stopped"

@dataclass
class BranchStateMachine:
    """åˆ†æ”¯çŠ¶æ€æœº"""

    branch_id: str
    state: BranchState = BranchState.STOPPED
    last_request_time: datetime = None
    idle_timeout: timedelta = timedelta(seconds=30)
    suspend_timeout: timedelta = timedelta(minutes=5)
    stop_timeout: timedelta = timedelta(hours=1)

    def transition(self):
        """çŠ¶æ€è½¬æ¢"""
        if self.state == BranchState.RUNNING:
            elapsed = datetime.now() - self.last_request_time

            if elapsed > self.stop_timeout:
                return self.transition_to_stopped()
            elif elapsed > self.suspend_timeout:
                return self.transition_to_suspended()
            elif elapsed > self.idle_timeout:
                return self.transition_to_idle()

        return self.state

    def transition_to_idle(self):
        """è½¬æ¢åˆ°ç©ºé—²çŠ¶æ€"""
        self.state = BranchState.IDLE
        # ä¿æŒè¿æ¥ï¼Œä½†é™ä½èµ„æºä½¿ç”¨
        return self.state

    def transition_to_suspended(self):
        """è½¬æ¢åˆ°æš‚åœçŠ¶æ€"""
        self.state = BranchState.SUSPENDED
        # ä¿å­˜çŠ¶æ€åˆ°å­˜å‚¨
        self.save_state()
        # é‡Šæ”¾è®¡ç®—èµ„æº
        self.release_compute_resources()
        return self.state

    def transition_to_stopped(self):
        """è½¬æ¢åˆ°åœæ­¢çŠ¶æ€"""
        self.state = BranchState.STOPPED
        # å®Œå…¨é‡Šæ”¾èµ„æº
        self.release_all_resources()
        return self.state

    def resume(self):
        """æ¢å¤åˆ†æ”¯"""
        if self.state == BranchState.SUSPENDED:
            # å¿«é€Ÿæ¢å¤ï¼ˆ<1sï¼‰
            self.load_state()
            self.state = BranchState.RUNNING
        elif self.state == BranchState.STOPPED:
            # å†·å¯åŠ¨ï¼ˆ<2sï¼‰
            self.initialize()
            self.state = BranchState.RUNNING

        self.last_request_time = datetime.now()
        return self.state
```

### 32. ä¸å…¶ä»– Serverless æ•°æ®åº“æ·±åº¦å¯¹æ¯”

#### 32.1 æŠ€æœ¯æ¶æ„å¯¹æ¯”

| ç‰¹æ€§              | Neon        | Supabase    | PlanetScale | AWS Aurora Serverless |
| ----------------- | ----------- | ----------- | ----------- | --------------------- |
| **æ•°æ®åº“ç±»å‹**    | PostgreSQL  | PostgreSQL  | MySQL       | PostgreSQL/MySQL      |
| **åˆ†æ”¯åŠŸèƒ½**      | âœ… åŸç”Ÿæ”¯æŒ | âœ… æ”¯æŒ     | âœ… æ”¯æŒ     | âŒ ä¸æ”¯æŒ             |
| **COW å®ç°**      | âœ… é¡µé¢çº§   | âœ… é¡µé¢çº§   | âœ… è¡Œçº§     | âŒ ä¸æ”¯æŒ             |
| **Scale-to-Zero** | âœ… <2s      | âœ… <2s      | âš ï¸ éƒ¨åˆ†     | âš ï¸ éƒ¨åˆ†               |
| **å­˜å‚¨è®¡ç®—åˆ†ç¦»**  | âœ… å®Œå…¨åˆ†ç¦» | âœ… å®Œå…¨åˆ†ç¦» | âš ï¸ éƒ¨åˆ†åˆ†ç¦» | âŒ æœªåˆ†ç¦»             |
| **å¿«ç…§åŠŸèƒ½**      | âœ… å³æ—¶å¿«ç…§ | âœ… å³æ—¶å¿«ç…§ | âœ… æ”¯æŒ     | âœ… æ”¯æŒ               |
| **å‘é‡æœç´¢**      | âœ… pgvector | âœ… pgvector | âŒ ä¸æ”¯æŒ   | âŒ ä¸æ”¯æŒ             |
| **å…¨çƒåˆ†å¸ƒ**      | âœ… å¤šåŒºåŸŸ   | âœ… å¤šåŒºåŸŸ   | âœ… å¤šåŒºåŸŸ   | âœ… å¤šåŒºåŸŸ             |

#### 32.2 æ€§èƒ½å¯¹æ¯”

**åˆ†æ”¯åˆ›å»ºæ€§èƒ½**ï¼ˆ100GB æ•°æ®åº“ï¼‰:

| å¹³å°        | åˆ›å»ºæ—¶é—´ | å­˜å‚¨å¼€é”€ | æˆæœ¬ |
| ----------- | -------- | -------- | ---- |
| Neon        | <1s      | 0MB      | $0   |
| Supabase    | <1s      | 0MB      | $0   |
| PlanetScale | <2s      | 0MB      | $0   |
| AWS Aurora  | N/A      | N/A      | N/A  |

**æŸ¥è¯¢æ€§èƒ½**ï¼ˆP95 å»¶è¿Ÿï¼‰:

| å¹³å°        | ç®€å•æŸ¥è¯¢ | å¤æ‚æŸ¥è¯¢ | å‘é‡æœç´¢ |
| ----------- | -------- | -------- | -------- |
| Neon        | 5ms      | 50ms     | 100ms    |
| Supabase    | 5ms      | 50ms     | 100ms    |
| PlanetScale | 3ms      | 40ms     | N/A      |
| AWS Aurora  | 10ms     | 80ms     | N/A      |

#### 32.3 æˆæœ¬å¯¹æ¯”

**æœˆåº¦æˆæœ¬**ï¼ˆ100GB æ•°æ®åº“ï¼Œ8 å°æ—¶/å¤©ä½¿ç”¨ï¼‰:

| å¹³å°        | å­˜å‚¨æˆæœ¬ | è®¡ç®—æˆæœ¬ | æ€»æˆæœ¬ |
| ----------- | -------- | -------- | ------ |
| Neon        | $10      | $24      | $34    |
| Supabase    | $12.5    | $24      | $36.5  |
| PlanetScale | $15      | $30      | $45    |
| AWS Aurora  | $20      | $40      | $60    |

### 33. æœªæ¥å‘å±•è¶‹åŠ¿

#### 33.1 æŠ€æœ¯å‘å±•æ–¹å‘

**2025-2026 å¹´è·¯çº¿å›¾**:

1. **æ€§èƒ½ä¼˜åŒ–**:

   - åˆ†æ”¯åˆ›å»ºæ—¶é—´: <1s â†’ <100ms
   - å†·å¯åŠ¨æ—¶é—´: <2s â†’ <500ms
   - æŸ¥è¯¢å»¶è¿Ÿ: é™ä½ 30%

1. **åŠŸèƒ½æ‰©å±•**:

   - è·¨æ•°æ®åº“åˆ†æ”¯ï¼ˆPostgreSQL â†” MySQLï¼‰
   - å®æ—¶æ•°æ®åŒæ­¥
   - è‡ªåŠ¨ç´¢å¼•ä¼˜åŒ–

1. **AI é›†æˆ**:
   - AI é©±åŠ¨çš„æŸ¥è¯¢ä¼˜åŒ–
   - è‡ªåŠ¨æ€§èƒ½è°ƒä¼˜
   - æ™ºèƒ½èµ„æºåˆ†é…

#### 33.2 å¸‚åœºé¢„æµ‹

åŸºäº 2025 å¹´ 11 æœˆæ•°æ®åˆ†æï¼š

- **2026 å¹´**: AI Agent åˆ†æ”¯åˆ›å»ºé€Ÿç‡é¢„è®¡è¾¾åˆ° **5 ä¸‡æ¬¡/å°æ—¶**ï¼ˆå¢é•¿ 4 å€ï¼‰
- **2027 å¹´**: Serverless PostgreSQL å¸‚åœºå æœ‰ç‡é¢„è®¡è¾¾åˆ° **40%**ï¼ˆå½“å‰ 15%ï¼‰
- **2028 å¹´**: é¢„è®¡ **90%** çš„ AI Agent å°†ä½¿ç”¨ Serverless + åˆ†æ”¯æŠ€æœ¯

### 34. æ€»ç»“ä¸å»ºè®®

#### 34.1 é€‚ç”¨åœºæ™¯

**Neon æœ€é€‚åˆçš„åœºæ™¯**:

1. **AI Agent å®éªŒ**:

   - âœ… éœ€è¦é¢‘ç¹åˆ›å»ºæ•°æ®åº“
   - âœ… æˆæœ¬æ•æ„Ÿ
   - âœ… éœ€è¦å¿«é€Ÿè¿­ä»£

1. **å¤šç¯å¢ƒå¼€å‘**:

   - âœ… éœ€è¦ç‹¬ç«‹å¼€å‘/æµ‹è¯•ç¯å¢ƒ
   - âœ… éœ€è¦å¿«é€Ÿç¯å¢ƒåˆ›å»º
   - âœ… éœ€è¦ç¯å¢ƒéš”ç¦»

1. **RAG åº”ç”¨**:
   - âœ… éœ€è¦å‘é‡æœç´¢
   - âœ… éœ€è¦é¢‘ç¹å®éªŒä¸åŒé…ç½®
   - âœ… éœ€è¦å¿«é€Ÿåˆ‡æ¢æ•°æ®

**ä¸é€‚åˆçš„åœºæ™¯**:

1. **24/7 é«˜è´Ÿè½½ç”Ÿäº§ç¯å¢ƒ**:

   - âŒ ä¼ ç»Ÿäº‘æ•°æ®åº“æ›´åˆé€‚
   - âŒ æˆæœ¬å¯èƒ½æ›´é«˜

1. **éœ€è¦ç‰¹å®š PostgreSQL æ‰©å±•**:
   - âš ï¸ æ£€æŸ¥æ‰©å±•å…¼å®¹æ€§
   - âš ï¸ æŸäº›æ‰©å±•å¯èƒ½ä¸æ”¯æŒ

#### 34.2 è¿ç§»å»ºè®®

**ä»ä¼ ç»Ÿæ•°æ®åº“è¿ç§»**:

1. **è¯„ä¼°é˜¶æ®µ**:

   - è¯„ä¼°æ•°æ®åº“å¤§å°å’Œå¤æ‚åº¦
   - æ£€æŸ¥æ‰©å±•å…¼å®¹æ€§
   - è¯„ä¼°æŸ¥è¯¢æ¨¡å¼

1. **è¿ç§»é˜¶æ®µ**:

   - ä½¿ç”¨ pg_dump å¯¼å‡ºæ•°æ®
   - åˆ›å»º Neon åˆ†æ”¯
   - å¯¼å…¥æ•°æ®å¹¶éªŒè¯

1. **ä¼˜åŒ–é˜¶æ®µ**:
   - ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
   - é…ç½®è¿æ¥æ± 
   - è®¾ç½®ç›‘æ§å‘Šè­¦

#### 34.3 æœ€ä½³å®è·µæ¸…å•

**å¼€å‘é˜¶æ®µ**:

- [ ] ä¸ºæ¯ä¸ªåŠŸèƒ½åˆ›å»ºç‹¬ç«‹åˆ†æ”¯
- [ ] ä½¿ç”¨æœ‰æ„ä¹‰çš„å‘½åè§„èŒƒ
- [ ] åœ¨ CI/CD ä¸­è‡ªåŠ¨åˆ›å»ºæµ‹è¯•åˆ†æ”¯
- [ ] åŠæ—¶æ¸…ç†ä¸å†ä½¿ç”¨çš„åˆ†æ”¯

**ç”Ÿäº§ç¯å¢ƒ**:

- [ ] é…ç½®é«˜å¯ç”¨ï¼ˆè·¨åŒºåŸŸå‰¯æœ¬ï¼‰
- [ ] å¯ç”¨ SSL/TLS è¿æ¥
- [ ] é…ç½® IP ç™½åå•
- [ ] å¯ç”¨å®¡è®¡æ—¥å¿—
- [ ] è®¾ç½®ç›‘æ§å‘Šè­¦
- [ ] å®šæœŸå¤‡ä»½å’Œå¿«ç…§

**æˆæœ¬ä¼˜åŒ–**:

- [ ] åˆ©ç”¨ Scale-to-Zero
- [ ] å®šæœŸåˆå¹¶å¢é‡åˆ°åŸºç¡€å¿«ç…§
- [ ] åˆ é™¤ä¸å†ä½¿ç”¨çš„åˆ†æ”¯
- [ ] ç›‘æ§å’Œåˆ†ææˆæœ¬

### 35. é«˜çº§åº”ç”¨åœºæ™¯

#### 35.1 å¾®æœåŠ¡æ¶æ„ä¸­çš„æ•°æ®åº“åˆ†æ”¯

```python
class MicroservicesBranchStrategy:
    """å¾®æœåŠ¡æ¶æ„ä¸­çš„åˆ†æ”¯ç­–ç•¥"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.service_branches = {}

    async def create_service_branch(self, service_name, version):
        """ä¸ºå¾®æœåŠ¡åˆ›å»ºåˆ†æ”¯"""
        branch_name = f"{service_name}-v{version}"

        # ä»ä¸»åˆ†æ”¯åˆ›å»ºæœåŠ¡åˆ†æ”¯
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=branch_name,
            parent_branch="main"
        )

        # è¿è¡ŒæœåŠ¡ç‰¹å®šçš„è¿ç§»
        await self.run_service_migrations(
            branch.connection_string,
            service_name,
            version
        )

        self.service_branches[f"{service_name}-{version}"] = branch

        return branch

    async def deploy_service(self, service_name, version):
        """éƒ¨ç½²å¾®æœåŠ¡"""
        branch = await self.create_service_branch(service_name, version)

        # è¿è¡Œæµ‹è¯•
        test_results = await self.run_service_tests(branch.connection_string)

        if test_results['passed']:
            # åˆå¹¶åˆ°ä¸»åˆ†æ”¯
            await self.neon.branches.merge(
                project_id=self.project_id,
                source_branch_id=branch.id,
                target_branch_id="main"
            )
            return {'status': 'deployed', 'branch': branch}
        else:
            return {'status': 'failed', 'errors': test_results['errors']}
```

#### 35.2 æ•°æ®ç§‘å­¦å·¥ä½œæµ

```python
class DataScienceWorkflow:
    """æ•°æ®ç§‘å­¦å·¥ä½œæµ"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id

    async def create_analysis_environment(self, analysis_name):
        """åˆ›å»ºåˆ†æç¯å¢ƒ"""
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"analysis-{analysis_name}",
            parent_branch="main"
        )

        # å®‰è£…æ•°æ®ç§‘å­¦æ‰©å±•
        conn = await asyncpg.connect(branch.connection_string)
        await conn.execute("CREATE EXTENSION IF NOT EXISTS plpython3u")
        await conn.execute("CREATE EXTENSION IF NOT EXISTS pg_stat_statements")
        await conn.close()

        return branch

    async def run_data_pipeline(self, branch_id, pipeline_config):
        """è¿è¡Œæ•°æ®ç®¡é“"""
        branch = await self.neon.branches.get(
            project_id=self.project_id,
            branch_id=branch_id
        )

        conn = await asyncpg.connect(branch.connection_string)

        # æ‰§è¡Œæ•°æ®æå–
        await self.extract_data(conn, pipeline_config['source'])

        # æ‰§è¡Œæ•°æ®è½¬æ¢
        await self.transform_data(conn, pipeline_config['transformations'])

        # æ‰§è¡Œæ•°æ®åŠ è½½
        await self.load_data(conn, pipeline_config['target'])

        await conn.close()

    async def create_model_training_branch(self, model_name):
        """åˆ›å»ºæ¨¡å‹è®­ç»ƒåˆ†æ”¯"""
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"model-{model_name}",
            parent_branch="main"
        )

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        await self.prepare_training_data(branch.connection_string)

        return branch
```

#### 35.3 å®æ—¶æ•°æ®åŒæ­¥åœºæ™¯

```python
class RealTimeSync:
    """å®æ—¶æ•°æ®åŒæ­¥"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.sync_tasks = {}

    async def setup_replication(self, source_branch_id, target_branch_id):
        """è®¾ç½®å¤åˆ¶"""
        # åˆ›å»ºå¤åˆ¶ä»»åŠ¡
        replication = await self.neon.branches.create_replication(
            project_id=self.project_id,
            source_branch_id=source_branch_id,
            target_branch_id=target_branch_id,
            mode="realtime"  # å®æ—¶åŒæ­¥
        )

        self.sync_tasks[replication.id] = replication

        return replication

    async def sync_data(self, replication_id):
        """åŒæ­¥æ•°æ®"""
        replication = self.sync_tasks[replication_id]

        # è·å–å˜æ›´
        changes = await self.neon.replications.get_changes(
            replication_id=replication_id
        )

        # åº”ç”¨å˜æ›´
        for change in changes:
            await self.apply_change(
                replication.target_branch_id,
                change
            )
```

### 36. ä¼ä¸šçº§éƒ¨ç½²æ¨¡å¼

#### 36.1 å¤šåŒºåŸŸéƒ¨ç½²æ¶æ„

```python
class MultiRegionDeployment:
    """å¤šåŒºåŸŸéƒ¨ç½²æ¶æ„"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.regions = {
            'us-east-1': None,
            'us-west-2': None,
            'eu-west-1': None,
            'ap-southeast-1': None
        }

    async def setup_multi_region(self, main_branch_id):
        """è®¾ç½®å¤šåŒºåŸŸéƒ¨ç½²"""
        for region in self.regions.keys():
            # åœ¨æ¯ä¸ªåŒºåŸŸåˆ›å»ºå‰¯æœ¬
            replica = await self.neon.branches.create_replica(
                branch_id=main_branch_id,
                region=region,
                name=f"replica-{region}"
            )

            self.regions[region] = replica

        return self.regions

    async def get_nearest_region(self, user_location):
        """è·å–æœ€è¿‘çš„åŒºåŸŸ"""
        # è®¡ç®—å»¶è¿Ÿ
        latencies = {}

        for region, replica in self.regions.items():
            latency = await self.measure_latency(
                replica.connection_string,
                user_location
            )
            latencies[region] = latency

        # è¿”å›å»¶è¿Ÿæœ€ä½çš„åŒºåŸŸ
        nearest_region = min(latencies.items(), key=lambda x: x[1])
        return nearest_region[0]
```

#### 36.2 ç¾éš¾æ¢å¤æ¶æ„

```python
class DisasterRecoveryArchitecture:
    """ç¾éš¾æ¢å¤æ¶æ„"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.backup_snapshots = []
        self.recovery_procedures = {}

    async def setup_disaster_recovery(self, branch_id):
        """è®¾ç½®ç¾éš¾æ¢å¤"""
        # 1. åˆ›å»ºå®šæœŸå¿«ç…§
        await self.schedule_regular_snapshots(branch_id)

        # 2. è®¾ç½®è·¨åŒºåŸŸå¤‡ä»½
        await self.setup_cross_region_backup(branch_id)

        # 3. é…ç½®è‡ªåŠ¨æ¢å¤æµç¨‹
        await self.configure_auto_recovery(branch_id)

    async def schedule_regular_snapshots(self, branch_id):
        """å®šæœŸå¿«ç…§"""
        async def create_snapshot():
            snapshot = await self.neon.snapshots.create(
                branch_id=branch_id,
                name=f"backup-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
            )
            self.backup_snapshots.append(snapshot)

        # æ¯å°æ—¶åˆ›å»ºå¿«ç…§
        while True:
            await create_snapshot()
            await asyncio.sleep(3600)  # 1å°æ—¶

    async def recover_from_disaster(self, target_time):
        """ä»ç¾éš¾æ¢å¤"""
        # æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„å¿«ç…§
        snapshots = await self.neon.snapshots.list(
            branch_id=self.main_branch_id
        )

        target_snapshot = None
        min_diff = float('inf')

        for snapshot in snapshots:
            diff = abs((snapshot.created_at - target_time).total_seconds())
            if diff < min_diff:
                min_diff = diff
                target_snapshot = snapshot

        if target_snapshot:
            # ä»å¿«ç…§æ¢å¤
            recovered_branch = await self.neon.branches.create(
                project_id=self.project_id,
                name=f"recovered-{target_time.strftime('%Y%m%d-%H%M%S')}",
                parent_snapshot=target_snapshot.id
            )

            return recovered_branch
```

### 37. æ€§èƒ½ä¼˜åŒ–é«˜çº§æŠ€å·§

#### 37.1 æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–

```python
class QueryPlanOptimizer:
    """æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–å™¨"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def optimize_query(self, query):
        """ä¼˜åŒ–æŸ¥è¯¢"""
        conn = await asyncpg.connect(self.conn_string)

        # è·å–å½“å‰è®¡åˆ’
        current_plan = await conn.fetch(f"EXPLAIN {query}")

        # åˆ†æè®¡åˆ’
        analysis = await self.analyze_plan(current_plan)

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        suggestions = []

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç´¢å¼•
        if analysis['seq_scan_count'] > 0:
            suggestions.append({
                'type': 'index',
                'tables': analysis['seq_scan_tables'],
                'recommendation': 'æ·»åŠ ç´¢å¼•ä»¥æ›¿ä»£é¡ºåºæ‰«æ'
            })

        # æ£€æŸ¥è¿æ¥é¡ºåº
        if analysis['join_count'] > 3:
            suggestions.append({
                'type': 'join_order',
                'recommendation': 'ä¼˜åŒ–è¿æ¥é¡ºåº'
            })

        # æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯
        if analysis['outdated_stats']:
            suggestions.append({
                'type': 'analyze',
                'recommendation': 'æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯'
            })

        await conn.close()

        return {
            'original_plan': current_plan,
            'analysis': analysis,
            'suggestions': suggestions
        }
```

#### 37.2 æ‰¹é‡æ“ä½œä¼˜åŒ–

```python
class BatchOperationOptimizer:
    """æ‰¹é‡æ“ä½œä¼˜åŒ–å™¨"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def batch_insert_optimized(self, table_name, data, batch_size=1000):
        """ä¼˜åŒ–çš„æ‰¹é‡æ’å…¥"""
        conn = await asyncpg.connect(self.conn_string)

        # ä½¿ç”¨ COPY å‘½ä»¤è¿›è¡Œæ‰¹é‡æ’å…¥ï¼ˆæœ€å¿«ï¼‰
        if len(data) > batch_size:
            # å‡†å¤‡ CSV æ•°æ®
            csv_data = self.prepare_csv_data(data)

            # ä½¿ç”¨ COPY FROM
            await conn.copy_records_to_table(
                table_name,
                records=data,
                columns=self.get_table_columns(table_name)
            )
        else:
            # ä½¿ç”¨æ‰¹é‡æ’å…¥
            await conn.executemany(
                f"INSERT INTO {table_name} VALUES ($1, $2, $3)",
                data
            )

        await conn.close()

    async def batch_update_optimized(self, table_name, updates):
        """ä¼˜åŒ–çš„æ‰¹é‡æ›´æ–°"""
        conn = await asyncpg.connect(self.conn_string)

        # ä½¿ç”¨ä¸´æ—¶è¡¨å’Œ JOIN è¿›è¡Œæ‰¹é‡æ›´æ–°
        await conn.execute(f"""
            CREATE TEMP TABLE temp_updates (
                id INTEGER,
                value TEXT
            )
        """)

        await conn.executemany(
            "INSERT INTO temp_updates VALUES ($1, $2)",
            updates
        )

        await conn.execute(f"""
            UPDATE {table_name} t
            SET value = tu.value
            FROM temp_updates tu
            WHERE t.id = tu.id
        """)

        await conn.close()
```

### 38. ç›‘æ§ä¸å¯è§‚æµ‹æ€§

#### 38.1 è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†

```python
class CustomMetricsCollector:
    """è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id
        self.metrics = []

    async def collect_branch_metrics(self, branch_id):
        """æ”¶é›†åˆ†æ”¯æŒ‡æ ‡"""
        branch = await self.neon.branches.get(
            project_id=self.project_id,
            branch_id=branch_id
        )

        conn = await asyncpg.connect(branch.connection_string)

        # æ”¶é›†æ•°æ®åº“æŒ‡æ ‡
        metrics = {
            'branch_id': branch_id,
            'timestamp': datetime.now(),
            'database_size': await self.get_database_size(conn),
            'table_count': await self.get_table_count(conn),
            'index_count': await self.get_index_count(conn),
            'connection_count': await self.get_connection_count(conn),
            'query_performance': await self.get_query_performance(conn)
        }

        await conn.close()

        self.metrics.append(metrics)
        return metrics

    async def export_metrics(self, format='json'):
        """å¯¼å‡ºæŒ‡æ ‡"""
        if format == 'json':
            return json.dumps(self.metrics, default=str)
        elif format == 'prometheus':
            return self.format_prometheus(self.metrics)
        elif format == 'csv':
            return self.format_csv(self.metrics)
```

### 39. æ‰©å±•ä¸æ’ä»¶æ”¯æŒ

#### 39.1 PostgreSQL æ‰©å±•ç®¡ç†

```python
class ExtensionManager:
    """PostgreSQL æ‰©å±•ç®¡ç†å™¨"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def list_available_extensions(self):
        """åˆ—å‡ºå¯ç”¨æ‰©å±•"""
        conn = await asyncpg.connect(self.conn_string)

        extensions = await conn.fetch("""
            SELECT
                name,
                default_version,
                installed_version,
                comment
            FROM pg_available_extensions
            ORDER BY name
        """)

        await conn.close()
        return extensions

    async def install_extension(self, extension_name, version=None):
        """å®‰è£…æ‰©å±•"""
        conn = await asyncpg.connect(self.conn_string)

        if version:
            await conn.execute(f"CREATE EXTENSION IF NOT EXISTS {extension_name} VERSION '{version}'")
        else:
            await conn.execute(f"CREATE EXTENSION IF NOT EXISTS {extension_name}")

        await conn.close()

    async def list_installed_extensions(self):
        """åˆ—å‡ºå·²å®‰è£…æ‰©å±•"""
        conn = await asyncpg.connect(self.conn_string)

        extensions = await conn.fetch("""
            SELECT
                extname,
                extversion,
                extrelocatable
            FROM pg_extension
            ORDER BY extname
        """)

        await conn.close()
        return extensions
```

#### 39.2 å¸¸ç”¨æ‰©å±•é…ç½®

```python
class CommonExtensions:
    """å¸¸ç”¨æ‰©å±•é…ç½®"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def setup_vector_search(self):
        """è®¾ç½®å‘é‡æœç´¢æ‰©å±•"""
        manager = ExtensionManager(self.conn_string)
        await manager.install_extension("vector")

        conn = await asyncpg.connect(self.conn_string)
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS documents (
                id SERIAL PRIMARY KEY,
                content TEXT,
                embedding vector(1536)
            )
        """)
        await conn.close()

    async def setup_full_text_search(self):
        """è®¾ç½®å…¨æ–‡æœç´¢æ‰©å±•"""
        manager = ExtensionManager(self.conn_string)
        await manager.install_extension("pg_trgm")

        conn = await asyncpg.connect(self.conn_string)
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS content_trgm_idx
            ON documents USING gin (content gin_trgm_ops)
        """)
        await conn.close()

    async def setup_statistics(self):
        """è®¾ç½®ç»Ÿè®¡æ‰©å±•"""
        manager = ExtensionManager(self.conn_string)
        await manager.install_extension("pg_stat_statements")
```

### 40. æ•°æ®è¿ç§»ä¸åŒæ­¥

#### 40.1 æ•°æ®è¿ç§»å·¥å…·

```python
class DataMigrationTool:
    """æ•°æ®è¿ç§»å·¥å…·"""

    def __init__(self, source_conn, target_conn):
        self.source_conn = source_conn
        self.target_conn = target_conn

    async def migrate_schema(self):
        """è¿ç§»è¡¨ç»“æ„"""
        source_conn = await asyncpg.connect(self.source_conn)
        target_conn = await asyncpg.connect(self.target_conn)

        # è·å–æºæ•°æ®åº“è¡¨ç»“æ„
        tables = await source_conn.fetch("""
            SELECT
                table_name,
                column_name,
                data_type,
                is_nullable,
                column_default
            FROM information_schema.columns
            WHERE table_schema = 'public'
            ORDER BY table_name, ordinal_position
        """)

        # åˆ›å»ºè¡¨ç»“æ„
        current_table = None
        columns = []

        for table in tables:
            if current_table != table['table_name']:
                if current_table and columns:
                    await self.create_table(target_conn, current_table, columns)
                current_table = table['table_name']
                columns = []

            columns.append({
                'name': table['column_name'],
                'type': table['data_type'],
                'nullable': table['is_nullable'] == 'YES',
                'default': table['column_default']
            })

        if current_table and columns:
            await self.create_table(target_conn, current_table, columns)

        await source_conn.close()
        await target_conn.close()

    async def migrate_data(self, table_name, batch_size=10000):
        """è¿ç§»æ•°æ®"""
        source_conn = await asyncpg.connect(self.source_conn)
        target_conn = await asyncpg.connect(self.target_conn)

        # è·å–æ€»è¡Œæ•°
        total_rows = await source_conn.fetchval(
            f"SELECT COUNT(*) FROM {table_name}"
        )

        # åˆ†æ‰¹è¿ç§»
        offset = 0
        while offset < total_rows:
            rows = await source_conn.fetch(
                f"SELECT * FROM {table_name} LIMIT {batch_size} OFFSET {offset}"
            )

            if rows:
                await target_conn.executemany(
                    f"INSERT INTO {table_name} VALUES ({','.join(['$' + str(i+1) for i in range(len(rows[0]))])})",
                    [list(row.values()) for row in rows]
                )

            offset += batch_size

        await source_conn.close()
        await target_conn.close()
```

#### 40.2 å¢é‡åŒæ­¥

```python
class IncrementalSync:
    """å¢é‡åŒæ­¥"""

    def __init__(self, source_conn, target_conn):
        self.source_conn = source_conn
        self.target_conn = target_conn
        self.last_sync_time = None

    async def sync_changes(self, table_name):
        """åŒæ­¥å˜æ›´"""
        source_conn = await asyncpg.connect(self.source_conn)
        target_conn = await asyncpg.connect(self.target_conn)

        # è·å–å˜æ›´ï¼ˆå‡è®¾æœ‰ updated_at å­—æ®µï¼‰
        if self.last_sync_time:
            changes = await source_conn.fetch(f"""
                SELECT * FROM {table_name}
                WHERE updated_at > $1
                ORDER BY updated_at
            """, self.last_sync_time)
        else:
            # é¦–æ¬¡åŒæ­¥ï¼Œè·å–æ‰€æœ‰æ•°æ®
            changes = await source_conn.fetch(f"SELECT * FROM {table_name}")

        # åº”ç”¨å˜æ›´
        for row in changes:
            await target_conn.execute(f"""
                INSERT INTO {table_name} VALUES ({','.join(['$' + str(i+1) for i in range(len(row))])})
                ON CONFLICT (id) DO UPDATE
                SET {','.join([f"{k} = EXCLUDED.{k}" for k in row.keys() if k != 'id'])}
            """, list(row.values()))

        # æ›´æ–°åŒæ­¥æ—¶é—´
        if changes:
            self.last_sync_time = changes[-1]['updated_at']

        await source_conn.close()
        await target_conn.close()
```

### 41. å®‰å…¨æœ€ä½³å®è·µæ‰©å±•

#### 41.1 æ•°æ®åŠ å¯†

```python
class DataEncryption:
    """æ•°æ®åŠ å¯†"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def setup_column_encryption(self, table_name, column_name):
        """è®¾ç½®åˆ—åŠ å¯†"""
        conn = await asyncpg.connect(self.conn_string)

        # å®‰è£…åŠ å¯†æ‰©å±•
        await conn.execute("CREATE EXTENSION IF NOT EXISTS pgcrypto")

        # åˆ›å»ºåŠ å¯†å‡½æ•°
        await conn.execute(f"""
            CREATE OR REPLACE FUNCTION encrypt_{table_name}_{column_name}(text)
            RETURNS bytea AS $$
            BEGIN
                RETURN pgp_sym_encrypt($1, current_setting('app.encryption_key'));
            END;
            $$ LANGUAGE plpgsql;
        """)

        # åˆ›å»ºè§£å¯†å‡½æ•°
        await conn.execute(f"""
            CREATE OR REPLACE FUNCTION decrypt_{table_name}_{column_name}(bytea)
            RETURNS text AS $$
            BEGIN
                RETURN pgp_sym_decrypt($1, current_setting('app.encryption_key'));
            END;
            $$ LANGUAGE plpgsql;
        """)

        await conn.close()

    async def encrypt_data(self, table_name, column_name, data):
        """åŠ å¯†æ•°æ®"""
        conn = await asyncpg.connect(self.conn_string)

        encrypted = await conn.fetchval(
            f"SELECT encrypt_{table_name}_{column_name}($1)",
            data
        )

        await conn.close()
        return encrypted

    async def decrypt_data(self, table_name, column_name, encrypted_data):
        """è§£å¯†æ•°æ®"""
        conn = await asyncpg.connect(self.conn_string)

        decrypted = await conn.fetchval(
            f"SELECT decrypt_{table_name}_{column_name}($1)",
            encrypted_data
        )

        await conn.close()
        return decrypted
```

#### 41.2 è¡Œçº§å®‰å…¨ç­–ç•¥

```python
class RowLevelSecurity:
    """è¡Œçº§å®‰å…¨ç­–ç•¥"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def enable_rls(self, table_name):
        """å¯ç”¨è¡Œçº§å®‰å…¨"""
        conn = await asyncpg.connect(self.conn_string)

        await conn.execute(f"""
            ALTER TABLE {table_name} ENABLE ROW LEVEL SECURITY
        """)

        await conn.close()

    async def create_policy(self, table_name, policy_name, policy_definition):
        """åˆ›å»ºç­–ç•¥"""
        conn = await asyncpg.connect(self.conn_string)

        await conn.execute(f"""
            CREATE POLICY {policy_name} ON {table_name}
            {policy_definition}
        """)

        await conn.close()

    async def create_user_policy(self, table_name, user_id_column):
        """åˆ›å»ºç”¨æˆ·ç­–ç•¥"""
        await self.create_policy(
            table_name,
            "user_policy",
            f"FOR ALL USING ({user_id_column} = current_setting('app.user_id')::int)"
        )
```

### 42. æ€§èƒ½ç›‘æ§ä¸è°ƒä¼˜

#### 42.1 æ…¢æŸ¥è¯¢åˆ†æ

```python
class SlowQueryAnalyzer:
    """æ…¢æŸ¥è¯¢åˆ†æå™¨"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def analyze_slow_queries(self, threshold_ms=100):
        """åˆ†ææ…¢æŸ¥è¯¢"""
        conn = await asyncpg.connect(self.conn_string)

        # å¯ç”¨ pg_stat_statements
        await conn.execute("CREATE EXTENSION IF NOT EXISTS pg_stat_statements")

        # è·å–æ…¢æŸ¥è¯¢
        slow_queries = await conn.fetch(f"""
            SELECT
                query,
                calls,
                total_exec_time,
                mean_exec_time,
                max_exec_time,
                min_exec_time,
                stddev_exec_time
            FROM pg_stat_statements
            WHERE mean_exec_time > {threshold_ms}
            ORDER BY mean_exec_time DESC
            LIMIT 20
        """)

        # åˆ†ææ¯ä¸ªæŸ¥è¯¢
        analysis = []
        for query in slow_queries:
            plan = await conn.fetch(f"EXPLAIN ANALYZE {query['query']}")

            analysis.append({
                'query': query['query'][:200],  # æˆªæ–­é•¿æŸ¥è¯¢
                'stats': dict(query),
                'execution_plan': [dict(p) for p in plan]
            })

        await conn.close()
        return analysis

    async def get_query_recommendations(self, query_text):
        """è·å–æŸ¥è¯¢ä¼˜åŒ–å»ºè®®"""
        conn = await asyncpg.connect(self.conn_string)

        # è·å–æ‰§è¡Œè®¡åˆ’
        plan = await conn.fetch(f"EXPLAIN {query_text}")

        recommendations = []

        for row in plan:
            plan_text = row['QUERY PLAN']

            # æ£€æŸ¥é¡ºåºæ‰«æ
            if 'Seq Scan' in plan_text:
                table_match = re.search(r'on (\w+)', plan_text)
                if table_match:
                    recommendations.append({
                        'type': 'index',
                        'table': table_match.group(1),
                        'recommendation': f"è€ƒè™‘åœ¨è¡¨ {table_match.group(1)} ä¸Šæ·»åŠ ç´¢å¼•"
                    })

            # æ£€æŸ¥åµŒå¥—å¾ªç¯
            if 'Nested Loop' in plan_text:
                recommendations.append({
                    'type': 'join',
                    'recommendation': 'è€ƒè™‘ä¼˜åŒ–è¿æ¥é¡ºåºæˆ–æ·»åŠ è¿æ¥æ¡ä»¶ç´¢å¼•'
                })

        await conn.close()
        return recommendations
```

#### 42.2 è‡ªåŠ¨ç´¢å¼•å»ºè®®

```python
class AutoIndexAdvisor:
    """è‡ªåŠ¨ç´¢å¼•å»ºè®®å™¨"""

    def __init__(self, connection_string):
        self.conn_string = connection_string

    async def analyze_table(self, table_name):
        """åˆ†æè¡¨å¹¶å»ºè®®ç´¢å¼•"""
        conn = await asyncpg.connect(self.conn_string)

        # è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯
        stats = await conn.fetch(f"""
            SELECT
                attname,
                n_distinct,
                correlation,
                most_common_vals,
                most_common_freqs
            FROM pg_stats
            WHERE schemaname = 'public'
            AND tablename = $1
        """, table_name)

        # è·å–ç°æœ‰ç´¢å¼•
        indexes = await conn.fetch(f"""
            SELECT indexname, indexdef
            FROM pg_indexes
            WHERE schemaname = 'public'
            AND tablename = $1
        """, table_name)

        existing_indexed_columns = set()
        for idx in indexes:
            # æå–ç´¢å¼•åˆ—
            match = re.search(r'\(([^)]+)\)', idx['indexdef'])
            if match:
                existing_indexed_columns.update(
                    [col.strip() for col in match.group(1).split(',')]
                )

        # ç”Ÿæˆå»ºè®®
        recommendations = []
        for stat in stats:
            column_name = stat['attname']

            # è·³è¿‡å·²æœ‰ç´¢å¼•çš„åˆ—
            if column_name in existing_indexed_columns:
                continue

            # é«˜åŸºæ•°ä¸”ä½ç›¸å…³æ€§é€‚åˆç´¢å¼•
            if stat['n_distinct'] > 100 and abs(stat['correlation']) < 0.1:
                recommendations.append({
                    'table': table_name,
                    'column': column_name,
                    'type': 'btree',
                    'reason': f"é«˜åŸºæ•° ({stat['n_distinct']}), ä½ç›¸å…³æ€§ ({stat['correlation']:.2f})",
                    'sql': f"CREATE INDEX idx_{table_name}_{column_name} ON {table_name} ({column_name})"
                })

        await conn.close()
        return recommendations
```

### 43. æ€»ç»“ä¸å¿«é€Ÿå¼€å§‹

#### 43.1 5 åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

```python
# 1. å®‰è£…ä¾èµ–
# pip install neon-python asyncpg

# 2. åˆ›å»ºå®¢æˆ·ç«¯
from neon import NeonClient

client = NeonClient(api_key="your-api-key")

# 3. åˆ›å»ºé¡¹ç›®
project = await client.projects.create(
    name="my-project",
    region="us-east-1"
)

# 4. åˆ›å»ºåˆ†æ”¯
branch = await client.branches.create(
    project_id=project.id,
    name="main",
    parent_branch=None
)

# 5. è¿æ¥æ•°æ®åº“
import asyncpg

conn = await asyncpg.connect(branch.connection_string)

# 6. åˆ›å»ºè¡¨
await conn.execute("""
    CREATE TABLE users (
        id SERIAL PRIMARY KEY,
        name TEXT,
        email TEXT UNIQUE
    )
""")

# 7. æ’å…¥æ•°æ®
await conn.execute(
    "INSERT INTO users (name, email) VALUES ($1, $2)",
    "John Doe", "john@example.com"
)

# 8. æŸ¥è¯¢æ•°æ®
rows = await conn.fetch("SELECT * FROM users")
print(rows)

await conn.close()
```

#### 43.2 å¸¸è§ä½¿ç”¨æ¨¡å¼

##### 43.2.1 æ¨¡å¼ 1: AI Agent å®éªŒ

```python
# ä¸ºæ¯æ¬¡å®éªŒåˆ›å»ºåˆ†æ”¯
for experiment in experiments:
    branch = await client.branches.create(
        project_id=project_id,
        name=f"experiment-{experiment.id}",
        parent_branch="main"
    )

    # è¿è¡Œå®éªŒ
    results = await run_experiment(branch.connection_string)

    # å®éªŒå®Œæˆååˆ é™¤åˆ†æ”¯
    await client.branches.delete(
        project_id=project_id,
        branch_id=branch.id
    )
```

##### 43.2.2 æ¨¡å¼ 2: å¤šç¯å¢ƒå¼€å‘

```python
# ä¸ºæ¯ä¸ªå¼€å‘è€…åˆ›å»ºç¯å¢ƒ
for developer in developers:
    branch = await client.branches.create(
        project_id=project_id,
        name=f"dev-{developer.id}",
        parent_branch="main"
    )

    # è¿è¡Œè¿ç§»
    await run_migrations(branch.connection_string)
```

##### 43.2.3 æ¨¡å¼ 3: A/B æµ‹è¯•

```python
# åˆ›å»ºæµ‹è¯•å˜ä½“
variants = ["control", "variant-a", "variant-b"]

for variant in variants:
    branch = await client.branches.create(
        project_id=project_id,
        name=f"ab-test-{variant}",
        parent_branch="main"
    )

    # é…ç½®å˜ä½“
    await configure_variant(branch.connection_string, variant)
```

### 44. å­¦ä¹ è·¯å¾„ä¸åŸ¹è®­èµ„æº

## 44. Neon å¹³å°å­¦ä¹ ä¸åŸ¹è®­

> **æ³¨æ„**: æœ¬èŠ‚ä¸“æ³¨äº **Neon å¹³å°**çš„å­¦ä¹ å’ŒåŸ¹è®­ã€‚å¦‚æœæ‚¨éœ€è¦ **PostgreSQL SQL åŸºç¡€**åŸ¹è®­ï¼Œè¯·å‚è€ƒï¼š
>
> - [æ ¸å¿ƒåŸºç¡€](../../01-æ ¸å¿ƒåŸºç¡€/README.md) - PostgreSQLåŸºç¡€åŸ¹è®­
> - [SQLè¯­è¨€](../../01-æ ¸å¿ƒåŸºç¡€/01.04-SQLè¯­è¨€/README.md) - SQLè¯­è¨€è§„èŒƒä¸æ ‡å‡†

### 44.1 åˆå­¦è€…å­¦ä¹ è·¯å¾„

#### é˜¶æ®µ 1: åŸºç¡€å…¥é—¨ï¼ˆ1-2 å‘¨ï¼‰

**å­¦ä¹ ç›®æ ‡**:

- ç†è§£ Serverless PostgreSQL æ¦‚å¿µ
- æŒæ¡ Neon å¹³å°åŸºæœ¬æ“ä½œ
- èƒ½å¤Ÿåˆ›å»ºå’Œç®¡ç†åˆ†æ”¯

**å­¦ä¹ å†…å®¹**:

1. **Serverless æ•°æ®åº“åŸºç¡€**:

   - Serverless æ¶æ„æ¦‚å¿µ
   - Scale-to-Zero æœºåˆ¶
   - ä¸ä¼ ç»Ÿæ•°æ®åº“çš„åŒºåˆ«

1. **Neon å¹³å°å…¥é—¨**:

   - æ³¨å†Œå’Œåˆ›å»ºé¡¹ç›®
   - åˆ›å»ºç¬¬ä¸€ä¸ªåˆ†æ”¯
   - è¿æ¥æ•°æ®åº“

1. **åŸºç¡€æ“ä½œ**:
   - åˆ›å»ºã€åˆ—å‡ºã€åˆ é™¤åˆ†æ”¯
   - ä½¿ç”¨è¿æ¥å­—ç¬¦ä¸²
   - æ‰§è¡ŒåŸºæœ¬ SQL æŸ¥è¯¢

**å®è·µç»ƒä¹ **:

```python
# ç»ƒä¹  1: åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ªåˆ†æ”¯
from neon import NeonClient

client = NeonClient(api_key="your-api-key")

# åˆ›å»ºé¡¹ç›®
project = await client.projects.create(
    name="learning-project",
    region="us-east-1"
)

# åˆ›å»ºä¸»åˆ†æ”¯
main_branch = await client.branches.create(
    project_id=project.id,
    name="main",
    parent_branch=None
)

# è¿æ¥æ•°æ®åº“
import asyncpg
conn = await asyncpg.connect(main_branch.connection_string)

# åˆ›å»ºè¡¨
await conn.execute("""
    CREATE TABLE students (
        id SERIAL PRIMARY KEY,
        name TEXT,
        email TEXT
    )
""")

# æ’å…¥æ•°æ®
await conn.execute(
    "INSERT INTO students (name, email) VALUES ($1, $2)",
    "Alice", "alice@example.com"
)

# æŸ¥è¯¢æ•°æ®
rows = await conn.fetch("SELECT * FROM students")
print(rows)

await conn.close()
```

#### é˜¶æ®µ 2: ä¸­çº§åº”ç”¨ï¼ˆ2-4 å‘¨ï¼‰

**å­¦ä¹ ç›®æ ‡**:

- æŒæ¡åˆ†æ”¯ç®¡ç†é«˜çº§æŠ€å·§
- ç†è§£ COW æŠ€æœ¯åŸç†
- èƒ½å¤Ÿè¿›è¡Œæ€§èƒ½ä¼˜åŒ–

**å­¦ä¹ å†…å®¹**:

1. **åˆ†æ”¯ç®¡ç†**:

   - åˆ†æ”¯åˆå¹¶ç­–ç•¥
   - å¿«ç…§ç®¡ç†
   - åˆ†æ”¯ç”Ÿå‘½å‘¨æœŸç®¡ç†

1. **æ€§èƒ½ä¼˜åŒ–**:

   - è¿æ¥æ± é…ç½®
   - æŸ¥è¯¢ä¼˜åŒ–
   - ç´¢å¼•ç­–ç•¥

1. **æˆæœ¬ä¼˜åŒ–**:
   - Scale-to-Zero ä½¿ç”¨
   - å­˜å‚¨ä¼˜åŒ–
   - æˆæœ¬ç›‘æ§

**å®è·µç»ƒä¹ **:

```python
# ç»ƒä¹  2: åˆ†æ”¯åˆå¹¶
# åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
feature_branch = await client.branches.create(
    project_id=project.id,
    name="feature-user-authentication",
    parent_branch="main"
)

# åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘
feature_conn = await asyncpg.connect(feature_branch.connection_string)
await feature_conn.execute("""
    CREATE TABLE users (
        id SERIAL PRIMARY KEY,
        username TEXT UNIQUE,
        password_hash TEXT
    )
""")
await feature_conn.close()

# æµ‹è¯•é€šè¿‡ååˆå¹¶åˆ°ä¸»åˆ†æ”¯
await client.branches.merge(
    project_id=project.id,
    source_branch_id=feature_branch.id,
    target_branch_id="main"
)
```

#### é˜¶æ®µ 3: é«˜çº§åº”ç”¨ï¼ˆ4-8 å‘¨ï¼‰

**å­¦ä¹ ç›®æ ‡**:

- æŒæ¡ä¼ä¸šçº§éƒ¨ç½²æ¨¡å¼
- èƒ½å¤Ÿè®¾è®¡é«˜å¯ç”¨æ¶æ„
- ç†è§£å®‰å…¨æœ€ä½³å®è·µ

**å­¦ä¹ å†…å®¹**:

1. **ä¼ä¸šçº§æ¶æ„**:

   - å¤šåŒºåŸŸéƒ¨ç½²
   - ç¾éš¾æ¢å¤
   - é«˜å¯ç”¨é…ç½®

1. **å®‰å…¨å®è·µ**:

   - æ•°æ®åŠ å¯†
   - è®¿é—®æ§åˆ¶
   - å®¡è®¡æ—¥å¿—

1. **ç›‘æ§è¿ç»´**:
   - æ€§èƒ½ç›‘æ§
   - æ•…éšœæ’æŸ¥
   - è‡ªåŠ¨åŒ–è¿ç»´

**å®è·µç»ƒä¹ **:

```python
# ç»ƒä¹  3: å¤šåŒºåŸŸéƒ¨ç½²
class MultiRegionSetup:
    async def setup(self, main_branch_id):
        regions = ['us-east-1', 'us-west-2', 'eu-west-1']

        for region in regions:
            replica = await client.branches.create_replica(
                branch_id=main_branch_id,
                region=region,
                name=f"replica-{region}"
            )
            print(f"Created replica in {region}")
```

#### 44.2 åœ¨çº¿åŸ¹è®­è¯¾ç¨‹

**æ¨èè¯¾ç¨‹**:

1. **Neon å®˜æ–¹æ•™ç¨‹**:

   - [Neon å¿«é€Ÿå¼€å§‹](https://neon.tech/docs/quickstart)
   - [åˆ†æ”¯ç®¡ç†æŒ‡å—](https://neon.tech/docs/branches)
   - [Scale-to-Zero è¯¦è§£](https://neon.tech/docs/scale-to-zero)

1. **è§†é¢‘æ•™ç¨‹**:

   - Neon YouTube é¢‘é“
   - PostgreSQL Serverless ç³»åˆ—è¯¾ç¨‹
   - AI Agent æ•°æ®åº“å®è·µ

1. **å®è·µé¡¹ç›®**:
   - æ„å»º RAG åº”ç”¨
   - å¤šç¯å¢ƒå¼€å‘æµç¨‹
   - A/B æµ‹è¯•å¹³å°

#### 44.3 å®æˆ˜é¡¹ç›®

#### é¡¹ç›® 1: AI Agent å®éªŒå¹³å°

**é¡¹ç›®æè¿°**: æ„å»ºä¸€ä¸ªæ”¯æŒ AI Agent é¢‘ç¹å®éªŒçš„æ•°æ®åº“å¹³å°ï¼Œèƒ½å¤Ÿå¿«é€Ÿåˆ›å»ºåˆ†æ”¯ã€è¿è¡Œå®éªŒã€å¯¹æ¯”ç»“æœã€‚

**æŠ€æœ¯æ ˆ**:

- Neon Serverless PostgreSQL
- Python/FastAPI
- LangChain
- pgvector

**é¡¹ç›®æ­¥éª¤**:

```python
# æ­¥éª¤ 1: é¡¹ç›®åˆå§‹åŒ–
class AIAgentExperimentPlatform:
    def __init__(self):
        self.neon = NeonClient(api_key=os.getenv("NEON_API_KEY"))
        self.project_id = os.getenv("NEON_PROJECT_ID")
        self.experiments = {}

    # æ­¥éª¤ 2: åˆ›å»ºå®éªŒåˆ†æ”¯
    async def create_experiment(self, experiment_config):
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"experiment-{experiment_config['id']}",
            parent_branch="main"
        )

        # è®¾ç½®å‘é‡å­˜å‚¨
        await self.setup_vectorstore(branch.connection_string)

        return branch

    # æ­¥éª¤ 3: è¿è¡Œå®éªŒ
    async def run_experiment(self, experiment_id, queries):
        branch = self.experiments[experiment_id]['branch']
        results = []

        for query in queries:
            docs = await self.search_documents(branch.connection_string, query)
            results.append({
                'query': query,
                'results': docs,
                'timestamp': datetime.now()
            })

        return results

    # æ­¥éª¤ 4: å¯¹æ¯”å®éªŒç»“æœ
    async def compare_experiments(self, experiment_ids, query):
        comparison = {}

        for exp_id in experiment_ids:
            results = await self.run_experiment(exp_id, [query])
            comparison[exp_id] = results[0]

        return comparison
```

#### é¡¹ç›® 2: å¤šç¯å¢ƒå¼€å‘å¹³å°

**é¡¹ç›®æè¿°**: ä¸ºå¼€å‘å›¢é˜Ÿæ„å»ºä¸€ä¸ªå¤šç¯å¢ƒç®¡ç†å¹³å°ï¼Œæ”¯æŒå¿«é€Ÿåˆ›å»ºå¼€å‘/æµ‹è¯•ç¯å¢ƒã€ç¯å¢ƒéš”ç¦»ã€è‡ªåŠ¨æ¸…ç†ã€‚

**æŠ€æœ¯æ ˆ**:

- Neon Serverless PostgreSQL
- Django/FastAPI
- Docker
- CI/CD é›†æˆ

**é¡¹ç›®æ­¥éª¤**:

```python
# æ­¥éª¤ 1: ç¯å¢ƒç®¡ç†
class DevelopmentEnvironmentManager:
    async def create_environment(self, developer_id, environment_type):
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name=f"{environment_type}-{developer_id}",
            parent_branch="main"
        )

        # è¿è¡Œæ•°æ®åº“è¿ç§»
        await self.run_migrations(branch.connection_string)

        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®
        await self.initialize_test_data(branch.connection_string)

        return branch

    # æ­¥éª¤ 2: ç¯å¢ƒæ¸…ç†
    async def cleanup_old_environments(self, days_unused=7):
        cutoff = datetime.now() - timedelta(days=days_unused)

        for env_id, env_info in list(self.environments.items()):
            if env_info['last_used'] < cutoff:
                await self.neon.branches.delete(
                    project_id=self.project_id,
                    branch_id=env_info['branch'].id
                )
                del self.environments[env_id]
```

#### é¡¹ç›® 3: RAG åº”ç”¨æ„å»º

**é¡¹ç›®æè¿°**: ä½¿ç”¨ Neon + pgvector æ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰åº”ç”¨ï¼Œæ”¯æŒæ–‡æ¡£å­˜å‚¨ã€å‘é‡æœç´¢ã€
é—®ç­”ç³»ç»Ÿã€‚

**æŠ€æœ¯æ ˆ**:

- Neon Serverless PostgreSQL
- pgvector
- LangChain
- OpenAI API

**é¡¹ç›®æ­¥éª¤**:

```python
# æ­¥éª¤ 1: è®¾ç½®å‘é‡å­˜å‚¨
class RAGApplication:
    async def setup(self):
        # åˆ›å»ºåˆ†æ”¯
        branch = await self.neon.branches.create(
            project_id=self.project_id,
            name="rag-app",
            parent_branch="main"
        )

        # å®‰è£… pgvector
        conn = await asyncpg.connect(branch.connection_string)
        await conn.execute("CREATE EXTENSION IF NOT EXISTS vector")

        # åˆ›å»ºæ–‡æ¡£è¡¨
        await conn.execute("""
            CREATE TABLE documents (
                id SERIAL PRIMARY KEY,
                content TEXT,
                embedding vector(1536),
                metadata JSONB
            )
        """)

        await conn.close()

    # æ­¥éª¤ 2: æ·»åŠ æ–‡æ¡£
    async def add_documents(self, documents):
        embeddings = OpenAIEmbeddings()

        for doc in documents:
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = await embeddings.aembed_query(doc['content'])

            # å­˜å‚¨åˆ°æ•°æ®åº“
            conn = await asyncpg.connect(self.branch.connection_string)
            await conn.execute("""
                INSERT INTO documents (content, embedding, metadata)
                VALUES ($1, $2, $3)
            """, doc['content'], embedding, json.dumps(doc.get('metadata', {})))
            await conn.close()

    # æ­¥éª¤ 3: æœç´¢å’Œé—®ç­”
    async def query(self, question):
        # ç”Ÿæˆé—®é¢˜å‘é‡
        embeddings = OpenAIEmbeddings()
        question_embedding = await embeddings.aembed_query(question)

        # å‘é‡æœç´¢
        conn = await asyncpg.connect(self.branch.connection_string)
        results = await conn.fetch("""
            SELECT content, metadata,
                   1 - (embedding <=> $1::vector) as similarity
            FROM documents
            ORDER BY embedding <=> $1::vector
            LIMIT 5
        """, question_embedding)
        await conn.close()

        # ç”Ÿæˆç­”æ¡ˆ
        context = "\n".join([r['content'] for r in results])
        answer = await self.generate_answer(question, context)

        return answer
```

#### 44.4 è®¤è¯ä¸è€ƒè¯•

**Neon è®¤è¯è·¯å¾„**:

1. **Neon åŸºç¡€è®¤è¯**:

   - è€ƒè¯•å†…å®¹: åŸºç¡€æ“ä½œã€åˆ†æ”¯ç®¡ç†ã€Scale-to-Zero
   - è€ƒè¯•æ—¶é•¿: 60 åˆ†é’Ÿ
   - é¢˜ç›®ç±»å‹: é€‰æ‹©é¢˜ã€å®æ“é¢˜
   - é€šè¿‡åˆ†æ•°: 70%

1. **Neon é«˜çº§è®¤è¯**:
   - è€ƒè¯•å†…å®¹: ä¼ä¸šçº§éƒ¨ç½²ã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨å®è·µ
   - è€ƒè¯•æ—¶é•¿: 90 åˆ†é’Ÿ
   - é¢˜ç›®ç±»å‹: æ¡ˆä¾‹åˆ†æã€æ¶æ„è®¾è®¡ã€å®æ“é¢˜
   - é€šè¿‡åˆ†æ•°: 75%

**å¤‡è€ƒèµ„æº**:

```python
# è®¤è¯è€ƒè¯•ç»ƒä¹ é¢˜
class CertificationPractice:
    """è®¤è¯è€ƒè¯•ç»ƒä¹ é¢˜"""

    def practice_branch_management(self):
        """ç»ƒä¹  1: åˆ†æ”¯ç®¡ç†"""
        # é¢˜ç›®: åˆ›å»ºä¸€ä¸ªåˆ†æ”¯ï¼Œä¿®æ”¹æ•°æ®ï¼Œç„¶ååˆå¹¶å›ä¸»åˆ†æ”¯
        # ä½ çš„ä»£ç ...
        pass

    def practice_performance_optimization(self):
        """ç»ƒä¹  2: æ€§èƒ½ä¼˜åŒ–"""
        # é¢˜ç›®: ä¼˜åŒ–ä¸€ä¸ªæ…¢æŸ¥è¯¢ï¼Œæ·»åŠ é€‚å½“çš„ç´¢å¼•
        # ä½ çš„ä»£ç ...
        pass

    def practice_disaster_recovery(self):
        """ç»ƒä¹  3: ç¾éš¾æ¢å¤"""
        # é¢˜ç›®: è®¾è®¡ä¸€ä¸ªç¾éš¾æ¢å¤æ–¹æ¡ˆ
        # ä½ çš„ä»£ç ...
        pass
```

#### 44.5 å­¦ä¹ ç¤¾åŒºä¸èµ„æº

**å®˜æ–¹ç¤¾åŒº**:

1. **Neon Discord**:

   - å®æ—¶è®¨è®º
   - æŠ€æœ¯æ”¯æŒ
   - ç»éªŒåˆ†äº«

1. **GitHub Discussions**:

   - æŠ€æœ¯é—®é¢˜
   - åŠŸèƒ½å»ºè®®
   - æœ€ä½³å®è·µ

1. **Stack Overflow**:
   - æ ‡ç­¾: `neon-database`, `serverless-postgresql`
   - å¸¸è§é—®é¢˜è§£ç­”

**å­¦ä¹ èµ„æº**:

1. **å®˜æ–¹æ–‡æ¡£**:

   - [Neon æ–‡æ¡£](https://neon.tech/docs)
   - [API å‚è€ƒ](https://neon.tech/api-reference)
   - [ç¤ºä¾‹ä»£ç ](https://github.com/neondatabase/examples)

1. **åšå®¢æ–‡ç« **:

   - Neon æŠ€æœ¯åšå®¢
   - Serverless PostgreSQL æœ€ä½³å®è·µ
   - AI Agent æ•°æ®åº“ä½¿ç”¨æ¡ˆä¾‹

1. **è§†é¢‘èµ„æº**:
   - Neon YouTube é¢‘é“
   - æŠ€æœ¯ä¼šè®®æ¼”è®²
   - åœ¨çº¿ç ”è®¨ä¼š

#### 44.6 å®è·µç»ƒä¹ é¢˜åº“

**åŸºç¡€ç»ƒä¹ **:

1. **ç»ƒä¹  1: åˆ›å»ºå’Œç®¡ç†åˆ†æ”¯**

   ```python
   # ä»»åŠ¡: åˆ›å»ºä¸€ä¸ªåä¸º "test-branch" çš„åˆ†æ”¯
   # åœ¨åˆ†æ”¯ä¸­åˆ›å»ºä¸€ä¸ªè¡¨å¹¶æ’å…¥æ•°æ®
   # åˆ—å‡ºæ‰€æœ‰åˆ†æ”¯
   # åˆ é™¤æµ‹è¯•åˆ†æ”¯
   ```

1. **ç»ƒä¹  2: å¿«ç…§å’Œæ¢å¤**

   ```python
   # ä»»åŠ¡: åˆ›å»ºä¸€ä¸ªå¿«ç…§
   # ä¿®æ”¹æ•°æ®
   # ä»å¿«ç…§æ¢å¤æ•°æ®
   ```

1. **ç»ƒä¹  3: Scale-to-Zero**

   ```python
   # ä»»åŠ¡: è§‚å¯Ÿæ•°æ®åº“è‡ªåŠ¨åœæ­¢
   # æµ‹è¯•å¿«é€Ÿæ¢å¤
   # æµ‹é‡æ¢å¤æ—¶é—´
   ```

**ä¸­çº§ç»ƒä¹ **:

1. **ç»ƒä¹  4: åˆ†æ”¯åˆå¹¶**

   ```python
   # ä»»åŠ¡: åˆ›å»ºä¸¤ä¸ªåŠŸèƒ½åˆ†æ”¯
   # åœ¨ä¸åŒåˆ†æ”¯ä¸Šä¿®æ”¹ä¸åŒè¡¨
   # åˆå¹¶ä¸¤ä¸ªåˆ†æ”¯åˆ°ä¸»åˆ†æ”¯
   ```

1. **ç»ƒä¹  5: æ€§èƒ½ä¼˜åŒ–**

   ```python
   # ä»»åŠ¡: åˆ†ææ…¢æŸ¥è¯¢
   # æ·»åŠ ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
   # å¯¹æ¯”ä¼˜åŒ–å‰åæ€§èƒ½
   ```

1. **ç»ƒä¹  6: æˆæœ¬ä¼˜åŒ–**

   ```python
   # ä»»åŠ¡: åˆ†ææœˆåº¦æˆæœ¬
   # è¯†åˆ«å¯ä»¥ä¼˜åŒ–çš„åˆ†æ”¯
   # å®æ–½æˆæœ¬ä¼˜åŒ–ç­–ç•¥
   ```

**é«˜çº§ç»ƒä¹ **:

1. **ç»ƒä¹  7: å¤šåŒºåŸŸéƒ¨ç½²**

   ```python
   # ä»»åŠ¡: è®¾ç½®å¤šåŒºåŸŸå‰¯æœ¬
   # æµ‹è¯•åŒºåŸŸé—´æ•°æ®åŒæ­¥
   # å®ç°æœ€è¿‘åŒºåŸŸé€‰æ‹©
   ```

1. **ç»ƒä¹  8: ç¾éš¾æ¢å¤**

   ```python
   # ä»»åŠ¡: è®¾è®¡ç¾éš¾æ¢å¤æ–¹æ¡ˆ
   # å®ç°è‡ªåŠ¨å¤‡ä»½
   # æµ‹è¯•æ¢å¤æµç¨‹
   ```

1. **ç»ƒä¹  9: å®‰å…¨åŠ å›º**

   ```python
   # ä»»åŠ¡: é…ç½® SSL/TLS
   # å®ç°æ•°æ®åŠ å¯†
   # è®¾ç½®è¡Œçº§å®‰å…¨ç­–ç•¥
   ```

#### 44.7 å­¦ä¹ æ£€æŸ¥æ¸…å•

**åˆå­¦è€…æ£€æŸ¥æ¸…å•**:

- [ ] ç†è§£ Serverless PostgreSQL æ¦‚å¿µ
- [ ] èƒ½å¤Ÿåˆ›å»ºå’Œç®¡ç† Neon é¡¹ç›®
- [ ] æŒæ¡åˆ†æ”¯çš„åŸºæœ¬æ“ä½œ
- [ ] èƒ½å¤Ÿè¿æ¥å’Œæ‰§è¡Œ SQL æŸ¥è¯¢
- [ ] ç†è§£ Scale-to-Zero æœºåˆ¶
- [ ] å®Œæˆè‡³å°‘ 3 ä¸ªåŸºç¡€ç»ƒä¹ 

**ä¸­çº§å¼€å‘è€…æ£€æŸ¥æ¸…å•**:

- [ ] æŒæ¡åˆ†æ”¯åˆå¹¶ç­–ç•¥
- [ ] èƒ½å¤Ÿè¿›è¡Œæ€§èƒ½ä¼˜åŒ–
- [ ] ç†è§£ COW æŠ€æœ¯åŸç†
- [ ] èƒ½å¤Ÿé…ç½®è¿æ¥æ± 
- [ ] æŒæ¡æˆæœ¬ä¼˜åŒ–æŠ€å·§
- [ ] å®Œæˆè‡³å°‘ 3 ä¸ªä¸­çº§ç»ƒä¹ 
- [ ] å®Œæˆä¸€ä¸ªå®æˆ˜é¡¹ç›®

**é«˜çº§æ¶æ„å¸ˆæ£€æŸ¥æ¸…å•**:

- [ ] èƒ½å¤Ÿè®¾è®¡ä¼ä¸šçº§æ¶æ„
- [ ] æŒæ¡å¤šåŒºåŸŸéƒ¨ç½²
- [ ] èƒ½å¤Ÿè®¾è®¡ç¾éš¾æ¢å¤æ–¹æ¡ˆ
- [ ] æŒæ¡å®‰å…¨æœ€ä½³å®è·µ
- [ ] èƒ½å¤Ÿè¿›è¡Œæ•…éšœæ’æŸ¥
- [ ] å®Œæˆè‡³å°‘ 3 ä¸ªé«˜çº§ç»ƒä¹ 
- [ ] å®Œæˆ 2-3 ä¸ªå®æˆ˜é¡¹ç›®
- [ ] é€šè¿‡é«˜çº§è®¤è¯è€ƒè¯•

#### 44.8 å­¦ä¹ è·¯çº¿å›¾

```text
Neon å­¦ä¹ è·¯çº¿å›¾:

ç¬¬ 1-2 å‘¨: åŸºç¡€å…¥é—¨
  â”œâ”€â”€ Serverless æ¦‚å¿µ
  â”œâ”€â”€ Neon å¹³å°ä»‹ç»
  â”œâ”€â”€ åŸºç¡€æ“ä½œ
  â””â”€â”€ ç¬¬ä¸€ä¸ªé¡¹ç›®

ç¬¬ 3-4 å‘¨: åˆ†æ”¯ç®¡ç†
  â”œâ”€â”€ åˆ†æ”¯åˆ›å»ºå’Œç®¡ç†
  â”œâ”€â”€ å¿«ç…§å’Œæ¢å¤
  â”œâ”€â”€ åˆ†æ”¯åˆå¹¶
  â””â”€â”€ å®è·µé¡¹ç›®

ç¬¬ 5-6 å‘¨: æ€§èƒ½ä¼˜åŒ–
  â”œâ”€â”€ æŸ¥è¯¢ä¼˜åŒ–
  â”œâ”€â”€ ç´¢å¼•ç­–ç•¥
  â”œâ”€â”€ è¿æ¥æ± é…ç½®
  â””â”€â”€ æ€§èƒ½æµ‹è¯•

ç¬¬ 7-8 å‘¨: é«˜çº§ç‰¹æ€§
  â”œâ”€â”€ å¤šåŒºåŸŸéƒ¨ç½²
  â”œâ”€â”€ ç¾éš¾æ¢å¤
  â”œâ”€â”€ å®‰å…¨å®è·µ
  â””â”€â”€ ä¼ä¸šçº§é¡¹ç›®

ç¬¬ 9-10 å‘¨: å®æˆ˜åº”ç”¨
  â”œâ”€â”€ AI Agent å¹³å°
  â”œâ”€â”€ RAG åº”ç”¨
  â”œâ”€â”€ å¤šç¯å¢ƒç®¡ç†
  â””â”€â”€ è®¤è¯è€ƒè¯•å‡†å¤‡
```

#### 44.9 åŸ¹è®­è¯¾ç¨‹å¤§çº²

#### è¯¾ç¨‹ 1: Neon åŸºç¡€åŸ¹è®­ï¼ˆ8 å°æ—¶ï¼‰

##### æ¨¡å— 1: Serverless PostgreSQL åŸºç¡€ï¼ˆ2 å°æ—¶ï¼‰

- Serverless æ¶æ„æ¦‚è¿°
- Scale-to-Zero æœºåˆ¶
- ä¸ä¼ ç»Ÿæ•°æ®åº“å¯¹æ¯”
- é€‚ç”¨åœºæ™¯åˆ†æ

##### æ¨¡å— 2: Neon å¹³å°å…¥é—¨ï¼ˆ2 å°æ—¶ï¼‰

- å¹³å°æ³¨å†Œå’Œé…ç½®
- é¡¹ç›®åˆ›å»ºå’Œç®¡ç†
- åˆ†æ”¯åˆ›å»ºå’Œç®¡ç†
- è¿æ¥å­—ç¬¦ä¸²ä½¿ç”¨

##### æ¨¡å— 3: åˆ†æ”¯ç®¡ç†å®è·µï¼ˆ2 å°æ—¶ï¼‰

- åˆ†æ”¯åˆ›å»ºç­–ç•¥
- å¿«ç…§ç®¡ç†
- åˆ†æ”¯åˆå¹¶
- åˆ†æ”¯ç”Ÿå‘½å‘¨æœŸç®¡ç†

##### æ¨¡å— 4: å®æˆ˜ç»ƒä¹ ï¼ˆ2 å°æ—¶ï¼‰

- æ„å»ºç¬¬ä¸€ä¸ªåº”ç”¨
- å¤šç¯å¢ƒå¼€å‘å®è·µ
- é—®é¢˜è§£ç­”å’Œè®¨è®º

#### è¯¾ç¨‹ 2: Neon é«˜çº§åŸ¹è®­ï¼ˆ16 å°æ—¶ï¼‰

##### æ¨¡å— 1: æ€§èƒ½ä¼˜åŒ–ï¼ˆ4 å°æ—¶ï¼‰

- æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§
- ç´¢å¼•ç­–ç•¥
- è¿æ¥æ± é…ç½®
- æ‰¹é‡æ“ä½œä¼˜åŒ–

##### æ¨¡å— 2: ä¼ä¸šçº§éƒ¨ç½²ï¼ˆ4 å°æ—¶ï¼‰

- å¤šåŒºåŸŸéƒ¨ç½²æ¶æ„
- é«˜å¯ç”¨é…ç½®
- ç¾éš¾æ¢å¤æ–¹æ¡ˆ
- ç›‘æ§å’Œå‘Šè­¦

##### æ¨¡å— 3: å®‰å…¨å®è·µï¼ˆ4 å°æ—¶ï¼‰

- æ•°æ®åŠ å¯†
- è®¿é—®æ§åˆ¶
- å®¡è®¡æ—¥å¿—
- åˆè§„æ€§è¦æ±‚

##### æ¨¡å— 4: å®æˆ˜é¡¹ç›®ï¼ˆ4 å°æ—¶ï¼‰

- AI Agent å¹³å°æ„å»º
- RAG åº”ç”¨å¼€å‘
- ä¼ä¸šçº§æ¶æ„è®¾è®¡
- æœ€ä½³å®è·µæ€»ç»“

#### 44.10 åœ¨çº¿å­¦ä¹ å¹³å°

**æ¨èå¹³å°**:

1. **Neon å®˜æ–¹å­¦ä¹ ä¸­å¿ƒ**:

   - äº’åŠ¨å¼æ•™ç¨‹
   - è§†é¢‘è¯¾ç¨‹
   - å®è·µå®éªŒå®¤
   - è¿›åº¦è·Ÿè¸ª

1. **Udemy/Coursera**:

   - "Serverless PostgreSQL å®Œæ•´æŒ‡å—"
   - "Neon å¹³å°å®æˆ˜"
   - "AI Agent æ•°æ®åº“å®è·µ"

1. **Pluralsight**:
   - "PostgreSQL Serverless æ¶æ„"
   - "æ•°æ®åº“åˆ†æ”¯ç®¡ç†"
   - "æ€§èƒ½ä¼˜åŒ–æŠ€å·§"

**å­¦ä¹ èµ„æºé“¾æ¥**:

```markdown
## å…è´¹èµ„æº

- [Neon å®˜æ–¹æ–‡æ¡£](https://neon.tech/docs)
- [Neon ç¤ºä¾‹ä»£ç ](https://github.com/neondatabase/examples)
- [Neon YouTube é¢‘é“](https://youtube.com/@neondatabase)

## ä»˜è´¹è¯¾ç¨‹

- [Neon è®¤è¯åŸ¹è®­](https://neon.tech/training)
- [Serverless PostgreSQL å¤§å¸ˆç­](https://example.com/course)
- [ä¼ä¸šåŸ¹è®­å®šåˆ¶](https://neon.tech/enterprise-training)
```

#### 44.11 å®è·µå®éªŒå®¤

#### å®éªŒå®¤ 1: åˆ†æ”¯ç®¡ç†å®éªŒå®¤

```python
# å®éªŒå®¤ç¯å¢ƒè®¾ç½®
class BranchManagementLab:
    """åˆ†æ”¯ç®¡ç†å®éªŒå®¤"""

    def __init__(self):
        self.scenarios = [
            {
                'name': 'åˆ›å»ºåŠŸèƒ½åˆ†æ”¯',
                'description': 'åˆ›å»ºä¸€ä¸ªåŠŸèƒ½åˆ†æ”¯ï¼Œæ·»åŠ æ–°è¡¨ï¼Œç„¶ååˆå¹¶å›ä¸»åˆ†æ”¯',
                'steps': [
                    'åˆ›å»º feature-branch',
                    'åœ¨åˆ†æ”¯ä¸­åˆ›å»º users è¡¨',
                    'æ’å…¥æµ‹è¯•æ•°æ®',
                    'åˆå¹¶åˆ° main åˆ†æ”¯',
                    'éªŒè¯æ•°æ®'
                ],
                'solution': self.solution_create_feature_branch
            },
            {
                'name': 'å¿«ç…§æ¢å¤',
                'description': 'åˆ›å»ºå¿«ç…§ï¼Œä¿®æ”¹æ•°æ®ï¼Œç„¶åä»å¿«ç…§æ¢å¤',
                'steps': [
                    'åˆ›å»ºå¿«ç…§',
                    'ä¿®æ”¹æ•°æ®',
                    'ä»å¿«ç…§æ¢å¤',
                    'éªŒè¯æ•°æ®æ¢å¤'
                ],
                'solution': self.solution_snapshot_restore
            }
        ]

    async def run_lab(self, scenario_name):
        """è¿è¡Œå®éªŒå®¤åœºæ™¯"""
        scenario = next(s for s in self.scenarios if s['name'] == scenario_name)

        print(f"åœºæ™¯: {scenario['name']}")
        print(f"æè¿°: {scenario['description']}")
        print("\næ­¥éª¤:")
        for i, step in enumerate(scenario['steps'], 1):
            print(f"{i}. {step}")

        # è¿è¡Œè§£å†³æ–¹æ¡ˆ
        await scenario['solution']()

    async def solution_create_feature_branch(self):
        """è§£å†³æ–¹æ¡ˆ: åˆ›å»ºåŠŸèƒ½åˆ†æ”¯"""
        # å­¦ç”Ÿéœ€è¦å®ç°çš„ä»£ç 
        pass
```

#### å®éªŒå®¤ 2: æ€§èƒ½ä¼˜åŒ–å®éªŒå®¤

```python
class PerformanceOptimizationLab:
    """æ€§èƒ½ä¼˜åŒ–å®éªŒå®¤"""

    def setup_slow_query_scenario(self):
        """è®¾ç½®æ…¢æŸ¥è¯¢åœºæ™¯"""
        # åˆ›å»ºä¸€ä¸ªå¤§è¡¨
        await conn.execute("""
            CREATE TABLE orders (
                id SERIAL PRIMARY KEY,
                customer_id INTEGER,
                product_id INTEGER,
                order_date DATE,
                amount DECIMAL
            )
        """)

        # æ’å…¥å¤§é‡æ•°æ®ï¼ˆæ— ç´¢å¼•ï¼‰
        for i in range(100000):
            await conn.execute("""
                INSERT INTO orders (customer_id, product_id, order_date, amount)
                VALUES ($1, $2, $3, $4)
            """, i % 1000, i % 100, '2024-01-01', 100.0)

        # å­¦ç”Ÿä»»åŠ¡: ä¼˜åŒ–è¿™ä¸ªæŸ¥è¯¢
        # SELECT * FROM orders WHERE customer_id = 123 AND order_date > '2024-01-01'
```

#### 44.12 å­¦ä¹ è¿›åº¦è·Ÿè¸ª

```python
class LearningProgressTracker:
    """å­¦ä¹ è¿›åº¦è·Ÿè¸ªå™¨"""

    def __init__(self):
        self.modules = {
            'åŸºç¡€å…¥é—¨': {
                'completed': False,
                'exercises_completed': 0,
                'total_exercises': 5,
                'score': 0
            },
            'åˆ†æ”¯ç®¡ç†': {
                'completed': False,
                'exercises_completed': 0,
                'total_exercises': 5,
                'score': 0
            },
            'æ€§èƒ½ä¼˜åŒ–': {
                'completed': False,
                'exercises_completed': 0,
                'total_exercises': 5,
                'score': 0
            },
            'ä¼ä¸šçº§éƒ¨ç½²': {
                'completed': False,
                'exercises_completed': 0,
                'total_exercises': 5,
                'score': 0
            }
        }

    def update_progress(self, module_name, exercise_completed=True):
        """æ›´æ–°è¿›åº¦"""
        if module_name in self.modules:
            if exercise_completed:
                self.modules[module_name]['exercises_completed'] += 1

            # æ£€æŸ¥æ˜¯å¦å®Œæˆæ¨¡å—
            if self.modules[module_name]['exercises_completed'] >= \
               self.modules[module_name]['total_exercises']:
                self.modules[module_name]['completed'] = True

    def get_progress_report(self):
        """è·å–è¿›åº¦æŠ¥å‘Š"""
        total_modules = len(self.modules)
        completed_modules = sum(1 for m in self.modules.values() if m['completed'])

        return {
            'total_modules': total_modules,
            'completed_modules': completed_modules,
            'completion_percentage': (completed_modules / total_modules) * 100,
            'module_details': self.modules
        }
```

#### 44.13 å­¦ä¹ èµ„æºæ¨è

**ä¹¦ç±**:

1. **ã€ŠServerless PostgreSQL å®æˆ˜ã€‹**

   - ä½œè€…: PostgreSQL Modern Team
   - å†…å®¹: Serverless æ¶æ„ã€Neon å¹³å°ã€æœ€ä½³å®è·µ
   - é€‚åˆ: ä¸­çº§å¼€å‘è€…

1. **ã€Šæ•°æ®åº“åˆ†æ”¯ç®¡ç†æŒ‡å—ã€‹**
   - ä½œè€…: Database Experts
   - å†…å®¹: COW æŠ€æœ¯ã€åˆ†æ”¯ç­–ç•¥ã€åˆå¹¶æŠ€å·§
   - é€‚åˆ: é«˜çº§å¼€å‘è€…

**åœ¨çº¿èµ„æº**:

1. **å®˜æ–¹æ–‡æ¡£**:

   - [Neon æ–‡æ¡£](https://neon.tech/docs)
   - [API å‚è€ƒ](https://neon.tech/api-reference)
   - [ç¤ºä¾‹ä»£ç åº“](https://github.com/neondatabase/examples)

1. **ç¤¾åŒºèµ„æº**:

   - [Neon Discord](https://discord.gg/neondatabase)
   - [GitHub Discussions](https://github.com/neondatabase/neon/discussions)
   - [Stack Overflow](https://stackoverflow.com/questions/tagged/neon-database)

1. **è§†é¢‘æ•™ç¨‹**:
   - Neon YouTube é¢‘é“
   - PostgreSQL ä¼šè®®æ¼”è®²
   - åœ¨çº¿æŠ€æœ¯åˆ†äº«

#### 44.14 å­¦ä¹ æˆæœè¯„ä¼°

**è¯„ä¼°æ ‡å‡†**:

1. **ç†è®ºçŸ¥è¯†** (30%):

   - Serverless æ¶æ„ç†è§£
   - COW æŠ€æœ¯åŸç†
   - Scale-to-Zero æœºåˆ¶

1. **å®è·µèƒ½åŠ›** (50%):

   - åˆ†æ”¯ç®¡ç†æ“ä½œ
   - æ€§èƒ½ä¼˜åŒ–æŠ€å·§
   - æ•…éšœæ’æŸ¥èƒ½åŠ›

1. **é¡¹ç›®ç»éªŒ** (20%):
   - å®Œæˆå®æˆ˜é¡¹ç›®
   - è§£å†³å®é™…é—®é¢˜
   - æœ€ä½³å®è·µåº”ç”¨

**è¯„ä¼°æ–¹å¼**:

```python
class LearningAssessment:
    """å­¦ä¹ è¯„ä¼°"""

    def assess_knowledge(self):
        """ç†è®ºçŸ¥è¯†è¯„ä¼°"""
        questions = [
            {
                'question': 'ä»€ä¹ˆæ˜¯ Copy-on-Write æŠ€æœ¯ï¼Ÿ',
                'type': 'essay',
                'points': 10
            },
            {
                'question': 'Scale-to-Zero çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ',
                'type': 'multiple_choice',
                'options': ['A', 'B', 'C', 'D'],
                'points': 5
            }
        ]
        return questions

    def assess_practice(self):
        """å®è·µèƒ½åŠ›è¯„ä¼°"""
        tasks = [
            {
                'task': 'åˆ›å»ºä¸€ä¸ªåˆ†æ”¯å¹¶åˆå¹¶',
                'time_limit': 10,  # åˆ†é’Ÿ
                'points': 20
            },
            {
                'task': 'ä¼˜åŒ–ä¸€ä¸ªæ…¢æŸ¥è¯¢',
                'time_limit': 15,
                'points': 30
            }
        ]
        return tasks

    def assess_project(self):
        """é¡¹ç›®ç»éªŒè¯„ä¼°"""
        projects = [
            {
                'name': 'AI Agent å®éªŒå¹³å°',
                'requirements': [
                    'æ”¯æŒåˆ†æ”¯åˆ›å»º',
                    'å‘é‡æœç´¢åŠŸèƒ½',
                    'å®éªŒç»“æœå¯¹æ¯”'
                ],
                'points': 50
            }
        ]
        return projects
```

### 45. PostgreSQL å…¨é¢åŸ¹è®­

#### 45.1 SQL åŸºç¡€åŸ¹è®­

**SQL æ•°æ®ç±»å‹**:

```sql
-- æ•°å€¼ç±»å‹
CREATE TABLE numeric_types (
    id SERIAL PRIMARY KEY,                    -- è‡ªå¢æ•´æ•°
    small_int SMALLINT,                       -- -32768 åˆ° 32767
    integer_col INTEGER,                      -- -2147483648 åˆ° 2147483647
    big_int BIGINT,                           -- å¤§æ•´æ•°
    decimal_col DECIMAL(10, 2),               -- ç²¾ç¡®æ•°å€¼
    numeric_col NUMERIC(10, 2),               -- ç²¾ç¡®æ•°å€¼ï¼ˆåŒ DECIMALï¼‰
    real_col REAL,                            -- å•ç²¾åº¦æµ®ç‚¹æ•°
    double_col DOUBLE PRECISION,              -- åŒç²¾åº¦æµ®ç‚¹æ•°
    money_col MONEY                           -- è´§å¸ç±»å‹
);

-- å­—ç¬¦ç±»å‹
CREATE TABLE character_types (
    id SERIAL PRIMARY KEY,
    varchar_col VARCHAR(255),                 -- å¯å˜é•¿åº¦å­—ç¬¦ä¸²
    char_col CHAR(10),                        -- å›ºå®šé•¿åº¦å­—ç¬¦ä¸²
    text_col TEXT,                            -- æ— é™é•¿åº¦æ–‡æœ¬
    name_col NAME                             -- æ ‡è¯†ç¬¦åç§°
);

-- æ—¥æœŸæ—¶é—´ç±»å‹
CREATE TABLE datetime_types (
    id SERIAL PRIMARY KEY,
    date_col DATE,                            -- æ—¥æœŸ
    time_col TIME,                            -- æ—¶é—´
    timestamp_col TIMESTAMP,                  -- æ—¶é—´æˆ³
    timestamptz_col TIMESTAMPTZ,              -- å¸¦æ—¶åŒºçš„æ—¶é—´æˆ³
    interval_col INTERVAL                     -- æ—¶é—´é—´éš”
);

-- å¸ƒå°”ç±»å‹
CREATE TABLE boolean_types (
    id SERIAL PRIMARY KEY,
    is_active BOOLEAN,                        -- TRUE/FALSE/NULL
    status BOOLEAN DEFAULT TRUE
);

-- JSON ç±»å‹
CREATE TABLE json_types (
    id SERIAL PRIMARY KEY,
    json_col JSON,                            -- JSON æ•°æ®
    jsonb_col JSONB                           -- äºŒè¿›åˆ¶ JSONï¼ˆæ¨èï¼‰
);

-- æ•°ç»„ç±»å‹
CREATE TABLE array_types (
    id SERIAL PRIMARY KEY,
    tags TEXT[],                              -- æ–‡æœ¬æ•°ç»„
    numbers INTEGER[],                        -- æ•´æ•°æ•°ç»„
    matrix INTEGER[][]                        -- å¤šç»´æ•°ç»„
);

-- UUID ç±»å‹
CREATE TABLE uuid_types (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name TEXT
);
```

**DML æ“ä½œï¼ˆæ•°æ®æ“ä½œè¯­è¨€ï¼‰**:

```sql
-- INSERT æ’å…¥æ•°æ®
INSERT INTO users (name, email, age)
VALUES ('John Doe', 'john@example.com', 30);

-- æ‰¹é‡æ’å…¥
INSERT INTO users (name, email, age)
VALUES
    ('Alice', 'alice@example.com', 25),
    ('Bob', 'bob@example.com', 35),
    ('Charlie', 'charlie@example.com', 28);

-- ä»æŸ¥è¯¢æ’å…¥
INSERT INTO users_backup (name, email, age)
SELECT name, email, age FROM users WHERE age > 25;

-- UPDATE æ›´æ–°æ•°æ®
UPDATE users
SET age = 31, email = 'john.new@example.com'
WHERE id = 1;

-- ä½¿ç”¨å­æŸ¥è¯¢æ›´æ–°
UPDATE orders
SET total_amount = (
    SELECT SUM(amount)
    FROM order_items
    WHERE order_items.order_id = orders.id
)
WHERE id = 1;

-- DELETE åˆ é™¤æ•°æ®
DELETE FROM users WHERE id = 1;

-- åˆ é™¤æ‰€æœ‰æ•°æ®ï¼ˆä¿ç•™è¡¨ç»“æ„ï¼‰
TRUNCATE TABLE users;

-- TRUNCATE æ›´å¿«ï¼Œä½†æ— æ³•å›æ»š
TRUNCATE TABLE users CASCADE;  -- çº§è”åˆ é™¤ç›¸å…³è¡¨æ•°æ®
```

**DQL æ“ä½œï¼ˆæ•°æ®æŸ¥è¯¢è¯­è¨€ï¼‰**:

```sql
-- SELECT åŸºç¡€æŸ¥è¯¢
SELECT * FROM users;

-- é€‰æ‹©ç‰¹å®šåˆ—
SELECT name, email FROM users;

-- ä½¿ç”¨åˆ«å
SELECT
    name AS user_name,
    email AS user_email,
    age AS user_age
FROM users;

-- WHERE æ¡ä»¶è¿‡æ»¤
SELECT * FROM users
WHERE age > 25 AND email LIKE '%@example.com';

-- ä½¿ç”¨ IN
SELECT * FROM users
WHERE id IN (1, 2, 3, 4, 5);

-- ä½¿ç”¨ BETWEEN
SELECT * FROM users
WHERE age BETWEEN 25 AND 35;

-- ä½¿ç”¨ IS NULL
SELECT * FROM users
WHERE email IS NULL;

-- ORDER BY æ’åº
SELECT * FROM users
ORDER BY age DESC, name ASC;

-- LIMIT å’Œ OFFSET
SELECT * FROM users
ORDER BY id
LIMIT 10 OFFSET 20;  -- è·³è¿‡å‰20æ¡ï¼Œå–10æ¡

-- DISTINCT å»é‡
SELECT DISTINCT age FROM users;

-- GROUP BY åˆ†ç»„
SELECT
    age,
    COUNT(*) AS user_count,
    AVG(age) AS avg_age
FROM users
GROUP BY age
HAVING COUNT(*) > 5;  -- HAVING è¿‡æ»¤åˆ†ç»„ç»“æœ

-- JOIN è¿æ¥
-- INNER JOIN
SELECT u.name, o.order_date, o.total_amount
FROM users u
INNER JOIN orders o ON u.id = o.user_id;

-- LEFT JOIN
SELECT u.name, o.order_date
FROM users u
LEFT JOIN orders o ON u.id = o.user_id;

-- RIGHT JOIN
SELECT u.name, o.order_date
FROM users u
RIGHT JOIN orders o ON u.id = o.user_id;

-- FULL OUTER JOIN
SELECT u.name, o.order_date
FROM users u
FULL OUTER JOIN orders o ON u.id = o.user_id;

-- CROSS JOINï¼ˆç¬›å¡å°”ç§¯ï¼‰
SELECT u.name, p.product_name
FROM users u
CROSS JOIN products p;

-- å­æŸ¥è¯¢
-- æ ‡é‡å­æŸ¥è¯¢
SELECT
    name,
    (SELECT COUNT(*) FROM orders WHERE orders.user_id = users.id) AS order_count
FROM users;

-- EXISTS å­æŸ¥è¯¢
SELECT * FROM users u
WHERE EXISTS (
    SELECT 1 FROM orders o
    WHERE o.user_id = u.id AND o.total_amount > 1000
);

-- UNION åˆå¹¶æŸ¥è¯¢ç»“æœ
SELECT name FROM users
UNION
SELECT name FROM customers;

-- UNION ALLï¼ˆä¿ç•™é‡å¤ï¼‰
SELECT name FROM users
UNION ALL
SELECT name FROM customers;
```

#### 45.2 äº‹åŠ¡ç®¡ç†

**äº‹åŠ¡åŸºç¡€**:

```sql
-- äº‹åŠ¡çš„åŸºæœ¬æ¦‚å¿µ
-- ACID ç‰¹æ€§ï¼š
-- A - Atomicityï¼ˆåŸå­æ€§ï¼‰ï¼šäº‹åŠ¡è¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥
-- C - Consistencyï¼ˆä¸€è‡´æ€§ï¼‰ï¼šäº‹åŠ¡å‰åæ•°æ®åº“ä¿æŒä¸€è‡´çŠ¶æ€
-- I - Isolationï¼ˆéš”ç¦»æ€§ï¼‰ï¼šå¹¶å‘äº‹åŠ¡ä¹‹é—´ç›¸äº’éš”ç¦»
-- D - Durabilityï¼ˆæŒä¹…æ€§ï¼‰ï¼šæäº¤çš„äº‹åŠ¡æ°¸ä¹…ä¿å­˜

-- å¼€å§‹äº‹åŠ¡
BEGIN;

-- æˆ–è€…
BEGIN TRANSACTION;

-- æäº¤äº‹åŠ¡
COMMIT;

-- å›æ»šäº‹åŠ¡
ROLLBACK;

-- ä¿å­˜ç‚¹ï¼ˆSavepointï¼‰
BEGIN;
INSERT INTO users (name, email) VALUES ('User1', 'user1@example.com');
SAVEPOINT sp1;
INSERT INTO users (name, email) VALUES ('User2', 'user2@example.com');
ROLLBACK TO SAVEPOINT sp1;  -- å›æ»šåˆ°ä¿å­˜ç‚¹
COMMIT;  -- User1 ä¼šè¢«æäº¤ï¼ŒUser2 ä¼šè¢«å›æ»š
```

**äº‹åŠ¡éš”ç¦»çº§åˆ«**:

```sql
-- PostgreSQL æ”¯æŒçš„äº‹åŠ¡éš”ç¦»çº§åˆ«
-- 1. READ UNCOMMITTEDï¼ˆæœªæäº¤è¯»ï¼‰- PostgreSQL ä¸æ”¯æŒï¼Œå®é™…æ˜¯ READ COMMITTED
-- 2. READ COMMITTEDï¼ˆæäº¤è¯»ï¼‰- é»˜è®¤çº§åˆ«
-- 3. REPEATABLE READï¼ˆå¯é‡å¤è¯»ï¼‰
-- 4. SERIALIZABLEï¼ˆä¸²è¡ŒåŒ–ï¼‰

-- è®¾ç½®äº‹åŠ¡éš”ç¦»çº§åˆ«
BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED;
SELECT * FROM users WHERE id = 1;
COMMIT;

BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
SELECT * FROM users WHERE id = 1;
COMMIT;

BEGIN TRANSACTION ISOLATION LEVEL SERIALIZABLE;
SELECT * FROM users WHERE id = 1;
COMMIT;

-- æŸ¥çœ‹å½“å‰éš”ç¦»çº§åˆ«
SHOW transaction_isolation;
```

**å¹¶å‘æ§åˆ¶**:

```sql
-- æ‚²è§‚é”ï¼ˆPessimistic Lockingï¼‰
-- SELECT FOR UPDATEï¼ˆè¡Œçº§æ’ä»–é”ï¼‰
BEGIN;
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
COMMIT;

-- SELECT FOR SHAREï¼ˆè¡Œçº§å…±äº«é”ï¼‰
BEGIN;
SELECT * FROM accounts WHERE id = 1 FOR SHARE;
-- å…¶ä»–äº‹åŠ¡å¯ä»¥è¯»å–ï¼Œä½†ä¸èƒ½ä¿®æ”¹
COMMIT;

-- SELECT FOR UPDATE NOWAITï¼ˆä¸ç­‰å¾…é”ï¼‰
BEGIN;
SELECT * FROM accounts WHERE id = 1 FOR UPDATE NOWAIT;
-- å¦‚æœé”è¢«å ç”¨ï¼Œç«‹å³è¿”å›é”™è¯¯
COMMIT;

-- ä¹è§‚é”ï¼ˆOptimistic Lockingï¼‰
-- ä½¿ç”¨ç‰ˆæœ¬å·
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name TEXT,
    price DECIMAL,
    version INTEGER DEFAULT 1
);

-- æ›´æ–°æ—¶æ£€æŸ¥ç‰ˆæœ¬
UPDATE products
SET price = 100, version = version + 1
WHERE id = 1 AND version = 1;
-- å¦‚æœ version ä¸åŒ¹é…ï¼Œæ›´æ–°å¤±è´¥ï¼ˆè¯´æ˜æ•°æ®å·²è¢«ä¿®æ”¹ï¼‰
```

**æ­»é”å¤„ç†**:

```sql
-- æ­»é”ç¤ºä¾‹
-- äº‹åŠ¡ 1
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
COMMIT;

-- äº‹åŠ¡ 2ï¼ˆåŒæ—¶æ‰§è¡Œï¼‰
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 2;
UPDATE accounts SET balance = balance + 100 WHERE id = 1;
COMMIT;

-- PostgreSQL ä¼šè‡ªåŠ¨æ£€æµ‹æ­»é”å¹¶å›æ»šå…¶ä¸­ä¸€ä¸ªäº‹åŠ¡

-- æŸ¥çœ‹é”ä¿¡æ¯
SELECT
    locktype,
    relation::regclass,
    mode,
    granted
FROM pg_locks
WHERE relation = 'accounts'::regclass;

-- æŸ¥çœ‹ç­‰å¾…é”çš„æŸ¥è¯¢
SELECT
    blocked_locks.pid AS blocked_pid,
    blocking_locks.pid AS blocking_pid,
    blocked_activity.usename AS blocked_user,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS blocking_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

#### 45.3 ç´¢å¼•ä¸æŸ¥è¯¢ä¼˜åŒ–

**ç´¢å¼•ç±»å‹**:

```sql
-- B-tree ç´¢å¼•ï¼ˆé»˜è®¤ï¼Œæœ€å¸¸ç”¨ï¼‰
CREATE INDEX idx_users_email ON users(email);

-- å”¯ä¸€ç´¢å¼•
CREATE UNIQUE INDEX idx_users_email_unique ON users(email);

-- å¤åˆç´¢å¼•
CREATE INDEX idx_users_name_age ON users(name, age);

-- éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æ»¡è¶³æ¡ä»¶çš„è¡Œï¼‰
CREATE INDEX idx_active_users ON users(email) WHERE is_active = TRUE;

-- è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX idx_users_lower_email ON users(LOWER(email));

-- Hash ç´¢å¼•ï¼ˆåªæ”¯æŒç­‰å€¼æŸ¥è¯¢ï¼‰
CREATE INDEX idx_users_id_hash ON users USING HASH(id);

-- GiST ç´¢å¼•ï¼ˆé€šç”¨æœç´¢æ ‘ï¼Œç”¨äºå¤æ‚æ•°æ®ç±»å‹ï¼‰
CREATE INDEX idx_documents_content_gist ON documents USING GIST(content);

-- GIN ç´¢å¼•ï¼ˆå€’æ’ç´¢å¼•ï¼Œç”¨äºå…¨æ–‡æœç´¢ã€æ•°ç»„ã€JSONBï¼‰
CREATE INDEX idx_documents_content_gin ON documents USING GIN(to_tsvector('english', content));
CREATE INDEX idx_users_tags_gin ON users USING GIN(tags);
CREATE INDEX idx_products_metadata_gin ON products USING GIN(metadata);

-- BRIN ç´¢å¼•ï¼ˆå—èŒƒå›´ç´¢å¼•ï¼Œç”¨äºå¤§è¡¨ï¼‰
CREATE INDEX idx_orders_date_brin ON orders USING BRIN(order_date);

-- SP-GiST ç´¢å¼•ï¼ˆç©ºé—´åˆ†åŒº GiSTï¼‰
CREATE INDEX idx_locations_point_spgist ON locations USING SPGIST(point);
```

**æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§**:

```sql
-- 1. ä½¿ç”¨ EXPLAIN åˆ†ææŸ¥è¯¢è®¡åˆ’
EXPLAIN SELECT * FROM users WHERE email = 'john@example.com';

-- EXPLAIN ANALYZEï¼ˆå®é™…æ‰§è¡Œå¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼‰
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'john@example.com';

-- EXPLAIN VERBOSEï¼ˆæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼‰
EXPLAIN VERBOSE SELECT * FROM users WHERE email = 'john@example.com';

-- EXPLAIN BUFFERSï¼ˆæ˜¾ç¤ºç¼“å†²åŒºä½¿ç”¨æƒ…å†µï¼‰
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM users WHERE email = 'john@example.com';

-- 2. é¿å… SELECT *
SELECT id, name, email FROM users;  -- åªé€‰æ‹©éœ€è¦çš„åˆ—

-- 3. ä½¿ç”¨ LIMIT
SELECT * FROM users ORDER BY id LIMIT 10;  -- é™åˆ¶ç»“æœé›†å¤§å°

-- 4. ä½¿ç”¨ç´¢å¼•åˆ—è¿›è¡Œè¿‡æ»¤
SELECT * FROM users WHERE email = 'john@example.com';  -- email æœ‰ç´¢å¼•
-- è€Œä¸æ˜¯
SELECT * FROM users WHERE UPPER(email) = 'JOHN@EXAMPLE.COM';  -- å‡½æ•°è°ƒç”¨æ— æ³•ä½¿ç”¨ç´¢å¼•

-- 5. é¿å…åœ¨ WHERE å­å¥ä¸­ä½¿ç”¨å‡½æ•°
-- ä¸å¥½
SELECT * FROM users WHERE EXTRACT(YEAR FROM created_at) = 2024;
-- å¥½
SELECT * FROM users WHERE created_at >= '2024-01-01' AND created_at < '2025-01-01';

-- 6. ä½¿ç”¨ EXISTS è€Œä¸æ˜¯ INï¼ˆå¯¹äºå¤§å­æŸ¥è¯¢ï¼‰
-- ä¸å¥½
SELECT * FROM users WHERE id IN (SELECT user_id FROM orders);
-- å¥½
SELECT * FROM users WHERE EXISTS (SELECT 1 FROM orders WHERE orders.user_id = users.id);

-- 7. ä½¿ç”¨ JOIN è€Œä¸æ˜¯å­æŸ¥è¯¢
-- ä¸å¥½
SELECT name, (SELECT COUNT(*) FROM orders WHERE orders.user_id = users.id) FROM users;
-- å¥½
SELECT u.name, COUNT(o.id)
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name;

-- 8. ä½¿ç”¨ UNION ALL è€Œä¸æ˜¯ UNIONï¼ˆå¦‚æœä¸éœ€è¦å»é‡ï¼‰
-- UNION ä¼šå»é‡ï¼Œæ€§èƒ½è¾ƒæ…¢
SELECT name FROM users
UNION ALL
SELECT name FROM customers;

-- 9. ä½¿ç”¨æ‰¹é‡æ“ä½œ
-- ä¸å¥½ï¼ˆN+1 æŸ¥è¯¢ï¼‰
FOR EACH user IN users:
    INSERT INTO logs (user_id, action) VALUES (user.id, 'login');
-- å¥½ï¼ˆæ‰¹é‡æ’å…¥ï¼‰
INSERT INTO logs (user_id, action)
SELECT id, 'login' FROM users;
```

#### 45.4 æ•°æ®ç±»å‹æ·±å…¥

**JSON/JSONB æ“ä½œ**:

```sql
-- JSONB æ“ä½œç¬¦
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name TEXT,
    metadata JSONB
);

-- æ’å…¥ JSON æ•°æ®
INSERT INTO products (name, metadata) VALUES (
    'Product 1',
    '{"price": 100, "category": "electronics", "tags": ["new", "popular"]}'::jsonb
);

-- è®¿é—® JSON å­—æ®µ
SELECT metadata->>'price' AS price FROM products;
SELECT metadata->'tags' AS tags FROM products;
SELECT metadata->'tags'->0 AS first_tag FROM products;

-- JSONB æŸ¥è¯¢
SELECT * FROM products WHERE metadata @> '{"category": "electronics"}'::jsonb;
SELECT * FROM products WHERE metadata ? 'price';
SELECT * FROM products WHERE metadata ?| array['price', 'category'];
SELECT * FROM products WHERE metadata ?& array['price', 'category'];

-- JSONB æ›´æ–°
UPDATE products
SET metadata = metadata || '{"discount": 10}'::jsonb
WHERE id = 1;

-- JSONB å‡½æ•°
SELECT jsonb_pretty(metadata) FROM products;
SELECT jsonb_object_keys(metadata) FROM products;
SELECT jsonb_array_elements(metadata->'tags') FROM products;
```

**æ•°ç»„æ“ä½œ**:

```sql
-- æ•°ç»„æ“ä½œç¬¦
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name TEXT,
    tags TEXT[]
);

-- æ’å…¥æ•°ç»„
INSERT INTO users (name, tags) VALUES ('John', ARRAY['admin', 'developer']);

-- æ•°ç»„æŸ¥è¯¢
SELECT * FROM users WHERE 'admin' = ANY(tags);
SELECT * FROM users WHERE tags @> ARRAY['admin'];
SELECT * FROM users WHERE tags && ARRAY['admin', 'user'];

-- æ•°ç»„å‡½æ•°
SELECT array_length(tags, 1) FROM users;
SELECT array_append(tags, 'new_tag') FROM users;
SELECT array_remove(tags, 'old_tag') FROM users;
SELECT unnest(tags) FROM users;  -- å±•å¼€æ•°ç»„ä¸ºè¡Œ
```

#### 45.5 å‡½æ•°ä¸å­˜å‚¨è¿‡ç¨‹

**ç”¨æˆ·å®šä¹‰å‡½æ•°**:

```sql
-- åˆ›å»ºå‡½æ•°
-- è®¡ç®—æ€»ä»·å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION calculate_total(p_price DECIMAL, p_quantity INTEGER)
RETURNS DECIMAL
LANGUAGE plpgsql
AS $$
DECLARE
    v_total DECIMAL;
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_price IS NULL THEN
        RAISE EXCEPTION 'ä»·æ ¼ä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_quantity IS NULL THEN
        RAISE EXCEPTION 'æ•°é‡ä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_price < 0 THEN
        RAISE EXCEPTION 'ä»·æ ¼ä¸èƒ½ä¸ºè´Ÿæ•°: %', p_price;
    END IF;

    IF p_quantity < 0 THEN
        RAISE EXCEPTION 'æ•°é‡ä¸èƒ½ä¸ºè´Ÿæ•°: %', p_quantity;
    END IF;

    -- è®¡ç®—æ€»ä»·
    BEGIN
        v_total := p_price * p_quantity;

        -- æ£€æŸ¥æ•°å€¼æº¢å‡º
        IF v_total > 999999999999.99 THEN
            RAISE EXCEPTION 'è®¡ç®—ç»“æœè¶…å‡ºèŒƒå›´';
        END IF;

        RETURN v_total;
    EXCEPTION
        WHEN numeric_value_out_of_range THEN
            RAISE EXCEPTION 'è®¡ç®—ç»“æœæ•°å€¼æº¢å‡º';
        WHEN OTHERS THEN
            RAISE EXCEPTION 'è®¡ç®—æ€»ä»·å¤±è´¥: %', SQLERRM;
    END;
END;
$$;

-- ä½¿ç”¨å‡½æ•°
SELECT calculate_total(100, 5);

-- é—®å€™å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION greet(p_name TEXT, p_greeting TEXT DEFAULT 'Hello')
RETURNS TEXT
LANGUAGE plpgsql
AS $$
DECLARE
    v_result TEXT;
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_name IS NULL OR TRIM(p_name) = '' THEN
        RAISE EXCEPTION 'å§“åä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_greeting IS NULL THEN
        p_greeting := 'Hello';
    END IF;

    -- æ„å»ºé—®å€™è¯­
    BEGIN
        v_result := TRIM(p_greeting) || ', ' || TRIM(p_name) || '!';

        -- æ£€æŸ¥ç»“æœé•¿åº¦
        IF LENGTH(v_result) > 500 THEN
            RAISE WARNING 'é—®å€™è¯­ç»“æœè¿‡é•¿ï¼Œå·²æˆªæ–­';
            v_result := LEFT(v_result, 500);
        END IF;

        RETURN v_result;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'æ„å»ºé—®å€™è¯­å¤±è´¥: %', SQLERRM;
    END;
END;
$$;

SELECT greet('John');  -- Hello, John!
SELECT greet('John', 'Hi');  -- Hi, John!

-- æŒ‰å¹´é¾„æŸ¥è¯¢ç”¨æˆ·å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION get_users_by_age(p_min_age INTEGER, p_max_age INTEGER)
RETURNS TABLE(id INTEGER, name TEXT, age INTEGER)
LANGUAGE plpgsql
AS $$
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_min_age IS NULL THEN
        RAISE EXCEPTION 'æœ€å°å¹´é¾„ä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_max_age IS NULL THEN
        RAISE EXCEPTION 'æœ€å¤§å¹´é¾„ä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_min_age < 0 THEN
        RAISE EXCEPTION 'æœ€å°å¹´é¾„ä¸èƒ½ä¸ºè´Ÿæ•°: %', p_min_age;
    END IF;

    IF p_max_age < 0 THEN
        RAISE EXCEPTION 'æœ€å¤§å¹´é¾„ä¸èƒ½ä¸ºè´Ÿæ•°: %', p_max_age;
    END IF;

    IF p_min_age > p_max_age THEN
        RAISE EXCEPTION 'æœ€å°å¹´é¾„ä¸èƒ½å¤§äºæœ€å¤§å¹´é¾„: % > %', p_min_age, p_max_age;
    END IF;

    IF p_max_age > 200 THEN
        RAISE EXCEPTION 'æœ€å¤§å¹´é¾„è¶…å‡ºåˆç†èŒƒå›´: %', p_max_age;
    END IF;

    -- æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'users') THEN
        RAISE EXCEPTION 'usersè¡¨ä¸å­˜åœ¨';
    END IF;

    -- æŸ¥è¯¢ç”¨æˆ·
    BEGIN
        RETURN QUERY
        SELECT u.id, u.name, u.age
        FROM users u
        WHERE u.age BETWEEN p_min_age AND p_max_age
          AND u.age IS NOT NULL
        ORDER BY u.age ASC, u.id ASC;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'æŸ¥è¯¢ç”¨æˆ·å¤±è´¥: %', SQLERRM;
    END;
END;
$$;

SELECT * FROM get_users_by_age(25, 35);

-- è®¡ç®—é˜¶ä¹˜å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION factorial(p_n INTEGER)
RETURNS BIGINT
LANGUAGE plpgsql
AS $$
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_n IS NULL THEN
        RAISE EXCEPTION 'å‚æ•°ä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_n < 0 THEN
        RAISE EXCEPTION 'é˜¶ä¹˜å‚æ•°ä¸èƒ½ä¸ºè´Ÿæ•°: %', p_n;
    END IF;

    -- é˜²æ­¢æ ˆæº¢å‡ºï¼ˆé™åˆ¶æœ€å¤§è¾“å…¥å€¼ï¼‰
    IF p_n > 20 THEN
        RAISE EXCEPTION 'é˜¶ä¹˜å‚æ•°è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´æ ˆæº¢å‡º: % (æœ€å¤§æ”¯æŒ20)', p_n;
    END IF;

    -- åŸºç¡€æƒ…å†µ
    IF p_n <= 1 THEN
        RETURN 1;
    ELSE
        -- é€’å½’è®¡ç®—ï¼ˆä½¿ç”¨BIGINTé˜²æ­¢æ•´æ•°æº¢å‡ºï¼‰
        BEGIN
            RETURN p_n * factorial(p_n - 1);
        EXCEPTION
            WHEN numeric_value_out_of_range THEN
                RAISE EXCEPTION 'é˜¶ä¹˜è®¡ç®—ç»“æœæº¢å‡º: %!', p_n;
            WHEN OTHERS THEN
                RAISE EXCEPTION 'è®¡ç®—é˜¶ä¹˜å¤±è´¥: %', SQLERRM;
        END;
    END IF;
END;
$$;
```

**å­˜å‚¨è¿‡ç¨‹**:

```sql
-- è½¬è´¦å­˜å‚¨è¿‡ç¨‹ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE PROCEDURE transfer_money(
    p_from_account INTEGER,
    p_to_account INTEGER,
    p_amount DECIMAL
)
LANGUAGE plpgsql
AS $$
DECLARE
    v_from_balance DECIMAL;
    v_to_balance DECIMAL;
    v_version INTEGER;
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_from_account IS NULL THEN
        RAISE EXCEPTION 'è½¬å‡ºè´¦æˆ·IDä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_to_account IS NULL THEN
        RAISE EXCEPTION 'è½¬å…¥è´¦æˆ·IDä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_amount IS NULL OR p_amount <= 0 THEN
        RAISE EXCEPTION 'è½¬è´¦é‡‘é¢å¿…é¡»å¤§äº0: %', p_amount;
    END IF;

    IF p_from_account = p_to_account THEN
        RAISE EXCEPTION 'è½¬å‡ºè´¦æˆ·å’Œè½¬å…¥è´¦æˆ·ä¸èƒ½ç›¸åŒ';
    END IF;

    -- æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'accounts') THEN
        RAISE EXCEPTION 'accountsè¡¨ä¸å­˜åœ¨';
    END IF;

    -- é”å®šå¹¶æ£€æŸ¥è½¬å‡ºè´¦æˆ·
    BEGIN
        SELECT balance, version INTO v_from_balance, v_version
        FROM accounts
        WHERE id = p_from_account
        FOR UPDATE;

        IF NOT FOUND THEN
            RAISE EXCEPTION 'è½¬å‡ºè´¦æˆ·ä¸å­˜åœ¨: %', p_from_account;
        END IF;

        IF v_from_balance IS NULL THEN
            RAISE EXCEPTION 'è½¬å‡ºè´¦æˆ·ä½™é¢ä¸ºç©º';
        END IF;

        IF v_from_balance < p_amount THEN
            RAISE EXCEPTION 'ä½™é¢ä¸è¶³: å½“å‰ä½™é¢=%, éœ€è¦=%', v_from_balance, p_amount;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'æ£€æŸ¥è½¬å‡ºè´¦æˆ·å¤±è´¥: %', SQLERRM;
    END;

    -- æ£€æŸ¥è½¬å…¥è´¦æˆ·
    BEGIN
        SELECT balance INTO v_to_balance
        FROM accounts
        WHERE id = p_to_account
        FOR UPDATE;

        IF NOT FOUND THEN
            RAISE EXCEPTION 'è½¬å…¥è´¦æˆ·ä¸å­˜åœ¨: %', p_to_account;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'æ£€æŸ¥è½¬å…¥è´¦æˆ·å¤±è´¥: %', SQLERRM;
    END;

    -- æ‰§è¡Œè½¬è´¦
    BEGIN
        -- æ‰£æ¬¾
        UPDATE accounts
        SET balance = balance - p_amount,
            version = version + 1
        WHERE id = p_from_account
          AND version = v_version;  -- ä¹è§‚é”

        IF NOT FOUND THEN
            RAISE EXCEPTION 'è½¬è´¦å¤±è´¥ï¼šè´¦æˆ·ç‰ˆæœ¬ä¸åŒ¹é…ï¼Œå¯èƒ½è¢«å¹¶å‘ä¿®æ”¹';
        END IF;

        -- å…¥è´¦
        UPDATE accounts
        SET balance = COALESCE(balance, 0) + p_amount,
            version = COALESCE(version, 0) + 1
        WHERE id = p_to_account;

        IF NOT FOUND THEN
            RAISE EXCEPTION 'è½¬è´¦å¤±è´¥ï¼šè½¬å…¥è´¦æˆ·æ›´æ–°å¤±è´¥';
        END IF;

        -- éªŒè¯ä½™é¢
        SELECT balance INTO v_from_balance
        FROM accounts
        WHERE id = p_from_account;

        IF v_from_balance < 0 THEN
            RAISE EXCEPTION 'è½¬è´¦åä½™é¢å¼‚å¸¸: %', v_from_balance;
        END IF;
    EXCEPTION
        WHEN numeric_value_out_of_range THEN
            RAISE EXCEPTION 'è½¬è´¦é‡‘é¢è®¡ç®—æº¢å‡º';
        WHEN OTHERS THEN
            RAISE EXCEPTION 'æ‰§è¡Œè½¬è´¦å¤±è´¥: %', SQLERRM;
    END;
EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'transfer_moneyæ‰§è¡Œå¤±è´¥: %', SQLERRM;
END;
$$;

-- è°ƒç”¨å­˜å‚¨è¿‡ç¨‹
CALL transfer_money(1, 2, 100);
```

**è§¦å‘å™¨**:

```sql
-- åˆ›å»ºè§¦å‘å™¨å‡½æ•°
CREATE OR REPLACE FUNCTION update_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºè§¦å‘å™¨
CREATE TRIGGER update_users_updated_at
BEFORE UPDATE ON users
FOR EACH ROW
EXECUTE FUNCTION update_updated_at();

-- å®¡è®¡æ—¥å¿—è§¦å‘å™¨å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION audit_log()
RETURNS TRIGGER
LANGUAGE plpgsql
AS $$
DECLARE
    v_old_data JSONB;
    v_new_data JSONB;
BEGIN
    -- æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'audit_logs') THEN
        RAISE WARNING 'audit_logsè¡¨ä¸å­˜åœ¨ï¼Œæ— æ³•è®°å½•å®¡è®¡æ—¥å¿—';
        RETURN COALESCE(NEW, OLD);
    END IF;

    -- è½¬æ¢OLDè®°å½•ä¸ºJSONB
    BEGIN
        IF OLD IS NOT NULL THEN
            v_old_data := row_to_json(OLD)::JSONB;
        ELSE
            v_old_data := NULL;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'è½¬æ¢OLDè®°å½•ä¸ºJSONBå¤±è´¥: %', SQLERRM;
            v_old_data := NULL;
    END;

    -- è½¬æ¢NEWè®°å½•ä¸ºJSONB
    BEGIN
        IF NEW IS NOT NULL THEN
            v_new_data := row_to_json(NEW)::JSONB;
        ELSE
            v_new_data := NULL;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'è½¬æ¢NEWè®°å½•ä¸ºJSONBå¤±è´¥: %', SQLERRM;
            v_new_data := NULL;
    END;

    -- æ’å…¥å®¡è®¡æ—¥å¿—
    BEGIN
        INSERT INTO audit_logs (table_name, operation, old_data, new_data, changed_at)
        VALUES (
            COALESCE(TG_TABLE_NAME, 'unknown'),
            COALESCE(TG_OP, 'unknown'),
            v_old_data,
            v_new_data,
            NOW()
        );
    EXCEPTION
        WHEN unique_violation THEN
            RAISE WARNING 'å®¡è®¡æ—¥å¿—è®°å½•å·²å­˜åœ¨';
        WHEN foreign_key_violation THEN
            RAISE WARNING 'è¿åå¤–é”®çº¦æŸï¼Œæ— æ³•è®°å½•å®¡è®¡æ—¥å¿—';
        WHEN OTHERS THEN
            RAISE WARNING 'è®°å½•å®¡è®¡æ—¥å¿—å¤±è´¥: %', SQLERRM;
    END;

    RETURN COALESCE(NEW, OLD);
EXCEPTION
    WHEN OTHERS THEN
        RAISE WARNING 'audit_logè§¦å‘å™¨å‡½æ•°æ‰§è¡Œå¤±è´¥: %', SQLERRM;
        RETURN COALESCE(NEW, OLD);  -- å³ä½¿å‡ºé”™ä¹Ÿè¿”å›è®°å½•ï¼Œé¿å…å½±å“ä¸»æ“ä½œ
END;
$$;

CREATE TRIGGER audit_users
AFTER INSERT OR UPDATE OR DELETE ON users
FOR EACH ROW
EXECUTE FUNCTION audit_log();
```

#### 45.6 è§†å›¾ä¸ç‰©åŒ–è§†å›¾

**è§†å›¾ï¼ˆViewsï¼‰**:

```sql
-- åˆ›å»ºè§†å›¾
CREATE VIEW active_users AS
SELECT id, name, email
FROM users
WHERE is_active = TRUE;

-- ä½¿ç”¨è§†å›¾
SELECT * FROM active_users;

-- å¯æ›´æ–°è§†å›¾
CREATE VIEW user_orders AS
SELECT u.id AS user_id, u.name, o.id AS order_id, o.total_amount
FROM users u
JOIN orders o ON u.id = o.user_id;

-- ç‰©åŒ–è§†å›¾ï¼ˆMaterialized Viewsï¼‰
CREATE MATERIALIZED VIEW user_order_summary AS
SELECT
    u.id AS user_id,
    u.name,
    COUNT(o.id) AS order_count,
    SUM(o.total_amount) AS total_spent,
    AVG(o.total_amount) AS avg_order_amount
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name;

-- åˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW user_order_summary;

-- å¹¶å‘åˆ·æ–°ï¼ˆPostgreSQL 9.4+ï¼‰
REFRESH MATERIALIZED VIEW CONCURRENTLY user_order_summary;

-- åœ¨ç‰©åŒ–è§†å›¾ä¸Šåˆ›å»ºç´¢å¼•
CREATE INDEX idx_user_order_summary_user_id ON user_order_summary(user_id);
```

#### 45.7 æƒé™ç®¡ç†

**ç”¨æˆ·å’Œè§’è‰²**:

```sql
-- åˆ›å»ºè§’è‰²
CREATE ROLE app_user WITH LOGIN PASSWORD 'password';

-- åˆ›å»ºåªè¯»è§’è‰²
CREATE ROLE readonly_user WITH LOGIN PASSWORD 'password';

-- æˆäºˆæƒé™
GRANT SELECT ON users TO readonly_user;
GRANT SELECT ON orders TO readonly_user;

-- æˆäºˆæ‰€æœ‰è¡¨çš„æƒé™
GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly_user;

-- æˆäºˆæœªæ¥è¡¨çš„æƒé™
ALTER DEFAULT PRIVILEGES IN SCHEMA public
GRANT SELECT ON TABLES TO readonly_user;

-- æ’¤é”€æƒé™
REVOKE SELECT ON users FROM readonly_user;

-- è§’è‰²ç»§æ‰¿
CREATE ROLE admin_user;
GRANT app_user TO admin_user;  -- admin_user ç»§æ‰¿ app_user çš„æƒé™

-- æŸ¥çœ‹æƒé™
SELECT
    grantee,
    table_schema,
    table_name,
    privilege_type
FROM information_schema.table_privileges
WHERE grantee = 'readonly_user';
```

**è¡Œçº§å®‰å…¨ï¼ˆRLSï¼‰**:

```sql
-- å¯ç”¨è¡Œçº§å®‰å…¨
ALTER TABLE orders ENABLE ROW LEVEL SECURITY;

-- åˆ›å»ºç­–ç•¥
CREATE POLICY user_orders_policy ON orders
FOR ALL
TO app_user
USING (user_id = current_setting('app.user_id')::INTEGER);

-- ä½¿ç”¨ç­–ç•¥
SET app.user_id = 1;
SELECT * FROM orders;  -- åªèƒ½çœ‹åˆ° user_id = 1 çš„è®¢å•
```

#### 45.8 å¤‡ä»½ä¸æ¢å¤

**é€»è¾‘å¤‡ä»½**:

```bash
# pg_dump å¤‡ä»½å•ä¸ªæ•°æ®åº“
pg_dump -h localhost -U postgres -d mydb > backup.sql

# pg_dump å¤‡ä»½æ‰€æœ‰æ•°æ®åº“
pg_dumpall -h localhost -U postgres > all_databases.sql

# å‹ç¼©å¤‡ä»½
pg_dump -h localhost -U postgres -d mydb | gzip > backup.sql.gz

# åªå¤‡ä»½è¡¨ç»“æ„
pg_dump -h localhost -U postgres -d mydb --schema-only > schema.sql

# åªå¤‡ä»½æ•°æ®
pg_dump -h localhost -U postgres -d mydb --data-only > data.sql

# æ¢å¤æ•°æ®åº“
psql -h localhost -U postgres -d mydb < backup.sql
```

**ç‰©ç†å¤‡ä»½**:

```bash
# pg_basebackupï¼ˆéœ€è¦é…ç½®æµå¤åˆ¶ï¼‰
pg_basebackup -h localhost -U postgres -D /backup/postgresql -Ft -z -P

# ä½¿ç”¨ WAL å½’æ¡£è¿›è¡Œè¿ç»­å¤‡ä»½
# åœ¨ postgresql.conf ä¸­é…ç½®ï¼š
# archive_mode = on
# archive_command = 'cp %p /backup/wal/%f'
```

#### 45.9 æ€§èƒ½è°ƒä¼˜

**é…ç½®å‚æ•°è°ƒä¼˜**:

```sql
-- æŸ¥çœ‹å½“å‰é…ç½®
SHOW shared_buffers;
SHOW work_mem;
SHOW maintenance_work_mem;
SHOW effective_cache_size;

-- ä¿®æ”¹é…ç½®ï¼ˆéœ€è¦é‡å¯ï¼‰
-- åœ¨ postgresql.conf ä¸­ï¼š
-- shared_buffers = 256MB          # å…±äº«ç¼“å†²åŒºï¼ˆé€šå¸¸è®¾ä¸ºå†…å­˜çš„ 25%ï¼‰
-- work_mem = 4MB                  # æ¯ä¸ªæ“ä½œçš„å·¥ä½œå†…å­˜
-- maintenance_work_mem = 64MB     # ç»´æŠ¤æ“ä½œçš„å·¥ä½œå†…å­˜
-- effective_cache_size = 1GB      # æ“ä½œç³»ç»Ÿå’Œ PostgreSQL çš„ç¼“å­˜å¤§å°
-- max_connections = 100           # æœ€å¤§è¿æ¥æ•°
```

**æŸ¥è¯¢æ€§èƒ½åˆ†æ**:

```sql
-- å¯ç”¨ pg_stat_statements
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- æŸ¥çœ‹æ…¢æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- é‡ç½®ç»Ÿè®¡ä¿¡æ¯
SELECT pg_stat_statements_reset();

-- æŸ¥çœ‹è¡¨ç»Ÿè®¡ä¿¡æ¯
SELECT
    schemaname,
    tablename,
    n_live_tup,
    n_dead_tup,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze
FROM pg_stat_user_tables;

-- æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan;
```

#### 45.10 PostgreSQL åŸ¹è®­è¯¾ç¨‹å¤§çº²

#### è¯¾ç¨‹ 1: PostgreSQL SQL åŸºç¡€ï¼ˆ16 å°æ—¶ï¼‰

##### æ¨¡å— 1: SQL åŸºç¡€ï¼ˆ4 å°æ—¶ï¼‰

- æ•°æ®ç±»å‹
- DDLï¼ˆCREATE, ALTER, DROPï¼‰
- DMLï¼ˆINSERT, UPDATE, DELETEï¼‰
- DQLï¼ˆSELECT, WHERE, JOINï¼‰

##### æ¨¡å— 2: é«˜çº§æŸ¥è¯¢ï¼ˆ4 å°æ—¶ï¼‰

- å­æŸ¥è¯¢
- çª—å£å‡½æ•°
- CTEï¼ˆå…¬ç”¨è¡¨è¡¨è¾¾å¼ï¼‰
- é€’å½’æŸ¥è¯¢

##### æ¨¡å— 3: äº‹åŠ¡å’Œå¹¶å‘ï¼ˆ4 å°æ—¶ï¼‰

- äº‹åŠ¡åŸºç¡€
- ACID ç‰¹æ€§
- éš”ç¦»çº§åˆ«
- é”æœºåˆ¶

##### æ¨¡å— 4: ç´¢å¼•å’Œä¼˜åŒ–ï¼ˆ4 å°æ—¶ï¼‰

- ç´¢å¼•ç±»å‹
- æŸ¥è¯¢ä¼˜åŒ–
- EXPLAIN åˆ†æ
- æ€§èƒ½è°ƒä¼˜

#### è¯¾ç¨‹ 2: PostgreSQL é«˜çº§ç‰¹æ€§ï¼ˆ24 å°æ—¶ï¼‰

##### æ¨¡å— 1: å‡½æ•°å’Œå­˜å‚¨è¿‡ç¨‹ï¼ˆ6 å°æ—¶ï¼‰

- ç”¨æˆ·å®šä¹‰å‡½æ•°
- å­˜å‚¨è¿‡ç¨‹
- è§¦å‘å™¨
- äº‹ä»¶è§¦å‘å™¨

##### æ¨¡å— 2: é«˜çº§æ•°æ®ç±»å‹ï¼ˆ6 å°æ—¶ï¼‰

- JSON/JSONB
- æ•°ç»„
- èŒƒå›´ç±»å‹
- è‡ªå®šä¹‰ç±»å‹

##### æ¨¡å— 3: è§†å›¾å’Œç‰©åŒ–è§†å›¾ï¼ˆ4 å°æ—¶ï¼‰

- è§†å›¾åˆ›å»ºå’Œä½¿ç”¨
- ç‰©åŒ–è§†å›¾
- è§†å›¾ä¼˜åŒ–

##### æ¨¡å— 4: å®‰å…¨å’Œæƒé™ï¼ˆ4 å°æ—¶ï¼‰

- ç”¨æˆ·å’Œè§’è‰²
- æƒé™ç®¡ç†
- è¡Œçº§å®‰å…¨
- å®¡è®¡

##### æ¨¡å— 5: å¤‡ä»½å’Œæ¢å¤ï¼ˆ4 å°æ—¶ï¼‰

- é€»è¾‘å¤‡ä»½
- ç‰©ç†å¤‡ä»½
- æ—¶é—´ç‚¹æ¢å¤
- å¤åˆ¶é…ç½®

#### 45.11 é«˜çº§ SQL ç‰¹æ€§

**çª—å£å‡½æ•°ï¼ˆWindow Functionsï¼‰**:

```sql
-- ROW_NUMBER() - è¡Œå·
SELECT
    name,
    salary,
    ROW_NUMBER() OVER (ORDER BY salary DESC) AS rank
FROM employees;

-- RANK() - æ’åï¼ˆç›¸åŒå€¼ç›¸åŒæ’åï¼Œè·³è¿‡åç»­æ’åï¼‰
SELECT
    name,
    salary,
    RANK() OVER (ORDER BY salary DESC) AS rank
FROM employees;

-- DENSE_RANK() - å¯†é›†æ’åï¼ˆç›¸åŒå€¼ç›¸åŒæ’åï¼Œä¸è·³è¿‡ï¼‰
SELECT
    name,
    salary,
    DENSE_RANK() OVER (ORDER BY salary DESC) AS rank
FROM employees;

-- åˆ†åŒºçª—å£å‡½æ•°
SELECT
    department,
    name,
    salary,
    ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) AS dept_rank
FROM employees;

-- èšåˆçª—å£å‡½æ•°
SELECT
    name,
    salary,
    AVG(salary) OVER (PARTITION BY department) AS dept_avg_salary,
    SUM(salary) OVER (PARTITION BY department) AS dept_total_salary
FROM employees;

-- LAG å’Œ LEADï¼ˆè®¿é—®å‰åè¡Œï¼‰
SELECT
    order_date,
    total_amount,
    LAG(total_amount) OVER (ORDER BY order_date) AS prev_amount,
    LEAD(total_amount) OVER (ORDER BY order_date) AS next_amount
FROM orders;

-- FIRST_VALUE å’Œ LAST_VALUE
SELECT
    name,
    salary,
    FIRST_VALUE(salary) OVER (PARTITION BY department ORDER BY salary DESC) AS highest_salary,
    LAST_VALUE(salary) OVER (PARTITION BY department ORDER BY salary DESC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS lowest_salary
FROM employees;

-- ç´¯è®¡èšåˆ
SELECT
    order_date,
    total_amount,
    SUM(total_amount) OVER (ORDER BY order_date) AS running_total,
    AVG(total_amount) OVER (ORDER BY order_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS seven_day_avg
FROM orders;
```

**CTEï¼ˆå…¬ç”¨è¡¨è¡¨è¾¾å¼ï¼‰**:

```sql
-- ç®€å• CTE
WITH high_salary_employees AS (
    SELECT * FROM employees WHERE salary > 100000
)
SELECT * FROM high_salary_employees;

-- å¤šä¸ª CTE
WITH
    dept_stats AS (
        SELECT
            department,
            AVG(salary) AS avg_salary,
            COUNT(*) AS emp_count
        FROM employees
        GROUP BY department
    ),
    high_avg_depts AS (
        SELECT department
        FROM dept_stats
        WHERE avg_salary > 80000
    )
SELECT e.*
FROM employees e
JOIN high_avg_depts h ON e.department = h.department;

-- é€’å½’ CTE
WITH RECURSIVE employee_hierarchy AS (
    -- åŸºç¡€æŸ¥è¯¢ï¼ˆé¡¶çº§ç®¡ç†è€…ï¼‰
    SELECT id, name, manager_id, 1 AS level
    FROM employees
    WHERE manager_id IS NULL

    UNION ALL

    -- é€’å½’æŸ¥è¯¢ï¼ˆä¸‹å±ï¼‰
    SELECT e.id, e.name, e.manager_id, eh.level + 1
    FROM employees e
    JOIN employee_hierarchy eh ON e.manager_id = eh.id
)
SELECT * FROM employee_hierarchy;

-- CTE ç”¨äºæ›´æ–°
WITH updated_salaries AS (
    SELECT id, salary * 1.1 AS new_salary
    FROM employees
    WHERE department = 'Engineering'
)
UPDATE employees e
SET salary = us.new_salary
FROM updated_salaries us
WHERE e.id = us.id;
```

**é«˜çº§æŸ¥è¯¢æŠ€å·§**:

```sql
-- CASE è¡¨è¾¾å¼
SELECT
    name,
    salary,
    CASE
        WHEN salary > 100000 THEN 'High'
        WHEN salary > 50000 THEN 'Medium'
        ELSE 'Low'
    END AS salary_category
FROM employees;

-- æ¡ä»¶èšåˆ
SELECT
    department,
    COUNT(*) AS total_employees,
    COUNT(CASE WHEN salary > 100000 THEN 1 END) AS high_salary_count,
    SUM(CASE WHEN salary > 100000 THEN salary ELSE 0 END) AS high_salary_total
FROM employees
GROUP BY department;

-- FILTER å­å¥ï¼ˆPostgreSQL 9.4+ï¼‰
SELECT
    department,
    COUNT(*) AS total_employees,
    COUNT(*) FILTER (WHERE salary > 100000) AS high_salary_count,
    SUM(salary) FILTER (WHERE salary > 100000) AS high_salary_total
FROM employees
GROUP BY department;

-- æ¨ªå‘è¿æ¥ï¼ˆLATERAL JOINï¼‰
SELECT
    u.name,
    recent_orders.order_date,
    recent_orders.total_amount
FROM users u
CROSS JOIN LATERAL (
    SELECT order_date, total_amount
    FROM orders
    WHERE orders.user_id = u.id
    ORDER BY order_date DESC
    LIMIT 3
) AS recent_orders;

-- æ•°ç»„èšåˆ
SELECT
    department,
    array_agg(name ORDER BY salary DESC) AS employee_names,
    array_agg(salary ORDER BY salary DESC) AS salaries
FROM employees
GROUP BY department;

-- JSON èšåˆ
SELECT
    department,
    json_agg(json_build_object('name', name, 'salary', salary)) AS employees
FROM employees
GROUP BY department;
```

#### 45.12 æ•°æ®åº“è®¾è®¡æœ€ä½³å®è·µ

**è§„èŒƒåŒ–è®¾è®¡**:

```sql
-- ç¬¬ä¸€èŒƒå¼ï¼ˆ1NFï¼‰ï¼šæ¯ä¸ªå­—æ®µéƒ½æ˜¯åŸå­å€¼
-- ä¸å¥½
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name TEXT,
    addresses TEXT  -- åŒ…å«å¤šä¸ªåœ°å€
);

-- å¥½
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name TEXT
);

CREATE TABLE addresses (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    address TEXT
);

-- ç¬¬äºŒèŒƒå¼ï¼ˆ2NFï¼‰ï¼šæ¶ˆé™¤éƒ¨åˆ†ä¾èµ–
-- ä¸å¥½
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER,
    user_name TEXT,  -- ä¾èµ–äº user_idï¼Œä¸æ˜¯ä¸»é”®
    product_id INTEGER,
    product_name TEXT,  -- ä¾èµ–äº product_idï¼Œä¸æ˜¯ä¸»é”®
    quantity INTEGER
);

-- å¥½
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    product_id INTEGER REFERENCES products(id),
    quantity INTEGER
);

-- ç¬¬ä¸‰èŒƒå¼ï¼ˆ3NFï¼‰ï¼šæ¶ˆé™¤ä¼ é€’ä¾èµ–
-- ä¸å¥½
CREATE TABLE employees (
    id SERIAL PRIMARY KEY,
    name TEXT,
    department_id INTEGER,
    department_name TEXT,  -- ä¾èµ–äº department_idï¼Œä¼ é€’ä¾èµ–
    manager_id INTEGER
);

-- å¥½
CREATE TABLE employees (
    id SERIAL PRIMARY KEY,
    name TEXT,
    department_id INTEGER REFERENCES departments(id),
    manager_id INTEGER REFERENCES employees(id)
);

CREATE TABLE departments (
    id SERIAL PRIMARY KEY,
    name TEXT
);
```

**ç´¢å¼•è®¾è®¡åŸåˆ™**:

```sql
-- 1. ä¸»é”®è‡ªåŠ¨åˆ›å»ºç´¢å¼•
CREATE TABLE users (
    id SERIAL PRIMARY KEY  -- è‡ªåŠ¨åˆ›å»ºä¸»é”®ç´¢å¼•
);

-- 2. å¤–é”®åˆ—åˆ›å»ºç´¢å¼•
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id)
);
CREATE INDEX idx_orders_user_id ON orders(user_id);

-- 3. é¢‘ç¹æŸ¥è¯¢çš„åˆ—åˆ›å»ºç´¢å¼•
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_orders_date ON orders(order_date);

-- 4. å¤åˆç´¢å¼•çš„é¡ºåºå¾ˆé‡è¦
-- æŸ¥è¯¢: WHERE status = 'active' AND created_at > '2024-01-01'
CREATE INDEX idx_orders_status_date ON orders(status, created_at);
-- status åœ¨å‰ï¼Œå› ä¸ºé€‰æ‹©æ€§æ›´é«˜

-- 5. è¦†ç›–ç´¢å¼•ï¼ˆåŒ…å«æŸ¥è¯¢æ‰€éœ€çš„æ‰€æœ‰åˆ—ï¼‰
CREATE INDEX idx_users_covering ON users(email) INCLUDE (name, age);
-- æŸ¥è¯¢åªéœ€è¦ email, name, age æ—¶ï¼Œå¯ä»¥ç›´æ¥ä»ç´¢å¼•è·å–ï¼Œæ— éœ€å›è¡¨

-- 6. éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•éœ€è¦çš„è¡Œï¼‰
CREATE INDEX idx_active_users ON users(email) WHERE is_active = TRUE;

-- 7. è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX idx_users_lower_email ON users(LOWER(email));
```

#### 45.13 å¸¸è§ SQL æ¨¡å¼

**åˆ†é¡µæŸ¥è¯¢**:

```sql
-- æ–¹æ³• 1: LIMIT/OFFSETï¼ˆç®€å•ä½†æ€§èƒ½è¾ƒå·®ï¼‰
SELECT * FROM users
ORDER BY id
LIMIT 10 OFFSET 20;

-- æ–¹æ³• 2: æ¸¸æ ‡åˆ†é¡µï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
-- ç¬¬ä¸€é¡µ
SELECT * FROM users
WHERE id > 0
ORDER BY id
LIMIT 10;

-- ç¬¬äºŒé¡µï¼ˆä½¿ç”¨ä¸Šä¸€é¡µæœ€åä¸€æ¡è®°å½•çš„ idï¼‰
SELECT * FROM users
WHERE id > 100  -- ä¸Šä¸€é¡µæœ€åä¸€æ¡è®°å½•çš„ id
ORDER BY id
LIMIT 10;
```

**æŸ¥æ‰¾é‡å¤è®°å½•**:

```sql
-- æŸ¥æ‰¾é‡å¤çš„ email
SELECT email, COUNT(*)
FROM users
GROUP BY email
HAVING COUNT(*) > 1;

-- åˆ é™¤é‡å¤è®°å½•ï¼ˆä¿ç•™ id æœ€å°çš„ï¼‰
DELETE FROM users u1
USING users u2
WHERE u1.email = u2.email
AND u1.id > u2.id;
```

**æ ‘å½¢ç»“æ„æŸ¥è¯¢**:

```sql
-- ä½¿ç”¨é€’å½’ CTE æŸ¥è¯¢æ ‘å½¢ç»“æ„
WITH RECURSIVE category_tree AS (
    -- æ ¹èŠ‚ç‚¹
    SELECT id, name, parent_id, 1 AS level, name AS path
    FROM categories
    WHERE parent_id IS NULL

    UNION ALL

    -- å­èŠ‚ç‚¹
    SELECT c.id, c.name, c.parent_id, ct.level + 1, ct.path || ' > ' || c.name
    FROM categories c
    JOIN category_tree ct ON c.parent_id = ct.id
)
SELECT * FROM category_tree ORDER BY path;
```

**æ•°æ®è¿ç§»æ¨¡å¼**:

```sql
-- å®‰å…¨çš„è¡¨ç»“æ„å˜æ›´
BEGIN;

-- 1. æ·»åŠ æ–°åˆ—ï¼ˆå…è®¸ NULLï¼‰
ALTER TABLE users ADD COLUMN new_field TEXT;

-- 2. å¡«å……æ–°åˆ—æ•°æ®
UPDATE users SET new_field = 'default_value' WHERE new_field IS NULL;

-- 3. æ·»åŠ  NOT NULL çº¦æŸ
ALTER TABLE users ALTER COLUMN new_field SET NOT NULL;

COMMIT;

-- é‡å‘½ååˆ—
ALTER TABLE users RENAME COLUMN old_name TO new_name;

-- ä¿®æ”¹åˆ—ç±»å‹
ALTER TABLE users ALTER COLUMN age TYPE INTEGER USING age::INTEGER;
```

#### 45.14 PostgreSQL å®è·µç»ƒä¹ 

#### ç»ƒä¹  1: å¤æ‚æŸ¥è¯¢

```sql
-- ä»»åŠ¡: æŸ¥è¯¢æ¯ä¸ªéƒ¨é—¨å·¥èµ„æœ€é«˜çš„å‰ 3 åå‘˜å·¥
WITH ranked_employees AS (
    SELECT
        department,
        name,
        salary,
        ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) AS rank
    FROM employees
)
SELECT department, name, salary
FROM ranked_employees
WHERE rank <= 3;
```

#### ç»ƒä¹  2: æ•°æ®æ¸…ç†

```sql
-- ä»»åŠ¡: æ¸…ç†é‡å¤æ•°æ®ï¼Œä¿ç•™æœ€æ–°çš„è®°å½•
DELETE FROM users u1
USING users u2
WHERE u1.email = u2.email
AND u1.created_at < u2.created_at;
```

#### ç»ƒä¹  3: æ•°æ®ç»Ÿè®¡

```sql
-- ä»»åŠ¡: ç”Ÿæˆæœˆåº¦é”€å”®æŠ¥å‘Š
SELECT
    DATE_TRUNC('month', order_date) AS month,
    COUNT(*) AS order_count,
    SUM(total_amount) AS total_revenue,
    AVG(total_amount) AS avg_order_value,
    COUNT(DISTINCT user_id) AS unique_customers
FROM orders
GROUP BY DATE_TRUNC('month', order_date)
ORDER BY month;
```

#### ç»ƒä¹  4: æ€§èƒ½ä¼˜åŒ–

```sql
-- ä»»åŠ¡: ä¼˜åŒ–è¿™ä¸ªæ…¢æŸ¥è¯¢
-- åŸå§‹æŸ¥è¯¢
SELECT u.name, o.order_date, o.total_amount
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.email LIKE '%@example.com'
ORDER BY o.order_date DESC
LIMIT 100;

-- ä¼˜åŒ–æ­¥éª¤:
-- 1. åœ¨ users.email ä¸Šåˆ›å»ºç´¢å¼•
CREATE INDEX idx_users_email ON users(email);

-- 2. åœ¨ orders.user_id å’Œ orders.order_date ä¸Šåˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_orders_user_date ON orders(user_id, order_date DESC);

-- 3. å¦‚æœå¯èƒ½ï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„è¿‡æ»¤æ¡ä»¶
SELECT u.name, o.order_date, o.total_amount
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.email LIKE 'user%@example.com'  -- æ›´å…·ä½“çš„æ¨¡å¼
ORDER BY o.order_date DESC
LIMIT 100;
```

#### 45.15 PostgreSQL è®¤è¯è€ƒè¯•å‡†å¤‡

**PostgreSQL è®¤è¯è·¯å¾„**:

1. **PostgreSQL åŸºç¡€è®¤è¯ï¼ˆPGBï¼‰**:

   - SQL åŸºç¡€
   - æ•°æ®ç±»å‹
   - åŸºæœ¬æŸ¥è¯¢
   - äº‹åŠ¡åŸºç¡€

1. **PostgreSQL é«˜çº§è®¤è¯ï¼ˆPGAï¼‰**:
   - é«˜çº§ SQL
   - æ€§èƒ½ä¼˜åŒ–
   - å¤‡ä»½æ¢å¤
   - é«˜å¯ç”¨é…ç½®

**è€ƒè¯•å‡†å¤‡èµ„æº**:

```python
# è€ƒè¯•ç»ƒä¹ é¢˜ç”Ÿæˆå™¨
class PostgreSQLExamPractice:
    """PostgreSQL è€ƒè¯•ç»ƒä¹ """

    def generate_sql_questions(self):
        """ç”Ÿæˆ SQL é¢˜ç›®"""
        questions = [
            {
                'question': 'å¦‚ä½•åˆ›å»ºä¸€ä¸ªåŒ…å«å¤–é”®çš„è¡¨ï¼Ÿ',
                'type': 'coding',
                'solution': '''
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    total_amount DECIMAL
);
'''
            },
            {
                'question': 'ä»€ä¹ˆæ˜¯äº‹åŠ¡çš„ ACID ç‰¹æ€§ï¼Ÿ',
                'type': 'essay',
                'solution': '''
A - Atomicityï¼ˆåŸå­æ€§ï¼‰
C - Consistencyï¼ˆä¸€è‡´æ€§ï¼‰
I - Isolationï¼ˆéš”ç¦»æ€§ï¼‰
D - Durabilityï¼ˆæŒä¹…æ€§ï¼‰
'''
            }
        ]
        return questions

    def practice_transactions(self):
        """äº‹åŠ¡ç»ƒä¹ """
        scenarios = [
            {
                'name': 'é“¶è¡Œè½¬è´¦',
                'description': 'å®ç°ä¸€ä¸ªå®‰å…¨çš„è½¬è´¦æ“ä½œ',
                'solution': '''
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
COMMIT;
'''
            }
        ]
        return scenarios
```

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£

- [Neon å®˜æ–¹æ–‡æ¡£](https://neon.tech/docs) - å®Œæ•´çš„ Neon ä½¿ç”¨æ–‡æ¡£
- [Neon API æ–‡æ¡£](https://neon.tech/api-reference) - API å‚è€ƒæ–‡æ¡£
- [Neon CLI æ–‡æ¡£](https://neon.tech/docs/cli) - å‘½ä»¤è¡Œå·¥å…·æ–‡æ¡£

### å¼€å‘èµ„æº

- [Neon GitHub](https://github.com/neondatabase/neon) - å¼€æºä»£ç åº“
- [Neon Discord](https://discord.gg/neondatabase) - ç¤¾åŒºè®¨è®º
- [Neon Blog](https://neon.tech/blog) - æŠ€æœ¯åšå®¢

### ç›¸å…³èµ„æº

- [PostgreSQL å®˜æ–¹æ–‡æ¡£](https://www.postgresql.org/docs/) - PostgreSQL å‚è€ƒ
- [pgvector æ–‡æ¡£](https://github.com/pgvector/pgvector) - å‘é‡æœç´¢æ‰©å±•

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥ **ç»´æŠ¤è€…**: PostgreSQL Modern Team **æ–‡æ¡£ç¼–å·**: 03-02-01
