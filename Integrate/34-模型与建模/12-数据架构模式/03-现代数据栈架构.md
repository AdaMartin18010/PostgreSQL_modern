# 现代数据栈架构建模指南

> **创建日期**: 2025年1月
> **来源**: PostgreSQL 18+ + 实践总结
> **状态**: PostgreSQL 18+新特性
> **文档编号**: 12-03

---

## 📑 目录

- [现代数据栈架构建模指南](#现代数据栈架构建模指南)
  - [📑 目录](#-目录)
  - [1. 概述](#1-概述)
  - [1.1 理论基础](#11-理论基础)
    - [1.1.1 现代数据栈概念](#111-现代数据栈概念)
    - [1.1.2 ETL vs ELT](#112-etl-vs-elt)
    - [1.1.3 数据管道理论](#113-数据管道理论)
    - [1.1.4 数据仓库分层理论](#114-数据仓库分层理论)
    - [1.1.5 复杂度分析](#115-复杂度分析)
  - [2. 数据管道建模](#2-数据管道建模)
    - [2.1 数据源表](#21-数据源表)
    - [2.2 数据管道表](#22-数据管道表)
    - [2.3 管道执行记录表（TimescaleDB）](#23-管道执行记录表timescaledb)
  - [3. 数据仓库建模](#3-数据仓库建模)
    - [3.1 数据仓库表](#31-数据仓库表)
    - [3.2 数据质量检查表](#32-数据质量检查表)
  - [4. 数据应用建模](#4-数据应用建模)
    - [4.1 数据应用表](#41-数据应用表)
    - [4.2 数据应用使用统计表（TimescaleDB）](#42-数据应用使用统计表timescaledb)
  - [5. PostgreSQL 18优化](#5-postgresql-18优化)
    - [5.1 异步I/O优化](#51-异步io优化)
    - [5.2 虚拟生成列优化](#52-虚拟生成列优化)
    - [5.3 TimescaleDB连续聚合](#53-timescaledb连续聚合)
  - [6. 性能优化建议](#6-性能优化建议)
    - [6.1 索引优化策略](#61-索引优化策略)
    - [6.2 TimescaleDB分区优化](#62-timescaledb分区优化)
    - [6.3 TimescaleDB连续聚合优化](#63-timescaledb连续聚合优化)
    - [6.4 物化视图缓存](#64-物化视图缓存)
    - [6.5 PostgreSQL 18异步I/O优化](#65-postgresql-18异步io优化)
  - [7. 最佳实践](#7-最佳实践)
    - [7.1 数据管道](#71-数据管道)
    - [7.2 数据仓库](#72-数据仓库)
    - [7.3 数据应用](#73-数据应用)
    - [7.4 SQL实现注意事项](#74-sql实现注意事项)
  - [8. 常见问题与解决方案](#8-常见问题与解决方案)
    - [问题1: 数据管道执行失败率高](#问题1-数据管道执行失败率高)
    - [问题2: 数据仓库查询性能慢](#问题2-数据仓库查询性能慢)
    - [问题3: 数据应用访问慢](#问题3-数据应用访问慢)
    - [问题4: 数据管道监控困难](#问题4-数据管道监控困难)
  - [9. 相关资源](#9-相关资源)
    - [9.1 核心相关文档](#91-核心相关文档)
    - [9.2 官方资源](#92-官方资源)

---

## 1. 概述

现代数据栈（Modern Data Stack）是一套云原生的数据工具集合，包括数据提取、转换、加载（ETL）、数据仓库、BI工具等。

**核心组件**:

- 数据提取（Extract）
- 数据转换（Transform）
- 数据加载（Load）
- 数据仓库（Data Warehouse）
- 数据应用（Data Applications）

---

## 1.1 理论基础

### 1.1.1 现代数据栈概念

**现代数据栈（Modern Data Stack）**是云原生、模块化的数据工具集合：

- **云原生**: 基于云服务构建
- **模块化**: 各组件可独立选择和替换
- **自助服务**: 业务用户可以自助使用
- **实时性**: 支持实时数据处理

### 1.1.2 ETL vs ELT

**ETL（Extract-Transform-Load）**:

- 在加载前进行转换
- 适合结构化数据
- 转换逻辑在ETL工具中

**ELT（Extract-Load-Transform）**:

- 先加载原始数据
- 在数据仓库中转换
- 适合大数据和灵活转换

### 1.1.3 数据管道理论

**数据管道（Data Pipeline）**是数据流转的通道：

1. **提取（Extract）**: 从数据源提取数据
2. **转换（Transform）**: 对数据进行转换
3. **加载（Load）**: 加载到目标系统

**管道模式**:

- **批处理管道**: 定期批量处理数据
- **流式管道**: 实时处理数据流
- **混合管道**: 结合批处理和流式处理

### 1.1.4 数据仓库分层理论

**数据仓库分层架构**:

1. **ODS（Operational Data Store）**: 操作数据存储层
2. **DWD（Data Warehouse Detail）**: 数据仓库明细层
3. **DWS（Data Warehouse Summary）**: 数据仓库汇总层
4. **ADS（Application Data Service）**: 应用数据服务层

**分层原则**:

- **数据质量递增**: 每层数据质量逐步提升
- **数据粒度递减**: 从明细到汇总
- **查询性能递增**: 每层查询性能逐步提升

### 1.1.5 复杂度分析

**存储复杂度**:

- **数据源**: $O(S)$ where S is number of sources
- **数据管道**: $O(P)$ where P is number of pipelines
- **数据仓库**: $O(D)$ where D is data volume

**处理复杂度**:

- **ETL处理**: $O(N)$ where N is data size
- **管道执行**: $O(P \times E)$ where E is execution time
- **查询处理**: $O(\log D)$ with index

---

## 2. 数据管道建模

### 2.1 数据源表

```sql
CREATE TABLE data_sources (
    id SERIAL PRIMARY KEY,
    source_name VARCHAR(255) NOT NULL,
    source_type VARCHAR(50) NOT NULL,  -- 'database', 'api', 'file', 'stream', etc.
    connection_config JSONB NOT NULL,  -- 连接配置（加密存储）
    schema_definition JSONB,  -- 数据模式定义
    extraction_config JSONB DEFAULT '{}',  -- 提取配置
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(source_name)
);

-- 创建索引
CREATE INDEX idx_data_sources_type ON data_sources(source_type);
CREATE INDEX idx_data_sources_active ON data_sources(is_active) WHERE is_active = TRUE;
```

### 2.2 数据管道表

```sql
CREATE TABLE data_pipelines (
    id SERIAL PRIMARY KEY,
    pipeline_name VARCHAR(255) NOT NULL,
    source_id INTEGER NOT NULL REFERENCES data_sources(id),
    target_id INTEGER NOT NULL REFERENCES data_sources(id),
    pipeline_type VARCHAR(50) NOT NULL CHECK (pipeline_type IN ('batch', 'streaming', 'cdc')),
    transformation_code TEXT,  -- 转换代码（SQL、Python等）
    transformation_config JSONB DEFAULT '{}',
    schedule_config JSONB DEFAULT '{}',  -- 调度配置（cron表达式等）
    status VARCHAR(20) NOT NULL CHECK (status IN ('active', 'paused', 'failed', 'disabled')),
    last_run_at TIMESTAMPTZ,
    next_run_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(pipeline_name)
);

-- 创建索引
CREATE INDEX idx_data_pipelines_source ON data_pipelines(source_id);
CREATE INDEX idx_data_pipelines_target ON data_pipelines(target_id);
CREATE INDEX idx_data_pipelines_status ON data_pipelines(status);
CREATE INDEX idx_data_pipelines_next_run ON data_pipelines(next_run_at) WHERE status = 'active';
```

### 2.3 管道执行记录表（TimescaleDB）

```sql
-- 管道执行记录表（使用TimescaleDB）
CREATE TABLE pipeline_executions (
    time TIMESTAMPTZ NOT NULL,
    pipeline_id INTEGER NOT NULL REFERENCES data_pipelines(id),
    execution_id VARCHAR(255) UNIQUE NOT NULL,
    status VARCHAR(20) NOT NULL CHECK (status IN ('running', 'completed', 'failed', 'cancelled')),
    records_processed BIGINT DEFAULT 0,
    records_failed BIGINT DEFAULT 0,
    processing_time_seconds INTEGER,
    error_message TEXT,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (execution_id, time)
);

-- 创建TimescaleDB超表
SELECT create_hypertable(
    'pipeline_executions',
    'time',
    chunk_time_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);

-- 创建索引
CREATE INDEX idx_pipeline_executions_pipeline ON pipeline_executions(pipeline_id, time DESC);
CREATE INDEX idx_pipeline_executions_status ON pipeline_executions(status, time DESC);
```

---

## 3. 数据仓库建模

### 3.1 数据仓库表

```sql
CREATE TABLE data_warehouse_tables (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(255) NOT NULL,
    schema_name VARCHAR(100) NOT NULL DEFAULT 'public',
    table_type VARCHAR(50) NOT NULL CHECK (table_type IN ('fact', 'dimension', 'aggregate', 'staging')),
    description TEXT,
    schema_definition JSONB,  -- 表结构定义
    partition_strategy VARCHAR(50),  -- 'range', 'list', 'hash', 'none'
    partition_columns TEXT[],
    retention_policy_days INTEGER,  -- 数据保留策略
    refresh_frequency VARCHAR(50),  -- 'hourly', 'daily', 'weekly', 'on-demand'
    last_refresh_at TIMESTAMPTZ,
    next_refresh_at TIMESTAMPTZ,
    row_count BIGINT,
    size_bytes BIGINT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(schema_name, table_name)
);

-- 创建索引
CREATE INDEX idx_data_warehouse_tables_type ON data_warehouse_tables(table_type);
CREATE INDEX idx_data_warehouse_tables_next_refresh ON data_warehouse_tables(next_refresh_at)
WHERE next_refresh_at IS NOT NULL;
```

### 3.2 数据质量检查表

```sql
CREATE TABLE data_warehouse_quality_checks (
    id SERIAL PRIMARY KEY,
    table_id INTEGER NOT NULL REFERENCES data_warehouse_tables(id),
    check_name VARCHAR(255) NOT NULL,
    check_type VARCHAR(50) NOT NULL,  -- 'row_count', 'null_check', 'uniqueness', 'referential_integrity'
    check_query TEXT NOT NULL,  -- 检查SQL
    threshold_value NUMERIC(10,6),
    last_check_at TIMESTAMPTZ,
    last_check_result VARCHAR(20),  -- 'pass', 'fail', 'warning'
    last_check_value NUMERIC(10,6),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(table_id, check_name)
);

-- 创建索引
CREATE INDEX idx_data_warehouse_quality_checks_table ON data_warehouse_quality_checks(table_id);
CREATE INDEX idx_data_warehouse_quality_checks_active ON data_warehouse_quality_checks(is_active) WHERE is_active = TRUE;
```

---

## 4. 数据应用建模

### 4.1 数据应用表

```sql
CREATE TABLE data_applications (
    id SERIAL PRIMARY KEY,
    app_name VARCHAR(255) NOT NULL,
    app_type VARCHAR(50) NOT NULL,  -- 'bi', 'dashboard', 'api', 'ml_model', etc.
    description TEXT,
    data_sources INTEGER[] DEFAULT ARRAY[]::INTEGER[],  -- 数据源ID列表
    access_config JSONB DEFAULT '{}',  -- 访问配置
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(app_name)
);

-- 创建索引
CREATE INDEX idx_data_applications_type ON data_applications(app_type);
CREATE INDEX idx_data_applications_active ON data_applications(is_active) WHERE is_active = TRUE;
```

### 4.2 数据应用使用统计表（TimescaleDB）

```sql
-- 数据应用使用统计表（使用TimescaleDB）
CREATE TABLE data_application_usage (
    time TIMESTAMPTZ NOT NULL,
    app_id INTEGER NOT NULL REFERENCES data_applications(id),
    user_id VARCHAR(255) NOT NULL,
    action_type VARCHAR(50) NOT NULL,  -- 'view', 'query', 'export', 'share'
    query_text TEXT,
    execution_time_ms INTEGER,
    records_returned INTEGER,
    status VARCHAR(20) NOT NULL CHECK (status IN ('success', 'error', 'timeout')),
    error_message TEXT,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (app_id, user_id, time)
);

-- 创建TimescaleDB超表
SELECT create_hypertable(
    'data_application_usage',
    'time',
    chunk_time_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);

-- 创建索引
CREATE INDEX idx_data_application_usage_app ON data_application_usage(app_id, time DESC);
CREATE INDEX idx_data_application_usage_user ON data_application_usage(user_id, time DESC);
CREATE INDEX idx_data_application_usage_status ON data_application_usage(status, time DESC);
```

---

## 5. PostgreSQL 18优化

### 5.1 异步I/O优化

```sql
-- PostgreSQL 18：异步I/O优化（数据管道批量写入）
BEGIN;
DO $$
BEGIN
    ALTER SYSTEM SET io_direct = 'data';
    ALTER SYSTEM SET io_combine_limit = '256kB';
    PERFORM pg_reload_conf();
    RAISE NOTICE '异步I/O配置已更新（数据管道写入性能提升50-60%）';
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE '配置异步I/O失败: %', SQLERRM;
        ROLLBACK;
        RAISE;
END $$;
COMMIT;
```

### 5.2 虚拟生成列优化

```sql
-- PostgreSQL 18：使用虚拟生成列优化计算字段
ALTER TABLE pipeline_executions
ADD COLUMN success_rate NUMERIC(5,2) GENERATED ALWAYS AS (
    CASE
        WHEN records_processed > 0 THEN
            ((records_processed - records_failed)::NUMERIC / records_processed * 100)
        ELSE 0
    END
) VIRTUAL;

ALTER TABLE data_warehouse_quality_checks
ADD COLUMN check_status VARCHAR(20) GENERATED ALWAYS AS (
    CASE
        WHEN last_check_result IS NULL THEN 'pending'
        WHEN threshold_value IS NULL THEN last_check_result
        WHEN last_check_value >= threshold_value THEN 'pass'
        ELSE 'fail'
    END
) VIRTUAL;
```

### 5.3 TimescaleDB连续聚合

```sql
-- 创建管道执行统计的连续聚合
CREATE MATERIALIZED VIEW pipeline_executions_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    pipeline_id,
    COUNT(*) AS execution_count,
    COUNT(*) FILTER (WHERE status = 'completed') AS success_count,
    COUNT(*) FILTER (WHERE status = 'failed') AS failure_count,
    AVG(processing_time_seconds) AS avg_processing_time,
    SUM(records_processed) AS total_records_processed
FROM pipeline_executions
GROUP BY bucket, pipeline_id;

-- 创建刷新策略
SELECT add_continuous_aggregate_policy(
    'pipeline_executions_hourly',
    start_offset => INTERVAL '1 day',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour'
);
```

---

## 6. 性能优化建议

### 6.1 索引优化策略

**数据管道查询优化**:

```sql
-- 为常用查询创建复合索引
CREATE INDEX idx_pipeline_executions_pipeline_status
ON pipeline_executions(pipeline_id, status, time DESC);
CREATE INDEX idx_pipeline_executions_status_time
ON pipeline_executions(status, time DESC)
WHERE status IN ('running', 'failed');

-- 为JSONB字段创建GIN索引
CREATE INDEX idx_pipeline_executions_config
ON pipeline_executions USING gin(execution_config);
```

**数据仓库查询优化**:

```sql
-- 为数据仓库表创建索引
CREATE INDEX idx_data_warehouse_tables_name ON data_warehouse_tables(table_name);
CREATE INDEX idx_data_warehouse_tables_layer ON data_warehouse_tables(layer);
```

### 6.2 TimescaleDB分区优化

**管道执行记录分区**:

```sql
-- TimescaleDB自动分区优化
SELECT create_hypertable(
    'pipeline_executions',
    'time',
    chunk_time_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);
```

**数据应用使用统计分区**:

```sql
-- 创建TimescaleDB超表
SELECT create_hypertable(
    'data_application_usage_stats',
    'timestamp',
    chunk_time_interval => INTERVAL '1 hour',
    if_not_exists => TRUE
);
```

### 6.3 TimescaleDB连续聚合优化

**管道执行统计聚合**:

```sql
-- 创建连续聚合视图
CREATE MATERIALIZED VIEW pipeline_executions_daily
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', time) AS bucket,
    pipeline_id,
    COUNT(*) AS execution_count,
    COUNT(*) FILTER (WHERE status = 'completed') AS success_count,
    COUNT(*) FILTER (WHERE status = 'failed') AS failure_count,
    AVG(processing_time_seconds) AS avg_processing_time
FROM pipeline_executions
GROUP BY bucket, pipeline_id;

-- 自动刷新策略
SELECT add_continuous_aggregate_policy(
    'pipeline_executions_daily',
    start_offset => INTERVAL '7 days',
    end_offset => INTERVAL '1 day',
    schedule_interval => INTERVAL '1 hour'
);
```

### 6.4 物化视图缓存

**缓存数据仓库汇总**:

```sql
-- 创建物化视图缓存数据仓库汇总
CREATE MATERIALIZED VIEW mv_data_warehouse_summary AS
SELECT
    layer,
    COUNT(*) AS table_count,
    SUM(record_count) AS total_records,
    AVG(data_size_bytes) AS avg_size_bytes
FROM data_warehouse_tables
GROUP BY layer;

-- 定期刷新
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_data_warehouse_summary;
```

### 6.5 PostgreSQL 18异步I/O优化

**异步I/O配置**:

```sql
-- PostgreSQL 18：启用异步I/O优化数据管道写入
ALTER SYSTEM SET io_direct = 'data';
ALTER SYSTEM SET io_combine_limit = '256kB';
SELECT pg_reload_conf();
```

---

## 7. 最佳实践

### 7.1 数据管道

1. **错误处理**: 完善的错误处理和重试机制
2. **监控告警**: 实时监控管道执行状态
3. **数据质量**: 在管道中集成数据质量检查
4. **幂等性**: 确保管道执行的幂等性

### 7.2 数据仓库

1. **分层设计**: 使用分层架构（ODS、DWD、DWS、ADS）
2. **分区策略**: 合理使用分区提升查询性能
3. **索引优化**: 为常用查询创建合适的索引
4. **数据治理**: 建立数据治理机制

### 7.3 数据应用

1. **缓存策略**: 对热点数据进行缓存
2. **查询优化**: 优化查询性能
3. **访问控制**: 细粒度的访问控制
4. **性能监控**: 监控应用性能

### 7.4 SQL实现注意事项

1. **错误处理**: 使用DO块处理管道操作错误
2. **事务管理**: 管道执行应在事务中处理
3. **性能监控**: 使用EXPLAIN ANALYZE分析查询性能
4. **并发控制**: 处理并发管道执行的竞争条件

---

## 8. 常见问题与解决方案

### 问题1: 数据管道执行失败率高

**原因**:

- 数据源连接失败
- 数据格式不匹配
- 转换逻辑错误

**解决方案**:

- 实现重试机制
- 数据格式验证
- 错误日志记录

**示例**:

```sql
-- 创建管道执行重试函数
CREATE OR REPLACE FUNCTION retry_pipeline_execution(
    p_execution_id INTEGER,
    p_max_retries INTEGER DEFAULT 3
)
RETURNS VOID AS $$
DECLARE
    v_retry_count INTEGER;
    v_status VARCHAR(20);
BEGIN
    SELECT retry_count, status INTO v_retry_count, v_status
    FROM pipeline_executions
    WHERE id = p_execution_id;

    IF v_status = 'failed' AND v_retry_count < p_max_retries THEN
        UPDATE pipeline_executions
        SET
            status = 'pending',
            retry_count = retry_count + 1,
            updated_at = NOW()
        WHERE id = p_execution_id;
    END IF;
END;
$$ LANGUAGE plpgsql;
```

### 问题2: 数据仓库查询性能慢

**原因**:

- 缺少索引
- 分区策略不合理
- 数据量过大

**解决方案**:

- 为常用查询创建索引
- 优化分区策略
- 使用物化视图缓存

**示例**:

```sql
-- 优化查询索引
CREATE INDEX idx_data_warehouse_tables_layer_name
ON data_warehouse_tables(layer, table_name);

-- 创建物化视图缓存
CREATE MATERIALIZED VIEW mv_dwd_summary AS
SELECT
    DATE_TRUNC('day', created_at) AS date,
    COUNT(*) AS record_count,
    SUM(amount) AS total_amount
FROM dwd_transactions
GROUP BY DATE_TRUNC('day', created_at);
```

### 问题3: 数据应用访问慢

**原因**:

- 缺少缓存
- 查询复杂
- 数据量大

**解决方案**:

- 实现缓存策略
- 优化查询
- 使用物化视图

### 问题4: 数据管道监控困难

**原因**:

- 监控数据分散
- 缺少统一监控视图
- 告警机制不完善

**解决方案**:

- 集中管理监控数据
- 创建监控汇总视图
- 实现告警机制

**示例**:

```sql
-- 创建管道监控视图
CREATE MATERIALIZED VIEW mv_pipeline_monitoring AS
SELECT
    p.pipeline_name,
    COUNT(e.id) AS total_executions,
    COUNT(*) FILTER (WHERE e.status = 'completed') AS success_count,
    COUNT(*) FILTER (WHERE e.status = 'failed') AS failure_count,
    AVG(e.processing_time_seconds) AS avg_processing_time,
    MAX(e.time) AS last_execution_time
FROM data_pipelines p
LEFT JOIN pipeline_executions e ON p.id = e.pipeline_id
WHERE e.time >= NOW() - INTERVAL '24 hours'
GROUP BY p.id, p.pipeline_name;

-- 定期刷新
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_pipeline_monitoring;
```

---

## 9. 相关资源

### 9.1 核心相关文档

- [数据网格架构](./01-数据网格架构.md) - 数据网格架构建模指南
- [数据湖架构](./02-数据湖架构.md) - 数据湖架构建模指南
- [PostgreSQL18新特性](../08-PostgreSQL建模实践/PostgreSQL18新特性.md) - PostgreSQL 18新特性指南

### 9.2 官方资源

- [PostgreSQL 18文档](https://www.postgresql.org/docs/18/) - PostgreSQL 18官方文档
- [TimescaleDB文档](https://docs.timescale.com/) - TimescaleDB官方文档

---

**最后更新**: 2025年1月
**维护者**: PostgreSQL Modern Team
**状态**: ✅ 已完成
