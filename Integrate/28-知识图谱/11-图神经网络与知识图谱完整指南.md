---
> **ğŸ“‹ æ–‡æ¡£æ¥æº**: æ–°å¢æ·±åŒ–æ–‡æ¡£
> **ğŸ“… åˆ›å»ºæ—¥æœŸ**: 2025-01
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºæ·±åº¦è¡¥å……ï¼Œæ·±åŒ–å›¾ç¥ç»ç½‘ç»œæŠ€æœ¯æ ˆ

---

# å›¾ç¥ç»ç½‘ç»œä¸çŸ¥è¯†å›¾è°±å®Œæ•´æŒ‡å—

## å…ƒæ•°æ®

- **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-01
- **æŠ€æœ¯æ ˆ**: PostgreSQL 16+ | Apache AGE 1.5+ | PyTorch Geometric | DGL | TensorFlow GNN
- **éš¾åº¦çº§åˆ«**: â­â­â­â­â­ (ä¸“å®¶çº§)
- **é¢„è®¡é˜…è¯»**: 180åˆ†é’Ÿ
- **å‰ç½®è¦æ±‚**: ç†Ÿæ‚‰å›¾æ•°æ®åº“ã€æ·±åº¦å­¦ä¹ å’ŒçŸ¥è¯†å›¾è°±åŸºç¡€

---

## ğŸ“‹ å®Œæ•´ç›®å½•

- [å›¾ç¥ç»ç½‘ç»œä¸çŸ¥è¯†å›¾è°±å®Œæ•´æŒ‡å—](#å›¾ç¥ç»ç½‘ç»œä¸çŸ¥è¯†å›¾è°±å®Œæ•´æŒ‡å—)
  - [å…ƒæ•°æ®](#å…ƒæ•°æ®)
  - [ğŸ“‹ å®Œæ•´ç›®å½•](#-å®Œæ•´ç›®å½•)
  - [1. GNNåŸºç¡€ç†è®º](#1-gnnåŸºç¡€ç†è®º)
    - [1.1 å›¾ç¥ç»ç½‘ç»œæ¦‚è¿°](#11-å›¾ç¥ç»ç½‘ç»œæ¦‚è¿°)
      - [ä¸ºä»€ä¹ˆéœ€è¦GNNï¼Ÿ](#ä¸ºä»€ä¹ˆéœ€è¦gnn)
    - [1.2 GNNæ ¸å¿ƒæ¦‚å¿µ](#12-gnnæ ¸å¿ƒæ¦‚å¿µ)
      - [æ¶ˆæ¯ä¼ é€’æœºåˆ¶](#æ¶ˆæ¯ä¼ é€’æœºåˆ¶)
      - [å›¾è¡¨ç¤ºå­¦ä¹ ](#å›¾è¡¨ç¤ºå­¦ä¹ )
    - [1.3 GNNæ¶æ„ç±»å‹](#13-gnnæ¶æ„ç±»å‹)
      - [å·ç§¯ç±»GNN](#å·ç§¯ç±»gnn)
      - [æ³¨æ„åŠ›ç±»GNN](#æ³¨æ„åŠ›ç±»gnn)
      - [é‡‡æ ·ç±»GNN](#é‡‡æ ·ç±»gnn)
  - [2. çŸ¥è¯†å›¾è°±ä¸­çš„GNNåº”ç”¨](#2-çŸ¥è¯†å›¾è°±ä¸­çš„gnnåº”ç”¨)
    - [2.1 èŠ‚ç‚¹åˆ†ç±»](#21-èŠ‚ç‚¹åˆ†ç±»)
      - [å®ç°ç¤ºä¾‹](#å®ç°ç¤ºä¾‹)
    - [2.2 å…³ç³»é¢„æµ‹ï¼ˆé“¾æ¥é¢„æµ‹ï¼‰](#22-å…³ç³»é¢„æµ‹é“¾æ¥é¢„æµ‹)
      - [TransEé£æ ¼çš„é“¾æ¥é¢„æµ‹](#transeé£æ ¼çš„é“¾æ¥é¢„æµ‹)
      - [GNN-basedé“¾æ¥é¢„æµ‹](#gnn-basedé“¾æ¥é¢„æµ‹)
    - [2.3 å®ä½“å¯¹é½](#23-å®ä½“å¯¹é½)
    - [2.4 çŸ¥è¯†å›¾è°±è¡¥å…¨](#24-çŸ¥è¯†å›¾è°±è¡¥å…¨)
  - [3. GNNæ¨¡å‹è¯¦è§£](#3-gnnæ¨¡å‹è¯¦è§£)
    - [3.1 GCN (Graph Convolutional Network)](#31-gcn-graph-convolutional-network)
      - [å®ç°](#å®ç°)
    - [3.2 GraphSAGE](#32-graphsage)
    - [3.3 GAT (Graph Attention Network)](#33-gat-graph-attention-network)
    - [3.4 RGCN (Relational GCN)](#34-rgcn-relational-gcn)
  - [4. çŸ¥è¯†å›¾è°±åµŒå…¥](#4-çŸ¥è¯†å›¾è°±åµŒå…¥)
    - [4.1 TransEä¸Transå®¶æ—](#41-transeä¸transå®¶æ—)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
  - [ğŸ“ æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)

---

## 1. GNNåŸºç¡€ç†è®º

### 1.1 å›¾ç¥ç»ç½‘ç»œæ¦‚è¿°

å›¾ç¥ç»ç½‘ç»œ(Graph Neural Networks, GNN)æ˜¯ä¸“é—¨å¤„ç†å›¾ç»“æ„æ•°æ®çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚åœ¨çŸ¥è¯†å›¾è°±é¢†åŸŸï¼ŒGNNèƒ½å¤Ÿå­¦ä¹ å®ä½“å’Œå…³ç³»çš„è¡¨ç¤ºï¼Œå¹¶è¿›è¡Œå„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚

#### ä¸ºä»€ä¹ˆéœ€è¦GNNï¼Ÿ

```text
ä¼ ç»Ÿæ–¹æ³•å±€é™æ€§:
âŒ æ— æ³•å¤„ç†å›¾ç»“æ„ä¿¡æ¯
âŒ éš¾ä»¥æ•è·é‚»å±…èŠ‚ç‚¹çš„å½±å“
âŒ ç¼ºä¹ç»“æ„æ„ŸçŸ¥èƒ½åŠ›

GNNä¼˜åŠ¿:
âœ… ç›´æ¥åœ¨å›¾ç»“æ„ä¸Šæ“ä½œ
âœ… é€šè¿‡æ¶ˆæ¯ä¼ é€’èšåˆé‚»å±…ä¿¡æ¯
âœ… å­¦ä¹ ç»“æ„æ„ŸçŸ¥çš„èŠ‚ç‚¹è¡¨ç¤º
âœ… ç«¯åˆ°ç«¯å¯è®­ç»ƒ
```

### 1.2 GNNæ ¸å¿ƒæ¦‚å¿µ

#### æ¶ˆæ¯ä¼ é€’æœºåˆ¶

GNNçš„æ ¸å¿ƒæ˜¯æ¶ˆæ¯ä¼ é€’(Message Passing)æœºåˆ¶ï¼š

```python
class MessagePassing:
    """
    æ¶ˆæ¯ä¼ é€’åŸºç¡€æ¡†æ¶

    æ ¸å¿ƒå…¬å¼:
    h_v^(l+1) = UPDATE(h_v^(l), AGGREGATE({MESSAGE(h_u^(l), h_v^(l), e_uv) | u âˆˆ N(v)}))
    """

    def message(self, x_i, x_j, edge_attr):
        """
        æ¶ˆæ¯å‡½æ•°: ç”Ÿæˆä»èŠ‚ç‚¹jåˆ°èŠ‚ç‚¹içš„æ¶ˆæ¯

        Args:
            x_i: ç›®æ ‡èŠ‚ç‚¹içš„ç‰¹å¾
            x_j: æºèŠ‚ç‚¹jçš„ç‰¹å¾
            edge_attr: è¾¹çš„ç‰¹å¾

        Returns:
            æ¶ˆæ¯å‘é‡
        """
        # åŸºç¡€å®ç°ï¼šä»…ä¼ é€’é‚»å±…ç‰¹å¾
        return x_j

    def aggregate(self, messages, index, dim_size):
        """
        èšåˆå‡½æ•°: èšåˆæ¥è‡ªæ‰€æœ‰é‚»å±…çš„æ¶ˆæ¯

        Args:
            messages: æ‰€æœ‰æ¶ˆæ¯
            index: ç›®æ ‡èŠ‚ç‚¹ç´¢å¼•
            dim_size: èŠ‚ç‚¹æ•°é‡

        Returns:
            èšåˆåçš„æ¶ˆæ¯
        """
        # åŸºç¡€å®ç°ï¼šæ±‚å’Œèšåˆ
        from torch_scatter import scatter
        return scatter(messages, index, dim=0, dim_size=dim_size, reduce='sum')

    def update(self, aggr_out, x):
        """
        æ›´æ–°å‡½æ•°: æ›´æ–°èŠ‚ç‚¹è¡¨ç¤º

        Args:
            aggr_out: èšåˆåçš„æ¶ˆæ¯
            x: åŸå§‹èŠ‚ç‚¹ç‰¹å¾

        Returns:
            æ›´æ–°åçš„èŠ‚ç‚¹ç‰¹å¾
        """
        # åŸºç¡€å®ç°ï¼šç›´æ¥ä½¿ç”¨èšåˆç»“æœ
        return aggr_out
```

#### å›¾è¡¨ç¤ºå­¦ä¹ 

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops, degree

class BasicGNN(MessagePassing):
    """åŸºç¡€GNNå±‚"""

    def __init__(self, in_channels, out_channels):
        super(BasicGNN, self).__init__(aggr='add')  # èšåˆæ–¹å¼: sum
        self.lin = nn.Linear(in_channels, out_channels)

    def forward(self, x, edge_index):
        """
        Args:
            x: èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ [N, in_channels]
            edge_index: è¾¹ç´¢å¼• [2, E]
        """
        # æ·»åŠ è‡ªç¯
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))

        # ç‰¹å¾å˜æ¢
        x = self.lin(x)

        # æ¶ˆæ¯ä¼ é€’
        return self.propagate(edge_index, x=x)

    def message(self, x_j):
        """æ¶ˆæ¯: ä¼ é€’é‚»å±…ç‰¹å¾"""
        return x_j
```

### 1.3 GNNæ¶æ„ç±»å‹

#### å·ç§¯ç±»GNN

åŸºäºå›¾å·ç§¯çš„æ¨¡å‹ï¼Œé€šè¿‡å·ç§¯æ“ä½œèšåˆé‚»å±…ä¿¡æ¯ï¼š

```python
from torch_geometric.nn import GCNConv

class GCNLayer(nn.Module):
    """å›¾å·ç§¯å±‚"""

    def __init__(self, in_channels, out_channels):
        super(GCNLayer, self).__init__()
        self.conv = GCNConv(in_channels, out_channels)
        self.bn = nn.BatchNorm1d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x, edge_index):
        x = self.conv(x, edge_index)
        x = self.bn(x)
        x = self.relu(x)
        return x
```

#### æ³¨æ„åŠ›ç±»GNN

ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€å­¦ä¹ é‚»å±…æƒé‡ï¼š

```python
from torch_geometric.nn import GATConv

class GATLayer(nn.Module):
    """å›¾æ³¨æ„åŠ›å±‚"""

    def __init__(self, in_channels, out_channels, heads=8, dropout=0.6):
        super(GATLayer, self).__init__()
        self.conv = GATConv(
            in_channels,
            out_channels,
            heads=heads,
            dropout=dropout,
            concat=True
        )

    def forward(self, x, edge_index):
        return self.conv(x, edge_index)
```

#### é‡‡æ ·ç±»GNN

é€šè¿‡é‡‡æ ·é‚»å±…èŠ‚ç‚¹å¤„ç†å¤§è§„æ¨¡å›¾ï¼š

```python
from torch_geometric.nn import SAGEConv

class GraphSAGELayer(nn.Module):
    """GraphSAGEå±‚"""

    def __init__(self, in_channels, out_channels):
        super(GraphSAGELayer, self).__init__()
        self.conv = SAGEConv(in_channels, out_channels)

    def forward(self, x, edge_index):
        return self.conv(x, edge_index)
```

---

## 2. çŸ¥è¯†å›¾è°±ä¸­çš„GNNåº”ç”¨

### 2.1 èŠ‚ç‚¹åˆ†ç±»

ä½¿ç”¨GNNå¯¹çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“è¿›è¡Œåˆ†ç±»ã€‚

#### å®ç°ç¤ºä¾‹

```python
import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data

class KGNodeClassifier(nn.Module):
    """çŸ¥è¯†å›¾è°±èŠ‚ç‚¹åˆ†ç±»å™¨"""

    def __init__(self, num_features, hidden_dim, num_classes, num_layers=2):
        super(KGNodeClassifier, self).__init__()
        self.num_layers = num_layers

        # GCNå±‚
        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(num_features, hidden_dim))
        for _ in range(num_layers - 2):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))
        if num_layers > 1:
            self.convs.append(GCNConv(hidden_dim, num_classes))
        else:
            self.convs.append(GCNConv(num_features, num_classes))

        self.dropout = nn.Dropout(0.5)

    def forward(self, x, edge_index):
        """å‰å‘ä¼ æ’­"""
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = F.relu(x)
            x = self.dropout(x)

        x = self.convs[-1](x, edge_index)
        return F.log_softmax(x, dim=1)

# ä½¿ç”¨ç¤ºä¾‹
def train_node_classifier(graph_data, labels, train_mask, val_mask, test_mask):
    """è®­ç»ƒèŠ‚ç‚¹åˆ†ç±»å™¨"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = KGNodeClassifier(
        num_features=graph_data.num_features,
        hidden_dim=64,
        num_classes=labels.max().item() + 1,
        num_layers=2
    ).to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
    criterion = nn.NLLLoss()

    graph_data = graph_data.to(device)
    labels = labels.to(device)

    for epoch in range(200):
        model.train()
        optimizer.zero_grad()

        # å‰å‘ä¼ æ’­
        out = model(graph_data.x, graph_data.edge_index)

        # æŸå¤±è®¡ç®—ï¼ˆä»…è®­ç»ƒé›†ï¼‰
        loss = criterion(out[train_mask], labels[train_mask])

        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()

        # éªŒè¯
        if epoch % 10 == 0:
            model.eval()
            with torch.no_grad():
                val_out = model(graph_data.x, graph_data.edge_index)
                val_loss = criterion(val_out[val_mask], labels[val_mask])
                val_pred = val_out[val_mask].argmax(dim=1)
                val_acc = (val_pred == labels[val_mask]).sum().item() / val_mask.sum().item()

                print(f'Epoch {epoch}, Loss: {loss.item():.4f}, '
                      f'Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.4f}')

    return model
```

### 2.2 å…³ç³»é¢„æµ‹ï¼ˆé“¾æ¥é¢„æµ‹ï¼‰

é¢„æµ‹çŸ¥è¯†å›¾è°±ä¸­ç¼ºå¤±çš„å…³ç³»ï¼ˆä¸‰å…ƒç»„ï¼‰ã€‚

#### TransEé£æ ¼çš„é“¾æ¥é¢„æµ‹

```python
class LinkPredictor(nn.Module):
    """é“¾æ¥é¢„æµ‹å™¨ï¼ˆåŸºäºåµŒå…¥ï¼‰"""

    def __init__(self, num_entities, num_relations, embedding_dim=100):
        super(LinkPredictor, self).__init__()
        self.embedding_dim = embedding_dim

        # å®ä½“åµŒå…¥
        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)
        # å…³ç³»åµŒå…¥
        self.relation_embedding = nn.Embedding(num_relations, embedding_dim)

        # åˆå§‹åŒ–
        nn.init.xavier_uniform_(self.entity_embedding.weight.data)
        nn.init.xavier_uniform_(self.relation_embedding.weight.data)

    def forward(self, head, relation, tail):
        """
        TransEè¯„åˆ†å‡½æ•°: f(h, r, t) = -||h + r - t||

        Args:
            head: å¤´å®ä½“ID [batch_size]
            relation: å…³ç³»ID [batch_size]
            tail: å°¾å®ä½“ID [batch_size]
        """
        h = self.entity_embedding(head)  # [batch_size, embedding_dim]
        r = self.relation_embedding(relation)  # [batch_size, embedding_dim]
        t = self.entity_embedding(tail)  # [batch_size, embedding_dim]

        # TransEè¯„åˆ†
        score = h + r - t
        score = torch.norm(score, p=2, dim=1)
        return -score  # è´Ÿè·ç¦»ä½œä¸ºåˆ†æ•°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰

# è®­ç»ƒ
def train_link_predictor(model, train_triples, num_epochs=100):
    """è®­ç»ƒé“¾æ¥é¢„æµ‹å™¨"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0

        for batch in train_triples:  # batch: (head, relation, tail, neg_head, neg_tail)
            head, relation, tail, neg_head, neg_tail = batch
            head, relation, tail = head.to(device), relation.to(device), tail.to(device)
            neg_head, neg_tail = neg_head.to(device), neg_tail.to(device)

            optimizer.zero_grad()

            # æ­£æ ·æœ¬åˆ†æ•°
            pos_score = model(head, relation, tail)

            # è´Ÿæ ·æœ¬åˆ†æ•°ï¼ˆéšæœºæ›¿æ¢å¤´æˆ–å°¾å®ä½“ï¼‰
            neg_score_head = model(neg_head, relation, tail)
            neg_score_tail = model(head, relation, neg_tail)

            # å¯¹æ¯”æŸå¤±ï¼ˆMargin Lossï¼‰
            margin = 1.0
            loss = F.relu(margin - pos_score + neg_score_head).mean() + \
                   F.relu(margin - pos_score + neg_score_tail).mean()

            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        if epoch % 10 == 0:
            print(f'Epoch {epoch}, Loss: {total_loss / len(train_triples):.4f}')

    return model
```

#### GNN-basedé“¾æ¥é¢„æµ‹

```python
from torch_geometric.nn import RGCNConv

class GNNLinkPredictor(nn.Module):
    """åŸºäºGNNçš„é“¾æ¥é¢„æµ‹å™¨"""

    def __init__(self, num_entities, num_relations, embedding_dim=64, hidden_dim=64):
        super(GNNLinkPredictor, self).__init__()
        self.num_entities = num_entities
        self.num_relations = num_relations

        # å®ä½“åµŒå…¥ï¼ˆåˆå§‹åŒ–ï¼‰
        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)

        # RGCNå±‚ï¼ˆå…³ç³»å›¾å·ç§¯ï¼‰
        self.conv1 = RGCNConv(embedding_dim, hidden_dim, num_relations, num_bases=30)
        self.conv2 = RGCNConv(hidden_dim, embedding_dim, num_relations, num_bases=30)

        self.dropout = nn.Dropout(0.2)

    def forward(self, x, edge_index, edge_type):
        """é€šè¿‡RGCNè·å–å®ä½“è¡¨ç¤º"""
        x = self.entity_embedding(x)
        x = self.conv1(x, edge_index, edge_type)
        x = F.relu(x)
        x = self.dropout(x)
        x = self.conv2(x, edge_index, edge_type)
        return x

    def predict(self, entity_embeddings, head, relation, tail):
        """é¢„æµ‹é“¾æ¥"""
        h = entity_embeddings[head]
        r = self.relation_embedding(relation)  # éœ€è¦å®šä¹‰å…³ç³»åµŒå…¥
        t = entity_embeddings[tail]

        # DistMultè¯„åˆ†å‡½æ•°
        score = torch.sum(h * r * t, dim=1)
        return score
```

### 2.3 å®ä½“å¯¹é½

ä½¿ç”¨GNNå¯¹é½ä¸åŒçŸ¥è¯†å›¾è°±ä¸­çš„ç›¸åŒå®ä½“ã€‚

```python
class EntityAlignmentGNN(nn.Module):
    """å®ä½“å¯¹é½GNN"""

    def __init__(self, num_features, hidden_dim, embedding_dim):
        super(EntityAlignmentGNN, self).__init__()
        self.conv1 = GCNConv(num_features, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, embedding_dim)

    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)
        return F.normalize(x, p=2, dim=1)  # L2å½’ä¸€åŒ–

def align_entities(model, graph1, graph2, seed_alignments):
    """
    å¯¹é½ä¸¤ä¸ªçŸ¥è¯†å›¾è°±çš„å®ä½“

    Args:
        model: GNNæ¨¡å‹
        graph1: ç¬¬ä¸€ä¸ªçŸ¥è¯†å›¾è°±
        graph2: ç¬¬äºŒä¸ªçŸ¥è¯†å›¾è°±
        seed_alignments: ç§å­å¯¹é½å¯¹ [(entity1_id, entity2_id), ...]
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    # è·å–å®ä½“åµŒå…¥
    with torch.no_grad():
        emb1 = model(graph1.x, graph1.edge_index).cpu().numpy()
        emb2 = model(graph2.x, graph2.edge_index).cpu().numpy()

    # ä½¿ç”¨ç§å­å¯¹é½è®­ç»ƒå¯¹é½æ¨¡å‹ï¼ˆå¦‚çº¿æ€§å˜æ¢ï¼‰
    from sklearn.linear_model import LinearRegression

    seed_emb1 = emb1[[e1 for e1, e2 in seed_alignments]]
    seed_emb2 = emb2[[e2 for e1, e2 in seed_alignments]]

    align_model = LinearRegression()
    align_model.fit(seed_emb1, seed_emb2)

    # å¯¹é½æ‰€æœ‰å®ä½“
    aligned_emb2 = align_model.predict(emb1)

    # æŸ¥æ‰¾æœ€è¿‘é‚»
    from sklearn.metrics.pairwise import cosine_similarity
    similarity = cosine_similarity(emb2, aligned_emb2)

    # è¿”å›å¯¹é½ç»“æœ
    alignments = []
    for i in range(len(emb1)):
        best_match = similarity[:, i].argmax()
        alignments.append((i, best_match, similarity[best_match, i]))

    return alignments
```

### 2.4 çŸ¥è¯†å›¾è°±è¡¥å…¨

ä½¿ç”¨GNNè¡¥å…¨ç¼ºå¤±çš„ä¸‰å…ƒç»„ã€‚

```python
class KGCompletionGNN(nn.Module):
    """çŸ¥è¯†å›¾è°±è¡¥å…¨GNN"""

    def __init__(self, num_entities, num_relations, embedding_dim=100):
        super(KGCompletionGNN, self).__init__()
        self.embedding_dim = embedding_dim

        # å®ä½“å’Œå…³ç³»åµŒå…¥
        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)
        self.relation_embedding = nn.Embedding(num_relations, embedding_dim)

        # GNNå±‚
        self.conv1 = RGCNConv(embedding_dim, embedding_dim, num_relations)
        self.conv2 = RGCNConv(embedding_dim, embedding_dim, num_relations)

    def forward(self, edge_index, edge_type):
        """é€šè¿‡RGCNè·å–å®ä½“è¡¨ç¤º"""
        x = self.entity_embedding.weight
        x = self.conv1(x, edge_index, edge_type)
        x = F.relu(x)
        x = self.conv2(x, edge_index, edge_type)
        return x

    def score(self, head, relation, tail):
        """ComplExè¯„åˆ†å‡½æ•°"""
        h = self.entity_embedding(head)
        r = self.relation_embedding(relation)
        t = self.entity_embedding(tail)

        # ComplEx: Re(<h, r, conj(t)>)
        score = torch.sum(
            torch.real(torch.conj(h) * r * torch.conj(t)),
            dim=1
        )
        return score

def complete_kg(model, graph, query_head, query_relation, k=10):
    """
    è¡¥å…¨çŸ¥è¯†å›¾è°±

    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        query_head: æŸ¥è¯¢å¤´å®ä½“
        query_relation: æŸ¥è¯¢å…³ç³»
        k: è¿”å›Top Kå€™é€‰

    Returns:
        Top Kå°¾å®ä½“å€™é€‰
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.eval()

    # è·å–å®ä½“è¡¨ç¤º
    with torch.no_grad():
        entity_embeddings = model(graph.edge_index, graph.edge_type)

    h = entity_embeddings[query_head]
    r = model.relation_embedding(torch.tensor([query_relation]).to(device))

    # è®¡ç®—ä¸æ‰€æœ‰å®ä½“çš„åˆ†æ•°
    scores = model.score(
        torch.full((entity_embeddings.size(0),), query_head).to(device),
        torch.full((entity_embeddings.size(0),), query_relation).to(device),
        torch.arange(entity_embeddings.size(0)).to(device)
    )

    # è¿”å›Top K
    top_k_scores, top_k_indices = torch.topk(scores, k)
    return top_k_indices.cpu().tolist(), top_k_scores.cpu().tolist()
```

---

## 3. GNNæ¨¡å‹è¯¦è§£

### 3.1 GCN (Graph Convolutional Network)

GCNæ˜¯æœ€åŸºç¡€çš„å›¾å·ç§¯ç½‘ç»œã€‚

#### å®ç°

```python
class GCN(nn.Module):
    """å›¾å·ç§¯ç½‘ç»œ"""

    def __init__(self, num_features, hidden_dim, num_classes, num_layers=2, dropout=0.5):
        super(GCN, self).__init__()
        self.convs = nn.ModuleList()

        # ç¬¬ä¸€å±‚
        self.convs.append(GCNConv(num_features, hidden_dim))

        # ä¸­é—´å±‚
        for _ in range(num_layers - 2):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))

        # è¾“å‡ºå±‚
        self.convs.append(GCNConv(hidden_dim, num_classes))

        self.dropout = nn.Dropout(dropout)

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = F.relu(x)
            x = self.dropout(x)

        x = self.convs[-1](x, edge_index)
        return F.log_softmax(x, dim=1)
```

### 3.2 GraphSAGE

GraphSAGEé€šè¿‡é‡‡æ ·å’Œèšåˆé‚»å±…èŠ‚ç‚¹å¤„ç†å¤§è§„æ¨¡å›¾ã€‚

```python
from torch_geometric.nn import SAGEConv

class GraphSAGE(nn.Module):
    """GraphSAGEæ¨¡å‹"""

    def __init__(self, num_features, hidden_dim, num_classes, num_layers=2):
        super(GraphSAGE, self).__init__()
        self.convs = nn.ModuleList()

        self.convs.append(SAGEConv(num_features, hidden_dim))
        for _ in range(num_layers - 2):
            self.convs.append(SAGEConv(hidden_dim, hidden_dim))
        self.convs.append(SAGEConv(hidden_dim, num_classes))

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = F.relu(x)
        x = self.convs[-1](x, edge_index)
        return F.log_softmax(x, dim=1)
```

### 3.3 GAT (Graph Attention Network)

GATä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ é‚»å±…æƒé‡ã€‚

```python
from torch_geometric.nn import GATConv

class GAT(nn.Module):
    """å›¾æ³¨æ„åŠ›ç½‘ç»œ"""

    def __init__(self, num_features, hidden_dim, num_classes, heads=8, dropout=0.6):
        super(GAT, self).__init__()
        self.conv1 = GATConv(num_features, hidden_dim, heads=heads, dropout=dropout)
        self.conv2 = GATConv(hidden_dim * heads, num_classes, heads=1, dropout=dropout)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x, edge_index):
        x = self.dropout(x)
        x = F.elu(self.conv1(x, edge_index))
        x = self.dropout(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)
```

### 3.4 RGCN (Relational GCN)

RGCNä¸“é—¨å¤„ç†å¤šå…³ç³»å›¾ï¼ˆå¦‚çŸ¥è¯†å›¾è°±ï¼‰ã€‚

```python
from torch_geometric.nn import RGCNConv

class RGCN(nn.Module):
    """å…³ç³»å›¾å·ç§¯ç½‘ç»œ"""

    def __init__(self, num_entities, num_relations, embedding_dim, hidden_dim, num_classes):
        super(RGCN, self).__init__()
        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)
        self.conv1 = RGCNConv(embedding_dim, hidden_dim, num_relations, num_bases=30)
        self.conv2 = RGCNConv(hidden_dim, num_classes, num_relations, num_bases=30)

    def forward(self, edge_index, edge_type):
        x = self.entity_embedding.weight
        x = F.relu(self.conv1(x, edge_index, edge_type))
        x = self.conv2(x, edge_index, edge_type)
        return F.log_softmax(x, dim=1)
```

---

## 4. çŸ¥è¯†å›¾è°±åµŒå…¥

### 4.1 TransEä¸Transå®¶æ—

TransEæ˜¯ç»å…¸çš„KGåµŒå…¥æ–¹æ³•ã€‚

```python
class TransE(nn.Module):
    """TransEæ¨¡å‹"""

    def __init__(self, num_entities, num_relations, embedding_dim=100, margin=1.0):
        super(TransE, self).__init__()
        self.margin = margin
        self.embedding_dim = embedding_dim

        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)
        self.relation_embedding = nn.Embedding(num_relations, embedding_dim)

        # åˆå§‹åŒ–
        nn.init.xavier_uniform_(self.entity_embedding.weight.data)
        nn.init.xavier_uniform_(self.relation_embedding.weight.data)

    def forward(self, head, relation, tail):
        """TransEè¯„åˆ†: -||h + r - t||"""
        h = F.normalize(self.entity_embedding(head), p=2, dim=1)
        r = self.relation_embedding(relation)
        t = F.normalize(self.entity_embedding(tail), p=2, dim=1)

        score = h + r - t
        return -torch.norm(score, p=2, dim=1)
```

---

*[ç”±äºç¯‡å¹…é™åˆ¶ï¼Œæœ¬æ–‡æ¡£åç»­ç« èŠ‚ï¼ˆComplExä¸RotatEã€GNN-basedåµŒå…¥ã€å®è·µæ¡ˆä¾‹ã€æ€§èƒ½ä¼˜åŒ–ï¼‰å°†åœ¨ä¸‹ä¸€ç‰ˆæœ¬è¡¥å……]*

---

## ğŸ“š å‚è€ƒèµ„æº

1. **PyTorch Geometric**: <https://pytorch-geometric.readthedocs.io/>
2. **DGL**: <https://www.dgl.ai/>
3. **GNNç»¼è¿°**: <https://arxiv.org/abs/1812.08434>
4. **KGåµŒå…¥ç»¼è¿°**: <https://arxiv.org/abs/2003.08019>

---

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0** (2025-01): åˆå§‹ç‰ˆæœ¬
  - GNNåŸºç¡€ç†è®º
  - çŸ¥è¯†å›¾è°±ä¸­çš„GNNåº”ç”¨
  - å¸¸ç”¨GNNæ¨¡å‹å®ç°
  - çŸ¥è¯†å›¾è°±åµŒå…¥åŸºç¡€

---

**ä¸‹ä¸€æ­¥**: è¡¥å……æ›´å¤šåµŒå…¥æ–¹æ³•ã€å®è·µæ¡ˆä¾‹å’Œæ€§èƒ½ä¼˜åŒ–ç« èŠ‚ | [è¿”å›ç›®å½•](./README.md)
