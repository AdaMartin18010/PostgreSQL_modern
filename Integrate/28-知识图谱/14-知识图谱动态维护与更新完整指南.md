---
> **📋 文档来源**: 新增深化文档
> **📅 创建日期**: 2025-01
> **⚠️ 注意**: 本文档聚焦知识图谱的动态维护、自动更新和扩展

---

# 知识图谱动态维护与更新完整指南

## 元数据

- **文档版本**: v1.0
- **创建日期**: 2025-01
- **技术栈**: PostgreSQL 17+/18+ | Apache AGE | GNN | TaxoExpan | 增量更新
- **难度级别**: ⭐⭐⭐⭐⭐ (专家级)
- **预计阅读**: 150分钟
- **前置要求**: 熟悉知识图谱基础、图神经网络、知识抽取

---

## 📋 完整目录

- [知识图谱动态维护与更新完整指南](#知识图谱动态维护与更新完整指南)
  - [元数据](#元数据)
  - [📋 完整目录](#-完整目录)
  - [1. 知识图谱维护概述](#1-知识图谱维护概述)
    - [1.1 维护挑战](#11-维护挑战)
      - [主要挑战](#主要挑战)
    - [1.2 维护策略](#12-维护策略)
      - [维护模式](#维护模式)
    - [1.3 维护流程](#13-维护流程)
      - [标准维护流程](#标准维护流程)
  - [2. 自监督扩展：TaxoExpan](#2-自监督扩展taxoexpan)
    - [2.1 TaxoExpan原理](#21-taxoexpan原理)
      - [核心思想](#核心思想)
      - [技术优势](#技术优势)
    - [2.2 位置增强GNN](#22-位置增强gnn)
      - [GNN架构](#gnn架构)
    - [2.3 训练数据自动生成](#23-训练数据自动生成)
      - [数据生成策略](#数据生成策略)
    - [2.4 TaxoExpan实现](#24-taxoexpan实现)
      - [完整实现](#完整实现)
  - [3. 增量更新策略](#3-增量更新策略)
    - [3.1 增量更新架构](#31-增量更新架构)
      - [架构设计](#架构设计)
    - [3.2 变更检测](#32-变更检测)
      - [变更检测实现](#变更检测实现)
    - [3.3 增量合并](#33-增量合并)
      - [增量合并实现](#增量合并实现)
  - [4. 知识冲突检测与解决](#4-知识冲突检测与解决)
    - [4.1 冲突类型](#41-冲突类型)
      - [冲突分类](#冲突分类)
    - [4.2 冲突检测算法](#42-冲突检测算法)
      - [冲突检测实现](#冲突检测实现)
    - [4.3 冲突解决策略](#43-冲突解决策略)
      - [解决策略](#解决策略)
    - [4.4 冲突解决实现](#44-冲突解决实现)
  - [5. 版本管理与回滚](#5-版本管理与回滚)
    - [5.1 版本管理策略](#51-版本管理策略)
      - [版本表设计](#版本表设计)
    - [5.2 快照与检查点](#52-快照与检查点)
      - [快照创建](#快照创建)
    - [5.3 版本查询](#53-版本查询)
      - [时间旅行查询](#时间旅行查询)
    - [5.4 回滚机制](#54-回滚机制)
  - [6. 知识质量保证](#6-知识质量保证)
    - [6.1 质量评估指标](#61-质量评估指标)
      - [质量指标](#质量指标)
  - [📚 参考资源](#-参考资源)
  - [📝 更新日志](#-更新日志)

---

## 1. 知识图谱维护概述

### 1.1 维护挑战

#### 主要挑战

```text
挑战1: 知识更新频率高
- 新知识不断产生
- 旧知识需要更新
- 错误知识需要纠正

挑战2: 知识冲突
- 不同来源的知识可能冲突
- 需要冲突检测与解决机制

挑战3: 一致性维护
- 实体关系一致性
- 模式一致性
- 数据一致性

挑战4: 版本管理
- 知识图谱版本控制
- 变更追踪
- 回滚机制

挑战5: 质量保证
- 知识准确性
- 知识完整性
- 知识时效性
```

### 1.2 维护策略

#### 维护模式

```text
模式1: 实时更新
- 检测到变更立即更新
- 适合: 实时性要求高的场景
- 缺点: 可能影响查询性能

模式2: 批量更新
- 定期批量处理更新
- 适合: 大规模更新
- 缺点: 延迟较高

模式3: 增量更新（推荐）
- 只处理变更部分
- 平衡实时性和性能
- 适合大多数场景

模式4: 混合更新
- 关键知识实时更新
- 非关键知识批量更新
```

### 1.3 维护流程

#### 标准维护流程

```text
1. 变更检测
   ├─ 数据源监控
   ├─ 变更识别
   └─ 变更分类

2. 变更验证
   ├─ 格式验证
   ├─ 语义验证
   └─ 冲突检测

3. 变更应用
   ├─ 实体更新
   ├─ 关系更新
   └─ 属性更新

4. 一致性检查
   ├─ 模式一致性
   ├─ 数据一致性
   └─ 完整性检查

5. 质量评估
   ├─ 准确性评估
   ├─ 完整性评估
   └─ 时效性评估

6. 版本管理
   ├─ 创建版本快照
   ├─ 记录变更日志
   └─ 更新版本号
```

---

## 2. 自监督扩展：TaxoExpan

### 2.1 TaxoExpan原理

TaxoExpan是一种自监督的分类扩展方法，利用位置增强的图神经网络来自动生成训练数据，以预测新概念与现有分类之间的关系。

#### 核心思想

```text
传统方法:
需要标注数据 → 训练模型 → 扩展分类

TaxoExpan:
现有分类 → 自动生成训练数据 → 训练GNN模型 → 扩展分类
          (自监督学习)
```

#### 技术优势

- ✅ **无需标注数据**: 自动生成训练数据
- ✅ **位置感知**: 利用图神经网络增强位置感知
- ✅ **高效扩展**: 快速扩展分类体系
- ✅ **高质量**: 生成高质量的分类关系

### 2.2 位置增强GNN

#### GNN架构

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv

class PositionEnhancedGNN(nn.Module):
    """位置增强的图神经网络"""

    def __init__(self, num_features, hidden_dim, num_layers=2):
        super(PositionEnhancedGNN, self).__init__()

        # GCN层
        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(num_features, hidden_dim))
        for _ in range(num_layers - 1):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))

        # 位置编码
        self.position_embedding = nn.Embedding(1000, hidden_dim)  # 假设最大深度1000

    def forward(self, x, edge_index, positions):
        """
        Args:
            x: 节点特征
            edge_index: 边索引
            positions: 节点在图中的位置（深度）
        """
        # GCN传播
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            x = F.relu(x)
            if i < len(self.convs) - 1:
                x = F.dropout(x, training=self.training)

        # 位置增强
        pos_emb = self.position_embedding(positions)
        x = x + pos_emb  # 位置信息融合

        return x
```

### 2.3 训练数据自动生成

#### 数据生成策略

```python
class TaxoExpanDataGenerator:
    """TaxoExpan训练数据生成器"""

    def __init__(self, taxonomy_graph):
        self.taxonomy = taxonomy_graph

    def generate_training_data(self):
        """
        自动生成训练数据

        策略:
        1. 从现有分类中采样正样本（父子关系）
        2. 随机组合生成负样本（非父子关系）
        3. 使用位置信息增强样本
        """
        positive_samples = []
        negative_samples = []

        # 生成正样本（现有的父子关系）
        for parent, children in self.taxonomy.items():
            for child in children:
                positive_samples.append({
                    'parent': parent,
                    'child': child,
                    'label': 1,  # 正样本
                    'position': self._get_position(parent)  # 位置信息
                })

        # 生成负样本（随机组合，非父子关系）
        all_concepts = list(self.taxonomy.keys()) + \
                      [c for children in self.taxonomy.values() for c in children]

        for _ in range(len(positive_samples)):
            parent = random.choice(all_concepts)
            child = random.choice(all_concepts)

            # 确保不是父子关系
            if child not in self.taxonomy.get(parent, []):
                negative_samples.append({
                    'parent': parent,
                    'child': child,
                    'label': 0,  # 负样本
                    'position': self._get_position(parent)
                })

        return positive_samples + negative_samples

    def _get_position(self, concept):
        """获取概念在分类体系中的位置（深度）"""
        # 计算从根节点到该节点的深度
        return self._calculate_depth(concept)
```

### 2.4 TaxoExpan实现

#### 完整实现

```python
class TaxoExpan:
    """TaxoExpan分类扩展系统"""

    def __init__(self, taxonomy_graph, embedding_model):
        self.taxonomy = taxonomy_graph
        self.embedding_model = embedding_model
        self.gnn_model = PositionEnhancedGNN(
            num_features=embedding_model.embedding_dim,
            hidden_dim=128,
            num_layers=2
        )

    def train(self):
        """训练模型"""
        # 1. 生成训练数据
        data_generator = TaxoExpanDataGenerator(self.taxonomy)
        training_data = data_generator.generate_training_data()

        # 2. 准备图数据
        graph_data = self._build_graph()

        # 3. 训练GNN模型
        optimizer = torch.optim.Adam(self.gnn_model.parameters(), lr=0.01)
        criterion = nn.BCEWithLogitsLoss()

        for epoch in range(100):
            self.gnn_model.train()
            optimizer.zero_grad()

            # 获取节点嵌入
            node_embeddings = self.gnn_model(
                graph_data.x,
                graph_data.edge_index,
                graph_data.positions
            )

            # 计算损失
            total_loss = 0
            for sample in training_data:
                parent_emb = node_embeddings[sample['parent_id']]
                child_emb = node_embeddings[sample['child_id']]

                # 预测是否为父子关系
                score = torch.dot(parent_emb, child_emb)
                loss = criterion(score, torch.tensor(sample['label'], dtype=torch.float))
                total_loss += loss

            total_loss.backward()
            optimizer.step()

    def expand(self, new_concepts: List[str], top_k: int = 5) -> Dict[str, List[str]]:
        """
        扩展分类体系

        Args:
            new_concepts: 新概念列表
            top_k: 为每个新概念返回top-k个可能的父节点

        Returns:
            {concept: [parent_candidates]}
        """
        results = {}

        # 获取所有现有概念的嵌入
        graph_data = self._build_graph()
        self.gnn_model.eval()
        with torch.no_grad():
            node_embeddings = self.gnn_model(
                graph_data.x,
                graph_data.edge_index,
                graph_data.positions
            )

        # 为每个新概念找到最佳父节点
        for concept in new_concepts:
            concept_emb = self.embedding_model.encode(concept)

            # 计算与所有现有概念的相似度
            similarities = []
            for parent_id, parent_emb in enumerate(node_embeddings):
                similarity = F.cosine_similarity(
                    concept_emb.unsqueeze(0),
                    parent_emb.unsqueeze(0)
                )
                similarities.append((parent_id, similarity.item()))

            # 选择top-k
            similarities.sort(key=lambda x: x[1], reverse=True)
            top_parents = [self.taxonomy.concept_by_id(id) for id, _ in similarities[:top_k]]

            results[concept] = top_parents

        return results
```

---

## 3. 增量更新策略

### 3.1 增量更新架构

#### 架构设计

```text
数据源
  ↓
变更检测器
  ├─ 变更识别
  ├─ 变更分类
  └─ 变更优先级
  ↓
变更验证器
  ├─ 格式验证
  ├─ 语义验证
  └─ 冲突检测
  ↓
增量更新引擎
  ├─ 实体更新
  ├─ 关系更新
  └─ 属性更新
  ↓
一致性检查器
  ├─ 模式一致性
  ├─ 数据一致性
  └─ 完整性检查
  ↓
知识图谱
```

### 3.2 变更检测

#### 变更检测实现

```python
class ChangeDetector:
    """知识图谱变更检测器"""

    def __init__(self, db_connection):
        self.conn = db_connection
        self.cursor = self.conn.cursor()

    def detect_changes(self, source_data: List[Dict], last_sync_time: TIMESTAMPTZ) -> List[Dict]:
        """
        检测知识图谱变更

        Args:
            source_data: 数据源数据
            last_sync_time: 上次同步时间

        Returns:
            变更列表: [{type: 'add'|'update'|'delete', entity: {...}}]
        """
        changes = []

        # 获取当前知识图谱状态
        current_entities = self._get_current_entities()
        current_relations = self._get_current_relations()

        # 检测新增实体
        source_entity_ids = {e['id'] for e in source_data}
        current_entity_ids = {e['id'] for e in current_entities}

        new_entity_ids = source_entity_ids - current_entity_ids
        for entity_id in new_entity_ids:
            entity = next(e for e in source_data if e['id'] == entity_id)
            changes.append({
                'type': 'add',
                'entity_type': 'entity',
                'data': entity
            })

        # 检测更新实体
        updated_entity_ids = source_entity_ids & current_entity_ids
        for entity_id in updated_entity_ids:
            source_entity = next(e for e in source_data if e['id'] == entity_id)
            current_entity = next(e for e in current_entities if e['id'] == entity_id)

            if self._has_changed(source_entity, current_entity):
                changes.append({
                    'type': 'update',
                    'entity_type': 'entity',
                    'data': source_entity,
                    'old_data': current_entity
                })

        # 检测删除实体
        deleted_entity_ids = current_entity_ids - source_entity_ids
        for entity_id in deleted_entity_ids:
            entity = next(e for e in current_entities if e['id'] == entity_id)
            changes.append({
                'type': 'delete',
                'entity_type': 'entity',
                'data': entity
            })

        return changes

    def _has_changed(self, source_entity: Dict, current_entity: Dict) -> bool:
        """检查实体是否发生变化"""
        # 比较关键属性
        key_attrs = ['name', 'type', 'properties']
        for attr in key_attrs:
            if source_entity.get(attr) != current_entity.get(attr):
                return True
        return False
```

### 3.3 增量合并

#### 增量合并实现

```python
class IncrementalMerger:
    """增量合并器"""

    def __init__(self, db_connection):
        self.conn = db_connection
        self.cursor = self.conn.cursor()

    def merge_changes(self, changes: List[Dict]):
        """
        合并变更到知识图谱

        Args:
            changes: 变更列表
        """
        for change in changes:
            if change['type'] == 'add':
                self._add_entity(change['data'])
            elif change['type'] == 'update':
                self._update_entity(change['data'], change.get('old_data'))
            elif change['type'] == 'delete':
                self._delete_entity(change['data'])

        self.conn.commit()

    def _add_entity(self, entity: Dict):
        """添加实体"""
        # 使用Apache AGE添加节点
        self.cursor.execute(f"""
            SELECT * FROM cypher('knowledge_graph', $$
                CREATE (n:Entity {{
                    id: {entity['id']},
                    name: '{entity['name']}',
                    type: '{entity['type']}',
                    properties: '{json.dumps(entity.get('properties', {}))}'
                }})
                RETURN n
            $$) AS (n agtype);
        """)

    def _update_entity(self, entity: Dict, old_entity: Dict = None):
        """更新实体"""
        self.cursor.execute(f"""
            SELECT * FROM cypher('knowledge_graph', $$
                MATCH (n:Entity {{id: {entity['id']}}})
                SET n.name = '{entity['name']}',
                    n.type = '{entity['type']}',
                    n.properties = '{json.dumps(entity.get('properties', {}))}',
                    n.updated_at = timestamp()
                RETURN n
            $$) AS (n agtype);
        """)

    def _delete_entity(self, entity: Dict):
        """删除实体（软删除）"""
        self.cursor.execute(f"""
            SELECT * FROM cypher('knowledge_graph', $$
                MATCH (n:Entity {{id: {entity['id']}}})
                SET n.deleted = true,
                    n.deleted_at = timestamp()
                RETURN n
            $$) AS (n agtype);
        """)
```

---

## 4. 知识冲突检测与解决

### 4.1 冲突类型

#### 冲突分类

```text
类型1: 属性冲突
- 同一实体的同一属性有不同的值
- 例如: 某人的年龄在不同数据源中不同

类型2: 关系冲突
- 同一对实体之间的关系不同
- 例如: A和B的关系在不同数据源中不同

类型3: 实体冲突
- 同一概念被识别为不同实体
- 例如: "北京"和"北京市"被识别为不同实体

类型4: 语义冲突
- 概念的含义冲突
- 例如: "苹果"指水果还是公司
```

### 4.2 冲突检测算法

#### 冲突检测实现

```python
class ConflictDetector:
    """知识冲突检测器"""

    def __init__(self, db_connection):
        self.conn = db_connection
        self.cursor = self.conn.cursor()

    def detect_conflicts(self) -> List[Dict]:
        """
        检测知识图谱中的冲突

        Returns:
            冲突列表: [{type: 'attribute'|'relation'|'entity', ...}]
        """
        conflicts = []

        # 检测属性冲突
        conflicts.extend(self._detect_attribute_conflicts())

        # 检测关系冲突
        conflicts.extend(self._detect_relation_conflicts())

        # 检测实体冲突
        conflicts.extend(self._detect_entity_conflicts())

        return conflicts

    def _detect_attribute_conflicts(self) -> List[Dict]:
        """检测属性冲突"""
        conflicts = []

        # 查询同一实体在不同数据源中的属性值
        self.cursor.execute("""
            SELECT
                e.id,
                e.name,
                a.attribute_name,
                a.attribute_value,
                a.source,
                COUNT(DISTINCT a.attribute_value) as value_count
            FROM entities e
            JOIN attributes a ON e.id = a.entity_id
            GROUP BY e.id, e.name, a.attribute_name, a.attribute_value, a.source
            HAVING COUNT(DISTINCT a.attribute_value) > 1
        """)

        for row in self.cursor.fetchall():
            conflicts.append({
                'type': 'attribute',
                'entity_id': row[0],
                'entity_name': row[1],
                'attribute_name': row[2],
                'conflicting_values': row[3],
                'sources': row[4]
            })

        return conflicts

    def _detect_relation_conflicts(self) -> List[Dict]:
        """检测关系冲突"""
        conflicts = []

        # 查询同一对实体之间的不同关系
        self.cursor.execute("""
            SELECT
                r1.source_entity_id,
                r1.target_entity_id,
                r1.relation_type as relation1,
                r2.relation_type as relation2,
                r1.source as source1,
                r2.source as source2
            FROM relations r1
            JOIN relations r2 ON
                r1.source_entity_id = r2.source_entity_id AND
                r1.target_entity_id = r2.target_entity_id
            WHERE r1.relation_type != r2.relation_type
              AND r1.source != r2.source
        """)

        for row in self.cursor.fetchall():
            conflicts.append({
                'type': 'relation',
                'source_entity_id': row[0],
                'target_entity_id': row[1],
                'conflicting_relations': [row[2], row[3]],
                'sources': [row[4], row[5]]
            })

        return conflicts
```

### 4.3 冲突解决策略

#### 解决策略

```text
策略1: 时间优先（Latest Wins）
- 使用最新的数据
- 适合: 数据持续更新的场景

策略2: 来源优先（Source Priority）
- 根据数据源优先级选择
- 适合: 有明确数据源优先级

策略3: 投票机制（Voting）
- 选择出现次数最多的值
- 适合: 多个数据源的情况

策略4: 置信度优先（Confidence）
- 根据置信度选择
- 适合: 有置信度信息的场景

策略5: 人工审核（Manual Review）
- 冲突标记，等待人工处理
- 适合: 关键知识或复杂冲突
```

### 4.4 冲突解决实现

```python
class ConflictResolver:
    """冲突解决器"""

    def __init__(self, db_connection, resolution_strategy='latest_wins'):
        self.conn = db_connection
        self.cursor = self.conn.cursor()
        self.strategy = resolution_strategy

    def resolve_conflicts(self, conflicts: List[Dict]):
        """解决冲突"""
        for conflict in conflicts:
            if conflict['type'] == 'attribute':
                self._resolve_attribute_conflict(conflict)
            elif conflict['type'] == 'relation':
                self._resolve_relation_conflict(conflict)
            elif conflict['type'] == 'entity':
                self._resolve_entity_conflict(conflict)

        self.conn.commit()

    def _resolve_attribute_conflict(self, conflict: Dict):
        """解决属性冲突"""
        if self.strategy == 'latest_wins':
            # 选择最新的值
            resolved_value = max(
                conflict['conflicting_values'],
                key=lambda x: x['timestamp']
            )['value']
        elif self.strategy == 'source_priority':
            # 根据来源优先级选择
            source_priority = {'source1': 1, 'source2': 2, 'source3': 3}
            resolved_value = min(
                conflict['conflicting_values'],
                key=lambda x: source_priority.get(x['source'], 999)
            )['value']
        elif self.strategy == 'voting':
            # 选择出现次数最多的值
            from collections import Counter
            value_counts = Counter(v['value'] for v in conflict['conflicting_values'])
            resolved_value = value_counts.most_common(1)[0][0]

        # 更新实体属性
        self.cursor.execute(f"""
            UPDATE attributes
            SET attribute_value = %s,
                resolved = true,
                resolution_strategy = %s
            WHERE entity_id = %s
              AND attribute_name = %s
        """, (resolved_value, self.strategy, conflict['entity_id'], conflict['attribute_name']))
```

---

## 5. 版本管理与回滚

### 5.1 版本管理策略

#### 版本表设计

```sql
-- 知识图谱版本表
CREATE TABLE kg_versions (
    version_id SERIAL PRIMARY KEY,
    version_number VARCHAR(50) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    description TEXT,
    change_count INTEGER DEFAULT 0,
    snapshot_path TEXT  -- 快照存储路径
);

-- 变更日志表
CREATE TABLE kg_changes (
    change_id BIGSERIAL PRIMARY KEY,
    version_id INTEGER REFERENCES kg_versions(version_id),
    change_type TEXT NOT NULL,  -- 'add', 'update', 'delete'
    entity_type TEXT NOT NULL,  -- 'entity', 'relation', 'attribute'
    entity_id TEXT NOT NULL,
    old_data JSONB,
    new_data JSONB,
    changed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    source TEXT
);

-- 创建索引
CREATE INDEX idx_changes_version ON kg_changes(version_id);
CREATE INDEX idx_changes_entity ON kg_changes(entity_type, entity_id);
```

### 5.2 快照与检查点

#### 快照创建

```python
class KGSnapshotManager:
    """知识图谱快照管理器"""

    def __init__(self, db_connection):
        self.conn = db_connection
        self.cursor = self.conn.cursor()

    def create_snapshot(self, version_number: str, description: str = None) -> int:
        """
        创建知识图谱快照

        Args:
            version_number: 版本号
            description: 版本描述

        Returns:
            版本ID
        """
        # 1. 创建版本记录
        self.cursor.execute("""
            INSERT INTO kg_versions (version_number, description, change_count)
            VALUES (%s, %s, 0)
            RETURNING version_id
        """, (version_number, description))

        version_id = self.cursor.fetchone()[0]

        # 2. 导出当前知识图谱状态
        snapshot_data = self._export_kg_state()

        # 3. 保存快照
        snapshot_path = f"/snapshots/kg_v{version_number}_{version_id}.json"
        with open(snapshot_path, 'w') as f:
            json.dump(snapshot_data, f, indent=2, ensure_ascii=False)

        # 4. 更新快照路径
        self.cursor.execute("""
            UPDATE kg_versions
            SET snapshot_path = %s
            WHERE version_id = %s
        """, (snapshot_path, version_id))

        self.conn.commit()
        return version_id

    def _export_kg_state(self) -> Dict:
        """导出知识图谱当前状态"""
        # 导出实体
        self.cursor.execute("""
            SELECT id, name, type, properties
            FROM entities
            WHERE deleted IS NOT TRUE
        """)
        entities = [dict(row) for row in self.cursor.fetchall()]

        # 导出关系
        self.cursor.execute("""
            SELECT source_entity_id, target_entity_id, relation_type, properties
            FROM relations
            WHERE deleted IS NOT TRUE
        """)
        relations = [dict(row) for row in self.cursor.fetchall()]

        return {
            'entities': entities,
            'relations': relations,
            'exported_at': datetime.utcnow().isoformat()
        }
```

### 5.3 版本查询

#### 时间旅行查询

```sql
-- 查询特定版本的知识图谱状态
CREATE OR REPLACE FUNCTION query_kg_at_version(p_version_id INTEGER)
RETURNS TABLE (
    entity_id TEXT,
    entity_name TEXT,
    entity_type TEXT,
    properties JSONB
) AS $$
BEGIN
    RETURN QUERY
    -- 获取该版本及之前的所有变更
    WITH version_changes AS (
        SELECT *
        FROM kg_changes
        WHERE version_id <= p_version_id
        ORDER BY change_id DESC
    ),
    entity_states AS (
        SELECT DISTINCT ON (entity_id)
            entity_id,
            CASE
                WHEN change_type = 'delete' THEN NULL
                ELSE new_data
            END AS current_data
        FROM version_changes
        WHERE entity_type = 'entity'
        ORDER BY entity_id, change_id DESC
    )
    SELECT
        es.entity_id,
        es.current_data->>'name' AS entity_name,
        es.current_data->>'type' AS entity_type,
        es.current_data->'properties' AS properties
    FROM entity_states es
    WHERE es.current_data IS NOT NULL;
END;
$$ LANGUAGE plpgsql;
```

### 5.4 回滚机制

```python
class KGRollbackManager:
    """知识图谱回滚管理器"""

    def __init__(self, db_connection):
        self.conn = db_connection
        self.cursor = self.conn.cursor()

    def rollback_to_version(self, target_version_id: int):
        """
        回滚到指定版本

        Args:
            target_version_id: 目标版本ID
        """
        # 1. 获取目标版本之后的变更
        self.cursor.execute("""
            SELECT *
            FROM kg_changes
            WHERE version_id > %s
            ORDER BY change_id DESC
        """, (target_version_id,))

        changes = self.cursor.fetchall()

        # 2. 反向应用变更（回滚）
        for change in changes:
            if change['change_type'] == 'add':
                # 反向: 删除
                self._delete_entity(change['entity_id'])
            elif change['change_type'] == 'delete':
                # 反向: 恢复
                self._restore_entity(change['old_data'])
            elif change['change_type'] == 'update':
                # 反向: 恢复旧值
                self._restore_entity(change['old_data'])

        # 3. 创建回滚版本
        self.cursor.execute("""
            INSERT INTO kg_versions (version_number, description, change_count)
            VALUES (%s, %s, %s)
            RETURNING version_id
        """, (
            f"rollback_to_v{target_version_id}",
            f"Rollback to version {target_version_id}",
            len(changes)
        ))

        self.conn.commit()
```

---

## 6. 知识质量保证

### 6.1 质量评估指标

#### 质量指标

```python
class KGQualityMetrics:
    """知识图谱质量指标"""

    def evaluate_quality(self) -> Dict[str, float]:
        """
        评估知识图谱质量

        Returns:
            {
                'accuracy': 0.95,      # 准确性
                'completeness': 0.88,  # 完整性
                'consistency': 0.92,   # 一致性
                'timeliness': 0.85,    # 时效性
                'relevance': 0.90      # 相关性
            }
        """
        metrics = {
            'accuracy': self._evaluate_accuracy(),
            'completeness': self._evaluate_completeness(),
            'consistency': self._evaluate_consistency(),
            'timeliness': self._evaluate_timeliness(),
            'relevance': self._evaluate_relevance()
        }

        # 综合质量分数
        metrics['overall_quality'] = sum(metrics.values()) / len(metrics)

        return metrics

    def _evaluate_accuracy(self) -> float:
        """评估准确性"""
        # 检查冲突数量
        conflict_count = self._count_conflicts()
        total_entities = self._count_entities()

        # 准确性 = 1 - 冲突率
        conflict_rate = conflict_count / max(total_entities, 1)
        accuracy = 1.0 - min(conflict_rate, 1.0)

        return accuracy

    def _evaluate_completeness(self) -> float:
        """评估完整性"""
        # 检查必需属性的完整性
        entities_with_all_attrs = self._count_entities_with_all_attributes()
        total_entities = self._count_entities()

        completeness = entities_with_all_attrs / max(total_entities, 1)
        return completeness
```

---

## 📚 参考资源

1. **TaxoExpan论文**: Self-Supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network
2. **GenTaxo论文**: Enhancing Taxonomy Completion with Concept Generation via Fusing Relational Representations
3. **知识图谱质量**: Knowledge Graph Quality Assessment

---

## 📝 更新日志

- **v1.0** (2025-01): 初始版本
  - 知识图谱维护概述
  - TaxoExpan自监督扩展完整实现
  - 增量更新策略
  - 知识冲突检测与解决
  - 版本管理与回滚
  - 知识质量保证

---

**状态**: ✅ **文档完成** | [返回目录](./README.md)
