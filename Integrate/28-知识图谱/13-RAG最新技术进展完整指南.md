---
> **ğŸ“‹ æ–‡æ¡£æ¥æº**: æ–°å¢æ·±åŒ–æ–‡æ¡£
> **ğŸ“… åˆ›å»ºæ—¥æœŸ**: 2025-01
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£èšç„¦RAGé¢†åŸŸæœ€æ–°æŠ€æœ¯è¿›å±•ï¼ˆ2024-2025ï¼‰

---

# RAGæœ€æ–°æŠ€æœ¯è¿›å±•å®Œæ•´æŒ‡å—

## å…ƒæ•°æ®

- **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-01
- **æŠ€æœ¯æ ˆ**: PostgreSQL 17+/18+ | pgvector | LangChain | OpenAI/Anthropic API
- **éš¾åº¦çº§åˆ«**: â­â­â­â­â­ (ä¸“å®¶çº§)
- **é¢„è®¡é˜…è¯»**: 120åˆ†é’Ÿ
- **å‰ç½®è¦æ±‚**: ç†Ÿæ‚‰åŸºç¡€RAGå’ŒRAGé«˜çº§æŠ€æœ¯

---

## ğŸ“‹ å®Œæ•´ç›®å½•

- [RAGæœ€æ–°æŠ€æœ¯è¿›å±•å®Œæ•´æŒ‡å—](#ragæœ€æ–°æŠ€æœ¯è¿›å±•å®Œæ•´æŒ‡å—)
  - [å…ƒæ•°æ®](#å…ƒæ•°æ®)
  - [ğŸ“‹ å®Œæ•´ç›®å½•](#-å®Œæ•´ç›®å½•)
  - [1. ActiveRAGï¼šè‡ªä¸»çŸ¥è¯†åŒåŒ–ä¸é€‚åº”](#1-activeragè‡ªä¸»çŸ¥è¯†åŒåŒ–ä¸é€‚åº”)
    - [1.1 ActiveRAGæ¶æ„](#11-activeragæ¶æ„)
      - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
      - [æ¶æ„ä¼˜åŠ¿](#æ¶æ„ä¼˜åŠ¿)
    - [1.2 çŸ¥è¯†åŒåŒ–ä»£ç†](#12-çŸ¥è¯†åŒåŒ–ä»£ç†)
      - [å·¥ä½œåŸç†](#å·¥ä½œåŸç†)
    - [1.3 æ€ç»´é€‚åº”ä»£ç†](#13-æ€ç»´é€‚åº”ä»£ç†)
      - [1.3.1 å·¥ä½œåŸç†](#131-å·¥ä½œåŸç†)
    - [1.4 ActiveRAGå®ç°](#14-activeragå®ç°)
      - [å®Œæ•´ç³»ç»Ÿå®ç°](#å®Œæ•´ç³»ç»Ÿå®ç°)
  - [2. Multi-Head RAGï¼šå¤šæ–¹é¢é—®é¢˜è§£å†³](#2-multi-head-ragå¤šæ–¹é¢é—®é¢˜è§£å†³)
    - [2.1 MRAGæ¶æ„åŸç†](#21-mragæ¶æ„åŸç†)
      - [2.1.1 æ ¸å¿ƒæ€æƒ³](#211-æ ¸å¿ƒæ€æƒ³)
      - [æŠ€æœ¯ä¼˜åŠ¿](#æŠ€æœ¯ä¼˜åŠ¿)
    - [2.2 å­æ–¹é¢æ¢ç´¢å™¨](#22-å­æ–¹é¢æ¢ç´¢å™¨)
      - [å®ç°åŸç†](#å®ç°åŸç†)
    - [2.3 å¤šæ–¹é¢æ£€ç´¢å™¨](#23-å¤šæ–¹é¢æ£€ç´¢å™¨)
      - [2.3.1 å®ç°åŸç†](#231-å®ç°åŸç†)
    - [2.4 ç”Ÿæˆå¼åˆ—è¡¨æ’åºå™¨](#24-ç”Ÿæˆå¼åˆ—è¡¨æ’åºå™¨)
      - [2.4.1 å®ç°åŸç†](#241-å®ç°åŸç†)
    - [2.5 MRAGå®ç°](#25-mragå®ç°)
      - [å®Œæ•´ç³»ç»Ÿ](#å®Œæ•´ç³»ç»Ÿ)
  - [3. RAG-Instructï¼šå¤šæ ·åŒ–æ£€ç´¢å¢å¼ºæŒ‡ä»¤](#3-rag-instructå¤šæ ·åŒ–æ£€ç´¢å¢å¼ºæŒ‡ä»¤)
    - [3.1 RAG-InstructåŸç†](#31-rag-instructåŸç†)
      - [æ ¸å¿ƒç‰¹ç‚¹](#æ ¸å¿ƒç‰¹ç‚¹)
    - [3.2 äº”ç§RAGèŒƒå¼](#32-äº”ç§ragèŒƒå¼)
      - [èŒƒå¼åˆ†ç±»](#èŒƒå¼åˆ†ç±»)
    - [3.3 æŒ‡ä»¤åˆæˆæ–¹æ³•](#33-æŒ‡ä»¤åˆæˆæ–¹æ³•)
      - [æŒ‡ä»¤ç”Ÿæˆå™¨](#æŒ‡ä»¤ç”Ÿæˆå™¨)
    - [3.4 RAG-Instructå®ç°](#34-rag-instructå®ç°)
      - [3.4.1 å®Œæ•´ç³»ç»Ÿ](#341-å®Œæ•´ç³»ç»Ÿ)
  - [4. HiRAGï¼šå±‚æ¬¡åŒ–çŸ¥è¯†å¢å¼ºRAG](#4-hiragå±‚æ¬¡åŒ–çŸ¥è¯†å¢å¼ºrag)
    - [4.1 HiRAGæ¶æ„](#41-hiragæ¶æ„)
      - [4.1.1 æ ¸å¿ƒæ€æƒ³](#411-æ ¸å¿ƒæ€æƒ³)
    - [4.2 å±‚æ¬¡åŒ–çŸ¥è¯†æ„å»º](#42-å±‚æ¬¡åŒ–çŸ¥è¯†æ„å»º)
    - [4.3 å±‚æ¬¡åŒ–æ£€ç´¢](#43-å±‚æ¬¡åŒ–æ£€ç´¢)
  - [5. RichRAGï¼šå¤šæ–¹é¢æŸ¥è¯¢å“åº”ç”Ÿæˆ](#5-richragå¤šæ–¹é¢æŸ¥è¯¢å“åº”ç”Ÿæˆ)
    - [5.1 RichRAGæ¡†æ¶](#51-richragæ¡†æ¶)
      - [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
    - [5.4 RichRAGå®ç°](#54-richragå®ç°)
  - [6. ERM4ï¼šå››æ¨¡å—ååŒRAGç³»ç»Ÿ](#6-erm4å››æ¨¡å—ååŒragç³»ç»Ÿ)
    - [6.1 ERM4æ¶æ„](#61-erm4æ¶æ„)
      - [å››æ¨¡å—](#å››æ¨¡å—)
    - [6.2 å››æ¨¡å—è¯¦è§£](#62-å››æ¨¡å—è¯¦è§£)
  - [7. XRAGï¼šé«˜çº§RAGç»„ä»¶åŸºå‡†æµ‹è¯•](#7-xragé«˜çº§ragç»„ä»¶åŸºå‡†æµ‹è¯•)
    - [7.1 XRAGæ¡†æ¶](#71-xragæ¡†æ¶)
      - [æ ¸å¿ƒé˜¶æ®µ](#æ ¸å¿ƒé˜¶æ®µ)
    - [7.3 åŸºå‡†æµ‹è¯•æ–¹æ³•](#73-åŸºå‡†æµ‹è¯•æ–¹æ³•)
  - [8. æŠ€æœ¯å¯¹æ¯”ä¸é€‰æ‹©å»ºè®®](#8-æŠ€æœ¯å¯¹æ¯”ä¸é€‰æ‹©å»ºè®®)
    - [8.1 æŠ€æœ¯å¯¹æ¯”çŸ©é˜µ](#81-æŠ€æœ¯å¯¹æ¯”çŸ©é˜µ)
    - [8.2 é€‰æ‹©å»ºè®®](#82-é€‰æ‹©å»ºè®®)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
  - [ğŸ“ æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)

---

## 1. ActiveRAGï¼šè‡ªä¸»çŸ¥è¯†åŒåŒ–ä¸é€‚åº”

### 1.1 ActiveRAGæ¶æ„

ActiveRAGå¼•å…¥äº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ¨¡æ‹Ÿäººç±»çš„å­¦ä¹ è¡Œä¸ºï¼Œå¸®åŠ©LLMä¸»åŠ¨å‚ä¸å¹¶ä»æ£€ç´¢åˆ°çš„è¯æ®ä¸­å­¦ä¹ ã€‚

#### æ ¸å¿ƒæ€æƒ³

```text
ä¼ ç»ŸRAGæµç¨‹:
ç”¨æˆ·æŸ¥è¯¢ â†’ æ£€ç´¢ â†’ LLMç”Ÿæˆç­”æ¡ˆ

ActiveRAGæµç¨‹:
ç”¨æˆ·æŸ¥è¯¢ â†’ æ£€ç´¢ â†’ çŸ¥è¯†åŒåŒ–ä»£ç† â†’ æ€ç»´é€‚åº”ä»£ç† â†’ LLMç”Ÿæˆç­”æ¡ˆ
                      â†“                    â†“
                å…³è”å¤–éƒ¨çŸ¥è¯†          æ ¡å‡†å†…éƒ¨æ€ç»´
```

#### æ¶æ„ä¼˜åŠ¿

- âœ… **ä¸»åŠ¨å­¦ä¹ **: LLMä¸»åŠ¨å‚ä¸çŸ¥è¯†åŒåŒ–è¿‡ç¨‹
- âœ… **çŸ¥è¯†å…³è”**: å°†å¤–éƒ¨çŸ¥è¯†ä¸å‚æ•°åŒ–è®°å¿†å…³è”
- âœ… **æ€ç»´æ ¡å‡†**: ä¼˜åŒ–LLMå†…éƒ¨æ€ç»´ä»¥æå‡å“åº”è´¨é‡
- âœ… **å™ªå£°æŠ‘åˆ¶**: ç¼“è§£å™ªå£°æ£€ç´¢çš„å½±å“
- âœ… **æ€§èƒ½æå‡**: æ¯”ä¼ ç»ŸRAGæå‡10%+çš„æ€§èƒ½

### 1.2 çŸ¥è¯†åŒåŒ–ä»£ç†

#### å·¥ä½œåŸç†

```python
class KnowledgeAssimilationAgent:
    """çŸ¥è¯†åŒåŒ–ä»£ç†"""

    def __init__(self, llm, retriever):
        self.llm = llm
        self.retriever = retriever

    def assimilate_knowledge(self, query: str, retrieved_docs: List[Dict]) -> Dict:
        """
        å°†æ£€ç´¢åˆ°çš„å¤–éƒ¨çŸ¥è¯†ä¸LLMçš„å‚æ•°åŒ–è®°å¿†å…³è”

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨

        Returns:
            åŒåŒ–åçš„çŸ¥è¯†ç»“æ„
        """
        # 1. æå–å…³é”®ä¿¡æ¯
        key_info = self._extract_key_information(retrieved_docs)

        # 2. å…³è”åˆ°LLMè®°å¿†
        memory_links = self._link_to_memory(query, key_info)

        # 3. æ„å»ºçŸ¥è¯†å›¾è°±
        knowledge_graph = self._build_knowledge_graph(key_info, memory_links)

        return {
            'key_info': key_info,
            'memory_links': memory_links,
            'knowledge_graph': knowledge_graph
        }

    def _extract_key_information(self, docs: List[Dict]) -> List[Dict]:
        """æå–å…³é”®ä¿¡æ¯"""
        prompt = f"""
        ä»ä»¥ä¸‹æ–‡æ¡£ä¸­æå–å…³é”®ä¿¡æ¯ï¼š

        {self._format_docs(docs)}

        è¯·æå–ï¼š
        1. æ ¸å¿ƒæ¦‚å¿µ
        2. å…³é”®äº‹å®
        3. å…³ç³»ä¸å…³è”
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        # è§£æå“åº”ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯
        return self._parse_key_info(response.choices[0].message.content)

    def _link_to_memory(self, query: str, key_info: List[Dict]) -> List[Dict]:
        """å…³è”åˆ°LLMè®°å¿†"""
        prompt = f"""
        æŸ¥è¯¢: {query}

        å…³é”®ä¿¡æ¯: {key_info}

        è¯·å°†è¿™äº›ä¿¡æ¯å…³è”åˆ°å·²æœ‰çš„çŸ¥è¯†è®°å¿†ä¸­ï¼Œè¯†åˆ«ï¼š
        1. ä¸æŸ¥è¯¢ç›¸å…³çš„å·²æœ‰çŸ¥è¯†
        2. æ–°çŸ¥è¯†ç‚¹
        3. çŸ¥è¯†å†²çª
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        return self._parse_memory_links(response.choices[0].message.content)
```

### 1.3 æ€ç»´é€‚åº”ä»£ç†

#### 1.3.1 å·¥ä½œåŸç†

```python
class ThoughtAdaptationAgent:
    """æ€ç»´é€‚åº”ä»£ç†"""

    def __init__(self, llm):
        self.llm = llm

    def calibrate_thinking(self, query: str, assimilated_knowledge: Dict) -> Dict:
        """
        æ ¡å‡†LLMçš„å†…éƒ¨æ€ç»´ä»¥ä¼˜åŒ–å“åº”

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            assimilated_knowledge: åŒåŒ–åçš„çŸ¥è¯†

        Returns:
            æ ¡å‡†åçš„æ€ç»´ç»“æ„
        """
        # 1. åˆ†æå½“å‰æ€ç»´çŠ¶æ€
        current_thinking = self._analyze_thinking(query)

        # 2. è¯†åˆ«æ€ç»´åå·®
        biases = self._identify_biases(current_thinking, assimilated_knowledge)

        # 3. æ ¡å‡†æ€ç»´
        calibrated_thinking = self._calibrate(current_thinking, biases, assimilated_knowledge)

        return calibrated_thinking

    def _analyze_thinking(self, query: str) -> Dict:
        """åˆ†æå½“å‰æ€ç»´çŠ¶æ€"""
        prompt = f"""
        åˆ†æå¯¹äºä»¥ä¸‹æŸ¥è¯¢çš„æ€è€ƒè¿‡ç¨‹ï¼š

        æŸ¥è¯¢: {query}

        è¯·è¯†åˆ«ï¼š
        1. æ€è€ƒè·¯å¾„
        2. ä½¿ç”¨çš„å‡è®¾
        3. æ½œåœ¨çš„ç›²ç‚¹
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        return self._parse_thinking(response.choices[0].message.content)
```

### 1.4 ActiveRAGå®ç°

#### å®Œæ•´ç³»ç»Ÿå®ç°

```python
class ActiveRAG:
    """ActiveRAGå®Œæ•´ç³»ç»Ÿ"""

    def __init__(self, llm, retriever):
        self.llm = llm
        self.retriever = retriever
        self.assimilation_agent = KnowledgeAssimilationAgent(llm, retriever)
        self.adaptation_agent = ThoughtAdaptationAgent(llm)

    def query(self, question: str) -> Dict[str, Any]:
        """ä½¿ç”¨ActiveRAGå›ç­”æŸ¥è¯¢"""
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retrieved_docs = self.retriever.retrieve(question, top_k=5)

        # 2. çŸ¥è¯†åŒåŒ–
        assimilated_knowledge = self.assimilation_agent.assimilate_knowledge(
            question, retrieved_docs
        )

        # 3. æ€ç»´é€‚åº”
        calibrated_thinking = self.adaptation_agent.calibrate_thinking(
            question, assimilated_knowledge
        )

        # 4. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(
            question,
            retrieved_docs,
            assimilated_knowledge,
            calibrated_thinking
        )

        return {
            'answer': answer,
            'retrieved_docs': retrieved_docs,
            'assimilated_knowledge': assimilated_knowledge,
            'calibrated_thinking': calibrated_thinking
        }

    def _generate_answer(self, question: str, docs: List[Dict],
                        knowledge: Dict, thinking: Dict) -> str:
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
        context = f"""
        æ£€ç´¢åˆ°çš„æ–‡æ¡£:
        {self._format_docs(docs)}

        åŒåŒ–çš„çŸ¥è¯†:
        {json.dumps(knowledge, ensure_ascii=False, indent=2)}

        æ ¡å‡†çš„æ€ç»´:
        {json.dumps(thinking, ensure_ascii=False, indent=2)}
        """

        prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”æŸ¥è¯¢ã€‚

        æŸ¥è¯¢: {question}

        {context}

        è¯·ç”Ÿæˆä¸€ä¸ªå‡†ç¡®ã€å®Œæ•´çš„ç­”æ¡ˆï¼Œå……åˆ†åˆ©ç”¨åŒåŒ–çš„çŸ¥è¯†å’Œæ ¡å‡†çš„æ€ç»´ã€‚
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        return response.choices[0].message.content
```

---

## 2. Multi-Head RAGï¼šå¤šæ–¹é¢é—®é¢˜è§£å†³

### 2.1 MRAGæ¶æ„åŸç†

Multi-Head RAG (MRAG)æ—¨åœ¨è§£å†³éœ€è¦æ£€ç´¢å¤šç¯‡å†…å®¹å·®å¼‚è¾ƒå¤§çš„æ–‡æ¡£çš„æŸ¥è¯¢ã€‚

#### 2.1.1 æ ¸å¿ƒæ€æƒ³

```text
ä¼ ç»ŸRAG:
æŸ¥è¯¢ â†’ å•ä¸€æ£€ç´¢ â†’ å•ä¸€ç»“æœé›†

MRAG:
æŸ¥è¯¢ â†’ å¤šå¤´æ³¨æ„åŠ› â†’ å¤šæ–¹é¢æ£€ç´¢ â†’ å¤šæ–¹é¢ç»“æœ â†’ èåˆæ’åº â†’ æœ€ç»ˆç»“æœ
```

#### æŠ€æœ¯ä¼˜åŠ¿

- âœ… **å¤šæ–¹é¢ç†è§£**: åˆ©ç”¨Transformerå¤šå¤´æ³¨æ„åŠ›æ•æ‰ä¸åŒæ–¹é¢
- âœ… **å·®å¼‚åŒ–æ£€ç´¢**: æ£€ç´¢å†…å®¹å·®å¼‚è¾ƒå¤§çš„æ–‡æ¡£
- âœ… **æ€§èƒ½æå‡**: ç›¸å…³æ€§æå‡æœ€å¤š20%

### 2.2 å­æ–¹é¢æ¢ç´¢å™¨

#### å®ç°åŸç†

```python
class AspectExplorer:
    """å­æ–¹é¢æ¢ç´¢å™¨"""

    def __init__(self, llm):
        self.llm = llm

    def explore_aspects(self, query: str) -> List[str]:
        """
        æ¢ç´¢æŸ¥è¯¢çš„å¤šä¸ªå­æ–¹é¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            å­æ–¹é¢åˆ—è¡¨
        """
        prompt = f"""
        åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼Œè¯†åˆ«å…¶åŒ…å«çš„å¤šä¸ªå­æ–¹é¢ï¼š

        æŸ¥è¯¢: {query}

        è¯·è¯†åˆ«ï¼š
        1. æŸ¥è¯¢æ¶‰åŠçš„ä¸»è¦æ–¹é¢
        2. æ¯ä¸ªæ–¹é¢çš„å…·ä½“å…³æ³¨ç‚¹
        3. ä¸åŒæ–¹é¢çš„å·®å¼‚

        è¿”å›JSONæ ¼å¼çš„å­æ–¹é¢åˆ—è¡¨ã€‚
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        aspects = json.loads(response.choices[0].message.content)
        return aspects.get('aspects', [])
```

### 2.3 å¤šæ–¹é¢æ£€ç´¢å™¨

#### 2.3.1 å®ç°åŸç†

```python
class MultiAspectRetriever:
    """å¤šæ–¹é¢æ£€ç´¢å™¨"""

    def __init__(self, retriever, embedding_model):
        self.retriever = retriever
        self.embedding_model = embedding_model

    def retrieve_multiple_aspects(self, query: str, aspects: List[str],
                                 top_k_per_aspect: int = 5) -> Dict[str, List[Dict]]:
        """
        ä¸ºæ¯ä¸ªå­æ–¹é¢æ£€ç´¢ç›¸å…³æ–‡æ¡£

        Args:
            query: åŸå§‹æŸ¥è¯¢
            aspects: å­æ–¹é¢åˆ—è¡¨
            top_k_per_aspect: æ¯ä¸ªæ–¹é¢æ£€ç´¢çš„æ–‡æ¡£æ•°

        Returns:
            {aspect: [documents]}
        """
        results = {}

        for aspect in aspects:
            # ä¸ºæ¯ä¸ªæ–¹é¢æ„å»ºç‰¹å®šæŸ¥è¯¢
            aspect_query = f"{query} {aspect}"

            # æ£€ç´¢è¯¥æ–¹é¢çš„æ–‡æ¡£
            docs = self.retriever.retrieve(aspect_query, top_k=top_k_per_aspect)

            results[aspect] = docs

        return results
```

### 2.4 ç”Ÿæˆå¼åˆ—è¡¨æ’åºå™¨

#### 2.4.1 å®ç°åŸç†

```python
class GenerativeListReranker:
    """ç”Ÿæˆå¼åˆ—è¡¨æ’åºå™¨"""

    def __init__(self, llm):
        self.llm = llm

    def rerank(self, query: str, aspect_docs: Dict[str, List[Dict]],
               top_k: int = 10) -> List[Dict]:
        """
        å¯¹æ‰€æœ‰æ–¹é¢çš„æ–‡æ¡£è¿›è¡Œé‡æ–°æ’åº

        Args:
            query: åŸå§‹æŸ¥è¯¢
            aspect_docs: å„æ–¹é¢æ£€ç´¢åˆ°çš„æ–‡æ¡£
            top_k: æœ€ç»ˆè¿”å›çš„æ–‡æ¡£æ•°

        Returns:
            æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        # åˆå¹¶æ‰€æœ‰æ–‡æ¡£
        all_docs = []
        for aspect, docs in aspect_docs.items():
            for doc in docs:
                doc['aspect'] = aspect
                all_docs.append(doc)

        # å»é‡ï¼ˆåŸºäºå†…å®¹ç›¸ä¼¼åº¦ï¼‰
        unique_docs = self._deduplicate(all_docs)

        # ä½¿ç”¨LLMè¿›è¡Œé‡æ–°æ’åº
        sorted_docs = self._llm_rerank(query, unique_docs, top_k)

        return sorted_docs

    def _llm_rerank(self, query: str, docs: List[Dict], top_k: int) -> List[Dict]:
        """ä½¿ç”¨LLMé‡æ–°æ’åº"""
        doc_texts = [f"{i+1}. {doc['content'][:200]}" for i, doc in enumerate(docs)]

        prompt = f"""
        æŸ¥è¯¢: {query}

        å€™é€‰æ–‡æ¡£:
        {chr(10).join(doc_texts)}

        è¯·æ ¹æ®ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ï¼Œå¯¹æ–‡æ¡£è¿›è¡Œæ’åºï¼ˆè¿”å›æ–‡æ¡£ç¼–å·åˆ—è¡¨ï¼Œæœ€ç›¸å…³çš„åœ¨å‰ï¼‰ã€‚
        åªè¿”å›å‰{top_k}ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£ç¼–å·ã€‚
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        ranked_indices = self._parse_ranked_indices(response.choices[0].message.content)

        return [docs[i-1] for i in ranked_indices if 1 <= i <= len(docs)]
```

### 2.5 MRAGå®ç°

#### å®Œæ•´ç³»ç»Ÿ

```python
class MultiHeadRAG:
    """Multi-Head RAGå®Œæ•´ç³»ç»Ÿ"""

    def __init__(self, llm, retriever, embedding_model):
        self.llm = llm
        self.retriever = retriever
        self.aspect_explorer = AspectExplorer(llm)
        self.multi_aspect_retriever = MultiAspectRetriever(retriever, embedding_model)
        self.reranker = GenerativeListReranker(llm)

    def query(self, question: str, top_k: int = 10) -> Dict[str, Any]:
        """ä½¿ç”¨MRAGå›ç­”æŸ¥è¯¢"""
        # 1. æ¢ç´¢å­æ–¹é¢
        aspects = self.aspect_explorer.explore_aspects(question)

        # 2. å¤šæ–¹é¢æ£€ç´¢
        aspect_docs = self.multi_aspect_retriever.retrieve_multiple_aspects(
            question, aspects
        )

        # 3. é‡æ–°æ’åº
        ranked_docs = self.reranker.rerank(question, aspect_docs, top_k)

        # 4. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(question, ranked_docs)

        return {
            'answer': answer,
            'aspects': aspects,
            'retrieved_docs': ranked_docs,
            'aspect_docs': aspect_docs
        }

    def _generate_answer(self, question: str, docs: List[Dict]) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        context = self._format_docs(docs)

        prompt = f"""
        åŸºäºä»¥ä¸‹å¤šæ–¹é¢æ£€ç´¢åˆ°çš„æ–‡æ¡£å›ç­”æŸ¥è¯¢ã€‚

        æŸ¥è¯¢: {question}

        {context}

        è¯·ç”Ÿæˆä¸€ä¸ªå…¨é¢ã€å‡†ç¡®çš„ç­”æ¡ˆï¼Œæ¶µç›–æŸ¥è¯¢çš„å„ä¸ªæ–¹é¢ã€‚
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        return response.choices[0].message.content
```

---

## 3. RAG-Instructï¼šå¤šæ ·åŒ–æ£€ç´¢å¢å¼ºæŒ‡ä»¤

### 3.1 RAG-InstructåŸç†

RAG-Instructæ˜¯ä¸€ç§é€šç”¨æ–¹æ³•ï¼Œæ—¨åœ¨åŸºäºä»»ä½•æºè¯­æ–™åº“åˆæˆå¤šæ ·ä¸”é«˜è´¨é‡çš„RAGæŒ‡ä»¤æ•°æ®ã€‚

#### æ ¸å¿ƒç‰¹ç‚¹

- âœ… **å¤šæ ·åŒ–æŒ‡ä»¤**: åˆ©ç”¨äº”ç§RAGèŒƒå¼åˆæˆæŒ‡ä»¤
- âœ… **é«˜è´¨é‡æ•°æ®**: é€šè¿‡æŒ‡ä»¤æ¨¡æ‹Ÿå¢å¼ºæŒ‡ä»¤è´¨é‡
- âœ… **é€šç”¨æ–¹æ³•**: é€‚ç”¨äºä»»ä½•æºè¯­æ–™åº“
- âœ… **æ€§èƒ½æå‡**: æ˜¾è‘—ä¼˜äºå„ç§RAGåŸºçº¿

### 3.2 äº”ç§RAGèŒƒå¼

#### èŒƒå¼åˆ†ç±»

```python
class RAGParadigm:
    """RAGèŒƒå¼å®šä¹‰"""

    PARADIGMS = {
        'exact_match': {
            'description': 'ç²¾ç¡®åŒ¹é…ï¼šæŸ¥è¯¢ä¸æ–‡æ¡£é«˜åº¦ç›¸å…³',
            'characteristics': ['ç›´æ¥ç­”æ¡ˆ', 'é«˜ç›¸å…³æ€§']
        },
        'partial_match': {
            'description': 'éƒ¨åˆ†åŒ¹é…ï¼šæŸ¥è¯¢ä¸æ–‡æ¡£éƒ¨åˆ†ç›¸å…³',
            'characteristics': ['é—´æ¥ç­”æ¡ˆ', 'ä¸­ç­‰ç›¸å…³æ€§']
        },
        'contextual': {
            'description': 'ä¸Šä¸‹æ–‡åŒ¹é…ï¼šéœ€è¦ç†è§£ä¸Šä¸‹æ–‡',
            'characteristics': ['ä¸Šä¸‹æ–‡æ¨ç†', 'éšå«ä¿¡æ¯']
        },
        'synthesis': {
            'description': 'ç»¼åˆåŒ¹é…ï¼šéœ€è¦ç»¼åˆå¤šä¸ªæ–‡æ¡£',
            'characteristics': ['å¤šæ–‡æ¡£èåˆ', 'ç»¼åˆåˆ†æ']
        },
        'creative': {
            'description': 'åˆ›é€ æ€§åŒ¹é…ï¼šéœ€è¦åˆ›é€ æ€§ç†è§£',
            'characteristics': ['åˆ›æ–°æ€§å›ç­”', 'æ·±åº¦ç†è§£']
        }
    }
```

### 3.3 æŒ‡ä»¤åˆæˆæ–¹æ³•

#### æŒ‡ä»¤ç”Ÿæˆå™¨

```python
class RAGInstructionGenerator:
    """RAGæŒ‡ä»¤ç”Ÿæˆå™¨"""

    def __init__(self, llm):
        self.llm = llm

    def generate_instructions(self, corpus: List[str], num_instructions: int = 100) -> List[Dict]:
        """
        ä»è¯­æ–™åº“ç”ŸæˆRAGæŒ‡ä»¤

        Args:
            corpus: æºè¯­æ–™åº“
            num_instructions: ç”Ÿæˆçš„æŒ‡ä»¤æ•°é‡

        Returns:
            æŒ‡ä»¤åˆ—è¡¨
        """
        instructions = []

        for paradigm_name, paradigm_info in RAGParadigm.PARADIGMS.items():
            # ä¸ºæ¯ä¸ªèŒƒå¼ç”ŸæˆæŒ‡ä»¤
            paradigm_instructions = self._generate_paradigm_instructions(
                corpus, paradigm_name, num_instructions // 5
            )
            instructions.extend(paradigm_instructions)

        return instructions

    def _generate_paradigm_instructions(self, corpus: List[str],
                                       paradigm: str, num: int) -> List[Dict]:
        """ä¸ºç‰¹å®šèŒƒå¼ç”ŸæˆæŒ‡ä»¤"""
        instructions = []

        for doc in corpus[:num*2]:  # ä½¿ç”¨æ›´å¤šæ–‡æ¡£ä»¥å¢åŠ å¤šæ ·æ€§
            prompt = f"""
            åŸºäºä»¥ä¸‹æ–‡æ¡£ï¼ŒæŒ‰ç…§{paradigm}èŒƒå¼ç”Ÿæˆä¸€ä¸ªRAGæŒ‡ä»¤ã€‚

            èŒƒå¼ç‰¹ç‚¹: {RAGParadigm.PARADIGMS[paradigm]['description']}

            æ–‡æ¡£:
            {doc[:500]}

            è¯·ç”Ÿæˆï¼š
            1. ä¸€ä¸ªæŸ¥è¯¢é—®é¢˜
            2. ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
            3. æœŸæœ›çš„ç­”æ¡ˆ

            è¿”å›JSONæ ¼å¼ã€‚
            """

            response = self.llm.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.8  # å¢åŠ å¤šæ ·æ€§
            )

            instruction = json.loads(response.choices[0].message.content)
            instruction['paradigm'] = paradigm
            instructions.append(instruction)

        return instructions[:num]
```

### 3.4 RAG-Instructå®ç°

#### 3.4.1 å®Œæ•´ç³»ç»Ÿ

```python
class RAGInstructSystem:
    """RAG-Instructç³»ç»Ÿ"""

    def __init__(self, llm, retriever, instruction_generator=None):
        self.llm = llm
        self.retriever = retriever
        self.instruction_generator = instruction_generator or RAGInstructionGenerator(llm)
        self.instructions = []

    def build_instruction_dataset(self, corpus: List[str], num_instructions: int = 100):
        """æ„å»ºæŒ‡ä»¤æ•°æ®é›†"""
        self.instructions = self.instruction_generator.generate_instructions(
            corpus, num_instructions
        )
        return self.instructions

    def train_on_instructions(self, instructions: List[Dict]):
        """åœ¨æŒ‡ä»¤ä¸Šè®­ç»ƒRAGç³»ç»Ÿ"""
        # è¿™é‡Œå¯ä»¥å®ç°å¾®è°ƒé€»è¾‘
        # æˆ–è€…ä½¿ç”¨æŒ‡ä»¤è¿›è¡Œfew-shot learning
        self.instructions = instructions

    def query(self, question: str, use_instructions: bool = True) -> str:
        """ä½¿ç”¨RAG-Instructå›ç­”æŸ¥è¯¢"""
        if use_instructions and self.instructions:
            # é€‰æ‹©ç›¸å…³çš„æŒ‡ä»¤ä½œä¸ºfew-shotç¤ºä¾‹
            relevant_instructions = self._select_relevant_instructions(question, top_k=3)

            # æ„å»ºfew-shot prompt
            few_shot_examples = self._format_instructions(relevant_instructions)
        else:
            few_shot_examples = ""

        # æ£€ç´¢æ–‡æ¡£
        retrieved_docs = self.retriever.retrieve(question, top_k=5)

        # ç”Ÿæˆç­”æ¡ˆ
        prompt = f"""
        {few_shot_examples}

        åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”æŸ¥è¯¢ã€‚

        æŸ¥è¯¢: {question}

        æ–‡æ¡£:
        {self._format_docs(retrieved_docs)}

        è¯·ç”Ÿæˆç­”æ¡ˆã€‚
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        return response.choices[0].message.content

    def _select_relevant_instructions(self, question: str, top_k: int = 3) -> List[Dict]:
        """é€‰æ‹©ç›¸å…³çš„æŒ‡ä»¤"""
        # ä½¿ç”¨ç®€å•çš„ç›¸ä¼¼åº¦é€‰æ‹©
        question_embedding = self._embed(question)

        instruction_scores = []
        for instruction in self.instructions:
            query_embedding = self._embed(instruction['query'])
            score = self._cosine_similarity(question_embedding, query_embedding)
            instruction_scores.append((score, instruction))

        instruction_scores.sort(reverse=True, key=lambda x: x[0])
        return [inst for _, inst in instruction_scores[:top_k]]
```

---

## 4. HiRAGï¼šå±‚æ¬¡åŒ–çŸ¥è¯†å¢å¼ºRAG

### 4.1 HiRAGæ¶æ„

HiRAG (Hierarchical Retrieval-Augmented Generation)é€šè¿‡å¼•å…¥å±‚æ¬¡åŒ–çŸ¥è¯†ï¼Œæå‡RAGç³»ç»Ÿåœ¨ç´¢å¼•å’Œæ£€ç´¢è¿‡ç¨‹ä¸­çš„è¯­ä¹‰ç†è§£å’Œç»“æ„æ•æ‰èƒ½åŠ›ã€‚

#### 4.1.1 æ ¸å¿ƒæ€æƒ³

```text
ä¼ ç»ŸRAG:
æ–‡æ¡£ â†’ æ‰å¹³åŒ–ç´¢å¼• â†’ æ£€ç´¢

HiRAG:
æ–‡æ¡£ â†’ å±‚æ¬¡åŒ–çŸ¥è¯†ç»“æ„ â†’ å±‚æ¬¡åŒ–ç´¢å¼• â†’ å±‚æ¬¡åŒ–æ£€ç´¢ â†’ ç»“æœ
        â”œâ”€ ä¸»é¢˜å±‚
        â”œâ”€ æ®µè½å±‚
        â””â”€ å¥å­å±‚
```

### 4.2 å±‚æ¬¡åŒ–çŸ¥è¯†æ„å»º

```python
class HierarchicalKnowledgeBuilder:
    """å±‚æ¬¡åŒ–çŸ¥è¯†æ„å»ºå™¨"""

    def __init__(self, llm):
        self.llm = llm

    def build_hierarchy(self, documents: List[str]) -> Dict:
        """
        æ„å»ºå±‚æ¬¡åŒ–çŸ¥è¯†ç»“æ„

        Returns:
            {
                'topics': [...],
                'paragraphs': [...],
                'sentences': [...],
                'relationships': [...]
            }
        """
        # 1. ä¸»é¢˜æå–
        topics = self._extract_topics(documents)

        # 2. æ®µè½ç»„ç»‡
        paragraphs = self._organize_paragraphs(documents, topics)

        # 3. å¥å­æå–
        sentences = self._extract_sentences(paragraphs)

        # 4. æ„å»ºå…³ç³»
        relationships = self._build_relationships(topics, paragraphs, sentences)

        return {
            'topics': topics,
            'paragraphs': paragraphs,
            'sentences': sentences,
            'relationships': relationships
        }
```

### 4.3 å±‚æ¬¡åŒ–æ£€ç´¢

```python
class HierarchicalRetriever:
    """å±‚æ¬¡åŒ–æ£€ç´¢å™¨"""

    def __init__(self, hierarchy: Dict, embedding_model):
        self.hierarchy = hierarchy
        self.embedding_model = embedding_model

    def hierarchical_retrieve(self, query: str, top_k: int = 10) -> List[Dict]:
        """
        å±‚æ¬¡åŒ–æ£€ç´¢

        1. å…ˆåœ¨ä¸»é¢˜å±‚æ£€ç´¢
        2. ç„¶ååœ¨æ®µè½å±‚æ£€ç´¢
        3. æœ€ååœ¨å¥å­å±‚æ£€ç´¢
        """
        # ä¸»é¢˜å±‚æ£€ç´¢
        relevant_topics = self._retrieve_topics(query, top_k=3)

        # æ®µè½å±‚æ£€ç´¢ï¼ˆé™åˆ¶åœ¨ç›¸å…³ä¸»é¢˜å†…ï¼‰
        relevant_paragraphs = self._retrieve_paragraphs(
            query, relevant_topics, top_k=5
        )

        # å¥å­å±‚æ£€ç´¢ï¼ˆé™åˆ¶åœ¨ç›¸å…³æ®µè½å†…ï¼‰
        relevant_sentences = self._retrieve_sentences(
            query, relevant_paragraphs, top_k=top_k
        )

        return relevant_sentences
```

---

## 5. RichRAGï¼šå¤šæ–¹é¢æŸ¥è¯¢å“åº”ç”Ÿæˆ

### 5.1 RichRAGæ¡†æ¶

RichRAGæ—¨åœ¨å¤„ç†ç”¨æˆ·æå‡ºçš„å¹¿æ³›ã€å¼€æ”¾å¼æŸ¥è¯¢ï¼Œç”Ÿæˆæ¶µç›–å¤šä¸ªç›¸å…³æ–¹é¢çš„ä¸°å¯Œé•¿æ–‡æœ¬ç­”æ¡ˆã€‚

#### æ ¸å¿ƒç»„ä»¶

1. **å­æ–¹é¢æ¢ç´¢å™¨**: è¯†åˆ«æŸ¥è¯¢çš„å¤šä¸ªå­æ–¹é¢
2. **å¤šæ–¹é¢æ£€ç´¢å™¨**: ä¸ºæ¯ä¸ªæ–¹é¢æ£€ç´¢ç›¸å…³æ–‡æ¡£
3. **ç”Ÿæˆå¼åˆ—è¡¨æ’åºå™¨**: å¯¹æ‰€æœ‰æ£€ç´¢ç»“æœé‡æ–°æ’åº

### 5.4 RichRAGå®ç°

```python
class RichRAG:
    """RichRAGå®Œæ•´ç³»ç»Ÿ"""

    def __init__(self, llm, retriever):
        self.llm = llm
        self.retriever = retriever

    def generate_rich_response(self, query: str) -> Dict[str, Any]:
        """ç”Ÿæˆä¸°å¯Œçš„å¤šæ–¹é¢å“åº”"""
        # 1. å­æ–¹é¢æ¢ç´¢
        aspects = self._explore_aspects(query)

        # 2. å¤šæ–¹é¢æ£€ç´¢
        aspect_docs = {}
        for aspect in aspects:
            aspect_docs[aspect] = self.retriever.retrieve(
                f"{query} {aspect}", top_k=5
            )

        # 3. ç”Ÿæˆå¤šæ–¹é¢ç­”æ¡ˆ
        rich_answer = self._generate_multi_aspect_answer(query, aspects, aspect_docs)

        return {
            'answer': rich_answer,
            'aspects': aspects,
            'aspect_docs': aspect_docs
        }
```

---

## 6. ERM4ï¼šå››æ¨¡å—ååŒRAGç³»ç»Ÿ

### 6.1 ERM4æ¶æ„

ERM4 (Enhancing Retrieval and Managing Retrieval)æå‡ºäº†å››ä¸ªæ¨¡å—çš„ååŒå·¥ä½œï¼Œä»¥æé«˜RAGç³»ç»Ÿçš„å“åº”è´¨é‡å’Œæ•ˆç‡ã€‚

#### å››æ¨¡å—

1. **æŸ¥è¯¢é‡å†™æ¨¡å—**: ä¼˜åŒ–æŸ¥è¯¢è¡¨è¾¾
2. **çŸ¥è¯†è¿‡æ»¤æ¨¡å—**: è¿‡æ»¤ä¸ç›¸å…³çŸ¥è¯†
3. **è®°å¿†çŸ¥è¯†åº“æ¨¡å—**: ç»´æŠ¤é•¿æœŸè®°å¿†
4. **æ£€ç´¢è§¦å‘å™¨æ¨¡å—**: æ™ºèƒ½è§¦å‘æ£€ç´¢

### 6.2 å››æ¨¡å—è¯¦è§£

```python
class ERM4System:
    """ERM4ç³»ç»Ÿ"""

    def __init__(self, llm, retriever):
        self.llm = llm
        self.retriever = retriever
        self.memory_kb = MemoryKnowledgeBase()

    def query(self, question: str) -> str:
        """ERM4æŸ¥è¯¢æµç¨‹"""
        # 1. æŸ¥è¯¢é‡å†™
        rewritten_query = self._rewrite_query(question)

        # 2. æ£€æŸ¥è®°å¿†çŸ¥è¯†åº“
        memory_results = self.memory_kb.search(rewritten_query)

        # 3. å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢
        if self._should_retrieve(rewritten_query, memory_results):
            # 4. æ£€ç´¢
            retrieved_docs = self.retriever.retrieve(rewritten_query, top_k=10)

            # 5. çŸ¥è¯†è¿‡æ»¤
            filtered_docs = self._filter_knowledge(retrieved_docs, rewritten_query)

            # 6. æ›´æ–°è®°å¿†çŸ¥è¯†åº“
            self.memory_kb.update(filtered_docs)
        else:
            filtered_docs = memory_results

        # 7. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(question, filtered_docs)

        return answer
```

---

## 7. XRAGï¼šé«˜çº§RAGç»„ä»¶åŸºå‡†æµ‹è¯•

### 7.1 XRAGæ¡†æ¶

XRAGæ˜¯ä¸€ä¸ªå¼€æºçš„æ¨¡å—åŒ–ä»£ç åº“ï¼Œæ—¨åœ¨å¯¹é«˜çº§RAGæ¨¡å—çš„åŸºç¡€ç»„ä»¶è¿›è¡Œå…¨é¢è¯„ä¼°ã€‚

#### æ ¸å¿ƒé˜¶æ®µ

1. **é¢„æ£€ç´¢**: æŸ¥è¯¢é‡å†™ã€æŸ¥è¯¢æ‰©å±•
2. **æ£€ç´¢**: å‘é‡æ£€ç´¢ã€å…³é”®è¯æ£€ç´¢ã€æ··åˆæ£€ç´¢
3. **åæ£€ç´¢**: é‡æ’åºã€è¿‡æ»¤
4. **ç”Ÿæˆ**: ä¸Šä¸‹æ–‡æ„å»ºã€ç­”æ¡ˆç”Ÿæˆ

### 7.3 åŸºå‡†æµ‹è¯•æ–¹æ³•

```python
class XRAGEvaluator:
    """XRAGè¯„ä¼°å™¨"""

    def evaluate_component(self, component: str, test_dataset: List[Dict]) -> Dict:
        """
        è¯„ä¼°ç‰¹å®šç»„ä»¶

        Args:
            component: ç»„ä»¶åç§°ï¼ˆ'pre_retrieval', 'retrieval', 'post_retrieval', 'generation'ï¼‰
            test_dataset: æµ‹è¯•æ•°æ®é›†
        """
        results = {
            'component': component,
            'metrics': {},
            'performance': {}
        }

        for test_case in test_dataset:
            # æ ¹æ®ç»„ä»¶ç±»å‹è¿›è¡Œè¯„ä¼°
            if component == 'pre_retrieval':
                result = self._evaluate_pre_retrieval(test_case)
            elif component == 'retrieval':
                result = self._evaluate_retrieval(test_case)
            # ... å…¶ä»–ç»„ä»¶

            # èšåˆç»“æœ
            self._aggregate_results(results, result)

        return results
```

---

## 8. æŠ€æœ¯å¯¹æ¯”ä¸é€‰æ‹©å»ºè®®

### 8.1 æŠ€æœ¯å¯¹æ¯”çŸ©é˜µ

| æŠ€æœ¯ | æ ¸å¿ƒä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ | å¤æ‚åº¦ | æ€§èƒ½æå‡ |
|------|---------|---------|--------|---------|
| **ActiveRAG** | ä¸»åŠ¨å­¦ä¹ ã€çŸ¥è¯†åŒåŒ– | å¤æ‚æŸ¥è¯¢ã€éœ€è¦æ·±åº¦ç†è§£ | é«˜ | 10%+ |
| **Multi-Head RAG** | å¤šæ–¹é¢æ£€ç´¢ | å¤šé¢é—®é¢˜ã€å·®å¼‚åŒ–æ–‡æ¡£ | ä¸­ | 20% |
| **RAG-Instruct** | æŒ‡ä»¤æ•°æ®åˆæˆ | è®­ç»ƒæ•°æ®ç”Ÿæˆã€few-shot | ä¸­ | æ˜¾è‘— |
| **HiRAG** | å±‚æ¬¡åŒ–æ£€ç´¢ | é•¿æ–‡æ¡£ã€ç»“æ„åŒ–çŸ¥è¯† | é«˜ | æ˜¾è‘— |
| **RichRAG** | å¤šæ–¹é¢å“åº” | å¼€æ”¾æ€§é—®é¢˜ã€å…¨é¢å›ç­” | ä¸­ | æ˜¾è‘— |
| **ERM4** | å››æ¨¡å—ååŒ | å¤æ‚åœºæ™¯ã€éœ€è¦è®°å¿† | é«˜ | æ˜¾è‘— |

### 8.2 é€‰æ‹©å»ºè®®

```text
é€‰æ‹©ActiveRAG:
âœ… éœ€è¦ä¸»åŠ¨å­¦ä¹ å’ŒçŸ¥è¯†å…³è”
âœ… å¤æ‚æŸ¥è¯¢åœºæ™¯
âœ… å¯¹å‡†ç¡®æ€§è¦æ±‚é«˜

é€‰æ‹©Multi-Head RAG:
âœ… æŸ¥è¯¢æ¶‰åŠå¤šä¸ªæ–¹é¢
âœ… éœ€è¦æ£€ç´¢å·®å¼‚åŒ–æ–‡æ¡£
âœ… éœ€è¦å…¨é¢çš„ç­”æ¡ˆ

é€‰æ‹©RAG-Instruct:
âœ… éœ€è¦ç”Ÿæˆè®­ç»ƒæ•°æ®
âœ… éœ€è¦few-shot learning
âœ… å¸Œæœ›æå‡æ¨¡å‹RAGèƒ½åŠ›

é€‰æ‹©HiRAG:
âœ… å¤„ç†é•¿æ–‡æ¡£
âœ… éœ€è¦ç»“æ„åŒ–çŸ¥è¯†
âœ… éœ€è¦å±‚æ¬¡åŒ–ç†è§£

é€‰æ‹©RichRAG:
âœ… å¼€æ”¾æ€§é—®é¢˜
âœ… éœ€è¦å…¨é¢å›ç­”
âœ… ç”¨æˆ·æœŸæœ›è¯¦ç»†è§£é‡Š

é€‰æ‹©ERM4:
âœ… å¤æ‚åœºæ™¯
âœ… éœ€è¦é•¿æœŸè®°å¿†
âœ… éœ€è¦æ™ºèƒ½æ£€ç´¢è§¦å‘
```

---

## ğŸ“š å‚è€ƒèµ„æº

1. **ActiveRAGè®ºæ–‡**: ActiveRAG: Revealing the Treasures of Knowledge via Active Learning
2. **Multi-Head RAGè®ºæ–‡**: Multi-Head RAG: Solving Multi-Aspect Problems with Retrieval-Augmented Generation
3. **RAG-Instructè®ºæ–‡**: RAG-Instruct: Diversifying Retrieval-Augmented Instruction Data
4. **HiRAGè®ºæ–‡**: HiRAG: Hierarchical Retrieval-Augmented Generation
5. **RichRAGè®ºæ–‡**: RichRAG: Enhancing Response Quality with Multi-Aspect Retrieval
6. **ERM4è®ºæ–‡**: ERM4: Four Modules for Enhancing RAG Quality and Efficiency
7. **XRAGè®ºæ–‡**: XRAG: Comprehensive Benchmarking of Advanced RAG Components

---

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0** (2025-01): åˆå§‹ç‰ˆæœ¬
  - ActiveRAGå®Œæ•´å®ç°
  - Multi-Head RAGå®Œæ•´å®ç°
  - RAG-Instructå®Œæ•´å®ç°
  - HiRAGæ¶æ„ä¸å®ç°
  - RichRAGæ¡†æ¶ä¸å®ç°
  - ERM4ç³»ç»Ÿå®ç°
  - XRAGåŸºå‡†æµ‹è¯•æ¡†æ¶
  - æŠ€æœ¯å¯¹æ¯”ä¸é€‰æ‹©å»ºè®®

---

**çŠ¶æ€**: âœ… **æ–‡æ¡£å®Œæˆ** | [è¿”å›ç›®å½•](./README.md)
