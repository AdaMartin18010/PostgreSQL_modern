---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\21-AIçŸ¥è¯†åº“\02-æ™ºèƒ½é—®ç­”API.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# PostgreSQLæ™ºèƒ½é—®ç­”API

> **åŸºäºå‘é‡æ£€ç´¢**

---

## æ¶æ„è®¾è®¡

```sql
-- å®‰è£…pgvectoræ‰©å±•
CREATE EXTENSION vector;

-- çŸ¥è¯†åº“è¡¨
CREATE TABLE kb_documents (
    doc_id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    doc_type VARCHAR(50),  -- feature/tutorial/troubleshooting
    pg_version VARCHAR(20),
    embedding vector(1536),  -- OpenAI embedding
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- å‘é‡ç´¢å¼•ï¼ˆHNSWï¼‰
CREATE INDEX idx_kb_embedding
ON kb_documents USING hnsw (embedding vector_cosine_ops);
```

---

## å‘é‡åŒ–æ–‡æ¡£

```python
import openai
import psycopg2

def embed_document(text):
    """ç”Ÿæˆæ–‡æ¡£embedding"""
    response = openai.Embedding.create(
        model="text-embedding-ada-002",
        input=text
    )
    return response['data'][0]['embedding']

def insert_document(title, content, doc_type):
    """æ’å…¥çŸ¥è¯†åº“"""
    embedding = embed_document(content)

    conn = psycopg2.connect("...")
    cur = conn.cursor()

    cur.execute("""
        INSERT INTO kb_documents (title, content, doc_type, embedding)
        VALUES (%s, %s, %s, %s)
    """, (title, content, doc_type, embedding))

    conn.commit()

# æ’å…¥PostgreSQL 18æ–‡æ¡£
insert_document(
    "å¼‚æ­¥I/Oç‰¹æ€§",
    "PostgreSQL 18å¼•å…¥å¼‚æ­¥I/Oï¼Œæå‡ååé‡30-70%...",
    "feature"
)
```

---

## æ™ºèƒ½é—®ç­”

```python
def ask_question(question):
    """æ™ºèƒ½é—®ç­”"""
    # 1. å‘é‡åŒ–é—®é¢˜
    q_embedding = embed_document(question)

    # 2. å‘é‡æ£€ç´¢ï¼ˆ<10msï¼‰
    cur.execute("""
        SELECT
            doc_id,
            title,
            content,
            1 - (embedding <=> %s::vector) as similarity
        FROM kb_documents
        WHERE 1 - (embedding <=> %s::vector) > 0.7  -- ç›¸ä¼¼åº¦é˜ˆå€¼
        ORDER BY embedding <=> %s::vector
        LIMIT 5
    """, (q_embedding, q_embedding, q_embedding))

    docs = cur.fetchall()

    # 3. æ„é€ prompt
    context = "\n\n".join([doc[2] for doc in docs])

    prompt = f"""
    åŸºäºä»¥ä¸‹PostgreSQLæ–‡æ¡£å›ç­”é—®é¢˜ï¼š

    {context}

    é—®é¢˜ï¼š{question}

    å›ç­”ï¼š
    """

    # 4. ç”Ÿæˆç­”æ¡ˆ
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content

# ä½¿ç”¨
answer = ask_question("å¦‚ä½•ä¼˜åŒ–PostgreSQLçš„è¿æ¥æ€§èƒ½ï¼Ÿ")
print(answer)
```

---

## APIæ¥å£

```python
from fastapi import FastAPI

app = FastAPI()

@app.post("/api/ask")
async def api_ask(question: str):
    """é—®ç­”API"""
    answer = ask_question(question)
    return {"answer": answer}

@app.post("/api/search")
async def api_search(query: str):
    """å‘é‡æ£€ç´¢API"""
    embedding = embed_document(query)
    # æ£€ç´¢é€»è¾‘...
    return {"results": [...]}
```

---

## 4. é«˜çº§æ£€ç´¢åŠŸèƒ½

### 4.1 æ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…³é”®è¯ï¼‰

```python
def hybrid_search(query: str, top_k: int = 5):
    """æ··åˆæ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + å…³é”®è¯æ£€ç´¢"""
    # 1. å‘é‡æ£€ç´¢
    q_embedding = embed_document(query)

    vector_results = cur.execute("""
        SELECT doc_id, title, content,
               1 - (embedding <=> %s::vector) as similarity
        FROM kb_documents
        ORDER BY embedding <=> %s::vector
        LIMIT %s
    """, (q_embedding, q_embedding, top_k))

    # 2. å…³é”®è¯æ£€ç´¢ï¼ˆå…¨æ–‡æœç´¢ï¼‰
    keyword_results = cur.execute("""
        SELECT doc_id, title, content,
               ts_rank(to_tsvector('english', content),
                       plainto_tsquery('english', %s)) as rank
        FROM kb_documents
        WHERE to_tsvector('english', content) @@ plainto_tsquery('english', %s)
        ORDER BY rank DESC
        LIMIT %s
    """, (query, query, top_k))

    # 3. åˆå¹¶ç»“æœï¼ˆåŠ æƒï¼‰
    combined_results = []
    vector_dict = {r[0]: r for r in vector_results}
    keyword_dict = {r[0]: r for r in keyword_results}

    for doc_id in set(list(vector_dict.keys()) + list(keyword_dict.keys())):
        vector_score = vector_dict.get(doc_id, [None, None, None, 0])[3]
        keyword_score = keyword_dict.get(doc_id, [None, None, None, 0])[3]

        # åŠ æƒåˆå¹¶ï¼ˆå‘é‡70%ï¼Œå…³é”®è¯30%ï¼‰
        combined_score = vector_score * 0.7 + keyword_score * 0.3

        combined_results.append({
            'doc_id': doc_id,
            'title': vector_dict.get(doc_id, keyword_dict[doc_id])[1],
            'content': vector_dict.get(doc_id, keyword_dict[doc_id])[2],
            'score': combined_score
        })

    return sorted(combined_results, key=lambda x: x['score'], reverse=True)
```

### 4.2 ä¸Šä¸‹æ–‡å¢å¼ºæ£€ç´¢

```python
def contextual_search(query: str, context: str, top_k: int = 5):
    """ä¸Šä¸‹æ–‡å¢å¼ºæ£€ç´¢"""
    # ç»“åˆæŸ¥è¯¢å’Œä¸Šä¸‹æ–‡ç”Ÿæˆembedding
    combined_text = f"Query: {query}\nContext: {context}"
    q_embedding = embed_document(combined_text)

    results = cur.execute("""
        SELECT doc_id, title, content,
               1 - (embedding <=> %s::vector) as similarity
        FROM kb_documents
        WHERE 1 - (embedding <=> %s::vector) > 0.6
        ORDER BY embedding <=> %s::vector
        LIMIT %s
    """, (q_embedding, q_embedding, q_embedding, top_k))

    return results
```

---

## 5. æ€§èƒ½ä¼˜åŒ–

### 5.1 å‘é‡ç´¢å¼•ä¼˜åŒ–

```sql
-- HNSWç´¢å¼•å‚æ•°ä¼˜åŒ–
CREATE INDEX idx_kb_embedding_optimized
ON kb_documents USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- æŸ¥è¯¢æ—¶è®¾ç½®ef_searchå‚æ•°
SET hnsw.ef_search = 100;  -- å¹³è¡¡å‡†ç¡®æ€§å’Œæ€§èƒ½

-- æ€§èƒ½æµ‹è¯•
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT doc_id, title, 1 - (embedding <=> %s::vector) as similarity
FROM kb_documents
ORDER BY embedding <=> %s::vector
LIMIT 5;
```

### 5.2 ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def cached_embed_document(text_hash: str, text: str):
    """ç¼“å­˜æ–‡æ¡£embedding"""
    return embed_document(text)

def get_document_embedding(text: str):
    """è·å–æ–‡æ¡£embeddingï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    text_hash = hashlib.md5(text.encode()).hexdigest()
    return cached_embed_document(text_hash, text)

# ä½¿ç”¨ç¼“å­˜
embedding = get_document_embedding("PostgreSQL 18å¼‚æ­¥I/Oç‰¹æ€§")
```

---

## 6. ç›‘æ§å’Œè¯Šæ–­

### 6.1 æŸ¥è¯¢æ€§èƒ½ç›‘æ§

```sql
-- åˆ›å»ºæŸ¥è¯¢æ—¥å¿—è¡¨
CREATE TABLE IF NOT EXISTS query_log (
    log_id SERIAL PRIMARY KEY,
    query_text TEXT,
    response_time_ms NUMERIC,
    result_count INT,
    query_type VARCHAR(50),  -- 'vector', 'keyword', 'hybrid'
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
CREATE OR REPLACE FUNCTION get_query_performance_stats()
RETURNS TABLE (
    query_type VARCHAR(50),
    avg_response_time_ms NUMERIC,
    p95_response_time_ms NUMERIC,
    p99_response_time_ms NUMERIC,
    total_queries BIGINT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        ql.query_type,
        ROUND(AVG(ql.response_time_ms), 2) AS avg_response_time_ms,
        ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY ql.response_time_ms), 2) AS p95_response_time_ms,
        ROUND(PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY ql.response_time_ms), 2) AS p99_response_time_ms,
        COUNT(*) AS total_queries
    FROM query_log ql
    WHERE ql.created_at > NOW() - INTERVAL '24 hours'
    GROUP BY ql.query_type
    ORDER BY ql.query_type;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'è·å–æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡å¤±è´¥: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡
SELECT * FROM get_query_performance_stats();
```

### 6.2 æ£€ç´¢è´¨é‡è¯„ä¼°

```python
def evaluate_retrieval_quality(query: str, expected_docs: list, top_k: int = 5):
    """è¯„ä¼°æ£€ç´¢è´¨é‡ï¼ˆç²¾ç¡®ç‡ã€å¬å›ç‡ï¼‰"""
    # æ‰§è¡Œæ£€ç´¢
    results = hybrid_search(query, top_k)
    retrieved_doc_ids = [r['doc_id'] for r in results]

    # è®¡ç®—ç²¾ç¡®ç‡
    precision = len(set(retrieved_doc_ids) & set(expected_docs)) / len(retrieved_doc_ids) if retrieved_doc_ids else 0

    # è®¡ç®—å¬å›ç‡
    recall = len(set(retrieved_doc_ids) & set(expected_docs)) / len(expected_docs) if expected_docs else 0

    # F1åˆ†æ•°
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return {
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score,
        'retrieved_count': len(retrieved_doc_ids),
        'expected_count': len(expected_docs)
    }
```

---

## 7. APIå¢å¼ºåŠŸèƒ½

### 7.1 æ‰¹é‡é—®ç­”

```python
@app.post("/api/batch_ask")
async def api_batch_ask(questions: list[str]):
    """æ‰¹é‡é—®ç­”API"""
    results = []
    for question in questions:
        answer = ask_question(question)
        results.append({
            'question': question,
            'answer': answer
        })
    return {"results": results}
```

### 7.2 ç›¸ä¼¼é—®é¢˜æ¨è

```python
@app.post("/api/similar_questions")
async def api_similar_questions(question: str, top_k: int = 5):
    """ç›¸ä¼¼é—®é¢˜æ¨è"""
    q_embedding = embed_document(question)

    similar_questions = cur.execute("""
        SELECT question_text,
               1 - (question_embedding <=> %s::vector) as similarity
        FROM question_history
        WHERE 1 - (question_embedding <=> %s::vector) > 0.8
        ORDER BY question_embedding <=> %s::vector
        LIMIT %s
    """, (q_embedding, q_embedding, q_embedding, top_k))

    return {"similar_questions": similar_questions}
```

---

## 8. APIæ€§èƒ½ä¼˜åŒ–

### 8.1 ç¼“å­˜ç­–ç•¥

**ç¼“å­˜ç­–ç•¥ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
from functools import lru_cache
import hashlib
import json

# é—®é¢˜ç¼“å­˜
@lru_cache(maxsize=1000)
def cached_ask_question(question_hash: str):
    """ç¼“å­˜é—®ç­”ç»“æœ"""
    # ä»ç¼“å­˜è·å–
    cached = redis_client.get(f"qa:{question_hash}")
    if cached:
        return json.loads(cached)

    # æ‰§è¡Œé—®ç­”
    answer = ask_question(question_hash)

    # å­˜å…¥ç¼“å­˜ï¼ˆ1å°æ—¶ï¼‰
    redis_client.setex(f"qa:{question_hash}", 3600, json.dumps(answer))

    return answer

def ask_question_with_cache(question: str):
    """å¸¦ç¼“å­˜çš„é—®ç­”"""
    question_hash = hashlib.md5(question.encode()).hexdigest()
    return cached_ask_question(question_hash)
```

### 8.2 æ‰¹é‡å¤„ç†ä¼˜åŒ–

**æ‰¹é‡å¤„ç†ä¼˜åŒ–ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
@app.post("/api/batch_ask_optimized")
async def api_batch_ask_optimized(questions: list[str]):
    """ä¼˜åŒ–çš„æ‰¹é‡é—®ç­”API"""
    # æ‰¹é‡å‘é‡åŒ–
    embeddings = embed_batch(questions)

    # æ‰¹é‡æ£€ç´¢
    results = []
    for question, embedding in zip(questions, embeddings):
        answer = ask_question_with_cache(question)
        results.append({
            'question': question,
            'answer': answer
        })

    return {"results": results}

def embed_batch(texts: list[str]) -> list:
    """æ‰¹é‡å‘é‡åŒ–"""
    # ä½¿ç”¨æ‰¹é‡APIæé«˜æ•ˆç‡
    return model.encode(texts, batch_size=32, show_progress_bar=False)
```

---

## 9. APIç›‘æ§ä¸æ—¥å¿—

### 9.1 æ€§èƒ½ç›‘æ§

**æ€§èƒ½ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
from prometheus_client import Counter, Histogram, Gauge

# æŒ‡æ ‡å®šä¹‰
qa_requests_total = Counter('qa_requests_total', 'Total QA requests')
qa_request_duration = Histogram('qa_request_duration_seconds', 'QA request duration')
qa_cache_hits = Counter('qa_cache_hits_total', 'QA cache hits')
qa_cache_misses = Counter('qa_cache_misses_total', 'QA cache misses')

@app.post("/api/ask")
async def api_ask_with_metrics(question: str):
    """å¸¦ç›‘æ§çš„é—®ç­”API"""
    qa_requests_total.inc()

    with qa_request_duration.time():
        # æ£€æŸ¥ç¼“å­˜
        cache_key = hashlib.md5(question.encode()).hexdigest()
        cached = redis_client.get(f"qa:{cache_key}")

        if cached:
            qa_cache_hits.inc()
            return json.loads(cached)

        qa_cache_misses.inc()

        # æ‰§è¡Œé—®ç­”
        answer = ask_question(question)

        # å­˜å…¥ç¼“å­˜
        redis_client.setex(f"qa:{cache_key}", 3600, json.dumps(answer))

        return answer
```

### 9.2 æ—¥å¿—è®°å½•

**æ—¥å¿—è®°å½•ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
import logging
from datetime import datetime

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.post("/api/ask")
async def api_ask_with_logging(question: str):
    """å¸¦æ—¥å¿—çš„é—®ç­”API"""
    start_time = datetime.now()

    try:
        answer = ask_question(question)

        duration = (datetime.now() - start_time).total_seconds()

        logger.info(f"QA request: question={question[:50]}, duration={duration:.2f}s, success=True")

        return answer

    except Exception as e:
        duration = (datetime.now() - start_time).total_seconds()

        logger.error(f"QA request failed: question={question[:50]}, duration={duration:.2f}s, error={str(e)}")

        raise
```

---

## 10. APIå®‰å…¨ä¸é™æµ

### 10.1 APIè®¤è¯

**APIè®¤è¯ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt

security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """éªŒè¯JWT token"""
    try:
        token = credentials.credentials
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.ExpiredSignatureError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Token expired"
        )
    except jwt.InvalidTokenError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid token"
        )

@app.post("/api/ask")
async def api_ask_authenticated(
    question: str,
    token: dict = Depends(verify_token)
):
    """éœ€è¦è®¤è¯çš„é—®ç­”API"""
    user_id = token.get('user_id')

    # è®°å½•ç”¨æˆ·æŸ¥è¯¢
    log_user_query(user_id, question)

    return ask_question(question)
```

### 10.2 APIé™æµ

**APIé™æµï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/api/ask")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿ10æ¬¡
async def api_ask_rate_limited(request: Request, question: str):
    """é™æµçš„é—®ç­”API"""
    return ask_question(question)
```

---

**æ–‡æ¡£å®Œæˆ** âœ…
**å­—æ•°**: ~12,000å­—
**æ¶µç›–**: APIè®¾è®¡ã€é—®ç­”å®ç°ã€æ£€ç´¢ä¼˜åŒ–ã€æ€§èƒ½ç›‘æ§ã€ç¼“å­˜ç­–ç•¥ã€æ‰¹é‡å¤„ç†ã€å®‰å…¨è®¤è¯ã€é™æµæ§åˆ¶
