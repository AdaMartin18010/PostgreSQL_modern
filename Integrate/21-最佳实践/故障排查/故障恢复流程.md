---

> **📋 文档来源**: `PostgreSQL_View\09-实践指南\故障排查\故障恢复流程.md`
> **📅 复制日期**: 2025-12-22
> **⚠️ 注意**: 本文档为复制版本，原文件保持不变

---

# PostgreSQL 向量搜索故障恢复流程

> **更新时间**: 2025 年 11 月 1 日
> **技术版本**: PostgreSQL 14+, pgvector 0.7.0+
> **文档编号**: 09-03-03

## 📑 目录

- [1.1 文档目标](#11-文档目标)
- [1.2 恢复目标](#12-恢复目标)
- [1.3 恢复原则](#13-恢复原则)
- [2.1 数据库服务故障](#21-数据库服务故障)
- [2.2 索引损坏](#22-索引损坏)
- [2.3 磁盘空间不足](#23-磁盘空间不足)
- [2.4 内存溢出](#24-内存溢出)
- [2.5 数据损坏](#25-数据损坏)
- [3.1 故障检测](#31-故障检测)
- [3.2 自动恢复](#32-自动恢复)
- [3.3 数据恢复](#33-数据恢复)
- [4.1 服务验证](#41-服务验证)
- [4.2 数据验证](#42-数据验证)
- [4.3 性能验证](#43-性能验证)
- [5.1 数据一致性检查](#51-数据一致性检查)
- [5.2 性能优化](#52-性能优化)
- [5.3 预防措施](#53-预防措施)
- [6.1 演练计划](#61-演练计划)
- [6.2 演练执行](#62-演练执行)
- [6.3 演练总结](#63-演练总结)
- [7.1 故障预防](#71-故障预防)
- [7.2 快速恢复](#72-快速恢复)
- [8.1 案例：金融系统故障恢复实施](#81-案例金融系统故障恢复实施)
- [8.2 案例：电商平台故障恢复优化](#82-案例电商平台故障恢复优化)
- [8.1 官方文档](#81-官方文档)
- [8.2 技术文档](#82-技术文档)
- [8.3 相关资源](#83-相关资源)
---

## 1. 概述

### 1.1 文档目标

**核心目标**:

本文档提供 PostgreSQL + pgvector 生产环境的故障恢复流程，确保在故障发生时能够快速恢复服务。

**文档价值**:

| 价值项       | 说明               | 影响         |
| ------------ | ------------------ | ------------ |
| **快速恢复** | 提供标准化恢复流程 | 减少故障时间 |
| **自动恢复** | 支持自动化恢复     | 提高恢复效率 |
| **故障预防** | 提供预防措施       | 减少故障发生 |

### 1.2 恢复目标

**恢复时间目标（RTO）**:

| 故障类型       | RTO          | 说明     |
| -------------- | ------------ | -------- |
| **服务不可用** | **<15 分钟** | 紧急故障 |
| **性能下降**   | **<1 小时**  | 性能问题 |
| **数据损坏**   | **<4 小时**  | 数据恢复 |

**恢复点目标（RPO）**:

| 恢复方式         | RPO         | 说明                 |
| ---------------- | ----------- | -------------------- |
| **完整备份恢复** | 24 小时     | 恢复到最近备份点     |
| **PITR 恢复**    | **<1 分钟** | **恢复到任意时间点** |

### 1.3 恢复原则

**恢复原则**:

1. **安全第一**: 确保恢复过程不造成数据丢失
1. **快速恢复**: 优先恢复核心服务
1. **最小影响**: 尽量减少对业务的影响
1. **可追溯**: 记录恢复过程和结果

## 2. 故障分类

### 2.1 数据库服务故障

#### 2.1.1 症状描述

**常见症状**:

1. **无法连接数据库**:

   ```text
   psql: error: connection to server failed
   FATAL: could not connect to server
   ```

1. **服务未运行**:

   ```bash
   systemctl status postgresql
   # Active: inactive (dead)
   ```

1. **端口未监听**:

   ```bash
   netstat -tuln | grep 5432
   # 无输出或端口未监听
   ```

**常见原因**:

| 原因         | 说明                     | 影响         |
| ------------ | ------------------------ | ------------ |
| **服务崩溃** | PostgreSQL 进程异常退出  | 服务不可用   |
| **配置错误** | postgresql.conf 配置错误 | 服务无法启动 |
| **资源不足** | 内存或磁盘不足           | 服务无法启动 |

#### 2.1.2 诊断步骤

**诊断步骤**:

```bash
# 步骤 1: 检查服务状态
systemctl status postgresql

# 步骤 2: 查看系统日志
journalctl -u postgresql -n 100 --no-pager

# 步骤 3: 查看 PostgreSQL 日志
tail -f /var/log/postgresql/postgresql-18-main.log

# 步骤 4: 检查进程
ps aux | grep postgres

# 步骤 5: 检查端口
netstat -tuln | grep 5432
# 或
ss -tuln | grep 5432

# 步骤 6: 检查配置
postgres --check-config -D /var/lib/postgresql/18/main
```

#### 2.1.3 恢复流程

**恢复流程详解**:

```bash
# 步骤 1: 尝试启动服务
systemctl start postgresql

# 如果启动失败，检查日志
journalctl -u postgresql -n 50 --no-pager

# 步骤 2: 检查配置（如果有配置错误）
postgres --check-config -D /var/lib/postgresql/18/main

# 步骤 3: 检查数据目录权限
ls -la /var/lib/postgresql/18/main
# 应该属于 postgres:postgres，权限为 0700

# 步骤 4: 检查磁盘空间
df -h /var/lib/postgresql

# 步骤 5: 检查内存
free -h

# 步骤 6: 如果以上都正常，尝试手动启动
sudo -u postgres postgres -D /var/lib/postgresql/18/main

# 步骤 7: 验证服务
psql -U postgres -c "SELECT version();"
```

**恢复时间**:

| 故障原因     | 恢复时间       | 说明         |
| ------------ | -------------- | ------------ |
| **服务崩溃** | **<5 分钟**    | 快速重启     |
| **配置错误** | **10-30 分钟** | 需要修复配置 |
| **资源不足** | **30-60 分钟** | 需要扩容资源 |

#### 2.1.4 验证恢复

**验证恢复步骤**:

```sql
-- 1. 验证连接
SELECT version();

-- 2. 验证数据库列表
SELECT datname FROM pg_database;

-- 3. 验证扩展
SELECT * FROM pg_extension WHERE extname = 'vector';

-- 4. 验证表
SELECT COUNT(*) FROM information_schema.tables
WHERE table_schema = 'public';

-- 5. 验证向量查询
SELECT COUNT(*) FROM documents
WHERE embedding IS NOT NULL;

-- 6. 验证索引
SELECT indexname FROM pg_indexes
WHERE tablename = 'documents'
  AND indexdef LIKE '%vector%';
```

### 2.2 索引损坏

#### 2.2.1 症状描述

**常见错误**:

```text
ERROR: index "documents_embedding_idx" is corrupted
ERROR: could not read block 12345 in file "base/16384/12345"
```

**常见原因**:

| 原因         | 说明           | 影响       |
| ------------ | -------------- | ---------- |
| **磁盘错误** | 磁盘 I/O 错误  | 索引损坏   |
| **系统崩溃** | 非正常关闭     | 索引不完整 |
| **硬件故障** | 内存或磁盘故障 | 索引损坏   |

#### 2.2.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查索引状态
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_stat_user_indexes
WHERE indexname = 'documents_embedding_idx';

-- 步骤 2: 尝试使用索引查询
EXPLAIN ANALYZE
SELECT * FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 10;

-- 如果报错，说明索引可能损坏

-- 步骤 3: 检查表健康度
SELECT
    schemaname,
    tablename,
    n_live_tup,
    n_dead_tup,
    last_vacuum,
    last_autovacuum
FROM pg_stat_user_tables
WHERE tablename = 'documents';

-- 步骤 4: 检查磁盘健康度（系统命令）
# smartctl -a /dev/sda  # 检查磁盘健康度
# dmesg | grep -i error  # 检查系统错误
```

#### 2.2.3 恢复流程

**恢复流程详解**:

```sql
-- 方案 1: 重建索引（推荐）
-- 步骤 1: 删除损坏的索引
DROP INDEX CONCURRENTLY documents_embedding_idx;

-- 注意：CONCURRENTLY 允许在重建时继续查询
-- 但构建时间可能更长

-- 步骤 2: 重建索引
CREATE INDEX CONCURRENTLY documents_embedding_idx
ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 步骤 3: 验证索引
EXPLAIN ANALYZE
SELECT * FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 10;

-- 方案 2: 如果表数据也有问题，先 VACUUM
VACUUM ANALYZE documents;

-- 然后重建索引
REINDEX INDEX CONCURRENTLY documents_embedding_idx;

-- 方案 3: 紧急情况，使用非并发重建（会锁表）
DROP INDEX documents_embedding_idx;
CREATE INDEX documents_embedding_idx
ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**恢复时间**:

| 索引大小    | 恢复时间       | 说明     |
| ----------- | -------------- | -------- |
| **<10GB**   | **10-30 分钟** | 小索引   |
| **10-50GB** | **30-60 分钟** | 中等索引 |
| **>50GB**   | **1-3 小时**   | 大索引   |

### 2.3 磁盘空间不足

#### 2.3.1 症状描述

**常见错误**:

```text
ERROR: could not extend file: No space left on device
ERROR: database filesystem is out of disk space
```

**常见原因**:

| 原因               | 说明           | 影响         |
| ------------------ | -------------- | ------------ |
| **数据增长**       | 数据量快速增长 | 磁盘空间耗尽 |
| **WAL 日志未清理** | WAL 归档未清理 | 磁盘空间耗尽 |
| **备份文件过多**   | 备份文件未清理 | 磁盘空间耗尽 |

#### 2.3.2 诊断步骤

**诊断步骤**:

```bash
# 步骤 1: 检查磁盘空间
df -h

# 步骤 2: 检查数据目录大小
du -sh /var/lib/postgresql/18/main/*

# 步骤 3: 检查 WAL 日志大小
du -sh /var/lib/postgresql/18/main/pg_wal/

# 步骤 4: 检查备份目录
du -sh /backup/postgres/*

# 步骤 5: 检查最大的表
psql -U postgres -d vector_db -c "
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 10;
"
```

#### 2.3.3 恢复流程

**恢复流程详解**:

```bash
# 步骤 1: 清理 WAL 日志（如果已归档）
# 检查 WAL 归档状态
psql -U postgres -c "SELECT pg_current_wal_lsn();"

# 清理旧的 WAL 日志
find /var/lib/postgresql/18/main/pg_wal/ -type f -mtime +3 -delete

# 或使用 pg_archivecleanup（如果已归档）
pg_archivecleanup /backup/wal/ archive_000000010000000100000001

# 步骤 2: 清理临时文件
rm -rf /tmp/postgresql_*
rm -rf /var/tmp/postgresql_*

# 步骤 3: 执行 VACUUM（回收空间）
psql -U postgres -d vector_db <<EOF
VACUUM FULL documents;
VACUUM FULL account_behaviors;
-- 对其他大表执行 VACUUM FULL
EOF

# 步骤 4: 清理旧备份
find /backup/postgres/ -type f -mtime +7 -delete

# 步骤 5: 扩大磁盘空间（如果需要）
# 使用 LVM 扩展或添加新磁盘
# lvextend -L +100G /dev/mapper/vg00-lv00
# resize2fs /dev/mapper/vg00-lv00

# 步骤 6: 验证空间
df -h
```

**空间清理优先级**:

| 清理项          | 优先级 | 风险 | 说明         |
| --------------- | ------ | ---- | ------------ |
| **临时文件**    | **高** | 低   | 安全清理     |
| **旧 WAL 日志** | **高** | 中   | 确保已归档   |
| **旧备份**      | **中** | 低   | 保留必要备份 |
| **VACUUM FULL** | **低** | 高   | 可能锁表     |

### 2.4 内存溢出

#### 2.4.1 症状描述

**常见错误**:

```text
ERROR: out of memory
DETAIL: Failed on request of size 4294967296
ERROR: could not allocate memory for query
```

**常见原因**:

| 原因             | 说明                                | 影响     |
| ---------------- | ----------------------------------- | -------- |
| **内存配置过高** | work_mem × max_connections > 总内存 | 内存溢出 |
| **查询过大**     | 批量查询内存需求过大                | 内存溢出 |
| **索引构建**     | HNSW 索引构建内存需求过大           | 内存溢出 |

#### 2.4.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查内存配置
SELECT
    name,
    setting,
    unit,
    (setting::NUMERIC *
     (SELECT setting::NUMERIC FROM pg_settings WHERE name = 'max_connections')) as total_mem_mb
FROM pg_settings
WHERE name IN (
    'shared_buffers',
    'work_mem',
    'maintenance_work_mem',
    'effective_cache_size',
    'max_connections'
);

-- 步骤 2: 检查系统内存
-- 使用系统命令
# free -h
# top 或 htop

-- 步骤 3: 检查当前内存使用
SELECT
    pid,
    usename,
    datname,
    application_name,
    state,
    query_start,
    LEFT(query, 100) as query_preview
FROM pg_stat_activity
WHERE state = 'active'
ORDER BY query_start;

-- 步骤 4: 检查索引构建进度（如果有正在构建的索引）
SELECT
    pid,
    datname,
    query,
    state,
    query_start
FROM pg_stat_activity
WHERE query LIKE '%CREATE INDEX%';
```

#### 2.4.3 恢复流程

**恢复流程详解**:

```sql
-- 方案 1: 临时降低内存配置（紧急）
-- 注意：这些配置需要重新加载或重启

ALTER SYSTEM SET work_mem = '64MB';
ALTER SYSTEM SET maintenance_work_mem = '512MB';
SELECT pg_reload_conf();

-- 某些参数需要重启 PostgreSQL
-- systemctl restart postgresql

-- 方案 2: 取消长时间运行的查询
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE state = 'active'
  AND query_start < NOW() - INTERVAL '1 hour'
  AND query NOT LIKE '%pg_stat_activity%';

-- 方案 3: 使用较小的索引参数
-- 重建索引时使用较小的参数

DROP INDEX IF EXISTS documents_embedding_idx;
CREATE INDEX documents_embedding_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 8,               -- 减小 m（默认 16）
    ef_construction = 32  -- 减小 ef_construction（默认 64）
);

-- 方案 4: 分批构建索引（超大规模数据）
-- 使用分区表，逐分区构建索引

-- 方案 5: 增加系统内存（长期方案）
-- 升级服务器内存或添加内存条
```

**内存优化建议**:

| 总内存   | work_mem | max_connections | 说明     |
| -------- | -------- | --------------- | -------- |
| **8GB**  | 64MB     | 50              | 小型应用 |
| **16GB** | 128MB    | 100             | 中型应用 |
| **32GB** | 256MB    | 200             | 大型应用 |

### 2.5 数据损坏

#### 2.5.1 症状描述

**常见症状**:

1. **查询错误**:

   ```text
   ERROR: invalid page header in block 12345
   ERROR: could not read block 12345
   ```

1. **数据不一致**:
   - COUNT(\*) 结果异常
   - 查询结果错误
   - 索引与实际数据不符

**常见原因**:

| 原因         | 说明                  | 影响       |
| ------------ | --------------------- | ---------- |
| **硬件故障** | 磁盘或内存故障        | 数据损坏   |
| **系统崩溃** | 非正常关闭            | 数据不一致 |
| **软件 Bug** | PostgreSQL 或扩展 Bug | 数据损坏   |

#### 2.5.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查数据完整性
SELECT
    schemaname,
    tablename,
    n_live_tup,
    n_dead_tup,
    last_vacuum,
    last_autovacuum,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as table_size
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 步骤 2: 检查损坏的表（PostgreSQL 9.6+）
SELECT
    c.oid,
    c.relname,
    pg_catalog.pg_table_is_visible(c.oid) as is_visible
FROM pg_catalog.pg_class c
LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
WHERE c.relkind = 'r'
  AND n.nspname = 'public'
  AND NOT EXISTS (
      SELECT 1 FROM pg_stat_user_tables
      WHERE schemaname = 'public' AND tablename = c.relname
  );

-- 步骤 3: 尝试查询表（检查是否有错误）
SELECT COUNT(*) FROM documents;

-- 步骤 4: 检查系统日志（系统命令）
# dmesg | grep -i error
# journalctl -u postgresql | grep -i error
```

#### 2.5.3 恢复流程

**恢复流程详解**:

```sql
-- 方案 1: VACUUM FULL（回收空间并修复）
VACUUM FULL documents;

-- 注意：VACUUM FULL 会锁表，生产环境需谨慎

-- 方案 2: REINDEX（重建索引）
REINDEX TABLE documents;

-- 方案 3: 从备份恢复（如果数据损坏严重）
-- 参考备份与恢复文档

-- 方案 4: 使用 pg_resetwal（最后手段，需停止服务）
-- 警告：可能导致数据丢失，仅在紧急情况下使用

# sudo systemctl stop postgresql
# sudo -u postgres pg_resetwal -D /var/lib/postgresql/18/main
# sudo systemctl start postgresql

-- 方案 5: 使用 pg_checksums 检查（PostgreSQL 12+）
-- 启用 checksums
# initdb --data-checksums

-- 检查数据完整性
# pg_checksums --check -D /var/lib/postgresql/18/main
```

## 3. 恢复流程

### 3.1 故障检测

#### 3.1.1 自动故障检测

**Python 自动故障检测脚本**:

```python
# fault_detection.py
import psycopg2
import subprocess
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DATABASE_URL = "postgresql://postgres:postgres@localhost:5432/vector_db"

def detect_faults():
    """自动故障检测"""
    faults = []

    # 1. 检查数据库连接
    try:
        conn = psycopg2.connect(DATABASE_URL, connect_timeout=5)
        conn.close()
        logger.info("✅ 数据库连接正常")
    except psycopg2.OperationalError as e:
        fault = {
            'type': '连接故障',
            'severity': 'CRITICAL',
            'message': f"无法连接数据库: {str(e)}",
            'action': '重启 PostgreSQL 服务'
        }
        faults.append(fault)
        logger.error(f"❌ {fault['message']}")

    # 2. 检查扩展
    if not faults:
        try:
            conn = psycopg2.connect(DATABASE_URL)
            cur = conn.cursor()
            cur.execute("SELECT * FROM pg_extension WHERE extname = 'vector'")
            if cur.fetchone() is None:
                fault = {
                    'type': '扩展缺失',
                    'severity': 'HIGH',
                    'message': 'pgvector 扩展未启用',
                    'action': 'CREATE EXTENSION vector;'
                }
                faults.append(fault)
                logger.error(f"❌ {fault['message']}")
            conn.close()
        except Exception as e:
            fault = {
                'type': '查询故障',
                'severity': 'HIGH',
                'message': f"查询失败: {str(e)}",
                'action': '检查数据库状态'
            }
            faults.append(fault)
            logger.error(f"❌ {fault['message']}")

    # 3. 检查索引
    if not faults:
        try:
            conn = psycopg2.connect(DATABASE_URL)
            cur = conn.cursor()
            cur.execute("""
                SELECT COUNT(*) FROM pg_indexes
                WHERE tablename = 'documents'
                  AND indexdef LIKE '%vector%'
            """)
            index_count = cur.fetchone()[0]
            if index_count == 0:
                fault = {
                    'type': '索引缺失',
                    'severity': 'MEDIUM',
                    'message': '向量索引不存在',
                    'action': '创建向量索引'
                }
                faults.append(fault)
                logger.warning(f"⚠️ {fault['message']}")
            conn.close()
        except Exception as e:
            logger.error(f"检查索引失败: {str(e)}")

    # 4. 检查磁盘空间
    try:
        result = subprocess.run(
            ["df", "-h", "/var/lib/postgresql"],
            capture_output=True,
            text=True,
            check=True
        )
        lines = result.stdout.strip().split('\n')
        if len(lines) > 1:
            usage = lines[1].split()[4].rstrip('%')
            if int(usage) > 90:
                fault = {
                    'type': '磁盘空间不足',
                    'severity': 'CRITICAL',
                    'message': f"磁盘使用率: {usage}%",
                    'action': '清理磁盘空间'
                }
                faults.append(fault)
                logger.error(f"❌ {fault['message']}")
    except Exception as e:
        logger.error(f"检查磁盘空间失败: {str(e)}")

    # 5. 检查内存
    try:
        result = subprocess.run(
            ["free", "-m"],
            capture_output=True,
            text=True,
            check=True
        )
        lines = result.stdout.strip().split('\n')
        if len(lines) > 1:
            mem_info = lines[1].split()
            total_mem = int(mem_info[1])
            used_mem = int(mem_info[2])
            usage = (used_mem / total_mem) * 100
            if usage > 90:
                fault = {
                    'type': '内存不足',
                    'severity': 'HIGH',
                    'message': f"内存使用率: {usage:.1f}%",
                    'action': '优化内存配置或增加内存'
                }
                faults.append(fault)
                logger.warning(f"⚠️ {fault['message']}")
    except Exception as e:
        logger.error(f"检查内存失败: {str(e)}")

    return faults

if __name__ == "__main__":
    faults = detect_faults()
    if faults:
        print(f"\n发现 {len(faults)} 个问题:")
        for fault in faults:
            print(f"  [{fault['severity']}] {fault['type']}: {fault['message']}")
            print(f"    操作: {fault['action']}")
    else:
        print("✅ 未发现问题")
```

#### 3.1.2 故障分类

**故障分类矩阵**:

| 故障类型         | 严重程度 | 优先级 | 响应时间     |
| ---------------- | -------- | ------ | ------------ |
| **服务不可用**   | CRITICAL | P0     | **<15 分钟** |
| **数据损坏**     | CRITICAL | P0     | **<15 分钟** |
| **磁盘空间不足** | CRITICAL | P0     | **<30 分钟** |
| **索引损坏**     | HIGH     | P1     | **<1 小时**  |
| **内存溢出**     | HIGH     | P1     | **<1 小时**  |
| **扩展问题**     | MEDIUM   | P2     | **<4 小时**  |

### 3.2 自动恢复

#### 3.2.1 自动恢复脚本

**Python 自动恢复脚本**:

```python
# auto_recovery.py
import psycopg2
import subprocess
import logging
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def restart_postgresql():
    """重启 PostgreSQL 服务"""
    try:
        result = subprocess.run(
            ["systemctl", "restart", "postgresql"],
            capture_output=True,
            text=True,
            check=True,
            timeout=60
        )
        logger.info("✅ PostgreSQL 服务已重启")

        # 等待服务启动
        time.sleep(10)

        # 验证服务
        conn = psycopg2.connect(DATABASE_URL, connect_timeout=10)
        conn.close()
        logger.info("✅ PostgreSQL 服务验证成功")
        return True
    except Exception as e:
        logger.error(f"❌ 重启失败: {str(e)}")
        return False

def rebuild_indexes():
    """重建索引"""
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()

        # 删除旧索引
        cur.execute("DROP INDEX IF EXISTS documents_embedding_idx CASCADE;")
        conn.commit()

        # 重建索引
        cur.execute("""
            CREATE INDEX CONCURRENTLY documents_embedding_idx
            ON documents
            USING hnsw (embedding vector_cosine_ops)
            WITH (m = 16, ef_construction = 64);
        """)
        conn.commit()

        logger.info("✅ 索引重建成功")
        conn.close()
        return True
    except Exception as e:
        logger.error(f"❌ 索引重建失败: {str(e)}")
        return False

def cleanup_connections():
    """清理空闲连接"""
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()

        cur.execute("""
            SELECT pg_terminate_backend(pid)
            FROM pg_stat_activity
            WHERE datname = 'vector_db'
              AND state = 'idle'
              AND state_change < NOW() - INTERVAL '10 minutes';
        """)

        terminated = cur.rowcount
        conn.commit()
        conn.close()

        logger.info(f"✅ 清理了 {terminated} 个空闲连接")
        return True
    except Exception as e:
        logger.error(f"❌ 清理连接失败: {str(e)}")
        return False

def cleanup_disk_space():
    """清理磁盘空间"""
    try:
        # 清理临时文件
        subprocess.run(["rm", "-rf", "/tmp/postgresql_*"], check=False)

        # 清理旧 WAL（如果已归档）
        subprocess.run([
            "find", "/var/lib/postgresql/18/main/pg_wal/",
            "-type", "f", "-mtime", "+3", "-delete"
        ], check=False)

        logger.info("✅ 磁盘清理完成")
        return True
    except Exception as e:
        logger.error(f"❌ 磁盘清理失败: {str(e)}")
        return False

def auto_recover():
    """自动恢复"""
    from fault_detection import detect_faults

    faults = detect_faults()

    if not faults:
        logger.info("✅ 未发现问题")
        return True

    recovered = []
    failed = []

    for fault in faults:
        fault_type = fault['type']
        logger.info(f"尝试恢复: {fault_type}")

        if fault_type == '连接故障':
            if restart_postgresql():
                recovered.append(fault_type)
            else:
                failed.append(fault_type)

        elif fault_type == '索引缺失' or fault_type == '索引损坏':
            if rebuild_indexes():
                recovered.append(fault_type)
            else:
                failed.append(fault_type)

        elif fault_type == '磁盘空间不足':
            if cleanup_disk_space():
                recovered.append(fault_type)
            else:
                failed.append(fault_type)

        elif fault_type == '内存不足':
            if cleanup_connections():
                recovered.append(fault_type)
            else:
                failed.append(fault_type)

    # 验证恢复
    faults_after = detect_faults()

    if not faults_after:
        logger.info("✅ 所有故障已自动恢复")
        return True
    else:
        logger.warning(f"⚠️ 仍有 {len(faults_after)} 个问题需要人工干预")
        return False

if __name__ == "__main__":
    auto_recover()
```

#### 3.2.2 恢复策略

**恢复策略矩阵**:

| 故障类型         | 自动恢复     | 人工干预 | 恢复时间     |
| ---------------- | ------------ | -------- | ------------ |
| **服务不可用**   | 重启服务     | 配置错误 | **<5 分钟**  |
| **索引损坏**     | 重建索引     | 数据损坏 | **<1 小时**  |
| **磁盘空间不足** | 清理临时文件 | 扩容磁盘 | **<30 分钟** |
| **内存溢出**     | 清理连接     | 增加内存 | **<30 分钟** |

### 3.3 数据恢复

#### 3.3.1 从备份恢复

**从备份恢复流程**:

```bash
# 步骤 1: 停止服务（如果需要完整恢复）
systemctl stop postgresql

# 步骤 2: 备份当前数据（以防万一）
pg_dump -U postgres -d vector_db -F c -f backup_before_restore_$(date +%Y%m%d_%H%M%S).dump

# 步骤 3: 清理现有数据（谨慎操作）
dropdb -U postgres vector_db
createdb -U postgres vector_db

# 步骤 4: 从备份恢复
pg_restore -U postgres \
  -d vector_db \
  -F c \
  --clean \
  --if-exists \
  backup_vector_db_20251101_020000.dump

# 步骤 5: 验证恢复
psql -U postgres -d vector_db -c "
SELECT
    COUNT(*) as table_count,
    SUM(n_live_tup) as total_rows
FROM pg_stat_user_tables
WHERE schemaname = 'public';
"

# 步骤 6: 启动服务
systemctl start postgresql
```

#### 3.3.2 点对点恢复

**PITR 恢复流程**:

```bash
# 步骤 1: 停止服务
systemctl stop postgresql

# 步骤 2: 备份当前数据目录（以防万一）
mv /var/lib/postgresql/18/main /var/lib/postgresql/18/main.backup

# 步骤 3: 恢复基础备份
mkdir -p /var/lib/postgresql/18/main
tar -xzf /backup/base_20251101_020000.tar.gz -C /var/lib/postgresql/18/main

# 步骤 4: 配置恢复参数
cat > /var/lib/postgresql/18/main/postgresql.conf <<EOF
recovery_target_time = '2025-11-01 10:00:00'
restore_command = 'cp /backup/wal/%f %p'
recovery_target_action = 'promote'
EOF

# 步骤 5: 创建恢复信号文件
touch /var/lib/postgresql/18/main/recovery.signal

# 步骤 6: 启动服务（自动恢复）
systemctl start postgresql

# 步骤 7: 监控恢复进度
tail -f /var/log/postgresql/postgresql-18-main.log

# 步骤 8: 验证恢复
psql -U postgres -d vector_db -c "SELECT NOW();"
```

#### 3.3.3 部分恢复

**部分恢复流程**:

```bash
# 方案 1: 恢复特定表
pg_restore -U postgres \
  -d vector_db \
  -t documents \
  -F c \
  --clean \
  --if-exists \
  backup_vector_db_20251101_020000.dump

# 方案 2: 仅恢复数据（表结构已存在）
pg_restore -U postgres \
  -d vector_db \
  --data-only \
  -F c \
  backup_data_20251101_020000.dump

# 方案 3: 仅恢复结构（重新创建表）
pg_restore -U postgres \
  -d vector_db \
  --schema-only \
  -F c \
  backup_schema_20251101_020000.dump
```

## 4. 恢复验证

### 4.1 服务验证

**服务验证步骤**:

```bash
# 1. 检查服务状态
systemctl status postgresql

# 2. 检查端口监听
netstat -tuln | grep 5432

# 3. 测试连接
psql -U postgres -c "SELECT version();"

# 4. 检查数据库列表
psql -U postgres -c "\l"

# 5. 检查扩展
psql -U postgres -d vector_db -c "\dx"
```

### 4.2 数据验证

**数据验证查询**:

```sql
-- 1. 验证表数量
SELECT COUNT(*) as table_count
FROM information_schema.tables
WHERE table_schema = 'public'
  AND table_type = 'BASE TABLE';

-- 2. 验证数据行数
SELECT
    schemaname,
    tablename,
    n_live_tup as row_count
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY n_live_tup DESC;

-- 3. 验证向量数据
SELECT
    COUNT(*) as total_vectors,
    COUNT(*) FILTER (WHERE embedding IS NOT NULL) as non_null_vectors
FROM documents;

-- 4. 验证索引
SELECT
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
  AND indexdef LIKE '%vector%';

-- 5. 测试向量查询
SELECT
    id,
    content,
    1 - (embedding <=> query_vector::vector) as similarity
FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 5;
```

### 4.3 性能验证

**性能验证查询**:

```sql
-- 1. 测试查询性能
EXPLAIN ANALYZE
SELECT * FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 10;

-- 2. 检查查询计划（确保使用索引）
EXPLAIN
SELECT * FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 10;

-- 预期输出应包含：
-- Index Scan using documents_embedding_idx

-- 3. 检查缓存命中率
SELECT
    sum(heap_blks_read) as disk_reads,
    sum(heap_blks_hit) as cache_hits,
    sum(heap_blks_hit)::float / NULLIF(sum(heap_blks_hit) + sum(heap_blks_read), 0) * 100 as cache_hit_rate
FROM pg_statio_user_tables
WHERE schemaname = 'public';
```

## 5. 恢复后处理

### 5.1 数据一致性检查

**数据一致性检查**:

```sql
-- 1. 执行 VACUUM ANALYZE
VACUUM ANALYZE documents;

-- 2. 更新统计信息
ANALYZE documents;

-- 3. 检查死元组
SELECT
    schemaname,
    tablename,
    n_dead_tup,
    n_live_tup,
    (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) * 100 as dead_ratio
FROM pg_stat_user_tables
WHERE tablename = 'documents';

-- 4. 重建索引（如果需要）
REINDEX INDEX CONCURRENTLY documents_embedding_idx;
```

### 5.2 性能优化

**性能优化步骤**:

```sql
-- 1. 更新统计信息
ANALYZE documents;

-- 2. 检查慢查询
SELECT
    query,
    mean_exec_time,
    calls
FROM pg_stat_statements
WHERE query LIKE '%<=>%' OR query LIKE '%<->%'
ORDER BY mean_exec_time DESC
LIMIT 10;

-- 3. 检查索引效率
SELECT
    indexname,
    idx_scan,
    idx_tup_read
FROM pg_stat_user_indexes
WHERE tablename = 'documents';

-- 4. 优化查询参数（如果需要）
SET hnsw.ef_search = 40;
SET ivfflat.probes = 10;
```

### 5.3 预防措施

**预防措施清单**:

1. **监控告警**: 设置监控告警，及时发现问题
1. **定期备份**: 每天执行备份，保留多个备份
1. **定期维护**: 定期执行 VACUUM 和 ANALYZE
1. **容量规划**: 监控磁盘和内存使用，提前扩容

## 6. 故障恢复演练

### 6.1 演练计划

**演练计划**:

| 演练类型     | 频率   | 时间       | 说明             |
| ------------ | ------ | ---------- | ---------------- |
| **完整演练** | 每季度 | 2-4 小时   | 模拟完整故障恢复 |
| **部分演练** | 每月   | 30-60 分钟 | 模拟特定故障     |
| **快速演练** | 每周   | 15 分钟    | 验证恢复流程     |

### 6.2 演练执行

**演练执行步骤**:

1. **准备阶段**: 准备测试环境、备份文件
1. **模拟故障**: 模拟各种故障场景
1. **执行恢复**: 按照恢复流程执行恢复
1. **验证恢复**: 验证服务、数据和性能
1. **记录结果**: 记录恢复时间和遇到的问题

### 6.3 演练总结

**演练总结内容**:

1. **恢复时间**: 记录各类型故障的恢复时间
1. **问题总结**: 记录遇到的问题和解决方案
1. **流程优化**: 优化恢复流程，提高恢复效率
1. **培训更新**: 更新培训和文档

## 7. 最佳实践

### 7.1 故障预防

**故障预防措施**:

1. **监控告警**:

   - 设置服务监控
   - 设置性能告警
   - 设置资源告警

1. **定期维护**:

   - 每天 ANALYZE
   - 每周 VACUUM ANALYZE
   - 每月检查索引效率

1. **容量规划**:
   - 监控磁盘使用
   - 监控内存使用
   - 提前扩容资源

### 7.2 快速恢复

**快速恢复技巧**:

1. **自动化**: 使用自动化脚本减少人工干预
1. **预案准备**: 提前准备恢复脚本和流程
1. **团队协作**: 建立故障响应团队
1. **文档完善**: 保持恢复文档更新

## 8. 实际应用案例

### 8.1 案例：金融系统故障恢复实施

**业务场景**:

某银行核心系统（2025年数据）：

- **数据规模**: 50TB
- **交易量**: 每秒10000笔
- **RTO要求**: <30分钟
- **RPO要求**: <5分钟

**故障恢复流程**:

```bash
# 1. 故障检测
# 使用Patroni自动检测主节点故障
patronictl list

# 2. 自动故障转移
# Patroni自动提升从节点为主节点
# 故障转移时间: <2分钟

# 3. 数据恢复验证
psql -h new-primary -c "
    SELECT
        COUNT(*) as record_count,
        MAX(transaction_time) as latest_transaction
    FROM transactions
    WHERE transaction_time > NOW() - INTERVAL '1 hour';
"

# 4. 应用切换
# 更新应用连接配置，指向新主节点
```

**实施效果**:

| 指标 | 优化前 | 优化后 | 改善 |
| --- | --- | --- | --- |
| **故障恢复时间** | 2小时 | **<25分钟** | **79%** ⬇️ |
| **数据丢失** | 1小时 | **<3分钟** | **95%** ⬇️ |
| **系统可用性** | 99.5% | **99.99%** | **+0.49%** |
| **自动化程度** | 30% | **95%** | **+217%** |

### 8.2 案例：电商平台故障恢复优化

**业务场景**:

某大型电商平台（2025年数据）：

- **数据规模**: 200TB
- **查询QPS**: 50000
- **RTO要求**: <1小时
- **业务要求**: 支持跨区域故障恢复

**故障恢复流程**:

```bash
# 1. 跨区域故障检测
# 主区域: us-east-1
# 备份区域: us-west-2

# 2. 检测主区域故障
if ! check_primary_region_health; then
    echo "Primary region failed, switching to backup region"

    # 3. 切换到备份区域
    promote_backup_region

    # 4. 更新DNS和负载均衡器配置
    update_dns_records
    update_load_balancer

    # 5. 验证数据完整性
    verify_data_integrity
fi
```

**实施效果**:

| 指标 | 优化前 | 优化后 | 改善 |
| --- | --- | --- | --- |
| **故障恢复时间** | 4小时 | **<45分钟** | **81%** ⬇️ |
| **跨区域恢复** | 不支持 | **支持** | **新增功能** |
| **数据丢失** | 30分钟 | **<8分钟** | **73%** ⬇️ |
| **业务连续性** | 85% | **99.5%** | **+17%** |

---

## 9. 参考资料

### 8.1 官方文档

- [PostgreSQL 故障排查](https://www.postgresql.org/docs/current/runtime-config-logging.html) -
  Runtime Configuration
- [PostgreSQL 恢复文档](https://www.postgresql.org/docs/current/recovery.html) - Recovery
  Documentation

### 8.2 技术文档

- [常见问题诊断](./常见问题诊断.md) - Common Issues Diagnosis
- [备份与恢复](../运维手册/备份与恢复.md) - Backup and Recovery

### 8.3 相关资源

- [PostgreSQL 高可用](https://www.postgresql.org/docs/current/high-availability.html) - High
  Availability
- [故障恢复最佳实践](https://www.postgresql.org/docs/current/recovery-config.html) - Recovery
  Configuration

---

**最后更新**: 2025 年 11 月 1 日
**维护者**: PostgreSQL Modern Team
**文档编号**: 09-03-02
