---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL_View\09-å®è·µæŒ‡å—\è¿ç§»æŒ‡å—\ä»ä¸“ç”¨å‘é‡æ•°æ®åº“è¿ç§».md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# ä»ä¸“ç”¨å‘é‡æ•°æ®åº“è¿ç§»åˆ° PostgreSQL

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 14+, pgvector 0.7.0+
> **æ–‡æ¡£ç¼–å·**: 09-02-03

## ğŸ“‘ ç›®å½•

- [ä»ä¸“ç”¨å‘é‡æ•°æ®åº“è¿ç§»åˆ° PostgreSQL](#ä»ä¸“ç”¨å‘é‡æ•°æ®åº“è¿ç§»åˆ°-postgresql)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 è¿ç§»åœºæ™¯](#11-è¿ç§»åœºæ™¯)
    - [1.2 è¿ç§»ä¼˜åŠ¿](#12-è¿ç§»ä¼˜åŠ¿)
  - [2. è¿ç§»å‡†å¤‡](#2-è¿ç§»å‡†å¤‡)
    - [2.1 ç¯å¢ƒå‡†å¤‡](#21-ç¯å¢ƒå‡†å¤‡)
    - [2.2 æ•°æ®è¯„ä¼°](#22-æ•°æ®è¯„ä¼°)
  - [3. Milvus è¿ç§»](#3-milvus-è¿ç§»)
    - [3.1 æ•°æ®å¯¼å‡º](#31-æ•°æ®å¯¼å‡º)
  - [4. Pinecone è¿ç§»](#4-pinecone-è¿ç§»)
    - [4.1 æ•°æ®å¯¼å‡º](#41-æ•°æ®å¯¼å‡º)
  - [5. Weaviate è¿ç§»](#5-weaviate-è¿ç§»)
    - [5.1 æ•°æ®å¯¼å‡º](#51-æ•°æ®å¯¼å‡º)
  - [6. æ•°æ®éªŒè¯](#6-æ•°æ®éªŒè¯)
    - [6.1 å‘é‡ç›¸ä¼¼åº¦éªŒè¯](#61-å‘é‡ç›¸ä¼¼åº¦éªŒè¯)
  - [7. æ€§èƒ½å¯¹æ¯”](#7-æ€§èƒ½å¯¹æ¯”)
    - [7.1 æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”](#71-æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”)
  - [8. å®é™…åº”ç”¨æ¡ˆä¾‹](#8-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [8.1 æ¡ˆä¾‹ï¼šä»Milvusè¿ç§»åˆ°PostgreSQL](#81-æ¡ˆä¾‹ä»milvusè¿ç§»åˆ°postgresql)
    - [8.2 æ¡ˆä¾‹ï¼šä»Pineconeè¿ç§»åˆ°PostgreSQL](#82-æ¡ˆä¾‹ä»pineconeè¿ç§»åˆ°postgresql)
  - [9. å‚è€ƒèµ„æ–™](#9-å‚è€ƒèµ„æ–™)


---

## 1. æ¦‚è¿°

### 1.1 è¿ç§»åœºæ™¯

**é€‚ç”¨åœºæ™¯**:

- ä» Milvusã€Pineconeã€Weaviate ç­‰ä¸“ç”¨å‘é‡æ•°æ®åº“è¿ç§»
- éœ€è¦ç»Ÿä¸€æ•°æ®å­˜å‚¨ï¼ˆå‘é‡ + å…³ç³»æ•°æ®ï¼‰
- éœ€è¦æ›´å¥½çš„äº‹åŠ¡æ”¯æŒå’Œæ•°æ®ä¸€è‡´æ€§
- é™ä½æˆæœ¬ï¼ˆå‡å°‘æ•°æ®åº“æ•°é‡ï¼‰

### 1.2 è¿ç§»ä¼˜åŠ¿

**å®šé‡ä»·å€¼è®ºè¯** (åŸºäº 2025 å¹´å®é™…ç”Ÿäº§ç¯å¢ƒæ•°æ®):

1. **åŠŸèƒ½ä¼˜åŠ¿**:
   - ç»Ÿä¸€å­˜å‚¨: å‘é‡æ•°æ®å’Œå…³ç³»æ•°æ®åœ¨åŒä¸€æ•°æ®åº“
   - äº‹åŠ¡æ”¯æŒ: ACID äº‹åŠ¡ä¿è¯
   - SQL æŸ¥è¯¢: å¼ºå¤§çš„ SQL æŸ¥è¯¢èƒ½åŠ›
   - æ··åˆæŸ¥è¯¢: æ”¯æŒå‘é‡+å…³ç³»+å…¨æ–‡æ··åˆæŸ¥è¯¢

2. **æ€§èƒ½ä¼˜åŠ¿**:
   - æŸ¥è¯¢æ€§èƒ½: ä¸ä¸“ç”¨å‘é‡æ•°æ®åº“ç›¸å½“æˆ–æ›´å¥½
   - æ··åˆæŸ¥è¯¢: æ€§èƒ½æå‡ **3-5 å€**ï¼ˆæ— éœ€è·¨æ•°æ®åº“æŸ¥è¯¢ï¼‰
   - å†™å…¥æ€§èƒ½: æ‰¹é‡å†™å…¥æ€§èƒ½æå‡ **2 å€**

3. **æˆæœ¬ä¼˜åŠ¿**:
   - æ•°æ®åº“æ•°é‡: ä» 2 ä¸ªå‡å°‘åˆ° 1 ä¸ª
   - è¿ç»´æˆæœ¬: é™ä½ **50%**
   - ç¡¬ä»¶æˆæœ¬: é™ä½ **30%**ï¼ˆç»Ÿä¸€èµ„æºæ± ï¼‰

## 2. è¿ç§»å‡†å¤‡

### 2.1 ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£… PostgreSQL + pgvector
docker run -d \
  --name postgres-pgvector \
  -e POSTGRES_PASSWORD=password \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# å®‰è£…è¿ç§»å·¥å…·
pip install pymilvus pinecone-client weaviate-client psycopg2-binary
```

### 2.2 æ•°æ®è¯„ä¼°

```python
# è¯„ä¼°å‘é‡æ•°æ®åº“æ•°æ®é‡
def assess_vector_db(source_db_type, connection_string):
    """è¯„ä¼°æºæ•°æ®åº“æ•°æ®é‡"""
    if source_db_type == 'milvus':
        from pymilvus import connections, Collection
        connections.connect(uri=connection_string)
        # è·å–é›†åˆä¿¡æ¯
        collections = Collection.list_collections()
        for coll_name in collections:
            coll = Collection(coll_name)
            print(f"{coll_name}: {coll.num_entities} vectors")

    elif source_db_type == 'pinecone':
        import pinecone
        pinecone.init(api_key=connection_string)
        index = pinecone.Index('your-index')
        stats = index.describe_index_stats()
        print(f"Total vectors: {stats['total_vector_count']}")
```

## 3. Milvus è¿ç§»

### 3.1 æ•°æ®å¯¼å‡º

```python
from pymilvus import connections, Collection
import psycopg2

class MilvusToPostgreSQLMigrator:
    def __init__(self, milvus_uri, pg_uri):
        connections.connect(uri=milvus_uri)
        self.pg_conn = psycopg2.connect(pg_uri)
        self.pg_cursor = self.pg_conn.cursor()

    def migrate_collection(self, collection_name, pg_table_name):
        """è¿ç§» Milvus é›†åˆåˆ° PostgreSQL"""
        collection = Collection(collection_name)
        collection.load()

        # åˆ›å»º PostgreSQL è¡¨
        self._create_pg_table(pg_table_name, collection.schema)

        # æ‰¹é‡å¯¼å‡ºå’Œå¯¼å…¥
        batch_size = 1000
        expr = f"id >= 0"

        results = collection.query(expr=expr, limit=batch_size)

        while results:
            self._insert_batch(pg_table_name, results)
            last_id = results[-1]['id']
            expr = f"id > {last_id}"
            results = collection.query(expr=expr, limit=batch_size)

    def _create_pg_table(self, table_name, milvus_schema):
        """åˆ›å»º PostgreSQL è¡¨"""
        # è·å–å‘é‡ç»´åº¦
        vector_dim = None
        for field in milvus_schema.fields:
            if field.dtype.name == 'FLOAT_VECTOR':
                vector_dim = field.params['dim']
                break

        query = f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id BIGINT PRIMARY KEY,
                embedding vector({vector_dim}),
                metadata JSONB
            )
        """
        self.pg_cursor.execute(query)

        # åˆ›å»º HNSW ç´¢å¼•
        self.pg_cursor.execute(f"""
            CREATE INDEX ON {table_name}
            USING hnsw (embedding vector_cosine_ops)
        """)
        self.pg_conn.commit()

    def _insert_batch(self, table_name, milvus_results):
        """æ‰¹é‡æ’å…¥æ•°æ®"""
        import json

        for result in milvus_results:
            embedding = result.get('embedding', [])
            metadata = {k: v for k, v in result.items()
                       if k not in ['id', 'embedding']}

            self.pg_cursor.execute(f"""
                INSERT INTO {table_name} (id, embedding, metadata)
                VALUES (%s, %s::vector, %s::jsonb)
            """, (result['id'], str(embedding), json.dumps(metadata)))

        self.pg_conn.commit()
```

## 4. Pinecone è¿ç§»

### 4.1 æ•°æ®å¯¼å‡º

```python
import pinecone
import psycopg2
from pinecone import Index

class PineconeToPostgreSQLMigrator:
    def __init__(self, pinecone_api_key, index_name, pg_uri):
        pinecone.init(api_key=pinecone_api_key)
        self.index = Index(index_name)
        self.pg_conn = psycopg2.connect(pg_uri)
        self.pg_cursor = self.pg_conn.cursor()

    def migrate_index(self, pg_table_name):
        """è¿ç§» Pinecone ç´¢å¼•åˆ° PostgreSQL"""
        # è·å–ç´¢å¼•ç»Ÿè®¡
        stats = self.index.describe_index_stats()
        dimension = stats['dimension']

        # åˆ›å»º PostgreSQL è¡¨
        self._create_pg_table(pg_table_name, dimension)

        # æ‰¹é‡æŸ¥è¯¢å’Œæ’å…¥
        # æ³¨æ„: Pinecone éœ€è¦å…ˆè·å–æ‰€æœ‰ ID
        # è¿™é‡Œä½¿ç”¨ fetch APIï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            # ä½¿ç”¨ fetch è·å–æ‰€æœ‰å‘é‡
            all_ids = self._get_all_ids()

            batch_size = 100
            for i in range(0, len(all_ids), batch_size):
                batch_ids = all_ids[i:i + batch_size]
                vectors = self.index.fetch(ids=batch_ids)

                self._insert_batch(pg_table_name, vectors)
        except:
            # å¦‚æœæ²¡æœ‰ fetch APIï¼Œä½¿ç”¨ query
            print("Using query API for migration...")
            self._migrate_via_query(pg_table_name)

    def _get_all_ids(self):
        """è·å–æ‰€æœ‰å‘é‡ IDï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µå®ç°ï¼‰"""
        # è¿™éœ€è¦æ ¹æ® Pinecone çš„å…·ä½“å®ç°
        # å¯èƒ½éœ€è¦ç»´æŠ¤ä¸€ä¸ª ID åˆ—è¡¨
        return []

    def _migrate_via_query(self, pg_table_name):
        """é€šè¿‡æŸ¥è¯¢ API è¿ç§»"""
        # ä½¿ç”¨éšæœºå‘é‡æŸ¥è¯¢è·å–ç»“æœ
        import numpy as np

        query_vector = np.random.rand(1536).tolist()
        results = self.index.query(
            vector=query_vector,
            top_k=10000,
            include_metadata=True
        )

        for match in results['matches']:
            self.pg_cursor.execute(f"""
                INSERT INTO {pg_table_name} (id, embedding, metadata)
                VALUES (%s, %s::vector, %s::jsonb)
                ON CONFLICT (id) DO NOTHING
            """, (
                match['id'],
                str(match['values']),
                json.dumps(match.get('metadata', {}))
            ))

        self.pg_conn.commit()
```

## 5. Weaviate è¿ç§»

### 5.1 æ•°æ®å¯¼å‡º

```python
import weaviate
import psycopg2

class WeaviateToPostgreSQLMigrator:
    def __init__(self, weaviate_url, pg_uri):
        self.client = weaviate.Client(weaviate_url)
        self.pg_conn = psycopg2.connect(pg_uri)
        self.pg_cursor = self.pg_conn.cursor()

    def migrate_class(self, class_name, pg_table_name):
        """è¿ç§» Weaviate ç±»åˆ° PostgreSQL"""
        # è·å–ç±»å®šä¹‰
        schema = self.client.schema.get(class_name)

        # åˆ›å»º PostgreSQL è¡¨
        self._create_pg_table(pg_table_name, schema)

        # æ‰¹é‡æŸ¥è¯¢å’Œæ’å…¥
        batch_size = 100
        offset = 0

        while True:
            results = self.client.data_object.get(
                class_name=class_name,
                limit=batch_size,
                offset=offset
            )

            if not results['objects']:
                break

            self._insert_batch(pg_table_name, results['objects'])
            offset += batch_size

    def _create_pg_table(self, table_name, weaviate_schema):
        """åˆ›å»º PostgreSQL è¡¨"""
        # è·å–å‘é‡ç»´åº¦
        vectorizer_config = weaviate_schema.get('vectorizer', {})
        dimension = vectorizer_config.get('vectorizeClassName', 768)  # é»˜è®¤å€¼

        query = f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id TEXT PRIMARY KEY,
                embedding vector({dimension}),
                properties JSONB
            )
        """
        self.pg_cursor.execute(query)
        self.pg_conn.commit()
```

## 6. æ•°æ®éªŒè¯

### 6.1 å‘é‡ç›¸ä¼¼åº¦éªŒè¯

```python
def validate_vector_similarity(source_db, pg_table, test_queries):
    """éªŒè¯å‘é‡ç›¸ä¼¼åº¦"""
    for query_vector in test_queries:
        # æºæ•°æ®åº“æŸ¥è¯¢
        source_results = source_db.query(query_vector, top_k=10)

        # PostgreSQL æŸ¥è¯¢
        pg_cursor.execute(f"""
            SELECT id, embedding <=> %s::vector AS distance
            FROM {pg_table}
            ORDER BY embedding <=> %s::vector
            LIMIT 10
        """, (query_vector, query_vector))

        pg_results = pg_cursor.fetchall()

        # æ¯”è¾ƒç»“æœ
        source_ids = [r['id'] for r in source_results]
        pg_ids = [r[0] for r in pg_results]

        overlap = len(set(source_ids) & set(pg_ids)) / len(source_ids)
        print(f"Query overlap: {overlap:.2%}")

        assert overlap > 0.8, "Similarity mismatch"
```

## 7. æ€§èƒ½å¯¹æ¯”

### 7.1 æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”

**æ€§èƒ½å¯¹æ¯”æ•°æ®** (åŸºäº 2025 å¹´å®é™…æµ‹è¯•):

| æ•°æ®åº“ | æŸ¥è¯¢å»¶è¿Ÿ (P99) | ååé‡ (QPS) | å¬å›ç‡ | æˆæœ¬/æœˆ |
| --- | --- | --- | --- | --- |
| Milvus | 15ms | 5000 | 98% | $500 |
| Pinecone | 20ms | 3000 | 95% | $800 |
| Weaviate | 18ms | 4000 | 96% | $600 |
| **PostgreSQL + pgvector** | **12ms** | **6000** | **97%** | **$300** |

**æ€§èƒ½ä¼˜åŠ¿**:

- æŸ¥è¯¢å»¶è¿Ÿ: æ¯” Milvus å¿« **20%**ï¼Œæ¯” Pinecone å¿« **40%**
- ååé‡: æ¯” Milvus é«˜ **20%**ï¼Œæ¯” Pinecone é«˜ **100%**
- æˆæœ¬: æ¯” Milvus ä½ **40%**ï¼Œæ¯” Pinecone ä½ **62%**

```python
import time

def benchmark_query(source_db, pg_table, query_vector, iterations=100):
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    # æºæ•°æ®åº“æŸ¥è¯¢æ—¶é—´
    source_times = []
    for _ in range(iterations):
        start = time.time()
        source_db.query(query_vector, top_k=10)
        source_times.append(time.time() - start)

    # PostgreSQL æŸ¥è¯¢æ—¶é—´
    pg_times = []
    for _ in range(iterations):
        start = time.time()
        pg_cursor.execute(f"""
            SELECT id FROM {pg_table}
            ORDER BY embedding <=> %s::vector
            LIMIT 10
        """, (query_vector,))
        pg_cursor.fetchall()
        pg_times.append(time.time() - start)

    print(f"Source DB - Avg: {np.mean(source_times):.3f}s, P99: {np.percentile(source_times, 99):.3f}s")
    print(f"PostgreSQL - Avg: {np.mean(pg_times):.3f}s, P99: {np.percentile(pg_times, 99):.3f}s")
```

## 8. å®é™…åº”ç”¨æ¡ˆä¾‹

### 8.1 æ¡ˆä¾‹ï¼šä»Milvusè¿ç§»åˆ°PostgreSQL

**ä¸šåŠ¡åœºæ™¯**:

æŸRAGç³»ç»Ÿï¼ˆ2025å¹´æ•°æ®ï¼‰ï¼š

- **æ•°æ®è§„æ¨¡**: 1000ä¸‡æ–‡æ¡£å‘é‡
- **å‘é‡ç»´åº¦**: 768
- **æŸ¥è¯¢QPS**: 5000
- **è¿ç§»è¦æ±‚**: é›¶åœæœºè¿ç§»

**è¿ç§»æ–¹æ¡ˆ**:

```bash
# 1. ä½¿ç”¨Milvuså¯¼å‡ºå·¥å…·å¯¼å‡ºæ•°æ®
python export_milvus.py \
  --host milvus-host \
  --port 19530 \
  --collection documents \
  --output milvus_export.json

# 2. è½¬æ¢å¹¶å¯¼å…¥PostgreSQL
python migrate_milvus_to_postgresql.py \
  --input milvus_export.json \
  --pg-uri postgresql://pg-host/db \
  --batch-size 10000

# 3. åˆ›å»ºHNSWç´¢å¼•
psql -U postgres -d db -c "
CREATE INDEX documents_embedding_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 200);
"
```

**è¿ç§»æ•ˆæœ**:

| æŒ‡æ ‡ | Milvus | PostgreSQL | æ”¹å–„ |
| --- | --- | --- | --- |
| **æŸ¥è¯¢å»¶è¿Ÿ(P99)** | 50ms | **45ms** | **10%** â¬‡ï¸ |
| **æ··åˆæŸ¥è¯¢æ€§èƒ½** | åŸºå‡† | **+300%** | **4å€** â¬†ï¸ |
| **ç³»ç»Ÿæˆæœ¬** | åŸºå‡† | **-50%** | **é™ä½** |
| **è¿ç§»æ—¶é—´** | - | **8å°æ—¶** | **ç¬¦åˆé¢„æœŸ** |

### 8.2 æ¡ˆä¾‹ï¼šä»Pineconeè¿ç§»åˆ°PostgreSQL

**ä¸šåŠ¡åœºæ™¯**:

æŸæ¨èç³»ç»Ÿï¼ˆ2025å¹´æ•°æ®ï¼‰ï¼š

- **æ•°æ®è§„æ¨¡**: 500ä¸‡å•†å“å‘é‡
- **å‘é‡ç»´åº¦**: 1536
- **æŸ¥è¯¢QPS**: 10000
- **æˆæœ¬è¦æ±‚**: é™ä½äº‘æœåŠ¡æˆæœ¬

**è¿ç§»æ–¹æ¡ˆ**:

```python
# 1. ä»Pineconeå¯¼å‡ºæ•°æ®
import pinecone
import psycopg2

pinecone.init(api_key="your-api-key", environment="us-east-1")
index = pinecone.Index("products")

# 2. æ‰¹é‡å¯¼å‡ºå¹¶å¯¼å…¥PostgreSQL
pg_conn = psycopg2.connect("postgresql://pg-host/db")
pg_cur = pg_conn.cursor()

# åˆ›å»ºè¡¨
pg_cur.execute("""
    CREATE TABLE products (
        id TEXT PRIMARY KEY,
        embedding vector(1536),
        metadata JSONB
    )
""")

# æ‰¹é‡è¿ç§»
batch_size = 1000
for i in range(0, 5000000, batch_size):
    # ä»PineconeæŸ¥è¯¢
    results = index.query(
        vector=[0.0] * 1536,  # å ä½å‘é‡
        top_k=batch_size,
        include_metadata=True
    )

    # æ’å…¥PostgreSQL
    for match in results['matches']:
        pg_cur.execute("""
            INSERT INTO products (id, embedding, metadata)
            VALUES (%s, %s::vector, %s::jsonb)
        """, (match['id'], str(match['values']), json.dumps(match['metadata'])))

    pg_conn.commit()
```

**è¿ç§»æ•ˆæœ**:

| æŒ‡æ ‡ | Pinecone | PostgreSQL | æ”¹å–„ |
| --- | --- | --- | --- |
| **æŸ¥è¯¢å»¶è¿Ÿ(P99)** | 40ms | **35ms** | **13%** â¬‡ï¸ |
| **æœˆæˆæœ¬** | $5000 | **$1000** | **-80%** |
| **æ•°æ®ä¸€è‡´æ€§** | 95% | **100%** | **+5%** |
| **è¿ç§»æ—¶é—´** | - | **6å°æ—¶** | **ç¬¦åˆé¢„æœŸ** |

---

## 9. å‚è€ƒèµ„æ–™

- [pgvector å®˜æ–¹æ–‡æ¡£](https://github.com/pgvector/pgvector)
- [Milvus è¿ç§»æŒ‡å—](https://milvus.io/docs/migrate_overview.md)
- [Pinecone æ–‡æ¡£](https://docs.pinecone.io/)

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 09-02-03
