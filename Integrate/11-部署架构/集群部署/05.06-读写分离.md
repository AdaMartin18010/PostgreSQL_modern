---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL\05-éƒ¨ç½²æ¶æ„\é›†ç¾¤éƒ¨ç½²\05.06-è¯»å†™åˆ†ç¦».md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# è¯»å†™åˆ†ç¦»é…ç½®æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **æœ€åæ›´æ–°**: 2025-11-13
> **ç‰ˆæœ¬è¦†ç›–**: PostgreSQL 18.x (æ¨è) â­ | 17.x (æ¨è) | 16.x (å…¼å®¹)
> **æ–‡æ¡£çŠ¶æ€**: âœ… å·²åˆ›å»º

---

## ğŸ“‹ ç›®å½•

- [è¯»å†™åˆ†ç¦»é…ç½®æŒ‡å—](#è¯»å†™åˆ†ç¦»é…ç½®æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [ä¼˜åŠ¿](#ä¼˜åŠ¿)
    - [æŒ‘æˆ˜](#æŒ‘æˆ˜)
  - [2. æ¶æ„è®¾è®¡](#2-æ¶æ„è®¾è®¡)
    - [2.1 åŸºæœ¬æ¶æ„](#21-åŸºæœ¬æ¶æ„)
    - [2.2 ä¸­é—´ä»¶æ¶æ„](#22-ä¸­é—´ä»¶æ¶æ„)
    - [2.3 åº”ç”¨å±‚è·¯ç”±](#23-åº”ç”¨å±‚è·¯ç”±)
  - [3. ä½¿ç”¨ pgpool-II](#3-ä½¿ç”¨-pgpool-ii)
    - [3.1 å®‰è£…é…ç½®](#31-å®‰è£…é…ç½®)
      - [å®‰è£…](#å®‰è£…)
      - [åŸºæœ¬é…ç½®ï¼ˆpgpool.confï¼‰](#åŸºæœ¬é…ç½®pgpoolconf)
    - [3.2 å¯åŠ¨æœåŠ¡](#32-å¯åŠ¨æœåŠ¡)
    - [3.3 è¿æ¥æµ‹è¯•](#33-è¿æ¥æµ‹è¯•)
  - [4. ä½¿ç”¨ pgbouncer](#4-ä½¿ç”¨-pgbouncer)
    - [4.1 é…ç½®ï¼ˆpgbouncer.iniï¼‰](#41-é…ç½®pgbouncerini)
    - [4.2 åº”ç”¨å±‚è·¯ç”±](#42-åº”ç”¨å±‚è·¯ç”±)
  - [5. åº”ç”¨å±‚è·¯ç”±](#5-åº”ç”¨å±‚è·¯ç”±)
    - [5.1 Django é…ç½®](#51-django-é…ç½®)
    - [5.2 Spring Boot é…ç½®](#52-spring-boot-é…ç½®)
  - [6. è´Ÿè½½å‡è¡¡](#6-è´Ÿè½½å‡è¡¡)
    - [6.1 è½®è¯¢ï¼ˆRound Robinï¼‰](#61-è½®è¯¢round-robin)
    - [6.2 åŠ æƒè½®è¯¢](#62-åŠ æƒè½®è¯¢)
    - [6.3 åŸºäºå»¶è¿Ÿçš„è·¯ç”±](#63-åŸºäºå»¶è¿Ÿçš„è·¯ç”±)
  - [7. ç›‘æ§ä¸è¯Šæ–­](#7-ç›‘æ§ä¸è¯Šæ–­)
    - [7.1 pgpool-II ç›‘æ§](#71-pgpool-ii-ç›‘æ§)
    - [7.2 å¤åˆ¶å»¶è¿Ÿç›‘æ§](#72-å¤åˆ¶å»¶è¿Ÿç›‘æ§)
    - [7.3 è¯»å†™åˆ†ç¦»æ•ˆæœç›‘æ§](#73-è¯»å†™åˆ†ç¦»æ•ˆæœç›‘æ§)
  - [7. pgpool-IIè¯¦ç»†é…ç½®](#7-pgpool-iiè¯¦ç»†é…ç½®)
    - [7.1 ç”Ÿäº§çº§é…ç½®](#71-ç”Ÿäº§çº§é…ç½®)
    - [7.2 è´Ÿè½½å‡è¡¡é…ç½®](#72-è´Ÿè½½å‡è¡¡é…ç½®)
    - [7.3 æ•…éšœè½¬ç§»é…ç½®](#73-æ•…éšœè½¬ç§»é…ç½®)
    - [7.4 æ€§èƒ½ä¼˜åŒ–é…ç½®](#74-æ€§èƒ½ä¼˜åŒ–é…ç½®)
  - [8. åº”ç”¨å±‚è·¯ç”±è¯¦ç»†å®ç°](#8-åº”ç”¨å±‚è·¯ç”±è¯¦ç»†å®ç°)
    - [8.1 Djangoå®Œæ•´é…ç½®ç¤ºä¾‹](#81-djangoå®Œæ•´é…ç½®ç¤ºä¾‹)
    - [8.2 Spring Bootå®Œæ•´é…ç½®ç¤ºä¾‹](#82-spring-bootå®Œæ•´é…ç½®ç¤ºä¾‹)
    - [8.3 Node.jsé…ç½®ç¤ºä¾‹](#83-nodejsé…ç½®ç¤ºä¾‹)
    - [8.4 Pythonè¿æ¥æ± é…ç½®](#84-pythonè¿æ¥æ± é…ç½®)
  - [9. æ•…éšœæ’æŸ¥å’Œè¯Šæ–­](#9-æ•…éšœæ’æŸ¥å’Œè¯Šæ–­)
    - [9.1 è¯»å†™åˆ†ç¦»é—®é¢˜è¯Šæ–­](#91-è¯»å†™åˆ†ç¦»é—®é¢˜è¯Šæ–­)
    - [9.2 è´Ÿè½½å‡è¡¡é—®é¢˜](#92-è´Ÿè½½å‡è¡¡é—®é¢˜)
    - [9.3 è¿æ¥æ± é—®é¢˜](#93-è¿æ¥æ± é—®é¢˜)
    - [9.4 æ€§èƒ½é—®é¢˜è¯Šæ–­](#94-æ€§èƒ½é—®é¢˜è¯Šæ–­)
  - [10. ç›‘æ§å’Œå‘Šè­¦](#10-ç›‘æ§å’Œå‘Šè­¦)
    - [10.1 è¯»å†™åˆ†ç¦»æ•ˆæœç›‘æ§](#101-è¯»å†™åˆ†ç¦»æ•ˆæœç›‘æ§)
    - [10.2 å»¶è¿Ÿç›‘æ§](#102-å»¶è¿Ÿç›‘æ§)
    - [10.3 å‘Šè­¦è§„åˆ™é…ç½®](#103-å‘Šè­¦è§„åˆ™é…ç½®)
    - [10.4 æ€§èƒ½æŒ‡æ ‡ç›‘æ§](#104-æ€§èƒ½æŒ‡æ ‡ç›‘æ§)
  - [11. æ™ºèƒ½äº‹åŠ¡è·¯ç”±](#11-æ™ºèƒ½äº‹åŠ¡è·¯ç”±)
    - [11.1 äº‹åŠ¡è·¯ç”±ç­–ç•¥è®¾è®¡](#111-äº‹åŠ¡è·¯ç”±ç­–ç•¥è®¾è®¡)
      - [11.1.1 è·¯ç”±ç®—æ³•è®¾è®¡](#1111-è·¯ç”±ç®—æ³•è®¾è®¡)
      - [11.1.2 è·¯ç”±è§„åˆ™é…ç½®](#1112-è·¯ç”±è§„åˆ™é…ç½®)
    - [11.2 ä¸šåŠ¡ç±»å‹è¯†åˆ«å’Œè·¯ç”±](#112-ä¸šåŠ¡ç±»å‹è¯†åˆ«å’Œè·¯ç”±)
      - [11.2.1 ä¸šåŠ¡ç±»å‹è¯†åˆ«](#1121-ä¸šåŠ¡ç±»å‹è¯†åˆ«)
      - [11.2.2 è·¯ç”±å®ç°](#1122-è·¯ç”±å®ç°)
    - [11.3 è¯»å†™åˆ†ç¦»æ™ºèƒ½è·¯ç”±](#113-è¯»å†™åˆ†ç¦»æ™ºèƒ½è·¯ç”±)
      - [11.3.1 è¯»æ“ä½œè·¯ç”±](#1131-è¯»æ“ä½œè·¯ç”±)
      - [11.3.2 å†™æ“ä½œè·¯ç”±](#1132-å†™æ“ä½œè·¯ç”±)
    - [11.4 è´Ÿè½½å‡è¡¡ç®—æ³•](#114-è´Ÿè½½å‡è¡¡ç®—æ³•)
      - [11.4.1 è½®è¯¢ç®—æ³•ï¼ˆRound Robinï¼‰](#1141-è½®è¯¢ç®—æ³•round-robin)
      - [11.4.2 åŠ æƒè½®è¯¢ï¼ˆWeighted Round Robinï¼‰](#1142-åŠ æƒè½®è¯¢weighted-round-robin)
      - [11.4.3 æœ€å°‘è¿æ¥ï¼ˆLeast Connectionsï¼‰](#1143-æœ€å°‘è¿æ¥least-connections)
      - [11.4.4 ä¸€è‡´æ€§å“ˆå¸Œ](#1144-ä¸€è‡´æ€§å“ˆå¸Œ)
    - [11.5 å®é™…é…ç½®ç¤ºä¾‹](#115-å®é™…é…ç½®ç¤ºä¾‹)
      - [11.5.1 pgpool-IIæ™ºèƒ½è·¯ç”±é…ç½®](#1151-pgpool-iiæ™ºèƒ½è·¯ç”±é…ç½®)
      - [11.5.2 Djangoæ™ºèƒ½è·¯ç”±é…ç½®](#1152-djangoæ™ºèƒ½è·¯ç”±é…ç½®)
      - [11.5.3 Spring Bootæ™ºèƒ½è·¯ç”±é…ç½®](#1153-spring-bootæ™ºèƒ½è·¯ç”±é…ç½®)
      - [11.5.4 Node.jsæ™ºèƒ½è·¯ç”±é…ç½®](#1154-nodejsæ™ºèƒ½è·¯ç”±é…ç½®)
  - [12. äº¤å‰å¼•ç”¨](#12-äº¤å‰å¼•ç”¨)
    - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)
      - [éƒ¨ç½²æ¶æ„](#éƒ¨ç½²æ¶æ„)
      - [æ ¸å¿ƒè¯¾ç¨‹](#æ ¸å¿ƒè¯¾ç¨‹)
      - [æŸ¥è¯¢ä¸ä¼˜åŒ–](#æŸ¥è¯¢ä¸ä¼˜åŒ–)
      - [è¿ç»´å®è·µ](#è¿ç»´å®è·µ)
    - [å¤–éƒ¨èµ„æº](#å¤–éƒ¨èµ„æº)

---

## 1. æ¦‚è¿°

è¯»å†™åˆ†ç¦»ï¼ˆRead-Write Splittingï¼‰æ˜¯å°†è¯»æ“ä½œå’Œå†™æ“ä½œåˆ†å‘åˆ°ä¸åŒçš„æ•°æ®åº“å®ä¾‹ï¼Œä»¥æé«˜ç³»ç»Ÿæ•´ä½“æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚

### ä¼˜åŠ¿

- **æå‡è¯»æ€§èƒ½**: è¯»æ“ä½œåˆ†æ•£åˆ°å¤šä¸ªä»åº“
- **é™ä½ä¸»åº“å‹åŠ›**: ä¸»åº“ä¸“æ³¨äºå†™æ“ä½œ
- **æé«˜å¯ç”¨æ€§**: ä»åº“æ•…éšœä¸å½±å“å†™æ“ä½œ
- **æ°´å¹³æ‰©å±•**: é€šè¿‡å¢åŠ ä»åº“æ‰©å±•è¯»èƒ½åŠ›

### æŒ‘æˆ˜

- **æ•°æ®ä¸€è‡´æ€§**: ä¸»ä»å¤åˆ¶å»¶è¿Ÿå¯¼è‡´è¯»å»¶è¿Ÿ
- **è·¯ç”±å¤æ‚æ€§**: éœ€è¦åŒºåˆ†è¯»å†™æ“ä½œ
- **æ•…éšœå¤„ç†**: ä»åº“æ•…éšœæ—¶çš„è‡ªåŠ¨åˆ‡æ¢

---

## 2. æ¶æ„è®¾è®¡

### 2.1 åŸºæœ¬æ¶æ„

```text
åº”ç”¨å±‚
  â”‚
  â”œâ”€ å†™æ“ä½œ â”€â”€â†’ ä¸»åº“ (Primary)
  â”‚
  â””â”€ è¯»æ“ä½œ â”€â”€â†’ ä»åº“ (Standby) â”€â”€â†’ ä»åº“ (Standby)
```

### 2.2 ä¸­é—´ä»¶æ¶æ„

```text
åº”ç”¨å±‚
  â”‚
  â””â”€ pgpool-II / pgbouncer
      â”‚
      â”œâ”€ å†™æ“ä½œ â”€â”€â†’ ä¸»åº“
      â”‚
      â””â”€ è¯»æ“ä½œ â”€â”€â†’ ä»åº“ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
```

### 2.3 åº”ç”¨å±‚è·¯ç”±

```text
åº”ç”¨å±‚ï¼ˆè¿æ¥æ± ï¼‰
  â”‚
  â”œâ”€ å†™è¿æ¥ â”€â”€â†’ ä¸»åº“
  â”‚
  â””â”€ è¯»è¿æ¥ â”€â”€â†’ ä»åº“ï¼ˆè½®è¯¢/éšæœºï¼‰
```

---

## 3. ä½¿ç”¨ pgpool-II

### 3.1 å®‰è£…é…ç½®

#### å®‰è£…

```bash
# Ubuntu/Debian
sudo apt-get install pgpool2

# æˆ–ä»æºç ç¼–è¯‘
wget https://www.pgpool.net/download.php?f=pgpool-II-4.4.3.tar.gz
tar xzf pgpool-II-4.4.3.tar.gz
cd pgpool-II-4.4.3
./configure --prefix=/usr/local/pgpool
make && make install
```

#### åŸºæœ¬é…ç½®ï¼ˆpgpool.confï¼‰

```text
# ç›‘å¬åœ°å€å’Œç«¯å£
listen_addresses = '*'
port = 9999

# åç«¯æ•°æ®åº“é…ç½®
backend_hostname0 = 'primary_host'
backend_port0 = 5432
backend_weight0 = 0  # ä¸»åº“æƒé‡ï¼ˆå†™æ“ä½œï¼‰
backend_flag0 = 'ALLOW_TO_FAILOVER'

backend_hostname1 = 'standby1_host'
backend_port1 = 5432
backend_weight1 = 1  # ä»åº“æƒé‡ï¼ˆè¯»æ“ä½œï¼‰
backend_flag1 = 'ALLOW_TO_FAILOVER'

backend_hostname2 = 'standby2_host'
backend_port2 = 5432
backend_weight2 = 1
backend_flag2 = 'ALLOW_TO_FAILOVER'

# è´Ÿè½½å‡è¡¡æ¨¡å¼
load_balance_mode = on

# ä¸»ä»å¤åˆ¶æ£€æŸ¥
master_slave_mode = on
master_slave_sub_mode = 'stream'

# å¥åº·æ£€æŸ¥
health_check_period = 30
health_check_timeout = 10
health_check_user = 'postgres'
health_check_password = 'password'
health_check_database = 'postgres'

# æ•…éšœè½¬ç§»
failover_on_backend_error = on
```

### 3.2 å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨ pgpool-II
pgpool -n -f /etc/pgpool2/pgpool.conf -F /etc/pgpool2/pcp.conf

# æˆ–ä½¿ç”¨ systemd
sudo systemctl start pgpool2
sudo systemctl enable pgpool2
```

### 3.3 è¿æ¥æµ‹è¯•

```bash
# é€šè¿‡ pgpool è¿æ¥
psql -h pgpool_host -p 9999 -U postgres -d mydb

# æŸ¥çœ‹åç«¯çŠ¶æ€
psql -h pgpool_host -p 9999 -U postgres -c "SHOW POOL_NODES;"
```

---

## 4. ä½¿ç”¨ pgbouncer

### 4.1 é…ç½®ï¼ˆpgbouncer.iniï¼‰

```ini
[databases]
mydb = host=primary_host port=5432 dbname=mydb
mydb_ro = host=standby1_host port=5432 dbname=mydb

[pgbouncer]
listen_addr = *
listen_port = 6432
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt

# è¿æ¥æ± æ¨¡å¼
pool_mode = transaction

# è¿æ¥é™åˆ¶
max_client_conn = 1000
default_pool_size = 25
```

### 4.2 åº”ç”¨å±‚è·¯ç”±

```python
# Python ç¤ºä¾‹
import psycopg2

# å†™æ“ä½œè¿æ¥ï¼ˆä¸»åº“ï¼‰
write_conn = psycopg2.connect(
    host='pgbouncer_host',
    port=6432,
    database='mydb',
    user='app_user',
    password='password'
)

# è¯»æ“ä½œè¿æ¥ï¼ˆä»åº“ï¼‰
read_conn = psycopg2.connect(
    host='pgbouncer_host',
    port=6432,
    database='mydb_ro',
    user='app_user',
    password='password'
)
```

---

## 5. åº”ç”¨å±‚è·¯ç”±

### 5.1 Django é…ç½®

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'USER': 'app_user',
        'PASSWORD': 'password',
        'HOST': 'primary_host',
        'PORT': '5432',
    },
    'read': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'USER': 'app_user',
        'PASSWORD': 'password',
        'HOST': 'standby1_host',
        'PORT': '5432',
    }
}

# æ•°æ®åº“è·¯ç”±
DATABASE_ROUTERS = ['myapp.dbrouter.DatabaseRouter']
```

```python
# dbrouter.py
class DatabaseRouter:
    def db_for_read(self, model, **hints):
        return 'read'

    def db_for_write(self, model, **hints):
        return 'default'
```

### 5.2 Spring Boot é…ç½®

```yaml
# application.yml
spring:
  datasource:
    write:
      jdbc-url: jdbc:postgresql://primary_host:5432/mydb
      username: app_user
      password: password
    read:
      - jdbc-url: jdbc:postgresql://standby1_host:5432/mydb
        username: app_user
        password: password
      - jdbc-url: jdbc:postgresql://standby2_host:5432/mydb
        username: app_user
        password: password
```

---

## 6. è´Ÿè½½å‡è¡¡

### 6.1 è½®è¯¢ï¼ˆRound Robinï¼‰

```python
class RoundRobinRouter:
    def __init__(self, read_hosts):
        self.read_hosts = read_hosts
        self.current = 0

    def get_read_host(self):
        host = self.read_hosts[self.current]
        self.current = (self.current + 1) % len(self.read_hosts)
        return host
```

### 6.2 åŠ æƒè½®è¯¢

```python
class WeightedRoundRobinRouter:
    def __init__(self, read_hosts_with_weights):
        self.hosts = read_hosts_with_weights
        self.current_weight = 0
        self.current_index = -1

    def get_read_host(self):
        while True:
            self.current_index = (self.current_index + 1) % len(self.hosts)
            if self.current_index == 0:
                self.current_weight -= sum(w for _, w in self.hosts)
            self.current_weight += self.hosts[self.current_index][1]
            if self.current_weight > 0:
                return self.hosts[self.current_index][0]
```

### 6.3 åŸºäºå»¶è¿Ÿçš„è·¯ç”±

```python
import time

class LatencyBasedRouter:
    def __init__(self, read_hosts):
        self.read_hosts = read_hosts
        self.latencies = {host: 0 for host in read_hosts}

    def measure_latency(self, host):
        start = time.time()
        # æ‰§è¡Œç®€å•æŸ¥è¯¢
        conn = psycopg2.connect(host=host, ...)
        conn.execute("SELECT 1")
        conn.close()
        return time.time() - start

    def get_read_host(self):
        # å®šæœŸæµ‹é‡å»¶è¿Ÿ
        for host in self.read_hosts:
            self.latencies[host] = self.measure_latency(host)

        # é€‰æ‹©å»¶è¿Ÿæœ€ä½çš„ä¸»æœº
        return min(self.latencies, key=self.latencies.get)
```

---

## 7. ç›‘æ§ä¸è¯Šæ–­

### 7.1 pgpool-II ç›‘æ§

```sql
-- æŸ¥çœ‹åç«¯èŠ‚ç‚¹çŠ¶æ€
SHOW POOL_NODES;

-- æŸ¥çœ‹è¿æ¥æ± çŠ¶æ€
SHOW POOL_PROCESSES;

-- æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
SHOW POOL_STATS;
```

### 7.2 å¤åˆ¶å»¶è¿Ÿç›‘æ§

```sql
-- ç›‘æ§ä¸»ä»å»¶è¿Ÿ
SELECT
  application_name,
  client_addr,
  state,
  pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn)) AS lag,
  EXTRACT(EPOCH FROM (now() - replay_lag)) AS lag_seconds
FROM pg_stat_replication;
```

### 7.3 è¯»å†™åˆ†ç¦»æ•ˆæœç›‘æ§

```sql
-- ä¸»åº“ï¼šå†™æ“ä½œç»Ÿè®¡
SELECT
  datname,
  xact_commit,
  xact_rollback,
  blks_read,
  blks_hit
FROM pg_stat_database
WHERE datname = 'mydb';

-- ä»åº“ï¼šè¯»æ“ä½œç»Ÿè®¡
SELECT
  datname,
  numbackends,
  xact_commit,
  blks_read,
  blks_hit,
  tup_returned,
  tup_fetched
FROM pg_stat_database
WHERE datname = 'mydb';
```

---

## 7. pgpool-IIè¯¦ç»†é…ç½®

### 7.1 ç”Ÿäº§çº§é…ç½®

**å®Œæ•´çš„pgpool.confç”Ÿäº§é…ç½®**:

```conf
# ============================================
# åŸºæœ¬é…ç½®
# ============================================
listen_addresses = '*'
port = 9999
socket_dir = '/var/run/pgpool'
pcp_listen_addresses = '*'
pcp_port = 9898
pcp_socket_dir = '/var/run/pgpool'

# ============================================
# åç«¯æ•°æ®åº“é…ç½®
# ============================================
# ä¸»åº“ï¼ˆå†™æ“ä½œï¼‰
backend_hostname0 = 'primary_host'
backend_port0 = 5432
backend_weight0 = 0                    # ä¸»åº“æƒé‡ä¸º0ï¼ˆä»…å†™æ“ä½œï¼‰
backend_flag0 = 'ALLOW_TO_FAILOVER'
backend_data_directory0 = '/var/lib/postgresql/data'
backend_application_name0 = 'primary'

# ä»åº“1ï¼ˆè¯»æ“ä½œï¼‰
backend_hostname1 = 'standby1_host'
backend_port1 = 5432
backend_weight1 = 1                    # ä»åº“æƒé‡ä¸º1ï¼ˆè¯»æ“ä½œï¼‰
backend_flag1 = 'ALLOW_TO_FAILOVER'
backend_data_directory1 = '/var/lib/postgresql/data'
backend_application_name1 = 'standby1'

# ä»åº“2ï¼ˆè¯»æ“ä½œï¼‰
backend_hostname2 = 'standby2_host'
backend_port2 = 5432
backend_weight2 = 1
backend_flag2 = 'ALLOW_TO_FAILOVER'
backend_data_directory2 = '/var/lib/postgresql/data'
backend_application_name2 = 'standby2'

# ============================================
# è¿æ¥æ± é…ç½®
# ============================================
num_init_children = 32                # åˆå§‹å­è¿›ç¨‹æ•°
max_pool = 4                          # æ¯ä¸ªå­è¿›ç¨‹çš„æœ€å¤§è¿æ¥æ•°
child_life_time = 300                  # å­è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸï¼ˆç§’ï¼‰
child_max_connections = 0              # å­è¿›ç¨‹æœ€å¤§è¿æ¥æ•°ï¼ˆ0=æ— é™åˆ¶ï¼‰
connection_life_time = 0               # è¿æ¥ç”Ÿå‘½å‘¨æœŸï¼ˆ0=æ— é™åˆ¶ï¼‰
client_idle_limit = 0                  # å®¢æˆ·ç«¯ç©ºé—²é™åˆ¶ï¼ˆ0=æ— é™åˆ¶ï¼‰

# ============================================
# è´Ÿè½½å‡è¡¡é…ç½®
# ============================================
load_balance_mode = on                 # å¯ç”¨è´Ÿè½½å‡è¡¡
ignore_leading_white_space = on       # å¿½ç•¥å‰å¯¼ç©ºæ ¼

# ============================================
# ä¸»ä»å¤åˆ¶æ¨¡å¼
# ============================================
master_slave_mode = on                 # å¯ç”¨ä¸»ä»æ¨¡å¼
master_slave_sub_mode = 'stream'       # æµå¤åˆ¶æ¨¡å¼
failover_on_backend_error = on         # åç«¯é”™è¯¯æ—¶æ•…éšœè½¬ç§»

# ============================================
# å¥åº·æ£€æŸ¥é…ç½®
# ============================================
health_check_period = 30               # å¥åº·æ£€æŸ¥å‘¨æœŸï¼ˆç§’ï¼‰
health_check_timeout = 10              # å¥åº·æ£€æŸ¥è¶…æ—¶ï¼ˆç§’ï¼‰
health_check_user = 'postgres'         # å¥åº·æ£€æŸ¥ç”¨æˆ·
health_check_password = 'password'     # å¥åº·æ£€æŸ¥å¯†ç 
health_check_database = 'postgres'     # å¥åº·æ£€æŸ¥æ•°æ®åº“
health_check_max_retries = 3           # æœ€å¤§é‡è¯•æ¬¡æ•°
health_check_retry_delay = 1           # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰

# ============================================
# æ•…éšœè½¬ç§»é…ç½®
# ============================================
failover_command = '/usr/local/bin/failover.sh %h %p %d %H %P %r %R'
failback_command = '/usr/local/bin/failback.sh %h %p %d %H %P %r %R'
follow_master_command = '/usr/local/bin/follow_master.sh %h %p %d %H %P %r %R'

# ============================================
# æ—¥å¿—é…ç½®
# ============================================
log_destination = 'stderr'
logging_collector = on
log_directory = '/var/log/pgpool'
log_filename = 'pgpool-%Y-%m-%d.log'
log_rotation_age = 1d
log_rotation_size = 100MB
log_min_messages = warning
log_connections = on
log_hostname = on
log_statement = on
log_per_node_statement = on

# ============================================
# è®¤è¯é…ç½®
# ============================================
enable_pool_hba = on
pool_passwd = 'pool_passwd'

# ============================================
# æ€§èƒ½ä¼˜åŒ–
# ============================================
memory_cache_enabled = on              # å¯ç”¨å†…å­˜ç¼“å­˜
memqcache_method = 'memcached'         # ä½¿ç”¨Memcached
memqcache_memcached_host = 'memcached_host'
memqcache_memcached_port = 11211
memqcache_total_size = 67108864        # 64MB
memqcache_max_num_cache = 1000000
memqcache_expire = 3600
memqcache_auto_cache_invalidation = on
```

**pool_hba.confé…ç½®**:

```conf
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# æœ¬åœ°è¿æ¥
local   all             all                                     md5

# IPv4æœ¬åœ°è¿æ¥
host    all             all             127.0.0.1/32            md5

# åº”ç”¨æœåŠ¡å™¨è¿æ¥
host    all             app_user        192.168.1.0/24          scram-sha-256

# ç®¡ç†è¿æ¥
host    all             postgres        192.168.1.0/24          scram-sha-256
```

### 7.2 è´Ÿè½½å‡è¡¡é…ç½®

**è´Ÿè½½å‡è¡¡ç­–ç•¥é…ç½®**:

```conf
# pgpool.conf
# è´Ÿè½½å‡è¡¡æ¨¡å¼
load_balance_mode = on

# è´Ÿè½½å‡è¡¡æƒé‡ï¼ˆæ ¹æ®ä»åº“æ€§èƒ½è°ƒæ•´ï¼‰
backend_weight1 = 2                    # é«˜æ€§èƒ½ä»åº“æƒé‡æ›´é«˜
backend_weight2 = 1                    # æ™®é€šä»åº“æƒé‡è¾ƒä½

# åŸºäºè¯­å¥çš„è´Ÿè½½å‡è¡¡
statement_level_load_balance = on      # è¯­å¥çº§è´Ÿè½½å‡è¡¡

# è´Ÿè½½å‡è¡¡ç®—æ³•
# - round_robin: è½®è¯¢ï¼ˆé»˜è®¤ï¼‰
# - weighted_round_robin: åŠ æƒè½®è¯¢
# - least_connections: æœ€å°‘è¿æ¥
load_balance_algorithm = 'round_robin'
```

**è´Ÿè½½å‡è¡¡æµ‹è¯•**:

```sql
-- æµ‹è¯•è´Ÿè½½å‡è¡¡
-- æ‰§è¡Œå¤šæ¬¡æŸ¥è¯¢ï¼Œè§‚å¯Ÿè¿æ¥åˆ†å¸ƒ
SELECT pg_backend_pid(), inet_server_addr(), inet_server_port();

-- æŸ¥çœ‹è´Ÿè½½å‡è¡¡ç»Ÿè®¡
SHOW POOL_STATS;
```

### 7.3 æ•…éšœè½¬ç§»é…ç½®

**æ•…éšœè½¬ç§»è„šæœ¬**:

```bash
#!/bin/bash
# /usr/local/bin/failover.sh
# å‚æ•°: $1=å¤±è´¥èŠ‚ç‚¹ä¸»æœºå $2=å¤±è´¥èŠ‚ç‚¹ç«¯å£ $3=å¤±è´¥èŠ‚ç‚¹æ•°æ®åº“ $4=æ–°ä¸»åº“ä¸»æœºå $5=æ–°ä¸»åº“ç«¯å£ $6=æ—§ä¸»åº“æ•°æ®ç›®å½• $7=æ–°ä¸»åº“æ•°æ®ç›®å½•

FAILED_NODE=$1
FAILED_PORT=$2
FAILED_DB=$3
NEW_PRIMARY=$4
NEW_PRIMARY_PORT=$5
OLD_PRIMARY_DATA=$6
NEW_PRIMARY_DATA=$7

echo "Failover: $FAILED_NODE:$FAILED_PORT -> $NEW_PRIMARY:$NEW_PRIMARY_PORT"

# 1. æå‡æ–°ä¸»åº“
ssh postgres@$NEW_PRIMARY "psql -c 'SELECT pg_promote();'"

# 2. æ›´æ–°åº”ç”¨è¿æ¥å­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰
# curl -X POST http://app-server/api/config/update-db-host -d "host=$NEW_PRIMARY"

# 3. å‘é€é€šçŸ¥
echo "Failover completed: $NEW_PRIMARY is now primary" | mail -s "PostgreSQL Failover Alert" admin@example.com

exit 0
```

**æ•…éšœè½¬ç§»é…ç½®**:

```conf
# pgpool.conf
failover_command = '/usr/local/bin/failover.sh %h %p %d %H %P %r %R'
failback_command = '/usr/local/bin/failback.sh %h %p %d %H %P %r %R'
follow_master_command = '/usr/local/bin/follow_master.sh %h %p %d %H %P %r %R'

# æ•…éšœè½¬ç§»è¶…æ—¶
failover_timeout = 60                  # æ•…éšœè½¬ç§»è¶…æ—¶ï¼ˆç§’ï¼‰

# è‡ªåŠ¨æ•…éšœæ¢å¤
failback_on_backend_error = off       # ä¸è‡ªåŠ¨æ•…éšœæ¢å¤ï¼ˆæ¨èæ‰‹åŠ¨æ¢å¤ï¼‰
```

### 7.4 æ€§èƒ½ä¼˜åŒ–é…ç½®

**è¿æ¥æ± ä¼˜åŒ–**:

```conf
# pgpool.conf
# è¿æ¥æ± å¤§å°ä¼˜åŒ–
num_init_children = 64                # æ ¹æ®å¹¶å‘è¿æ¥æ•°è°ƒæ•´
max_pool = 4                          # æ¯ä¸ªå­è¿›ç¨‹çš„æœ€å¤§è¿æ¥æ•°
child_life_time = 300                  # å­è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸ

# è¿æ¥å¤ç”¨
connection_life_time = 0               # è¿æ¥ç”Ÿå‘½å‘¨æœŸï¼ˆ0=æ— é™åˆ¶ï¼‰
client_idle_limit = 0                  # å®¢æˆ·ç«¯ç©ºé—²é™åˆ¶

# æŸ¥è¯¢ç¼“å­˜
memory_cache_enabled = on
memqcache_method = 'memcached'
memqcache_total_size = 134217728      # 128MB
memqcache_max_num_cache = 1000000
memqcache_expire = 3600
```

**æŸ¥è¯¢ä¼˜åŒ–**:

```conf
# pgpool.conf
# æŸ¥è¯¢ç¼“å­˜
memory_cache_enabled = on
memqcache_method = 'memcached'
memqcache_total_size = 134217728      # 128MB

# æŸ¥è¯¢é‡å†™
rewrite_query = on                     # å¯ç”¨æŸ¥è¯¢é‡å†™
rewrite_query_list = 'SELECT'          # é‡å†™SELECTæŸ¥è¯¢

# å¹¶è¡ŒæŸ¥è¯¢
parallel_mode = off                    # ç¦ç”¨å¹¶è¡Œæ¨¡å¼ï¼ˆæ¨èï¼‰
```

## 8. åº”ç”¨å±‚è·¯ç”±è¯¦ç»†å®ç°

### 8.1 Djangoå®Œæ•´é…ç½®ç¤ºä¾‹

**å®Œæ•´çš„Djangoé…ç½®**:

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'USER': 'app_user',
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': 'primary_host',
        'PORT': '5432',
        'OPTIONS': {
            'connect_timeout': 10,
            'options': '-c statement_timeout=30000'
        },
        'CONN_MAX_AGE': 600,           # è¿æ¥æ± æœ€å¤§å¹´é¾„
    },
    'read': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'USER': 'app_user',
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': 'standby1_host',
        'PORT': '5432',
        'OPTIONS': {
            'connect_timeout': 10,
            'options': '-c statement_timeout=30000'
        },
        'CONN_MAX_AGE': 600,
    },
    'read2': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'USER': 'app_user',
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': 'standby2_host',
        'PORT': '5432',
        'OPTIONS': {
            'connect_timeout': 10,
            'options': '-c statement_timeout=30000'
        },
        'CONN_MAX_AGE': 600,
    }
}

# æ•°æ®åº“è·¯ç”±
DATABASE_ROUTERS = ['myapp.dbrouter.DatabaseRouter']

# è¿æ¥æ± é…ç½®
DATABASES['default']['CONN_MAX_AGE'] = 600
DATABASES['read']['CONN_MAX_AGE'] = 600
DATABASES['read2']['CONN_MAX_AGE'] = 600
```

**æ•°æ®åº“è·¯ç”±å®ç°**:

```python
# myapp/dbrouter.py
import random
from django.conf import settings

class DatabaseRouter:
    """æ•°æ®åº“è·¯ç”±ï¼šå®ç°è¯»å†™åˆ†ç¦»"""

    read_databases = ['read', 'read2']

    def db_for_read(self, model, **hints):
        """è¯»æ“ä½œè·¯ç”±åˆ°ä»åº“"""
        # éšæœºé€‰æ‹©ä»åº“ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
        return random.choice(self.read_databases)

    def db_for_write(self, model, **hints):
        """å†™æ“ä½œè·¯ç”±åˆ°ä¸»åº“"""
        return 'default'

    def allow_relation(self, obj1, obj2, **hints):
        """å…è®¸è·¨æ•°æ®åº“å…³ç³»"""
        return True

    def allow_migrate(self, db, app_label, model_name=None, **hints):
        """è¿ç§»åªåœ¨ä¸»åº“æ‰§è¡Œ"""
        if db == 'default':
            return True
        return False
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
# views.py
from django.db import connections

def get_user_list(request):
    """è¯»æ“ä½œè‡ªåŠ¨è·¯ç”±åˆ°ä»åº“"""
    users = User.objects.all()  # è‡ªåŠ¨è·¯ç”±åˆ°ä»åº“
    return render(request, 'users.html', {'users': users})

def create_user(request):
    """å†™æ“ä½œè‡ªåŠ¨è·¯ç”±åˆ°ä¸»åº“"""
    user = User.objects.create(  # è‡ªåŠ¨è·¯ç”±åˆ°ä¸»åº“
        username=request.POST['username'],
        email=request.POST['email']
    )
    return redirect('user_list')

# æ‰‹åŠ¨æŒ‡å®šæ•°æ®åº“
def get_user_from_primary(request, user_id):
    """å¼ºåˆ¶ä»ä¸»åº“è¯»å–ï¼ˆè¯»å–åˆšå†™å…¥çš„æ•°æ®ï¼‰"""
    user = User.objects.using('default').get(id=user_id)
    return render(request, 'user.html', {'user': user})
```

### 8.2 Spring Bootå®Œæ•´é…ç½®ç¤ºä¾‹

**å®Œæ•´çš„Spring Booté…ç½®**:

```yaml
# application.yml
spring:
  datasource:
    # ä¸»åº“é…ç½®ï¼ˆå†™æ“ä½œï¼‰
    write:
      jdbc-url: jdbc:postgresql://primary_host:5432/mydb?sslmode=require
      username: app_user
      password: ${DB_PASSWORD}
      driver-class-name: org.postgresql.Driver
      hikari:
        maximum-pool-size: 20
        minimum-idle: 5
        connection-timeout: 30000
        idle-timeout: 600000
        max-lifetime: 1800000

    # ä»åº“é…ç½®ï¼ˆè¯»æ“ä½œï¼‰
    read:
      - jdbc-url: jdbc:postgresql://standby1_host:5432/mydb?sslmode=require
        username: app_user
        password: ${DB_PASSWORD}
        driver-class-name: org.postgresql.Driver
        hikari:
          maximum-pool-size: 20
          minimum-idle: 5
          connection-timeout: 30000
          idle-timeout: 600000
          max-lifetime: 1800000
      - jdbc-url: jdbc:postgresql://standby2_host:5432/mydb?sslmode=require
        username: app_user
        password: ${DB_PASSWORD}
        driver-class-name: org.postgresql.Driver
        hikari:
          maximum-pool-size: 20
          minimum-idle: 5
          connection-timeout: 30000
          idle-timeout: 600000
          max-lifetime: 1800000

  jpa:
    hibernate:
      ddl-auto: none
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
```

**æ•°æ®æºé…ç½®ç±»**:

```java
// DataSourceConfig.java
@Configuration
public class DataSourceConfig {

    @Bean
    @Primary
    @ConfigurationProperties("spring.datasource.write")
    public DataSource writeDataSource() {
        return DataSourceBuilder.create().build();
    }

    @Bean
    @ConfigurationProperties("spring.datasource.read")
    public List<DataSource> readDataSources() {
        return Arrays.asList(
            DataSourceBuilder.create().build(),
            DataSourceBuilder.create().build()
        );
    }

    @Bean
    public DataSource routingDataSource() {
        RoutingDataSource routingDataSource = new RoutingDataSource();
        Map<Object, Object> dataSourceMap = new HashMap<>();
        dataSourceMap.put("write", writeDataSource());
        for (int i = 0; i < readDataSources().size(); i++) {
            dataSourceMap.put("read" + i, readDataSources().get(i));
        }
        routingDataSource.setTargetDataSources(dataSourceMap);
        routingDataSource.setDefaultTargetDataSource(writeDataSource());
        return routingDataSource;
    }
}
```

**è·¯ç”±æ•°æ®æºå®ç°**:

```java
// RoutingDataSource.java
public class RoutingDataSource extends AbstractRoutingDataSource {

    private static final ThreadLocal<String> contextHolder = new ThreadLocal<>();
    private static final Random random = new Random();

    @Override
    protected Object determineCurrentLookupKey() {
        return contextHolder.get();
    }

    public static void setReadDataSource() {
        // éšæœºé€‰æ‹©ä»åº“
        int index = random.nextInt(2);
        contextHolder.set("read" + index);
    }

    public static void setWriteDataSource() {
        contextHolder.set("write");
    }

    public static void clear() {
        contextHolder.remove();
    }
}
```

**AOPåˆ‡é¢å®ç°**:

```java
// ReadWriteAspect.java
@Aspect
@Component
public class ReadWriteAspect {

    @Around("@annotation(org.springframework.transaction.annotation.Transactional)")
    public Object routeDataSource(ProceedingJoinPoint joinPoint) throws Throwable {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        Transactional transactional = signature.getMethod().getAnnotation(Transactional.class);

        if (transactional != null && transactional.readOnly()) {
            RoutingDataSource.setReadDataSource();
        } else {
            RoutingDataSource.setWriteDataSource();
        }

        try {
            return joinPoint.proceed();
        } finally {
            RoutingDataSource.clear();
        }
    }
}
```

### 8.3 Node.jsé…ç½®ç¤ºä¾‹

**Node.jsè¿æ¥æ± é…ç½®**:

```javascript
// db.js
const { Pool } = require('pg');
const _ = require('lodash');

// ä¸»åº“è¿æ¥æ± ï¼ˆå†™æ“ä½œï¼‰
const writePool = new Pool({
  host: 'primary_host',
  port: 5432,
  database: 'mydb',
  user: 'app_user',
  password: process.env.DB_PASSWORD,
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 30000,
});

// ä»åº“è¿æ¥æ± ï¼ˆè¯»æ“ä½œï¼‰
const readPools = [
  new Pool({
    host: 'standby1_host',
    port: 5432,
    database: 'mydb',
    user: 'app_user',
    password: process.env.DB_PASSWORD,
    max: 20,
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 30000,
  }),
  new Pool({
    host: 'standby2_host',
    port: 5432,
    database: 'mydb',
    user: 'app_user',
    password: process.env.DB_PASSWORD,
    max: 20,
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 30000,
  }),
];

// è·å–è¯»è¿æ¥æ± ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
function getReadPool() {
  return _.sample(readPools);
}

// æ•°æ®åº“æ“ä½œå°è£…
const db = {
  // å†™æ“ä½œ
  async query(sql, params) {
    return await writePool.query(sql, params);
  },

  // è¯»æ“ä½œ
  async read(sql, params) {
    const pool = getReadPool();
    return await pool.query(sql, params);
  },

  // äº‹åŠ¡ï¼ˆå†™æ“ä½œï¼‰
  async transaction(callback) {
    const client = await writePool.connect();
    try {
      await client.query('BEGIN');
      const result = await callback(client);
      await client.query('COMMIT');
      return result;
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  },
};

module.exports = db;
```

**ä½¿ç”¨ç¤ºä¾‹**:

```javascript
// routes/users.js
const db = require('../db');

// è¯»æ“ä½œï¼ˆè·¯ç”±åˆ°ä»åº“ï¼‰
router.get('/users', async (req, res) => {
  const result = await db.read('SELECT * FROM users');
  res.json(result.rows);
});

// å†™æ“ä½œï¼ˆè·¯ç”±åˆ°ä¸»åº“ï¼‰
router.post('/users', async (req, res) => {
  const result = await db.query(
    'INSERT INTO users (username, email) VALUES ($1, $2) RETURNING *',
    [req.body.username, req.body.email]
  );
  res.json(result.rows[0]);
});
```

### 8.4 Pythonè¿æ¥æ± é…ç½®

**Pythonè¿æ¥æ± é…ç½®**:

```python
# db.py
import psycopg2
from psycopg2 import pool
import random
import os

# ä¸»åº“è¿æ¥æ± ï¼ˆå†™æ“ä½œï¼‰
write_pool = psycopg2.pool.ThreadedConnectionPool(
    1,
    20,
    host='primary_host',
    port=5432,
    database='mydb',
    user='app_user',
    password=os.getenv('DB_PASSWORD'),
    connect_timeout=10
)

# ä»åº“è¿æ¥æ± ï¼ˆè¯»æ“ä½œï¼‰
read_pools = [
    psycopg2.pool.ThreadedConnectionPool(
        1,
        20,
        host='standby1_host',
        port=5432,
        database='mydb',
        user='app_user',
        password=os.getenv('DB_PASSWORD'),
        connect_timeout=10
    ),
    psycopg2.pool.ThreadedConnectionPool(
        1,
        20,
        host='standby2_host',
        port=5432,
        database='mydb',
        user='app_user',
        password=os.getenv('DB_PASSWORD'),
        connect_timeout=10
    ),
]

def get_read_pool():
    """è·å–è¯»è¿æ¥æ± ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰"""
    return random.choice(read_pools)

def execute_write(query, params=None):
    """æ‰§è¡Œå†™æ“ä½œ"""
    conn = write_pool.getconn()
    try:
        cursor = conn.cursor()
        cursor.execute(query, params)
        result = cursor.fetchall() if cursor.description else None
        conn.commit()
        return result
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        cursor.close()
        write_pool.putconn(conn)

def execute_read(query, params=None):
    """æ‰§è¡Œè¯»æ“ä½œ"""
    pool = get_read_pool()
    conn = pool.getconn()
    try:
        cursor = conn.cursor()
        cursor.execute(query, params)
        result = cursor.fetchall()
        return result
    finally:
        cursor.close()
        pool.putconn(conn)
```

## 9. æ•…éšœæ’æŸ¥å’Œè¯Šæ–­

### 9.1 è¯»å†™åˆ†ç¦»é—®é¢˜è¯Šæ–­

**é—®é¢˜è¯Šæ–­æ­¥éª¤**:

```sql
-- 1. æ£€æŸ¥pgpool-IIçŠ¶æ€
SHOW POOL_NODES;
SHOW POOL_PROCESSES;
SHOW POOL_STATS;

-- 2. æ£€æŸ¥åç«¯èŠ‚ç‚¹çŠ¶æ€
SELECT * FROM pgpool_nodes;

-- 3. æ£€æŸ¥è¯»å†™åˆ†ç¦»æ˜¯å¦ç”Ÿæ•ˆ
-- åœ¨ä¸»åº“æ‰§è¡Œ
SELECT count(*) FROM pg_stat_activity WHERE state = 'active';

-- åœ¨ä»åº“æ‰§è¡Œ
SELECT count(*) FROM pg_stat_activity WHERE state = 'active';

-- 4. æ£€æŸ¥æŸ¥è¯¢è·¯ç”±
-- é€šè¿‡pgpoolè¿æ¥æ‰§è¡ŒæŸ¥è¯¢ï¼ŒæŸ¥çœ‹å®é™…è¿æ¥çš„èŠ‚ç‚¹
SELECT pg_backend_pid(), inet_server_addr(), inet_server_port();
```

**å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ**:

```bash
# é—®é¢˜1: è¯»æ“ä½œä»ç„¶è·¯ç”±åˆ°ä¸»åº“
# åŸå› : pgpool-IIé…ç½®é”™è¯¯æˆ–æŸ¥è¯¢è¢«è¯†åˆ«ä¸ºå†™æ“ä½œ
# è§£å†³: æ£€æŸ¥pgpool.confé…ç½®
grep -i "load_balance_mode\|master_slave_mode" /etc/pgpool2/pgpool.conf

# é—®é¢˜2: è´Ÿè½½å‡è¡¡ä¸å·¥ä½œ
# åŸå› : åç«¯èŠ‚ç‚¹æƒé‡é…ç½®é”™è¯¯
# è§£å†³: æ£€æŸ¥backend_weighté…ç½®
grep -i "backend_weight" /etc/pgpool2/pgpool.conf

# é—®é¢˜3: è¿æ¥æ± è€—å°½
# åŸå› : è¿æ¥æ•°è¶…è¿‡é™åˆ¶
# è§£å†³: å¢åŠ è¿æ¥æ± å¤§å°æˆ–ä¼˜åŒ–è¿æ¥ä½¿ç”¨
SHOW POOL_STATS;
```

### 9.2 è´Ÿè½½å‡è¡¡é—®é¢˜

**è´Ÿè½½å‡è¡¡é—®é¢˜è¯Šæ–­**:

```sql
-- 1. æ£€æŸ¥è´Ÿè½½å‡è¡¡çŠ¶æ€
SHOW POOL_NODES;
-- æŸ¥çœ‹backend_weightå’ŒçŠ¶æ€

-- 2. æ£€æŸ¥è¿æ¥åˆ†å¸ƒ
SELECT
  backend_hostname,
  backend_port,
  count(*) as connection_count
FROM pg_stat_activity
GROUP BY backend_hostname, backend_port;

-- 3. æ£€æŸ¥æŸ¥è¯¢åˆ†å¸ƒ
-- é€šè¿‡pgpoolæ‰§è¡Œå¤šæ¬¡æŸ¥è¯¢ï¼Œè§‚å¯Ÿè¿æ¥èŠ‚ç‚¹
SELECT pg_backend_pid(), inet_server_addr();
```

**è´Ÿè½½å‡è¡¡ä¼˜åŒ–**:

```conf
# pgpool.conf
# æ ¹æ®ä»åº“æ€§èƒ½è°ƒæ•´æƒé‡
backend_weight1 = 2                    # é«˜æ€§èƒ½ä»åº“
backend_weight2 = 1                    # æ™®é€šä»åº“

# ä½¿ç”¨åŠ æƒè½®è¯¢
load_balance_algorithm = 'weighted_round_robin'
```

### 9.3 è¿æ¥æ± é—®é¢˜

**è¿æ¥æ± é—®é¢˜è¯Šæ–­**:

```sql
-- 1. æ£€æŸ¥è¿æ¥æ± çŠ¶æ€
SHOW POOL_PROCESSES;
SHOW POOL_STATS;

-- 2. æ£€æŸ¥è¿æ¥æ•°
SELECT
  datname,
  count(*) as connections,
  count(*) FILTER (WHERE state = 'active') as active_connections,
  count(*) FILTER (WHERE state = 'idle') as idle_connections
FROM pg_stat_activity
GROUP BY datname;

-- 3. æ£€æŸ¥è¿æ¥ç­‰å¾…
SELECT
  pid,
  wait_event_type,
  wait_event,
  state,
  query
FROM pg_stat_activity
WHERE wait_event_type IS NOT NULL;
```

**è¿æ¥æ± ä¼˜åŒ–**:

```conf
# pgpool.conf
# ä¼˜åŒ–è¿æ¥æ± å¤§å°
num_init_children = 64                # æ ¹æ®å¹¶å‘è¿æ¥æ•°è°ƒæ•´
max_pool = 4                          # æ¯ä¸ªå­è¿›ç¨‹çš„æœ€å¤§è¿æ¥æ•°

# è¿æ¥å¤ç”¨
connection_life_time = 0               # è¿æ¥ç”Ÿå‘½å‘¨æœŸ
client_idle_limit = 0                  # å®¢æˆ·ç«¯ç©ºé—²é™åˆ¶
```

### 9.4 æ€§èƒ½é—®é¢˜è¯Šæ–­

**æ€§èƒ½è¯Šæ–­è„šæœ¬**:

```bash
#!/bin/bash
# scripts/read_write_performance_diagnosis.sh

echo "=== è¯»å†™åˆ†ç¦»æ€§èƒ½è¯Šæ–­ ==="

# 1. ä¸»åº“å†™æ“ä½œç»Ÿè®¡
echo "=== ä¸»åº“å†™æ“ä½œç»Ÿè®¡ ==="
psql -h primary_host -U postgres -c "
SELECT
  datname,
  xact_commit,
  xact_rollback,
  blks_read,
  blks_hit,
  tup_inserted,
  tup_updated,
  tup_deleted
FROM pg_stat_database
WHERE datname = 'mydb';
"

# 2. ä»åº“è¯»æ“ä½œç»Ÿè®¡
echo "=== ä»åº“è¯»æ“ä½œç»Ÿè®¡ ==="
psql -h standby1_host -U postgres -c "
SELECT
  datname,
  numbackends,
  xact_commit,
  blks_read,
  blks_hit,
  tup_returned,
  tup_fetched
FROM pg_stat_database
WHERE datname = 'mydb';
"

# 3. pgpool-IIç»Ÿè®¡
echo "=== pgpool-IIç»Ÿè®¡ ==="
psql -h pgpool_host -p 9999 -U postgres -c "SHOW POOL_STATS;"

# 4. å¤åˆ¶å»¶è¿Ÿ
echo "=== å¤åˆ¶å»¶è¿Ÿ ==="
psql -h primary_host -U postgres -c "
SELECT
  application_name,
  pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn)) AS lag
FROM pg_stat_replication;
"
```

## 10. ç›‘æ§å’Œå‘Šè­¦

### 10.1 è¯»å†™åˆ†ç¦»æ•ˆæœç›‘æ§

**è¯»å†™åˆ†ç¦»æ•ˆæœç›‘æ§SQL**:

```sql
-- 1. ä¸»åº“å†™æ“ä½œç»Ÿè®¡
SELECT
  datname,
  xact_commit as writes,
  tup_inserted + tup_updated + tup_deleted as rows_written,
  blks_read + blks_hit as total_blocks
FROM pg_stat_database
WHERE datname = 'mydb';

-- 2. ä»åº“è¯»æ“ä½œç»Ÿè®¡
SELECT
  datname,
  numbackends as connections,
  xact_commit as reads,
  tup_returned + tup_fetched as rows_read,
  blks_read + blks_hit as total_blocks
FROM pg_stat_database
WHERE datname = 'mydb';

-- 3. è¯»å†™åˆ†ç¦»æ¯”ä¾‹
-- ä¸»åº“å†™æ“ä½œ / (ä¸»åº“å†™æ“ä½œ + ä»åº“è¯»æ“ä½œ)
SELECT
  (SELECT xact_commit FROM pg_stat_database WHERE datname = 'mydb') as writes,
  (SELECT sum(xact_commit) FROM pg_stat_database WHERE datname = 'mydb') as total_ops,
  round(
    100.0 * (SELECT xact_commit FROM pg_stat_database WHERE datname = 'mydb') /
    (SELECT sum(xact_commit) FROM pg_stat_database WHERE datname = 'mydb'),
    2
  ) as write_percentage;
```

### 10.2 å»¶è¿Ÿç›‘æ§

**å»¶è¿Ÿç›‘æ§é…ç½®**:

```sql
-- åˆ›å»ºå»¶è¿Ÿç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW read_write_lag_monitor AS
SELECT
  'primary' AS node_type,
  datname,
  pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(),
    (SELECT restart_lsn FROM pg_replication_slots WHERE slot_name = 'replica1')
  )) AS lag_size
FROM pg_stat_database
WHERE datname = 'mydb'
UNION ALL
SELECT
  'standby' AS node_type,
  datname,
  pg_size_pretty(pg_wal_lsn_diff(
    (SELECT pg_current_wal_lsn() FROM pg_stat_database WHERE datname = 'mydb'),
    pg_last_wal_replay_lsn()
  )) AS lag_size
FROM pg_stat_database
WHERE datname = 'mydb';
```

### 10.3 å‘Šè­¦è§„åˆ™é…ç½®

**Prometheuså‘Šè­¦è§„åˆ™**:

```yaml
# read-write-split-alerts.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: postgres-read-write-split-alerts
  namespace: monitoring
spec:
  groups:
  - name: postgres_read_write_split
    interval: 30s
    rules:
    - alert: PostgreSQLReadWriteSplitImbalance
      expr: |
        (pg_stat_database_xact_commit{datname="mydb",instance="primary"} /
         (pg_stat_database_xact_commit{datname="mydb",instance="primary"} +
          sum(pg_stat_database_xact_commit{datname="mydb",instance=~"standby.*"}))) > 0.5
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "PostgreSQL read-write split imbalance"
        description: "Write operations account for {{ $value | humanizePercentage }} of total operations"

    - alert: PostgreSQLReplicationLagHigh
      expr: pg_replication_lag > 10485760  # 10MB
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "PostgreSQL replication lag is high"
        description: "Replication lag is {{ $value }} bytes"
```

### 10.4 æ€§èƒ½æŒ‡æ ‡ç›‘æ§

**æ€§èƒ½æŒ‡æ ‡ç›‘æ§**:

```sql
-- 1. pgpool-IIæ€§èƒ½æŒ‡æ ‡
SHOW POOL_STATS;

-- 2. è¿æ¥æ± ä½¿ç”¨ç‡
SELECT
  (SELECT count(*) FROM pg_stat_activity) as current_connections,
  (SELECT setting::int FROM pg_settings WHERE name = 'max_connections') as max_connections,
  round(
    100.0 * (SELECT count(*) FROM pg_stat_activity) /
    (SELECT setting::int FROM pg_settings WHERE name = 'max_connections'),
    2
  ) as connection_usage_percent;

-- 3. æŸ¥è¯¢æ€§èƒ½
SELECT
  query,
  calls,
  mean_time,
  max_time,
  total_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 20;
```

---

## 11. æ™ºèƒ½äº‹åŠ¡è·¯ç”±

### 11.1 äº‹åŠ¡è·¯ç”±ç­–ç•¥è®¾è®¡

**æ™ºèƒ½äº‹åŠ¡è·¯ç”±**æ˜¯æ ¹æ®äº‹åŠ¡ç±»å‹ã€ä¸šåŠ¡ç‰¹å¾å’Œç³»ç»Ÿè´Ÿè½½ï¼Œè‡ªåŠ¨å°†äº‹åŠ¡è·¯ç”±åˆ°æœ€åˆé€‚çš„æ•°æ®åº“èŠ‚ç‚¹ï¼Œä»¥ä¼˜åŒ–æ€§èƒ½å’Œèµ„æºåˆ©ç”¨ã€‚

#### 11.1.1 è·¯ç”±ç®—æ³•è®¾è®¡

**è·¯ç”±å†³ç­–å› ç´ **ï¼š

1. **äº‹åŠ¡ç±»å‹**ï¼š
   - è¯»äº‹åŠ¡ â†’ ä»åº“
   - å†™äº‹åŠ¡ â†’ ä¸»åº“
   - åªè¯»äº‹åŠ¡ â†’ ä»åº“ï¼ˆå¯æ¥å—å»¶è¿Ÿï¼‰

2. **ä¸šåŠ¡ç±»å‹**ï¼š
   - å…³é”®ä¸šåŠ¡ â†’ ä¸»åº“ï¼ˆå¼ºä¸€è‡´æ€§ï¼‰
   - éå…³é”®ä¸šåŠ¡ â†’ ä»åº“ï¼ˆæœ€ç»ˆä¸€è‡´æ€§ï¼‰

3. **ç³»ç»Ÿè´Ÿè½½**ï¼š
   - è´Ÿè½½ä½çš„èŠ‚ç‚¹ä¼˜å…ˆ
   - èµ„æºåˆ©ç”¨ç‡ä½çš„èŠ‚ç‚¹ä¼˜å…ˆ

4. **æ•°æ®ä¸€è‡´æ€§è¦æ±‚**ï¼š
   - å¼ºä¸€è‡´æ€§ â†’ ä¸»åº“
   - æœ€ç»ˆä¸€è‡´æ€§ â†’ ä»åº“

**è·¯ç”±ç®—æ³•ç¤ºä¾‹**ï¼š

```python
# æ™ºèƒ½äº‹åŠ¡è·¯ç”±ç®—æ³•ï¼ˆPythonï¼‰
from enum import Enum
from typing import Optional, List
import psycopg

class TransactionType(Enum):
    READ = "read"
    WRITE = "write"
    READ_WRITE = "read_write"

class BusinessType(Enum):
    CRITICAL = "critical"  # å…³é”®ä¸šåŠ¡
    NORMAL = "normal"      # æ™®é€šä¸šåŠ¡
    BATCH = "batch"        # æ‰¹é‡ä¸šåŠ¡

class ConsistencyLevel(Enum):
    STRONG = "strong"      # å¼ºä¸€è‡´æ€§
    EVENTUAL = "eventual"  # æœ€ç»ˆä¸€è‡´æ€§

class SmartRouter:
    def __init__(self, primary_conn, standby_conns: List):
        self.primary_conn = primary_conn
        self.standby_conns = standby_conns

    def route_transaction(
        self,
        transaction_type: TransactionType,
        business_type: BusinessType = BusinessType.NORMAL,
        consistency_level: ConsistencyLevel = ConsistencyLevel.EVENTUAL
    ) -> psycopg.Connection:
        """æ™ºèƒ½è·¯ç”±äº‹åŠ¡åˆ°åˆé€‚çš„èŠ‚ç‚¹"""

        # å†™äº‹åŠ¡å¿…é¡»è·¯ç”±åˆ°ä¸»åº“
        if transaction_type == TransactionType.WRITE:
            return self.primary_conn

        # å…³é”®ä¸šåŠ¡æˆ–å¼ºä¸€è‡´æ€§è¦æ±‚ â†’ ä¸»åº“
        if business_type == BusinessType.CRITICAL or consistency_level == ConsistencyLevel.STRONG:
            return self.primary_conn

        # è¯»äº‹åŠ¡ â†’ é€‰æ‹©è´Ÿè½½æœ€ä½çš„ä»åº“
        if transaction_type == TransactionType.READ:
            return self._select_best_standby()

        # é»˜è®¤è·¯ç”±åˆ°ä¸»åº“
        return self.primary_conn

    def _select_best_standby(self) -> psycopg.Connection:
        """é€‰æ‹©è´Ÿè½½æœ€ä½çš„ä»åº“"""
        best_conn = None
        min_load = float('inf')

        for conn in self.standby_conns:
            load = self._get_node_load(conn)
            if load < min_load:
                min_load = load
                best_conn = conn

        return best_conn or self.standby_conns[0]

    def _get_node_load(self, conn: psycopg.Connection) -> float:
        """è·å–èŠ‚ç‚¹è´Ÿè½½ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰"""
        with conn.cursor() as cur:
            cur.execute("""
                SELECT
                  COUNT(*) as active_connections,
                  AVG(EXTRACT(EPOCH FROM (now() - query_start))) as avg_query_time
                FROM pg_stat_activity
                WHERE state = 'active'
            """)
            result = cur.fetchone()
            if result:
                connections, avg_time = result
                # è´Ÿè½½ = è¿æ¥æ•° * å¹³å‡æŸ¥è¯¢æ—¶é—´
                return connections * (avg_time or 0)
        return 0.0

# ä½¿ç”¨ç¤ºä¾‹
router = SmartRouter(primary_conn, [standby1_conn, standby2_conn])

# è¯»äº‹åŠ¡è·¯ç”±åˆ°ä»åº“
read_conn = router.route_transaction(
    TransactionType.READ,
    BusinessType.NORMAL,
    ConsistencyLevel.EVENTUAL
)

# å†™äº‹åŠ¡è·¯ç”±åˆ°ä¸»åº“
write_conn = router.route_transaction(
    TransactionType.WRITE,
    BusinessType.CRITICAL,
    ConsistencyLevel.STRONG
)
```

#### 11.1.2 è·¯ç”±è§„åˆ™é…ç½®

**è·¯ç”±è§„åˆ™é…ç½®**ï¼š

```yaml
# æ™ºèƒ½äº‹åŠ¡è·¯ç”±è§„åˆ™é…ç½®ï¼ˆYAMLæ ¼å¼ï¼‰
routing_rules:
  # è§„åˆ™1ï¼šå…³é”®ä¸šåŠ¡å†™æ“ä½œ
  - name: "critical_write"
    conditions:
      transaction_type: "write"
      business_type: "critical"
    action:
      route_to: "primary"
      consistency: "strong"

  # è§„åˆ™2ï¼šæ™®é€šè¯»æ“ä½œ
  - name: "normal_read"
    conditions:
      transaction_type: "read"
      business_type: "normal"
    action:
      route_to: "standby"
      consistency: "eventual"
      load_balancing: "least_connections"

  # è§„åˆ™3ï¼šæ‰¹é‡è¯»æ“ä½œ
  - name: "batch_read"
    conditions:
      transaction_type: "read"
      business_type: "batch"
    action:
      route_to: "standby"
      consistency: "eventual"
      load_balancing: "round_robin"

  # è§„åˆ™4ï¼šå¼ºä¸€è‡´æ€§è¯»æ“ä½œ
  - name: "strong_consistency_read"
    conditions:
      transaction_type: "read"
      consistency_requirement: "strong"
    action:
      route_to: "primary"
      consistency: "strong"
```

### 11.2 ä¸šåŠ¡ç±»å‹è¯†åˆ«å’Œè·¯ç”±

#### 11.2.1 ä¸šåŠ¡ç±»å‹è¯†åˆ«

**ä¸šåŠ¡ç±»å‹åˆ†ç±»**ï¼š

1. **å…³é”®ä¸šåŠ¡ï¼ˆCriticalï¼‰**ï¼š
   - é‡‘èäº¤æ˜“
   - ç”¨æˆ·è®¤è¯
   - è®¢å•æ”¯ä»˜
   - è¦æ±‚ï¼šå¼ºä¸€è‡´æ€§ã€ä½å»¶è¿Ÿ

2. **æ™®é€šä¸šåŠ¡ï¼ˆNormalï¼‰**ï¼š
   - ç”¨æˆ·æŸ¥è¯¢
   - å†…å®¹æµè§ˆ
   - æ•°æ®ç»Ÿè®¡
   - è¦æ±‚ï¼šæœ€ç»ˆä¸€è‡´æ€§å¯æ¥å—

3. **æ‰¹é‡ä¸šåŠ¡ï¼ˆBatchï¼‰**ï¼š
   - æ•°æ®å¯¼å‡º
   - æŠ¥è¡¨ç”Ÿæˆ
   - æ•°æ®åˆ†æ
   - è¦æ±‚ï¼šå¯æ¥å—å»¶è¿Ÿã€é«˜ååé‡

**è¯†åˆ«æ–¹æ³•**ï¼š

```python
# ä¸šåŠ¡ç±»å‹è¯†åˆ«ï¼ˆPythonï¼‰
import re
from typing import Optional

class BusinessTypeIdentifier:
    def __init__(self):
        # å…³é”®ä¸šåŠ¡SQLæ¨¡å¼
        self.critical_patterns = [
            r'\b(INSERT|UPDATE|DELETE).*accounts\b',
            r'\b(INSERT|UPDATE|DELETE).*transactions\b',
            r'\b(INSERT|UPDATE|DELETE).*orders\b.*status.*paid',
            r'\bSELECT.*FROM.*users.*WHERE.*password\b',
        ]

        # æ‰¹é‡ä¸šåŠ¡SQLæ¨¡å¼
        self.batch_patterns = [
            r'\bSELECT.*COUNT\(.*\)\b',
            r'\bSELECT.*GROUP BY\b',
            r'\bSELECT.*ORDER BY.*LIMIT\s+\d{4,}\b',  # å¤§é‡æ•°æ®
        ]

    def identify(self, sql: str, transaction_type: TransactionType) -> BusinessType:
        """è¯†åˆ«ä¸šåŠ¡ç±»å‹"""
        sql_upper = sql.upper()

        # æ£€æŸ¥å…³é”®ä¸šåŠ¡æ¨¡å¼
        for pattern in self.critical_patterns:
            if re.search(pattern, sql_upper, re.IGNORECASE):
                return BusinessType.CRITICAL

        # æ£€æŸ¥æ‰¹é‡ä¸šåŠ¡æ¨¡å¼
        if transaction_type == TransactionType.READ:
            for pattern in self.batch_patterns:
                if re.search(pattern, sql_upper, re.IGNORECASE):
                    return BusinessType.BATCH

        return BusinessType.NORMAL

# ä½¿ç”¨ç¤ºä¾‹
identifier = BusinessTypeIdentifier()

sql = "SELECT * FROM accounts WHERE user_id = 123"
business_type = identifier.identify(sql, TransactionType.READ)
# è¿”å›ï¼šBusinessType.NORMAL

sql = "UPDATE accounts SET balance = balance - 100 WHERE id = 1"
business_type = identifier.identify(sql, TransactionType.WRITE)
# è¿”å›ï¼šBusinessType.CRITICAL
```

#### 11.2.2 è·¯ç”±å®ç°

**åº”ç”¨å±‚è·¯ç”±å®ç°**ï¼š

```python
# åº”ç”¨å±‚æ™ºèƒ½è·¯ç”±å®ç°ï¼ˆPythonï¼‰
class ApplicationRouter:
    def __init__(self, router: SmartRouter, identifier: BusinessTypeIdentifier):
        self.router = router
        self.identifier = identifier

    def execute_query(
        self,
        sql: str,
        params: Optional[tuple] = None,
        consistency_level: ConsistencyLevel = ConsistencyLevel.EVENTUAL
    ):
        """æ‰§è¡ŒæŸ¥è¯¢ï¼ˆè‡ªåŠ¨è·¯ç”±ï¼‰"""
        # è¯†åˆ«äº‹åŠ¡ç±»å‹
        transaction_type = self._detect_transaction_type(sql)

        # è¯†åˆ«ä¸šåŠ¡ç±»å‹
        business_type = self.identifier.identify(sql, transaction_type)

        # è·¯ç”±åˆ°åˆé€‚çš„èŠ‚ç‚¹
        conn = self.router.route_transaction(
            transaction_type,
            business_type,
            consistency_level
        )

        # æ‰§è¡ŒæŸ¥è¯¢
        with conn.cursor() as cur:
            cur.execute(sql, params)
            if transaction_type == TransactionType.READ:
                return cur.fetchall()
            else:
                conn.commit()
                return cur.rowcount

    def _detect_transaction_type(self, sql: str) -> TransactionType:
        """æ£€æµ‹äº‹åŠ¡ç±»å‹"""
        sql_upper = sql.strip().upper()
        if sql_upper.startswith('SELECT'):
            return TransactionType.READ
        elif sql_upper.startswith(('INSERT', 'UPDATE', 'DELETE')):
            return TransactionType.WRITE
        else:
            return TransactionType.READ_WRITE
```

### 11.3 è¯»å†™åˆ†ç¦»æ™ºèƒ½è·¯ç”±

#### 11.3.1 è¯»æ“ä½œè·¯ç”±

**è¯»æ“ä½œè·¯ç”±ç­–ç•¥**ï¼š

1. **å¼ºä¸€è‡´æ€§è¯»**ï¼šè·¯ç”±åˆ°ä¸»åº“
2. **æœ€ç»ˆä¸€è‡´æ€§è¯»**ï¼šè·¯ç”±åˆ°è´Ÿè½½æœ€ä½çš„ä»åº“
3. **æ‰¹é‡è¯»**ï¼šè·¯ç”±åˆ°ä¸“ç”¨åˆ†æä»åº“

**å®ç°ç¤ºä¾‹**ï¼š

```python
# è¯»æ“ä½œæ™ºèƒ½è·¯ç”±ï¼ˆPythonï¼‰
class ReadRouter:
    def __init__(self, primary_conn, standby_conns: List, analytics_conn=None):
        self.primary_conn = primary_conn
        self.standby_conns = standby_conns
        self.analytics_conn = analytics_conn

    def route_read(
        self,
        sql: str,
        require_strong_consistency: bool = False,
        is_analytics_query: bool = False
    ) -> psycopg.Connection:
        """è·¯ç”±è¯»æ“ä½œ"""

        # åˆ†ææŸ¥è¯¢è·¯ç”±åˆ°åˆ†æåº“
        if is_analytics_query and self.analytics_conn:
            return self.analytics_conn

        # å¼ºä¸€è‡´æ€§è¦æ±‚ â†’ ä¸»åº“
        if require_strong_consistency:
            return self.primary_conn

        # æœ€ç»ˆä¸€è‡´æ€§ â†’ é€‰æ‹©è´Ÿè½½æœ€ä½çš„ä»åº“
        return self._select_best_standby()

    def _select_best_standby(self) -> psycopg.Connection:
        """é€‰æ‹©æœ€ä½³ä»åº“"""
        # æ£€æŸ¥ä»åº“å»¶è¿Ÿ
        best_conn = None
        min_lag = float('inf')

        for conn in self.standby_conns:
            lag = self._get_replication_lag(conn)
            if lag < min_lag:
                min_lag = lag
                best_conn = conn

        return best_conn or self.standby_conns[0]

    def _get_replication_lag(self, conn: psycopg.Connection) -> float:
        """è·å–å¤åˆ¶å»¶è¿Ÿï¼ˆç§’ï¼‰"""
        with conn.cursor() as cur:
            cur.execute("""
                SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag
            """)
            result = cur.fetchone()
            return result[0] if result and result[0] else 0.0
```

#### 11.3.2 å†™æ“ä½œè·¯ç”±

**å†™æ“ä½œè·¯ç”±ç­–ç•¥**ï¼š

1. **æ‰€æœ‰å†™æ“ä½œ**ï¼šå¿…é¡»è·¯ç”±åˆ°ä¸»åº“
2. **äº‹åŠ¡è·¯ç”±**ï¼šåŒ…å«å†™æ“ä½œçš„äº‹åŠ¡è·¯ç”±åˆ°ä¸»åº“
3. **æ‰¹é‡å†™**ï¼šè€ƒè™‘ä¸»åº“è´Ÿè½½ï¼Œå¯èƒ½éœ€è¦é™æµ

**å®ç°ç¤ºä¾‹**ï¼š

```python
# å†™æ“ä½œè·¯ç”±ï¼ˆPythonï¼‰
class WriteRouter:
    def __init__(self, primary_conn):
        self.primary_conn = primary_conn

    def route_write(
        self,
        sql: str,
        check_primary_health: bool = True
    ) -> psycopg.Connection:
        """è·¯ç”±å†™æ“ä½œï¼ˆæ€»æ˜¯è·¯ç”±åˆ°ä¸»åº“ï¼‰"""

        # æ£€æŸ¥ä¸»åº“å¥åº·çŠ¶æ€
        if check_primary_health:
            if not self._is_primary_healthy():
                raise Exception("Primary database is not healthy")

        return self.primary_conn

    def _is_primary_healthy(self) -> bool:
        """æ£€æŸ¥ä¸»åº“å¥åº·çŠ¶æ€"""
        try:
            with self.primary_conn.cursor() as cur:
                cur.execute("SELECT 1")
                return True
        except Exception:
            return False
```

### 11.4 è´Ÿè½½å‡è¡¡ç®—æ³•

#### 11.4.1 è½®è¯¢ç®—æ³•ï¼ˆRound Robinï¼‰

**è½®è¯¢ç®—æ³•**ï¼šæŒ‰é¡ºåºè½®æµåˆ†é…è¯·æ±‚åˆ°å„ä¸ªèŠ‚ç‚¹ã€‚

**å®ç°ç¤ºä¾‹**ï¼š

```python
# è½®è¯¢è´Ÿè½½å‡è¡¡ï¼ˆPythonï¼‰
class RoundRobinBalancer:
    def __init__(self, connections: List):
        self.connections = connections
        self.current_index = 0

    def get_connection(self) -> psycopg.Connection:
        """è·å–ä¸‹ä¸€ä¸ªè¿æ¥ï¼ˆè½®è¯¢ï¼‰"""
        conn = self.connections[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.connections)
        return conn
```

#### 11.4.2 åŠ æƒè½®è¯¢ï¼ˆWeighted Round Robinï¼‰

**åŠ æƒè½®è¯¢**ï¼šæ ¹æ®èŠ‚ç‚¹æ€§èƒ½è®¾ç½®æƒé‡ï¼Œé«˜æ€§èƒ½èŠ‚ç‚¹åˆ†é…æ›´å¤šè¯·æ±‚ã€‚

**å®ç°ç¤ºä¾‹**ï¼š

```python
# åŠ æƒè½®è¯¢è´Ÿè½½å‡è¡¡ï¼ˆPythonï¼‰
class WeightedRoundRobinBalancer:
    def __init__(self, connections_with_weights: List[tuple]):
        """
        connections_with_weights: [(connection, weight), ...]
        ä¾‹å¦‚ï¼š[(conn1, 3), (conn2, 2), (conn3, 1)]
        """
        self.connections = [c for c, _ in connections_with_weights]
        self.weights = [w for _, w in connections_with_weights]
        self.current_weights = self.weights.copy()
        self.current_index = 0

    def get_connection(self) -> psycopg.Connection:
        """è·å–ä¸‹ä¸€ä¸ªè¿æ¥ï¼ˆåŠ æƒè½®è¯¢ï¼‰"""
        # æ‰¾åˆ°æƒé‡æœ€å¤§çš„èŠ‚ç‚¹
        max_weight = max(self.current_weights)
        max_index = self.current_weights.index(max_weight)

        # å‡å°‘å½“å‰èŠ‚ç‚¹çš„æƒé‡
        self.current_weights[max_index] -= sum(self.weights)

        # å¦‚æœæ‰€æœ‰æƒé‡éƒ½<=0ï¼Œé‡ç½®
        if all(w <= 0 for w in self.current_weights):
            self.current_weights = self.weights.copy()

        return self.connections[max_index]
```

#### 11.4.3 æœ€å°‘è¿æ¥ï¼ˆLeast Connectionsï¼‰

**æœ€å°‘è¿æ¥**ï¼šé€‰æ‹©å½“å‰è¿æ¥æ•°æœ€å°‘çš„èŠ‚ç‚¹ã€‚

**å®ç°ç¤ºä¾‹**ï¼š

```python
# æœ€å°‘è¿æ¥è´Ÿè½½å‡è¡¡ï¼ˆPythonï¼‰
class LeastConnectionsBalancer:
    def __init__(self, connections: List):
        self.connections = connections

    def get_connection(self) -> psycopg.Connection:
        """è·å–è¿æ¥æ•°æœ€å°‘çš„èŠ‚ç‚¹"""
        best_conn = None
        min_connections = float('inf')

        for conn in self.connections:
            connections = self._get_active_connections(conn)
            if connections < min_connections:
                min_connections = connections
                best_conn = conn

        return best_conn or self.connections[0]

    def _get_active_connections(self, conn: psycopg.Connection) -> int:
        """è·å–èŠ‚ç‚¹æ´»è·ƒè¿æ¥æ•°"""
        with conn.cursor() as cur:
            cur.execute("""
                SELECT COUNT(*)
                FROM pg_stat_activity
                WHERE state = 'active'
            """)
            result = cur.fetchone()
            return result[0] if result else 0
```

#### 11.4.4 ä¸€è‡´æ€§å“ˆå¸Œ

**ä¸€è‡´æ€§å“ˆå¸Œ**ï¼šä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œç®—æ³•åˆ†é…è¯·æ±‚ï¼ŒèŠ‚ç‚¹å¢å‡æ—¶åªå½±å“ç›¸é‚»èŠ‚ç‚¹ã€‚

**å®ç°ç¤ºä¾‹**ï¼š

```python
# ä¸€è‡´æ€§å“ˆå¸Œè´Ÿè½½å‡è¡¡ï¼ˆPythonï¼‰
import hashlib

class ConsistentHashBalancer:
    def __init__(self, connections: List, virtual_nodes: int = 3):
        self.connections = connections
        self.virtual_nodes = virtual_nodes
        self.ring = {}
        self.sorted_keys = []

        # ä¸ºæ¯ä¸ªè¿æ¥åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹
        for conn in connections:
            for i in range(virtual_nodes):
                key = self._hash(f"{id(conn)}:{i}")
                self.ring[key] = conn
                self.sorted_keys.append(key)

        self.sorted_keys.sort()

    def _hash(self, key: str) -> int:
        """è®¡ç®—å“ˆå¸Œå€¼"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)

    def get_connection(self, routing_key: str) -> psycopg.Connection:
        """æ ¹æ®è·¯ç”±é”®è·å–è¿æ¥"""
        if not self.ring:
            return None

        hash_key = self._hash(routing_key)

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äºç­‰äºhash_keyçš„èŠ‚ç‚¹
        for ring_key in self.sorted_keys:
            if ring_key >= hash_key:
                return self.ring[ring_key]

        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆç¯çš„èµ·ç‚¹ï¼‰
        return self.ring[self.sorted_keys[0]]

# ä½¿ç”¨ç¤ºä¾‹
balancer = ConsistentHashBalancer([conn1, conn2, conn3])

# æ ¹æ®ç”¨æˆ·IDè·¯ç”±ï¼ˆç›¸åŒç”¨æˆ·æ€»æ˜¯è·¯ç”±åˆ°åŒä¸€èŠ‚ç‚¹ï¼‰
user_id = 123
conn = balancer.get_connection(f"user:{user_id}")
```

### 11.5 å®é™…é…ç½®ç¤ºä¾‹

#### 11.5.1 pgpool-IIæ™ºèƒ½è·¯ç”±é…ç½®

**pgpool-IIé…ç½®**ï¼š

```conf
# pgpool.conf
# æ™ºèƒ½è·¯ç”±é…ç½®

# å¯ç”¨è¯»å†™åˆ†ç¦»
master_slave_mode = on
load_balance_mode = on

# è¯»æ“ä½œè·¯ç”±åˆ°ä»åº“
read_function_list = 'currval,lastval,nextval,setval'
read_only_function_list = 'pg_read_file,pg_stat_file,pg_ls_dir,pg_current_logfile'

# å†™æ“ä½œè·¯ç”±åˆ°ä¸»åº“
write_function_list = 'nextval,setval'

# è´Ÿè½½å‡è¡¡ç®—æ³•
load_balance_mode = on
ignore_leading_white_space = on

# å»¶è¿Ÿæ£€æŸ¥ï¼ˆé¿å…è·¯ç”±åˆ°å»¶è¿Ÿè¿‡é«˜çš„ä»åº“ï¼‰
delay_threshold = 1000  # 1ç§’å»¶è¿Ÿé˜ˆå€¼

# å¥åº·æ£€æŸ¥
health_check_period = 10
health_check_timeout = 20
health_check_user = 'postgres'
health_check_password = 'password'
health_check_database = 'postgres'
```

#### 11.5.2 Djangoæ™ºèƒ½è·¯ç”±é…ç½®

**Djangoé…ç½®**ï¼š

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'USER': 'postgres',
        'PASSWORD': 'password',
        'HOST': 'primary-host',
        'PORT': '5432',
    },
    'read': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'USER': 'postgres',
        'PASSWORD': 'password',
        'HOST': 'standby-host',
        'PORT': '5432',
    }
}

# æ•°æ®åº“è·¯ç”±
DATABASE_ROUTERS = ['myapp.dbrouter.SmartDatabaseRouter']
```

**æ•°æ®åº“è·¯ç”±å®ç°**ï¼š

```python
# myapp/dbrouter.py
class SmartDatabaseRouter:
    """æ™ºèƒ½æ•°æ®åº“è·¯ç”±"""

    # è¯»æ“ä½œè·¯ç”±åˆ°ä»åº“çš„è¡¨
    read_tables = {'users', 'products', 'orders'}

    # å†™æ“ä½œè·¯ç”±åˆ°ä¸»åº“çš„è¡¨
    write_tables = {'users', 'products', 'orders', 'transactions'}

    def db_for_read(self, model, **hints):
        """è¯»æ“ä½œè·¯ç”±"""
        if model._meta.db_table in self.read_tables:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºä¸€è‡´æ€§
            if hints.get('require_strong_consistency', False):
                return 'default'  # ä¸»åº“
            return 'read'  # ä»åº“
        return None

    def db_for_write(self, model, **hints):
        """å†™æ“ä½œè·¯ç”±"""
        if model._meta.db_table in self.write_tables:
            return 'default'  # ä¸»åº“
        return None

    def allow_relation(self, obj1, obj2, **hints):
        """å…è®¸å…³ç³»"""
        return True

    def allow_migrate(self, db, app_label, model_name=None, **hints):
        """å…è®¸è¿ç§»"""
        return db == 'default'  # åªåœ¨ä¸»åº“è¿ç§»
```

#### 11.5.3 Spring Bootæ™ºèƒ½è·¯ç”±é…ç½®

**Spring Booté…ç½®**ï¼š

```yaml
# application.yml
spring:
  datasource:
    primary:
      jdbc-url: jdbc:postgresql://primary-host:5432/mydb
      username: postgres
      password: password
      driver-class-name: org.postgresql.Driver

    read:
      jdbc-url: jdbc:postgresql://standby-host:5432/mydb
      username: postgres
      password: password
      driver-class-name: org.postgresql.Driver
```

**æ•°æ®æºé…ç½®ç±»**ï¼š

```java
// DataSourceConfig.java
@Configuration
public class DataSourceConfig {

    @Bean
    @Primary
    @ConfigurationProperties("spring.datasource.primary")
    public DataSource primaryDataSource() {
        return DataSourceBuilder.create().build();
    }

    @Bean
    @ConfigurationProperties("spring.datasource.read")
    public DataSource readDataSource() {
        return DataSourceBuilder.create().build();
    }

    @Bean
    public DataSource routingDataSource() {
        RoutingDataSource routingDataSource = new RoutingDataSource();
        Map<Object, Object> dataSourceMap = new HashMap<>();
        dataSourceMap.put("primary", primaryDataSource());
        dataSourceMap.put("read", readDataSource());
        routingDataSource.setTargetDataSources(dataSourceMap);
        routingDataSource.setDefaultTargetDataSource(primaryDataSource());
        return routingDataSource;
    }
}

// RoutingDataSource.java
public class RoutingDataSource extends AbstractRoutingDataSource {

    @Override
    protected Object determineCurrentLookupKey() {
        // æ ¹æ®äº‹åŠ¡ç±»å‹å’Œä¸šåŠ¡ç±»å‹å†³å®šæ•°æ®æº
        if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {
            return "read";  // åªè¯»äº‹åŠ¡ â†’ ä»åº“
        }
        return "primary";  // å†™äº‹åŠ¡ â†’ ä¸»åº“
    }
}
```

#### 11.5.4 Node.jsæ™ºèƒ½è·¯ç”±é…ç½®

**Node.jsé…ç½®**ï¼š

```javascript
// db-router.js
const { Pool } = require('pg');

class SmartDatabaseRouter {
  constructor(config) {
    this.primaryPool = new Pool(config.primary);
    this.readPools = config.read.map(cfg => new Pool(cfg));
    this.currentReadIndex = 0;
  }

  async query(sql, params, options = {}) {
    const transactionType = this._detectTransactionType(sql);
    const requireStrongConsistency = options.requireStrongConsistency || false;

    // å†™æ“ä½œ â†’ ä¸»åº“
    if (transactionType === 'write') {
      return this.primaryPool.query(sql, params);
    }

    // å¼ºä¸€è‡´æ€§è¯» â†’ ä¸»åº“
    if (requireStrongConsistency) {
      return this.primaryPool.query(sql, params);
    }

    // æœ€ç»ˆä¸€è‡´æ€§è¯» â†’ ä»åº“ï¼ˆè½®è¯¢ï¼‰
    const readPool = this.readPools[this.currentReadIndex];
    this.currentReadIndex = (this.currentReadIndex + 1) % this.readPools.length;
    return readPool.query(sql, params);
  }

  _detectTransactionType(sql) {
    const sqlUpper = sql.trim().toUpperCase();
    if (sqlUpper.startsWith('SELECT')) {
      return 'read';
    } else if (sqlUpper.startsWith(('INSERT', 'UPDATE', 'DELETE'))) {
      return 'write';
    }
    return 'read';
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const router = new SmartDatabaseRouter({
  primary: {
    host: 'primary-host',
    port: 5432,
    database: 'mydb',
    user: 'postgres',
    password: 'password'
  },
  read: [
    {
      host: 'standby1-host',
      port: 5432,
      database: 'mydb',
      user: 'postgres',
      password: 'password'
    },
    {
      host: 'standby2-host',
      port: 5432,
      database: 'mydb',
      user: 'postgres',
      password: 'password'
    }
  ]
});

// è¯»æ“ä½œï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°ä»åº“ï¼‰
const users = await router.query('SELECT * FROM users WHERE id = $1', [123]);

// å†™æ“ä½œï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°ä¸»åº“ï¼‰
await router.query('INSERT INTO users (name) VALUES ($1)', ['Alice']);

// å¼ºä¸€è‡´æ€§è¯»ï¼ˆè·¯ç”±åˆ°ä¸»åº“ï¼‰
const account = await router.query(
  'SELECT * FROM accounts WHERE id = $1',
  [123],
  { requireStrongConsistency: true }
);
```

---

## 12. äº¤å‰å¼•ç”¨

### ç›¸å…³æ–‡æ¡£

#### éƒ¨ç½²æ¶æ„

- â­â­â­ [ä¸»ä»å¤åˆ¶é…ç½®æŒ‡å—](./05.05-ä¸»ä»å¤åˆ¶.md) - ä¸»ä»å¤åˆ¶åŸºç¡€
- â­â­â­ [é›†ç¾¤éƒ¨ç½²ä¸é«˜å¯ç”¨](./05.04-é›†ç¾¤éƒ¨ç½²ä¸é«˜å¯ç”¨.md) - é«˜å¯ç”¨æ¶æ„
- â­â­ [æ€§èƒ½è°ƒä¼˜å®è·µ](../å•æœºéƒ¨ç½²/05.02-æ€§èƒ½è°ƒä¼˜å®è·µ.md) - æ€§èƒ½ä¼˜åŒ–

#### æ ¸å¿ƒè¯¾ç¨‹

- â­â­ [äº‹åŠ¡ç®¡ç†ä¸ACIDç‰¹æ€§](../../01-æ ¸å¿ƒè¯¾ç¨‹/01.04-äº‹åŠ¡ç®¡ç†ä¸ACIDç‰¹æ€§.md) - äº‹åŠ¡ç®¡ç†åŸºç¡€
- â­â­ [å¹¶å‘æ§åˆ¶ä¸MVCCæœºåˆ¶](../../01-æ ¸å¿ƒè¯¾ç¨‹/01.05-å¹¶å‘æ§åˆ¶ä¸MVCCæœºåˆ¶.md) - å¹¶å‘æ§åˆ¶

#### æŸ¥è¯¢ä¸ä¼˜åŒ–

- â­â­ [æŸ¥è¯¢ä¼˜åŒ–å™¨åŸç†](../../03-æŸ¥è¯¢ä¸ä¼˜åŒ–/02.01-æŸ¥è¯¢ä¼˜åŒ–å™¨åŸç†.md) - æŸ¥è¯¢ä¼˜åŒ–
- â­ [æ‰§è¡Œè®¡åˆ’ä¸æ€§èƒ½è°ƒä¼˜](../../03-æŸ¥è¯¢ä¸ä¼˜åŒ–/02.04-æ‰§è¡Œè®¡åˆ’ä¸æ€§èƒ½è°ƒä¼˜.md) - æ€§èƒ½åˆ†æ

#### è¿ç»´å®è·µ

- â­â­â­ [ç›‘æ§ä¸è¯Šæ–­](../../06-è¿ç»´å®è·µ/ç›‘æ§ä¸è¯Šæ–­/06.01-ç›‘æ§ä¸è¯Šæ–­.md) - è¯»å†™åˆ†ç¦»ç›‘æ§
- â­â­ [å¤‡ä»½ä¸æ¢å¤](../../06-è¿ç»´å®è·µ/å¤‡ä»½ä¸æ¢å¤/06.06-å¤‡ä»½ä¸æ¢å¤.md) - å¤‡ä»½æ¢å¤

### å¤–éƒ¨èµ„æº

- [pgpool-II å®˜æ–¹æ–‡æ¡£](https://www.pgpool.net/docs/)
- [pgbouncer å®˜æ–¹æ–‡æ¡£](https://www.pgbouncer.org/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v3.0
**æœ€åæ›´æ–°**: 2025-01-16
**ç»´æŠ¤è€…**: PostgreSQL Documentation Team
