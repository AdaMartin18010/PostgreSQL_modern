---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL\05-éƒ¨ç½²æ¶æ„\å•æœºéƒ¨ç½²\05.02-æ€§èƒ½è°ƒä¼˜å®è·µ.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# æ€§èƒ½è°ƒä¼˜å®è·µ

**PostgreSQLç‰ˆæœ¬**: 18.x (æ¨è) â­ | 17.x (æ¨è) | 16.x, 15.x (å…¼å®¹)
**éš¾åº¦**: â­â­â­â­
**æœ€åæ›´æ–°**: 2025-11-12

> ğŸ†• **PostgreSQL 18 + pgvector 2.0 æ€§èƒ½ä¼˜åŒ–è¦ç‚¹** â­â­â­
>
> PostgreSQL 18 + pgvector 2.0 å¸¦æ¥å¤šé¡¹æ€§èƒ½æ”¹è¿›ï¼Œè°ƒä¼˜æ—¶åº”é‡ç‚¹å…³æ³¨ï¼š
>
> - âœ… **å¼‚æ­¥ I/O å­ç³»ç»Ÿ**: å‘é‡æ£€ç´¢ I/O æ€§èƒ½æå‡ 2-3 å€ â­â­â­
> - âœ… **è™šæ‹Ÿç”Ÿæˆåˆ—**: åŠ¨æ€è®¡ç®—ä¼˜åŒ–ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡ 15-25% â­â­
> - âœ… **å¹¶è¡ŒæŸ¥è¯¢å¢å¼º**: æ›´æ™ºèƒ½çš„å¹¶è¡Œæ‰§è¡Œè®¡åˆ’ï¼Œå»ºè®®è°ƒæ•´max_parallel_workers
> - âœ… **ç´¢å¼•ä¼˜åŒ–**: B-treeå»é‡ä¼˜åŒ–ï¼ŒBRINæ€§èƒ½æå‡15-20%
> - âœ… **å†…å­˜ç®¡ç†**: åŠ¨æ€å…±äº«å†…å­˜ï¼Œå¯å‡å°‘é¢„åˆ†é…å†…å­˜
> - âœ… **å‘é‡æ“ä½œ**: pgvector 2.0 SIMDä¼˜åŒ–ï¼Œæ€§èƒ½æå‡35-45%

---

## ç›®å½•

- [æ€§èƒ½è°ƒä¼˜å®è·µ](#æ€§èƒ½è°ƒä¼˜å®è·µ)
  - [ç›®å½•](#ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
  - [2. åˆå¹¶æ¥æºä¸æ˜ å°„](#2-åˆå¹¶æ¥æºä¸æ˜ å°„)
  - [3. åŸºçº¿ä¸å˜æ›´æ²»ç†](#3-åŸºçº¿ä¸å˜æ›´æ²»ç†)
    - [3.1 åŸºçº¿å‚æ•°å»ºç«‹](#31-åŸºçº¿å‚æ•°å»ºç«‹)
    - [3.2 SLAç›®æ ‡å®šä¹‰](#32-slaç›®æ ‡å®šä¹‰)
    - [3.3 æŒ‡æ ‡é˜ˆå€¼è®¾ç½®](#33-æŒ‡æ ‡é˜ˆå€¼è®¾ç½®)
    - [3.4 å˜æ›´ç¥¨æ®æ¨¡æ¿](#34-å˜æ›´ç¥¨æ®æ¨¡æ¿)
    - [3.5 é¢„ç”Ÿäº§å‹æµ‹](#35-é¢„ç”Ÿäº§å‹æµ‹)
  - [4. è°ƒä¼˜æµç¨‹](#4-è°ƒä¼˜æµç¨‹)
    - [4.1 æ­¥éª¤1: å…¥å£æŒ‡å¾è¯†åˆ«](#41-æ­¥éª¤1-å…¥å£æŒ‡å¾è¯†åˆ«)
    - [4.2 æ­¥éª¤2: å¿«é€Ÿä½“æ£€](#42-æ­¥éª¤2-å¿«é€Ÿä½“æ£€)
    - [4.3 æ­¥éª¤3: TopNåˆ†æ](#43-æ­¥éª¤3-topnåˆ†æ)
    - [4.4 æ­¥éª¤4: è®¡åˆ’æ ¸æŸ¥](#44-æ­¥éª¤4-è®¡åˆ’æ ¸æŸ¥)
    - [4.5 æ­¥éª¤5: ç­–ç•¥é€‰æ‹©](#45-æ­¥éª¤5-ç­–ç•¥é€‰æ‹©)
    - [4.6 æ­¥éª¤6: å°æ­¥å¿«è·‘](#46-æ­¥éª¤6-å°æ­¥å¿«è·‘)
    - [4.7 æ­¥éª¤7: å›å½’å®ˆæŠ¤](#47-æ­¥éª¤7-å›å½’å®ˆæŠ¤)
  - [5. å…¸å‹åœºæ™¯](#5-å…¸å‹åœºæ™¯)
  - [6. å·¥å…·ä¸æ–¹æ³•](#6-å·¥å…·ä¸æ–¹æ³•)
  - [7. å‚æ•°è°ƒä¼˜æŒ‡å—ï¼ˆæŒ‰å­ç³»ç»Ÿï¼‰](#7-å‚æ•°è°ƒä¼˜æŒ‡å—æŒ‰å­ç³»ç»Ÿ)
    - [7.1 è¿æ¥ä¸å¹¶å‘å‚æ•°](#71-è¿æ¥ä¸å¹¶å‘å‚æ•°)
    - [7.2 ç¼“å†²ä¸ç¼“å­˜å‚æ•°](#72-ç¼“å†²ä¸ç¼“å­˜å‚æ•°)
    - [7.3 å¹¶è¡Œä¸JITå‚æ•°](#73-å¹¶è¡Œä¸jitå‚æ•°)
    - [7.4 I/Oä¸å­˜å‚¨å‚æ•°](#74-ioä¸å­˜å‚¨å‚æ•°)
    - [7.5 WALä¸æŒä¹…åŒ–å‚æ•°](#75-walä¸æŒä¹…åŒ–å‚æ•°)
    - [7.6 ç»´æŠ¤ä¸è‡ªæ¸…ç†å‚æ•°](#76-ç»´æŠ¤ä¸è‡ªæ¸…ç†å‚æ•°)
  - [8. æŸ¥è¯¢å±‚ä¼˜åŒ–ç­–ç•¥](#8-æŸ¥è¯¢å±‚ä¼˜åŒ–ç­–ç•¥)
    - [8.1 ä»£ä»·å¯¹é½ä¼˜åŒ–](#81-ä»£ä»·å¯¹é½ä¼˜åŒ–)
    - [8.2 è®¿é—®è·¯å¾„ä¼˜åŒ–](#82-è®¿é—®è·¯å¾„ä¼˜åŒ–)
    - [8.3 è¿æ¥ç­–ç•¥ä¼˜åŒ–](#83-è¿æ¥ç­–ç•¥ä¼˜åŒ–)
    - [8.4 æŸ¥è¯¢é‡å†™ä¼˜åŒ–](#84-æŸ¥è¯¢é‡å†™ä¼˜åŒ–)
  - [9. å­˜å‚¨ä¸è¡¨è®¾è®¡](#9-å­˜å‚¨ä¸è¡¨è®¾è®¡)
  - [10. å…¸å‹å·¥ä½œè´Ÿè½½åŸºçº¿](#10-å…¸å‹å·¥ä½œè´Ÿè½½åŸºçº¿)
  - [11. éªŒè¯ä¸å›å½’](#11-éªŒè¯ä¸å›å½’)
  - [12. PostgreSQL 18 æ–°ç‰¹æ€§åº”ç”¨](#12-postgresql-18-æ–°ç‰¹æ€§åº”ç”¨)
    - [å¼‚æ­¥ I/O ä¼˜åŒ–](#å¼‚æ­¥-io-ä¼˜åŒ–)
    - [è™šæ‹Ÿç”Ÿæˆåˆ—ä¼˜åŒ–](#è™šæ‹Ÿç”Ÿæˆåˆ—ä¼˜åŒ–)
  - [13. ç´¢å¼•ä¼˜åŒ–æ·±åº¦åˆ†æ](#13-ç´¢å¼•ä¼˜åŒ–æ·±åº¦åˆ†æ)
    - [13.1 å¤åˆç´¢å¼•è®¾è®¡åŸåˆ™](#131-å¤åˆç´¢å¼•è®¾è®¡åŸåˆ™)
      - [13.1.1 å¤åˆç´¢å¼•åŸºç¡€](#1311-å¤åˆç´¢å¼•åŸºç¡€)
      - [13.1.2 è®¾è®¡åŸåˆ™](#1312-è®¾è®¡åŸåˆ™)
    - [13.2 åˆ—é¡ºåºé€‰æ‹©ç­–ç•¥](#132-åˆ—é¡ºåºé€‰æ‹©ç­–ç•¥)
      - [13.2.1 é€‰æ‹©æ€§è¯„ä¼°](#1321-é€‰æ‹©æ€§è¯„ä¼°)
      - [13.2.2 æŸ¥è¯¢é¢‘ç‡åˆ†æ](#1322-æŸ¥è¯¢é¢‘ç‡åˆ†æ)
      - [13.2.3 å®é™…æ¡ˆä¾‹](#1323-å®é™…æ¡ˆä¾‹)
    - [13.3 é€‰æ‹©æ€§è¯„ä¼°æ–¹æ³•](#133-é€‰æ‹©æ€§è¯„ä¼°æ–¹æ³•)
      - [13.3.1 ç»Ÿè®¡ä¿¡æ¯æŸ¥è¯¢](#1331-ç»Ÿè®¡ä¿¡æ¯æŸ¥è¯¢)
      - [13.3.2 ç›´æ–¹å›¾åˆ†æ](#1332-ç›´æ–¹å›¾åˆ†æ)
    - [13.4 ç´¢å¼•ç»´æŠ¤æœ€ä½³å®è·µ](#134-ç´¢å¼•ç»´æŠ¤æœ€ä½³å®è·µ)
      - [13.4.1 ç´¢å¼•é‡å»ºç­–ç•¥](#1341-ç´¢å¼•é‡å»ºç­–ç•¥)
      - [13.4.2 ç´¢å¼•ç›‘æ§](#1342-ç´¢å¼•ç›‘æ§)
    - [13.5 PostgreSQL 18ç´¢å¼•ä¼˜åŒ–](#135-postgresql-18ç´¢å¼•ä¼˜åŒ–)
      - [13.5.1 B-treeå»é‡ä¼˜åŒ–](#1351-b-treeå»é‡ä¼˜åŒ–)
      - [13.5.2 BRINæ€§èƒ½æå‡](#1352-brinæ€§èƒ½æå‡)
      - [13.5.3 å¹¶è¡Œç´¢å¼•æ„å»º](#1353-å¹¶è¡Œç´¢å¼•æ„å»º)
  - [14. ç»Ÿè®¡ä¿¡æ¯ç»´æŠ¤æœ€ä½³å®è·µ](#14-ç»Ÿè®¡ä¿¡æ¯ç»´æŠ¤æœ€ä½³å®è·µ)
    - [14.1 ANALYZEå‘½ä»¤æ·±åº¦ä½¿ç”¨](#141-analyzeå‘½ä»¤æ·±åº¦ä½¿ç”¨)
      - [14.1.1 ANALYZEåŸºç¡€](#1411-analyzeåŸºç¡€)
      - [14.1.2 ANALYZEå‚æ•°è¯¦è§£](#1412-analyzeå‚æ•°è¯¦è§£)
      - [14.1.3 ç»Ÿè®¡ä¿¡æ¯å†…å®¹](#1413-ç»Ÿè®¡ä¿¡æ¯å†…å®¹)
    - [14.2 ç»Ÿè®¡ä¿¡æ¯æ›´æ–°ç­–ç•¥](#142-ç»Ÿè®¡ä¿¡æ¯æ›´æ–°ç­–ç•¥)
      - [14.2.1 è‡ªåŠ¨ANALYZEé…ç½®](#1421-è‡ªåŠ¨analyzeé…ç½®)
      - [14.2.2 æ‰‹åŠ¨ANALYZEç­–ç•¥](#1422-æ‰‹åŠ¨analyzeç­–ç•¥)
      - [14.2.3 ç»Ÿè®¡ä¿¡æ¯ç›‘æ§](#1423-ç»Ÿè®¡ä¿¡æ¯ç›‘æ§)
    - [14.3 æŸ¥è¯¢è§„åˆ’å™¨ä¼˜åŒ–](#143-æŸ¥è¯¢è§„åˆ’å™¨ä¼˜åŒ–)
      - [14.3.1 ç»Ÿè®¡ä¿¡æ¯å¯¹è§„åˆ’å™¨çš„å½±å“](#1431-ç»Ÿè®¡ä¿¡æ¯å¯¹è§„åˆ’å™¨çš„å½±å“)
      - [14.3.2 æ‰©å±•ç»Ÿè®¡ä¿¡æ¯](#1432-æ‰©å±•ç»Ÿè®¡ä¿¡æ¯)
      - [14.3.3 æŸ¥è¯¢è®¡åˆ’éªŒè¯](#1433-æŸ¥è¯¢è®¡åˆ’éªŒè¯)
    - [14.4 PostgreSQL 18ç»Ÿè®¡ä¿¡æ¯æ–°ç‰¹æ€§](#144-postgresql-18ç»Ÿè®¡ä¿¡æ¯æ–°ç‰¹æ€§)
      - [14.4.1 è™šæ‹Ÿç”Ÿæˆåˆ—ç»Ÿè®¡](#1441-è™šæ‹Ÿç”Ÿæˆåˆ—ç»Ÿè®¡)
      - [14.4.2 æ”¹è¿›çš„å¤šå˜é‡ç»Ÿè®¡](#1442-æ”¹è¿›çš„å¤šå˜é‡ç»Ÿè®¡)
      - [14.4.3 æ›´ç²¾ç»†çš„ç›´æ–¹å›¾](#1443-æ›´ç²¾ç»†çš„ç›´æ–¹å›¾)
      - [14.4.4 è‡ªé€‚åº”ç»Ÿè®¡ä¿¡æ¯æ›´æ–°](#1444-è‡ªé€‚åº”ç»Ÿè®¡ä¿¡æ¯æ›´æ–°)
  - [15. è¯·æ±‚æ€§èƒ½è·Ÿè¸ª](#15-è¯·æ±‚æ€§èƒ½è·Ÿè¸ª)
    - [15.1 pg\_stat\_activityè§†å›¾æ·±åº¦ä½¿ç”¨](#151-pg_stat_activityè§†å›¾æ·±åº¦ä½¿ç”¨)
      - [15.1.1 è§†å›¾å­—æ®µè¯¦è§£](#1511-è§†å›¾å­—æ®µè¯¦è§£)
      - [15.1.2 è¿æ¥çŠ¶æ€åˆ†æ](#1512-è¿æ¥çŠ¶æ€åˆ†æ)
      - [15.1.3 ç­‰å¾…äº‹ä»¶åˆ†æ](#1513-ç­‰å¾…äº‹ä»¶åˆ†æ)
    - [15.2 å¹¶å‘é—®é¢˜è¯†åˆ«](#152-å¹¶å‘é—®é¢˜è¯†åˆ«)
      - [15.2.1 æ­»é”æ£€æµ‹](#1521-æ­»é”æ£€æµ‹)
      - [15.2.2 é˜»å¡æŸ¥è¯¢è¯†åˆ«](#1522-é˜»å¡æŸ¥è¯¢è¯†åˆ«)
      - [15.2.3 é•¿æ—¶é—´è¿è¡ŒæŸ¥è¯¢](#1523-é•¿æ—¶é—´è¿è¡ŒæŸ¥è¯¢)
    - [15.3 æ…¢æŸ¥è¯¢åˆ†æ](#153-æ…¢æŸ¥è¯¢åˆ†æ)
      - [15.3.1 ä½¿ç”¨pg\_stat\_statements](#1531-ä½¿ç”¨pg_stat_statements)
      - [15.3.2 æŸ¥è¯¢ä¼˜åŒ–å»ºè®®](#1532-æŸ¥è¯¢ä¼˜åŒ–å»ºè®®)
      - [15.3.3 å®æ—¶æ…¢æŸ¥è¯¢ç›‘æ§](#1533-å®æ—¶æ…¢æŸ¥è¯¢ç›‘æ§)
  - [16. äº‹åŠ¡èµ„æºæ¶ˆè€—åˆ†æ](#16-äº‹åŠ¡èµ„æºæ¶ˆè€—åˆ†æ)
    - [16.1 äº‹åŠ¡å†…å­˜ä½¿ç”¨ç›‘æ§](#161-äº‹åŠ¡å†…å­˜ä½¿ç”¨ç›‘æ§)
      - [16.1.1 work\_memç›‘æ§](#1611-work_memç›‘æ§)
      - [16.1.2 å†…å­˜ä½¿ç”¨åˆ†æ](#1612-å†…å­˜ä½¿ç”¨åˆ†æ)
    - [16.2 èµ„æºæ¶ˆè€—è¾ƒé«˜äº‹åŠ¡è¯†åˆ«](#162-èµ„æºæ¶ˆè€—è¾ƒé«˜äº‹åŠ¡è¯†åˆ«)
      - [16.2.1 è¯†åˆ«é«˜èµ„æºæ¶ˆè€—äº‹åŠ¡](#1621-è¯†åˆ«é«˜èµ„æºæ¶ˆè€—äº‹åŠ¡)
      - [16.2.2 èµ„æºæ¶ˆè€—åˆ†æå·¥å…·](#1622-èµ„æºæ¶ˆè€—åˆ†æå·¥å…·)
    - [16.3 èµ„æºé™åˆ¶é…ç½®](#163-èµ„æºé™åˆ¶é…ç½®)
      - [16.3.1 work\_memé…ç½®](#1631-work_memé…ç½®)
      - [16.3.2 è¿æ¥æ•°é™åˆ¶](#1632-è¿æ¥æ•°é™åˆ¶)
      - [16.3.3 èµ„æºé™åˆ¶æœ€ä½³å®è·µ](#1633-èµ„æºé™åˆ¶æœ€ä½³å®è·µ)
  - [17. MLé©±åŠ¨çš„æ€§èƒ½ä¼˜åŒ–](#17-mlé©±åŠ¨çš„æ€§èƒ½ä¼˜åŒ–)
    - [17.1 æœºå™¨å­¦ä¹ åœ¨æŸ¥è¯¢ä¼˜åŒ–ä¸­çš„åº”ç”¨](#171-æœºå™¨å­¦ä¹ åœ¨æŸ¥è¯¢ä¼˜åŒ–ä¸­çš„åº”ç”¨)
      - [17.1.1 MLæ¨¡å‹é€‰æ‹©](#1711-mlæ¨¡å‹é€‰æ‹©)
      - [17.1.2 ç‰¹å¾å·¥ç¨‹](#1712-ç‰¹å¾å·¥ç¨‹)
      - [17.1.3 æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°](#1713-æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°)
    - [17.2 è‡ªåŠ¨å‚æ•°è°ƒä¼˜](#172-è‡ªåŠ¨å‚æ•°è°ƒä¼˜)
      - [17.2.1 å‚æ•°è°ƒä¼˜ç®—æ³•](#1721-å‚æ•°è°ƒä¼˜ç®—æ³•)
      - [17.2.2 è‡ªåŠ¨åŒ–å·¥å…·](#1722-è‡ªåŠ¨åŒ–å·¥å…·)
    - [17.3 æ™ºèƒ½ç´¢å¼•æ¨è](#173-æ™ºèƒ½ç´¢å¼•æ¨è)
      - [17.3.1 ç´¢å¼•æ¨èç®—æ³•](#1731-ç´¢å¼•æ¨èç®—æ³•)
      - [17.3.2 å·¥å…·ä½¿ç”¨](#1732-å·¥å…·ä½¿ç”¨)
    - [17.4 è´Ÿè½½é¢„æµ‹å’Œèµ„æºè°ƒåº¦](#174-è´Ÿè½½é¢„æµ‹å’Œèµ„æºè°ƒåº¦)
      - [17.4.1 è´Ÿè½½é¢„æµ‹æ¨¡å‹](#1741-è´Ÿè½½é¢„æµ‹æ¨¡å‹)
      - [17.4.2 èµ„æºè°ƒåº¦ç­–ç•¥](#1742-èµ„æºè°ƒåº¦ç­–ç•¥)
  - [18. å®æˆ˜æ¡ˆä¾‹](#18-å®æˆ˜æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1: OLTPç³»ç»Ÿè°ƒä¼˜](#æ¡ˆä¾‹1-oltpç³»ç»Ÿè°ƒä¼˜)
    - [æ¡ˆä¾‹2: OLAPåˆ†æç³»ç»Ÿè°ƒä¼˜](#æ¡ˆä¾‹2-olapåˆ†æç³»ç»Ÿè°ƒä¼˜)
    - [æ¡ˆä¾‹3: æ··åˆè´Ÿè½½è°ƒä¼˜](#æ¡ˆä¾‹3-æ··åˆè´Ÿè½½è°ƒä¼˜)
  - [14. æ·±å…¥é˜…è¯»](#14-æ·±å…¥é˜…è¯»)
    - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)
      - [æŸ¥è¯¢ä¸ä¼˜åŒ–](#æŸ¥è¯¢ä¸ä¼˜åŒ–)
      - [æ ¸å¿ƒè¯¾ç¨‹](#æ ¸å¿ƒè¯¾ç¨‹)
      - [è¿ç»´å®è·µ](#è¿ç»´å®è·µ)
      - [å‰æ²¿æŠ€æœ¯](#å‰æ²¿æŠ€æœ¯)
      - [ç‰ˆæœ¬ç‰¹æ€§](#ç‰ˆæœ¬ç‰¹æ€§)
    - [å¤–éƒ¨èµ„æº](#å¤–éƒ¨èµ„æº)
  - [15. å‚è€ƒæ–‡çŒ®](#15-å‚è€ƒæ–‡çŒ®)

---

## 1. æ¦‚è¿°

- é¢å‘ç”Ÿäº§çš„â€œç›‘æµ‹â†’è¯Šæ–­â†’å®šä½â†’ä¼˜åŒ–â†’éªŒè¯â†’å›å½’é˜²æŠ¤â€é—­ç¯ã€‚
- åˆ†å±‚æ‹†è§£ï¼šç³»ç»Ÿèµ„æºï¼ˆCPU/å†…å­˜/IO/ç½‘ç»œï¼‰â†’ æ•°æ®åº“å®ä¾‹ï¼ˆè¿æ¥/ç¼“å†²/æ£€æŸ¥ç‚¹/WAL/Autovacuumï¼‰â†’ å¯¹è±¡ï¼ˆè¡¨/ç´¢å¼•/è†¨èƒ€ï¼‰â†’ æŸ¥è¯¢ä¸è®¡åˆ’ï¼ˆä»£ä»·/å¹¶è¡Œ/åŸºæ•°ï¼‰â†’ åº”ç”¨ï¼ˆè¿æ¥æ± /äº‹åŠ¡æ¨¡å‹ï¼‰ã€‚

## 2. åˆå¹¶æ¥æºä¸æ˜ å°„

- 1.1.16-æ€§èƒ½è°ƒä¼˜ä¸ç›‘æ§-æ‰©å……ç‰ˆ.md
- 1.1.16-æ€§èƒ½è°ƒä¼˜ä¸ç›‘æ§.md
- 03-æŸ¥è¯¢ä¸ä¼˜åŒ–/02.04-æ‰§è¡Œè®¡åˆ’ä¸æ€§èƒ½è°ƒä¼˜.mdï¼ˆäº¤å‰ï¼‰

## 3. åŸºçº¿ä¸å˜æ›´æ²»ç†

- å»ºç«‹"åŸºçº¿å‚æ•°+SLAç›®æ ‡+æŒ‡æ ‡é˜ˆå€¼+å›æ»šè„šæœ¬"çš„å˜æ›´å››ä»¶å¥—ã€‚
- æ¯æ¬¡è°ƒä¼˜ä»…å˜æ›´å°‘é‡å‚æ•°ï¼Œè®°å½•å˜æ›´ç¥¨æ®ï¼šå‚æ•°â†’æ—§å€¼â†’æ–°å€¼â†’é¢„æœŸå½±å“â†’éªŒè¯çª—å£â†’å›æ»šæ¡ä»¶ã€‚
- é¢„ç”Ÿäº§å‹æµ‹ä¸ç”Ÿäº§ç°åº¦ï¼šä»¥å…¸å‹å·¥ä½œè´Ÿè½½ï¼ˆOLTP/OLAP/æ··åˆï¼‰é‡æ”¾/å›æ”¾è¿›è¡Œå¯¹æ¯”ã€‚

### 3.1 åŸºçº¿å‚æ•°å»ºç«‹

```sql
-- 1. åˆ›å»ºå‚æ•°åŸºçº¿è¡¨
CREATE TABLE IF NOT EXISTS parameter_baseline (
    baseline_id SERIAL PRIMARY KEY,
    baseline_time TIMESTAMP DEFAULT NOW(),
    parameter_name TEXT,
    parameter_value TEXT,
    parameter_source TEXT,
    notes TEXT
);

-- 2. è®°å½•å½“å‰å‚æ•°åŸºçº¿
INSERT INTO parameter_baseline (parameter_name, parameter_value, parameter_source)
SELECT name, setting, source
FROM pg_settings
WHERE source IN ('configuration file', 'command line', 'environment variable')
AND name IN (
    'shared_buffers', 'work_mem', 'maintenance_work_mem',
    'max_connections', 'effective_cache_size',
    'random_page_cost', 'effective_io_concurrency',
    'checkpoint_timeout', 'max_wal_size',
    'autovacuum_vacuum_scale_factor', 'autovacuum_analyze_scale_factor'
);

-- 3. æŸ¥è¯¢å‚æ•°åŸºçº¿
SELECT * FROM parameter_baseline ORDER BY baseline_time DESC;
```

### 3.2 SLAç›®æ ‡å®šä¹‰

```sql
-- åˆ›å»ºSLAç›®æ ‡è¡¨
CREATE TABLE IF NOT EXISTS sla_targets (
    target_id SERIAL PRIMARY KEY,
    target_name TEXT,
    metric_name TEXT,
    target_value NUMERIC,
    unit TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- å®šä¹‰SLAç›®æ ‡
INSERT INTO sla_targets (target_name, metric_name, target_value, unit) VALUES
('P95å»¶è¿Ÿ', 'p95_latency', 100, 'ms'),
('P99å»¶è¿Ÿ', 'p99_latency', 500, 'ms'),
('ååé‡', 'tps', 1000, 'transactions/sec'),
('ç¼“å­˜å‘½ä¸­ç‡', 'cache_hit_ratio', 95, 'percent'),
('é”™è¯¯ç‡', 'error_rate', 0.1, 'percent');
```

### 3.3 æŒ‡æ ‡é˜ˆå€¼è®¾ç½®

```sql
-- åˆ›å»ºæŒ‡æ ‡é˜ˆå€¼è¡¨
CREATE TABLE IF NOT EXISTS metric_thresholds (
    threshold_id SERIAL PRIMARY KEY,
    metric_name TEXT,
    warning_threshold NUMERIC,
    critical_threshold NUMERIC,
    unit TEXT
);

-- è®¾ç½®æŒ‡æ ‡é˜ˆå€¼
INSERT INTO metric_thresholds (metric_name, warning_threshold, critical_threshold, unit) VALUES
('active_connections', 80, 95, 'count'),
('cache_hit_ratio', 90, 85, 'percent'),
('replication_lag', 1048576, 10485760, 'bytes'),  -- 1MB, 10MB
('dead_tuples_ratio', 10, 20, 'percent'),
('checkpoint_frequency', 5, 10, 'minutes');
```

### 3.4 å˜æ›´ç¥¨æ®æ¨¡æ¿

```sql
-- åˆ›å»ºå˜æ›´è®°å½•è¡¨
CREATE TABLE IF NOT EXISTS change_tickets (
    ticket_id SERIAL PRIMARY KEY,
    change_time TIMESTAMP DEFAULT NOW(),
    parameter_name TEXT,
    old_value TEXT,
    new_value TEXT,
    expected_impact TEXT,
    verification_window TEXT,
    rollback_condition TEXT,
    change_status TEXT,  -- 'pending', 'in_progress', 'completed', 'rolled_back'
    actual_impact TEXT,
    changed_by TEXT
);

-- è®°å½•å˜æ›´
INSERT INTO change_tickets (
    parameter_name, old_value, new_value, expected_impact,
    verification_window, rollback_condition, changed_by
) VALUES (
    'shared_buffers', '256MB', '512MB',
    'æé«˜ç¼“å­˜å‘½ä¸­ç‡5-10%',
    '2025-11-22 02:00 - 06:00',
    'P95å»¶è¿Ÿå¢åŠ >10%æˆ–é”™è¯¯ç‡ä¸Šå‡',
    current_user
);
```

### 3.5 é¢„ç”Ÿäº§å‹æµ‹

```bash
# ä½¿ç”¨pgbenchè¿›è¡Œå‹æµ‹
# 1. åˆå§‹åŒ–æµ‹è¯•æ•°æ®
pgbench -i -s 100 mydb  # -s: ç¼©æ”¾å› å­ï¼Œ100è¡¨ç¤º1000ä¸‡è¡Œ

# 2. è¿è¡ŒåŸºå‡†æµ‹è¯•
pgbench -c 10 -j 2 -T 300 mydb
# -c: å®¢æˆ·ç«¯æ•°
# -j: çº¿ç¨‹æ•°
# -T: è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰

# 3. è¿è¡Œè‡ªå®šä¹‰æµ‹è¯•
pgbench -f custom_script.sql -c 10 -j 2 -T 300 mydb

# 4. å¯¹æ¯”æµ‹è¯•ç»“æœ
# å˜æ›´å‰
pgbench -c 10 -j 2 -T 300 mydb > baseline.txt

# å˜æ›´å
pgbench -c 10 -j 2 -T 300 mydb > after_change.txt

# å¯¹æ¯”
diff baseline.txt after_change.txt
```

## 4. è°ƒä¼˜æµç¨‹

- æŒ‡æ ‡è§‚å¯Ÿâ†’ç“¶é¢ˆå½’å› ï¼ˆCPU/IO/é”/è®¡åˆ’ï¼‰â†’å˜æ›´éªŒè¯
- æ­¥éª¤åŒ–SOPï¼š
  1) å…¥å£æŒ‡å¾ï¼šP99/åå/é”™è¯¯ç‡å¼‚å¸¸ã€é˜Ÿåˆ—å †ç§¯ã€å‘Šè­¦è§¦å‘ï¼›
  2) å¿«é€Ÿä½“æ£€ï¼šè¿æ¥ã€CPUåˆ©ç”¨ã€IOé¥±å’Œã€WAL/æ£€æŸ¥ç‚¹ã€Autovacuumæ»åï¼›
  3) TopNï¼š`pg_stat_statements`/æ´»åŠ¨ä¼šè¯/ç­‰å¾…äº‹ä»¶ï¼›
  4) è®¡åˆ’æ ¸æŸ¥ï¼š`EXPLAIN (ANALYZE, BUFFERS, TIMING)` ä¸åŸºæ•°ã€å¹¶è¡Œåº¦ã€I/Oå‘½ä¸­ï¼›
  5) ç­–ç•¥é€‰æ‹©ï¼šç´¢å¼•/ç»Ÿè®¡/SQL/å‚æ•°/æ¶æ„æ”¹é€ ï¼›
  6) å°æ­¥å¿«è·‘ï¼šå•å˜é‡å˜æ›´â†’å¯¹æ¯”æŒ‡æ ‡â†’ä¿ç•™æˆ–å›æ»šï¼›
  7) å›å½’å®ˆæŠ¤ï¼šå‘Šè­¦é—¨æ§›ã€è‡ªåŠ¨å›æ»šå¼€å…³ï¼ˆå¿…è¦æ—¶ï¼‰ã€‚

### 4.1 æ­¥éª¤1: å…¥å£æŒ‡å¾è¯†åˆ«

```sql
-- 1. æ£€æŸ¥P99å»¶è¿Ÿï¼ˆéœ€è¦pg_stat_statementsï¼‰
SELECT
    queryid,
    LEFT(query, 100) as query_preview,
    calls,
    mean_exec_time,
    (SELECT percentile_cont(0.99) WITHIN GROUP (ORDER BY mean_exec_time)
     FROM pg_stat_statements) as p99_latency
FROM pg_stat_statements
WHERE mean_exec_time > (
    SELECT percentile_cont(0.99) WITHIN GROUP (ORDER BY mean_exec_time)
    FROM pg_stat_statements
)
ORDER BY mean_exec_time DESC
LIMIT 10;

-- 2. æ£€æŸ¥ååé‡
SELECT
    datname,
    xact_commit + xact_rollback as total_transactions,
    xact_commit,
    xact_rollback
FROM pg_stat_database
WHERE datname = current_database();

-- 3. æ£€æŸ¥é”™è¯¯ç‡
SELECT
    datname,
    xact_rollback::float / NULLIF(xact_commit + xact_rollback, 0) * 100 as error_rate
FROM pg_stat_database
WHERE datname = current_database();

-- 4. æ£€æŸ¥é˜Ÿåˆ—å †ç§¯
SELECT
    COUNT(*) FILTER (WHERE state = 'active') as active_queries,
    COUNT(*) FILTER (WHERE wait_event_type IS NOT NULL) as waiting_queries,
    COUNT(*) as total_connections
FROM pg_stat_activity
WHERE datname = current_database();
```

### 4.2 æ­¥éª¤2: å¿«é€Ÿä½“æ£€

```sql
-- 1. è¿æ¥æ•°æ£€æŸ¥
SELECT
    COUNT(*) as total_connections,
    COUNT(*) FILTER (WHERE state = 'active') as active_connections,
    COUNT(*) FILTER (WHERE state = 'idle') as idle_connections,
    COUNT(*) FILTER (WHERE state = 'idle in transaction') as idle_in_transaction
FROM pg_stat_activity
WHERE datname = current_database();

-- 2. CPUåˆ©ç”¨ç‡ï¼ˆé€šè¿‡ç­‰å¾…äº‹ä»¶æ¨æ–­ï¼‰
SELECT
    wait_event_type,
    COUNT(*) as count,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as percentage
FROM pg_stat_activity
WHERE wait_event_type IS NOT NULL
GROUP BY wait_event_type
ORDER BY count DESC;

-- 3. I/Oé¥±å’Œæ£€æŸ¥
SELECT
    datname,
    blks_read,
    blks_hit,
    ROUND(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) as cache_hit_ratio
FROM pg_stat_database
WHERE datname = current_database();

-- 4. WAL/æ£€æŸ¥ç‚¹æ£€æŸ¥
SELECT
    checkpoints_timed,
    checkpoints_req,
    checkpoint_write_time,
    checkpoint_sync_time,
    buffers_checkpoint,
    buffers_clean,
    buffers_backend
FROM pg_stat_bgwriter;

-- 5. Autovacuumæ»åæ£€æŸ¥
SELECT
    schemaname,
    tablename,
    n_dead_tup,
    n_live_tup,
    last_autovacuum,
    CASE
        WHEN n_live_tup > 0 THEN ROUND(100.0 * n_dead_tup / n_live_tup, 2)
        ELSE 0
    END as dead_tuple_percent
FROM pg_stat_user_tables
WHERE n_dead_tup > 10000
ORDER BY n_dead_tup DESC
LIMIT 20;
```

### 4.3 æ­¥éª¤3: TopNåˆ†æ

```sql
-- 1. TopNæ…¢æŸ¥è¯¢
SELECT
    queryid,
    LEFT(query, 200) as query_preview,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time,
    rows,
    ROUND(100.0 * shared_blks_hit / NULLIF(shared_blks_hit + shared_blks_read, 0), 2) as hit_ratio
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 10;

-- 2. TopNæ´»åŠ¨ä¼šè¯
SELECT
    pid,
    usename,
    application_name,
    state,
    wait_event_type,
    wait_event,
    query_start,
    NOW() - query_start as query_duration,
    LEFT(query, 100) as query_preview
FROM pg_stat_activity
WHERE state = 'active'
ORDER BY query_start
LIMIT 10;

-- 3. TopNç­‰å¾…äº‹ä»¶
SELECT
    wait_event_type,
    wait_event,
    COUNT(*) as count
FROM pg_stat_activity
WHERE wait_event_type IS NOT NULL
GROUP BY wait_event_type, wait_event
ORDER BY count DESC
LIMIT 10;
```

### 4.4 æ­¥éª¤4: è®¡åˆ’æ ¸æŸ¥

```sql
-- 1. æ‰§è¡ŒEXPLAIN (ANALYZE, BUFFERS, TIMING)
EXPLAIN (ANALYZE, BUFFERS, VERBOSE, COSTS, TIMING)
SELECT * FROM users WHERE email = 'user@example.com';

-- 2. åˆ†æè®¡åˆ’å…³é”®æŒ‡æ ‡
-- - Planning Time: è®¡åˆ’æ—¶é—´
-- - Execution Time: æ‰§è¡Œæ—¶é—´
-- - Buffers: shared hit/read/dirtied/written
-- - I/O Time: è¯»å–æ—¶é—´
-- - Rows: å®é™…è¡Œæ•° vs ä¼°ç®—è¡Œæ•°

-- 3. æ£€æŸ¥åŸºæ•°ä¼°ç®—è¯¯å·®
-- å¦‚æœå®é™…è¡Œæ•°ä¸ä¼°ç®—è¡Œæ•°å·®å¼‚å¤§ï¼Œéœ€è¦æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE users;

-- 4. æ£€æŸ¥å¹¶è¡Œåº¦
-- æŸ¥çœ‹è®¡åˆ’ä¸­æ˜¯å¦ä½¿ç”¨äº†å¹¶è¡Œå·¥ä½œè¿›ç¨‹
-- å¦‚æœåº”è¯¥å¹¶è¡Œä½†æ²¡æœ‰ï¼Œæ£€æŸ¥max_parallel_workers_per_gather

-- 5. æ£€æŸ¥I/Oå‘½ä¸­ç‡
-- shared hitåº”è¯¥å°½å¯èƒ½é«˜ï¼ˆ>95%ï¼‰
```

### 4.5 æ­¥éª¤5: ç­–ç•¥é€‰æ‹©

```sql
-- ç­–ç•¥1: ç´¢å¼•ä¼˜åŒ–
-- æ£€æŸ¥ç¼ºå¤±çš„ç´¢å¼•
SELECT
    schemaname,
    tablename,
    seq_scan,
    idx_scan,
    CASE
        WHEN seq_scan + idx_scan > 0
        THEN ROUND(100.0 * seq_scan / (seq_scan + idx_scan), 2)
        ELSE 0
    END as seq_scan_percent
FROM pg_stat_user_tables
WHERE seq_scan > 1000
AND seq_scan > idx_scan
ORDER BY seq_scan DESC
LIMIT 10;

-- ç­–ç•¥2: ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–
ALTER TABLE users ALTER COLUMN email SET STATISTICS 1000;
CREATE STATISTICS users_email_stats (dependencies) ON email, created_at FROM users;
ANALYZE users;

-- ç­–ç•¥3: SQLé‡å†™
-- ä¼˜åŒ–æŸ¥è¯¢é€»è¾‘ï¼Œå‡å°‘æ•°æ®æ‰«æ

-- ç­–ç•¥4: å‚æ•°è°ƒæ•´
ALTER SYSTEM SET work_mem = '64MB';
SELECT pg_reload_conf();

-- ç­–ç•¥5: æ¶æ„æ”¹é€ 
-- åˆ†åŒºè¡¨ã€è¯»å†™åˆ†ç¦»ã€ç¼“å­˜å±‚ç­‰
```

### 4.6 æ­¥éª¤6: å°æ­¥å¿«è·‘

```bash
# 1. è®°å½•å˜æ›´å‰æŒ‡æ ‡
psql -c "
SELECT
    'baseline' as stage,
    NOW() as timestamp,
    (SELECT SUM(total_exec_time) FROM pg_stat_statements) as total_exec_time,
    (SELECT SUM(blks_hit)::float / NULLIF(SUM(blks_hit) + SUM(blks_read), 0) * 100
     FROM pg_stat_database WHERE datname = current_database()) as cache_hit_ratio
" > /tmp/baseline_metrics.txt

# 2. æ‰§è¡Œå•å˜é‡å˜æ›´
psql -c "ALTER SYSTEM SET work_mem = '64MB';"
psql -c "SELECT pg_reload_conf();"

# 3. ç­‰å¾…ç¨³å®šæœŸï¼ˆ5-10åˆ†é’Ÿï¼‰
sleep 300

# 4. è®°å½•å˜æ›´åæŒ‡æ ‡
psql -c "
SELECT
    'after_change' as stage,
    NOW() as timestamp,
    (SELECT SUM(total_exec_time) FROM pg_stat_statements) as total_exec_time,
    (SELECT SUM(blks_hit)::float / NULLIF(SUM(blks_hit) + SUM(blks_read), 0) * 100
     FROM pg_stat_database WHERE datname = current_database()) as cache_hit_ratio
" > /tmp/after_change_metrics.txt

# 5. å¯¹æ¯”æŒ‡æ ‡
diff /tmp/baseline_metrics.txt /tmp/after_change_metrics.txt

# 6. å†³å®šä¿ç•™æˆ–å›æ»š
# å¦‚æœæ€§èƒ½æå‡ï¼Œä¿ç•™å˜æ›´
# å¦‚æœæ€§èƒ½ä¸‹é™ï¼Œå›æ»š
```

### 4.7 æ­¥éª¤7: å›å½’å®ˆæŠ¤

```sql
-- 1. åˆ›å»ºå‘Šè­¦é˜ˆå€¼è¡¨
CREATE TABLE IF NOT EXISTS alert_thresholds (
    threshold_id SERIAL PRIMARY KEY,
    metric_name TEXT,
    warning_value NUMERIC,
    critical_value NUMERIC,
    auto_rollback BOOLEAN DEFAULT false
);

-- 2. è®¾ç½®å‘Šè­¦é˜ˆå€¼
INSERT INTO alert_thresholds (metric_name, warning_value, critical_value, auto_rollback) VALUES
('p95_latency', 100, 200, false),  -- æ¯«ç§’
('error_rate', 0.1, 1.0, true),    -- ç™¾åˆ†æ¯”
('cache_hit_ratio', 90, 85, false); -- ç™¾åˆ†æ¯”

-- 3. ç›‘æ§æŸ¥è¯¢ï¼ˆå®šæœŸæ‰§è¡Œï¼‰
SELECT
    metric_name,
    current_value,
    warning_value,
    critical_value,
    CASE
        WHEN current_value >= critical_value THEN 'CRITICAL'
        WHEN current_value >= warning_value THEN 'WARNING'
        ELSE 'OK'
    END as status
FROM (
    SELECT
        'p95_latency' as metric_name,
        (SELECT percentile_cont(0.95) WITHIN GROUP (ORDER BY mean_exec_time)
         FROM pg_stat_statements) as current_value,
        (SELECT critical_value FROM alert_thresholds WHERE metric_name = 'p95_latency') as critical_value,
        (SELECT warning_value FROM alert_thresholds WHERE metric_name = 'p95_latency') as warning_value
) sub;
```

## 5. å…¸å‹åœºæ™¯

- ç´¢å¼•/ç»Ÿè®¡ä¿¡æ¯ã€è¿æ¥æ± ã€å¹¶è¡Œã€å­˜å‚¨ä¸æ£€æŸ¥ç‚¹
- ç¤ºä¾‹æ’æŸ¥ä¸å¤„ç½®ï¼š
  - ä¼°ç®—åå·®â†’æ‰©å¤§ç»Ÿè®¡ç›®æ ‡æˆ–åˆ›å»ºæ‰©å±•ç»Ÿè®¡ï¼š

    ```sql
    ALTER TABLE t ALTER COLUMN c SET STATISTICS 2000;
    CREATE STATISTICS s_t_multi (dependencies) ON c1, c2 FROM t;  -- ç›¸å…³æ€§
    ANALYZE t;
    ```

  - ç´¢å¼•æœªå‘½ä¸­â†’è°“è¯å¯ç´¢å¼•åŒ–/è¡¨è¾¾å¼ç´¢å¼•/ç±»å‹ä¸€è‡´ï¼š

    ```sql
    CREATE INDEX idx_t_lower_email ON t (lower(email));
    -- ç¡®ä¿æŸ¥è¯¢ç”¨ lower(email) = ...
    ```

  - é”ç­‰å¾…â†’å®šä½æŒé”é•¿äº‹åŠ¡ä¸å†²çªè¯­å¥ï¼Œå¿…è¦æ—¶æ‹†åˆ†DDL/æ‰¹é‡ï¼š

    ```sql
    SELECT * FROM pg_locks l JOIN pg_stat_activity a USING(pid) WHERE NOT granted;
    ```

  - è†¨èƒ€â†’è¯„ä¼° `autovacuum`ã€é‡å»ºç´¢å¼•/è¡¨ï¼š

    ```sql
    REINDEX TABLE CONCURRENTLY t;
    VACUUM (VERBOSE, ANALYZE) t;
    ```

## 6. å·¥å…·ä¸æ–¹æ³•

- EXPLAIN (ANALYZE, BUFFERS, TIMING)ã€pg_stat_statementsã€é‡‡æ ·/å‰–æ
- å¿…å¤‡æ‰©å±•ä¸è®¾ç½®ï¼š
  - `pg_stat_statements`ï¼š

    ```sql
    CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
    SELECT query, calls, mean_time, rows
    FROM pg_stat_statements ORDER BY total_time DESC LIMIT 20;
    ```

  - `auto_explain`ï¼ˆå¼€å‘/é¢„ç”Ÿäº§å¯ç”¨ï¼Œç”Ÿäº§æ…ç”¨é«˜é˜ˆå€¼ï¼‰ï¼š

    ```text
    shared_preload_libraries = 'pg_stat_statements,auto_explain'
    auto_explain.log_min_duration = '200ms'
    auto_explain.log_analyze = on
    auto_explain.log_buffers = on
    auto_explain.log_nested_statements = on
    ```

  - é‡‡æ ·ä¸ç­‰å¾…åˆ†æï¼š`pg_wait_sampling`ã€`pg_stat_kcache`ã€eBPF/bcc å·¥å…·ï¼ˆå¦‚ `profile`, `offcputime`ï¼‰ã€‚

## 7. å‚æ•°è°ƒä¼˜æŒ‡å—ï¼ˆæŒ‰å­ç³»ç»Ÿï¼‰

- è¿æ¥ä¸å¹¶å‘ï¼š
- åº”ç”¨ä¼˜å…ˆè¿æ¥æ± ï¼š`pgbouncer`ï¼ˆtransaction æ¨¡å¼ï¼‰â†’ é™ä½ `max_connections` å‹åŠ›ã€‚
- `max_connections`ï¼šåŸºäºå†…å­˜é¢„ç®—ä¸å·¥ä½œè´Ÿè½½å¹¶å‘åº¦ï¼›è¿‡é«˜ä¼šæ‹‰ä½å‘½ä¸­ç‡ä¸ä¸Šä¸‹æ–‡åˆ‡æ¢ã€‚
- `work_mem`ï¼šæŒ‰å¹¶å‘æ’åº/å“ˆå¸Œæ“ä½œä¼°ç®—ï¼›å¸¸è§åŸºçº¿ 4â€“64MBï¼Œé¿å…å…¨å±€æ”¾å¤§å¯¼è‡´å†…å­˜çˆ†ã€‚
- ç¼“å†²ä¸ç¼“å­˜ï¼š
- `shared_buffers`ï¼šå¸¸è§ 25% ç‰©ç†å†…å­˜èµ·æ­¥ï¼ˆLinux+PageCache æƒ…å†µï¼‰ï¼Œè¶…å¤§æœªå¿…æ”¶ç›Šæ›´é«˜ã€‚
- `effective_cache_size`ï¼šä¼°è®¡ OS PageCache + shared_buffersï¼ˆå¦‚å†…å­˜ 64GB â†’ 48GBï¼‰ã€‚
- å¹¶è¡Œä¸JITï¼š
- `max_parallel_workers_per_gather`ï¼š2â€“4 èµ·æ­¥ï¼›`max_parallel_workers`â‰¥æ€»å¹¶è¡Œã€‚
- `jit`ï¼šOLTP å¤šä¸ºå…³é—­æˆ–é˜ˆå€¼è¾ƒé«˜ï¼›OLAP å¤§æŸ¥è¯¢æ”¶ç›Šæ˜æ˜¾ã€‚
- I/O ä¸å­˜å‚¨ï¼š
- `random_page_cost`ï¼šSSD é€šå¸¸ 1.1â€“1.5ï¼›`effective_io_concurrency`ï¼šNVMe å¯ 256ã€‚
- æ£€æŸ¥ç‚¹ï¼š`checkpoint_timeout` 10â€“30minã€`max_wal_size` 2â€“20GBã€`checkpoint_completion_target` 0.7â€“0.9ã€‚
- WAL ä¸æŒä¹…åŒ–ï¼š
- `wal_compression`=onï¼ˆå†™æ”¾å¤§ä¸‹é™ï¼ŒCPU â†‘ï¼‰ï¼›`synchronous_commit` æ ¹æ®ä¸€è‡´æ€§éœ€æ±‚è°ƒèŠ‚ï¼ˆå¼‚æ­¥æ‰¹é‡å†™å¯ offï¼‰ã€‚
- ç»´æŠ¤ä¸è‡ªæ¸…ç†ï¼š
- `autovacuum_vacuum_scale_factor` é™ä½ä»¥æŠ‘åˆ¶è†¨èƒ€ï¼ˆå¦‚ 0.1â†’0.02 é’ˆå¯¹å¤§è¡¨ï¼‰ï¼Œç»“åˆ `autovacuum_vacuum_threshold`ã€‚
- `maintenance_work_mem`ï¼šç´¢å¼•é‡å»º/å¹¶è¡Œç»´æŠ¤æ—¶æé«˜ï¼ˆ512MBâ€“4GBï¼‰ã€‚

### 7.1 è¿æ¥ä¸å¹¶å‘å‚æ•°

```sql
-- 1. max_connections
-- è®¡ç®—ï¼šè€ƒè™‘åº”ç”¨è¿æ¥æ•° + ç®¡ç†è¿æ¥ + å¤åˆ¶è¿æ¥
-- å»ºè®®ï¼š100-300ï¼ˆä½¿ç”¨è¿æ¥æ± æ—¶ï¼‰
-- å†…å­˜å½±å“ï¼šæ¯ä¸ªè¿æ¥çº¦æ¶ˆè€— 10MBï¼ˆwork_memç­‰ï¼‰

-- æŸ¥çœ‹å½“å‰è¿æ¥æ•°
SELECT COUNT(*) FROM pg_stat_activity;

-- æŸ¥çœ‹è¿æ¥æ•°ä½¿ç”¨ç‡
SELECT
    COUNT(*) as current_connections,
    current_setting('max_connections')::int as max_connections,
    ROUND(100.0 * COUNT(*) / current_setting('max_connections')::int, 2) as usage_percent
FROM pg_stat_activity;

-- é…ç½®å»ºè®®
ALTER SYSTEM SET max_connections = 200;
-- å¦‚æœä½¿ç”¨pgbouncerï¼Œå¯ä»¥é™ä½åˆ°100-150

-- 2. work_mem
-- è®¡ç®—ï¼šwork_mem * max_connections < æ€»å†…å­˜çš„25%
-- å»ºè®®ï¼š4-64MBï¼Œæ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è°ƒæ•´

-- æŸ¥çœ‹work_memä½¿ç”¨æƒ…å†µ
SELECT
    pid,
    usename,
    query,
    work_mem_used,
    work_mem_max
FROM pg_stat_activity
WHERE work_mem_used > 0
ORDER BY work_mem_used DESC;

-- é…ç½®å»ºè®®ï¼ˆæ ¹æ®å¹¶å‘æŸ¥è¯¢æ•°ï¼‰
-- 10ä¸ªå¹¶å‘ï¼šwork_mem = 64MB
-- 50ä¸ªå¹¶å‘ï¼šwork_mem = 16MB
-- 100ä¸ªå¹¶å‘ï¼šwork_mem = 8MB
ALTER SYSTEM SET work_mem = '16MB';

-- 3. superuser_reserved_connections
-- ä¸ºè¶…çº§ç”¨æˆ·ä¿ç•™çš„è¿æ¥æ•°
ALTER SYSTEM SET superuser_reserved_connections = 3;
```

### 7.2 ç¼“å†²ä¸ç¼“å­˜å‚æ•°

```sql
-- 1. shared_buffers
-- å»ºè®®ï¼šç³»ç»Ÿå†…å­˜çš„25%ï¼ˆLinuxï¼‰ï¼ŒWindowså¯ä»¥æ›´é«˜
-- 64GBå†…å­˜ï¼š16GB shared_buffers

-- æŸ¥çœ‹å½“å‰é…ç½®
SHOW shared_buffers;

-- æŸ¥çœ‹ç¼“å†²å‘½ä¸­ç‡
SELECT
    datname,
    ROUND(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) as hit_ratio
FROM pg_stat_database
WHERE datname = current_database();

-- é…ç½®å»ºè®®
ALTER SYSTEM SET shared_buffers = '16GB';  -- 64GBç³»ç»Ÿ

-- 2. effective_cache_size
-- å»ºè®®ï¼šç³»ç»Ÿå†…å­˜çš„50-75%
-- 64GBå†…å­˜ï¼š32-48GB

ALTER SYSTEM SET effective_cache_size = '32GB';

-- 3. éªŒè¯é…ç½®
SELECT
    name,
    setting,
    unit,
    source
FROM pg_settings
WHERE name IN ('shared_buffers', 'effective_cache_size', 'work_mem');
```

### 7.3 å¹¶è¡Œä¸JITå‚æ•°

```sql
-- 1. å¹¶è¡Œå‚æ•°
-- max_parallel_workers_per_gather: æ¯ä¸ªæŸ¥è¯¢çš„æœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°
-- max_parallel_workers: ç³»ç»Ÿæœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ€»æ•°
-- max_worker_processes: ç³»ç»Ÿæœ€å¤§å·¥ä½œè¿›ç¨‹æ•°

-- æŸ¥çœ‹å¹¶è¡Œä½¿ç”¨æƒ…å†µ
SELECT
    pid,
    usename,
    query,
    parallel_workers
FROM pg_stat_activity
WHERE parallel_workers > 0;

-- é…ç½®å»ºè®®
ALTER SYSTEM SET max_parallel_workers_per_gather = 4;
ALTER SYSTEM SET max_parallel_workers = 8;
ALTER SYSTEM SET max_worker_processes = 16;

-- 2. JITå‚æ•°
-- OLTP: å…³é—­æˆ–è®¾ç½®é«˜é˜ˆå€¼
-- OLAP: å¯ç”¨ï¼Œé˜ˆå€¼è¾ƒä½

-- æŸ¥çœ‹JITä½¿ç”¨æƒ…å†µ
SELECT
    jit_functions,
    jit_generation_time,
    jit_inlining_count,
    jit_optimization_count
FROM pg_stat_statements
WHERE jit_functions > 0
LIMIT 10;

-- OLTPé…ç½®ï¼ˆå…³é—­JITï¼‰
ALTER SYSTEM SET jit = off;

-- OLAPé…ç½®ï¼ˆå¯ç”¨JITï¼‰
ALTER SYSTEM SET jit = on;
ALTER SYSTEM SET jit_above_cost = 100000;
ALTER SYSTEM SET jit_optimize_above_cost = 500000;
ALTER SYSTEM SET jit_inline_above_cost = 500000;
```

### 7.4 I/Oä¸å­˜å‚¨å‚æ•°

```sql
-- 1. random_page_cost
-- SSD: 1.1-1.5
-- HDD: 4.0ï¼ˆé»˜è®¤ï¼‰
-- NVMe: 1.0-1.1

-- æŸ¥çœ‹I/Oç»Ÿè®¡
SELECT
    datname,
    blks_read,
    blks_hit,
    ROUND(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) as hit_ratio
FROM pg_stat_database
WHERE datname = current_database();

-- SSDé…ç½®
ALTER SYSTEM SET random_page_cost = 1.1;

-- 2. effective_io_concurrency
-- SSD: 200
-- NVMe: 256
-- HDD: 2

ALTER SYSTEM SET effective_io_concurrency = 200;

-- 3. æ£€æŸ¥ç‚¹å‚æ•°
-- checkpoint_timeout: æ£€æŸ¥ç‚¹é—´éš”ï¼ˆ10-30åˆ†é’Ÿï¼‰
-- max_wal_size: æœ€å¤§WALå¤§å°ï¼ˆ2-20GBï¼‰
-- checkpoint_completion_target: æ£€æŸ¥ç‚¹å®Œæˆç›®æ ‡ï¼ˆ0.7-0.9ï¼‰

-- æŸ¥çœ‹æ£€æŸ¥ç‚¹ç»Ÿè®¡
SELECT
    checkpoints_timed,
    checkpoints_req,
    checkpoint_write_time,
    checkpoint_sync_time
FROM pg_stat_bgwriter;

-- é…ç½®å»ºè®®
ALTER SYSTEM SET checkpoint_timeout = '15min';
ALTER SYSTEM SET max_wal_size = '4GB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
```

### 7.5 WALä¸æŒä¹…åŒ–å‚æ•°

```sql
-- 1. wal_compression
-- å¯ç”¨å‹ç¼©å¯ä»¥å‡å°‘WALå¤§å°ï¼Œä½†å¢åŠ CPUä½¿ç”¨
ALTER SYSTEM SET wal_compression = on;

-- 2. synchronous_commit
-- local: æœ¬åœ°æäº¤å³å¯ï¼ˆæœ€å¿«ï¼Œå¯èƒ½ä¸¢æ•°æ®ï¼‰
-- remote_write: ç­‰å¾…å†™å…¥ä»åº“OSç¼“å­˜ï¼ˆæ¨èï¼‰
-- remote_apply: ç­‰å¾…ä»åº“åº”ç”¨ï¼ˆæœ€ä¸¥æ ¼ï¼Œæœ€æ…¢ï¼‰
-- off: ç­‰åŒäºlocalï¼ˆå·²åºŸå¼ƒï¼‰

-- æŸ¥çœ‹å½“å‰é…ç½®
SHOW synchronous_commit;

-- é…ç½®å»ºè®®ï¼ˆæ ¹æ®RPOéœ€æ±‚ï¼‰
ALTER SYSTEM SET synchronous_commit = 'remote_write';

-- 3. wal_buffers
-- å»ºè®®ï¼š16MBï¼ˆPostgreSQL 9.1+è‡ªåŠ¨è°ƒæ•´ï¼‰
ALTER SYSTEM SET wal_buffers = '16MB';

-- 4. min_wal_size / max_wal_size
ALTER SYSTEM SET min_wal_size = '1GB';
ALTER SYSTEM SET max_wal_size = '4GB';
```

### 7.6 ç»´æŠ¤ä¸è‡ªæ¸…ç†å‚æ•°

```sql
-- 1. autovacuumå‚æ•°
-- autovacuum_vacuum_scale_factor: è§¦å‘VACUUMçš„æ­»å…ƒç»„æ¯”ä¾‹
-- autovacuum_analyze_scale_factor: è§¦å‘ANALYZEçš„å˜æ›´æ¯”ä¾‹
-- autovacuum_vacuum_threshold: è§¦å‘VACUUMçš„æœ€å°æ­»å…ƒç»„æ•°

-- æŸ¥çœ‹autovacuumæ´»åŠ¨
SELECT
    schemaname,
    tablename,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze,
    n_dead_tup,
    n_live_tup
FROM pg_stat_user_tables
WHERE n_dead_tup > 10000
ORDER BY n_dead_tup DESC
LIMIT 20;

-- å…¨å±€é…ç½®
ALTER SYSTEM SET autovacuum_vacuum_scale_factor = 0.1;
ALTER SYSTEM SET autovacuum_analyze_scale_factor = 0.05;
ALTER SYSTEM SET autovacuum_vacuum_threshold = 50;

-- è¡¨çº§é…ç½®ï¼ˆå¤§è¡¨ï¼‰
ALTER TABLE large_table SET (
    autovacuum_vacuum_scale_factor = 0.02,
    autovacuum_analyze_scale_factor = 0.01
);

-- 2. maintenance_work_mem
-- ç”¨äºVACUUMã€CREATE INDEXç­‰ç»´æŠ¤æ“ä½œ
-- å»ºè®®ï¼š512MB-4GB

ALTER SYSTEM SET maintenance_work_mem = '1GB';

-- 3. autovacuum_max_workers
-- åŒæ—¶è¿è¡Œçš„autovacuumå·¥ä½œè¿›ç¨‹æ•°
ALTER SYSTEM SET autovacuum_max_workers = 3;
```

## 8. æŸ¥è¯¢å±‚ä¼˜åŒ–ç­–ç•¥

- ä»£ä»·å¯¹é½ï¼šæ ¡å‡† `default_statistics_target`ï¼ˆ100â€“500ï¼‰ä¸æ‰©å±•ç»Ÿè®¡ï¼Œé™ä½é”™è¯¯é€‰æ‹©ç‡ã€‚
- è®¿é—®è·¯å¾„ï¼šè¦†ç›–ç´¢å¼•ã€è¡¨è¾¾å¼/éƒ¨åˆ†ç´¢å¼•ã€BitmapScan èšåˆå›è¡¨æˆæœ¬ã€‚
- è¿æ¥ç­–ç•¥ï¼šå°è¡¨é©±åŠ¨ã€åˆé€‚çš„è¿æ¥é¡ºåºã€é¿å…éšå¼ç±»å‹è½¬æ¢å¯¼è‡´ Seq Scanã€‚

### 8.1 ä»£ä»·å¯¹é½ä¼˜åŒ–

```sql
-- 1. è°ƒæ•´ç»Ÿè®¡ç›®æ ‡
-- default_statistics_target: é»˜è®¤100ï¼Œå¯ä»¥æé«˜åˆ°200-500

-- æŸ¥çœ‹å½“å‰ç»Ÿè®¡ç›®æ ‡
SHOW default_statistics_target;

-- å…¨å±€é…ç½®
ALTER SYSTEM SET default_statistics_target = 200;

-- åˆ—çº§é…ç½®ï¼ˆé‡è¦åˆ—ï¼‰
ALTER TABLE users ALTER COLUMN email SET STATISTICS 500;
ALTER TABLE orders ALTER COLUMN user_id SET STATISTICS 300;

-- æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE users;
ANALYZE orders;

-- 2. åˆ›å»ºæ‰©å±•ç»Ÿè®¡
-- ç›¸å…³æ€§ç»Ÿè®¡
CREATE STATISTICS users_email_created_stats (dependencies)
ON email, created_at FROM users;

-- å¤šåˆ—ç»Ÿè®¡
CREATE STATISTICS orders_user_date_stats (dependencies, ndistinct)
ON user_id, order_date FROM orders;

-- æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE users;
ANALYZE orders;

-- 3. éªŒè¯ç»Ÿè®¡ä¿¡æ¯è´¨é‡
SELECT
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation,
    most_common_vals,
    most_common_freqs
FROM pg_stats
WHERE schemaname = 'public'
AND tablename = 'users'
AND attname = 'email';
```

### 8.2 è®¿é—®è·¯å¾„ä¼˜åŒ–

```sql
-- 1. è¦†ç›–ç´¢å¼•ï¼ˆINCLUDEåˆ—ï¼‰
-- é¿å…å›è¡¨ï¼Œæå‡æŸ¥è¯¢æ€§èƒ½
CREATE INDEX idx_users_email_covering ON users (email) INCLUDE (name, created_at);

-- æŸ¥è¯¢éªŒè¯
EXPLAIN (ANALYZE, BUFFERS)
SELECT name, created_at FROM users WHERE email = 'user@example.com';
-- åº”è¯¥æ˜¾ç¤ºIndex Only Scan

-- 2. è¡¨è¾¾å¼ç´¢å¼•
-- æ”¯æŒå‡½æ•°æŸ¥è¯¢
CREATE INDEX idx_users_lower_email ON users (lower(email));

-- æŸ¥è¯¢å¿…é¡»ä½¿ç”¨ç›¸åŒçš„è¡¨è¾¾å¼
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM users WHERE lower(email) = 'user@example.com';
-- åº”è¯¥ä½¿ç”¨ç´¢å¼•

-- 3. éƒ¨åˆ†ç´¢å¼•
-- åªç´¢å¼•éƒ¨åˆ†æ•°æ®ï¼Œå‡å°‘ç´¢å¼•å¤§å°
CREATE INDEX idx_orders_active ON orders (user_id, order_date)
WHERE status = 'active';

-- æŸ¥è¯¢éªŒè¯
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE user_id = 123 AND status = 'active';
-- åº”è¯¥ä½¿ç”¨éƒ¨åˆ†ç´¢å¼•

-- 4. å¤åˆç´¢å¼•ä¼˜åŒ–
-- è€ƒè™‘åˆ—çš„é€‰æ‹©æ€§å’ŒæŸ¥è¯¢æ¨¡å¼
CREATE INDEX idx_orders_user_date_status ON orders (user_id, order_date DESC, status);

-- æŸ¥è¯¢éªŒè¯
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders
WHERE user_id = 123
AND order_date >= '2024-01-01'
AND status = 'active'
ORDER BY order_date DESC;
```

### 8.3 è¿æ¥ç­–ç•¥ä¼˜åŒ–

```sql
-- 1. å°è¡¨é©±åŠ¨å¤§è¡¨
-- ç¡®ä¿å°è¡¨åœ¨JOINçš„å³ä¾§ï¼ˆå¦‚æœå¯èƒ½ï¼‰

-- é”™è¯¯ç¤ºä¾‹ï¼šå¤§è¡¨é©±åŠ¨å°è¡¨
EXPLAIN (ANALYZE, BUFFERS)
SELECT u.name, o.total
FROM large_orders o
JOIN small_users u ON o.user_id = u.id;

-- ä¼˜åŒ–ï¼šè°ƒæ•´JOINé¡ºåºæˆ–ä½¿ç”¨å­æŸ¥è¯¢
EXPLAIN (ANALYZE, BUFFERS)
SELECT u.name, o.total
FROM small_users u
JOIN large_orders o ON u.id = o.user_id;

-- 2. é¿å…éšå¼ç±»å‹è½¬æ¢
-- ç¡®ä¿JOINé”®ç±»å‹ä¸€è‡´

-- é”™è¯¯ç¤ºä¾‹ï¼šç±»å‹ä¸åŒ¹é…
SELECT u.id, o.user_id
FROM users u
JOIN orders o ON u.id::text = o.user_id;  -- ç±»å‹è½¬æ¢å¯¼è‡´Seq Scan

-- æ­£ç¡®ç¤ºä¾‹ï¼šç±»å‹ä¸€è‡´
SELECT u.id, o.user_id
FROM users u
JOIN orders o ON u.id = o.user_id::int;  -- æˆ–ä¿®æ”¹è¡¨ç»“æ„ä½¿ç±»å‹ä¸€è‡´

-- 3. ä½¿ç”¨åˆé€‚çš„è¿æ¥ç®—æ³•
-- Hash Join: é€‚åˆå¤§è¡¨JOIN
-- Nested Loop: é€‚åˆå°è¡¨JOIN
-- Merge Join: é€‚åˆå·²æ’åºçš„æ•°æ®

-- å¼ºåˆ¶è¿æ¥ç®—æ³•ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
SET enable_hashjoin = on;
SET enable_nestloop = on;
SET enable_mergejoin = on;

-- 4. è¿æ¥é¡ºåºä¼˜åŒ–
-- ä½¿ç”¨JOIN_COLLAPSE_LIMITæ§åˆ¶è¿æ¥é¡ºåº
SET join_collapse_limit = 8;  -- é»˜è®¤8ï¼Œå¯ä»¥è°ƒæ•´
```

### 8.4 æŸ¥è¯¢é‡å†™ä¼˜åŒ–

```sql
-- 1. é¿å…SELECT *
-- åªé€‰æ‹©éœ€è¦çš„åˆ—
SELECT id, name, email FROM users WHERE id = 123;
-- è€Œä¸æ˜¯
SELECT * FROM users WHERE id = 123;

-- 2. ä½¿ç”¨LIMIT
-- é™åˆ¶è¿”å›è¡Œæ•°
SELECT * FROM orders WHERE user_id = 123 ORDER BY order_date DESC LIMIT 10;

-- 3. ä½¿ç”¨EXISTSä»£æ›¿COUNT
-- EXISTSåœ¨æ‰¾åˆ°ç¬¬ä¸€æ¡è®°å½•åç«‹å³è¿”å›
SELECT * FROM users u
WHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id);
-- è€Œä¸æ˜¯
SELECT * FROM users u
WHERE (SELECT COUNT(*) FROM orders o WHERE o.user_id = u.id) > 0;

-- 4. é¿å…åœ¨WHEREå­å¥ä¸­ä½¿ç”¨å‡½æ•°
-- é”™è¯¯ç¤ºä¾‹
SELECT * FROM users WHERE DATE(created_at) = '2024-01-01';

-- æ­£ç¡®ç¤ºä¾‹
SELECT * FROM users
WHERE created_at >= '2024-01-01' AND created_at < '2024-01-02';

-- 5. ä½¿ç”¨UNION ALLä»£æ›¿UNIONï¼ˆå¦‚æœä¸éœ€è¦å»é‡ï¼‰
SELECT id, name FROM users WHERE id < 100
UNION ALL
SELECT id, name FROM users WHERE id >= 100;
-- è€Œä¸æ˜¯
SELECT id, name FROM users WHERE id < 100
UNION
SELECT id, name FROM users WHERE id >= 100;
```

- åˆ†åŒºä¸è£å‰ªï¼šæ—¶é—´/èŒƒå›´åˆ†åŒºï¼Œç¡®ä¿è°“è¯å¯è£å‰ªï¼›é¿å…è¿‡å¤šåˆ†åŒºå¯¼è‡´è®¡åˆ’æ—¶é—´æš´æ¶¨ã€‚
- å¹¶è¡Œï¼šç¡®ä¿è¿ç®—ç¬¦ä¸å‡½æ•°å¯å¹¶è¡Œï¼ˆimmutable/parallel safeï¼‰ã€‚

## 9. å­˜å‚¨ä¸è¡¨è®¾è®¡

- `fillfactor`ï¼šå†™å¤šè¡¨é™ä½ï¼ˆ80â€“90ï¼‰å‡å°‘é¡µåˆ†è£‚ï¼›è¯»å¤šä¿å®ˆæé«˜ç©ºé—´åˆ©ç”¨ã€‚
- TOAST/å‹ç¼©ï¼š9.5+ è‡ªé€‚åº”ï¼›PG15+ LZ4/ZSTDï¼ˆéœ€ç¼–è¯‘/è®¾ç½®ï¼‰å¯é™I/Oã€‚
- å†·çƒ­åˆ†å±‚ï¼šçƒ­è¡¨çƒ­ç´¢å¼•ç½®é«˜é€Ÿç›˜ï¼Œå†å²åˆ†åŒºè¿ç§»å†·ç›˜ï¼›å½’æ¡£è¡¨ä½¿ç”¨å‹ç¼©ä¸åªè¯»ç­–ç•¥ã€‚

## 10. å…¸å‹å·¥ä½œè´Ÿè½½åŸºçº¿

- OLTPï¼š
  - pgbouncer(transaction)ã€è¾ƒå° `work_mem`ï¼ˆ8â€“32MBï¼‰ã€`shared_buffers` 20â€“30%ã€JIT å…³é—­ã€`synchronous_commit=on`ï¼ˆé‡è¦äº¤æ˜“ï¼‰ã€‚
  - å¼ºåŒ– Autovacuum ä¸çƒ­ç‚¹ç´¢å¼•ã€ä½å»¶è¿Ÿæ£€æŸ¥ç‚¹é…ç½®ã€‚
- OLAPï¼š
  - å¹¶è¡Œå¼€å¯ï¼ˆ2â€“4ï¼‰ã€`work_mem` 64â€“512MBã€JIT æ‰“å¼€ï¼ˆé˜ˆå€¼ â‰¥200msï¼‰ã€`random_page_cost` ä½ã€`effective_io_concurrency` é«˜ã€‚
  - å®½è¡¨ã€åˆ—å¼å¤–éƒ¨å¼•æ“/FDWã€åˆ†åŒºè£å‰ªä¸ç‰©åŒ–ä¸­é—´ç»“æœã€‚
- æ··åˆï¼šåˆ†ç¦»è¯»å†™æ± ã€OLAP åœ¨åªè¯»å‰¯æœ¬è·‘ã€ä¸»åº“ä¿å®ˆå‚æ•°ã€‚

## 11. éªŒè¯ä¸å›å½’

- åŸºå‡†æ•°æ®ï¼šTPS/QPSã€P95/P99ã€é˜Ÿåˆ—é•¿åº¦ã€å‘½ä¸­ç‡ã€WALé€Ÿç‡ã€æ£€æŸ¥ç‚¹é¢‘ç‡ã€Vacuumæ»åã€é”ç­‰å¾…ã€‚
- å¯¹æ¯”æ–¹æ³•ï¼šè°ƒä¼˜å‰å 30â€“60 åˆ†é’Ÿç¨³å®šçª—å£ï¼›ä¸šåŠ¡ä½å³°ç°åº¦ 5â€“10% æµé‡ã€‚
- å›æ»šè§¦å‘ï¼šP95 æ¶åŒ–>10%ã€é”™è¯¯ç‡å‡é«˜ã€é”å†²çªä¸Šå‡ã€ç³»ç»Ÿè´Ÿè½½å¼‚å¸¸ã€‚

## 12. PostgreSQL 18 æ–°ç‰¹æ€§åº”ç”¨

### å¼‚æ­¥ I/O ä¼˜åŒ–

PostgreSQL 18 çš„å¼‚æ­¥ I/O å­ç³»ç»Ÿå¯ä»¥æ˜¾è‘—æå‡I/Oå¯†é›†å‹æ“ä½œçš„æ€§èƒ½ï¼š

```sql
-- PostgreSQL 18: å¼‚æ­¥ I/O è‡ªåŠ¨å¯ç”¨
-- æ— éœ€é¢å¤–é…ç½®ï¼Œç³»ç»Ÿè‡ªåŠ¨ä¼˜åŒ–I/Oæ“ä½œ
-- ç‰¹åˆ«é€‚ç”¨äºï¼š
-- - å¤§è§„æ¨¡å‘é‡æ£€ç´¢
-- - æ‰¹é‡æ•°æ®å¯¼å…¥
-- - å¹¶è¡ŒæŸ¥è¯¢
```

**æ€§èƒ½æå‡**:

- å‘é‡ç´¢å¼•æ„å»ºé€Ÿåº¦æå‡ 40%+
- å¤§è§„æ¨¡æŸ¥è¯¢I/Oæ€§èƒ½æå‡ 2-3å€
- æ›´å¥½çš„å¹¶å‘å¤„ç†èƒ½åŠ›

### è™šæ‹Ÿç”Ÿæˆåˆ—ä¼˜åŒ–

PostgreSQL 18 çš„è™šæ‹Ÿç”Ÿæˆåˆ—å¯ä»¥ä¼˜åŒ–è®¡ç®—å¯†é›†å‹æŸ¥è¯¢ï¼š

```sql
-- PostgreSQL 18: ä½¿ç”¨è™šæ‹Ÿç”Ÿæˆåˆ—ä¼˜åŒ–æŸ¥è¯¢
CREATE TABLE products (
    id UUID PRIMARY KEY,
    price DECIMAL(10,2),
    discount_rate FLOAT,
    -- è™šæ‹Ÿç”Ÿæˆåˆ—ï¼šè‡ªåŠ¨è®¡ç®—æœ€ç»ˆä»·æ ¼
    final_price DECIMAL(10,2) GENERATED ALWAYS AS (
        price * (1 - discount_rate)
    ) STORED
);

-- æŸ¥è¯¢æ—¶ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€é‡å¤è®¡ç®—
SELECT id, final_price FROM products WHERE final_price > 100;
```

**ä¼˜åŠ¿**:

- æŸ¥è¯¢æ€§èƒ½æå‡ 15-25%
- æ”¯æŒç´¢å¼•ä¼˜åŒ–
- å‡å°‘é‡å¤è®¡ç®—

---

## 13. ç´¢å¼•ä¼˜åŒ–æ·±åº¦åˆ†æ

### 13.1 å¤åˆç´¢å¼•è®¾è®¡åŸåˆ™

**å¤åˆç´¢å¼•ï¼ˆComposite Indexï¼‰**æ˜¯åœ¨å¤šä¸ªåˆ—ä¸Šåˆ›å»ºçš„ç´¢å¼•ï¼Œå¯ä»¥æ˜¾è‘—æå‡å¤šåˆ—æŸ¥è¯¢çš„æ€§èƒ½ã€‚æ­£ç¡®çš„å¤åˆç´¢å¼•è®¾è®¡æ˜¯PostgreSQLæ€§èƒ½ä¼˜åŒ–çš„å…³é”®ã€‚

#### 13.1.1 å¤åˆç´¢å¼•åŸºç¡€

**å¤åˆç´¢å¼•ç»“æ„**ï¼š

å¤åˆç´¢å¼•æŒ‰ç…§åˆ—çš„é¡ºåºç»„ç»‡æ•°æ®ï¼Œç±»ä¼¼äºç”µè¯ç°¿çš„æ’åºæ–¹å¼ï¼ˆå…ˆæŒ‰å§“æ°ï¼Œå†æŒ‰åå­—ï¼‰ã€‚

```sql
-- å¤åˆç´¢å¼•ç¤ºä¾‹
CREATE INDEX idx_users_name_email ON users (last_name, first_name, email);

-- ç´¢å¼•ç»“æ„ï¼ˆæ¦‚å¿µæ€§ï¼‰ï¼š
-- (Smith, John, john@example.com) -> row_id_1
-- (Smith, Jane, jane@example.com) -> row_id_2
-- (Doe, John, john.doe@example.com) -> row_id_3
```

**å¤åˆç´¢å¼•çš„ä¼˜åŠ¿**ï¼š

1. **å¤šåˆ—æŸ¥è¯¢ä¼˜åŒ–**ï¼šå¯ä»¥åŒæ—¶ä¼˜åŒ–å¤šåˆ—æ¡ä»¶æŸ¥è¯¢
2. **è¦†ç›–ç´¢å¼•**ï¼šå¦‚æœç´¢å¼•åŒ…å«æ‰€æœ‰æŸ¥è¯¢åˆ—ï¼Œå¯ä»¥é¿å…å›è¡¨
3. **æ’åºä¼˜åŒ–**ï¼šå¯ä»¥ä¼˜åŒ–ORDER BYå¤šåˆ—æ’åº

**å¤åˆç´¢å¼•çš„é™åˆ¶**ï¼š

1. **åˆ—é¡ºåºæ•æ„Ÿ**ï¼šåˆ—çš„é¡ºåºå¾ˆé‡è¦ï¼Œå½±å“ç´¢å¼•ä½¿ç”¨
2. **å·¦å‰ç¼€åŸåˆ™**ï¼šåªèƒ½ä½¿ç”¨ç´¢å¼•çš„æœ€å·¦å‰ç¼€
3. **ç»´æŠ¤æˆæœ¬**ï¼šç´¢å¼•åˆ—è¶Šå¤šï¼Œç»´æŠ¤æˆæœ¬è¶Šé«˜

#### 13.1.2 è®¾è®¡åŸåˆ™

**åŸåˆ™1ï¼šæœ€å·¦å‰ç¼€åŒ¹é…**:

PostgreSQLåªèƒ½ä½¿ç”¨å¤åˆç´¢å¼•çš„æœ€å·¦å‰ç¼€ï¼Œå› æ­¤åˆ—çš„é¡ºåºè‡³å…³é‡è¦ã€‚

```sql
-- ç´¢å¼•ï¼šidx_users_name_email (last_name, first_name, email)

-- âœ… å¯ä»¥ä½¿ç”¨ç´¢å¼•çš„æŸ¥è¯¢
SELECT * FROM users WHERE last_name = 'Smith';
SELECT * FROM users WHERE last_name = 'Smith' AND first_name = 'John';
SELECT * FROM users WHERE last_name = 'Smith' AND first_name = 'John' AND email = 'john@example.com';

-- âŒ ä¸èƒ½ä½¿ç”¨ç´¢å¼•çš„æŸ¥è¯¢ï¼ˆè·³è¿‡äº†last_nameï¼‰
SELECT * FROM users WHERE first_name = 'John';
SELECT * FROM users WHERE email = 'john@example.com';
SELECT * FROM users WHERE first_name = 'John' AND email = 'john@example.com';
```

**åŸåˆ™2ï¼šé«˜é€‰æ‹©æ€§åˆ—åœ¨å‰**:

å°†é€‰æ‹©æ€§é«˜çš„åˆ—ï¼ˆå”¯ä¸€å€¼å¤šçš„åˆ—ï¼‰æ”¾åœ¨å‰é¢ï¼Œå¯ä»¥æé«˜ç´¢å¼•æ•ˆç‡ã€‚

```sql
-- é€‰æ‹©æ€§åˆ†æ
SELECT
    COUNT(DISTINCT last_name) AS distinct_last_names,
    COUNT(DISTINCT first_name) AS distinct_first_names,
    COUNT(DISTINCT email) AS distinct_emails,
    COUNT(*) AS total_rows
FROM users;

-- ç»“æœç¤ºä¾‹ï¼š
-- distinct_last_names: 1000
-- distinct_first_names: 5000
-- distinct_emails: 10000
-- total_rows: 10000

-- é€‰æ‹©æ€§ï¼šemail > first_name > last_name
-- å› æ­¤ç´¢å¼•é¡ºåºåº”è¯¥æ˜¯ï¼š(email, first_name, last_name)
CREATE INDEX idx_users_email_name ON users (email, first_name, last_name);
```

**åŸåˆ™3ï¼šç­‰å€¼æŸ¥è¯¢åˆ—åœ¨å‰ï¼ŒèŒƒå›´æŸ¥è¯¢åˆ—åœ¨å**:

ç­‰å€¼æŸ¥è¯¢ï¼ˆ=ï¼‰çš„åˆ—åº”è¯¥æ”¾åœ¨èŒƒå›´æŸ¥è¯¢ï¼ˆ>, <, BETWEENï¼‰çš„åˆ—ä¹‹å‰ã€‚

```sql
-- æŸ¥è¯¢æ¨¡å¼ï¼šWHERE status = 'active' AND created_at > '2024-01-01'
-- statusæ˜¯ç­‰å€¼æŸ¥è¯¢ï¼Œcreated_atæ˜¯èŒƒå›´æŸ¥è¯¢
-- ç´¢å¼•é¡ºåºï¼šstatusåœ¨å‰ï¼Œcreated_atåœ¨å

CREATE INDEX idx_orders_status_date ON orders (status, created_at);

-- âœ… å¯ä»¥ä½¿ç”¨ç´¢å¼•
SELECT * FROM orders
WHERE status = 'active' AND created_at > '2024-01-01';

-- âŒ å¦‚æœé¡ºåºç›¸åï¼Œç´¢å¼•æ•ˆç‡é™ä½
CREATE INDEX idx_orders_date_status ON orders (created_at, status);
-- è¿™ä¸ªç´¢å¼•å¯¹ä¸Šè¿°æŸ¥è¯¢æ•ˆç‡è¾ƒä½
```

**åŸåˆ™4ï¼šè¦†ç›–ç´¢å¼•è®¾è®¡**:

å¦‚æœæŸ¥è¯¢åªéœ€è¦ç´¢å¼•åˆ—ï¼Œå¯ä»¥è®¾è®¡è¦†ç›–ç´¢å¼•é¿å…å›è¡¨ã€‚

```sql
-- æŸ¥è¯¢ï¼šSELECT user_id, status, created_at FROM orders WHERE status = 'active'
-- è®¾è®¡è¦†ç›–ç´¢å¼•
CREATE INDEX idx_orders_status_covering ON orders (status)
INCLUDE (user_id, created_at);

-- æˆ–è€…ä½¿ç”¨åŒ…å«æ‰€æœ‰åˆ—çš„å¤åˆç´¢å¼•
CREATE INDEX idx_orders_status_covering2 ON orders (status, user_id, created_at);

-- æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ï¼ˆä½¿ç”¨è¦†ç›–ç´¢å¼•ï¼Œé¿å…å›è¡¨ï¼‰
EXPLAIN (ANALYZE, BUFFERS)
SELECT user_id, status, created_at
FROM orders
WHERE status = 'active';
-- è¾“å‡ºï¼šIndex Only Scan using idx_orders_status_covering
```

### 13.2 åˆ—é¡ºåºé€‰æ‹©ç­–ç•¥

#### 13.2.1 é€‰æ‹©æ€§è¯„ä¼°

**é€‰æ‹©æ€§ï¼ˆSelectivityï¼‰**æ˜¯ç´¢å¼•åˆ—çš„å”¯ä¸€å€¼æ¯”ä¾‹ï¼Œé€‰æ‹©æ€§è¶Šé«˜ï¼Œç´¢å¼•æ•ˆç‡è¶Šé«˜ã€‚

**é€‰æ‹©æ€§è®¡ç®—å…¬å¼**ï¼š

```sql
-- é€‰æ‹©æ€§ = DISTINCTå€¼æ•°é‡ / æ€»è¡Œæ•°
-- é€‰æ‹©æ€§èŒƒå›´ï¼š0åˆ°1ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½

-- è®¡ç®—å„åˆ—çš„é€‰æ‹©æ€§
SELECT
    'last_name' AS column_name,
    COUNT(DISTINCT last_name)::DECIMAL / COUNT(*) AS selectivity
FROM users
UNION ALL
SELECT
    'first_name' AS column_name,
    COUNT(DISTINCT first_name)::DECIMAL / COUNT(*) AS selectivity
FROM users
UNION ALL
SELECT
    'email' AS column_name,
    COUNT(DISTINCT email)::DECIMAL / COUNT(*) AS selectivity
FROM users;

-- ç»“æœç¤ºä¾‹ï¼š
-- column_name | selectivity
-- ------------+------------
-- last_name   | 0.1000  (1000/10000)
-- first_name  | 0.5000  (5000/10000)
-- email       | 0.9999  (9999/10000)

-- é€‰æ‹©æ€§æ’åºï¼šemail > first_name > last_name
-- ç´¢å¼•é¡ºåºå»ºè®®ï¼š(email, first_name, last_name)
```

**å®é™…åº”ç”¨**ï¼š

```sql
-- åœºæ™¯ï¼šç”¨æˆ·è¡¨æŸ¥è¯¢
-- æŸ¥è¯¢æ¨¡å¼1ï¼šWHERE email = ? (æœ€å¸¸è§)
-- æŸ¥è¯¢æ¨¡å¼2ï¼šWHERE email = ? AND first_name = ?
-- æŸ¥è¯¢æ¨¡å¼3ï¼šWHERE email = ? AND first_name = ? AND last_name = ?

-- é€‰æ‹©æ€§åˆ†æ
SELECT
    COUNT(DISTINCT email) AS email_distinct,
    COUNT(DISTINCT first_name) AS first_name_distinct,
    COUNT(DISTINCT last_name) AS last_name_distinct,
    COUNT(*) AS total
FROM users;

-- æ ¹æ®é€‰æ‹©æ€§å’ŒæŸ¥è¯¢æ¨¡å¼ï¼Œè®¾è®¡ç´¢å¼•
CREATE INDEX idx_users_email_name ON users (email, first_name, last_name);
```

#### 13.2.2 æŸ¥è¯¢é¢‘ç‡åˆ†æ

**åˆ†ææŸ¥è¯¢æ¨¡å¼**ï¼š

ä½¿ç”¨`pg_stat_statements`åˆ†æå®é™…æŸ¥è¯¢æ¨¡å¼ï¼Œç¡®å®šç´¢å¼•åˆ—é¡ºåºã€‚

```sql
-- å¯ç”¨pg_stat_statements
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- åˆ†ææŸ¥è¯¢æ¨¡å¼
SELECT
    query,
    calls,
    mean_exec_time,
    (SELECT regexp_matches(query, 'WHERE\s+(\w+)\s*='))[1] AS first_condition,
    (SELECT regexp_matches(query, 'AND\s+(\w+)\s*='))[1] AS second_condition
FROM pg_stat_statements
WHERE query LIKE '%users%'
ORDER BY calls DESC
LIMIT 20;

-- æ ¹æ®æŸ¥è¯¢é¢‘ç‡å’Œæ¡ä»¶é¡ºåºï¼Œè®¾è®¡ç´¢å¼•
-- å¦‚æœå¤§å¤šæ•°æŸ¥è¯¢æ˜¯ WHERE email = ? AND first_name = ?
-- ç´¢å¼•åº”è¯¥æ˜¯ï¼š(email, first_name)
```

#### 13.2.3 å®é™…æ¡ˆä¾‹

**æ¡ˆä¾‹1ï¼šè®¢å•è¡¨ç´¢å¼•è®¾è®¡**ï¼š

```sql
-- è®¢å•è¡¨ç»“æ„
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER,
    status VARCHAR(20),
    created_at TIMESTAMP,
    total_amount DECIMAL(10,2)
);

-- æŸ¥è¯¢æ¨¡å¼åˆ†æ
-- 1. WHERE user_id = ? AND status = ? (80%çš„æŸ¥è¯¢)
-- 2. WHERE status = ? AND created_at > ? (15%çš„æŸ¥è¯¢)
-- 3. WHERE user_id = ? (5%çš„æŸ¥è¯¢)

-- é€‰æ‹©æ€§åˆ†æ
SELECT
    COUNT(DISTINCT user_id)::DECIMAL / COUNT(*) AS user_id_selectivity,
    COUNT(DISTINCT status)::DECIMAL / COUNT(*) AS status_selectivity,
    COUNT(*) AS total
FROM orders;

-- ç»“æœï¼šuser_idé€‰æ‹©æ€§ > statusé€‰æ‹©æ€§
-- ä½†æŸ¥è¯¢æ¨¡å¼1æœ€é¢‘ç¹ï¼Œä¸”user_idåœ¨å‰

-- è®¾è®¡ç´¢å¼•
CREATE INDEX idx_orders_user_status ON orders (user_id, status);
CREATE INDEX idx_orders_status_date ON orders (status, created_at);

-- éªŒè¯ç´¢å¼•ä½¿ç”¨
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders
WHERE user_id = 123 AND status = 'active';
-- åº”è¯¥ä½¿ç”¨ idx_orders_user_status
```

**æ¡ˆä¾‹2ï¼šå¤šæ¡ä»¶æŸ¥è¯¢ä¼˜åŒ–**ï¼š

```sql
-- äº§å“è¡¨
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    category_id INTEGER,
    brand_id INTEGER,
    price DECIMAL(10,2),
    stock INTEGER,
    created_at TIMESTAMP
);

-- æŸ¥è¯¢æ¨¡å¼ï¼š
-- WHERE category_id = ? AND brand_id = ? AND price BETWEEN ? AND ?

-- é€‰æ‹©æ€§åˆ†æ
SELECT
    COUNT(DISTINCT category_id) AS cat_distinct,
    COUNT(DISTINCT brand_id) AS brand_distinct,
    COUNT(*) AS total
FROM products;
-- category_id: 100ä¸ªä¸åŒå€¼
-- brand_id: 50ä¸ªä¸åŒå€¼
-- é€‰æ‹©æ€§ï¼šcategory_id > brand_id

-- è®¾è®¡ç´¢å¼•ï¼ˆç­‰å€¼æŸ¥è¯¢åœ¨å‰ï¼ŒèŒƒå›´æŸ¥è¯¢åœ¨åï¼‰
CREATE INDEX idx_products_cat_brand_price ON products (category_id, brand_id, price);

-- éªŒè¯
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM products
WHERE category_id = 1
  AND brand_id = 10
  AND price BETWEEN 100 AND 500;
```

### 13.3 é€‰æ‹©æ€§è¯„ä¼°æ–¹æ³•

#### 13.3.1 ç»Ÿè®¡ä¿¡æ¯æŸ¥è¯¢

**ä½¿ç”¨ç³»ç»Ÿè¡¨æŸ¥è¯¢é€‰æ‹©æ€§**ï¼š

```sql
-- æŸ¥è¯¢åˆ—çš„ç»Ÿè®¡ä¿¡æ¯
SELECT
    schemaname,
    tablename,
    attname AS column_name,
    n_distinct AS distinct_values,
    correlation,
    most_common_vals,
    most_common_freqs
FROM pg_stats
WHERE schemaname = 'public'
  AND tablename = 'users'
  AND attname IN ('last_name', 'first_name', 'email');

-- n_distinct: ä¸åŒå€¼çš„æ•°é‡ï¼ˆè´Ÿæ•°è¡¨ç¤ºæ¯”ä¾‹ï¼‰
-- correlation: åˆ—å€¼ä¸ç‰©ç†å­˜å‚¨é¡ºåºçš„ç›¸å…³æ€§ï¼ˆ-1åˆ°1ï¼‰
-- most_common_vals: æœ€å¸¸è§çš„å€¼
-- most_common_freqs: æœ€å¸¸è§å€¼çš„é¢‘ç‡
```

**è®¡ç®—å®é™…é€‰æ‹©æ€§**ï¼š

```sql
-- åˆ›å»ºé€‰æ‹©æ€§åˆ†æå‡½æ•°
-- åˆ†æé€‰æ‹©æ€§å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION analyze_selectivity(
    p_table_name TEXT,
    p_column_name TEXT
)
RETURNS TABLE (
    distinct_count BIGINT,
    total_count BIGINT,
    selectivity DECIMAL,
    recommendation TEXT
)
LANGUAGE plpgsql
AS $$
DECLARE
    v_distinct_val BIGINT;
    v_total_val BIGINT;
    v_sel DECIMAL;
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_table_name IS NULL OR TRIM(p_table_name) = '' THEN
        RAISE EXCEPTION 'è¡¨åä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_column_name IS NULL OR TRIM(p_column_name) = '' THEN
        RAISE EXCEPTION 'åˆ—åä¸èƒ½ä¸ºç©º';
    END IF;

    -- æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.tables
        WHERE table_schema = 'public' AND table_name = p_table_name
    ) THEN
        RAISE EXCEPTION 'è¡¨ä¸å­˜åœ¨: %', p_table_name;
    END IF;

    -- æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns
        WHERE table_schema = 'public'
          AND table_name = p_table_name
          AND column_name = p_column_name
    ) THEN
        RAISE EXCEPTION 'åˆ—ä¸å­˜åœ¨: %.%', p_table_name, p_column_name;
    END IF;

    -- æ‰§è¡Œé€‰æ‹©æ€§åˆ†æ
    BEGIN
        EXECUTE format(
            'SELECT COUNT(DISTINCT %I), COUNT(*) FROM %I',
            p_column_name, p_table_name
        )
        INTO v_distinct_val, v_total_val;

        IF v_total_val = 0 THEN
            RAISE WARNING 'è¡¨ä¸ºç©º: %', p_table_name;
            v_sel := 0;
        ELSE
            v_sel := v_distinct_val::DECIMAL / NULLIF(v_total_val, 0);
        END IF;
    EXCEPTION
        WHEN division_by_zero THEN
            v_sel := 0;
        WHEN numeric_value_out_of_range THEN
            RAISE EXCEPTION 'é€‰æ‹©æ€§è®¡ç®—æ•°å€¼æº¢å‡º';
        WHEN OTHERS THEN
            RAISE EXCEPTION 'åˆ†æé€‰æ‹©æ€§å¤±è´¥: %', SQLERRM;
    END;

    RETURN QUERY SELECT
        COALESCE(v_distinct_val, 0),
        COALESCE(v_total_val, 0),
        COALESCE(v_sel, 0),
        CASE
            WHEN v_sel > 0.9 THEN 'Excellent - High selectivity'::TEXT
            WHEN v_sel > 0.5 THEN 'Good - Medium-high selectivity'::TEXT
            WHEN v_sel > 0.1 THEN 'Fair - Medium selectivity'::TEXT
            ELSE 'Poor - Low selectivity, consider other columns first'::TEXT
        END;
EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'analyze_selectivityæ‰§è¡Œå¤±è´¥: %', SQLERRM;
END;
$$;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM analyze_selectivity('users', 'email');
SELECT * FROM analyze_selectivity('users', 'last_name');
```

#### 13.3.2 ç›´æ–¹å›¾åˆ†æ

**æŸ¥çœ‹ç›´æ–¹å›¾è¾¹ç•Œ**ï¼š

```sql
-- æŸ¥çœ‹åˆ—çš„ç›´æ–¹å›¾è¾¹ç•Œï¼ˆç”¨äºèŒƒå›´æŸ¥è¯¢ä¼˜åŒ–ï¼‰
SELECT
    schemaname,
    tablename,
    attname,
    histogram_bounds
FROM pg_stats
WHERE schemaname = 'public'
  AND tablename = 'orders'
  AND attname = 'created_at';

-- histogram_bounds: ç›´æ–¹å›¾çš„è¾¹ç•Œå€¼æ•°ç»„
-- ç”¨äºä¼°ç®—èŒƒå›´æŸ¥è¯¢çš„é€‰æ‹©æ€§
```

**é€‰æ‹©æ€§ä¼°ç®—**ï¼š

```sql
-- ä¼°ç®—èŒƒå›´æŸ¥è¯¢çš„é€‰æ‹©æ€§
-- ä¼°ç®—èŒƒå›´é€‰æ‹©æ€§å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION estimate_range_selectivity(
    p_table_name TEXT,
    p_column_name TEXT,
    p_min_val ANYELEMENT,
    p_max_val ANYELEMENT
)
RETURNS DECIMAL
LANGUAGE plpgsql
AS $$
DECLARE
    v_hist_bounds ANYARRAY;
    v_total_buckets INTEGER;
    v_matching_buckets INTEGER := 0;
    v_i INTEGER;
    v_bucket_min ANYELEMENT;
    v_bucket_max ANYELEMENT;
    v_result DECIMAL;
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_table_name IS NULL OR TRIM(p_table_name) = '' THEN
        RAISE EXCEPTION 'è¡¨åä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_column_name IS NULL OR TRIM(p_column_name) = '' THEN
        RAISE EXCEPTION 'åˆ—åä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_min_val IS NULL OR p_max_val IS NULL THEN
        RAISE EXCEPTION 'æœ€å°å€¼æˆ–æœ€å¤§å€¼ä¸èƒ½ä¸ºç©º';
    END IF;

    IF p_min_val > p_max_val THEN
        RAISE EXCEPTION 'æœ€å°å€¼ä¸èƒ½å¤§äºæœ€å¤§å€¼: % > %', p_min_val, p_max_val;
    END IF;

    -- è·å–ç›´æ–¹å›¾è¾¹ç•Œ
    BEGIN
        SELECT histogram_bounds INTO v_hist_bounds
        FROM pg_stats
        WHERE schemaname = 'public'
          AND tablename = p_table_name
          AND attname = p_column_name;

        IF v_hist_bounds IS NULL OR array_length(v_hist_bounds, 1) IS NULL THEN
            RAISE NOTICE 'ç›´æ–¹å›¾æ•°æ®ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤ä¼°ç®—: %', p_table_name || '.' || p_column_name;
            RETURN 0.1;  -- é»˜è®¤ä¼°ç®—
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'è·å–ç›´æ–¹å›¾å¤±è´¥: %', SQLERRM;
            RETURN 0.1;
    END;

    -- è®¡ç®—æ¡¶æ•°
    v_total_buckets := array_length(v_hist_bounds, 1) - 1;

    IF v_total_buckets IS NULL OR v_total_buckets <= 0 THEN
        RAISE WARNING 'ç›´æ–¹å›¾æ¡¶æ•°æ— æ•ˆ: %', v_total_buckets;
        RETURN 0.1;
    END IF;

    -- è®¡ç®—åŒ¹é…çš„æ¡¶æ•°
    BEGIN
        FOR v_i IN 1..v_total_buckets LOOP
            BEGIN
                v_bucket_min := v_hist_bounds[v_i];
                v_bucket_max := v_hist_bounds[v_i + 1];

                -- æ£€æŸ¥æ¡¶æ˜¯å¦ä¸æŸ¥è¯¢èŒƒå›´é‡å 
                IF v_bucket_max IS NOT NULL AND v_bucket_min IS NOT NULL THEN
                    IF v_bucket_max >= p_min_val AND v_bucket_min <= p_max_val THEN
                        v_matching_buckets := v_matching_buckets + 1;
                    END IF;
                END IF;
            EXCEPTION
                WHEN OTHERS THEN
                    RAISE WARNING 'å¤„ç†æ¡¶ % æ—¶å‡ºé”™: %', v_i, SQLERRM;
            END;
        END LOOP;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'è®¡ç®—åŒ¹é…æ¡¶æ•°å¤±è´¥: %', SQLERRM;
            RETURN 0.1;
    END;

    -- è¿”å›é€‰æ‹©æ€§ä¼°ç®—
    BEGIN
        v_result := v_matching_buckets::DECIMAL / NULLIF(v_total_buckets, 0);

        IF v_result IS NULL THEN
            RETURN 0.1;
        END IF;

        -- ç¡®ä¿ç»“æœåœ¨0-1ä¹‹é—´
        IF v_result < 0 THEN
            v_result := 0;
        ELSIF v_result > 1 THEN
            v_result := 1;
        END IF;

        RETURN v_result;
    EXCEPTION
        WHEN division_by_zero THEN
            RETURN 0.1;
        WHEN OTHERS THEN
            RAISE WARNING 'è®¡ç®—é€‰æ‹©æ€§å¤±è´¥: %', SQLERRM;
            RETURN 0.1;
    END;
EXCEPTION
    WHEN OTHERS THEN
        RAISE WARNING 'estimate_range_selectivityæ‰§è¡Œå¤±è´¥: %', SQLERRM;
        RETURN 0.1;
END;
$$;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT estimate_range_selectivity('orders', 'created_at',
                                  '2024-01-01'::TIMESTAMP,
                                  '2024-12-31'::TIMESTAMP);
```

### 13.4 ç´¢å¼•ç»´æŠ¤æœ€ä½³å®è·µ

#### 13.4.1 ç´¢å¼•é‡å»ºç­–ç•¥

**ä½•æ—¶é‡å»ºç´¢å¼•**ï¼š

1. **ç´¢å¼•è†¨èƒ€**ï¼šç´¢å¼•å ç”¨ç©ºé—´è¿‡å¤§
2. **æ€§èƒ½ä¸‹é™**ï¼šæŸ¥è¯¢æ€§èƒ½æ˜æ˜¾ä¸‹é™
3. **å¤§é‡æ›´æ–°**ï¼šè¡¨è¿›è¡Œäº†å¤§é‡UPDATE/DELETEæ“ä½œ

**æ£€æŸ¥ç´¢å¼•è†¨èƒ€**ï¼š

```sql
-- æ£€æŸ¥ç´¢å¼•è†¨èƒ€
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    idx_scan AS index_scans,
    idx_tup_read AS tuples_read,
    idx_tup_fetch AS tuples_fetched,
    -- ä¼°ç®—è†¨èƒ€ç‡ï¼ˆç®€åŒ–ï¼‰
    CASE
        WHEN idx_scan = 0 THEN 'UNUSED'
        WHEN idx_tup_fetch::DECIMAL / NULLIF(idx_tup_read, 0) < 0.1 THEN 'BLOATED'
        ELSE 'OK'
    END AS status
FROM pg_stat_user_indexes
ORDER BY pg_relation_size(indexrelid) DESC;

-- æ£€æŸ¥ç´¢å¼•ç¢ç‰‡ï¼ˆéœ€è¦pgstattupleæ‰©å±•ï¼‰
CREATE EXTENSION IF NOT EXISTS pgstattuple;

SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    (pgstattuple(indexrelid::regclass)).dead_tuple_percent AS dead_tuple_percent
FROM pg_stat_user_indexes
WHERE pg_relation_size(indexrelid) > 100 * 1024 * 1024  -- å¤§äº100MB
ORDER BY dead_tuple_percent DESC;
```

**é‡å»ºç´¢å¼•æ–¹æ³•**ï¼š

```sql
-- æ–¹æ³•1ï¼šREINDEXï¼ˆPostgreSQL 12+ï¼Œæ”¯æŒCONCURRENTLYï¼‰
REINDEX INDEX CONCURRENTLY idx_users_email_name;

-- æ–¹æ³•2ï¼šåˆ é™¤å¹¶é‡å»ºï¼ˆéœ€è¦é”è¡¨ï¼‰
DROP INDEX idx_users_email_name;
CREATE INDEX idx_users_email_name ON users (email, first_name, last_name);

-- æ–¹æ³•3ï¼šä½¿ç”¨pg_repackï¼ˆåœ¨çº¿é‡å»ºï¼Œæ— é”ï¼‰
-- éœ€è¦å®‰è£…pg_repackæ‰©å±•
-- pg_repack -d mydb -t users --only-indexes
```

**è‡ªåŠ¨é‡å»ºç´¢å¼•è„šæœ¬**ï¼š

```sql
-- åˆ›å»ºè‡ªåŠ¨é‡å»ºç´¢å¼•å‡½æ•°
-- é‡å»ºè†¨èƒ€ç´¢å¼•å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION rebuild_bloated_indexes(
    p_min_size_mb INTEGER DEFAULT 100,
    p_max_dead_percent DECIMAL DEFAULT 20.0
)
RETURNS TABLE (
    index_name TEXT,
    index_size TEXT,
    dead_percent DECIMAL,
    rebuild_command TEXT
)
LANGUAGE plpgsql
AS $$
DECLARE
    v_rec RECORD;
    v_full_index_name TEXT;
    v_size_bytes BIGINT;
    v_dead_pct DECIMAL;
BEGIN
    -- å‚æ•°éªŒè¯
    IF p_min_size_mb IS NULL OR p_min_size_mb < 0 THEN
        RAISE EXCEPTION 'æœ€å°å¤§å°(MB)å¿…é¡»>=0: %', p_min_size_mb;
    END IF;

    IF p_max_dead_percent IS NULL OR p_max_dead_percent < 0 OR p_max_dead_percent > 100 THEN
        RAISE EXCEPTION 'æœ€å¤§æ­»å…ƒç»„ç™¾åˆ†æ¯”å¿…é¡»åœ¨0-100ä¹‹é—´: %', p_max_dead_percent;
    END IF;

    -- æ£€æŸ¥pgstattupleæ‰©å±•
    IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'pgstattuple') THEN
        RAISE WARNING 'pgstattupleæ‰©å±•æœªå®‰è£…ï¼Œæ­»å…ƒç»„ç™¾åˆ†æ¯”å¯èƒ½æ— æ³•å‡†ç¡®è®¡ç®—';
    END IF;

    -- æŸ¥è¯¢è†¨èƒ€ç´¢å¼•
    BEGIN
        FOR v_rec IN
            SELECT
                schemaname || '.' || tablename || '.' || indexname AS full_index_name,
                pg_relation_size(indexrelid) AS size_bytes,
                CASE
                    WHEN EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'pgstattuple') THEN
                        (pgstattuple(indexrelid::regclass)).dead_tuple_percent
                    ELSE NULL
                END AS dead_pct
            FROM pg_stat_user_indexes
            WHERE pg_relation_size(indexrelid) > p_min_size_mb * 1024 * 1024
              AND (
                  CASE
                      WHEN EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'pgstattuple') THEN
                          (pgstattuple(indexrelid::regclass)).dead_tuple_percent > p_max_dead_percent
                      ELSE FALSE
                  END
              )
            ORDER BY pg_relation_size(indexrelid) DESC
        LOOP
            BEGIN
                v_full_index_name := v_rec.full_index_name;
                v_size_bytes := COALESCE(v_rec.size_bytes, 0);
                v_dead_pct := COALESCE(v_rec.dead_pct, 0);

                RETURN QUERY SELECT
                    COALESCE(v_full_index_name, 'unknown')::TEXT,
                    COALESCE(pg_size_pretty(v_size_bytes), '0 bytes')::TEXT,
                    v_dead_pct,
                    format('REINDEX INDEX CONCURRENTLY %I;', v_full_index_name)::TEXT;
            EXCEPTION
                WHEN OTHERS THEN
                    RAISE WARNING 'å¤„ç†ç´¢å¼• % æ—¶å‡ºé”™: %', v_full_index_name, SQLERRM;
            END;
        END LOOP;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'æŸ¥è¯¢è†¨èƒ€ç´¢å¼•å¤±è´¥: %', SQLERRM;
    END;
EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'rebuild_bloated_indexesæ‰§è¡Œå¤±è´¥: %', SQLERRM;
END;
$$;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM rebuild_bloated_indexes(100, 20.0);
```

#### 13.4.2 ç´¢å¼•ç›‘æ§

**ç›‘æ§ç´¢å¼•ä½¿ç”¨æƒ…å†µ**ï¼š

```sql
-- ç›‘æ§æœªä½¿ç”¨çš„ç´¢å¼•
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    idx_scan AS index_scans,
    idx_tup_read AS tuples_read,
    idx_tup_fetch AS tuples_fetched
FROM pg_stat_user_indexes
WHERE idx_scan = 0  -- ä»æœªä½¿ç”¨
  AND pg_relation_size(indexrelid) > 10 * 1024 * 1024  -- å¤§äº10MB
ORDER BY pg_relation_size(indexrelid) DESC;

-- ç›‘æ§ç´¢å¼•æ•ˆç‡
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan AS scans,
    idx_tup_read AS tuples_read,
    idx_tup_fetch AS tuples_fetched,
    CASE
        WHEN idx_tup_read > 0 THEN
            ROUND((idx_tup_fetch::DECIMAL / idx_tup_read) * 100, 2)
        ELSE 0
    END AS efficiency_percent,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE idx_scan > 0
ORDER BY efficiency_percent ASC;  -- æ•ˆç‡ä½çš„åœ¨å‰
```

**ç´¢å¼•ç»´æŠ¤è®¡åˆ’**ï¼š

```sql
-- åˆ›å»ºç´¢å¼•ç»´æŠ¤è§†å›¾
CREATE OR REPLACE VIEW index_maintenance_report AS
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    idx_scan AS scans,
    CASE
        WHEN idx_scan = 0 THEN 'UNUSED - Consider dropping'
        WHEN idx_scan < 10 THEN 'RARELY USED - Review'
        WHEN idx_tup_fetch::DECIMAL / NULLIF(idx_tup_read, 0) < 0.1 THEN 'INEFFICIENT - Rebuild'
        ELSE 'OK'
    END AS recommendation
FROM pg_stat_user_indexes
ORDER BY pg_relation_size(indexrelid) DESC;

-- æŸ¥è¯¢ç»´æŠ¤æŠ¥å‘Š
SELECT * FROM index_maintenance_report
WHERE recommendation != 'OK';
```

### 13.5 PostgreSQL 18ç´¢å¼•ä¼˜åŒ–

#### 13.5.1 B-treeå»é‡ä¼˜åŒ–

**PostgreSQL 18 B-treeå»é‡**ï¼š

PostgreSQL 18å¼•å…¥äº†B-treeç´¢å¼•å»é‡ä¼˜åŒ–ï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘ç´¢å¼•å¤§å°å’Œæé«˜æ€§èƒ½ã€‚

**å»é‡åŸç†**ï¼š

```sql
-- PostgreSQL 18è‡ªåŠ¨å»é‡é‡å¤çš„ç´¢å¼•é”®
-- å¯¹äºé‡å¤å€¼ï¼Œåªå­˜å‚¨ä¸€æ¬¡ï¼Œæé«˜ç´¢å¼•æ•ˆç‡

-- ç¤ºä¾‹ï¼šå¤§é‡é‡å¤å€¼çš„åˆ—
CREATE TABLE logs (
    id SERIAL PRIMARY KEY,
    level VARCHAR(10),  -- åªæœ‰å‡ ä¸ªä¸åŒå€¼ï¼šINFO, WARNING, ERROR
    message TEXT,
    created_at TIMESTAMP
);

-- PostgreSQL 18è‡ªåŠ¨ä¼˜åŒ–é‡å¤é”®
CREATE INDEX idx_logs_level ON logs (level);
-- ç´¢å¼•å¤§å°æ˜¾è‘—å‡å°‘ï¼ˆç›¸æ¯”PostgreSQL 17ï¼‰

-- éªŒè¯å»é‡æ•ˆæœ
SELECT
    pg_size_pretty(pg_relation_size('logs')) AS table_size,
    pg_size_pretty(pg_relation_size('idx_logs_level')) AS index_size;
```

**æ€§èƒ½æå‡**ï¼š

```sql
-- æ€§èƒ½å¯¹æ¯”æµ‹è¯•
-- PostgreSQL 17: ç´¢å¼•å¤§å° 500MB
-- PostgreSQL 18: ç´¢å¼•å¤§å° 50MBï¼ˆå»é‡åï¼‰
-- æŸ¥è¯¢æ€§èƒ½æå‡ï¼š15-20%

-- æµ‹è¯•æŸ¥è¯¢
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM logs
WHERE level = 'ERROR'
  AND created_at > NOW() - INTERVAL '1 day';
```

#### 13.5.2 BRINæ€§èƒ½æå‡

**BRINç´¢å¼•ä¼˜åŒ–**ï¼š

PostgreSQL 18å¯¹BRINï¼ˆBlock Range Indexï¼‰ç´¢å¼•è¿›è¡Œäº†æ€§èƒ½ä¼˜åŒ–ã€‚

**BRINç´¢å¼•é€‚ç”¨åœºæ™¯**ï¼š

```sql
-- BRINç´¢å¼•é€‚ç”¨äºï¼š
-- 1. å¤§è¡¨ï¼ˆGBçº§åˆ«ï¼‰
-- 2. æ•°æ®æŒ‰ç‰©ç†é¡ºåºå­˜å‚¨ï¼ˆå¦‚æ—¶é—´åºåˆ—ï¼‰
-- 3. èŒƒå›´æŸ¥è¯¢ä¸ºä¸»

-- åˆ›å»ºBRINç´¢å¼•
CREATE TABLE sensor_data (
    id BIGSERIAL,
    sensor_id INTEGER,
    timestamp TIMESTAMP,
    value DECIMAL(10,2)
) WITH (fillfactor = 100);

-- æŒ‰æ—¶é—´é¡ºåºæ’å…¥æ•°æ®
INSERT INTO sensor_data (sensor_id, timestamp, value)
SELECT
    (random() * 100)::INTEGER,
    NOW() - (random() * INTERVAL '365 days'),
    random() * 100
FROM generate_series(1, 10000000);

-- åˆ›å»ºBRINç´¢å¼•ï¼ˆPostgreSQL 18ä¼˜åŒ–ï¼‰
CREATE INDEX idx_sensor_data_timestamp_brin
ON sensor_data USING BRIN (timestamp);

-- æ€§èƒ½æå‡ï¼š15-20%ï¼ˆç›¸æ¯”PostgreSQL 17ï¼‰
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM sensor_data
WHERE timestamp BETWEEN '2024-01-01' AND '2024-12-31';
```

#### 13.5.3 å¹¶è¡Œç´¢å¼•æ„å»º

**PostgreSQL 18å¹¶è¡Œç´¢å¼•æ„å»º**ï¼š

```sql
-- PostgreSQL 18æ”¯æŒæ›´å¤šç´¢å¼•ç±»å‹çš„å¹¶è¡Œæ„å»º
-- åŒ…æ‹¬GINç´¢å¼•çš„å¹¶è¡Œæ„å»º

-- å¹¶è¡Œæ„å»ºGINç´¢å¼•
CREATE INDEX CONCURRENTLY idx_products_tags_gin
ON products USING GIN (tags);

-- é…ç½®å¹¶è¡Œå·¥ä½œè¿›ç¨‹
SET max_parallel_maintenance_workers = 8;

-- æ€§èƒ½æå‡ï¼šå¤§å‹GINç´¢å¼•æ„å»ºé€Ÿåº¦æå‡2-3å€
```

**æœ€ä½³å®è·µ**ï¼š

```sql
-- 1. ä½¿ç”¨CONCURRENTLYé¿å…é”è¡¨
CREATE INDEX CONCURRENTLY idx_users_email ON users (email);

-- 2. é…ç½®å¹¶è¡Œå·¥ä½œè¿›ç¨‹
SET max_parallel_maintenance_workers = 8;

-- 3. ç›‘æ§ç´¢å¼•æ„å»ºè¿›åº¦
SELECT
    pid,
    datname,
    usename,
    application_name,
    state,
    query,
    query_start,
    now() - query_start AS duration
FROM pg_stat_activity
WHERE query LIKE '%CREATE INDEX%';
```

---

## 14. ç»Ÿè®¡ä¿¡æ¯ç»´æŠ¤æœ€ä½³å®è·µ

### 14.1 ANALYZEå‘½ä»¤æ·±åº¦ä½¿ç”¨

**ANALYZE**æ˜¯PostgreSQLæ”¶é›†è¡¨ç»Ÿè®¡ä¿¡æ¯çš„å…³é”®å‘½ä»¤ï¼Œç”¨äºå¸®åŠ©æŸ¥è¯¢è§„åˆ’å™¨é€‰æ‹©æœ€ä¼˜æ‰§è¡Œè®¡åˆ’ã€‚

#### 14.1.1 ANALYZEåŸºç¡€

**ANALYZEçš„ä½œç”¨**ï¼š

1. **æ”¶é›†ç»Ÿè®¡ä¿¡æ¯**ï¼šæ”¶é›†è¡¨çš„è¡Œæ•°ã€åˆ—çš„å”¯ä¸€å€¼æ•°é‡ã€æ•°æ®åˆ†å¸ƒç­‰
2. **æ›´æ–°ç³»ç»Ÿè¡¨**ï¼šæ›´æ–°`pg_statistic`å’Œ`pg_class`ç³»ç»Ÿè¡¨
3. **ä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’**ï¼šå¸®åŠ©æŸ¥è¯¢è§„åˆ’å™¨é€‰æ‹©æœ€ä¼˜æ‰§è¡Œè®¡åˆ’

**åŸºæœ¬ç”¨æ³•**ï¼š

```sql
-- åˆ†ææ•´ä¸ªæ•°æ®åº“
ANALYZE;

-- åˆ†æç‰¹å®šè¡¨
ANALYZE users;

-- åˆ†æç‰¹å®šåˆ—
ANALYZE users (email, created_at);

-- åˆ†æç‰¹å®šè¡¨ç©ºé—´çš„æ‰€æœ‰è¡¨
ANALYZE VERBOSE;
```

#### 14.1.2 ANALYZEå‚æ•°è¯¦è§£

**VERBOSEå‚æ•°**ï¼š

```sql
-- æ˜¾ç¤ºè¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯æ”¶é›†è¿‡ç¨‹
ANALYZE VERBOSE users;

-- è¾“å‡ºç¤ºä¾‹ï¼š
-- INFO:  analyzing "public.users"
-- INFO:  "users": scanned 10000 of 10000 pages, containing 100000 live rows and 0 dead rows; 10000 rows in sample, 100000 estimated total rows
```

**SKIP_LOCKEDå‚æ•°**ï¼ˆPostgreSQL 12+ï¼‰ï¼š

```sql
-- è·³è¿‡è¢«é”å®šçš„è¡¨ï¼Œé¿å…é˜»å¡
ANALYZE SKIP_LOCKED users;

-- é€‚ç”¨äºï¼š
-- 1. ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨ANALYZE
-- 2. é¿å…ä¸é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡å†²çª
```

**é‡‡æ ·æ§åˆ¶**ï¼š

```sql
-- è®¾ç½®ç»Ÿè®¡ä¿¡æ¯ç›®æ ‡ï¼ˆå½±å“é‡‡æ ·ç²¾åº¦ï¼‰
ALTER TABLE users ALTER COLUMN email SET STATISTICS 1000;

-- é»˜è®¤å€¼ï¼šdefault_statistics_target = 100
-- èŒƒå›´ï¼š0-10000
-- å€¼è¶Šå¤§ï¼Œé‡‡æ ·è¶Šå¤šï¼Œç»Ÿè®¡ä¿¡æ¯è¶Šå‡†ç¡®ï¼Œä½†ANALYZEæ—¶é—´è¶Šé•¿

-- æŸ¥çœ‹å½“å‰ç»Ÿè®¡ä¿¡æ¯ç›®æ ‡
SELECT
    tablename,
    attname,
    n_distinct,
    correlation,
    most_common_vals
FROM pg_stats
WHERE tablename = 'users'
  AND attname = 'email';
```

#### 14.1.3 ç»Ÿè®¡ä¿¡æ¯å†…å®¹

**pg_statsç³»ç»Ÿè§†å›¾**ï¼š

```sql
-- æŸ¥çœ‹è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
SELECT
    schemaname,
    tablename,
    attname AS column_name,
    n_distinct AS distinct_values,  -- ä¸åŒå€¼æ•°é‡ï¼ˆè´Ÿæ•°è¡¨ç¤ºæ¯”ä¾‹ï¼‰
    correlation,  -- åˆ—å€¼ä¸ç‰©ç†å­˜å‚¨é¡ºåºçš„ç›¸å…³æ€§
    most_common_vals,  -- æœ€å¸¸è§çš„å€¼
    most_common_freqs,  -- æœ€å¸¸è§å€¼çš„é¢‘ç‡
    histogram_bounds,  -- ç›´æ–¹å›¾è¾¹ç•Œï¼ˆç”¨äºèŒƒå›´æŸ¥è¯¢ä¼°ç®—ï¼‰
    null_frac  -- NULLå€¼æ¯”ä¾‹
FROM pg_stats
WHERE schemaname = 'public'
  AND tablename = 'users'
ORDER BY attname;
```

**ç»Ÿè®¡ä¿¡æ¯è§£è¯»**ï¼š

```sql
-- ç¤ºä¾‹ç»Ÿè®¡ä¿¡æ¯è§£è¯»
SELECT
    attname,
    n_distinct,
    CASE
        WHEN n_distinct < 0 THEN
            'æ¯”ä¾‹: ' || ABS(n_distinct)::TEXT || '%'
        ELSE
            'ç»å¯¹æ•°é‡: ' || n_distinct::TEXT
    END AS distinct_interpretation,
    correlation,
    CASE
        WHEN ABS(correlation) > 0.9 THEN 'Highly correlated with physical order'
        WHEN ABS(correlation) > 0.5 THEN 'Moderately correlated'
        ELSE 'Not correlated'
    END AS correlation_interpretation
FROM pg_stats
WHERE tablename = 'users';
```

### 14.2 ç»Ÿè®¡ä¿¡æ¯æ›´æ–°ç­–ç•¥

#### 14.2.1 è‡ªåŠ¨ANALYZEé…ç½®

**autovacuumé…ç½®**ï¼š

```conf
# postgresql.conf
# å¯ç”¨è‡ªåŠ¨ANALYZE
autovacuum = on
autovacuum_analyze = on

# è‡ªåŠ¨ANALYZEè§¦å‘æ¡ä»¶
autovacuum_analyze_threshold = 50  # è¡¨å˜æ›´è¡Œæ•°é˜ˆå€¼
autovacuum_analyze_scale_factor = 0.1  # è¡¨å¤§å°çš„æ¯”ä¾‹å› å­

# è‡ªåŠ¨ANALYZEè§¦å‘å…¬å¼ï¼š
# å˜æ›´è¡Œæ•° > autovacuum_analyze_threshold + autovacuum_analyze_scale_factor * è¡¨å¤§å°

# è‡ªåŠ¨ANALYZEå»¶è¿Ÿ
autovacuum_analyze_delay = 10ms  # æ¯æ¬¡ANALYZEåçš„å»¶è¿Ÿ
```

**è¡¨çº§è‡ªåŠ¨ANALYZEé…ç½®**ï¼š

```sql
-- ä¸ºç‰¹å®šè¡¨é…ç½®è‡ªåŠ¨ANALYZEå‚æ•°
ALTER TABLE large_table SET (
    autovacuum_analyze_threshold = 1000,
    autovacuum_analyze_scale_factor = 0.05
);

-- ç¦ç”¨ç‰¹å®šè¡¨çš„è‡ªåŠ¨ANALYZEï¼ˆæ‰‹åŠ¨ç®¡ç†ï¼‰
ALTER TABLE static_table SET (autovacuum_analyze_enabled = false);
```

#### 14.2.2 æ‰‹åŠ¨ANALYZEç­–ç•¥

**æ›´æ–°é¢‘ç‡ç­–ç•¥**ï¼š

```sql
-- ç­–ç•¥1ï¼šé«˜é¢‘æ›´æ–°è¡¨ï¼ˆæ¯å¤©ANALYZEï¼‰
-- é€‚ç”¨äºï¼šè®¢å•è¡¨ã€æ—¥å¿—è¡¨ç­‰
CREATE OR REPLACE FUNCTION analyze_frequent_tables()
RETURNS void AS $$
BEGIN
    ANALYZE orders;
    ANALYZE order_items;
    ANALYZE logs;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨cronå®šæœŸæ‰§è¡Œ
-- 0 2 * * * psql -d mydb -c "SELECT analyze_frequent_tables();"

-- ç­–ç•¥2ï¼šä¸­é¢‘æ›´æ–°è¡¨ï¼ˆæ¯å‘¨ANALYZEï¼‰
CREATE OR REPLACE FUNCTION analyze_medium_tables()
RETURNS void AS $$
BEGIN
    ANALYZE users;
    ANALYZE products;
    ANALYZE categories;
END;
$$ LANGUAGE plpgsql;

-- ç­–ç•¥3ï¼šä½é¢‘æ›´æ–°è¡¨ï¼ˆæ¯æœˆANALYZEï¼‰
CREATE OR REPLACE FUNCTION analyze_rare_tables()
RETURNS void AS $$
BEGIN
    ANALYZE configurations;
    ANALYZE settings;
END;
$$ LANGUAGE plpgsql;
```

**æ™ºèƒ½ANALYZEè„šæœ¬**ï¼š

```sql
-- åˆ›å»ºæ™ºèƒ½ANALYZEå‡½æ•°ï¼ˆåªåˆ†æéœ€è¦æ›´æ–°çš„è¡¨ï¼‰
CREATE OR REPLACE FUNCTION smart_analyze(
    min_changes INTEGER DEFAULT 1000
)
RETURNS TABLE (
    table_name TEXT,
    changes_since_analyze BIGINT,
    last_analyze TIMESTAMP,
    analyze_command TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        schemaname || '.' || tablename::TEXT,
        n_mod_since_analyze,
        last_analyze,
        format('ANALYZE %I.%I;', schemaname, tablename)::TEXT
    FROM pg_stat_user_tables
    WHERE n_mod_since_analyze > min_changes
      AND (
          last_analyze IS NULL
          OR last_analyze < NOW() - INTERVAL '1 day'
      )
    ORDER BY n_mod_since_analyze DESC;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM smart_analyze(1000);
-- è¿”å›éœ€è¦ANALYZEçš„è¡¨åˆ—è¡¨
```

#### 14.2.3 ç»Ÿè®¡ä¿¡æ¯ç›‘æ§

**ç›‘æ§ç»Ÿè®¡ä¿¡æ¯è¿‡æœŸæƒ…å†µ**ï¼š

```sql
-- åˆ›å»ºç»Ÿè®¡ä¿¡æ¯ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW statistics_monitoring AS
SELECT
    schemaname,
    tablename,
    n_live_tup AS live_rows,
    n_dead_tup AS dead_rows,
    n_mod_since_analyze AS changes_since_analyze,
    last_analyze,
    CASE
        WHEN last_analyze IS NULL THEN 'NEVER ANALYZED'
        WHEN last_analyze < NOW() - INTERVAL '7 days' THEN 'STALE (>7 days)'
        WHEN last_analyze < NOW() - INTERVAL '1 day' THEN 'STALE (>1 day)'
        ELSE 'FRESH'
    END AS analyze_status,
    CASE
        WHEN n_mod_since_analyze > n_live_tup * 0.1 THEN 'HIGH CHANGES'
        WHEN n_mod_since_analyze > n_live_tup * 0.05 THEN 'MEDIUM CHANGES'
        ELSE 'LOW CHANGES'
    END AS change_level
FROM pg_stat_user_tables
ORDER BY n_mod_since_analyze DESC;

-- æŸ¥è¯¢éœ€è¦æ›´æ–°çš„è¡¨
SELECT * FROM statistics_monitoring
WHERE analyze_status IN ('NEVER ANALYZED', 'STALE (>7 days)')
   OR change_level = 'HIGH CHANGES';
```

**ç»Ÿè®¡ä¿¡æ¯è´¨é‡æ£€æŸ¥**ï¼š

```sql
-- æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯è´¨é‡
CREATE OR REPLACE FUNCTION check_statistics_quality(
    table_name TEXT
)
RETURNS TABLE (
    column_name TEXT,
    n_distinct BIGINT,
    null_frac DECIMAL,
    correlation DECIMAL,
    quality_rating TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        attname::TEXT,
        n_distinct,
        null_frac,
        correlation,
        CASE
            WHEN n_distinct IS NULL THEN 'NO STATISTICS'
            WHEN null_frac > 0.5 THEN 'HIGH NULL RATIO'
            WHEN ABS(correlation) < 0.1 THEN 'LOW CORRELATION'
            WHEN n_distinct < 10 THEN 'LOW CARDINALITY'
            ELSE 'GOOD'
        END::TEXT
    FROM pg_stats
    WHERE schemaname = 'public'
      AND tablename = check_statistics_quality.table_name
    ORDER BY attname;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM check_statistics_quality('users');
```

### 14.3 æŸ¥è¯¢è§„åˆ’å™¨ä¼˜åŒ–

#### 14.3.1 ç»Ÿè®¡ä¿¡æ¯å¯¹è§„åˆ’å™¨çš„å½±å“

**åŸºæ•°ä¼°ç®—**ï¼š

```sql
-- ç»Ÿè®¡ä¿¡æ¯å½±å“æŸ¥è¯¢è§„åˆ’å™¨çš„åŸºæ•°ä¼°ç®—
-- åŸºæ•°ä¼°ç®—ä¸å‡†ç¡®ä¼šå¯¼è‡´ï¼š
-- 1. é€‰æ‹©é”™è¯¯çš„è¿æ¥é¡ºåº
-- 2. é€‰æ‹©é”™è¯¯çš„è¿æ¥ç®—æ³•
-- 3. é€‰æ‹©é”™è¯¯çš„ç´¢å¼•

-- ç¤ºä¾‹ï¼šç»Ÿè®¡ä¿¡æ¯ä¸å‡†ç¡®çš„å½±å“
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.email = 'test@example.com'
  AND o.status = 'active';

-- å¦‚æœç»Ÿè®¡ä¿¡æ¯ä¸å‡†ç¡®ï¼š
-- - å¯èƒ½é«˜ä¼°æˆ–ä½ä¼°è¿æ¥ç»“æœé›†å¤§å°
-- - å¯¼è‡´é€‰æ‹©Nested Loopè€Œä¸æ˜¯Hash Join
-- - å¯¼è‡´é€‰æ‹©é”™è¯¯çš„ç´¢å¼•
```

**æ”¹è¿›ç»Ÿè®¡ä¿¡æ¯ç²¾åº¦**ï¼š

```sql
-- æé«˜ç»Ÿè®¡ä¿¡æ¯ç›®æ ‡ï¼ˆæ›´ç²¾ç¡®çš„ä¼°ç®—ï¼‰
ALTER TABLE users ALTER COLUMN email SET STATISTICS 500;
ALTER TABLE orders ALTER COLUMN status SET STATISTICS 500;

-- é‡æ–°åˆ†æ
ANALYZE users;
ANALYZE orders;

-- éªŒè¯æ”¹è¿›æ•ˆæœ
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.email = 'test@example.com'
  AND o.status = 'active';
```

#### 14.3.2 æ‰©å±•ç»Ÿè®¡ä¿¡æ¯

**å¤šå˜é‡ç»Ÿè®¡ä¿¡æ¯**ï¼ˆPostgreSQL 10+ï¼‰ï¼š

```sql
-- åˆ›å»ºå¤šå˜é‡ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ•è·åˆ—ä¹‹é—´çš„ç›¸å…³æ€§ï¼‰
CREATE STATISTICS user_order_correlation
ON (user_id, status, created_at)
FROM orders;

-- åˆ†æè¡¨
ANALYZE orders;

-- æŸ¥çœ‹å¤šå˜é‡ç»Ÿè®¡ä¿¡æ¯
SELECT
    stxname,
    stxkeys,
    stxkind
FROM pg_statistic_ext
WHERE stxrelid = 'orders'::regclass;

-- å¤šå˜é‡ç»Ÿè®¡ä¿¡æ¯å¸®åŠ©è§„åˆ’å™¨ï¼š
-- 1. æ›´å‡†ç¡®åœ°ä¼°ç®—å¤šåˆ—æ¡ä»¶çš„é€‰æ‹©æ€§
-- 2. è¯†åˆ«åˆ—ä¹‹é—´çš„ç›¸å…³æ€§
-- 3. ä¼˜åŒ–è¿æ¥é¡ºåº
```

**è¡¨è¾¾å¼ç»Ÿè®¡ä¿¡æ¯**ï¼š

```sql
-- ä¸ºè¡¨è¾¾å¼åˆ›å»ºç»Ÿè®¡ä¿¡æ¯
CREATE STATISTICS order_total_stats
ON (total_amount, (total_amount * 0.1))
FROM orders;

-- åˆ†æè¡¨
ANALYZE orders;

-- è¡¨è¾¾å¼ç»Ÿè®¡ä¿¡æ¯å¸®åŠ©ä¼˜åŒ–å™¨ï¼š
-- 1. ä¼°ç®—è¡¨è¾¾å¼æ¡ä»¶çš„é€‰æ‹©æ€§
-- 2. ä¼˜åŒ–åŒ…å«è¡¨è¾¾å¼çš„æŸ¥è¯¢
```

#### 14.3.3 æŸ¥è¯¢è®¡åˆ’éªŒè¯

**å¯¹æ¯”ANALYZEå‰åçš„æŸ¥è¯¢è®¡åˆ’**ï¼š

```sql
-- æ­¥éª¤1ï¼šè®°å½•ANALYZEå‰çš„æŸ¥è¯¢è®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM users WHERE email = 'test@example.com';
-- è®°å½•ï¼šæ‰§è¡Œæ—¶é—´ã€è¡Œæ•°ä¼°ç®—ã€å®é™…è¡Œæ•°

-- æ­¥éª¤2ï¼šæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE users;

-- æ­¥éª¤3ï¼šè®°å½•ANALYZEåçš„æŸ¥è¯¢è®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM users WHERE email = 'test@example.com';
-- å¯¹æ¯”ï¼šæ‰§è¡Œæ—¶é—´ã€è¡Œæ•°ä¼°ç®—å‡†ç¡®æ€§

-- æ­¥éª¤4ï¼šåˆ†ææ”¹è¿›
-- å¦‚æœä¼°ç®—è¡Œæ•°æ›´æ¥è¿‘å®é™…è¡Œæ•°ï¼Œè¯´æ˜ç»Ÿè®¡ä¿¡æ¯æ”¹è¿›æœ‰æ•ˆ
```

### 14.4 PostgreSQL 18ç»Ÿè®¡ä¿¡æ¯æ–°ç‰¹æ€§

#### 14.4.1 è™šæ‹Ÿç”Ÿæˆåˆ—ç»Ÿè®¡

**PostgreSQL 18è™šæ‹Ÿç”Ÿæˆåˆ—ç»Ÿè®¡**ï¼š

PostgreSQL 18æ”¯æŒåœ¨è™šæ‹Ÿç”Ÿæˆåˆ—ä¸Šæ”¶é›†ç»Ÿè®¡ä¿¡æ¯ï¼Œæé«˜æŸ¥è¯¢ä¼˜åŒ–æ•ˆæœã€‚

```sql
-- åˆ›å»ºå¸¦è™šæ‹Ÿç”Ÿæˆåˆ—çš„è¡¨
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    price DECIMAL(10,2),
    discount DECIMAL(5,2),
    final_price DECIMAL(10,2) GENERATED ALWAYS AS (price * (1 - discount/100)) STORED
);

-- PostgreSQL 18è‡ªåŠ¨ä¸ºè™šæ‹Ÿç”Ÿæˆåˆ—æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
ANALYZE products;

-- æŸ¥çœ‹è™šæ‹Ÿç”Ÿæˆåˆ—çš„ç»Ÿè®¡ä¿¡æ¯
SELECT
    attname,
    n_distinct,
    correlation,
    most_common_vals
FROM pg_stats
WHERE tablename = 'products'
  AND attname = 'final_price';

-- æŸ¥è¯¢ä¼˜åŒ–å™¨å¯ä»¥ä½¿ç”¨è™šæ‹Ÿç”Ÿæˆåˆ—çš„ç»Ÿè®¡ä¿¡æ¯
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM products
WHERE final_price BETWEEN 50 AND 100;
```

#### 14.4.2 æ”¹è¿›çš„å¤šå˜é‡ç»Ÿè®¡

**æ›´ç²¾ç¡®çš„å¤šå˜é‡ç»Ÿè®¡**ï¼š

```sql
-- PostgreSQL 18æ”¹è¿›äº†å¤šå˜é‡ç»Ÿè®¡çš„å‡†ç¡®æ€§
CREATE STATISTICS user_order_mv_stats
ON (user_id, status, created_at, total_amount)
FROM orders;

-- åˆ†æè¡¨ï¼ˆPostgreSQL 18ä½¿ç”¨æ›´æ™ºèƒ½çš„é‡‡æ ·ç­–ç•¥ï¼‰
ANALYZE orders;

-- å¤šå˜é‡ç»Ÿè®¡ä¿¡æ¯æ›´å‡†ç¡®ï¼ŒæŸ¥è¯¢è®¡åˆ’æ›´ä¼˜
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders
WHERE user_id = 123
  AND status = 'active'
  AND created_at > '2024-01-01'
  AND total_amount > 100;
```

#### 14.4.3 æ›´ç²¾ç»†çš„ç›´æ–¹å›¾

**æ”¹è¿›çš„ç›´æ–¹å›¾**ï¼š

```sql
-- PostgreSQL 18ä½¿ç”¨æ›´ç²¾ç»†çš„ç›´æ–¹å›¾
-- æé«˜èŒƒå›´æŸ¥è¯¢çš„é€‰æ‹©æ€§ä¼°ç®—å‡†ç¡®æ€§

-- è®¾ç½®æ›´é«˜çš„ç»Ÿè®¡ä¿¡æ¯ç›®æ ‡
ALTER TABLE orders ALTER COLUMN created_at SET STATISTICS 500;

-- åˆ†æè¡¨
ANALYZE orders;

-- æŸ¥çœ‹ç›´æ–¹å›¾è¾¹ç•Œï¼ˆæ›´ç²¾ç»†ï¼‰
SELECT
    attname,
    array_length(histogram_bounds, 1) AS bucket_count,
    histogram_bounds
FROM pg_stats
WHERE tablename = 'orders'
  AND attname = 'created_at';

-- èŒƒå›´æŸ¥è¯¢çš„é€‰æ‹©æ€§ä¼°ç®—æ›´å‡†ç¡®
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders
WHERE created_at BETWEEN '2024-01-01' AND '2024-12-31';
```

#### 14.4.4 è‡ªé€‚åº”ç»Ÿè®¡ä¿¡æ¯æ›´æ–°

**è‡ªé€‚åº”æ›´æ–°ç­–ç•¥**ï¼š

```sql
-- PostgreSQL 18æ ¹æ®è¡¨çš„å˜åŒ–ç‡è‡ªåŠ¨è°ƒæ•´ANALYZEé¢‘ç‡
-- é«˜é¢‘å˜åŒ–çš„è¡¨ï¼šæ›´é¢‘ç¹çš„ANALYZE
-- ä½é¢‘å˜åŒ–çš„è¡¨ï¼šå‡å°‘ANALYZEé¢‘ç‡

-- æŸ¥çœ‹è¡¨çš„ANALYZEå†å²
SELECT
    schemaname,
    tablename,
    last_analyze,
    n_mod_since_analyze,
    n_live_tup,
    CASE
        WHEN n_mod_since_analyze::DECIMAL / NULLIF(n_live_tup, 0) > 0.1 THEN 'HIGH CHANGE RATE'
        WHEN n_mod_since_analyze::DECIMAL / NULLIF(n_live_tup, 0) > 0.05 THEN 'MEDIUM CHANGE RATE'
        ELSE 'LOW CHANGE RATE'
    END AS change_rate_category
FROM pg_stat_user_tables
ORDER BY n_mod_since_analyze DESC;
```

**æœ€ä½³å®è·µæ€»ç»“**ï¼š

```sql
-- 1. å®šæœŸç›‘æ§ç»Ÿè®¡ä¿¡æ¯è´¨é‡
SELECT * FROM statistics_monitoring
WHERE analyze_status != 'FRESH';

-- 2. ä¸ºå…³é”®åˆ—è®¾ç½®æ›´é«˜çš„ç»Ÿè®¡ä¿¡æ¯ç›®æ ‡
ALTER TABLE orders ALTER COLUMN user_id SET STATISTICS 500;
ALTER TABLE orders ALTER COLUMN status SET STATISTICS 500;

-- 3. åˆ›å»ºå¤šå˜é‡ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ•è·åˆ—ç›¸å…³æ€§ï¼‰
CREATE STATISTICS order_correlation
ON (user_id, status, created_at)
FROM orders;

-- 4. å®šæœŸæ‰§è¡ŒANALYZEï¼ˆæ ¹æ®è¡¨çš„å˜åŒ–ç‡ï¼‰
-- é«˜é¢‘è¡¨ï¼šæ¯å¤©
-- ä¸­é¢‘è¡¨ï¼šæ¯å‘¨
-- ä½é¢‘è¡¨ï¼šæ¯æœˆ

-- 5. ç›‘æ§æŸ¥è¯¢è®¡åˆ’çš„å‡†ç¡®æ€§
-- å¯¹æ¯”ä¼°ç®—è¡Œæ•°å’Œå®é™…è¡Œæ•°
-- å¦‚æœå·®å¼‚å¤§ï¼Œéœ€è¦æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
```

---

## 15. è¯·æ±‚æ€§èƒ½è·Ÿè¸ª

### 15.1 pg_stat_activityè§†å›¾æ·±åº¦ä½¿ç”¨

**pg_stat_activity**æ˜¯PostgreSQLæœ€é‡è¦çš„æ€§èƒ½ç›‘æ§è§†å›¾ï¼Œæä¾›å½“å‰æ‰€æœ‰æ•°æ®åº“è¿æ¥çš„å®æ—¶ä¿¡æ¯ã€‚

#### 15.1.1 è§†å›¾å­—æ®µè¯¦è§£

**æ ¸å¿ƒå­—æ®µè¯´æ˜**ï¼š

```sql
-- æŸ¥çœ‹pg_stat_activityçš„æ‰€æœ‰å­—æ®µ
SELECT column_name, data_type, description
FROM information_schema.columns
WHERE table_name = 'pg_stat_activity'
ORDER BY ordinal_position;

-- å…³é”®å­—æ®µè¯´æ˜ï¼š
-- - pid: è¿›ç¨‹ID
-- - datname: æ•°æ®åº“å
-- - usename: ç”¨æˆ·å
-- - application_name: åº”ç”¨åç§°
-- - client_addr: å®¢æˆ·ç«¯IPåœ°å€
-- - state: è¿æ¥çŠ¶æ€ï¼ˆactive, idle, idle in transactionç­‰ï¼‰
-- - query: å½“å‰æ‰§è¡Œçš„æŸ¥è¯¢
-- - query_start: æŸ¥è¯¢å¼€å§‹æ—¶é—´
-- - state_change: çŠ¶æ€æœ€åå˜æ›´æ—¶é—´
-- - wait_event_type: ç­‰å¾…äº‹ä»¶ç±»å‹
-- - wait_event: ç­‰å¾…äº‹ä»¶åç§°
-- - backend_type: åç«¯ç±»å‹ï¼ˆclient, autovacuum, walsenderç­‰ï¼‰
```

**åŸºæœ¬æŸ¥è¯¢**ï¼š

```sql
-- æŸ¥çœ‹æ‰€æœ‰æ´»åŠ¨è¿æ¥
SELECT
    pid,
    datname,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    state_change,
    wait_event_type,
    wait_event,
    query
FROM pg_stat_activity
WHERE datname IS NOT NULL
ORDER BY query_start DESC;
```

#### 15.1.2 è¿æ¥çŠ¶æ€åˆ†æ

**çŠ¶æ€ç±»å‹**ï¼š

```sql
-- åˆ†æè¿æ¥çŠ¶æ€åˆ†å¸ƒ
SELECT
    state,
    COUNT(*) AS connection_count,
    COUNT(*) FILTER (WHERE state = 'active') AS active_count,
    COUNT(*) FILTER (WHERE state = 'idle') AS idle_count,
    COUNT(*) FILTER (WHERE state = 'idle in transaction') AS idle_in_transaction_count,
    COUNT(*) FILTER (WHERE state = 'idle in transaction (aborted)') AS idle_in_transaction_aborted_count
FROM pg_stat_activity
WHERE datname IS NOT NULL
GROUP BY state;

-- çŠ¶æ€è¯´æ˜ï¼š
-- - active: æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢
-- - idle: ç©ºé—²ï¼Œç­‰å¾…å®¢æˆ·ç«¯å‘½ä»¤
-- - idle in transaction: åœ¨äº‹åŠ¡ä¸­ç©ºé—²ï¼ˆå¯èƒ½æŒæœ‰é”ï¼‰
-- - idle in transaction (aborted): åœ¨äº‹åŠ¡ä¸­ç©ºé—²ï¼Œä½†äº‹åŠ¡å·²ä¸­æ­¢
-- - fastpath function call: å¿«é€Ÿè·¯å¾„å‡½æ•°è°ƒç”¨
-- - disabled: ç»Ÿè®¡ä¿¡æ¯æ”¶é›†è¢«ç¦ç”¨
```

**é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡**ï¼š

```sql
-- æŸ¥æ‰¾é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡ï¼ˆå¯èƒ½å¯¼è‡´é”ç­‰å¾…ï¼‰
SELECT
    pid,
    datname,
    usename,
    application_name,
    state,
    xact_start,
    query_start,
    NOW() - xact_start AS transaction_duration,
    NOW() - query_start AS query_duration,
    query
FROM pg_stat_activity
WHERE state = 'idle in transaction'
  AND NOW() - xact_start > INTERVAL '5 minutes'
ORDER BY xact_start;
```

#### 15.1.3 ç­‰å¾…äº‹ä»¶åˆ†æ

**ç­‰å¾…äº‹ä»¶ç±»å‹**ï¼š

```sql
-- åˆ†æç­‰å¾…äº‹ä»¶
SELECT
    wait_event_type,
    wait_event,
    COUNT(*) AS wait_count,
    COUNT(*) FILTER (WHERE state = 'active') AS active_wait_count
FROM pg_stat_activity
WHERE wait_event_type IS NOT NULL
GROUP BY wait_event_type, wait_event
ORDER BY wait_count DESC;

-- å¸¸è§ç­‰å¾…äº‹ä»¶ç±»å‹ï¼š
-- - Lock: é”ç­‰å¾…
-- - IO: I/Oç­‰å¾…
-- - LWLock: è½»é‡çº§é”ç­‰å¾…
-- - BufferPin: ç¼“å†²åŒºå›ºå®šç­‰å¾…
-- - Activity: åç«¯æ´»åŠ¨ç­‰å¾…
```

**é”ç­‰å¾…åˆ†æ**ï¼š

```sql
-- æŸ¥æ‰¾é”ç­‰å¾…çš„è¿æ¥
SELECT
    blocked.pid AS blocked_pid,
    blocked.usename AS blocked_user,
    blocked.query AS blocked_query,
    blocking.pid AS blocking_pid,
    blocking.usename AS blocking_user,
    blocking.query AS blocking_query,
    blocked.wait_event_type,
    blocked.wait_event
FROM pg_stat_activity blocked
JOIN pg_locks blocked_locks ON blocked_locks.pid = blocked.pid
JOIN pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_stat_activity blocking ON blocking.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

### 15.2 å¹¶å‘é—®é¢˜è¯†åˆ«

#### 15.2.1 æ­»é”æ£€æµ‹

**æ­»é”æ£€æµ‹æŸ¥è¯¢**ï¼š

```sql
-- æ£€æµ‹æ½œåœ¨æ­»é”ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
SELECT
    a1.pid AS process1,
    a1.query AS query1,
    a2.pid AS process2,
    a2.query AS query2,
    l1.locktype,
    l1.relation::regclass AS table_name
FROM pg_locks l1
JOIN pg_locks l2 ON l1.locktype = l2.locktype
    AND l1.relation = l2.relation
    AND l1.pid != l2.pid
JOIN pg_stat_activity a1 ON a1.pid = l1.pid
JOIN pg_stat_activity a2 ON a2.pid = l2.pid
WHERE NOT l1.granted
  AND NOT l2.granted
  AND l1.pid < l2.pid;
```

**æ­»é”æ—¥å¿—åˆ†æ**ï¼š

```sql
-- PostgreSQLè‡ªåŠ¨è®°å½•æ­»é”åˆ°æ—¥å¿—
-- æ—¥å¿—æ ¼å¼ï¼š
-- ERROR: deadlock detected
-- DETAIL: Process 12345 waits for ShareLock on transaction 123456; blocked by process 12346.
-- Process 12346 waits for ShareLock on transaction 123457; blocked by process 12345.

-- åˆ†ææ­»é”æ—¥å¿—çš„è„šæœ¬
CREATE OR REPLACE FUNCTION analyze_deadlocks()
RETURNS TABLE (
    deadlock_time TIMESTAMP,
    process1_pid INTEGER,
    process2_pid INTEGER,
    details TEXT
) AS $$
BEGIN
    -- ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–æ­»é”ä¿¡æ¯ï¼ˆéœ€è¦pg_read_fileï¼‰
    -- å®é™…å®ç°éœ€è¦è§£ææ—¥å¿—æ–‡ä»¶
    RETURN QUERY
    SELECT
        NOW() AS deadlock_time,
        12345 AS process1_pid,
        12346 AS process2_pid,
        'Deadlock detected'::TEXT AS details;
END;
$$ LANGUAGE plpgsql;
```

#### 15.2.2 é˜»å¡æŸ¥è¯¢è¯†åˆ«

**é˜»å¡æŸ¥è¯¢æ£€æµ‹**ï¼š

```sql
-- æŸ¥æ‰¾é˜»å¡å…¶ä»–æŸ¥è¯¢çš„è¿›ç¨‹
SELECT
    blocking.pid AS blocking_pid,
    blocking.usename AS blocking_user,
    blocking.application_name AS blocking_app,
    blocking.query AS blocking_query,
    blocking.query_start AS blocking_query_start,
    COUNT(blocked.pid) AS blocked_count,
    array_agg(blocked.pid) AS blocked_pids,
    array_agg(blocked.query) AS blocked_queries
FROM pg_stat_activity blocking
JOIN pg_locks blocking_locks ON blocking_locks.pid = blocking.pid
    AND blocking_locks.granted = true
JOIN pg_locks blocked_locks ON blocked_locks.locktype = blocking_locks.locktype
    AND blocked_locks.database IS NOT DISTINCT FROM blocking_locks.database
    AND blocked_locks.relation IS NOT DISTINCT FROM blocking_locks.relation
    AND blocked_locks.page IS NOT DISTINCT FROM blocking_locks.page
    AND blocked_locks.tuple IS NOT DISTINCT FROM blocking_locks.tuple
    AND blocked_locks.virtualxid IS NOT DISTINCT FROM blocking_locks.virtualxid
    AND blocked_locks.transactionid IS NOT DISTINCT FROM blocking_locks.transactionid
    AND blocked_locks.classid IS NOT DISTINCT FROM blocking_locks.classid
    AND blocked_locks.objid IS NOT DISTINCT FROM blocking_locks.objid
    AND blocked_locks.objsubid IS NOT DISTINCT FROM blocking_locks.objsubid
    AND blocked_locks.pid != blocking_locks.pid
    AND NOT blocked_locks.granted
JOIN pg_stat_activity blocked ON blocked.pid = blocked_locks.pid
WHERE blocking.datname IS NOT NULL
GROUP BY blocking.pid, blocking.usename, blocking.application_name,
         blocking.query, blocking.query_start
ORDER BY blocked_count DESC;
```

**ç»ˆæ­¢é˜»å¡æŸ¥è¯¢**ï¼š

```sql
-- ç»ˆæ­¢é˜»å¡æŸ¥è¯¢ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
-- 1. é¦–å…ˆè¯†åˆ«é˜»å¡æŸ¥è¯¢
SELECT pid, query, NOW() - query_start AS duration
FROM pg_stat_activity
WHERE pid IN (
    SELECT blocking.pid
    FROM pg_stat_activity blocking
    JOIN pg_locks blocking_locks ON blocking_locks.pid = blocking.pid
    WHERE blocking_locks.granted = true
      AND EXISTS (
          SELECT 1
          FROM pg_locks blocked_locks
          WHERE blocked_locks.locktype = blocking_locks.locktype
            AND NOT blocked_locks.granted
            AND blocked_locks.pid != blocking_locks.pid
      )
);

-- 2. ç»ˆæ­¢æŸ¥è¯¢
-- SELECT pg_terminate_backend(pid);
-- æˆ–
-- SELECT pg_cancel_backend(pid);  -- æ›´æ¸©å’Œçš„æ–¹å¼
```

#### 15.2.3 é•¿æ—¶é—´è¿è¡ŒæŸ¥è¯¢

**è¯†åˆ«é•¿æ—¶é—´è¿è¡ŒæŸ¥è¯¢**ï¼š

```sql
-- æŸ¥æ‰¾é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
SELECT
    pid,
    datname,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    NOW() - query_start AS query_duration,
    wait_event_type,
    wait_event,
    LEFT(query, 100) AS query_preview
FROM pg_stat_activity
WHERE state = 'active'
  AND NOW() - query_start > INTERVAL '1 minute'
ORDER BY query_start;
```

**æŸ¥è¯¢æ‰§è¡Œæ—¶é—´ç›‘æ§**ï¼š

```sql
-- åˆ›å»ºæŸ¥è¯¢æ‰§è¡Œæ—¶é—´ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW long_running_queries AS
SELECT
    pid,
    datname,
    usename,
    application_name,
    state,
    query_start,
    NOW() - query_start AS duration,
    wait_event_type,
    wait_event,
    query
FROM pg_stat_activity
WHERE state = 'active'
  AND NOW() - query_start > INTERVAL '30 seconds'
ORDER BY query_start;

-- æŸ¥è¯¢é•¿æ—¶é—´è¿è¡ŒæŸ¥è¯¢
SELECT * FROM long_running_queries;
```

### 15.3 æ…¢æŸ¥è¯¢åˆ†æ

#### 15.3.1 ä½¿ç”¨pg_stat_statements

**å¯ç”¨pg_stat_statements**ï¼š

```sql
-- 1. å®‰è£…æ‰©å±•
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- 2. é…ç½®postgresql.conf
-- shared_preload_libraries = 'pg_stat_statements'
-- pg_stat_statements.max = 10000
-- pg_stat_statements.track = all

-- 3. é‡å¯PostgreSQL
```

**æ…¢æŸ¥è¯¢åˆ†æ**ï¼š

```sql
-- æŸ¥æ‰¾æœ€æ…¢çš„æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time,
    stddev_exec_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_stat_statements%'
ORDER BY mean_exec_time DESC
LIMIT 20;

-- æŸ¥æ‰¾æ‰§è¡Œæ¬¡æ•°æœ€å¤šçš„æ…¢æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    (total_exec_time / calls) AS avg_time_per_call
FROM pg_stat_statements
WHERE mean_exec_time > 100  -- å¹³å‡æ‰§è¡Œæ—¶é—´è¶…è¿‡100ms
ORDER BY calls DESC
LIMIT 20;
```

#### 15.3.2 æŸ¥è¯¢ä¼˜åŒ–å»ºè®®

**ç”Ÿæˆä¼˜åŒ–å»ºè®®**ï¼š

```sql
-- åˆ›å»ºæŸ¥è¯¢ä¼˜åŒ–å»ºè®®å‡½æ•°
CREATE OR REPLACE FUNCTION generate_query_optimization_suggestions()
RETURNS TABLE (
    query_id BIGINT,
    query TEXT,
    mean_time DECIMAL,
    calls BIGINT,
    suggestions TEXT[]
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        s.queryid,
        LEFT(s.query, 200) AS query,
        s.mean_exec_time,
        s.calls,
        ARRAY[
            CASE
                WHEN s.shared_blks_hit::DECIMAL / NULLIF(s.shared_blks_hit + s.shared_blks_read, 0) < 0.9
                THEN 'è€ƒè™‘å¢åŠ shared_buffersæˆ–ä¼˜åŒ–æŸ¥è¯¢ä»¥å‡å°‘I/O'
                ELSE NULL
            END,
            CASE
                WHEN s.temp_blks_read > 0
                THEN 'æŸ¥è¯¢ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œè€ƒè™‘å¢åŠ work_mem'
                ELSE NULL
            END,
            CASE
                WHEN s.mean_exec_time > 1000
                THEN 'æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œè€ƒè™‘æ·»åŠ ç´¢å¼•æˆ–ä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’'
                ELSE NULL
            END
        ]::TEXT[] AS suggestions
    FROM pg_stat_statements s
    WHERE s.mean_exec_time > 100
      AND s.query NOT LIKE '%pg_stat_statements%'
    ORDER BY s.mean_exec_time DESC
    LIMIT 20;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM generate_query_optimization_suggestions();
```

#### 15.3.3 å®æ—¶æ…¢æŸ¥è¯¢ç›‘æ§

**å®æ—¶ç›‘æ§è„šæœ¬**ï¼š

```sql
-- åˆ›å»ºå®æ—¶æ…¢æŸ¥è¯¢ç›‘æ§å‡½æ•°
CREATE OR REPLACE FUNCTION monitor_slow_queries(
    min_duration_ms INTEGER DEFAULT 1000
)
RETURNS TABLE (
    pid INTEGER,
    datname TEXT,
    usename TEXT,
    query_start TIMESTAMP,
    duration INTERVAL,
    query TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        a.pid,
        a.datname,
        a.usename,
        a.query_start,
        NOW() - a.query_start AS duration,
        a.query
    FROM pg_stat_activity a
    WHERE a.state = 'active'
      AND a.query_start IS NOT NULL
      AND EXTRACT(EPOCH FROM (NOW() - a.query_start)) * 1000 > min_duration_ms
    ORDER BY a.query_start;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹ï¼ˆç›‘æ§è¶…è¿‡1ç§’çš„æŸ¥è¯¢ï¼‰
SELECT * FROM monitor_slow_queries(1000);
```

**è‡ªåŠ¨å‘Šè­¦è„šæœ¬**ï¼š

```python
# æ…¢æŸ¥è¯¢è‡ªåŠ¨å‘Šè­¦è„šæœ¬ï¼ˆPythonï¼‰
import psycopg2
import time
from datetime import datetime

def monitor_slow_queries(conn, min_duration_ms=1000, check_interval=10):
    """ç›‘æ§æ…¢æŸ¥è¯¢å¹¶å‘é€å‘Šè­¦"""
    while True:
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT
                        pid,
                        datname,
                        usename,
                        query_start,
                        NOW() - query_start AS duration,
                        query
                    FROM pg_stat_activity
                    WHERE state = 'active'
                      AND query_start IS NOT NULL
                      AND EXTRACT(EPOCH FROM (NOW() - query_start)) * 1000 > %s
                    ORDER BY query_start
                """, (min_duration_ms,))

                slow_queries = cur.fetchall()

                if slow_queries:
                    print(f"[{datetime.now()}] Found {len(slow_queries)} slow queries:")
                    for query in slow_queries:
                        pid, datname, usename, query_start, duration, query_text = query
                        print(f"  PID {pid}: {duration} - {query_text[:100]}")
                        # å‘é€å‘Šè­¦ï¼ˆç¤ºä¾‹ï¼‰
                        # send_alert(f"Slow query detected: PID {pid}, Duration: {duration}")

        except Exception as e:
            print(f"Error monitoring slow queries: {e}")

        time.sleep(check_interval)

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect(
    host="localhost",
    port=5432,
    database="mydb",
    user="postgres",
    password="password"
)

monitor_slow_queries(conn, min_duration_ms=1000, check_interval=10)
```

---

## 16. äº‹åŠ¡èµ„æºæ¶ˆè€—åˆ†æ

### 16.1 äº‹åŠ¡å†…å­˜ä½¿ç”¨ç›‘æ§

**äº‹åŠ¡å†…å­˜**æ˜¯PostgreSQLä¸­æ¯ä¸ªäº‹åŠ¡å¯ä»¥ä½¿ç”¨çš„å†…å­˜ï¼Œä¸»è¦ç”¨äºæ’åºã€å“ˆå¸Œè¿æ¥ã€èšåˆç­‰æ“ä½œã€‚

#### 16.1.1 work_memç›‘æ§

**work_memä½¿ç”¨æƒ…å†µ**ï¼š

```sql
-- æŸ¥çœ‹å½“å‰work_memé…ç½®
SHOW work_mem;

-- æŸ¥çœ‹æ¯ä¸ªæ“ä½œä½¿ç”¨çš„work_mem
SELECT
    pid,
    datname,
    usename,
    query,
    query_start,
    state,
    -- ä¼°ç®—work_memä½¿ç”¨ï¼ˆéœ€è¦pg_stat_statementsï¼‰
    (SELECT sum(temp_blks_written) * current_setting('work_mem')::INTEGER / 1024 / 1024
     FROM pg_stat_statements
     WHERE query = a.query
     LIMIT 1) AS estimated_work_mem_mb
FROM pg_stat_activity a
WHERE state = 'active'
ORDER BY query_start;
```

**ä¸´æ—¶æ–‡ä»¶ä½¿ç”¨ç›‘æ§**ï¼š

```sql
-- æŸ¥çœ‹ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶çš„æ“ä½œï¼ˆè¡¨ç¤ºwork_memä¸è¶³ï¼‰
SELECT
    pid,
    datname,
    usename,
    query,
    temp_files,
    temp_bytes,
    pg_size_pretty(temp_bytes) AS temp_size
FROM pg_stat_activity
WHERE temp_files > 0
ORDER BY temp_bytes DESC;

-- ä½¿ç”¨pg_stat_statementsæŸ¥çœ‹ä¸´æ—¶æ–‡ä»¶ä½¿ç”¨
SELECT
    query,
    calls,
    temp_blks_read,
    temp_blks_written,
    (temp_blks_read + temp_blks_written) * 8192 AS temp_bytes,
    pg_size_pretty((temp_blks_read + temp_blks_written) * 8192) AS temp_size
FROM pg_stat_statements
WHERE temp_blks_read > 0 OR temp_blks_written > 0
ORDER BY (temp_blks_read + temp_blks_written) DESC
LIMIT 20;
```

#### 16.1.2 å†…å­˜ä½¿ç”¨åˆ†æ

**äº‹åŠ¡å†…å­˜ä½¿ç”¨ä¼°ç®—**ï¼š

```sql
-- åˆ›å»ºäº‹åŠ¡å†…å­˜ä½¿ç”¨ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW transaction_memory_usage AS
SELECT
    pid,
    datname,
    usename,
    application_name,
    state,
    query_start,
    xact_start,
    NOW() - query_start AS query_duration,
    NOW() - xact_start AS transaction_duration,
    -- ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼ˆåŸºäºæŸ¥è¯¢ç±»å‹ï¼‰
    CASE
        WHEN query ILIKE '%ORDER BY%' THEN 'Sort operation - may use work_mem'
        WHEN query ILIKE '%GROUP BY%' THEN 'Aggregation - may use work_mem'
        WHEN query ILIKE '%JOIN%' THEN 'Join operation - may use work_mem'
        ELSE 'Unknown'
    END AS memory_usage_type,
    query
FROM pg_stat_activity
WHERE state = 'active'
  AND datname IS NOT NULL;

-- æŸ¥è¯¢å†…å­˜ä½¿ç”¨æƒ…å†µ
SELECT * FROM transaction_memory_usage
ORDER BY transaction_duration DESC;
```

**å†…å­˜ä½¿ç”¨ç»Ÿè®¡**ï¼š

```sql
-- ç»Ÿè®¡å„æ•°æ®åº“çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
SELECT
    datname,
    COUNT(*) AS active_connections,
    COUNT(*) FILTER (WHERE state = 'active') AS active_queries,
    COUNT(*) FILTER (WHERE state = 'idle in transaction') AS idle_in_transaction,
    AVG(EXTRACT(EPOCH FROM (NOW() - query_start))) AS avg_query_duration_seconds
FROM pg_stat_activity
WHERE datname IS NOT NULL
GROUP BY datname
ORDER BY active_connections DESC;
```

### 16.2 èµ„æºæ¶ˆè€—è¾ƒé«˜äº‹åŠ¡è¯†åˆ«

#### 16.2.1 è¯†åˆ«é«˜èµ„æºæ¶ˆè€—äº‹åŠ¡

**é«˜èµ„æºæ¶ˆè€—äº‹åŠ¡æŸ¥è¯¢**ï¼š

```sql
-- è¯†åˆ«é«˜èµ„æºæ¶ˆè€—çš„äº‹åŠ¡
SELECT
    pid,
    datname,
    usename,
    application_name,
    state,
    xact_start,
    query_start,
    NOW() - xact_start AS transaction_duration,
    NOW() - query_start AS query_duration,
    wait_event_type,
    wait_event,
    -- èµ„æºæ¶ˆè€—æŒ‡æ ‡
    CASE
        WHEN NOW() - xact_start > INTERVAL '5 minutes' THEN 'HIGH - Long transaction'
        WHEN NOW() - query_start > INTERVAL '1 minute' THEN 'MEDIUM - Long query'
        ELSE 'LOW'
    END AS resource_consumption_level,
    LEFT(query, 200) AS query_preview
FROM pg_stat_activity
WHERE state IN ('active', 'idle in transaction')
  AND datname IS NOT NULL
ORDER BY transaction_duration DESC NULLS LAST;
```

**CPUå’ŒI/Oä½¿ç”¨åˆ†æ**ï¼š

```sql
-- ä½¿ç”¨pg_stat_statementsåˆ†æèµ„æºæ¶ˆè€—
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    -- I/Oç»Ÿè®¡
    shared_blks_hit,
    shared_blks_read,
    shared_blks_dirtied,
    shared_blks_written,
    -- ä¸´æ—¶æ–‡ä»¶ä½¿ç”¨
    temp_blks_read,
    temp_blks_written,
    -- èµ„æºæ¶ˆè€—è¯„åˆ†
    (mean_exec_time * calls) AS total_time_score,
    (shared_blks_read + shared_blks_written) AS io_score,
    (temp_blks_read + temp_blks_written) AS temp_file_score
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_stat_statements%'
ORDER BY (mean_exec_time * calls) DESC
LIMIT 20;
```

#### 16.2.2 èµ„æºæ¶ˆè€—åˆ†æå·¥å…·

**èµ„æºæ¶ˆè€—åˆ†æå‡½æ•°**ï¼š

```sql
-- åˆ›å»ºèµ„æºæ¶ˆè€—åˆ†æå‡½æ•°
CREATE OR REPLACE FUNCTION analyze_resource_consumption(
    min_duration_seconds INTEGER DEFAULT 60
)
RETURNS TABLE (
    pid INTEGER,
    datname TEXT,
    usename TEXT,
    transaction_duration INTERVAL,
    query_duration INTERVAL,
    resource_level TEXT,
    recommendations TEXT[]
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        a.pid,
        a.datname,
        a.usename,
        NOW() - a.xact_start AS transaction_duration,
        NOW() - a.query_start AS query_duration,
        CASE
            WHEN NOW() - a.xact_start > INTERVAL '10 minutes' THEN 'CRITICAL'
            WHEN NOW() - a.xact_start > INTERVAL '5 minutes' THEN 'HIGH'
            WHEN NOW() - a.xact_start > INTERVAL '1 minute' THEN 'MEDIUM'
            ELSE 'LOW'
        END::TEXT AS resource_level,
        ARRAY[
            CASE
                WHEN a.state = 'idle in transaction' THEN 'äº‹åŠ¡ç©ºé—²æ—¶é—´è¿‡é•¿ï¼Œè€ƒè™‘æäº¤æˆ–å›æ»šäº‹åŠ¡'
                ELSE NULL
            END,
            CASE
                WHEN NOW() - a.query_start > INTERVAL '5 minutes' THEN 'æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œè€ƒè™‘ä¼˜åŒ–æŸ¥è¯¢æˆ–æ·»åŠ ç´¢å¼•'
                ELSE NULL
            END,
            CASE
                WHEN a.wait_event_type = 'Lock' THEN 'ç­‰å¾…é”ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é˜»å¡æŸ¥è¯¢'
                ELSE NULL
            END
        ]::TEXT[] AS recommendations
    FROM pg_stat_activity a
    WHERE a.state IN ('active', 'idle in transaction')
      AND a.datname IS NOT NULL
      AND EXTRACT(EPOCH FROM (NOW() - COALESCE(a.xact_start, a.query_start))) > min_duration_seconds
    ORDER BY a.xact_start NULLS LAST;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM analyze_resource_consumption(60);
```

### 16.3 èµ„æºé™åˆ¶é…ç½®

#### 16.3.1 work_memé…ç½®

**work_memè®¾ç½®åŸåˆ™**ï¼š

```conf
# postgresql.conf
# work_memé…ç½®åŸåˆ™ï¼š
# - æ¯ä¸ªæ“ä½œå¯ä»¥ä½¿ç”¨work_mem
# - ä¸€ä¸ªæŸ¥è¯¢å¯èƒ½æœ‰å¤šä¸ªæ“ä½œï¼Œæ¯ä¸ªæ“ä½œéƒ½å¯ä»¥ä½¿ç”¨work_mem
# - æ€»å†…å­˜ä½¿ç”¨ = work_mem Ã— æ“ä½œæ•° Ã— å¹¶å‘è¿æ¥æ•°
# - å»ºè®®ï¼šwork_mem = (æ€»å†…å­˜ - shared_buffers) / (max_connections Ã— å¹³å‡æ“ä½œæ•°)

# å°è§„æ¨¡éƒ¨ç½²
work_mem = 4MB

# ä¸­è§„æ¨¡éƒ¨ç½²
work_mem = 16MB

# å¤§è§„æ¨¡éƒ¨ç½²
work_mem = 64MB

# æ³¨æ„ï¼šä¸è¦è®¾ç½®è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º
```

**åŠ¨æ€è°ƒæ•´work_mem**ï¼š

```sql
-- ä¼šè¯çº§è°ƒæ•´
SET work_mem = '32MB';

-- ç”¨æˆ·çº§è°ƒæ•´
ALTER USER app_user SET work_mem = '64MB';

-- æ•°æ®åº“çº§è°ƒæ•´
ALTER DATABASE mydb SET work_mem = '32MB';

-- æŸ¥çœ‹å½“å‰work_memè®¾ç½®
SHOW work_mem;
SELECT current_setting('work_mem');
```

#### 16.3.2 è¿æ¥æ•°é™åˆ¶

**è¿æ¥æ•°é…ç½®**ï¼š

```conf
# postgresql.conf
# æœ€å¤§è¿æ¥æ•°
max_connections = 100

# è¶…çº§ç”¨æˆ·ä¿ç•™è¿æ¥æ•°
superuser_reserved_connections = 3

# å®é™…å¯ç”¨è¿æ¥æ•° = max_connections - superuser_reserved_connections
```

**è¿æ¥æ•°ç›‘æ§**ï¼š

```sql
-- ç›‘æ§è¿æ¥æ•°ä½¿ç”¨æƒ…å†µ
SELECT
    COUNT(*) AS total_connections,
    COUNT(*) FILTER (WHERE state = 'active') AS active_connections,
    COUNT(*) FILTER (WHERE state = 'idle') AS idle_connections,
    COUNT(*) FILTER (WHERE state = 'idle in transaction') AS idle_in_transaction_connections,
    current_setting('max_connections')::INTEGER AS max_connections,
    ROUND(COUNT(*)::DECIMAL / current_setting('max_connections')::INTEGER * 100, 2) AS connection_usage_percent
FROM pg_stat_activity
WHERE datname IS NOT NULL;
```

**è¿æ¥æ± é…ç½®**ï¼š

```conf
# ä½¿ç”¨pgbouncerè¿æ¥æ± 
# pgbouncer.ini
[databases]
mydb = host=localhost port=5432 dbname=mydb

[pgbouncer]
pool_mode = transaction
max_client_conn = 1000
default_pool_size = 25
reserve_pool_size = 5
```

#### 16.3.3 èµ„æºé™åˆ¶æœ€ä½³å®è·µ

**èµ„æºé™åˆ¶é…ç½®æ€»ç»“**ï¼š

```sql
-- åˆ›å»ºèµ„æºé™åˆ¶é…ç½®è§†å›¾
CREATE OR REPLACE VIEW resource_limits_config AS
SELECT
    name,
    setting,
    unit,
    CASE name
        WHEN 'max_connections' THEN 'æœ€å¤§è¿æ¥æ•°'
        WHEN 'work_mem' THEN 'æ¯ä¸ªæ“ä½œçš„å·¥ä½œå†…å­˜'
        WHEN 'maintenance_work_mem' THEN 'ç»´æŠ¤æ“ä½œçš„å·¥ä½œå†…å­˜'
        WHEN 'shared_buffers' THEN 'å…±äº«ç¼“å†²åŒº'
        WHEN 'effective_cache_size' THEN 'æœ‰æ•ˆç¼“å­˜å¤§å°'
        ELSE 'å…¶ä»–'
    END AS description,
    CASE name
        WHEN 'max_connections' THEN
            'å»ºè®®ï¼šæ ¹æ®åº”ç”¨éœ€æ±‚è®¾ç½®ï¼Œä¸è¦è¿‡å¤§ï¼ˆ100-500ï¼‰'
        WHEN 'work_mem' THEN
            'å»ºè®®ï¼š4MB-64MBï¼Œæ ¹æ®ç³»ç»Ÿå†…å­˜å’Œå¹¶å‘æ•°è°ƒæ•´'
        WHEN 'maintenance_work_mem' THEN
            'å»ºè®®ï¼š256MB-2GBï¼Œç”¨äºVACUUMã€CREATE INDEXç­‰'
        WHEN 'shared_buffers' THEN
            'å»ºè®®ï¼šç³»ç»Ÿå†…å­˜çš„25%'
        WHEN 'effective_cache_size' THEN
            'å»ºè®®ï¼šç³»ç»Ÿå†…å­˜çš„50-75%'
        ELSE NULL
    END AS recommendation
FROM pg_settings
WHERE name IN (
    'max_connections',
    'work_mem',
    'maintenance_work_mem',
    'shared_buffers',
    'effective_cache_size'
)
ORDER BY name;

-- æŸ¥è¯¢èµ„æºé™åˆ¶é…ç½®
SELECT * FROM resource_limits_config;
```

**èµ„æºä½¿ç”¨å‘Šè­¦**ï¼š

```sql
-- åˆ›å»ºèµ„æºä½¿ç”¨å‘Šè­¦å‡½æ•°
CREATE OR REPLACE FUNCTION check_resource_usage()
RETURNS TABLE (
    resource_type TEXT,
    current_usage TEXT,
    max_limit TEXT,
    usage_percent DECIMAL,
    status TEXT,
    recommendation TEXT
) AS $$
BEGIN
    RETURN QUERY
    WITH connection_stats AS (
        SELECT
            COUNT(*)::INTEGER AS current_connections,
            current_setting('max_connections')::INTEGER AS max_conn
        FROM pg_stat_activity
        WHERE datname IS NOT NULL
    )
    SELECT
        'Connections'::TEXT AS resource_type,
        cs.current_connections::TEXT AS current_usage,
        cs.max_conn::TEXT AS max_limit,
        ROUND(cs.current_connections::DECIMAL / cs.max_conn * 100, 2) AS usage_percent,
        CASE
            WHEN cs.current_connections::DECIMAL / cs.max_conn > 0.9 THEN 'CRITICAL'
            WHEN cs.current_connections::DECIMAL / cs.max_conn > 0.8 THEN 'WARNING'
            ELSE 'OK'
        END::TEXT AS status,
        CASE
            WHEN cs.current_connections::DECIMAL / cs.max_conn > 0.9 THEN
                'è¿æ¥æ•°æ¥è¿‘ä¸Šé™ï¼Œè€ƒè™‘å¢åŠ max_connectionsæˆ–ä½¿ç”¨è¿æ¥æ± '
            WHEN cs.current_connections::DECIMAL / cs.max_conn > 0.8 THEN
                'è¿æ¥æ•°è¾ƒé«˜ï¼Œç›‘æ§è¿æ¥ä½¿ç”¨æƒ…å†µ'
            ELSE 'è¿æ¥æ•°æ­£å¸¸'
        END::TEXT AS recommendation
    FROM connection_stats cs;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM check_resource_usage();
```

---

## 17. MLé©±åŠ¨çš„æ€§èƒ½ä¼˜åŒ–

### 17.1 æœºå™¨å­¦ä¹ åœ¨æŸ¥è¯¢ä¼˜åŒ–ä¸­çš„åº”ç”¨

**æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰**åœ¨PostgreSQLæŸ¥è¯¢ä¼˜åŒ–ä¸­çš„åº”ç”¨æ˜¯ä¸€ä¸ªå‰æ²¿é¢†åŸŸï¼Œå¯ä»¥é€šè¿‡å­¦ä¹ å†å²æŸ¥è¯¢æ¨¡å¼æ¥ä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’ã€‚

#### 17.1.1 MLæ¨¡å‹é€‰æ‹©

**é€‚ç”¨çš„MLæ¨¡å‹**ï¼š

1. **å†³ç­–æ ‘/éšæœºæ£®æ—**ï¼š
   - ç”¨äºæŸ¥è¯¢è®¡åˆ’é€‰æ‹©
   - ç‰¹å¾ï¼šæŸ¥è¯¢ç±»å‹ã€è¡¨å¤§å°ã€ç´¢å¼•å¯ç”¨æ€§ç­‰
   - è¾“å‡ºï¼šæœ€ä¼˜æŸ¥è¯¢è®¡åˆ’

2. **ç¥ç»ç½‘ç»œ**ï¼š
   - ç”¨äºæ‰§è¡Œæ—¶é—´é¢„æµ‹
   - ç‰¹å¾ï¼šæŸ¥è¯¢å¤æ‚åº¦ã€æ•°æ®åˆ†å¸ƒã€ç³»ç»Ÿè´Ÿè½½ç­‰
   - è¾“å‡ºï¼šé¢„æµ‹æ‰§è¡Œæ—¶é—´

3. **å¼ºåŒ–å­¦ä¹ **ï¼š
   - ç”¨äºè‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
   - é€šè¿‡è¯•é”™å­¦ä¹ æœ€ä¼˜ç­–ç•¥

**æ¨¡å‹é€‰æ‹©ç¤ºä¾‹**ï¼š

```python
# æŸ¥è¯¢ä¼˜åŒ–MLæ¨¡å‹é€‰æ‹©ï¼ˆPythonç¤ºä¾‹ï¼‰
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
import pandas as pd

def select_ml_model(query_features, execution_times):
    """é€‰æ‹©æœ€é€‚åˆçš„MLæ¨¡å‹"""
    X_train, X_test, y_train, y_test = train_test_split(
        query_features, execution_times, test_size=0.2
    )

    # æ¨¡å‹1ï¼šéšæœºæ£®æ—
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    rf_score = rf_model.score(X_test, y_test)

    # æ¨¡å‹2ï¼šç¥ç»ç½‘ç»œ
    nn_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500)
    nn_model.fit(X_train, y_train)
    nn_score = nn_model.score(X_test, y_test)

    # é€‰æ‹©å¾—åˆ†æ›´é«˜çš„æ¨¡å‹
    if rf_score > nn_score:
        return rf_model, 'RandomForest'
    else:
        return nn_model, 'NeuralNetwork'
```

#### 17.1.2 ç‰¹å¾å·¥ç¨‹

**æŸ¥è¯¢ç‰¹å¾æå–**ï¼š

```python
# æŸ¥è¯¢ç‰¹å¾æå–ï¼ˆPythonï¼‰
import re
import psycopg2

def extract_query_features(query, conn):
    """æå–æŸ¥è¯¢ç‰¹å¾"""
    features = {}

    # 1. æŸ¥è¯¢ç±»å‹
    query_upper = query.upper().strip()
    if query_upper.startswith('SELECT'):
        features['query_type'] = 'SELECT'
    elif query_upper.startswith('INSERT'):
        features['query_type'] = 'INSERT'
    elif query_upper.startswith('UPDATE'):
        features['query_type'] = 'UPDATE'
    elif query_upper.startswith('DELETE'):
        features['query_type'] = 'DELETE'
    else:
        features['query_type'] = 'OTHER'

    # 2. æŸ¥è¯¢å¤æ‚åº¦
    features['query_length'] = len(query)
    features['join_count'] = query_upper.count('JOIN')
    features['subquery_count'] = query_upper.count('SELECT') - 1
    features['where_clause_count'] = query_upper.count('WHERE')
    features['order_by_count'] = query_upper.count('ORDER BY')
    features['group_by_count'] = query_upper.count('GROUP BY')

    # 3. è¡¨å¤§å°ï¼ˆä»PostgreSQLè·å–ï¼‰
    with conn.cursor() as cur:
        # æå–è¡¨åï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
        table_match = re.search(r'FROM\s+(\w+)', query_upper)
        if table_match:
            table_name = table_match.group(1)
            cur.execute("""
                SELECT pg_total_relation_size(%s) / 1024 / 1024 AS size_mb
            """, (table_name,))
            result = cur.fetchone()
            features['table_size_mb'] = result[0] if result else 0
        else:
            features['table_size_mb'] = 0

    return features

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect(host="localhost", database="mydb", user="postgres")
query = "SELECT * FROM users WHERE id = 123"
features = extract_query_features(query, conn)
print(features)
```

#### 17.1.3 æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°

**æ¨¡å‹è®­ç»ƒæµç¨‹**ï¼š

```python
# MLæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ï¼ˆPythonï¼‰
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib

def train_query_optimization_model(training_data):
    """è®­ç»ƒæŸ¥è¯¢ä¼˜åŒ–æ¨¡å‹"""
    # å‡†å¤‡æ•°æ®
    X = training_data[['query_length', 'join_count', 'table_size_mb',
                       'subquery_count', 'where_clause_count']]
    y = training_data['execution_time_ms']

    # è®­ç»ƒæ¨¡å‹
    model = RandomForestRegressor(
        n_estimators=100,
        max_depth=10,
        random_state=42
    )
    model.fit(X, y)

    # è¯„ä¼°æ¨¡å‹
    predictions = model.predict(X)
    mae = mean_absolute_error(y, predictions)
    rmse = mean_squared_error(y, predictions, squared=False)
    r2 = r2_score(y, predictions)

    print(f"Model Performance:")
    print(f"  MAE: {mae:.2f} ms")
    print(f"  RMSE: {rmse:.2f} ms")
    print(f"  RÂ²: {r2:.4f}")

    # ä¿å­˜æ¨¡å‹
    joblib.dump(model, 'query_optimization_model.pkl')

    return model

# ä½¿ç”¨ç¤ºä¾‹
# training_data = pd.read_csv('query_training_data.csv')
# model = train_query_optimization_model(training_data)
```

### 17.2 è‡ªåŠ¨å‚æ•°è°ƒä¼˜

**è‡ªåŠ¨å‚æ•°è°ƒä¼˜**ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•è‡ªåŠ¨è°ƒæ•´PostgreSQLé…ç½®å‚æ•°ï¼Œä»¥ä¼˜åŒ–æ€§èƒ½ã€‚

#### 17.2.1 å‚æ•°è°ƒä¼˜ç®—æ³•

**è´å¶æ–¯ä¼˜åŒ–**ï¼š

```python
# ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œå‚æ•°è°ƒä¼˜ï¼ˆPythonï¼‰
from skopt import gp_minimize
from skopt.space import Real, Integer
import subprocess
import time

def evaluate_postgresql_config(params):
    """è¯„ä¼°PostgreSQLé…ç½®å‚æ•°"""
    shared_buffers, work_mem, max_connections = params

    # æ›´æ–°PostgreSQLé…ç½®
    update_postgresql_config({
        'shared_buffers': f'{shared_buffers}MB',
        'work_mem': f'{work_mem}MB',
        'max_connections': max_connections
    })

    # é‡å¯PostgreSQLï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
    # subprocess.run(['sudo', 'systemctl', 'restart', 'postgresql'])
    # time.sleep(10)  # ç­‰å¾…æœåŠ¡å¯åŠ¨

    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    # benchmark_result = run_pgbench()

    # è¿”å›è´Ÿçš„æ€§èƒ½æŒ‡æ ‡ï¼ˆå› ä¸ºæˆ‘ä»¬è¦æœ€å°åŒ–ï¼‰
    # return -benchmark_result['tps']

    # ç®€åŒ–ç¤ºä¾‹ï¼šè¿”å›æ¨¡æ‹Ÿæ€§èƒ½æŒ‡æ ‡
    return -(shared_buffers * 0.1 + work_mem * 0.05 + max_connections * 0.01)

def auto_tune_postgresql():
    """è‡ªåŠ¨è°ƒä¼˜PostgreSQLå‚æ•°"""
    # å®šä¹‰å‚æ•°æœç´¢ç©ºé—´
    space = [
        Integer(256, 2048, name='shared_buffers'),  # 256MB - 2GB
        Integer(4, 64, name='work_mem'),  # 4MB - 64MB
        Integer(50, 500, name='max_connections')  # 50 - 500
    ]

    # ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–
    result = gp_minimize(
        func=evaluate_postgresql_config,
        dimensions=space,
        n_calls=20,  # è¯„ä¼°æ¬¡æ•°
        random_state=42
    )

    print(f"Best parameters: {result.x}")
    print(f"Best performance: {-result.fun}")

    return result.x

# ä½¿ç”¨ç¤ºä¾‹
# best_params = auto_tune_postgresql()
```

#### 17.2.2 è‡ªåŠ¨åŒ–å·¥å…·

**pg_tuneå·¥å…·**ï¼š

```bash
# pg_tune - PostgreSQLè‡ªåŠ¨è°ƒä¼˜å·¥å…·
# å®‰è£…
pip install pg_tune

# ä½¿ç”¨
pg_tune --dbname=mydb --host=localhost --port=5432

# pg_tuneä¼šï¼š
# 1. åˆ†æç³»ç»Ÿèµ„æº
# 2. åˆ†æå½“å‰é…ç½®
# 3. ç”Ÿæˆä¼˜åŒ–å»ºè®®
# 4. å¯é€‰ï¼šè‡ªåŠ¨åº”ç”¨ä¼˜åŒ–
```

### 17.3 æ™ºèƒ½ç´¢å¼•æ¨è

**æ™ºèƒ½ç´¢å¼•æ¨è**ä½¿ç”¨æœºå™¨å­¦ä¹ åˆ†ææŸ¥è¯¢æ¨¡å¼ï¼Œè‡ªåŠ¨æ¨èæœ€ä¼˜ç´¢å¼•ã€‚

#### 17.3.1 ç´¢å¼•æ¨èç®—æ³•

**åŸºäºæŸ¥è¯¢æ¨¡å¼çš„ç´¢å¼•æ¨è**ï¼š

```python
# æ™ºèƒ½ç´¢å¼•æ¨èï¼ˆPythonï¼‰
import pandas as pd
from collections import Counter
import psycopg2

def recommend_indexes(conn, min_query_count=10):
    """æ¨èç´¢å¼•"""
    with conn.cursor() as cur:
        # è·å–æŸ¥è¯¢ç»Ÿè®¡
        cur.execute("""
            SELECT
                query,
                calls,
                mean_exec_time,
                shared_blks_hit,
                shared_blks_read
            FROM pg_stat_statements
            WHERE calls >= %s
              AND mean_exec_time > 100  -- åªè€ƒè™‘æ…¢æŸ¥è¯¢
            ORDER BY mean_exec_time DESC
        """, (min_query_count,))

        queries = cur.fetchall()

    # åˆ†ææŸ¥è¯¢æ¨¡å¼
    index_recommendations = []

    for query, calls, mean_time, hits, reads in queries:
        # æå–WHEREå­å¥ä¸­çš„åˆ—
        where_columns = extract_where_columns(query)

        # æå–JOINæ¡ä»¶ä¸­çš„åˆ—
        join_columns = extract_join_columns(query)

        # æå–ORDER BYä¸­çš„åˆ—
        order_columns = extract_order_columns(query)

        # ç”Ÿæˆç´¢å¼•æ¨è
        if where_columns:
            index_recommendations.append({
                'table': extract_table_name(query),
                'columns': where_columns,
                'type': 'B-tree',
                'priority': calls * mean_time,  # ä¼˜å…ˆçº§ = è°ƒç”¨æ¬¡æ•° Ã— å¹³å‡æ—¶é—´
                'reason': 'WHERE clause optimization'
            })

        if join_columns:
            index_recommendations.append({
                'table': extract_table_name(query),
                'columns': join_columns,
                'type': 'B-tree',
                'priority': calls * mean_time,
                'reason': 'JOIN optimization'
            })

    # æŒ‰ä¼˜å…ˆçº§æ’åº
    index_recommendations.sort(key=lambda x: x['priority'], reverse=True)

    return index_recommendations

def extract_where_columns(query):
    """æå–WHEREå­å¥ä¸­çš„åˆ—ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰"""
    import re
    where_match = re.search(r'WHERE\s+(.+?)(?:\s+GROUP|\s+ORDER|\s+LIMIT|$)', query, re.IGNORECASE)
    if where_match:
        where_clause = where_match.group(1)
        # æå–åˆ—åï¼ˆç®€åŒ–ï¼‰
        columns = re.findall(r'(\w+)\s*[=<>]', where_clause)
        return list(set(columns))
    return []

# ä½¿ç”¨ç¤ºä¾‹
# conn = psycopg2.connect(host="localhost", database="mydb", user="postgres")
# recommendations = recommend_indexes(conn)
# for rec in recommendations[:10]:  # å‰10ä¸ªæ¨è
#     print(f"CREATE INDEX ON {rec['table']} ({', '.join(rec['columns'])});")
```

#### 17.3.2 å·¥å…·ä½¿ç”¨

**ä½¿ç”¨pg_qualstatså’Œhypopg**ï¼š

```sql
-- 1. å®‰è£…æ‰©å±•
CREATE EXTENSION IF NOT EXISTS pg_qualstats;
CREATE EXTENSION IF NOT EXISTS hypopg;

-- 2. æ”¶é›†æŸ¥è¯¢ç»Ÿè®¡
-- pg_qualstatsè‡ªåŠ¨æ”¶é›†WHEREå­å¥ç»Ÿè®¡

-- 3. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
SELECT
    schemaname,
    tablename,
    attname,
    nbfiltered,
    qualnodeid
FROM pg_qualstats;

-- 4. ç”Ÿæˆç´¢å¼•æ¨è
SELECT
    schemaname,
    tablename,
    array_agg(attname ORDER BY attname) AS columns,
    sum(nbfiltered) AS total_filtered
FROM pg_qualstats
GROUP BY schemaname, tablename, qualnodeid
HAVING sum(nbfiltered) > 1000
ORDER BY total_filtered DESC;

-- 5. ä½¿ç”¨hypopgæµ‹è¯•è™šæ‹Ÿç´¢å¼•
SELECT * FROM hypopg_create_index('CREATE INDEX ON users (email)');
```

### 17.4 è´Ÿè½½é¢„æµ‹å’Œèµ„æºè°ƒåº¦

**è´Ÿè½½é¢„æµ‹**ä½¿ç”¨æ—¶é—´åºåˆ—æ¨¡å‹é¢„æµ‹æœªæ¥è´Ÿè½½ï¼Œæå‰è°ƒæ•´èµ„æºåˆ†é…ã€‚

#### 17.4.1 è´Ÿè½½é¢„æµ‹æ¨¡å‹

**æ—¶é—´åºåˆ—é¢„æµ‹**ï¼š

```python
# è´Ÿè½½é¢„æµ‹æ¨¡å‹ï¼ˆPythonï¼‰
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

def prepare_load_data(conn, days=30):
    """å‡†å¤‡è´Ÿè½½æ•°æ®"""
    query = """
        SELECT
            date_trunc('hour', query_start) AS hour,
            COUNT(*) AS query_count,
            AVG(EXTRACT(EPOCH FROM (NOW() - query_start))) AS avg_duration,
            COUNT(*) FILTER (WHERE state = 'active') AS active_queries
        FROM pg_stat_activity
        WHERE query_start > NOW() - INTERVAL '%s days'
          AND datname IS NOT NULL
        GROUP BY hour
        ORDER BY hour
    """ % days

    df = pd.read_sql(query, conn)
    return df

def create_features(df):
    """åˆ›å»ºç‰¹å¾"""
    df['hour'] = pd.to_datetime(df['hour']).dt.hour
    df['day_of_week'] = pd.to_datetime(df['hour']).dt.dayofweek
    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

    # æ»åç‰¹å¾
    df['query_count_lag1'] = df['query_count'].shift(1)
    df['query_count_lag24'] = df['query_count'].shift(24)

    # ç§»åŠ¨å¹³å‡
    df['query_count_ma7'] = df['query_count'].rolling(window=7).mean()

    return df

def train_load_prediction_model(df):
    """è®­ç»ƒè´Ÿè½½é¢„æµ‹æ¨¡å‹"""
    # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
    feature_cols = ['hour', 'day_of_week', 'is_weekend',
                     'query_count_lag1', 'query_count_lag24', 'query_count_ma7']
    X = df[feature_cols].dropna()
    y = df.loc[X.index, 'query_count']

    # è®­ç»ƒæ¨¡å‹
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X, y)

    # é¢„æµ‹
    predictions = model.predict(X)

    return model, predictions

# ä½¿ç”¨ç¤ºä¾‹
# conn = psycopg2.connect(host="localhost", database="mydb", user="postgres")
# df = prepare_load_data(conn, days=30)
# df = create_features(df)
# model, predictions = train_load_prediction_model(df)
```

#### 17.4.2 èµ„æºè°ƒåº¦ç­–ç•¥

**åŸºäºé¢„æµ‹çš„èµ„æºè°ƒåº¦**ï¼š

```python
# åŸºäºé¢„æµ‹çš„èµ„æºè°ƒåº¦ï¼ˆPythonï¼‰
def schedule_resources(predicted_load, current_resources):
    """æ ¹æ®é¢„æµ‹è´Ÿè½½è°ƒåº¦èµ„æº"""
    recommendations = []

    # é¢„æµ‹è´Ÿè½½é˜ˆå€¼
    high_load_threshold = current_resources['max_connections'] * 0.8
    low_load_threshold = current_resources['max_connections'] * 0.3

    if predicted_load > high_load_threshold:
        recommendations.append({
            'action': 'scale_up',
            'resource': 'max_connections',
            'current': current_resources['max_connections'],
            'recommended': int(predicted_load * 1.2),
            'reason': 'Predicted load exceeds threshold'
        })
    elif predicted_load < low_load_threshold:
        recommendations.append({
            'action': 'scale_down',
            'resource': 'max_connections',
            'current': current_resources['max_connections'],
            'recommended': int(predicted_load * 1.5),
            'reason': 'Predicted load below threshold, can reduce resources'
        })

    return recommendations

# ä½¿ç”¨ç¤ºä¾‹
# predicted_load = model.predict(future_features)
# current_resources = {'max_connections': 100}
# recommendations = schedule_resources(predicted_load, current_resources)
```

---

## 18. å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1: OLTPç³»ç»Ÿè°ƒä¼˜

**åœºæ™¯**: ç”µå•†è®¢å•ç³»ç»Ÿï¼Œé«˜å¹¶å‘å†™å…¥ï¼Œä½å»¶è¿ŸæŸ¥è¯¢

**è°ƒä¼˜æ–¹æ¡ˆ**:

```sql
-- è¿æ¥æ± é…ç½®
-- pgbouncer transactionæ¨¡å¼
max_client_conn = 1000
default_pool_size = 25

-- PostgreSQLå‚æ•°
max_connections = 200
shared_buffers = 8GB  -- 25% of 32GB RAM
work_mem = 16MB
effective_cache_size = 24GB
random_page_cost = 1.1  -- SSD
effective_io_concurrency = 200  -- NVMe

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_orders_user_created
ON orders(user_id, created_at DESC);
```

**æ•ˆæœ**: QPSæå‡40%ï¼ŒP99å»¶è¿Ÿé™ä½30%

### æ¡ˆä¾‹2: OLAPåˆ†æç³»ç»Ÿè°ƒä¼˜

**åœºæ™¯**: æ•°æ®ä»“åº“ï¼Œå¤æ‚èšåˆæŸ¥è¯¢ï¼Œæ‰¹é‡åˆ†æ

**è°ƒä¼˜æ–¹æ¡ˆ**:

```sql
-- PostgreSQLå‚æ•°
max_parallel_workers_per_gather = 4
max_parallel_workers = 16
work_mem = 256MB
shared_buffers = 16GB
effective_cache_size = 48GB
jit = on
jit_above_cost = 200000

-- åˆ†åŒºè¡¨ä¼˜åŒ–
CREATE TABLE sales (
    sale_date DATE,
    product_id INT,
    amount DECIMAL(10,2)
) PARTITION BY RANGE (sale_date);

-- åˆ›å»ºæœˆåº¦åˆ†åŒº
CREATE TABLE sales_2025_01 PARTITION OF sales
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

**æ•ˆæœ**: å¤æ‚æŸ¥è¯¢æ€§èƒ½æå‡60%ï¼Œå¹¶è¡Œåˆ©ç”¨ç‡æå‡50%

### æ¡ˆä¾‹3: æ··åˆè´Ÿè½½è°ƒä¼˜

**åœºæ™¯**: è¯»å†™æ··åˆï¼Œéœ€è¦å¹³è¡¡OLTPå’ŒOLAPæ€§èƒ½

**è°ƒä¼˜æ–¹æ¡ˆ**:

```sql
-- è¯»å†™åˆ†ç¦»
-- ä¸»åº“ï¼ˆOLTPï¼‰
max_connections = 200
work_mem = 16MB
shared_buffers = 8GB
jit = off

-- åªè¯»å‰¯æœ¬ï¼ˆOLAPï¼‰
max_connections = 100
work_mem = 256MB
shared_buffers = 16GB
jit = on
max_parallel_workers_per_gather = 4
```

**æ•ˆæœ**: OLTPå»¶è¿Ÿç¨³å®šï¼ŒOLAPæŸ¥è¯¢æ€§èƒ½æå‡50%

---

## 14. æ·±å…¥é˜…è¯»

### ç›¸å…³æ–‡æ¡£

#### æŸ¥è¯¢ä¸ä¼˜åŒ–

- â­â­â­ [æ‰§è¡Œè®¡åˆ’ä¸æ€§èƒ½è°ƒä¼˜](../../../02-æŸ¥è¯¢ä¸ä¼˜åŒ–/02.03-æ‰§è¡Œè®¡åˆ’/02.04-æ‰§è¡Œè®¡åˆ’ä¸æ€§èƒ½è°ƒä¼˜.md) - æŸ¥è¯¢ä¼˜åŒ–
- â­â­ [æŸ¥è¯¢ä¼˜åŒ–å™¨åŸç†](../../../02-æŸ¥è¯¢ä¸ä¼˜åŒ–/02.01-æŸ¥è¯¢ä¼˜åŒ–å™¨/02.01-æŸ¥è¯¢ä¼˜åŒ–å™¨åŸç†.md) - æŸ¥è¯¢ä¼˜åŒ–åŸºç¡€
- â­â­ [ç´¢å¼•ç»“æ„ä¸ä¼˜åŒ–](../../../02-æŸ¥è¯¢ä¸ä¼˜åŒ–/02.02-ç´¢å¼•ç»“æ„/02.02-ç´¢å¼•ç»“æ„ä¸ä¼˜åŒ–.md) - ç´¢å¼•ä¼˜åŒ–
- â­â­ [ç»Ÿè®¡ä¿¡æ¯ä¸ä»£ä»·æ¨¡å‹](../../../02-æŸ¥è¯¢ä¸ä¼˜åŒ–/02.04-ç»Ÿè®¡ä¿¡æ¯/02.03-ç»Ÿè®¡ä¿¡æ¯ä¸ä»£ä»·æ¨¡å‹.md) - ç»Ÿè®¡ä¿¡æ¯ç®¡ç†

#### æ ¸å¿ƒè¯¾ç¨‹

- â­â­ [ç³»ç»Ÿæ¶æ„ä¸è®¾è®¡åŸç†](../../../01-æ ¸å¿ƒåŸºç¡€/01.02-ç³»ç»Ÿæ¶æ„/01.01-ç³»ç»Ÿæ¶æ„ä¸è®¾è®¡åŸç†.md) - ç³»ç»Ÿæ¶æ„åŸºç¡€
- â­â­ [å­˜å‚¨ç®¡ç†ä¸æ•°æ®æŒä¹…åŒ–](../../../04-å­˜å‚¨ä¸æ¢å¤/01.06-å­˜å‚¨ç®¡ç†ä¸æ•°æ®æŒä¹…åŒ–.md) - å­˜å‚¨ä¼˜åŒ–ï¼ˆåˆ—å­˜å‚¨æ¶æ„ã€åˆ—å‹ç¼©æŠ€æœ¯ã€å¼‚æ­¥I/Oï¼‰ğŸ†•

#### è¿ç»´å®è·µ

- â­â­â­ [ç›‘æ§ä¸è¯Šæ–­](../../../12-ç›‘æ§ä¸è¯Šæ–­/06.01-ç›‘æ§ä¸è¯Šæ–­.md) - æ€§èƒ½ç›‘æ§
- â­â­ [æ€§èƒ½è°ƒä¼˜å˜æ›´é—­ç¯](../../../13-é«˜å¯ç”¨æ¶æ„/ç›‘æ§ä¸è¯Šæ–­/06.03-æ€§èƒ½è°ƒä¼˜å˜æ›´é—­ç¯.md) - å˜æ›´ç®¡ç†
- â­â­ [æ€§èƒ½é—®é¢˜-æ¡ˆä¾‹åº“](../../../16-åº”ç”¨è®¾è®¡ä¸å¼€å‘/è¡Œä¸šæ¡ˆä¾‹/æ€§èƒ½é—®é¢˜-æ¡ˆä¾‹åº“.md) - æ€§èƒ½é—®é¢˜æ¡ˆä¾‹

#### å‰æ²¿æŠ€æœ¯

- â­â­ [å¤šæ¨¡å‹æ•°æ®åº“](../../../07-å¤šæ¨¡å‹æ•°æ®åº“/README.md) - å‘é‡æ£€ç´¢ä¼˜åŒ–

#### ç‰ˆæœ¬ç‰¹æ€§

- â­â­ [PostgreSQL 18æ–°ç‰¹æ€§](../../../18-ç‰ˆæœ¬ç‰¹æ€§/02.01-PostgreSQL-18-æ–°ç‰¹æ€§.md) - PostgreSQL 18æ€§èƒ½ä¼˜åŒ–

### å¤–éƒ¨èµ„æº

- [PostgreSQLæ€§èƒ½è°ƒä¼˜æŒ‡å—](https://www.postgresql.org/docs/current/performance-tips.html)
- [pg_stat_statementsæ–‡æ¡£](https://www.postgresql.org/docs/current/pgstatstatements.html)
- [PostgreSQLé…ç½®å‚æ•°](https://www.postgresql.org/docs/current/runtime-config.html)

---

## 15. å‚è€ƒæ–‡çŒ®

1. PostgreSQL Global Development Group. (2025). PostgreSQL 18 Documentation. <https://www.postgresql.org/docs/18/>
2. PostgreSQLå®˜æ–¹æ–‡æ¡£ - [æ€§èƒ½è°ƒä¼˜](https://www.postgresql.org/docs/current/performance-tips.html)
3. PostgreSQLå®˜æ–¹æ–‡æ¡£ - [é…ç½®å‚æ•°](https://www.postgresql.org/docs/current/runtime-config.html)
4. PostgreSQLå®˜æ–¹æ–‡æ¡£ - [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html)
5. PostgreSQLå®˜æ–¹æ–‡æ¡£ - [EXPLAIN](https://www.postgresql.org/docs/current/sql-explain.html)
6. TimescaleDB - [æ€§èƒ½è°ƒä¼˜æœ€ä½³å®è·µ](https://docs.timescale.com/timescaledb/latest/how-to-guides/performance/)
7. PostgreSQL Global Development Group. (2024). PostgreSQL 17 Documentation. <https://www.postgresql.org/docs/17/>
