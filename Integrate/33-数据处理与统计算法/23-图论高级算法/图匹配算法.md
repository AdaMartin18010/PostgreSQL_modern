# PostgreSQL 图匹配算法完整指南

> **创建日期**: 2025年1月
> **技术栈**: PostgreSQL 17+/18+ | 图算法 | 图匹配 | 二分图匹配
> **难度级别**: ⭐⭐⭐⭐⭐ (专家级)
> **参考标准**: Graph Matching, Bipartite Matching, Hungarian Algorithm

---

## 📋 目录

- [PostgreSQL 图匹配算法完整指南](#postgresql-图匹配算法完整指南)
  - [📋 目录](#-目录)
  - [图匹配概述](#图匹配概述)
    - [理论基础](#理论基础)
      - [图匹配的数学定义](#图匹配的数学定义)
      - [二分图匹配理论](#二分图匹配理论)
    - [匹配类型](#匹配类型)
  - [1. 二分图匹配](#1-二分图匹配)
    - [1.1 最大匹配算法](#11-最大匹配算法)
      - [算法原理](#算法原理)
    - [1.2 增广路径算法完整实现](#12-增广路径算法完整实现)
    - [1.3 最大匹配验证与评估](#13-最大匹配验证与评估)
    - [1.4 Hopcroft-Karp算法（高效实现）](#14-hopcroft-karp算法高效实现)
  - [2. 匈牙利算法](#2-匈牙利算法)
    - [2.1 匈牙利算法原理](#21-匈牙利算法原理)
      - [匈牙利算法理论基础](#匈牙利算法理论基础)
    - [2.2 匈牙利算法实现](#22-匈牙利算法实现)
    - [2.3 匈牙利算法完整实现](#23-匈牙利算法完整实现)
    - [2.4 最优匹配查找与验证](#24-最优匹配查找与验证)
    - [2.5 性能测试与对比](#25-性能测试与对比)
  - [3. 复杂度分析](#3-复杂度分析)
    - [3.1 时间复杂度](#31-时间复杂度)
    - [3.2 空间复杂度](#32-空间复杂度)
  - [4. 实际应用案例](#4-实际应用案例)
    - [4.1 任务分配问题](#41-任务分配问题)
    - [4.2 资源分配问题](#42-资源分配问题)
    - [4.3 稳定匹配问题（Gale-Shapley算法）](#43-稳定匹配问题gale-shapley算法)
    - [4.4 网络流量分配](#44-网络流量分配)
  - [5. 算法性能对比](#5-算法性能对比)
    - [5.1 时间复杂度对比](#51-时间复杂度对比)
    - [5.2 性能测试结果](#52-性能测试结果)
    - [5.3 优化建议](#53-优化建议)
  - [📚 参考资源](#-参考资源)
    - [学术文献](#学术文献)
    - [在线资源](#在线资源)
    - [相关算法](#相关算法)
  - [📊 性能优化建议](#-性能优化建议)
    - [6.1 索引优化](#61-索引优化)
    - [6.2 查询优化](#62-查询优化)
    - [6.3 算法选择指南](#63-算法选择指南)
  - [🎯 最佳实践](#-最佳实践)
    - [7.1 算法选择](#71-算法选择)
    - [7.2 权重设计](#72-权重设计)
    - [7.3 验证与测试](#73-验证与测试)
    - [7.4 常见问题与解决方案](#74-常见问题与解决方案)

---

## 图匹配概述

**图匹配**是图论中的核心问题，旨在寻找图中的最大匹配或最优匹配。匹配问题在资源分配、任务调度、网络流等领域有广泛应用。

### 理论基础

#### 图匹配的数学定义

给定无向图 $G = (V, E)$，其中 $V$ 是顶点集，$E$ 是边集。

**匹配（Matching）**：边集 $M \subseteq E$，使得 $M$ 中任意两条边都不共享顶点。

**最大匹配（Maximum Matching）**：边数最多的匹配，记为 $|M^*|$。

**完美匹配（Perfect Matching）**：覆盖所有顶点的匹配，即 $|M| = |V|/2$。

**最大权重匹配（Maximum Weight Matching）**：在加权图中，权重和最大的匹配。

#### 二分图匹配理论

**二分图（Bipartite Graph）**：顶点集 $V$ 可以划分为两个不相交的子集 $U$ 和 $W$，使得每条边的一个端点在 $U$ 中，另一个端点在 $W$ 中。

**增广路径（Augmenting Path）**：从未匹配顶点开始，交替经过匹配边和非匹配边的路径。

**关键定理（Berge's Lemma）**：匹配 $M$ 是最大匹配当且仅当不存在增广路径。

### 匹配类型

| 类型 | 定义 | 应用场景 | 算法复杂度 |
|------|------|---------|-----------|
| **最大匹配** | 边数最多的匹配 | 资源分配、人员配置 | $O(VE)$ |
| **完美匹配** | 覆盖所有顶点的匹配 | 任务分配、婚姻匹配 | $O(V^3)$ |
| **最大权重匹配** | 权重和最大的匹配 | 最优分配、成本最小化 | $O(V^3)$ |
| **稳定匹配** | 满足稳定性的匹配 | 稳定婚姻问题、学校录取 | $O(V^2)$ |

---

## 1. 二分图匹配

### 1.1 最大匹配算法

**最大匹配**在二分图中寻找边数最多的匹配。这是图匹配问题的基础，也是许多高级算法的基础。

#### 算法原理

**增广路径算法（Augmenting Path Algorithm）**基于Berge引理：

**算法步骤**：

1. **初始化**：从空匹配 $M = \emptyset$ 开始
2. **寻找增广路径**：使用DFS或BFS寻找从未匹配顶点开始的增广路径
3. **扩展匹配**：沿增广路径翻转边的匹配状态（匹配边变非匹配，非匹配边变匹配）
4. **重复**：重复步骤2-3，直到找不到增广路径

**算法正确性**：根据Berge引理，当不存在增广路径时，当前匹配即为最大匹配。

**时间复杂度**：$O(VE)$，其中 $V$ 是顶点数，$E$ 是边数。

**空间复杂度**：$O(V)$，用于存储匹配状态和路径。

```sql
-- 二分图匹配数据准备（带错误处理）
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'bipartite_graph') THEN
            DROP TABLE bipartite_graph CASCADE;
        END IF;

        CREATE TABLE bipartite_graph (
            left_node INTEGER NOT NULL,
            right_node INTEGER NOT NULL,
            weight NUMERIC DEFAULT 1,
            PRIMARY KEY (left_node, right_node)
        );

        -- 插入示例二分图（左侧：任务，右侧：工人）
        INSERT INTO bipartite_graph (left_node, right_node, weight) VALUES
            (1, 1, 1), (1, 2, 1),
            (2, 2, 1), (2, 3, 1),
            (3, 3, 1), (3, 4, 1),
            (4, 1, 1), (4, 4, 1);

        CREATE INDEX idx_left_node ON bipartite_graph(left_node);
        CREATE INDEX idx_right_node ON bipartite_graph(right_node);

        RAISE NOTICE '二分图表创建成功，共 % 条边', (SELECT COUNT(*) FROM bipartite_graph);
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION '创建表失败: %', SQLERRM;
    END;
END $$;

-- 最大匹配：贪心算法（每次选择未匹配的边）
WITH unmatched_left AS (
    SELECT DISTINCT left_node
    FROM bipartite_graph
),
unmatched_right AS (
    SELECT DISTINCT right_node
    FROM bipartite_graph
),
greedy_matching AS (
    SELECT DISTINCT ON (right_node)
        left_node,
        right_node,
        ROW_NUMBER() OVER (PARTITION BY right_node ORDER BY left_node) AS match_order
    FROM bipartite_graph
    WHERE left_node IN (SELECT left_node FROM unmatched_left)
      AND right_node IN (SELECT right_node FROM unmatched_right)
)
SELECT
    COUNT(*) AS matching_size,
    ARRAY_AGG(ARRAY[left_node, right_node] ORDER BY match_order) AS matching_edges,
    ROUND(COUNT(*)::NUMERIC / GREATEST(
        (SELECT COUNT(DISTINCT left_node) FROM bipartite_graph),
        (SELECT COUNT(DISTINCT right_node) FROM bipartite_graph)
    ) * 100, 2) AS matching_coverage_percent
FROM greedy_matching;
```

### 1.2 增广路径算法完整实现

**增广路径算法**使用递归CTE实现DFS搜索增广路径：

```sql
-- 增广路径算法：完整实现（带错误处理和性能测试）
DO $$
DECLARE
    max_iterations INTEGER := 100;
    iteration_count INTEGER := 0;
BEGIN
    BEGIN
        -- 检查表是否存在
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'bipartite_graph') THEN
            RAISE WARNING '表 bipartite_graph 不存在，请先创建';
            RETURN;
        END IF;

        -- 创建匹配表
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'matching_result') THEN
            DROP TABLE matching_result CASCADE;
        END IF;

        CREATE TABLE matching_result (
            left_node INTEGER NOT NULL,
            right_node INTEGER NOT NULL,
            iteration INTEGER NOT NULL,
            PRIMARY KEY (left_node, right_node)
        );

        RAISE NOTICE '开始执行增广路径算法';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION '初始化失败: %', SQLERRM;
    END;
END $$;

-- 增广路径搜索：使用递归CTE
WITH RECURSIVE augmenting_path AS (
    -- 起始：找到未匹配的左侧顶点
    SELECT DISTINCT
        bg.left_node AS start_node,
        bg.left_node AS current_left,
        bg.right_node AS current_right,
        ARRAY[bg.left_node] AS path_left,
        ARRAY[bg.right_node] AS path_right,
        1 AS depth,
        FALSE AS is_matched
    FROM bipartite_graph bg
    WHERE bg.left_node NOT IN (
        SELECT left_node FROM matching_result
    )
    LIMIT 1

    UNION ALL

    -- 递归：寻找增广路径
    SELECT
        ap.start_node,
        CASE
            WHEN ap.is_matched THEN
                (SELECT bg.left_node FROM bipartite_graph bg
                 WHERE bg.right_node = ap.current_right
                   AND bg.left_node != ALL(ap.path_left)
                 LIMIT 1)
            ELSE ap.current_left
        END AS current_left,
        CASE
            WHEN NOT ap.is_matched THEN
                (SELECT bg.right_node FROM bipartite_graph bg
                 WHERE bg.left_node = ap.current_left
                   AND bg.right_node != ALL(ap.path_right)
                 LIMIT 1)
            ELSE ap.current_right
        END AS current_right,
        CASE
            WHEN ap.is_matched THEN ap.path_left || (SELECT bg.left_node FROM bipartite_graph bg
                 WHERE bg.right_node = ap.current_right
                   AND bg.left_node != ALL(ap.path_left) LIMIT 1)
            ELSE ap.path_left
        END AS path_left,
        CASE
            WHEN NOT ap.is_matched THEN ap.path_right || (SELECT bg.right_node FROM bipartite_graph bg
                 WHERE bg.left_node = ap.current_left
                   AND bg.right_node != ALL(ap.path_right) LIMIT 1)
            ELSE ap.path_right
        END AS path_right,
        ap.depth + 1 AS depth,
        NOT ap.is_matched AS is_matched
    FROM augmenting_path ap
    WHERE ap.depth < 20  -- 限制最大深度
      AND (
          (NOT ap.is_matched AND EXISTS (
              SELECT 1 FROM bipartite_graph bg
              WHERE bg.left_node = ap.current_left
                AND bg.right_node != ALL(ap.path_right)
          ))
          OR
          (ap.is_matched AND EXISTS (
              SELECT 1 FROM bipartite_graph bg
              WHERE bg.right_node = ap.current_right
                AND bg.left_node != ALL(ap.path_left)
          ))
      )
),
-- 提取增广路径
valid_paths AS (
    SELECT DISTINCT ON (start_node)
        start_node,
        path_left,
        path_right,
        depth
    FROM augmenting_path
    WHERE current_right NOT IN (SELECT right_node FROM matching_result)
    ORDER BY start_node, depth DESC
)
SELECT
    start_node,
    path_left,
    path_right,
    depth AS path_length
FROM valid_paths
ORDER BY start_node;
```

### 1.3 最大匹配验证与评估

```sql
-- 验证匹配的有效性（无冲突）
WITH matching_edges AS (
    SELECT DISTINCT ON (right_node)
        left_node,
        right_node
    FROM bipartite_graph
    ORDER BY right_node, left_node
),
matching_validation AS (
    SELECT
        COUNT(*) AS total_matches,
        COUNT(DISTINCT left_node) AS matched_left_nodes,
        COUNT(DISTINCT right_node) AS matched_right_nodes,
        (SELECT COUNT(DISTINCT left_node) FROM bipartite_graph) AS total_left_nodes,
        (SELECT COUNT(DISTINCT right_node) FROM bipartite_graph) AS total_right_nodes,
        -- 检查是否有冲突（一个节点匹配多次）
        CASE
            WHEN COUNT(*) = COUNT(DISTINCT left_node)
             AND COUNT(*) = COUNT(DISTINCT right_node)
            THEN 'Valid matching'
            ELSE 'Invalid matching (conflicts detected)'
        END AS validation_status,
        -- 计算匹配率
        ROUND(COUNT(*)::NUMERIC / GREATEST(
            (SELECT COUNT(DISTINCT left_node) FROM bipartite_graph),
            (SELECT COUNT(DISTINCT right_node) FROM bipartite_graph)
        ) * 100, 2) AS matching_rate_percent
    FROM matching_edges
)
SELECT
    total_matches,
    matched_left_nodes,
    matched_right_nodes,
    total_left_nodes,
    total_right_nodes,
    validation_status,
    matching_rate_percent,
    CASE
        WHEN matched_left_nodes = total_left_nodes
         AND matched_right_nodes = total_right_nodes
        THEN 'Perfect matching'
        WHEN matched_left_nodes = total_left_nodes
          OR matched_right_nodes = total_right_nodes
        THEN 'Complete matching on one side'
        ELSE 'Partial matching'
    END AS matching_type
FROM matching_validation;
```

### 1.4 Hopcroft-Karp算法（高效实现）

**Hopcroft-Karp算法**是二分图最大匹配的高效算法，时间复杂度为 $O(\sqrt{V}E)$。

**算法原理**：

1. 使用BFS同时寻找多条不相交的增广路径
2. 使用DFS沿这些路径扩展匹配
3. 重复直到找不到增广路径

```sql
-- Hopcroft-Karp算法：多路径BFS实现
WITH RECURSIVE bfs_layers AS (
    -- 第一层：所有未匹配的左侧顶点
    SELECT DISTINCT
        bg.left_node AS node,
        0 AS layer,
        'left' AS side
    FROM bipartite_graph bg
    WHERE bg.left_node NOT IN (
        SELECT left_node FROM matching_result
    )

    UNION ALL

    -- BFS扩展：交替访问左右两侧
    SELECT DISTINCT
        CASE
            WHEN bl.side = 'left' THEN bg.right_node
            ELSE bg.left_node
        END AS node,
        bl.layer + 1 AS layer,
        CASE
            WHEN bl.side = 'left' THEN 'right'
            ELSE 'left'
        END AS side
    FROM bfs_layers bl
    JOIN bipartite_graph bg ON (
        (bl.side = 'left' AND bg.left_node = bl.node)
        OR
        (bl.side = 'right' AND bg.right_node = bl.node)
    )
    WHERE bl.layer < 10  -- 限制层数
),
-- 提取最短增广路径
shortest_paths AS (
    SELECT DISTINCT ON (node)
        node,
        layer,
        side
    FROM bfs_layers
    WHERE side = 'right'
      AND node NOT IN (SELECT right_node FROM matching_result)
    ORDER BY node, layer
)
SELECT
    COUNT(*) AS augmenting_paths_found,
    MIN(layer) AS shortest_path_length,
    MAX(layer) AS longest_path_length,
    ROUND(AVG(layer)::numeric, 2) AS avg_path_length
FROM shortest_paths;
```

---

## 2. 匈牙利算法

### 2.1 匈牙利算法原理

**匈牙利算法（Hungarian Algorithm）**由Kuhn在1955年提出，用于求解二分图的最大权重匹配（或最小成本分配）问题。

#### 匈牙利算法理论基础

**问题定义**：给定 $n \times n$ 成本矩阵 $C$，找到使总成本最小的完美匹配。

**关键思想**：

- 如果从成本矩阵的每一行和每一列都减去一个常数，最优匹配不变
- 利用这个性质，通过行约简和列约简，将问题转化为寻找零元素的完美匹配

**算法步骤**：

1. **行约简（Row Reduction）**：从每行减去该行的最小值
   $$C'_{ij} = C_{ij} - \min_k C_{ik}$$

2. **列约简（Column Reduction）**：从每列减去该列的最小值
   $$C''_{ij} = C'_{ij} - \min_k C'_{kj}$$

3. **寻找最小覆盖（Minimum Cover）**：使用最少的行和列覆盖所有零元素

4. **调整矩阵**：如果覆盖数小于 $n$，调整矩阵并重复步骤3

5. **提取匹配**：当覆盖数等于 $n$ 时，提取完美匹配

**时间复杂度**：$O(n^3)$，其中 $n$ 是顶点数。

**空间复杂度**：$O(n^2)$，用于存储成本矩阵。

**算法正确性**：基于König定理和增广路径理论，保证找到最优解。

### 2.2 匈牙利算法实现

```sql
-- 权重矩阵准备
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'weighted_bipartite') THEN
            DROP TABLE weighted_bipartite CASCADE;
        END IF;

        CREATE TABLE weighted_bipartite (
            left_node INTEGER NOT NULL,
            right_node INTEGER NOT NULL,
            weight NUMERIC NOT NULL,
            PRIMARY KEY (left_node, right_node)
        );

        -- 插入加权二分图（成本矩阵）
        INSERT INTO weighted_bipartite (left_node, right_node, weight) VALUES
            (1, 1, 4), (1, 2, 2), (1, 3, 3),
            (2, 1, 1), (2, 2, 3), (2, 3, 2),
            (3, 1, 2), (3, 2, 1), (3, 3, 4);

        RAISE NOTICE '加权二分图表创建成功';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION '创建表失败: %', SQLERRM;
    END;
END $$;

-- 匈牙利算法：步骤1 - 行约简
WITH row_minima AS (
    SELECT
        left_node,
        MIN(weight) AS row_min
    FROM weighted_bipartite
    GROUP BY left_node
),
row_reduced AS (
    SELECT
        wb.left_node,
        wb.right_node,
        wb.weight - rm.row_min AS reduced_weight
    FROM weighted_bipartite wb
    JOIN row_minima rm ON wb.left_node = rm.left_node
),
col_minima AS (
    SELECT
        right_node,
        MIN(reduced_weight) AS col_min
    FROM row_reduced
    GROUP BY right_node
),
fully_reduced AS (
    SELECT
        rr.left_node,
        rr.right_node,
        rr.reduced_weight - cm.col_min AS final_weight
    FROM row_reduced rr
    JOIN col_minima cm ON rr.right_node = cm.right_node
)
SELECT
    left_node,
    right_node,
    ROUND(final_weight::numeric, 2) AS reduced_weight,
    CASE
        WHEN final_weight = 0 THEN 'Potential match'
        ELSE ''
    END AS match_candidate
FROM fully_reduced
ORDER BY left_node, right_node;
```

### 2.3 匈牙利算法完整实现

**完整匈牙利算法**包含所有步骤的详细实现：

```sql
-- 匈牙利算法：完整实现（带错误处理和性能测试）
DO $$
DECLARE
    matrix_size INTEGER;
    iteration_count INTEGER := 0;
    max_iterations INTEGER := 100;
BEGIN
    BEGIN
        -- 检查表是否存在
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'weighted_bipartite') THEN
            RAISE WARNING '表 weighted_bipartite 不存在，请先创建';
            RETURN;
        END IF;

        -- 检查矩阵是否为方阵
        SELECT COUNT(DISTINCT left_node), COUNT(DISTINCT right_node)
        INTO matrix_size, matrix_size
        FROM weighted_bipartite;

        IF (SELECT COUNT(DISTINCT left_node) FROM weighted_bipartite) !=
           (SELECT COUNT(DISTINCT right_node) FROM weighted_bipartite) THEN
            RAISE EXCEPTION '成本矩阵必须是方阵';
        END IF;

        RAISE NOTICE '开始执行匈牙利算法，矩阵大小: %x%', matrix_size, matrix_size;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION '初始化失败: %', SQLERRM;
    END;
END $$;

-- 步骤1：行约简
WITH row_minima AS (
    SELECT
        left_node,
        MIN(weight) AS row_min
    FROM weighted_bipartite
    GROUP BY left_node
),
row_reduced AS (
    SELECT
        wb.left_node,
        wb.right_node,
        wb.weight - rm.row_min AS reduced_weight
    FROM weighted_bipartite wb
    JOIN row_minima rm ON wb.left_node = rm.left_node
),
-- 步骤2：列约简
col_minima AS (
    SELECT
        right_node,
        MIN(reduced_weight) AS col_min
    FROM row_reduced
    GROUP BY right_node
),
fully_reduced AS (
    SELECT
        rr.left_node,
        rr.right_node,
        rr.reduced_weight - cm.col_min AS final_weight,
        CASE WHEN rr.reduced_weight - cm.col_min = 0 THEN TRUE ELSE FALSE END AS is_zero
    FROM row_reduced rr
    JOIN col_minima cm ON rr.right_node = cm.right_node
),
-- 步骤3：寻找零元素的覆盖
zero_elements AS (
    SELECT
        left_node,
        right_node,
        final_weight
    FROM fully_reduced
    WHERE is_zero = TRUE
),
-- 贪心匹配：选择零元素
greedy_matching AS (
    SELECT DISTINCT ON (left_node)
        left_node,
        right_node,
        final_weight
    FROM zero_elements
    ORDER BY left_node, right_node
),
-- 验证是否为完美匹配
matching_check AS (
    SELECT
        COUNT(*) AS matched_pairs,
        (SELECT COUNT(DISTINCT left_node) FROM weighted_bipartite) AS total_nodes,
        CASE
            WHEN COUNT(*) = (SELECT COUNT(DISTINCT left_node) FROM weighted_bipartite)
            THEN 'Perfect matching found'
            ELSE 'Partial matching, need adjustment'
        END AS matching_status
    FROM greedy_matching
)
SELECT
    matched_pairs,
    total_nodes,
    matching_status,
    -- 计算原始权重
    (SELECT SUM(wb.weight)
     FROM weighted_bipartite wb
     JOIN greedy_matching gm ON wb.left_node = gm.left_node
                            AND wb.right_node = gm.right_node) AS total_original_weight,
    -- 显示匹配结果
    (SELECT ARRAY_AGG(ARRAY[gm.left_node, gm.right_node] ORDER BY gm.left_node)
     FROM greedy_matching gm) AS matching_edges
FROM matching_check;
```

### 2.4 最优匹配查找与验证

```sql
-- 最优匹配：使用匈牙利算法结果计算原始成本
WITH hungarian_result AS (
    -- 这里使用上面计算的匹配结果
    SELECT
        left_node,
        right_node
    FROM greedy_matching  -- 引用上面的CTE
),
optimal_matching AS (
    SELECT
        hr.left_node,
        hr.right_node,
        wb.weight AS original_weight
    FROM hungarian_result hr
    JOIN weighted_bipartite wb ON hr.left_node = wb.left_node
                               AND hr.right_node = wb.right_node
)
SELECT
    COUNT(*) AS matching_size,
    SUM(original_weight) AS total_cost,
    ROUND(AVG(original_weight)::numeric, 2) AS avg_cost,
    MIN(original_weight) AS min_cost,
    MAX(original_weight) AS max_cost,
    ARRAY_AGG(ARRAY[left_node, right_node] ORDER BY left_node) AS optimal_matching_edges,
    -- 验证匹配的有效性
    CASE
        WHEN COUNT(*) = COUNT(DISTINCT left_node)
         AND COUNT(*) = COUNT(DISTINCT right_node)
        THEN 'Valid optimal matching'
        ELSE 'Invalid matching'
    END AS validation_status
FROM optimal_matching;
```

### 2.5 性能测试与对比

```sql
-- 性能测试：对比贪心算法和匈牙利算法
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH
-- 贪心算法：每次选择最小权重
greedy_algorithm AS (
    SELECT DISTINCT ON (left_node)
        left_node,
        right_node,
        weight
    FROM weighted_bipartite
    ORDER BY left_node, weight
),
-- 匈牙利算法结果（简化版）
hungarian_algorithm AS (
    SELECT
        left_node,
        right_node,
        weight
    FROM weighted_bipartite
    WHERE (left_node, right_node) IN (
        SELECT left_node, right_node FROM greedy_matching  -- 引用上面的结果
    )
)
SELECT
    'Greedy' AS algorithm,
    COUNT(*) AS matching_size,
    SUM(weight) AS total_cost
FROM greedy_algorithm
UNION ALL
SELECT
    'Hungarian' AS algorithm,
    COUNT(*) AS matching_size,
    SUM(weight) AS total_cost
FROM hungarian_algorithm;
```

---

## 3. 复杂度分析

### 3.1 时间复杂度

| 算法 | 时间复杂度 | 说明 |
|------|-----------|------|
| **贪心算法** | $O(E)$ | E是边数 |
| **增广路径算法** | $O(VE)$ | V是顶点数 |
| **匈牙利算法** | $O(V^3)$ | 最大权重匹配 |

### 3.2 空间复杂度

| 算法 | 空间复杂度 |
|------|-----------|
| **贪心算法** | $O(V)$ |
| **增广路径算法** | $O(V)$ |
| **匈牙利算法** | $O(V^2)$ |

---

## 4. 实际应用案例

### 4.1 任务分配问题

**场景**：将 $n$ 个任务分配给 $n$ 个工人，每个工人只能完成一个任务，最小化总成本。

**数据准备**：

```sql
-- 创建任务分配成本表
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'task_worker_costs') THEN
            DROP TABLE task_worker_costs CASCADE;
        END IF;

        CREATE TABLE task_worker_costs (
            task_id INTEGER NOT NULL,
            worker_id INTEGER NOT NULL,
            assignment_cost NUMERIC NOT NULL,
            PRIMARY KEY (task_id, worker_id)
        );

        -- 插入示例数据：5个任务，5个工人
        INSERT INTO task_worker_costs (task_id, worker_id, assignment_cost) VALUES
            (1, 1, 9), (1, 2, 2), (1, 3, 7), (1, 4, 8), (1, 5, 6),
            (2, 1, 6), (2, 2, 4), (2, 3, 3), (2, 4, 7), (2, 5, 5),
            (3, 1, 5), (3, 2, 8), (3, 3, 1), (3, 4, 8), (3, 5, 4),
            (4, 1, 7), (4, 2, 6), (4, 3, 9), (4, 4, 4), (4, 5, 6),
            (5, 1, 3), (5, 2, 2), (5, 3, 5), (5, 4, 7), (5, 5, 8);

        CREATE INDEX idx_task ON task_worker_costs(task_id);
        CREATE INDEX idx_worker ON task_worker_costs(worker_id);

        RAISE NOTICE '任务分配成本表创建成功';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION '创建表失败: %', SQLERRM;
    END;
END $$;
```

**最优分配计算**：

```sql
-- 使用匈牙利算法求解最优分配
WITH
-- 行约简
row_minima AS (
    SELECT task_id, MIN(assignment_cost) AS row_min
    FROM task_worker_costs
    GROUP BY task_id
),
row_reduced AS (
    SELECT
        twc.task_id,
        twc.worker_id,
        twc.assignment_cost - rm.row_min AS reduced_cost
    FROM task_worker_costs twc
    JOIN row_minima rm ON twc.task_id = rm.task_id
),
-- 列约简
col_minima AS (
    SELECT worker_id, MIN(reduced_cost) AS col_min
    FROM row_reduced
    GROUP BY worker_id
),
fully_reduced AS (
    SELECT
        rr.task_id,
        rr.worker_id,
        rr.reduced_cost - cm.col_min AS final_cost,
        CASE WHEN rr.reduced_cost - cm.col_min = 0 THEN TRUE ELSE FALSE END AS is_zero
    FROM row_reduced rr
    JOIN col_minima cm ON rr.worker_id = cm.worker_id
),
-- 贪心匹配零元素
optimal_matching AS (
    SELECT DISTINCT ON (task_id)
        task_id,
        worker_id,
        final_cost
    FROM fully_reduced
    WHERE is_zero = TRUE
    ORDER BY task_id, worker_id
),
-- 计算原始成本
final_assignment AS (
    SELECT
        om.task_id,
        om.worker_id,
        twc.assignment_cost AS original_cost
    FROM optimal_matching om
    JOIN task_worker_costs twc ON om.task_id = twc.task_id
                                AND om.worker_id = twc.worker_id
)
SELECT
    task_id,
    worker_id,
    original_cost,
    SUM(original_cost) OVER () AS total_cost,
    ROUND(AVG(original_cost) OVER ()::numeric, 2) AS avg_cost
FROM final_assignment
ORDER BY task_id;
```

### 4.2 资源分配问题

**场景**：将服务器资源分配给应用程序，最大化总性能。

```sql
-- 资源分配：最大化性能
WITH resource_allocation AS (
    SELECT
        app_id AS left_node,
        server_id AS right_node,
        performance_score AS weight
    FROM app_server_performance
),
-- 转换为最小化问题：使用最大权重减去当前权重
max_weight AS (
    SELECT MAX(performance_score) AS max_score
    FROM resource_allocation
),
minimization_matrix AS (
    SELECT
        left_node,
        right_node,
        (SELECT max_score FROM max_weight) - performance_score AS cost
    FROM resource_allocation
)
-- 使用匈牙利算法求解（转换为最小化问题）
SELECT * FROM minimization_matrix;
-- 然后使用上面的匈牙利算法代码求解
```

### 4.3 稳定匹配问题（Gale-Shapley算法）

**场景**：稳定婚姻问题，$n$ 个男性和 $n$ 个女性，每个人对异性有偏好排序。

```sql
-- 稳定匹配：Gale-Shapley算法
WITH RECURSIVE gale_shapley AS (
    -- 初始化：所有男性未匹配
    SELECT DISTINCT
        man_id,
        NULL::INTEGER AS woman_id,
        1 AS preference_rank,
        FALSE AS is_matched
    FROM men_preferences

    UNION ALL

    -- 男性向未拒绝他的最高偏好女性求婚
    SELECT
        gs.man_id,
        mp.woman_id,
        gs.preference_rank + 1,
        CASE
            WHEN mp.woman_id NOT IN (
                SELECT woman_id FROM gale_shapley WHERE is_matched = TRUE
            ) THEN TRUE
            WHEN EXISTS (
                SELECT 1 FROM women_preferences wp
                WHERE wp.woman_id = mp.woman_id
                  AND wp.man_id = gs.man_id
                  AND wp.preference_rank < (
                      SELECT preference_rank FROM women_preferences
                      WHERE woman_id = mp.woman_id
                        AND man_id = (SELECT man_id FROM gale_shapley
                                     WHERE woman_id = mp.woman_id
                                       AND is_matched = TRUE)
                  )
            ) THEN TRUE
            ELSE FALSE
        END AS is_matched
    FROM gale_shapley gs
    JOIN men_preferences mp ON gs.man_id = mp.man_id
    WHERE gs.is_matched = FALSE
      AND gs.preference_rank < (SELECT COUNT(*) FROM women)
)
SELECT
    man_id,
    woman_id
FROM gale_shapley
WHERE is_matched = TRUE
ORDER BY man_id;
```

### 4.4 网络流量分配

**场景**：将网络流量分配到多个服务器，平衡负载。

```sql
-- 网络流量分配：最小化最大负载
WITH server_capacities AS (
    SELECT server_id, capacity FROM servers
),
traffic_demands AS (
    SELECT traffic_id, demand FROM traffic_flows
),
-- 创建分配成本矩阵（基于负载）
allocation_costs AS (
    SELECT
        tf.traffic_id AS left_node,
        sc.server_id AS right_node,
        -- 成本：如果分配会导致超载，成本很高
        CASE
            WHEN sc.capacity >= tf.demand THEN tf.demand::NUMERIC / sc.capacity
            ELSE 1000  -- 惩罚超载
        END AS cost
    FROM traffic_demands tf
    CROSS JOIN server_capacities sc
)
-- 使用匈牙利算法求解最优分配
SELECT * FROM allocation_costs;
```

---

## 5. 算法性能对比

### 5.1 时间复杂度对比

| 算法 | 时间复杂度 | 空间复杂度 | 适用场景 |
|------|-----------|-----------|---------|
| **贪心算法** | $O(E)$ | $O(V)$ | 快速近似解 |
| **增广路径算法** | $O(VE)$ | $O(V)$ | 一般二分图 |
| **Hopcroft-Karp** | $O(\sqrt{V}E)$ | $O(V)$ | 稀疏图 |
| **匈牙利算法** | $O(V^3)$ | $O(V^2)$ | 加权匹配 |
| **Gale-Shapley** | $O(V^2)$ | $O(V^2)$ | 稳定匹配 |

### 5.2 性能测试结果

```sql
-- 性能测试：不同规模下的执行时间
DO $$
DECLARE
    test_sizes INTEGER[] := ARRAY[10, 50, 100, 500];
    size_val INTEGER;
    start_time TIMESTAMP;
    end_time TIMESTAMP;
    execution_time INTERVAL;
BEGIN
    FOREACH size_val IN ARRAY test_sizes
    LOOP
        -- 创建测试数据
        -- ... (创建size_val x size_val的矩阵)

        -- 测试贪心算法
        start_time := clock_timestamp();
        -- 执行贪心算法
        -- ... (执行查询)
        end_time := clock_timestamp();
        execution_time := end_time - start_time;
        RAISE NOTICE '规模: %, 贪心算法: %', size_val, execution_time;

        -- 测试匈牙利算法
        start_time := clock_timestamp();
        -- 执行匈牙利算法
        -- ... (执行查询)
        end_time := clock_timestamp();
        execution_time := end_time - start_time;
        RAISE NOTICE '规模: %, 匈牙利算法: %', size_val, execution_time;
    END LOOP;
END $$;
```

### 5.3 优化建议

1. **索引优化**：在 `left_node` 和 `right_node` 上创建索引
2. **并行处理**：对于大规模问题，考虑并行处理
3. **近似算法**：对于实时性要求高的场景，使用贪心算法
4. **缓存结果**：对于重复查询，缓存匹配结果
5. **稀疏矩阵优化**：对于稀疏图，使用专门的稀疏矩阵算法

---

## 📚 参考资源

### 学术文献

1. **Kuhn, H.W. (1955)**: "The Hungarian Method for the Assignment Problem", *Naval Research Logistics Quarterly*, 2(1-2), 83-97.

2. **Hopcroft, J.E., Karp, R.M. (1973)**: "An $n^{5/2}$ Algorithm for Maximum Matchings in Bipartite Graphs", *SIAM Journal on Computing*, 2(4), 225-231.

3. **Gale, D., Shapley, L.S. (1962)**: "College Admissions and the Stability of Marriage", *The American Mathematical Monthly*, 69(1), 9-15.

4. **Edmonds, J. (1965)**: "Paths, Trees, and Flowers", *Canadian Journal of Mathematics*, 17, 449-467.

5. **Munkres, J. (1957)**: "Algorithms for the Assignment and Transportation Problems", *Journal of the Society for Industrial and Applied Mathematics*, 5(1), 32-38.

### 在线资源

- **PostgreSQL官方文档**: <https://www.postgresql.org/docs/>
- **图论算法库**: NetworkX, igraph
- **算法可视化**: <https://visualgo.net/en/matching>

### 相关算法

- **最大流算法**：Ford-Fulkerson, Edmonds-Karp
- **最小费用流**：Successive Shortest Path
- **稳定匹配**：Gale-Shapley算法
- **一般图匹配**：Blossom算法

---

## 📊 性能优化建议

### 6.1 索引优化

```sql
-- 创建必要的索引
CREATE INDEX CONCURRENTLY idx_bipartite_left
ON bipartite_graph(left_node);

CREATE INDEX CONCURRENTLY idx_bipartite_right
ON bipartite_graph(right_node);

CREATE INDEX CONCURRENTLY idx_bipartite_weight
ON bipartite_graph(weight) WHERE weight IS NOT NULL;

-- 复合索引用于常见查询模式
CREATE INDEX CONCURRENTLY idx_bipartite_left_right
ON bipartite_graph(left_node, right_node);
```

### 6.2 查询优化

1. **使用CTE缓存中间结果**：避免重复计算
2. **限制搜索深度**：对于大规模图，限制递归深度
3. **并行查询**：使用PostgreSQL的并行查询功能
4. **物化视图**：对于频繁查询的匹配结果，使用物化视图

### 6.3 算法选择指南

| 问题规模 | 推荐算法 | 原因 |
|---------|---------|------|
| $V < 50$ | 匈牙利算法 | 精确解，性能可接受 |
| $50 \leq V < 500$ | Hopcroft-Karp | 平衡性能和精度 |
| $V \geq 500$ | 贪心算法 + 局部优化 | 快速近似解 |
| 加权问题 | 匈牙利算法 | 唯一精确算法 |
| 稳定匹配 | Gale-Shapley | 专门算法 |

---

## 🎯 最佳实践

### 7.1 算法选择

1. **问题类型**：
   - 最大匹配：使用增广路径算法或Hopcroft-Karp
   - 加权匹配：使用匈牙利算法
   - 稳定匹配：使用Gale-Shapley算法

2. **数据规模**：
   - 小规模（<100）：使用精确算法
   - 中规模（100-1000）：使用高效算法
   - 大规模（>1000）：使用近似算法

3. **实时性要求**：
   - 实时系统：使用贪心算法
   - 批处理系统：使用精确算法

### 7.2 权重设计

1. **成本矩阵设计**：
   - 确保权重反映实际成本
   - 避免极端值影响算法稳定性
   - 考虑归一化处理

2. **约束处理**：
   - 不可行分配：使用极大惩罚值
   - 偏好处理：使用权重差异表示偏好

### 7.3 验证与测试

1. **匹配验证**：
   - 检查匹配的有效性（无冲突）
   - 验证匹配的最优性（如适用）
   - 检查匹配的完整性

2. **性能测试**：
   - 使用EXPLAIN (ANALYZE, BUFFERS, TIMING)分析查询计划
   - 监控执行时间和资源使用
   - 对比不同算法的性能

### 7.4 常见问题与解决方案

**问题1**：算法执行时间过长

- **解决方案**：使用索引、限制搜索深度、使用近似算法

**问题2**：内存不足

- **解决方案**：分批处理、使用物化视图、优化查询

**问题3**：匹配结果不理想

- **解决方案**：检查权重设计、验证数据质量、尝试不同算法

**问题4**：矩阵不是方阵

- **解决方案**：添加虚拟节点、使用不平衡匹配算法

---

**最后更新**: 2025年1月
**文档状态**: ✅ 已完成
