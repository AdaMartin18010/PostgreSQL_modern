# PostgreSQL æ¢¯åº¦æå‡ç®—æ³•å®Œæ•´æŒ‡å—

> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´1æœˆ
> **æŠ€æœ¯æ ˆ**: PostgreSQL 17+/18+ | æœºå™¨å­¦ä¹  | æ¢¯åº¦æå‡ | Boosting
> **éš¾åº¦çº§åˆ«**: â­â­â­â­â­ (ä¸“å®¶çº§)
> **å‚è€ƒæ ‡å‡†**: Gradient Boosting (Friedman), XGBoost, LightGBM, Machine Learning

---

## ğŸ“‹ ç›®å½•

- [PostgreSQL æ¢¯åº¦æå‡ç®—æ³•å®Œæ•´æŒ‡å—](#postgresql-æ¢¯åº¦æå‡ç®—æ³•å®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ¢¯åº¦æå‡æ¦‚è¿°](#æ¢¯åº¦æå‡æ¦‚è¿°)
    - [ç†è®ºåŸºç¡€](#ç†è®ºåŸºç¡€)
    - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
    - [ç®—æ³•æµç¨‹](#ç®—æ³•æµç¨‹)
  - [1. æ¢¯åº¦æå‡åŸç†](#1-æ¢¯åº¦æå‡åŸç†)
    - [1.1 åŠ æ³•æ¨¡å‹](#11-åŠ æ³•æ¨¡å‹)
    - [1.2 å‰å‘åˆ†æ­¥ç®—æ³•](#12-å‰å‘åˆ†æ­¥ç®—æ³•)
    - [1.3 æ¢¯åº¦ä¸‹é™](#13-æ¢¯åº¦ä¸‹é™)
  - [2. GBDTå®ç°](#2-gbdtå®ç°)
    - [2.1 å›å½’æ ‘æ„å»º](#21-å›å½’æ ‘æ„å»º)
    - [2.2 è´Ÿæ¢¯åº¦è®¡ç®—](#22-è´Ÿæ¢¯åº¦è®¡ç®—)
    - [2.3 æ¨¡å‹æ›´æ–°](#23-æ¨¡å‹æ›´æ–°)
  - [3. XGBoostä¼˜åŒ–](#3-xgboostä¼˜åŒ–)
    - [3.1 äºŒé˜¶æ¢¯åº¦](#31-äºŒé˜¶æ¢¯åº¦)
    - [3.2 æ­£åˆ™åŒ–](#32-æ­£åˆ™åŒ–)
    - [3.3 å¹¶è¡ŒåŒ–](#33-å¹¶è¡ŒåŒ–)
  - [4. LightGBMç‰¹æ€§](#4-lightgbmç‰¹æ€§)
    - [4.1 ç›´æ–¹å›¾ç®—æ³•](#41-ç›´æ–¹å›¾ç®—æ³•)
    - [4.2 å¶å­ä¼˜å…ˆ](#42-å¶å­ä¼˜å…ˆ)
  - [5. å¤æ‚åº¦åˆ†æ](#5-å¤æ‚åº¦åˆ†æ)
  - [6. PostgreSQL 18 å¹¶è¡Œæ¢¯åº¦æå‡å¢å¼º](#6-postgresql-18-å¹¶è¡Œæ¢¯åº¦æå‡å¢å¼º)
    - [6.1 å¹¶è¡Œæ¢¯åº¦æå‡åŸç†](#61-å¹¶è¡Œæ¢¯åº¦æå‡åŸç†)
    - [6.2 å¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—](#62-å¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—)
    - [6.3 å¹¶è¡Œå›å½’æ ‘æ„å»º](#63-å¹¶è¡Œå›å½’æ ‘æ„å»º)
  - [7. å®é™…åº”ç”¨æ¡ˆä¾‹](#7-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [6.1 å›å½’ä»»åŠ¡](#61-å›å½’ä»»åŠ¡)
    - [6.2 åˆ†ç±»ä»»åŠ¡](#62-åˆ†ç±»ä»»åŠ¡)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
  - [ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®](#-æ€§èƒ½ä¼˜åŒ–å»ºè®®)
  - [ğŸ¯ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
    - [SQLå®ç°æ³¨æ„äº‹é¡¹](#sqlå®ç°æ³¨æ„äº‹é¡¹)
    - [PostgreSQL 18 æ–°ç‰¹æ€§åº”ç”¨ï¼ˆå¢å¼ºï¼‰](#postgresql-18-æ–°ç‰¹æ€§åº”ç”¨å¢å¼º)
    - [é«˜çº§ä¼˜åŒ–æŠ€å·§ï¼ˆå¢å¼ºï¼‰](#é«˜çº§ä¼˜åŒ–æŠ€å·§å¢å¼º)

---

## æ¢¯åº¦æå‡æ¦‚è¿°

**æ¢¯åº¦æå‡ï¼ˆGradient Boostingï¼‰**æ˜¯ä¸€ç§å¼ºå¤§çš„é›†æˆå­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡é€æ­¥æ·»åŠ å¼±å­¦ä¹ å™¨æ¥ä¼˜åŒ–æŸå¤±å‡½æ•°ã€‚

### ç†è®ºåŸºç¡€

æ¢¯åº¦æå‡å°†**Boosting**å’Œ**æ¢¯åº¦ä¸‹é™**ç›¸ç»“åˆï¼Œé€šè¿‡è¿­ä»£åœ°æ·»åŠ æ¨¡å‹æ¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚

### æ ¸å¿ƒæ€æƒ³

**ç®—æ³•æ ¸å¿ƒ**:

1. åˆå§‹åŒ–æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯å¸¸æ•°ï¼‰
2. è®¡ç®—å½“å‰æ¨¡å‹çš„æ®‹å·®ï¼ˆè´Ÿæ¢¯åº¦ï¼‰
3. ç”¨æ®‹å·®è®­ç»ƒæ–°çš„å¼±å­¦ä¹ å™¨
4. å°†æ–°å­¦ä¹ å™¨æ·»åŠ åˆ°æ¨¡å‹ä¸­
5. é‡å¤æ­¥éª¤2-4ç›´åˆ°æ”¶æ•›

### ç®—æ³•æµç¨‹

**ä¼ªä»£ç **:

```
F_0(x) = argmin_Î³ Î£ L(y_i, Î³)
For m = 1 to M:
    r_im = -âˆ‚L(y_i, F_{m-1}(x_i))/âˆ‚F_{m-1}(x_i)
    h_m(x) = argmin_h Î£ (r_im - h(x_i))^2
    Î³_m = argmin_Î³ Î£ L(y_i, F_{m-1}(x_i) + Î³h_m(x_i))
    F_m(x) = F_{m-1}(x) + Î³_m h_m(x)
```

---

## 1. æ¢¯åº¦æå‡åŸç†

### 1.1 åŠ æ³•æ¨¡å‹

**åŠ æ³•æ¨¡å‹**:
$$F(x) = \sum_{m=0}^{M} \gamma_m h_m(x)$$

å…¶ä¸­ï¼š

- $h_m(x)$ æ˜¯ç¬¬ $m$ ä¸ªå¼±å­¦ä¹ å™¨
- $\gamma_m$ æ˜¯ç¬¬ $m$ ä¸ªå­¦ä¹ å™¨çš„æƒé‡

### 1.2 å‰å‘åˆ†æ­¥ç®—æ³•

**å‰å‘åˆ†æ­¥ç®—æ³•**é€æ­¥æ·»åŠ æ¨¡å‹ï¼š

$$F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)$$

æ¯ä¸€æ­¥éƒ½ä¼˜åŒ–ï¼š
$$\gamma_m, h_m = \arg\min_{\gamma, h} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + \gamma h(x_i))$$

### 1.3 æ¢¯åº¦ä¸‹é™

**æ¢¯åº¦ä¸‹é™**ç”¨äºä¼˜åŒ–æŸå¤±å‡½æ•°ï¼š

$$r_{im} = -\left[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right]_{F(x)=F_{m-1}(x)}$$

**è´Ÿæ¢¯åº¦**å°±æ˜¯å½“å‰æ¨¡å‹çš„æ®‹å·®ã€‚

```sql
-- æ¢¯åº¦æå‡æ•°æ®å‡†å¤‡ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'gb_training_data') THEN
            RAISE WARNING 'è¡¨ gb_training_data å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤';
            DROP TABLE gb_training_data CASCADE;
        END IF;

        CREATE TABLE gb_training_data (
            id SERIAL PRIMARY KEY,
            feature1 NUMERIC NOT NULL,
            feature2 NUMERIC NOT NULL,
            target NUMERIC NOT NULL
        );

        -- æ’å…¥è®­ç»ƒæ•°æ®
        INSERT INTO gb_training_data (feature1, feature2, target) VALUES
            (1.0, 2.0, 5.0), (1.5, 2.5, 6.0),
            (2.0, 3.0, 7.0), (2.5, 3.5, 8.0),
            (3.0, 4.0, 9.0), (3.5, 4.5, 10.0);

        RAISE NOTICE 'è¡¨ gb_training_data åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'è¡¨ gb_training_data å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE EXCEPTION 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;
```

---

## 2. GBDTå®ç°

### 2.1 å›å½’æ ‘æ„å»º

**GBDTï¼ˆGradient Boosting Decision Treeï¼‰**ä½¿ç”¨å›å½’æ ‘ä½œä¸ºå¼±å­¦ä¹ å™¨ã€‚

```sql
-- GBDTåˆå§‹æ¨¡å‹ï¼ˆå‡å€¼ï¼‰
WITH initial_prediction AS (
    SELECT
        id,
        target,
        AVG(target) OVER () AS initial_pred
    FROM gb_training_data
)
SELECT
    id,
    target,
    ROUND(initial_pred::numeric, 4) AS initial_prediction,
    target - initial_pred AS residual
FROM initial_prediction;
```

### 2.2 è´Ÿæ¢¯åº¦è®¡ç®—

**è´Ÿæ¢¯åº¦è®¡ç®—**ï¼ˆå¯¹äºå¹³æ–¹æŸå¤±ï¼Œè´Ÿæ¢¯åº¦å°±æ˜¯æ®‹å·®ï¼‰ï¼š

```sql
-- è´Ÿæ¢¯åº¦ï¼ˆæ®‹å·®ï¼‰è®¡ç®—
WITH current_predictions AS (
    SELECT
        id,
        target,
        current_prediction
    FROM model_predictions
),
residuals AS (
    SELECT
        id,
        target,
        current_prediction,
        target - current_prediction AS residual,
        -(target - current_prediction) AS negative_gradient
    FROM current_predictions
)
SELECT
    id,
    ROUND(residual::numeric, 4) AS residual,
    ROUND(negative_gradient::numeric, 4) AS negative_gradient
FROM residuals
ORDER BY id;
```

### 2.3 æ¨¡å‹æ›´æ–°

**æ¨¡å‹æ›´æ–°**ï¼š
$$F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)$$

```sql
-- æ¨¡å‹æ›´æ–°
WITH tree_predictions AS (
    SELECT
        id,
        tree_prediction
    FROM regression_tree_output
),
updated_model AS (
    SELECT
        mp.id,
        mp.current_prediction,
        tp.tree_prediction,
        0.1 AS learning_rate,
        mp.current_prediction + 0.1 * tp.tree_prediction AS updated_prediction
    FROM model_predictions mp
    JOIN tree_predictions tp ON mp.id = tp.id
)
SELECT
    id,
    ROUND(current_prediction::numeric, 4) AS old_prediction,
    ROUND(updated_prediction::numeric, 4) AS new_prediction
FROM updated_model;
```

---

## 3. XGBoostä¼˜åŒ–

### 3.1 äºŒé˜¶æ¢¯åº¦

**XGBoost**ä½¿ç”¨äºŒé˜¶æ³°å‹’å±•å¼€ï¼š

$$L^{(t)} \approx \sum_{i=1}^{n} [L(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i)]$$

å…¶ä¸­ï¼š

- $g_i = \partial_{\hat{y}^{(t-1)}} L(y_i, \hat{y}_i^{(t-1)})$ æ˜¯ä¸€é˜¶æ¢¯åº¦
- $h_i = \partial^2_{\hat{y}^{(t-1)}} L(y_i, \hat{y}_i^{(t-1)})$ æ˜¯äºŒé˜¶æ¢¯åº¦

```sql
-- äºŒé˜¶æ¢¯åº¦è®¡ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰
WITH gradients AS (
    SELECT
        id,
        target,
        prediction,
        target - prediction AS first_order_gradient,
        1.0 AS second_order_gradient  -- å¯¹äºå¹³æ–¹æŸå¤±ï¼ŒäºŒé˜¶æ¢¯åº¦ä¸ºå¸¸æ•°
    FROM model_predictions
)
SELECT
    id,
    ROUND(first_order_gradient::numeric, 4) AS g_i,
    ROUND(second_order_gradient::numeric, 4) AS h_i
FROM gradients;
```

### 3.2 æ­£åˆ™åŒ–

**XGBoostæ­£åˆ™åŒ–**ï¼š
$$\Omega(f_t) = \gamma T + \frac{1}{2}\lambda ||w||^2$$

å…¶ä¸­ï¼š

- $T$ æ˜¯å¶å­èŠ‚ç‚¹æ•°
- $w$ æ˜¯å¶å­èŠ‚ç‚¹æƒé‡
- $\gamma$ å’Œ $\lambda$ æ˜¯æ­£åˆ™åŒ–å‚æ•°

### 3.3 å¹¶è¡ŒåŒ–

**XGBoostå¹¶è¡ŒåŒ–**ï¼š

- ç‰¹å¾å¹¶è¡Œï¼šä¸åŒç‰¹å¾åœ¨ä¸åŒæœºå™¨ä¸Šè®¡ç®—
- æ•°æ®å¹¶è¡Œï¼šä¸åŒæ•°æ®åœ¨ä¸åŒæœºå™¨ä¸Šè®¡ç®—
- è¿‘ä¼¼ç®—æ³•ï¼šä½¿ç”¨ç›´æ–¹å›¾åŠ é€Ÿ

---

## 4. LightGBMç‰¹æ€§

### 4.1 ç›´æ–¹å›¾ç®—æ³•

**ç›´æ–¹å›¾ç®—æ³•**å°†è¿ç»­ç‰¹å¾ç¦»æ•£åŒ–ä¸ºç›´æ–¹å›¾ï¼ŒåŠ é€Ÿåˆ†è£‚ç‚¹æŸ¥æ‰¾ã€‚

```sql
-- ç›´æ–¹å›¾æ„å»ºï¼ˆç®€åŒ–ç‰ˆï¼‰
WITH feature_bins AS (
    SELECT
        feature1,
        WIDTH_BUCKET(feature1, 0, 10, 10) AS bin_id
    FROM gb_training_data
),
histogram AS (
    SELECT
        bin_id,
        COUNT(*) AS bin_count,
        AVG(target) AS bin_mean
    FROM feature_bins
    GROUP BY bin_id
)
SELECT
    bin_id,
    bin_count,
    ROUND(bin_mean::numeric, 4) AS bin_mean_value
FROM histogram
ORDER BY bin_id;
```

### 4.2 å¶å­ä¼˜å…ˆ

**Leaf-wiseç”Ÿé•¿**ç­–ç•¥ï¼Œæ¯æ¬¡é€‰æ‹©å¢ç›Šæœ€å¤§çš„å¶å­èŠ‚ç‚¹è¿›è¡Œåˆ†è£‚ã€‚

---

## 5. å¤æ‚åº¦åˆ†æ

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç‰¹ç‚¹ |
|------|-----------|-----------|------|
| **GBDT** | $O(Mn \log n)$ | $O(n)$ | åŸºç¡€ç®—æ³• |
| **XGBoost** | $O(Mn \log n)$ | $O(n)$ | äºŒé˜¶æ¢¯åº¦ä¼˜åŒ– |
| **LightGBM** | $O(Mn)$ | $O(n)$ | ç›´æ–¹å›¾åŠ é€Ÿ |

å…¶ä¸­ $M$ æ˜¯æ ‘çš„æ•°é‡ï¼Œ$n$ æ˜¯æ ·æœ¬æ•°ã€‚

---

## 6. PostgreSQL 18 å¹¶è¡Œæ¢¯åº¦æå‡å¢å¼º

**PostgreSQL 18** æ˜¾è‘—å¢å¼ºäº†å¹¶è¡Œæ¢¯åº¦æå‡è®¡ç®—èƒ½åŠ›ï¼Œæ”¯æŒå¹¶è¡Œæ‰§è¡Œè´Ÿæ¢¯åº¦è®¡ç®—ã€å›å½’æ ‘æ„å»ºå’Œæ¨¡å‹æ›´æ–°ï¼Œå¤§å¹…æå‡å¤§è§„æ¨¡æ¢¯åº¦æå‡è®­ç»ƒçš„æ€§èƒ½ã€‚

### 6.1 å¹¶è¡Œæ¢¯åº¦æå‡åŸç†

PostgreSQL 18 çš„å¹¶è¡Œæ¢¯åº¦æå‡é€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°ï¼š

1. **å¹¶è¡Œæ‰«æ**ï¼šå¤šä¸ªå·¥ä½œè¿›ç¨‹å¹¶è¡Œæ‰«æè®­ç»ƒæ•°æ®
2. **å¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—**ï¼šæ¯ä¸ªå·¥ä½œè¿›ç¨‹ç‹¬ç«‹è®¡ç®—è´Ÿæ¢¯åº¦
3. **å¹¶è¡Œæ ‘æ„å»º**ï¼šå¹¶è¡Œæ„å»ºå¤šä¸ªå›å½’æ ‘
4. **ç»“æœåˆå¹¶**ï¼šä¸»è¿›ç¨‹åˆå¹¶æ‰€æœ‰å·¥ä½œè¿›ç¨‹çš„è®¡ç®—ç»“æœ

### 6.2 å¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—

```sql
-- PostgreSQL 18 å¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'gradient_boosting_data') THEN
            RAISE WARNING 'è¡¨ gradient_boosting_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œå¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡ŒPostgreSQL 18å¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'å¹¶è¡Œè´Ÿæ¢¯åº¦è®¡ç®—å‡†å¤‡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;

-- å¹¶è¡Œè´Ÿæ¢¯åº¦ï¼šæ®‹å·®è®¡ç®—
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH residuals AS (
    SELECT
        sample_id,
        actual_value,
        predicted_value,
        actual_value - predicted_value AS residual
    FROM gradient_boosting_data
)
SELECT
    sample_id,
    ROUND(actual_value::numeric, 4) AS actual,
    ROUND(predicted_value::numeric, 4) AS predicted,
    ROUND(residual::numeric, 4) AS negative_gradient
FROM residuals
ORDER BY sample_id;
```

### 6.3 å¹¶è¡Œå›å½’æ ‘æ„å»º

```sql
-- PostgreSQL 18 å¹¶è¡Œå›å½’æ ‘æ„å»ºï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'gradient_boosting_data') THEN
            RAISE WARNING 'è¡¨ gradient_boosting_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œå¹¶è¡Œå›å½’æ ‘æ„å»º';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡ŒPostgreSQL 18å¹¶è¡Œå›å½’æ ‘æ„å»º';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'å¹¶è¡Œå›å½’æ ‘æ„å»ºå‡†å¤‡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;

-- å¹¶è¡Œå›å½’æ ‘ï¼šåˆ†è£‚ç‚¹é€‰æ‹©
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH split_candidates AS (
    SELECT
        feature_idx,
        split_value,
        AVG(residual) FILTER (WHERE feature_value <= split_value) AS left_mean,
        AVG(residual) FILTER (WHERE feature_value > split_value) AS right_mean,
        COUNT(*) FILTER (WHERE feature_value <= split_value) AS left_count,
        COUNT(*) FILTER (WHERE feature_value > split_value) AS right_count
    FROM gradient_boosting_data
    CROSS JOIN generate_series(1, array_length(features, 1)) AS feature_idx
    CROSS JOIN LATERAL (SELECT features[feature_idx] AS feature_value) AS fv
    CROSS JOIN (SELECT generate_series(0, 10, 0.5) AS split_value) AS splits
    GROUP BY feature_idx, split_value
),
split_scores AS (
    SELECT
        feature_idx,
        split_value,
        left_mean,
        right_mean,
        POWER(left_mean, 2) * left_count + POWER(right_mean, 2) * right_count AS split_score
    FROM split_candidates
)
SELECT
    feature_idx,
    split_value,
    ROUND(split_score::numeric, 4) AS score
FROM split_scores
ORDER BY split_score DESC
LIMIT 20;
```

---

## 7. å®é™…åº”ç”¨æ¡ˆä¾‹

### 6.1 å›å½’ä»»åŠ¡

```sql
-- æ¢¯åº¦æå‡å›å½’åº”ç”¨
WITH gb_regression AS (
    SELECT
        test_id,
        SUM(tree_prediction * learning_rate) AS final_prediction
    FROM gradient_boosting_predictions
    GROUP BY test_id
)
SELECT
    test_id,
    ROUND(final_prediction::numeric, 4) AS predicted_value
FROM gb_regression;
```

### 6.2 åˆ†ç±»ä»»åŠ¡

```sql
-- æ¢¯åº¦æå‡åˆ†ç±»åº”ç”¨
WITH gb_classification AS (
    SELECT
        test_id,
        SUM(tree_logit * learning_rate) AS final_logit
    FROM gradient_boosting_predictions
    GROUP BY test_id
),
probabilities AS (
    SELECT
        test_id,
        1.0 / (1.0 + EXP(-final_logit)) AS predicted_probability
    FROM gb_classification
)
SELECT
    test_id,
    ROUND(predicted_probability::numeric, 4) AS probability,
    CASE
        WHEN predicted_probability > 0.5 THEN 1
        ELSE 0
    END AS predicted_class
FROM probabilities;
```

---

## ğŸ“š å‚è€ƒèµ„æº

1. **Friedman, J.H. (2001)**: "Greedy function approximation: A gradient boosting machine"
2. **Chen, T., Guestrin, C. (2016)**: "XGBoost: A Scalable Tree Boosting System"
3. **Ke, G., et al. (2017)**: "LightGBM: A Highly Efficient Gradient Boosting Decision Tree"

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å­¦ä¹ ç‡**: ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆ0.01-0.1ï¼‰é…åˆæ›´å¤šæ ‘
2. **æ ‘æ·±åº¦**: æ§åˆ¶æ ‘çš„æ·±åº¦é˜²æ­¢è¿‡æ‹Ÿåˆ
3. **å­é‡‡æ ·**: ä½¿ç”¨è¡Œé‡‡æ ·å’Œåˆ—é‡‡æ ·æé«˜æ³›åŒ–èƒ½åŠ›
4. **æ—©åœ**: ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ—©åœ

## ğŸ¯ æœ€ä½³å®è·µ

1. **å‚æ•°è°ƒä¼˜**: è°ƒæ•´å­¦ä¹ ç‡ã€æ ‘æ·±åº¦ã€æ­£åˆ™åŒ–å‚æ•°
2. **ç‰¹å¾å·¥ç¨‹**: å¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼
3. **äº¤å‰éªŒè¯**: ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹
4. **é›†æˆ**: å¯ä»¥ä¸å…¶ä»–æ¨¡å‹é›†æˆè¿›ä¸€æ­¥æé«˜æ€§èƒ½

### SQLå®ç°æ³¨æ„äº‹é¡¹

1. **è¿­ä»£è®¡ç®—**: æ¢¯åº¦æå‡éœ€è¦è¿­ä»£ï¼Œæ³¨æ„æ”¶æ•›æ¡ä»¶å’Œæœ€å¤§è¿­ä»£æ¬¡æ•°
2. **æ•°å€¼ç²¾åº¦**: ä½¿ç”¨NUMERICç±»å‹ä¿æŒè®¡ç®—ç²¾åº¦
3. **å†…å­˜ç®¡ç†**: å­˜å‚¨å¤šä¸ªå¼±å­¦ä¹ å™¨å¯èƒ½å ç”¨å¤§é‡å†…å­˜
4. **æ—©åœæœºåˆ¶**: å®ç°æ—©åœæœºåˆ¶é˜²æ­¢è¿‡æ‹Ÿåˆ

### PostgreSQL 18 æ–°ç‰¹æ€§åº”ç”¨ï¼ˆå¢å¼ºï¼‰

**PostgreSQL 18**å¼•å…¥äº†å¤šé¡¹å¢å¼ºåŠŸèƒ½ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ¢¯åº¦æå‡ç®—æ³•çš„æ€§èƒ½ï¼š

1. **Skip Scanä¼˜åŒ–**ï¼š
   - å¯¹äºåŒ…å«æ ·æœ¬IDçš„ç´¢å¼•ï¼ŒSkip Scanå¯ä»¥è·³è¿‡ä¸å¿…è¦çš„ç´¢å¼•æ‰«æ
   - ç‰¹åˆ«é€‚ç”¨äºTop-Næ®‹å·®æŸ¥è¯¢å’Œå¤šæ ‘å¯¹æ¯”æŸ¥è¯¢

2. **å¼‚æ­¥I/Oå¢å¼º**ï¼š
   - å¯¹äºå¤§è§„æ¨¡æ¢¯åº¦æå‡è®­ç»ƒï¼Œå¼‚æ­¥I/Oå¯ä»¥æ˜¾è‘—æå‡æ€§èƒ½
   - é€‚ç”¨äºæ‰¹é‡è´Ÿæ¢¯åº¦è®¡ç®—å’Œå¹¶è¡Œå›å½’æ ‘æ„å»º

3. **å¹¶è¡ŒæŸ¥è¯¢å¢å¼º**ï¼š
   - æ¢¯åº¦æå‡æ”¯æŒæ›´å¥½çš„å¹¶è¡Œæ‰§è¡Œï¼ˆå·²åœ¨6èŠ‚è¯¦ç»†è¯´æ˜ï¼‰
   - é€‚ç”¨äºå¤§è§„æ¨¡Boostingå’Œå¹¶è¡Œå¼±å­¦ä¹ å™¨è®­ç»ƒ

**ç¤ºä¾‹ï¼šä½¿ç”¨Skip Scanä¼˜åŒ–æ¢¯åº¦æå‡æŸ¥è¯¢**

```sql
-- ä¸ºæ¢¯åº¦æå‡æ•°æ®åˆ›å»ºSkip Scanä¼˜åŒ–ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_gb_data_skip_scan
ON gb_training_data(sample_id DESC, residual DESC);

-- Skip Scanä¼˜åŒ–æŸ¥è¯¢ï¼šæŸ¥æ‰¾æ®‹å·®æœ€å¤§çš„æ ·æœ¬ï¼ˆç”¨äºä¸‹ä¸€è½®è®­ç»ƒï¼‰
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT ON (DATE_TRUNC('day', CURRENT_TIMESTAMP))
    sample_id,
    feature1,
    feature2,
    label,
    residual
FROM gb_training_data
ORDER BY ABS(residual) DESC
LIMIT 50;
```

### é«˜çº§ä¼˜åŒ–æŠ€å·§ï¼ˆå¢å¼ºï¼‰

**1. ä½¿ç”¨ç‰©åŒ–è§†å›¾ç¼“å­˜æ¢¯åº¦æå‡ç»“æœ**

å¯¹äºé¢‘ç¹ä½¿ç”¨çš„æ¢¯åº¦æå‡é¢„æµ‹ç»“æœï¼Œä½¿ç”¨ç‰©åŒ–è§†å›¾ç¼“å­˜ï¼š

```sql
-- åˆ›å»ºç‰©åŒ–è§†å›¾ç¼“å­˜æ¢¯åº¦æå‡é¢„æµ‹ç»“æœ
CREATE MATERIALIZED VIEW IF NOT EXISTS gradient_boosting_prediction_cache AS
WITH boosting_iterations AS (
    SELECT
        sample_id,
        iteration,
        -- ä½¿ç”¨çª—å£å‡½æ•°è®¡ç®—ç´¯ç§¯é¢„æµ‹ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
        SUM(weak_learner_prediction) OVER (
            PARTITION BY sample_id
            ORDER BY iteration
            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
        ) AS cumulative_prediction
    FROM gb_weak_learners
    WHERE iteration <= 100  -- é™åˆ¶è¿­ä»£æ¬¡æ•°
),
final_predictions AS (
    SELECT
        sample_id,
        MAX(iteration) AS final_iteration,
        MAX(cumulative_prediction) AS final_prediction
    FROM boosting_iterations
    GROUP BY sample_id
)
SELECT
    fp.sample_id,
    fp.final_iteration,
    ROUND(fp.final_prediction::numeric, 4) AS final_prediction,
    CASE
        WHEN ABS(fp.final_prediction) > 2 THEN 'High Prediction Value'
        WHEN ABS(fp.final_prediction) > 1 THEN 'Moderate Prediction Value'
        ELSE 'Low Prediction Value'
    END AS prediction_category
FROM final_predictions fp
ORDER BY ABS(fp.final_prediction) DESC;

-- åˆ›å»ºç´¢å¼•åŠ é€Ÿç‰©åŒ–è§†å›¾æŸ¥è¯¢
CREATE INDEX idx_gb_prediction_cache_sample ON gradient_boosting_prediction_cache(sample_id);
CREATE INDEX idx_gb_prediction_cache_category ON gradient_boosting_prediction_cache(prediction_category, ABS(final_prediction) DESC);

-- å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY gradient_boosting_prediction_cache;
```

**2. å®æ—¶æ¢¯åº¦æå‡ï¼šå¢é‡æ¨¡å‹æ›´æ–°**

**å®æ—¶æ¢¯åº¦æå‡**ï¼šå¯¹äºå®æ—¶æ•°æ®ï¼Œä½¿ç”¨å¢é‡æ–¹æ³•æ›´æ–°æ¨¡å‹ç»“æœã€‚

```sql
-- å®æ—¶æ¢¯åº¦æå‡ï¼šå¢é‡æ¨¡å‹æ›´æ–°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'gradient_boosting_state') THEN
            CREATE TABLE gradient_boosting_state (
                model_id VARCHAR(100) NOT NULL,
                iteration INTEGER NOT NULL,
                sum_residuals NUMERIC DEFAULT 0,
                sum_squared_residuals NUMERIC DEFAULT 0,
                count_samples BIGINT DEFAULT 0,
                mean_residual NUMERIC,
                loss_value NUMERIC,
                last_updated TIMESTAMPTZ DEFAULT NOW(),
                PRIMARY KEY (model_id, iteration)
            );

            CREATE INDEX idx_gradient_boosting_state_model ON gradient_boosting_state(model_id, iteration DESC);
            CREATE INDEX idx_gradient_boosting_state_updated ON gradient_boosting_state(last_updated DESC);

            RAISE NOTICE 'æ¢¯åº¦æå‡çŠ¶æ€è¡¨åˆ›å»ºæˆåŠŸ';
        END IF;

        RAISE NOTICE 'å¼€å§‹æ‰§è¡Œå¢é‡æ¢¯åº¦æå‡æ›´æ–°';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'å¢é‡æ¢¯åº¦æå‡æ›´æ–°å‡†å¤‡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**3. æ™ºèƒ½æ¢¯åº¦æå‡ä¼˜åŒ–ï¼šè‡ªé€‚åº”å­¦ä¹ ç‡é€‰æ‹©**

**æ™ºèƒ½æ¢¯åº¦æå‡ä¼˜åŒ–**ï¼šæ ¹æ®è®­ç»ƒè¿›åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å­¦ä¹ ç‡ã€‚

```sql
-- æ™ºèƒ½æ¢¯åº¦æå‡ä¼˜åŒ–ï¼šè‡ªé€‚åº”å­¦ä¹ ç‡é€‰æ‹©ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
DECLARE
    current_loss NUMERIC;
    previous_loss NUMERIC;
    recommended_learning_rate NUMERIC;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'gb_training_data') THEN
            RAISE WARNING 'è¡¨ gb_training_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œæ™ºèƒ½æ¢¯åº¦æå‡ä¼˜åŒ–';
            RETURN;
        END IF;

        -- è®¡ç®—å½“å‰æŸå¤±ï¼ˆç®€åŒ–ï¼šä½¿ç”¨æ®‹å·®çš„å‡æ–¹è¯¯å·®ï¼‰
        SELECT
            AVG(POWER(residual, 2)),
            (SELECT AVG(POWER(residual, 2)) FROM gb_training_data OFFSET 100)  -- å‡è®¾å‰100ä¸ªæ ·æœ¬çš„å†å²æŸå¤±
        INTO current_loss, previous_loss
        FROM gb_training_data
        LIMIT 100;

        -- æ ¹æ®æŸå¤±å˜åŒ–è‡ªé€‚åº”é€‰æ‹©å­¦ä¹ ç‡
        IF previous_loss IS NULL OR current_loss < previous_loss * 0.9 THEN
            recommended_learning_rate := 0.1;  -- å¿«é€Ÿä¸‹é™ï¼šä¿æŒè¾ƒé«˜å­¦ä¹ ç‡
        ELSIF current_loss < previous_loss THEN
            recommended_learning_rate := 0.05;  -- ç¨³å®šä¸‹é™ï¼šä¸­ç­‰å­¦ä¹ ç‡
        ELSE
            recommended_learning_rate := 0.01;  -- æŸå¤±å¢åŠ ï¼šé™ä½å­¦ä¹ ç‡
        END IF;

        RAISE NOTICE 'å½“å‰æŸå¤±: %, å†å²æŸå¤±: %, æ¨èå­¦ä¹ ç‡: %',
            current_loss, previous_loss, recommended_learning_rate;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ™ºèƒ½æ¢¯åº¦æå‡ä¼˜åŒ–å‡†å¤‡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

---

**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**æ–‡æ¡£çŠ¶æ€**: âœ… å·²å®Œæˆï¼ˆåŒ…å«å®Œæ•´ç†è®ºæ¨å¯¼ã€å®ç°å’ŒPostgreSQL 18æ–°ç‰¹æ€§æ”¯æŒï¼‰
