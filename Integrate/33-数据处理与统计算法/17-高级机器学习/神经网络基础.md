# PostgreSQL ç¥ç»ç½‘ç»œåŸºç¡€ç®—æ³•å®Œæ•´æŒ‡å—

> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´1æœˆ
> **æŠ€æœ¯æ ˆ**: PostgreSQL 17+/18+ | æœºå™¨å­¦ä¹  | ç¥ç»ç½‘ç»œ | æ·±åº¦å­¦ä¹ åŸºç¡€
> **éš¾åº¦çº§åˆ«**: â­â­â­â­â­ (ä¸“å®¶çº§)
> **å‚è€ƒæ ‡å‡†**: Neural Networks (Bishop), Deep Learning (Goodfellow), Pattern Recognition

---

## ğŸ“‹ ç›®å½•

- [PostgreSQL ç¥ç»ç½‘ç»œåŸºç¡€ç®—æ³•å®Œæ•´æŒ‡å—](#postgresql-ç¥ç»ç½‘ç»œåŸºç¡€ç®—æ³•å®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ç¥ç»ç½‘ç»œæ¦‚è¿°](#ç¥ç»ç½‘ç»œæ¦‚è¿°)
    - [ç†è®ºåŸºç¡€](#ç†è®ºåŸºç¡€)
    - [ç½‘ç»œç»“æ„](#ç½‘ç»œç»“æ„)
    - [æ¿€æ´»å‡½æ•°](#æ¿€æ´»å‡½æ•°)
  - [1. æ„ŸçŸ¥æœº](#1-æ„ŸçŸ¥æœº)
    - [1.1 æ„ŸçŸ¥æœºæ¨¡å‹](#11-æ„ŸçŸ¥æœºæ¨¡å‹)
    - [1.2 æ„ŸçŸ¥æœºå­¦ä¹ ç®—æ³•](#12-æ„ŸçŸ¥æœºå­¦ä¹ ç®—æ³•)
  - [2. å¤šå±‚æ„ŸçŸ¥æœº](#2-å¤šå±‚æ„ŸçŸ¥æœº)
    - [2.1 å‰å‘ä¼ æ’­](#21-å‰å‘ä¼ æ’­)
    - [2.2 åå‘ä¼ æ’­](#22-åå‘ä¼ æ’­)
  - [3. æ¿€æ´»å‡½æ•°](#3-æ¿€æ´»å‡½æ•°)
    - [3.1 Sigmoidå‡½æ•°](#31-sigmoidå‡½æ•°)
    - [3.2 ReLUå‡½æ•°](#32-reluå‡½æ•°)
    - [3.3 Tanhå‡½æ•°](#33-tanhå‡½æ•°)
  - [4. æŸå¤±å‡½æ•°](#4-æŸå¤±å‡½æ•°)
    - [4.1 å‡æ–¹è¯¯å·®](#41-å‡æ–¹è¯¯å·®)
    - [4.2 äº¤å‰ç†µ](#42-äº¤å‰ç†µ)
  - [5. ä¼˜åŒ–ç®—æ³•](#5-ä¼˜åŒ–ç®—æ³•)
    - [5.1 æ¢¯åº¦ä¸‹é™](#51-æ¢¯åº¦ä¸‹é™)
    - [5.2 åŠ¨é‡æ³•](#52-åŠ¨é‡æ³•)
  - [6. å¤æ‚åº¦åˆ†æ](#6-å¤æ‚åº¦åˆ†æ)
  - [7. å®é™…åº”ç”¨æ¡ˆä¾‹](#7-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [7.1 åˆ†ç±»ä»»åŠ¡](#71-åˆ†ç±»ä»»åŠ¡)
    - [7.2 å›å½’ä»»åŠ¡](#72-å›å½’ä»»åŠ¡)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
  - [ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®](#-æ€§èƒ½ä¼˜åŒ–å»ºè®®)
  - [ğŸ¯ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)

---

## ç¥ç»ç½‘ç»œæ¦‚è¿°

**ç¥ç»ç½‘ç»œï¼ˆNeural Networkï¼‰**æ˜¯å—ç”Ÿç‰©ç¥ç»ç½‘ç»œå¯å‘çš„è®¡ç®—æ¨¡å‹ï¼Œé€šè¿‡å¤šå±‚éçº¿æ€§å˜æ¢å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚

### ç†è®ºåŸºç¡€

ç¥ç»ç½‘ç»œç”±å¤šä¸ª**ç¥ç»å…ƒï¼ˆNeuronï¼‰**ç»„æˆï¼Œæ¯ä¸ªç¥ç»å…ƒæ¥æ”¶è¾“å…¥ï¼Œè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œé€šè¿‡æ¿€æ´»å‡½æ•°äº§ç”Ÿè¾“å‡ºã€‚

### ç½‘ç»œç»“æ„

**åŸºæœ¬ç»“æ„**:

- **è¾“å…¥å±‚**: æ¥æ”¶åŸå§‹ç‰¹å¾
- **éšè—å±‚**: è¿›è¡Œç‰¹å¾å˜æ¢ï¼ˆå¯ä»¥æœ‰å¤šä¸ªï¼‰
- **è¾“å‡ºå±‚**: äº§ç”Ÿæœ€ç»ˆé¢„æµ‹

**å…¨è¿æ¥å±‚**: æ¯ä¸€å±‚çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ä¸ä¸‹ä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒè¿æ¥ã€‚

### æ¿€æ´»å‡½æ•°

**æ¿€æ´»å‡½æ•°**å¼•å…¥éçº¿æ€§ï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å¤æ‚æ¨¡å¼ã€‚

---

## 1. æ„ŸçŸ¥æœº

### 1.1 æ„ŸçŸ¥æœºæ¨¡å‹

**æ„ŸçŸ¥æœºï¼ˆPerceptronï¼‰**æ˜¯æœ€ç®€å•çš„ç¥ç»ç½‘ç»œï¼Œåªæœ‰ä¸€ä¸ªç¥ç»å…ƒã€‚

**æ•°å­¦è¡¨ç¤º**:
$$y = f(\sum_{i=1}^{n} w_i x_i + b)$$

å…¶ä¸­ï¼š

- $x_i$ æ˜¯è¾“å…¥ç‰¹å¾
- $w_i$ æ˜¯æƒé‡
- $b$ æ˜¯åç½®
- $f$ æ˜¯æ¿€æ´»å‡½æ•°ï¼ˆé€šå¸¸æ˜¯é˜¶è·ƒå‡½æ•°ï¼‰

```sql
-- æ„ŸçŸ¥æœºå®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'perceptron_data') THEN
            RAISE WARNING 'è¡¨ perceptron_data å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤';
            DROP TABLE perceptron_data CASCADE;
        END IF;

        CREATE TABLE perceptron_data (
            id SERIAL PRIMARY KEY,
            feature1 NUMERIC NOT NULL,
            feature2 NUMERIC NOT NULL,
            label INTEGER NOT NULL CHECK (label IN (0, 1))
        );

        -- æ’å…¥çº¿æ€§å¯åˆ†æ•°æ®
        INSERT INTO perceptron_data (feature1, feature2, label) VALUES
            (1.0, 1.0, 1), (1.5, 1.5, 1),
            (2.0, 2.0, 0), (2.5, 2.5, 0);

        RAISE NOTICE 'è¡¨ perceptron_data åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'è¡¨ perceptron_data å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE EXCEPTION 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ„ŸçŸ¥æœºé¢„æµ‹
WITH perceptron_weights AS (
    SELECT
        0.5 AS w1,
        0.5 AS w2,
        -1.0 AS bias
),
perceptron_output AS (
    SELECT
        pd.id,
        pd.feature1,
        pd.feature2,
        pd.label,
        pd.feature1 * pw.w1 + pd.feature2 * pw.w2 + pw.bias AS weighted_sum,
        CASE
            WHEN pd.feature1 * pw.w1 + pd.feature2 * pw.w2 + pw.bias > 0 THEN 1
            ELSE 0
        END AS predicted_label
    FROM perceptron_data pd
    CROSS JOIN perceptron_weights pw
)
SELECT
    id,
    feature1,
    feature2,
    label,
    ROUND(weighted_sum::numeric, 4) AS weighted_sum,
    predicted_label,
    CASE
        WHEN label = predicted_label THEN 'Correct'
        ELSE 'Incorrect'
    END AS prediction_status
FROM perceptron_output;
```

### 1.2 æ„ŸçŸ¥æœºå­¦ä¹ ç®—æ³•

**æ„ŸçŸ¥æœºå­¦ä¹ è§„åˆ™**:
$$w_i \leftarrow w_i + \eta (y - \hat{y}) x_i$$
$$b \leftarrow b + \eta (y - \hat{y})$$

å…¶ä¸­ $\eta$ æ˜¯å­¦ä¹ ç‡ã€‚

```sql
-- æ„ŸçŸ¥æœºå­¦ä¹ ç®—æ³•ï¼ˆç®€åŒ–ç‰ˆï¼šå•æ¬¡æ›´æ–°ï¼‰
WITH current_weights AS (
    SELECT
        0.0 AS w1,
        0.0 AS w2,
        0.0 AS bias,
        0.1 AS learning_rate
),
misclassified_sample AS (
    SELECT
        feature1,
        feature2,
        label,
        predicted_label,
        label - predicted_label AS error
    FROM perceptron_output
    WHERE label != predicted_label
    LIMIT 1
),
weight_update AS (
    SELECT
        cw.w1 + cw.learning_rate * ms.error * ms.feature1 AS new_w1,
        cw.w2 + cw.learning_rate * ms.error * ms.feature2 AS new_w2,
        cw.bias + cw.learning_rate * ms.error AS new_bias
    FROM current_weights cw
    CROSS JOIN misclassified_sample ms
)
SELECT
    ROUND(new_w1::numeric, 4) AS updated_w1,
    ROUND(new_w2::numeric, 4) AS updated_w2,
    ROUND(new_bias::numeric, 4) AS updated_bias
FROM weight_update;
```

---

## 2. å¤šå±‚æ„ŸçŸ¥æœº

### 2.1 å‰å‘ä¼ æ’­

**å‰å‘ä¼ æ’­ï¼ˆForward Propagationï¼‰**ä»è¾“å…¥å±‚åˆ°è¾“å‡ºå±‚è®¡ç®—ç½‘ç»œè¾“å‡ºã€‚

**ç¬¬ $l$ å±‚çš„è®¡ç®—**:
$$z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}$$
$$a^{(l)} = f(z^{(l)})$$

å…¶ä¸­ï¼š

- $z^{(l)}$ æ˜¯ç¬¬ $l$ å±‚çš„åŠ æƒè¾“å…¥
- $a^{(l)}$ æ˜¯ç¬¬ $l$ å±‚çš„æ¿€æ´»å€¼
- $W^{(l)}$ æ˜¯ç¬¬ $l$ å±‚çš„æƒé‡çŸ©é˜µ

```sql
-- å‰å‘ä¼ æ’­å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼š2å±‚ç½‘ç»œï¼‰
WITH input_layer AS (
    SELECT
        id,
        feature1 AS a0_1,
        feature2 AS a0_2
    FROM perceptron_data
),
hidden_layer AS (
    SELECT
        il.id,
        -- éšè—å±‚åŠ æƒè¾“å…¥
        il.a0_1 * 0.5 + il.a0_2 * 0.3 + 0.1 AS z1_1,
        il.a0_1 * 0.4 + il.a0_2 * 0.6 + 0.2 AS z1_2,
        -- æ¿€æ´»å‡½æ•°ï¼ˆSigmoidï¼‰
        1.0 / (1.0 + EXP(-(il.a0_1 * 0.5 + il.a0_2 * 0.3 + 0.1))) AS a1_1,
        1.0 / (1.0 + EXP(-(il.a0_1 * 0.4 + il.a0_2 * 0.6 + 0.2))) AS a1_2
    FROM input_layer il
),
output_layer AS (
    SELECT
        hl.id,
        -- è¾“å‡ºå±‚åŠ æƒè¾“å…¥
        hl.a1_1 * 0.7 + hl.a1_2 * 0.5 + 0.3 AS z2_1,
        -- è¾“å‡ºå±‚æ¿€æ´»
        1.0 / (1.0 + EXP(-(hl.a1_1 * 0.7 + hl.a1_2 * 0.5 + 0.3))) AS output
    FROM hidden_layer hl
)
SELECT
    id,
    ROUND(output::numeric, 4) AS network_output
FROM output_layer;
```

### 2.2 åå‘ä¼ æ’­

**åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰**è®¡ç®—æŸå¤±å‡½æ•°å¯¹æƒé‡çš„æ¢¯åº¦ã€‚

**è¾“å‡ºå±‚è¯¯å·®**:
$$\delta^{(L)} = \nabla_a C \odot f'(z^{(L)})$$

**éšè—å±‚è¯¯å·®**:
$$\delta^{(l)} = ((W^{(l+1)})^T \delta^{(l+1)}) \odot f'(z^{(l)})$$

**æƒé‡æ¢¯åº¦**:
$$\frac{\partial C}{\partial w_{ij}^{(l)}} = \delta_i^{(l)} a_j^{(l-1)}$$

```sql
-- åå‘ä¼ æ’­å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼šå±•ç¤ºæ¢¯åº¦è®¡ç®—ï¼‰
WITH output_error AS (
    SELECT
        id,
        output,
        label,
        output - label AS output_delta,
        output * (1 - output) AS sigmoid_derivative
    FROM network_output
    JOIN perceptron_data USING (id)
),
hidden_error AS (
    SELECT
        id,
        output_delta * 0.7 * a1_1 * (1 - a1_1) AS hidden_delta_1,
        output_delta * 0.5 * a1_2 * (1 - a1_2) AS hidden_delta_2
    FROM output_error
    JOIN hidden_layer USING (id)
),
weight_gradients AS (
    SELECT
        -- è¾“å‡ºå±‚æƒé‡æ¢¯åº¦
        output_delta * a1_1 AS grad_w_output_1,
        output_delta * a1_2 AS grad_w_output_2,
        -- éšè—å±‚æƒé‡æ¢¯åº¦
        hidden_delta_1 * a0_1 AS grad_w_hidden_1_1,
        hidden_delta_1 * a0_2 AS grad_w_hidden_1_2
    FROM output_error
    JOIN hidden_error USING (id)
    JOIN input_layer USING (id)
)
SELECT
    ROUND(grad_w_output_1::numeric, 4) AS gradient_output_weight1,
    ROUND(grad_w_output_2::numeric, 4) AS gradient_output_weight2,
    ROUND(grad_w_hidden_1_1::numeric, 4) AS gradient_hidden_weight1_1
FROM weight_gradients
LIMIT 1;
```

---

## 3. æ¿€æ´»å‡½æ•°

### 3.1 Sigmoidå‡½æ•°

**Sigmoidå‡½æ•°**:
$$\sigma(x) = \frac{1}{1 + e^{-x}}$$

**å¯¼æ•°**:
$$\sigma'(x) = \sigma(x)(1 - \sigma(x))$$

```sql
-- Sigmoidå‡½æ•°å®ç°
SELECT
    x_value,
    ROUND((1.0 / (1.0 + EXP(-x_value)))::numeric, 4) AS sigmoid_value,
    ROUND(((1.0 / (1.0 + EXP(-x_value))) * (1 - 1.0 / (1.0 + EXP(-x_value))))::numeric, 4) AS sigmoid_derivative
FROM generate_series(-5, 5) AS x_value;
```

### 3.2 ReLUå‡½æ•°

**ReLUï¼ˆRectified Linear Unitï¼‰**:
$$ReLU(x) = \max(0, x)$$

**å¯¼æ•°**:
$$ReLU'(x) = \begin{cases} 1 & \text{if } x > 0 \\ 0 & \text{if } x \leq 0 \end{cases}$$

```sql
-- ReLUå‡½æ•°å®ç°
SELECT
    x_value,
    GREATEST(0, x_value) AS relu_value,
    CASE
        WHEN x_value > 0 THEN 1
        ELSE 0
    END AS relu_derivative
FROM generate_series(-5, 5) AS x_value;
```

### 3.3 Tanhå‡½æ•°

**Tanhå‡½æ•°**:
$$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$$

```sql
-- Tanhå‡½æ•°å®ç°
SELECT
    x_value,
    ROUND(TANH(x_value)::numeric, 4) AS tanh_value,
    ROUND((1 - POWER(TANH(x_value), 2))::numeric, 4) AS tanh_derivative
FROM generate_series(-5, 5) AS x_value;
```

---

## 4. æŸå¤±å‡½æ•°

### 4.1 å‡æ–¹è¯¯å·®

**å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**:
$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

```sql
-- MSEè®¡ç®—
SELECT
    AVG(POWER(label - predicted_output, 2)) AS mse,
    SQRT(AVG(POWER(label - predicted_output, 2))) AS rmse
FROM network_predictions;
```

### 4.2 äº¤å‰ç†µ

**äº¤å‰ç†µæŸå¤±**ï¼ˆäºŒåˆ†ç±»ï¼‰:
$$L = -\frac{1}{n}\sum_{i=1}^{n}[y_i \log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]$$

```sql
-- äº¤å‰ç†µæŸå¤±è®¡ç®—
SELECT
    -AVG(label * LN(NULLIF(predicted_output, 0)) +
        (1 - label) * LN(NULLIF(1 - predicted_output, 0))) AS cross_entropy_loss
FROM network_predictions;
```

---

## 5. ä¼˜åŒ–ç®—æ³•

### 5.1 æ¢¯åº¦ä¸‹é™

**æ‰¹é‡æ¢¯åº¦ä¸‹é™**:
$$W \leftarrow W - \eta \nabla_W L$$

```sql
-- æ¢¯åº¦ä¸‹é™æ›´æ–°
WITH weight_gradients AS (
    SELECT * FROM computed_gradients
),
updated_weights AS (
    SELECT
        weight_id,
        current_weight - 0.01 * gradient AS new_weight
    FROM weight_gradients
)
SELECT * FROM updated_weights;
```

### 5.2 åŠ¨é‡æ³•

**åŠ¨é‡æ³•**:
$$v_t = \beta v_{t-1} + \eta \nabla_W L$$
$$W \leftarrow W - v_t$$

```sql
-- åŠ¨é‡æ³•æ›´æ–°
WITH momentum_update AS (
    SELECT
        weight_id,
        0.9 * previous_velocity + 0.01 * gradient AS new_velocity,
        current_weight - (0.9 * previous_velocity + 0.01 * gradient) AS updated_weight
    FROM weight_state
)
SELECT * FROM momentum_update;
```

---

## 6. å¤æ‚åº¦åˆ†æ

| æ“ä½œ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ |
|------|-----------|-----------|
| **å‰å‘ä¼ æ’­** | $O(Ln^2)$ | $O(Ln)$ |
| **åå‘ä¼ æ’­** | $O(Ln^2)$ | $O(Ln)$ |
| **è®­ç»ƒ** | $O(ELn^2)$ | $O(Ln)$ |

å…¶ä¸­ $L$ æ˜¯å±‚æ•°ï¼Œ$n$ æ˜¯æ¯å±‚ç¥ç»å…ƒæ•°ï¼Œ$E$ æ˜¯è®­ç»ƒè½®æ•°ã€‚

---

## 7. PostgreSQL 18 å¹¶è¡Œç¥ç»ç½‘ç»œè®¡ç®—å¢å¼º

**PostgreSQL 18** æ˜¾è‘—å¢å¼ºäº†å¹¶è¡Œç¥ç»ç½‘ç»œè®¡ç®—èƒ½åŠ›ï¼Œæ”¯æŒå¹¶è¡Œæ‰§è¡Œå‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—ï¼Œå¤§å¹…æå‡å¤§è§„æ¨¡ç¥ç»ç½‘ç»œè®­ç»ƒçš„æ€§èƒ½ã€‚

### 7.1 å¹¶è¡Œç¥ç»ç½‘ç»œåŸç†

PostgreSQL 18 çš„å¹¶è¡Œç¥ç»ç½‘ç»œé€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°ï¼š

1. **å¹¶è¡Œæ‰«æ**ï¼šå¤šä¸ªå·¥ä½œè¿›ç¨‹å¹¶è¡Œæ‰«æè®­ç»ƒæ•°æ®
2. **å¹¶è¡Œå‰å‘ä¼ æ’­**ï¼šæ¯ä¸ªå·¥ä½œè¿›ç¨‹ç‹¬ç«‹æ‰§è¡Œå‰å‘ä¼ æ’­
3. **å¹¶è¡Œæ¢¯åº¦è®¡ç®—**ï¼šå¹¶è¡Œæ‰§è¡Œæ¢¯åº¦ä¸‹é™è®¡ç®—
4. **ç»“æœåˆå¹¶**ï¼šä¸»è¿›ç¨‹åˆå¹¶æ‰€æœ‰å·¥ä½œè¿›ç¨‹çš„è®¡ç®—ç»“æœ

### 7.2 å¹¶è¡Œå‰å‘ä¼ æ’­

```sql
-- PostgreSQL 18 å¹¶è¡Œå‰å‘ä¼ æ’­ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'neural_network_data') THEN
            RAISE WARNING 'è¡¨ neural_network_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œå¹¶è¡Œå‰å‘ä¼ æ’­';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡ŒPostgreSQL 18å¹¶è¡Œå‰å‘ä¼ æ’­';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'å¹¶è¡Œå‰å‘ä¼ æ’­å‡†å¤‡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;

-- å¹¶è¡Œå‰å‘ä¼ æ’­ï¼šå¤šå±‚æ„ŸçŸ¥æœº
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH input_layer AS (
    SELECT
        id,
        features,
        label
    FROM neural_network_data
),
hidden_layer AS (
    SELECT
        id,
        -- éšè—å±‚æ¿€æ´»ï¼šSigmoid
        1.0 / (1.0 + EXP(-(SUM(features[i] * weights[i]) + bias))) AS hidden_output
    FROM input_layer
    CROSS JOIN generate_series(1, array_length(features, 1)) AS i
    CROSS JOIN (SELECT generate_series(1, array_length(features, 1)) AS i,
                       random() * 0.1 AS weights, 0.1 AS bias) AS w
    GROUP BY id
),
output_layer AS (
    SELECT
        id,
        -- è¾“å‡ºå±‚æ¿€æ´»ï¼šSigmoid
        1.0 / (1.0 + EXP(-(hidden_output * output_weight + output_bias))) AS predicted_output
    FROM hidden_layer
    CROSS JOIN (SELECT 0.5 AS output_weight, 0.1 AS output_bias) AS output_params
)
SELECT
    id,
    ROUND(predicted_output::numeric, 4) AS prediction
FROM output_layer;
```

### 7.3 å¹¶è¡Œæ¢¯åº¦è®¡ç®—

```sql
-- PostgreSQL 18 å¹¶è¡Œæ¢¯åº¦è®¡ç®—ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'neural_network_data') THEN
            RAISE WARNING 'è¡¨ neural_network_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œå¹¶è¡Œæ¢¯åº¦è®¡ç®—';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡ŒPostgreSQL 18å¹¶è¡Œæ¢¯åº¦è®¡ç®—';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'å¹¶è¡Œæ¢¯åº¦è®¡ç®—å‡†å¤‡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;

-- å¹¶è¡Œæ¢¯åº¦è®¡ç®—ï¼šåå‘ä¼ æ’­
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH predictions AS (
    SELECT id, predicted_output, label FROM neural_network_predictions
),
loss_gradients AS (
    SELECT
        id,
        predicted_output - label AS output_error,
        predicted_output * (1 - predicted_output) AS sigmoid_derivative
    FROM predictions
),
weight_gradients AS (
    SELECT
        feature_idx,
        SUM(output_error * sigmoid_derivative * feature_value) AS gradient
    FROM loss_gradients lg
    JOIN neural_network_data nnd ON lg.id = nnd.id
    CROSS JOIN generate_series(1, array_length(nnd.features, 1)) AS feature_idx
    CROSS JOIN LATERAL (SELECT nnd.features[feature_idx] AS feature_value) AS fv
    GROUP BY feature_idx
)
SELECT
    feature_idx,
    ROUND(gradient::numeric, 6) AS weight_gradient
FROM weight_gradients
ORDER BY feature_idx;
```

---

## 8. å®é™…åº”ç”¨æ¡ˆä¾‹

### 7.1 åˆ†ç±»ä»»åŠ¡

```sql
-- ç¥ç»ç½‘ç»œåˆ†ç±»åº”ç”¨
WITH network_predictions AS (
    SELECT
        test_id,
        network_output,
        CASE
            WHEN network_output > 0.5 THEN 1
            ELSE 0
        END AS predicted_class
    FROM neural_network_forward_pass
)
SELECT
    predicted_class,
    COUNT(*) AS prediction_count,
    COUNT(*) FILTER (WHERE predicted_class = true_label)::NUMERIC / COUNT(*) AS accuracy
FROM network_predictions
GROUP BY predicted_class;
```

### 7.2 å›å½’ä»»åŠ¡

```sql
-- ç¥ç»ç½‘ç»œå›å½’åº”ç”¨
SELECT
    test_id,
    ROUND(network_output::numeric, 4) AS predicted_value,
    ROUND(ABS(network_output - true_value)::numeric, 4) AS absolute_error
FROM neural_network_regression;
```

---

## ğŸ“š å‚è€ƒèµ„æº

1. **Bishop, C.M. (2006)**: "Pattern Recognition and Machine Learning"
2. **Goodfellow, I., et al. (2016)**: "Deep Learning"
3. **Rumelhart, D.E., Hinton, G.E., Williams, R.J. (1986)**: "Learning representations by back-propagating errors"

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **æƒé‡åˆå§‹åŒ–**: ä½¿ç”¨Xavieræˆ–Heåˆå§‹åŒ–
2. **æ‰¹é‡å½’ä¸€åŒ–**: åŠ é€Ÿè®­ç»ƒå’Œæé«˜ç¨³å®šæ€§
3. **Dropout**: é˜²æ­¢è¿‡æ‹Ÿåˆ
4. **å­¦ä¹ ç‡è°ƒåº¦**: ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡

## ğŸ¯ æœ€ä½³å®è·µ

1. **ç½‘ç»œè®¾è®¡**: ä»ç®€å•ç½‘ç»œå¼€å§‹ï¼Œé€æ­¥å¢åŠ å¤æ‚åº¦
2. **æ­£åˆ™åŒ–**: ä½¿ç”¨L2æ­£åˆ™åŒ–æˆ–Dropout
3. **è¶…å‚æ•°è°ƒä¼˜**: è°ƒæ•´å­¦ä¹ ç‡ã€éšè—å±‚å¤§å°ç­‰
4. **æ—©åœ**: ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ—©åœé˜²æ­¢è¿‡æ‹Ÿåˆ

---

**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**æ–‡æ¡£çŠ¶æ€**: âœ… å·²å®Œæˆ
