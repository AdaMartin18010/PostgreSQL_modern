# PostgreSQL 逻辑回归完整指南

> **创建日期**: 2025年1月
> **技术栈**: PostgreSQL 17+/18+ | 逻辑回归 | 分类算法
> **难度级别**: ⭐⭐⭐⭐ (高级)

---

## 📋 目录

- [PostgreSQL 逻辑回归完整指南](#postgresql-逻辑回归完整指南)
  - [📋 目录](#-目录)
  - [逻辑回归概述](#逻辑回归概述)
    - [理论基础](#理论基础)
      - [模型定义](#模型定义)
      - [优势比（Odds Ratio）](#优势比odds-ratio)
      - [参数估计](#参数估计)
    - [核心算法](#核心算法)
  - [1. 二分类逻辑回归](#1-二分类逻辑回归)
    - [1.1 Sigmoid函数原理](#11-sigmoid函数原理)
      - [数学定义](#数学定义)
      - [性质](#性质)
      - [优势](#优势)
    - [1.2 Sigmoid函数实现](#12-sigmoid函数实现)
  - [2. 多分类逻辑回归](#2-多分类逻辑回归)
    - [2.1 Softmax函数原理](#21-softmax函数原理)
      - [数学定义](#数学定义-1)
      - [性质](#性质-1)
      - [与Sigmoid的关系](#与sigmoid的关系)
    - [2.2 Softmax函数实现](#22-softmax函数实现)
  - [3. 参数估计方法](#3-参数估计方法)
    - [3.1 梯度上升法](#31-梯度上升法)
      - [算法步骤](#算法步骤)
    - [3.2 牛顿法](#32-牛顿法)
  - [4. 模型评估](#4-模型评估)
    - [4.1 混淆矩阵](#41-混淆矩阵)
    - [4.2 评估指标](#42-评估指标)
      - [4.2.1 准确率（Accuracy）](#421-准确率accuracy)
      - [4.2.2 精确率（Precision）](#422-精确率precision)
      - [4.2.3 召回率（Recall）](#423-召回率recall)
      - [4.2.4 F1分数](#424-f1分数)
      - [4.2.5 特异性（Specificity）](#425-特异性specificity)
    - [4.3 ROC曲线和AUC](#43-roc曲线和auc)
      - [ROC曲线](#roc曲线)
      - [AUC（Area Under Curve）](#aucarea-under-curve)
      - [AUC的计算](#auc的计算)
  - [5. 实际应用案例](#5-实际应用案例)
    - [5.1 用户流失预测](#51-用户流失预测)
    - [5.2 信用评分](#52-信用评分)
    - [5.3 医学诊断](#53-医学诊断)
    - [5.4 营销响应预测](#54-营销响应预测)
  - [6. 算法性能对比与优化](#6-算法性能对比与优化)
    - [6.1 逻辑回归 vs 其他分类算法](#61-逻辑回归-vs-其他分类算法)
    - [6.2 性能优化建议](#62-性能优化建议)
    - [6.3 常见问题与解决方案](#63-常见问题与解决方案)
  - [7. 最佳实践](#7-最佳实践)
    - [7.1 数据准备](#71-数据准备)
    - [7.2 模型训练](#72-模型训练)
    - [7.3 模型评估](#73-模型评估)
    - [7.4 模型解释](#74-模型解释)
    - [7.5 SQL实现注意事项](#75-sql实现注意事项)
  - [📚 参考资源](#-参考资源)
    - [学术文献](#学术文献)
    - [在线资源](#在线资源)
    - [相关算法](#相关算法)

---

## 逻辑回归概述

**逻辑回归（Logistic Regression）**是一种经典的分类算法，虽然名字包含"回归"，但实际上是用于分类问题的线性模型。逻辑回归通过Sigmoid函数（二分类）或Softmax函数（多分类）将线性组合映射到概率空间，广泛应用于医学诊断、信用评分、用户行为预测等领域。

### 理论基础

#### 模型定义

**二分类逻辑回归模型**：
$$P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + ... + \beta_p x_p)}} = \sigma(\boldsymbol{\beta}^T \mathbf{x})$$

其中：

- $Y \in \{0, 1\}$ 是类别标签
- $\mathbf{x} = [1, x_1, ..., x_p]^T$ 是特征向量（包含截距项）
- $\boldsymbol{\beta} = [\beta_0, \beta_1, ..., \beta_p]^T$ 是参数向量
- $\sigma(z) = \frac{1}{1+e^{-z}}$ 是Sigmoid函数

#### 优势比（Odds Ratio）

**优势（Odds）**：
$$\text{Odds} = \frac{P(Y=1|X)}{P(Y=0|X)} = \frac{P(Y=1|X)}{1 - P(Y=1|X)} = e^{\boldsymbol{\beta}^T \mathbf{x}}$$

**对数优势（Log-Odds）**：
$$\log(\text{Odds}) = \boldsymbol{\beta}^T \mathbf{x}$$

#### 参数估计

**最大似然估计（Maximum Likelihood Estimation, MLE）**：

似然函数：
$$L(\boldsymbol{\beta}) = \prod_{i=1}^{n} P(Y=y_i|X=x_i) = \prod_{i=1}^{n} [\sigma(\boldsymbol{\beta}^T \mathbf{x}_i)]^{y_i} [1-\sigma(\boldsymbol{\beta}^T \mathbf{x}_i)]^{1-y_i}$$

对数似然函数：
$$\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} [y_i \log(\sigma(\boldsymbol{\beta}^T \mathbf{x}_i)) + (1-y_i)\log(1-\sigma(\boldsymbol{\beta}^T \mathbf{x}_i))]$$

**梯度**：
$$\frac{\partial \ell}{\partial \beta_j} = \sum_{i=1}^{n} (y_i - \sigma(\boldsymbol{\beta}^T \mathbf{x}_i)) x_{ij}$$

**梯度上升更新**：
$$\beta_j^{(t+1)} = \beta_j^{(t)} + \alpha \sum_{i=1}^{n} (y_i - \sigma(\boldsymbol{\beta}^T \mathbf{x}_i)) x_{ij}$$

其中 $\alpha$ 是学习率。

### 核心算法

| 算法 | 用途 | 复杂度 | 说明 |
|------|------|--------|------|
| **Sigmoid函数** | 二分类概率映射 | $O(1)$ | 将线性组合映射到[0,1] |
| **Softmax函数** | 多分类概率映射 | $O(k)$ | $k$是类别数 |
| **最大似然估计** | 参数估计 | $O(n \cdot p \cdot iter)$ | $iter$是迭代次数 |
| **梯度上升/下降** | 优化算法 | $O(n \cdot p \cdot iter)$ | 迭代求解最优参数 |
| **牛顿法** | 优化算法 | $O(n \cdot p^2 \cdot iter)$ | 二阶优化方法 |

---

## 1. 二分类逻辑回归

### 1.1 Sigmoid函数原理

**Sigmoid函数（Logistic函数）**将线性组合映射到0-1之间的概率值。

#### 数学定义

**Sigmoid函数**：
$$\sigma(z) = \frac{1}{1 + e^{-z}} = \frac{e^z}{1 + e^z}$$

#### 性质

1. **值域**：$\sigma(z) \in (0, 1)$
2. **单调性**：严格单调递增
3. **对称性**：$\sigma(-z) = 1 - \sigma(z)$
4. **导数**：$\sigma'(z) = \sigma(z)(1 - \sigma(z))$
5. **渐近性**：
   - $\lim_{z \to +\infty} \sigma(z) = 1$
   - $\lim_{z \to -\infty} \sigma(z) = 0$

#### 优势

- **概率解释**：输出可以直接解释为概率
- **平滑性**：处处可导，便于优化
- **有界性**：输出在[0,1]范围内，避免溢出

### 1.2 Sigmoid函数实现

```sql
-- 创建逻辑回归数据表（带错误处理）
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'logistic_data') THEN
            RAISE WARNING '表 logistic_data 已存在，先删除';
            DROP TABLE logistic_data CASCADE;
        END IF;

        CREATE TABLE logistic_data (
            id SERIAL PRIMARY KEY,
            feature1 NUMERIC NOT NULL,
            feature2 NUMERIC NOT NULL,
            label INTEGER NOT NULL CHECK (label IN (0, 1))
        );

        -- 插入示例数据
        INSERT INTO logistic_data (feature1, feature2, label) VALUES
            (1.0, 2.0, 0), (2.0, 3.0, 0), (3.0, 4.0, 1),
            (4.0, 5.0, 1), (5.0, 6.0, 1), (6.0, 7.0, 1),
            (7.0, 8.0, 1), (8.0, 9.0, 1), (9.0, 10.0, 1), (10.0, 11.0, 1);

        RAISE NOTICE '表 logistic_data 创建成功，已插入10条数据';
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '表 logistic_data 已存在';
        WHEN OTHERS THEN
            RAISE EXCEPTION '创建表失败: %', SQLERRM;
    END;
END $$;

-- Sigmoid函数实现（带错误处理）
CREATE OR REPLACE FUNCTION sigmoid(z NUMERIC)
RETURNS NUMERIC
LANGUAGE plpgsql
IMMUTABLE
AS $$
BEGIN
    BEGIN
        -- Sigmoid函数: 1 / (1 + exp(-z))
        -- 防止溢出
        IF z > 700 THEN
            RETURN 1.0;
        ELSIF z < -700 THEN
            RETURN 0.0;
        ELSE
            RETURN 1.0 / (1.0 + EXP(-z));
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'Sigmoid函数计算失败: %', SQLERRM;
            RETURN NULL;
    END;
END;
$$;

-- 逻辑回归预测（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'logistic_data') THEN
            RAISE WARNING '表 logistic_data 不存在，无法执行逻辑回归';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'sigmoid') THEN
            RAISE WARNING 'Sigmoid函数不存在，请先创建';
            RETURN;
        END IF;

        RAISE NOTICE '开始执行逻辑回归预测';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '逻辑回归准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 使用简化的权重进行预测（实际应用中需要通过训练得到）
WITH weights AS (
    SELECT 0.5 AS w1, 0.3 AS w2, -2.0 AS bias
),
predictions AS (
    SELECT
        id,
        feature1,
        feature2,
        label,
        sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) AS probability,
        CASE
            WHEN sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) > 0.5 THEN 1
            ELSE 0
        END AS predicted_label
    FROM logistic_data, weights w
)
SELECT
    id,
    feature1,
    feature2,
    label AS actual_label,
    ROUND(probability::numeric, 4) AS probability,
    predicted_label,
    CASE WHEN label = predicted_label THEN 1 ELSE 0 END AS is_correct
FROM predictions
ORDER BY id;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH weights AS (
    SELECT 0.5 AS w1, 0.3 AS w2, -2.0 AS bias
)
SELECT
    sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) AS probability
FROM logistic_data, weights w
LIMIT 100;
```

---

## 2. 多分类逻辑回归

### 2.1 Softmax函数原理

**Softmax函数**将多个线性组合映射到概率分布，是多分类逻辑回归的核心。

#### 数学定义

**Softmax函数**：
$$\text{Softmax}(z_j) = \frac{e^{z_j}}{\sum_{k=1}^{K} e^{z_k}}$$

其中 $z_j = \boldsymbol{\beta}_j^T \mathbf{x}$ 是第 $j$ 类的线性组合。

#### 性质

1. **概率分布**：$\sum_{j=1}^{K} \text{Softmax}(z_j) = 1$
2. **非负性**：$\text{Softmax}(z_j) > 0$ 对所有 $j$
3. **单调性**：如果 $z_j > z_k$，则 $\text{Softmax}(z_j) > \text{Softmax}(z_k)$
4. **数值稳定性**：使用 $z_j - \max_k z_k$ 防止溢出

#### 与Sigmoid的关系

对于二分类问题（$K=2$），Softmax等价于Sigmoid：
$$\text{Softmax}(z_1) = \frac{e^{z_1}}{e^{z_1} + e^{z_2}} = \frac{1}{1 + e^{z_2 - z_1}} = \sigma(z_1 - z_2)$$

### 2.2 Softmax函数实现

```sql
-- Softmax函数实现（带错误处理）
CREATE OR REPLACE FUNCTION softmax(z NUMERIC[])
RETURNS NUMERIC[]
LANGUAGE plpgsql
IMMUTABLE
AS $$
DECLARE
    max_z NUMERIC;
    exp_sum NUMERIC;
    result NUMERIC[];
    i INTEGER;
BEGIN
    BEGIN
        IF z IS NULL OR array_length(z, 1) IS NULL THEN
            RAISE WARNING '输入数组为空';
            RETURN NULL;
        END IF;

        -- 找到最大值（防止溢出）
        SELECT MAX(unnest) INTO max_z FROM unnest(z) AS unnest;

        -- 计算exp(z_i - max_z)的和
        SELECT SUM(EXP(unnest - max_z)) INTO exp_sum FROM unnest(z) AS unnest;

        -- 计算Softmax
        result := ARRAY[]::NUMERIC[];
        FOR i IN 1..array_length(z, 1) LOOP
            result := result || EXP(z[i] - max_z) / exp_sum;
        END LOOP;

        RETURN result;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'Softmax函数计算失败: %', SQLERRM;
            RETURN NULL;
    END;
END;
$$;

-- 多分类逻辑回归示例（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'multiclass_data') THEN
            RAISE WARNING '表 multiclass_data 不存在，创建示例表';

            CREATE TABLE multiclass_data (
                id SERIAL PRIMARY KEY,
                feature1 NUMERIC NOT NULL,
                feature2 NUMERIC NOT NULL,
                class_label INTEGER NOT NULL CHECK (class_label IN (0, 1, 2))
            );

            INSERT INTO multiclass_data (feature1, feature2, class_label) VALUES
                (1.0, 2.0, 0), (2.0, 3.0, 0), (3.0, 4.0, 1),
                (4.0, 5.0, 1), (5.0, 6.0, 2), (6.0, 7.0, 2);

            RAISE NOTICE '表 multiclass_data 创建成功';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'softmax') THEN
            RAISE WARNING 'Softmax函数不存在，请先创建';
            RETURN;
        END IF;

        RAISE NOTICE '开始执行多分类逻辑回归';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '多分类逻辑回归准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 多分类预测（使用简化的权重）
WITH weights AS (
    SELECT
        ARRAY[0.5, 0.3, -0.2] AS w1,  -- 类别0的权重
        ARRAY[0.2, 0.4, -0.1] AS w2,  -- 类别1的权重
        ARRAY[-0.3, 0.1, 0.5] AS w3,  -- 类别2的权重
        ARRAY[-1.0, -0.5, 0.0] AS bias
),
scores AS (
    SELECT
        id,
        feature1,
        feature2,
        class_label,
        ARRAY[
            w.w1[1] * feature1 + w.w1[2] * feature2 + w.w1[3] + w.bias[1],
            w.w2[1] * feature1 + w.w2[2] * feature2 + w.w2[3] + w.bias[2],
            w.w3[1] * feature1 + w.w3[2] * feature2 + w.w3[3] + w.bias[3]
        ] AS class_scores
    FROM multiclass_data, weights w
),
probabilities AS (
    SELECT
        id,
        feature1,
        feature2,
        class_label,
        class_scores,
        softmax(class_scores) AS probabilities
    FROM scores
)
SELECT
    id,
    feature1,
    feature2,
    class_label AS actual_class,
    probabilities[1] AS prob_class0,
    probabilities[2] AS prob_class1,
    probabilities[3] AS prob_class2,
    CASE
        WHEN probabilities[1] >= probabilities[2] AND probabilities[1] >= probabilities[3] THEN 0
        WHEN probabilities[2] >= probabilities[3] THEN 1
        ELSE 2
    END AS predicted_class
FROM probabilities
ORDER BY id;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH weights AS (
    SELECT ARRAY[0.5, 0.3, -0.2] AS w1
)
SELECT feature1, feature2 FROM multiclass_data LIMIT 100;
```

---

## 3. 参数估计方法

### 3.1 梯度上升法

**梯度上升法（Gradient Ascent）**通过迭代更新参数最大化对数似然函数。

#### 算法步骤

1. **初始化**：$\boldsymbol{\beta}^{(0)} = \mathbf{0}$
2. **迭代更新**：
   $$\beta_j^{(t+1)} = \beta_j^{(t)} + \alpha \sum_{i=1}^{n} (y_i - \sigma(\boldsymbol{\beta}^{(t)T} \mathbf{x}_i)) x_{ij}$$
3. **收敛判断**：当 $||\boldsymbol{\beta}^{(t+1)} - \boldsymbol{\beta}^{(t)}|| < \epsilon$ 时停止

```sql
-- 梯度上升法实现（简化版：展示迭代过程）
WITH initial_weights AS (
    SELECT
        0.0 AS beta0,
        0.0 AS beta1,
        0.0 AS beta2
),
gradient_step AS (
    SELECT
        iw.beta0 + 0.01 * SUM(ld.label - sigmoid(iw.beta0 + iw.beta1 * ld.feature1 + iw.beta2 * ld.feature2)) AS new_beta0,
        iw.beta1 + 0.01 * SUM((ld.label - sigmoid(iw.beta0 + iw.beta1 * ld.feature1 + iw.beta2 * ld.feature2)) * ld.feature1) AS new_beta1,
        iw.beta2 + 0.01 * SUM((ld.label - sigmoid(iw.beta0 + iw.beta1 * ld.feature1 + iw.beta2 * ld.feature2)) * ld.feature2) AS new_beta2
    FROM logistic_data ld
    CROSS JOIN initial_weights iw
    GROUP BY iw.beta0, iw.beta1, iw.beta2
)
SELECT
    ROUND(new_beta0::numeric, 6) AS updated_beta0,
    ROUND(new_beta1::numeric, 6) AS updated_beta1,
    ROUND(new_beta2::numeric, 6) AS updated_beta2
FROM gradient_step;
```

### 3.2 牛顿法

**牛顿法（Newton's Method）**使用二阶导数信息，收敛速度更快。

**更新公式**：
$$\boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} - [H(\boldsymbol{\beta}^{(t)})]^{-1} \nabla \ell(\boldsymbol{\beta}^{(t)})$$

其中 $H(\boldsymbol{\beta})$ 是Hessian矩阵（二阶导数矩阵）。

## 4. 模型评估

### 4.1 混淆矩阵

**混淆矩阵（Confusion Matrix）**展示分类结果的准确性，是分类模型评估的基础。

```sql
-- 混淆矩阵计算（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'logistic_data') THEN
            RAISE WARNING '表 logistic_data 不存在，无法计算混淆矩阵';
            RETURN;
        END IF;
        RAISE NOTICE '开始计算混淆矩阵';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '混淆矩阵计算准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 计算混淆矩阵
WITH weights AS (
    SELECT 0.5 AS w1, 0.3 AS w2, -2.0 AS bias
),
predictions AS (
    SELECT
        label AS actual,
        CASE
            WHEN sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) > 0.5 THEN 1
            ELSE 0
        END AS predicted
    FROM logistic_data, weights w
),
confusion_matrix AS (
    SELECT
        actual,
        predicted,
        COUNT(*) AS count
    FROM predictions
    GROUP BY actual, predicted
)
SELECT
    SUM(CASE WHEN actual = 0 AND predicted = 0 THEN count ELSE 0 END) AS true_negative,
    SUM(CASE WHEN actual = 0 AND predicted = 1 THEN count ELSE 0 END) AS false_positive,
    SUM(CASE WHEN actual = 1 AND predicted = 0 THEN count ELSE 0 END) AS false_negative,
    SUM(CASE WHEN actual = 1 AND predicted = 1 THEN count ELSE 0 END) AS true_positive,
    COUNT(*) AS total
FROM predictions;

-- 计算准确率、精确率、召回率
WITH weights AS (
    SELECT 0.5 AS w1, 0.3 AS w2, -2.0 AS bias
),
predictions AS (
    SELECT
        label AS actual,
        CASE
            WHEN sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) > 0.5 THEN 1
            ELSE 0
        END AS predicted
    FROM logistic_data, weights w
),
metrics AS (
    SELECT
        SUM(CASE WHEN actual = 0 AND predicted = 0 THEN 1 ELSE 0 END) AS tn,
        SUM(CASE WHEN actual = 0 AND predicted = 1 THEN 1 ELSE 0 END) AS fp,
        SUM(CASE WHEN actual = 1 AND predicted = 0 THEN 1 ELSE 0 END) AS fn,
        SUM(CASE WHEN actual = 1 AND predicted = 1 THEN 1 ELSE 0 END) AS tp,
        COUNT(*) AS total
    FROM predictions
)
SELECT
    tn,
    fp,
    fn,
    tp,
    total,
    ROUND((tp + tn)::numeric / NULLIF(total, 0), 4) AS accuracy,
    ROUND(tp::numeric / NULLIF(tp + fp, 0), 4) AS precision,
    ROUND(tp::numeric / NULLIF(tp + fn, 0), 4) AS recall,
    ROUND(2 * tp::numeric / NULLIF(2 * tp + fp + fn, 0), 4) AS f1_score
FROM metrics;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH weights AS (
    SELECT 0.5 AS w1, 0.3 AS w2, -2.0 AS bias
)
SELECT
    label AS actual,
    CASE
        WHEN sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) > 0.5 THEN 1
        ELSE 0
    END AS predicted
FROM logistic_data, weights w;
```

### 4.2 评估指标

#### 4.2.1 准确率（Accuracy）

**准确率**：正确分类的样本比例
$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

#### 4.2.2 精确率（Precision）

**精确率**：预测为正类中实际为正类的比例
$$Precision = \frac{TP}{TP + FP}$$

#### 4.2.3 召回率（Recall）

**召回率**：实际正类中被正确预测的比例
$$Recall = \frac{TP}{TP + FN}$$

#### 4.2.4 F1分数

**F1分数**：精确率和召回率的调和平均
$$F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}$$

#### 4.2.5 特异性（Specificity）

**特异性**：实际负类中被正确预测的比例
$$Specificity = \frac{TN}{TN + FP}$$

### 4.3 ROC曲线和AUC

**ROC曲线（Receiver Operating Characteristic Curve）**评估分类器在不同阈值下的性能。

#### ROC曲线

- **横轴**：假正率（False Positive Rate, FPR）= $\frac{FP}{FP + TN}$
- **纵轴**：真正率（True Positive Rate, TPR）= $\frac{TP}{TP + FN}$ = Recall

#### AUC（Area Under Curve）

**AUC值**：ROC曲线下的面积，取值范围[0, 1]

- **AUC = 1**：完美分类器
- **AUC = 0.5**：随机分类器
- **AUC > 0.7**：较好的分类器
- **AUC > 0.9**：优秀的分类器

#### AUC的计算

使用梯形法则或Mann-Whitney U统计量：
$$AUC = \frac{1}{n_+ n_-} \sum_{i:y_i=1} \sum_{j:y_j=0} I(p_i > p_j)$$

其中 $p_i$ 是第 $i$ 个样本的预测概率。

```sql
-- ROC曲线数据计算（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'logistic_data') THEN
            RAISE WARNING '表 logistic_data 不存在，无法计算ROC曲线';
            RETURN;
        END IF;
        RAISE NOTICE '开始计算ROC曲线数据';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'ROC曲线计算准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 计算不同阈值下的TPR和FPR
WITH weights AS (
    SELECT 0.5 AS w1, 0.3 AS w2, -2.0 AS bias
),
probabilities AS (
    SELECT
        label AS actual,
        sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) AS prob
    FROM logistic_data, weights w
),
thresholds AS (
    SELECT unnest(ARRAY[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]) AS threshold
),
roc_points AS (
    SELECT
        t.threshold,
        SUM(CASE WHEN p.actual = 1 AND p.prob >= t.threshold THEN 1 ELSE 0 END)::numeric /
        NULLIF(SUM(CASE WHEN p.actual = 1 THEN 1 ELSE 0 END), 0) AS tpr,
        SUM(CASE WHEN p.actual = 0 AND p.prob >= t.threshold THEN 1 ELSE 0 END)::numeric /
        NULLIF(SUM(CASE WHEN p.actual = 0 THEN 1 ELSE 0 END), 0) AS fpr
    FROM thresholds t
    CROSS JOIN probabilities p
    GROUP BY t.threshold
)
SELECT
    threshold,
    ROUND(COALESCE(tpr, 0)::numeric, 4) AS tpr,
    ROUND(COALESCE(fpr, 0)::numeric, 4) AS fpr
FROM roc_points
ORDER BY threshold;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH weights AS (
    SELECT 0.5 AS w1, 0.3 AS w2, -2.0 AS bias
)
SELECT
    sigmoid(w.w1 * feature1 + w.w2 * feature2 + w.bias) AS prob
FROM logistic_data, weights w
LIMIT 100;
```

---

## 5. 实际应用案例

### 5.1 用户流失预测

**用户流失预测**使用逻辑回归预测用户是否会流失，支持客户保留策略。

```sql
-- 用户流失预测示例（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'user_behavior') THEN
            RAISE WARNING '表 user_behavior 不存在，创建示例表';

            CREATE TABLE user_behavior (
                user_id SERIAL PRIMARY KEY,
                login_days INTEGER NOT NULL,
                purchase_count INTEGER NOT NULL,
                avg_session_duration NUMERIC NOT NULL,
                churned INTEGER NOT NULL CHECK (churned IN (0, 1))
            );

            INSERT INTO user_behavior (login_days, purchase_count, avg_session_duration, churned) VALUES
                (5, 2, 10.5, 1), (15, 5, 25.3, 0), (20, 8, 30.1, 0),
                (3, 1, 8.2, 1), (25, 10, 35.5, 0), (2, 0, 5.1, 1),
                (30, 12, 40.2, 0), (1, 0, 3.5, 1), (18, 6, 28.7, 0), (4, 1, 9.8, 1);

            RAISE NOTICE '表 user_behavior 创建成功';
        END IF;
        RAISE NOTICE '开始执行用户流失预测';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '用户流失预测准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 使用逻辑回归预测用户流失概率
WITH weights AS (
    SELECT
        -0.1 AS w_login,
        0.05 AS w_purchase,
        -0.02 AS w_duration,
        -1.5 AS bias
),
predictions AS (
    SELECT
        user_id,
        login_days,
        purchase_count,
        avg_session_duration,
        churned AS actual_churned,
        sigmoid(
            w.w_login * login_days +
            w.w_purchase * purchase_count +
            w.w_duration * avg_session_duration +
            w.bias
        ) AS churn_probability,
        CASE
            WHEN sigmoid(
                w.w_login * login_days +
                w.w_purchase * purchase_count +
                w.w_duration * avg_session_duration +
                w.bias
            ) > 0.5 THEN 1
            ELSE 0
        END AS predicted_churned
    FROM user_behavior, weights w
)
SELECT
    user_id,
    login_days,
    purchase_count,
    avg_session_duration,
    actual_churned,
    ROUND(churn_probability::numeric, 4) AS churn_probability,
    predicted_churned,
    CASE WHEN actual_churned = predicted_churned THEN 'Correct' ELSE 'Wrong' END AS prediction_status
FROM predictions
ORDER BY churn_probability DESC;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH weights AS (
    SELECT -0.1 AS w_login, 0.05 AS w_purchase, -0.02 AS w_duration, -1.5 AS bias
)
SELECT
    sigmoid(
        w.w_login * login_days +
        w.w_purchase * purchase_count +
        w.w_duration * avg_session_duration +
        w.bias
    ) AS churn_probability
FROM user_behavior, weights w;
```

### 5.2 信用评分

**场景**：使用逻辑回归进行信用评分，评估贷款申请人的违约风险。

```sql
-- 信用评分：违约风险预测
WITH credit_data AS (
    SELECT
        applicant_id,
        age,
        income,
        credit_score,
        debt_to_income_ratio,
        employment_years,
        default_flag  -- 0: 未违约, 1: 违约
    FROM loan_applications
    WHERE application_date >= CURRENT_DATE - INTERVAL '12 months'
),
normalized_features AS (
    SELECT
        applicant_id,
        default_flag,
        (age - AVG(age) OVER ()) / NULLIF(STDDEV(age) OVER (), 0) AS norm_age,
        (income - AVG(income) OVER ()) / NULLIF(STDDEV(income) OVER (), 0) AS norm_income,
        (credit_score - AVG(credit_score) OVER ()) / NULLIF(STDDEV(credit_score) OVER (), 0) AS norm_credit_score,
        (debt_to_income_ratio - AVG(debt_to_income_ratio) OVER ()) / NULLIF(STDDEV(debt_to_income_ratio) OVER (), 0) AS norm_dti,
        (employment_years - AVG(employment_years) OVER ()) / NULLIF(STDDEV(employment_years) OVER (), 0) AS norm_employment
    FROM credit_data
),
regression_weights AS (
    -- 训练得到的权重（示例值）
    SELECT
        -0.5 AS w_age,
        -0.8 AS w_income,
        -1.2 AS w_credit_score,
        0.6 AS w_dti,
        -0.4 AS w_employment,
        -1.0 AS bias
),
risk_predictions AS (
    SELECT
        nf.applicant_id,
        cd.age,
        cd.income,
        cd.credit_score,
        cd.debt_to_income_ratio,
        cd.default_flag AS actual_default,
        sigmoid(
            rw.w_age * nf.norm_age +
            rw.w_income * nf.norm_income +
            rw.w_credit_score * nf.norm_credit_score +
            rw.w_dti * nf.norm_dti +
            rw.w_employment * nf.norm_employment +
            rw.bias
        ) AS default_probability,
        CASE
            WHEN sigmoid(
                rw.w_age * nf.norm_age +
                rw.w_income * nf.norm_income +
                rw.w_credit_score * nf.norm_credit_score +
                rw.w_dti * nf.norm_dti +
                rw.w_employment * nf.norm_employment +
                rw.bias
            ) > 0.3 THEN 1  -- 阈值0.3（可根据业务调整）
            ELSE 0
        END AS predicted_default
    FROM normalized_features nf
    JOIN credit_data cd ON nf.applicant_id = cd.applicant_id
    CROSS JOIN regression_weights rw
),
risk_assessment AS (
    SELECT
        applicant_id,
        age,
        income,
        credit_score,
        ROUND(default_probability::numeric, 4) AS default_probability,
        CASE
            WHEN default_probability < 0.1 THEN '低风险'
            WHEN default_probability < 0.3 THEN '中风险'
            WHEN default_probability < 0.5 THEN '高风险'
            ELSE '极高风险'
        END AS risk_level,
        CASE
            WHEN default_probability < 0.1 THEN '批准'
            WHEN default_probability < 0.3 THEN '条件批准'
            WHEN default_probability < 0.5 THEN '拒绝'
            ELSE '拒绝'
        END AS recommendation
    FROM risk_predictions
)
SELECT
    applicant_id,
    credit_score,
    ROUND(default_probability::numeric, 4) AS default_probability,
    risk_level,
    recommendation
FROM risk_assessment
ORDER BY default_probability DESC;
```

### 5.3 医学诊断

**场景**：使用逻辑回归进行疾病诊断，预测患者患病的概率。

```sql
-- 医学诊断：疾病预测
WITH patient_data AS (
    SELECT
        patient_id,
        age,
        bmi,
        blood_pressure,
        cholesterol_level,
        glucose_level,
        family_history_flag,
        disease_flag  -- 0: 健康, 1: 患病
    FROM medical_records
    WHERE exam_date >= CURRENT_DATE - INTERVAL '6 months'
),
diagnostic_model AS (
    SELECT
        patient_id,
        age,
        bmi,
        blood_pressure,
        cholesterol_level,
        glucose_level,
        family_history_flag,
        disease_flag AS actual_disease,
        -- 使用训练好的模型权重（示例值）
        sigmoid(
            -0.05 * age +
            0.1 * bmi +
            0.02 * blood_pressure +
            0.01 * cholesterol_level +
            0.015 * glucose_level +
            0.5 * family_history_flag +
            -3.0  -- bias
        ) AS disease_probability
    FROM patient_data
),
diagnosis_results AS (
    SELECT
        patient_id,
        age,
        bmi,
        ROUND(disease_probability::numeric, 4) AS disease_probability,
        CASE
            WHEN disease_probability > 0.5 THEN 1
            ELSE 0
        END AS predicted_disease,
        actual_disease,
        CASE
            WHEN disease_probability < 0.2 THEN '低风险'
            WHEN disease_probability < 0.5 THEN '中等风险'
            WHEN disease_probability < 0.8 THEN '高风险'
            ELSE '极高风险'
        END AS risk_category
    FROM diagnostic_model
)
SELECT
    patient_id,
    age,
    ROUND(disease_probability::numeric, 4) AS disease_probability,
    risk_category,
    CASE
        WHEN actual_disease = predicted_disease THEN '正确'
        ELSE '错误'
    END AS prediction_status
FROM diagnosis_results
ORDER BY disease_probability DESC;
```

### 5.4 营销响应预测

**场景**：预测客户对营销活动的响应概率，优化营销策略。

```sql
-- 营销响应预测：预测客户对促销活动的响应
WITH customer_data AS (
    SELECT
        customer_id,
        age,
        total_purchases,
        avg_order_value,
        days_since_last_purchase,
        email_opens_rate,
        clicked_ads_count,
        responded_to_campaign  -- 0: 未响应, 1: 响应
    FROM marketing_campaign_data
    WHERE campaign_date >= CURRENT_DATE - INTERVAL '3 months'
),
response_model AS (
    SELECT
        customer_id,
        age,
        total_purchases,
        avg_order_value,
        days_since_last_purchase,
        email_opens_rate,
        clicked_ads_count,
        responded_to_campaign AS actual_response,
        -- 使用训练好的模型权重
        sigmoid(
            0.01 * age +
            0.05 * total_purchases +
            0.02 * avg_order_value +
            -0.01 * days_since_last_purchase +
            0.8 * email_opens_rate +
            0.3 * clicked_ads_count +
            -2.0  -- bias
        ) AS response_probability
    FROM customer_data
),
response_predictions AS (
    SELECT
        customer_id,
        age,
        total_purchases,
        ROUND(response_probability::numeric, 4) AS response_probability,
        CASE
            WHEN response_probability > 0.5 THEN 1
            ELSE 0
        END AS predicted_response,
        actual_response,
        CASE
            WHEN response_probability > 0.7 THEN '高响应概率'
            WHEN response_probability > 0.5 THEN '中等响应概率'
            WHEN response_probability > 0.3 THEN '低响应概率'
            ELSE '极低响应概率'
        END AS response_category
    FROM response_model
)
SELECT
    customer_id,
    total_purchases,
    ROUND(response_probability::numeric, 4) AS response_probability,
    response_category,
    CASE
        WHEN actual_response = predicted_response THEN '正确'
        ELSE '错误'
    END AS prediction_status
FROM response_predictions
ORDER BY response_probability DESC;
```

---

## 6. 算法性能对比与优化

### 6.1 逻辑回归 vs 其他分类算法

| 算法 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **逻辑回归** | 可解释性强、概率输出、训练快 | 假设线性关系、对异常值敏感 | 线性可分数据、需要概率输出 |
| **线性SVM** | 泛化能力强、支持高维数据 | 不提供概率、参数敏感 | 线性分类、高维数据 |
| **决策树** | 可解释、处理非线性 | 容易过拟合 | 特征重要性分析 |
| **随机森林** | 准确率高、抗过拟合 | 可解释性差 | 大规模数据 |
| **神经网络** | 表达能力强 | 需要大量数据、调参复杂 | 复杂非线性关系 |

### 6.2 性能优化建议

1. **函数优化**：使用IMMUTABLE标记提高函数性能
2. **索引优化**：在特征列上创建索引加速查询
3. **批量处理**：使用数组操作减少函数调用次数
4. **并行计算**：利用PostgreSQL并行查询加速梯度计算
5. **特征选择**：减少特征数量降低计算复杂度

### 6.3 常见问题与解决方案

**问题1**：模型不收敛

- **解决方案**：减小学习率、增加迭代次数、检查数据质量

**问题2**：过拟合

- **解决方案**：使用L1/L2正则化、减少特征数、增加数据量

**问题3**：类别不平衡

- **解决方案**：使用类别权重、SMOTE采样、调整阈值

**问题4**：特征共线性

- **解决方案**：删除相关特征、使用正则化、主成分分析

---

## 7. 最佳实践

### 7.1 数据准备

1. **特征工程**：
   - **标准化**：对连续特征进行Z-score标准化
   - **编码**：对分类特征进行独热编码或标签编码
   - **特征选择**：选择与目标变量相关性高的特征

2. **数据质量**：
   - 处理缺失值：删除或填充
   - 处理异常值：识别和处理极端值
   - 检查多重共线性：计算特征间相关系数

3. **数据分割**：
   - 训练集：70-80%
   - 验证集：10-15%
   - 测试集：10-15%

### 7.2 模型训练

1. **参数初始化**：
   - 通常初始化为0或小的随机值
   - 避免初始值过大导致梯度消失

2. **学习率选择**：
   - 通常从0.01开始
   - 使用学习率衰减策略
   - 监控损失函数变化

3. **正则化**：
   - **L1正则化（Lasso）**：$\lambda \sum_{j=1}^{p} |\beta_j|$，特征选择
   - **L2正则化（Ridge）**：$\lambda \sum_{j=1}^{p} \beta_j^2$，防止过拟合
   - **弹性网络**：结合L1和L2

### 7.3 模型评估

1. **评估指标选择**：
   - **准确率**：类别平衡时使用
   - **精确率和召回率**：类别不平衡时使用
   - **F1分数**：平衡精确率和召回率
   - **AUC**：评估整体分类能力

2. **交叉验证**：
   - k折交叉验证（通常k=5或k=10）
   - 分层k折交叉验证（保持类别比例）

3. **阈值优化**：
   - 使用ROC曲线选择最优阈值
   - 根据业务需求调整阈值（如成本敏感）

### 7.4 模型解释

1. **系数解释**：
   - 系数符号：正系数增加概率，负系数降低概率
   - 系数大小：绝对值越大，影响越大
   - 优势比：$e^{\beta_j}$ 表示特征增加1单位时优势的倍数

2. **特征重要性**：
   - 使用系数绝对值排序
   - 使用p值判断统计显著性
   - 使用优势比解释实际影响

### 7.5 SQL实现注意事项

1. **数值稳定性**：
   - Sigmoid函数防止溢出（检查z的范围）
   - Softmax函数减去最大值防止溢出
   - 使用NUMERIC类型保持精度

2. **性能优化**：
   - 创建特征索引
   - 使用物化视图缓存中间结果
   - 批量处理减少函数调用

3. **扩展函数**：
   - 考虑使用PL/Python调用scikit-learn
   - 或使用PostgreSQL扩展（如MADlib）

---

## 📚 参考资源

### 学术文献

1. **Cox, D.R. (1958)**: "The Regression Analysis of Binary Sequences", *Journal of the Royal Statistical Society*.

2. **Hosmer, D.W., Lemeshow, S. (2000)**: "Applied Logistic Regression", 2nd Edition, Wiley.

3. **《统计学习方法》**（李航，2012）- 第6章 逻辑斯谛回归与最大熵模型

4. **《The Elements of Statistical Learning》**（Hastie et al., 2009）- Chapter 4: Linear Methods for Classification

5. **《An Introduction to Statistical Learning》**（James et al., 2013）- Chapter 4: Classification

### 在线资源

- **scikit-learn逻辑回归**: <https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html>
- **PostgreSQL MADlib扩展**: <https://madlib.apache.org/>
- **逻辑回归可视化**: <https://seeing-theory.brown.edu/probability-distributions/index.html>

### 相关算法

- **线性回归**：回归问题的线性模型
- **感知机**：线性分类器
- **支持向量机**：最大间隔分类器
- **Softmax回归**：多分类逻辑回归
- **广义线性模型（GLM）**：逻辑回归的扩展

---

**最后更新**: 2025年1月
**文档状态**: ✅ 已完成
