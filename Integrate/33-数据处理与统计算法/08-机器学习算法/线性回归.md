# PostgreSQL 线性回归完整指南

> **创建日期**: 2025年1月
> **技术栈**: PostgreSQL 17+/18+ | 线性回归 | 机器学习
> **难度级别**: ⭐⭐⭐⭐ (高级)

---

## 📋 目录

- [PostgreSQL 线性回归完整指南](#postgresql-线性回归完整指南)
  - [📋 目录](#-目录)
  - [线性回归概述](#线性回归概述)
    - [理论基础](#理论基础)
      - [模型定义](#模型定义)
      - [矩阵表示](#矩阵表示)
      - [基本假设](#基本假设)
    - [核心算法](#核心算法)
  - [1. 简单线性回归](#1-简单线性回归)
    - [1.1 最小二乘法原理](#11-最小二乘法原理)
      - [目标函数](#目标函数)
      - [参数估计](#参数估计)
      - [统计性质](#统计性质)
    - [1.2 最小二乘法完整实现](#12-最小二乘法完整实现)
  - [2. 多元线性回归](#2-多元线性回归)
    - [2.1 多元线性回归原理](#21-多元线性回归原理)
      - [矩阵形式](#矩阵形式)
      - [参数估计](#参数估计-1)
      - [假设检验](#假设检验)
    - [2.2 多元线性回归完整实现](#22-多元线性回归完整实现)
  - [3. 回归评估](#3-回归评估)
    - [3.1 R²决定系数](#31-r决定系数)
      - [数学定义](#数学定义)
      - [R²的解释](#r的解释)
      - [调整R²](#调整r)
    - [3.2 回归评估指标](#32-回归评估指标)
      - [3.2.1 均方误差（MSE）](#321-均方误差mse)
      - [3.2.2 均方根误差（RMSE）](#322-均方根误差rmse)
      - [3.2.3 平均绝对误差（MAE）](#323-平均绝对误差mae)
      - [3.2.4 平均绝对百分比误差（MAPE）](#324-平均绝对百分比误差mape)
  - [4. 正则化方法](#4-正则化方法)
    - [4.1 岭回归（Ridge Regression）](#41-岭回归ridge-regression)
    - [4.2 Lasso回归](#42-lasso回归)
  - [5. 实际应用案例](#5-实际应用案例)
    - [5.1 销售预测](#51-销售预测)
    - [5.2 房价预测](#52-房价预测)
    - [5.3 需求预测](#53-需求预测)
    - [5.4 残差分析](#54-残差分析)
  - [6. 算法性能对比与优化](#6-算法性能对比与优化)
    - [6.1 线性回归 vs 其他回归方法](#61-线性回归-vs-其他回归方法)
    - [6.2 性能优化建议](#62-性能优化建议)
    - [6.3 常见问题与解决方案](#63-常见问题与解决方案)
  - [7. 最佳实践](#7-最佳实践)
    - [7.1 数据准备](#71-数据准备)
    - [7.2 模型训练](#72-模型训练)
    - [7.3 模型评估](#73-模型评估)
    - [7.4 假设检验](#74-假设检验)
    - [7.5 SQL实现注意事项](#75-sql实现注意事项)
  - [📚 参考资源](#-参考资源)
    - [学术文献](#学术文献)
    - [在线资源](#在线资源)
    - [相关算法](#相关算法)

---

## 线性回归概述

**线性回归（Linear Regression）**是机器学习中最基础且重要的算法，用于建立因变量（目标变量）与一个或多个自变量（特征）之间的线性关系模型。线性回归广泛应用于预测、趋势分析、因果关系研究等领域。

### 理论基础

#### 模型定义

**简单线性回归模型**：
$$y = \beta_0 + \beta_1 x + \epsilon$$

**多元线性回归模型**：
$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon$$

其中：

- $y$ 是因变量（响应变量）
- $x_1, x_2, ..., x_p$ 是自变量（特征变量）
- $\beta_0$ 是截距（Intercept）
- $\beta_1, \beta_2, ..., \beta_p$ 是回归系数（Slope Coefficients）
- $\epsilon$ 是误差项（随机误差）

#### 矩阵表示

**矩阵形式**：
$$\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$$

其中：

- $\mathbf{y} \in \mathbb{R}^{n}$ 是响应向量
- $\mathbf{X} \in \mathbb{R}^{n \times (p+1)}$ 是设计矩阵（包含截距列）
- $\boldsymbol{\beta} \in \mathbb{R}^{p+1}$ 是参数向量
- $\boldsymbol{\epsilon} \in \mathbb{R}^{n}$ 是误差向量

#### 基本假设

1. **线性关系**：因变量与自变量之间存在线性关系
2. **独立性**：观测值相互独立
3. **同方差性**：误差项的方差恒定（$\text{Var}(\epsilon_i) = \sigma^2$）
4. **正态性**：误差项服从正态分布（$\epsilon_i \sim N(0, \sigma^2)$）
5. **无多重共线性**：自变量之间不存在完全线性关系

### 核心算法

| 算法 | 用途 | 复杂度 | 优点 | 缺点 |
|------|------|--------|------|------|
| **最小二乘法（OLS）** | 简单/多元线性回归 | $O(np^2 + p^3)$ | 无偏估计、解析解 | 对异常值敏感 |
| **岭回归（Ridge）** | 多重共线性处理 | $O(np^2 + p^3)$ | 稳定、防止过拟合 | 不进行特征选择 |
| **Lasso回归** | 特征选择 | $O(np^2 + p^3)$ | 自动特征选择 | 可能删除重要特征 |
| **弹性网络（Elastic Net）** | 结合Ridge和Lasso | $O(np^2 + p^3)$ | 平衡Ridge和Lasso | 参数调优复杂 |

---

## 1. 简单线性回归

### 1.1 最小二乘法原理

**最小二乘法（Ordinary Least Squares, OLS）**是线性回归的参数估计方法，通过最小化残差平方和来估计回归系数。

#### 目标函数

**残差平方和（Sum of Squared Residuals, SSR）**：
$$SSR = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} (y_i - \beta_0 - \beta_1 x_i)^2$$

**目标**：找到 $\beta_0$ 和 $\beta_1$ 使得 $SSR$ 最小。

#### 参数估计

**对 $\beta_1$ 求偏导并令其为零**：
$$\frac{\partial SSR}{\partial \beta_1} = -2\sum_{i=1}^{n}(y_i - \beta_0 - \beta_1 x_i)x_i = 0$$

**对 $\beta_0$ 求偏导并令其为零**：
$$\frac{\partial SSR}{\partial \beta_0} = -2\sum_{i=1}^{n}(y_i - \beta_0 - \beta_1 x_i) = 0$$

**求解得到**：
$$\hat{\beta}_1 = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2} = \frac{n\sum x_i y_i - \sum x_i \sum y_i}{n\sum x_i^2 - (\sum x_i)^2}$$

$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$$

其中 $\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i$，$\bar{y} = \frac{1}{n}\sum_{i=1}^{n}y_i$。

#### 统计性质

**Gauss-Markov定理**：在满足基本假设的条件下，最小二乘估计量是最佳线性无偏估计量（BLUE）。

- **无偏性**：$E[\hat{\beta}_1] = \beta_1$
- **有效性**：在所有线性无偏估计量中，OLS估计量的方差最小
- **一致性**：当样本量趋于无穷时，估计量收敛到真实值

### 1.2 最小二乘法完整实现

```sql
-- 创建示例数据表（带错误处理）
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'regression_data') THEN
            RAISE WARNING '表 regression_data 已存在，先删除';
            DROP TABLE regression_data CASCADE;
        END IF;

        CREATE TABLE regression_data (
            id SERIAL PRIMARY KEY,
            x NUMERIC NOT NULL,
            y NUMERIC NOT NULL
        );

        -- 插入示例数据
        INSERT INTO regression_data (x, y) VALUES
            (1, 2.1), (2, 4.2), (3, 6.1), (4, 8.0), (5, 10.1),
            (6, 12.2), (7, 14.1), (8, 16.0), (9, 18.1), (10, 20.0);

        RAISE NOTICE '表 regression_data 创建成功，已插入10条数据';
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '表 regression_data 已存在';
        WHEN OTHERS THEN
            RAISE EXCEPTION '创建表失败: %', SQLERRM;
    END;
END $$;

-- 简单线性回归计算（带错误处理和性能测试）
DO $$
DECLARE
    n BIGINT;
    sum_x NUMERIC;
    sum_y NUMERIC;
    sum_xy NUMERIC;
    sum_x2 NUMERIC;
    slope NUMERIC;
    intercept NUMERIC;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'regression_data') THEN
            RAISE WARNING '表 regression_data 不存在，无法执行线性回归';
            RETURN;
        END IF;

        -- 检查数据
        SELECT COUNT(*) INTO n FROM regression_data WHERE x IS NOT NULL AND y IS NOT NULL;
        IF n < 2 THEN
            RAISE WARNING '数据点不足，至少需要2个点';
            RETURN;
        END IF;

        RAISE NOTICE '开始计算简单线性回归，数据点数: %', n;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '线性回归准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 计算回归系数（完整实现，包含统计推断）
WITH stats AS (
    SELECT
        COUNT(*) AS n,
        SUM(x) AS sum_x,
        SUM(y) AS sum_y,
        SUM(x * y) AS sum_xy,
        SUM(x * x) AS sum_x2,
        AVG(x) AS avg_x,
        AVG(y) AS avg_y,
        VARIANCE(x) AS var_x,
        VARIANCE(y) AS var_y,
        CORR(x, y) AS correlation
    FROM regression_data
    WHERE x IS NOT NULL AND y IS NOT NULL
),
regression_coefficients AS (
    SELECT
        n,
        avg_x,
        avg_y,
        var_x,
        var_y,
        correlation,
        -- 斜率
        CASE
            WHEN (n * sum_x2 - sum_x * sum_x) = 0 THEN NULL
            ELSE (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)
        END AS slope,
        -- 截距
        CASE
            WHEN (n * sum_x2 - sum_x * sum_x) = 0 THEN NULL
            ELSE (sum_y * sum_x2 - sum_x * sum_xy) / (n * sum_x2 - sum_x * sum_x)
        END AS intercept
    FROM stats
),
predictions AS (
    SELECT
        rd.id,
        rd.x,
        rd.y,
        rc.slope * rd.x + rc.intercept AS y_pred,
        rd.y - (rc.slope * rd.x + rc.intercept) AS residual
    FROM regression_data rd
    CROSS JOIN regression_coefficients rc
    WHERE rd.x IS NOT NULL AND rd.y IS NOT NULL
),
residual_stats AS (
    SELECT
        COUNT(*) AS n,
        SUM(POWER(residual, 2)) AS ss_residual,
        SUM(POWER(y - (SELECT avg_y FROM regression_coefficients), 2)) AS ss_total,
        AVG(POWER(residual, 2)) AS mse,
        SQRT(AVG(POWER(residual, 2))) AS rmse,
        AVG(ABS(residual)) AS mae
    FROM predictions
),
regression_summary AS (
    SELECT
        rc.n,
        ROUND(rc.avg_x::numeric, 4) AS mean_x,
        ROUND(rc.avg_y::numeric, 4) AS mean_y,
        ROUND(rc.slope::numeric, 6) AS slope,
        ROUND(rc.intercept::numeric, 6) AS intercept,
        ROUND(rc.correlation::numeric, 4) AS correlation,
        -- R²决定系数
        ROUND((1 - rs.ss_residual / NULLIF(rs.ss_total, 0))::numeric, 4) AS r_squared,
        -- 调整R²
        ROUND((1 - (rs.ss_residual / NULLIF(rs.n - 2, 0)) / (rs.ss_total / NULLIF(rs.n - 1, 0)))::numeric, 4) AS adjusted_r_squared,
        -- 均方误差
        ROUND(rs.mse::numeric, 4) AS mse,
        ROUND(rs.rmse::numeric, 4) AS rmse,
        ROUND(rs.mae::numeric, 4) AS mae,
        -- 标准误差
        ROUND(SQRT(rs.ss_residual / NULLIF(rs.n - 2, 0))::numeric, 4) AS standard_error
    FROM regression_coefficients rc
    CROSS JOIN residual_stats rs
)
SELECT
    n,
    mean_x,
    mean_y,
    slope,
    intercept,
    correlation,
    r_squared,
    adjusted_r_squared,
    mse,
    rmse,
    mae,
    standard_error,
    CASE
        WHEN r_squared > 0.9 THEN '优秀拟合'
        WHEN r_squared > 0.7 THEN '良好拟合'
        WHEN r_squared > 0.5 THEN '中等拟合'
        ELSE '拟合较差'
    END AS model_quality
FROM regression_summary;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH stats AS (
    SELECT
        COUNT(*) AS n,
        SUM(x) AS sum_x,
        SUM(y) AS sum_y,
        SUM(x * y) AS sum_xy,
        SUM(x * x) AS sum_x2
    FROM regression_data
    WHERE x IS NOT NULL AND y IS NOT NULL
)
SELECT
    (n * sum_xy - sum_x * sum_y) / NULLIF(n * sum_x2 - sum_x * sum_x, 0) AS slope,
    (sum_y * sum_x2 - sum_x * sum_xy) / NULLIF(n * sum_x2 - sum_x * sum_x, 0) AS intercept
FROM stats;
```

---

## 2. 多元线性回归

### 2.1 多元线性回归原理

**多元线性回归（Multiple Linear Regression）**处理多个自变量的情况，建立因变量与多个自变量之间的线性关系。

#### 矩阵形式

**模型**：
$$\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$$

**最小二乘估计**：
$$\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$$

#### 参数估计

**正规方程（Normal Equation）**：
$$\mathbf{X}^T\mathbf{X}\hat{\boldsymbol{\beta}} = \mathbf{X}^T\mathbf{y}$$

**解**：
$$\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$$

#### 假设检验

**t检验**：检验单个回归系数是否显著
$$t = \frac{\hat{\beta}_j}{SE(\hat{\beta}_j)} \sim t(n-p-1)$$

**F检验**：检验整体模型是否显著
$$F = \frac{MSR}{MSE} = \frac{SSR/p}{SSE/(n-p-1)} \sim F(p, n-p-1)$$

### 2.2 多元线性回归完整实现

```sql
-- 创建多元回归数据表（带错误处理）
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'multivariate_data') THEN
            RAISE WARNING '表 multivariate_data 已存在，先删除';
            DROP TABLE multivariate_data CASCADE;
        END IF;

        CREATE TABLE multivariate_data (
            id SERIAL PRIMARY KEY,
            x1 NUMERIC NOT NULL,
            x2 NUMERIC NOT NULL,
            y NUMERIC NOT NULL
        );

        -- 插入示例数据
        INSERT INTO multivariate_data (x1, x2, y) VALUES
            (1, 2, 5.1), (2, 3, 8.2), (3, 4, 11.1), (4, 5, 14.0), (5, 6, 17.1);

        RAISE NOTICE '表 multivariate_data 创建成功';
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '表 multivariate_data 已存在';
        WHEN OTHERS THEN
            RAISE EXCEPTION '创建表失败: %', SQLERRM;
    END;
END $$;

-- 多元线性回归（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'multivariate_data') THEN
            RAISE WARNING '表 multivariate_data 不存在，无法执行多元回归';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行多元线性回归';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '多元回归准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 多元线性回归：完整实现（包含协方差矩阵和回归系数）
WITH centered_data AS (
    SELECT
        id,
        x1,
        x2,
        y,
        x1 - AVG(x1) OVER () AS x1_centered,
        x2 - AVG(x2) OVER () AS x2_centered,
        y - AVG(y) OVER () AS y_centered
    FROM multivariate_data
    WHERE x1 IS NOT NULL AND x2 IS NOT NULL AND y IS NOT NULL
),
covariance_matrix AS (
    SELECT
        SUM(x1_centered * x1_centered) AS var_x1,
        SUM(x1_centered * x2_centered) AS cov_x1x2,
        SUM(x2_centered * x2_centered) AS var_x2,
        SUM(x1_centered * y_centered) AS cov_x1y,
        SUM(x2_centered * y_centered) AS cov_x2y,
        SUM(y_centered * y_centered) AS var_y
    FROM centered_data
),
regression_coefficients AS (
    SELECT
        -- 使用最小二乘法公式计算系数
        -- beta1 = (cov_x1y * var_x2 - cov_x2y * cov_x1x2) / (var_x1 * var_x2 - cov_x1x2^2)
        (cov_x1y * var_x2 - cov_x2y * cov_x1x2) /
        NULLIF(var_x1 * var_x2 - POWER(cov_x1x2, 2), 0) AS beta1,
        -- beta2 = (cov_x2y * var_x1 - cov_x1y * cov_x1x2) / (var_x1 * var_x2 - cov_x1x2^2)
        (cov_x2y * var_x1 - cov_x1y * cov_x1x2) /
        NULLIF(var_x1 * var_x2 - POWER(cov_x1x2, 2), 0) AS beta2,
        -- intercept = mean_y - beta1 * mean_x1 - beta2 * mean_x2
        (SELECT AVG(y) FROM multivariate_data) -
        (SELECT AVG(x1) FROM multivariate_data) *
        ((cov_x1y * var_x2 - cov_x2y * cov_x1x2) / NULLIF(var_x1 * var_x2 - POWER(cov_x1x2, 2), 0)) -
        (SELECT AVG(x2) FROM multivariate_data) *
        ((cov_x2y * var_x1 - cov_x1y * cov_x1x2) / NULLIF(var_x1 * var_x2 - POWER(cov_x1x2, 2), 0)) AS intercept
    FROM covariance_matrix
),
predictions AS (
    SELECT
        md.id,
        md.x1,
        md.x2,
        md.y,
        rc.beta1 * md.x1 + rc.beta2 * md.x2 + rc.intercept AS y_pred,
        md.y - (rc.beta1 * md.x1 + rc.beta2 * md.x2 + rc.intercept) AS residual
    FROM multivariate_data md
    CROSS JOIN regression_coefficients rc
    WHERE md.x1 IS NOT NULL AND md.x2 IS NOT NULL AND md.y IS NOT NULL
),
model_evaluation AS (
    SELECT
        COUNT(*) AS n,
        SUM(POWER(residual, 2)) AS ss_residual,
        SUM(POWER(y - (SELECT AVG(y) FROM multivariate_data), 2)) AS ss_total,
        AVG(POWER(residual, 2)) AS mse,
        SQRT(AVG(POWER(residual, 2))) AS rmse
    FROM predictions
)
SELECT
    ROUND(rc.beta1::numeric, 6) AS coefficient_x1,
    ROUND(rc.beta2::numeric, 6) AS coefficient_x2,
    ROUND(rc.intercept::numeric, 6) AS intercept,
    ROUND((1 - me.ss_residual / NULLIF(me.ss_total, 0))::numeric, 4) AS r_squared,
    ROUND(me.mse::numeric, 4) AS mse,
    ROUND(me.rmse::numeric, 4) AS rmse
FROM regression_coefficients rc
CROSS JOIN model_evaluation me;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH stats AS (
    SELECT
        COUNT(*) AS n,
        AVG(x1) AS avg_x1,
        AVG(x2) AS avg_x2,
        AVG(y) AS avg_y
    FROM multivariate_data
    WHERE x1 IS NOT NULL AND x2 IS NOT NULL AND y IS NOT NULL
)
SELECT * FROM stats;
```

---

## 3. 回归评估

### 3.1 R²决定系数

**R²决定系数（Coefficient of Determination）**衡量模型对数据的拟合程度，表示模型解释的方差占总方差的比例。

#### 数学定义

$$R^2 = 1 - \frac{SSR}{SST} = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}$$

其中：

- $SSR$（Sum of Squared Residuals）：残差平方和
- $SST$（Total Sum of Squares）：总平方和
- $SSE$（Explained Sum of Squares）：回归平方和，$SSE = SST - SSR$

#### R²的解释

- $R^2 = 1$：完美拟合，模型解释所有方差
- $R^2 = 0$：模型不比简单均值预测更好
- $R^2 < 0$：模型比简单均值预测更差（可能数据有问题）

#### 调整R²

**调整R²（Adjusted R²）**考虑自由度的影响：
$$R_{adj}^2 = 1 - \frac{SSR/(n-p-1)}{SST/(n-1)}$$

其中 $p$ 是自变量数量。调整R²惩罚过多的自变量，更适用于模型比较。

```sql
-- R²决定系数计算（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'regression_data') THEN
            RAISE WARNING '表 regression_data 不存在，无法计算R²';
            RETURN;
        END IF;
        RAISE NOTICE '开始计算R²决定系数';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'R²计算准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 计算R²
WITH regression AS (
    SELECT
        AVG(x) AS avg_x,
        AVG(y) AS avg_y,
        (COUNT(*) * SUM(x * y) - SUM(x) * SUM(y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS slope,
        (SUM(y) * SUM(x * x) - SUM(x) * SUM(x * y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS intercept
    FROM regression_data
    WHERE x IS NOT NULL AND y IS NOT NULL
),
predictions AS (
    SELECT
        y,
        r.slope * x + r.intercept AS y_pred,
        r.avg_y
    FROM regression_data, regression r
    WHERE x IS NOT NULL AND y IS NOT NULL
),
ss_res AS (
    SELECT SUM(POWER(y - y_pred, 2)) AS ss_residual
    FROM predictions
),
ss_tot AS (
    SELECT SUM(POWER(y - avg_y, 2)) AS ss_total
    FROM predictions
)
SELECT
    ss_residual,
    ss_total,
    CASE
        WHEN ss_total = 0 THEN NULL
        ELSE 1 - (ss_residual / ss_total)
    END AS r_squared
FROM ss_res, ss_tot;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH regression AS (
    SELECT
        AVG(x) AS avg_x,
        AVG(y) AS avg_y,
        (COUNT(*) * SUM(x * y) - SUM(x) * SUM(y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS slope,
        (SUM(y) * SUM(x * x) - SUM(x) * SUM(x * y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS intercept
    FROM regression_data
    WHERE x IS NOT NULL AND y IS NOT NULL
)
SELECT slope, intercept FROM regression;
```

### 3.2 回归评估指标

#### 3.2.1 均方误差（MSE）

**均方误差（Mean Squared Error, MSE）**：
$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

#### 3.2.2 均方根误差（RMSE）

**均方根误差（Root Mean Squared Error, RMSE）**：
$$RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

RMSE与目标变量具有相同的量纲，便于解释。

#### 3.2.3 平均绝对误差（MAE）

**平均绝对误差（Mean Absolute Error, MAE）**：
$$MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$

MAE对异常值不敏感，比MSE更稳健。

#### 3.2.4 平均绝对百分比误差（MAPE）

**平均绝对百分比误差（Mean Absolute Percentage Error, MAPE）**：
$$MAPE = \frac{100}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

MAPE是相对误差，便于不同量级数据的比较。

```sql
-- 均方误差计算（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'regression_data') THEN
            RAISE WARNING '表 regression_data 不存在，无法计算MSE';
            RETURN;
        END IF;
        RAISE NOTICE '开始计算均方误差';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'MSE计算准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

WITH regression AS (
    SELECT
        (COUNT(*) * SUM(x * y) - SUM(x) * SUM(y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS slope,
        (SUM(y) * SUM(x * x) - SUM(x) * SUM(x * y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS intercept
    FROM regression_data
    WHERE x IS NOT NULL AND y IS NOT NULL
),
predictions AS (
    SELECT
        y,
        r.slope * x + r.intercept AS y_pred
    FROM regression_data, regression r
    WHERE x IS NOT NULL AND y IS NOT NULL
)
SELECT
    COUNT(*) AS n,
    AVG(POWER(y - y_pred, 2)) AS mse,
    SQRT(AVG(POWER(y - y_pred, 2))) AS rmse,
    AVG(ABS(y - y_pred)) AS mae
FROM predictions;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH regression AS (
    SELECT
        (COUNT(*) * SUM(x * y) - SUM(x) * SUM(y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS slope,
        (SUM(y) * SUM(x * x) - SUM(x) * SUM(x * y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS intercept
    FROM regression_data
    WHERE x IS NOT NULL AND y IS NOT NULL
)
SELECT slope, intercept FROM regression;
```

---

## 4. 正则化方法

### 4.1 岭回归（Ridge Regression）

**岭回归**通过L2正则化防止过拟合，适用于多重共线性问题。

**目标函数**：
$$\min_{\boldsymbol{\beta}} ||\mathbf{y} - \mathbf{X}\boldsymbol{\beta}||^2 + \lambda ||\boldsymbol{\beta}||^2$$

**参数估计**：
$$\hat{\boldsymbol{\beta}}_{ridge} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}$$

其中 $\lambda \geq 0$ 是正则化参数。

```sql
-- 岭回归实现（概念性，完整实现需要矩阵运算扩展）
WITH ridge_regression AS (
    SELECT
        -- 使用伪逆矩阵方法（简化）
        -- 实际中需要使用MADlib或外部工具
        lambda_param := 0.1
)
-- 注意：完整的岭回归需要矩阵求逆，PostgreSQL原生不支持
SELECT 'Ridge regression requires matrix operations extension' AS note;
```

### 4.2 Lasso回归

**Lasso回归**通过L1正则化进行特征选择，可以将不重要的特征系数压缩为0。

**目标函数**：
$$\min_{\boldsymbol{\beta}} ||\mathbf{y} - \mathbf{X}\boldsymbol{\beta}||^2 + \lambda ||\boldsymbol{\beta}||_1$$

其中 $||\boldsymbol{\beta}||_1 = \sum_{j=1}^{p}|\beta_j|$ 是L1范数。

## 5. 实际应用案例

### 5.1 销售预测

**销售预测**使用线性回归预测未来销售额，支持业务规划和资源分配。

```sql
-- 销售预测示例（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sales_history') THEN
            RAISE WARNING '表 sales_history 不存在，创建示例表';

            CREATE TABLE sales_history (
                id SERIAL PRIMARY KEY,
                month_num INTEGER NOT NULL,
                sales_amount NUMERIC NOT NULL
            );

            INSERT INTO sales_history (month_num, sales_amount) VALUES
                (1, 1000), (2, 1200), (3, 1400), (4, 1600), (5, 1800),
                (6, 2000), (7, 2200), (8, 2400), (9, 2600), (10, 2800);

            RAISE NOTICE '表 sales_history 创建成功';
        END IF;
        RAISE NOTICE '开始执行销售预测';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '销售预测准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 计算回归模型并预测未来3个月
WITH regression AS (
    SELECT
        (COUNT(*) * SUM(month_num * sales_amount) - SUM(month_num) * SUM(sales_amount)) /
        NULLIF(COUNT(*) * SUM(month_num * month_num) - SUM(month_num) * SUM(month_num), 0) AS slope,
        (SUM(sales_amount) * SUM(month_num * month_num) - SUM(month_num) * SUM(month_num * sales_amount)) /
        NULLIF(COUNT(*) * SUM(month_num * month_num) - SUM(month_num) * SUM(month_num), 0) AS intercept
    FROM sales_history
    WHERE month_num IS NOT NULL AND sales_amount IS NOT NULL
),
predictions AS (
    SELECT
        month_num,
        sales_amount AS actual,
        r.slope * month_num + r.intercept AS predicted
    FROM sales_history, regression r
    WHERE month_num IS NOT NULL AND sales_amount IS NOT NULL

    UNION ALL

    -- 预测未来3个月
    SELECT
        11 AS month_num,
        NULL AS actual,
        r.slope * 11 + r.intercept AS predicted
    FROM regression r

    UNION ALL

    SELECT
        12 AS month_num,
        NULL AS actual,
        r.slope * 12 + r.intercept AS predicted
    FROM regression r

    UNION ALL

    SELECT
        13 AS month_num,
        NULL AS actual,
        r.slope * 13 + r.intercept AS predicted
    FROM regression r
)
SELECT
    month_num,
    actual,
    ROUND(predicted::numeric, 2) AS predicted,
    CASE WHEN actual IS NOT NULL THEN ROUND(ABS(actual - predicted)::numeric, 2) ELSE NULL END AS error
FROM predictions
ORDER BY month_num;
```

### 5.2 房价预测

**场景**：使用多元线性回归预测房价，考虑面积、位置、房龄等多个因素。

```sql
-- 房价预测：多元线性回归
WITH house_data AS (
    SELECT
        house_id,
        area_sqm,           -- 面积（平方米）
        location_score,     -- 位置评分
        age_years,          -- 房龄（年）
        floor_number,       -- 楼层
        price               -- 房价（万元）
    FROM house_listings
    WHERE price IS NOT NULL
),
normalized_features AS (
    SELECT
        house_id,
        price,
        (area_sqm - AVG(area_sqm) OVER ()) / NULLIF(STDDEV(area_sqm) OVER (), 0) AS norm_area,
        (location_score - AVG(location_score) OVER ()) / NULLIF(STDDEV(location_score) OVER (), 0) AS norm_location,
        (age_years - AVG(age_years) OVER ()) / NULLIF(STDDEV(age_years) OVER (), 0) AS norm_age,
        (floor_number - AVG(floor_number) OVER ()) / NULLIF(STDDEV(floor_number) OVER (), 0) AS norm_floor
    FROM house_data
),
regression_model AS (
    -- 使用标准化特征进行回归
    SELECT
        -- 简化：使用相关系数作为权重
        CORR(norm_area, price) AS weight_area,
        CORR(norm_location, price) AS weight_location,
        CORR(norm_age, price) AS weight_age,
        CORR(norm_floor, price) AS weight_floor,
        AVG(price) AS mean_price
    FROM normalized_features
),
predictions AS (
    SELECT
        hd.house_id,
        hd.price AS actual_price,
        rm.mean_price +
        nf.norm_area * rm.weight_area * (SELECT STDDEV(price) FROM house_data) +
        nf.norm_location * rm.weight_location * (SELECT STDDEV(price) FROM house_data) +
        nf.norm_age * rm.weight_age * (SELECT STDDEV(price) FROM house_data) +
        nf.norm_floor * rm.weight_floor * (SELECT STDDEV(price) FROM house_data) AS predicted_price
    FROM house_data hd
    JOIN normalized_features nf ON hd.house_id = nf.house_id
    CROSS JOIN regression_model rm
)
SELECT
    house_id,
    ROUND(actual_price::numeric, 2) AS actual_price,
    ROUND(predicted_price::numeric, 2) AS predicted_price,
    ROUND(ABS(actual_price - predicted_price)::numeric, 2) AS prediction_error,
    ROUND(ABS(actual_price - predicted_price) / NULLIF(actual_price, 0) * 100::numeric, 2) AS error_percentage
FROM predictions
ORDER BY prediction_error DESC
LIMIT 20;
```

### 5.3 需求预测

**场景**：预测产品需求量，考虑价格、促销、季节性等因素。

```sql
-- 需求预测：考虑多个影响因素
WITH demand_data AS (
    SELECT
        date,
        price,
        promotion_flag,
        EXTRACT(MONTH FROM date) AS month,
        demand_quantity
    FROM product_sales
    WHERE date >= CURRENT_DATE - INTERVAL '12 months'
),
feature_engineering AS (
    SELECT
        date,
        demand_quantity,
        price,
        CASE WHEN promotion_flag THEN 1 ELSE 0 END AS is_promotion,
        CASE WHEN EXTRACT(MONTH FROM date) IN (11, 12, 1) THEN 1 ELSE 0 END AS is_holiday_season,
        EXTRACT(MONTH FROM date) AS month_num
    FROM demand_data
),
regression_coefficients AS (
    SELECT
        -- 使用窗口函数计算回归系数（简化版）
        CORR(price, demand_quantity) AS price_coef,
        CORR(is_promotion::NUMERIC, demand_quantity) AS promotion_coef,
        CORR(is_holiday_season::NUMERIC, demand_quantity) AS season_coef,
        AVG(demand_quantity) AS mean_demand
    FROM feature_engineering
),
demand_predictions AS (
    SELECT
        fe.date,
        fe.demand_quantity AS actual_demand,
        rc.mean_demand +
        (fe.price - (SELECT AVG(price) FROM feature_engineering)) * rc.price_coef +
        (fe.is_promotion - (SELECT AVG(is_promotion) FROM feature_engineering)) * rc.promotion_coef +
        (fe.is_holiday_season - (SELECT AVG(is_holiday_season) FROM feature_engineering)) * rc.season_coef AS predicted_demand
    FROM feature_engineering fe
    CROSS JOIN regression_coefficients rc
)
SELECT
    date,
    ROUND(actual_demand::numeric, 2) AS actual_demand,
    ROUND(predicted_demand::numeric, 2) AS predicted_demand,
    ROUND(ABS(actual_demand - predicted_demand)::numeric, 2) AS prediction_error
FROM demand_predictions
ORDER BY date;
```

### 5.4 残差分析

**场景**：分析回归模型的残差，检查模型假设是否满足。

```sql
-- 残差分析：检查模型假设
WITH regression_model AS (
    SELECT
        (COUNT(*) * SUM(x * y) - SUM(x) * SUM(y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS slope,
        (SUM(y) * SUM(x * x) - SUM(x) * SUM(x * y)) / NULLIF(COUNT(*) * SUM(x * x) - SUM(x) * SUM(x), 0) AS intercept
    FROM regression_data
    WHERE x IS NOT NULL AND y IS NOT NULL
),
residuals AS (
    SELECT
        rd.id,
        rd.x,
        rd.y,
        rm.slope * rd.x + rm.intercept AS y_pred,
        rd.y - (rm.slope * rd.x + rm.intercept) AS residual,
        rd.y - (SELECT AVG(y) FROM regression_data) AS deviation_from_mean
    FROM regression_data rd
    CROSS JOIN regression_model rm
    WHERE rd.x IS NOT NULL AND rd.y IS NOT NULL
),
residual_analysis AS (
    SELECT
        COUNT(*) AS n,
        AVG(residual) AS mean_residual,
        STDDEV(residual) AS std_residual,
        MIN(residual) AS min_residual,
        MAX(residual) AS max_residual,
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY residual) AS q1_residual,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY residual) AS median_residual,
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY residual) AS q3_residual,
        -- 检查残差的正态性（使用偏度和峰度）
        AVG(POWER((residual - AVG(residual) OVER ()) / NULLIF(STDDEV(residual) OVER (), 0), 3)) AS skewness,
        AVG(POWER((residual - AVG(residual) OVER ()) / NULLIF(STDDEV(residual) OVER (), 0), 4)) - 3 AS kurtosis
    FROM residuals
)
SELECT
    n,
    ROUND(mean_residual::numeric, 6) AS mean_residual,
    ROUND(std_residual::numeric, 4) AS std_residual,
    ROUND(min_residual::numeric, 4) AS min_residual,
    ROUND(max_residual::numeric, 4) AS max_residual,
    ROUND(median_residual::numeric, 4) AS median_residual,
    ROUND(skewness::numeric, 4) AS residual_skewness,
    ROUND(kurtosis::numeric, 4) AS residual_kurtosis,
    CASE
        WHEN ABS(mean_residual) > 0.1 THEN '残差均值不为0，可能存在系统偏差'
        WHEN ABS(skewness) > 2 THEN '残差分布偏斜，可能违反正态性假设'
        WHEN ABS(kurtosis) > 3 THEN '残差分布异常，可能违反正态性假设'
        ELSE '残差分析正常'
    END AS residual_diagnosis
FROM residual_analysis;

-- 性能测试
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH regression AS (
    SELECT
        (COUNT(*) * SUM(month_num * sales_amount) - SUM(month_num) * SUM(sales_amount)) /
        NULLIF(COUNT(*) *SUM(month_num* month_num) - SUM(month_num) *SUM(month_num), 0) AS slope,
        (SUM(sales_amount)* SUM(month_num *month_num) - SUM(month_num)* SUM(month_num *sales_amount)) /
        NULLIF(COUNT(*) *SUM(month_num* month_num) - SUM(month_num) * SUM(month_num), 0) AS intercept
    FROM sales_history
    WHERE month_num IS NOT NULL AND sales_amount IS NOT NULL
)
SELECT slope, intercept FROM regression;

```

---

## 6. 算法性能对比与优化

### 6.1 线性回归 vs 其他回归方法

| 方法 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **线性回归** | 简单、可解释、快速 | 假设线性关系、对异常值敏感 | 线性关系数据 |
| **多项式回归** | 处理非线性关系 | 容易过拟合 | 非线性但平滑的数据 |
| **岭回归** | 处理多重共线性、稳定 | 不进行特征选择 | 特征相关性强 |
| **Lasso回归** | 自动特征选择 | 可能删除重要特征 | 高维数据、特征选择 |
| **弹性网络** | 结合Ridge和Lasso | 参数调优复杂 | 高维数据、多重共线性 |

### 6.2 性能优化建议

1. **索引优化**：在回归变量上创建索引以提高查询性能
2. **数据采样**：对于大数据集，使用采样方法减少计算量
3. **并行处理**：利用PostgreSQL的并行查询功能加速计算
4. **矩阵运算**：对于多元回归，考虑使用MADlib扩展或外部工具
5. **特征工程**：创建交互项、多项式特征提高模型表达能力

### 6.3 常见问题与解决方案

**问题1**：多重共线性

- **解决方案**：使用岭回归、删除相关特征、使用主成分回归

**问题2**：异方差性（残差方差不等）

- **解决方案**：使用加权最小二乘法（WLS）、数据变换

**问题3**：非线性关系

- **解决方案**：使用多项式回归、非线性变换、其他回归方法

**问题4**：异常值影响

- **解决方案**：使用稳健回归（Robust Regression）、删除或修正异常值

---

## 7. 最佳实践

### 7.1 数据准备

1. **数据质量检查**：
   - 检查缺失值：删除或填充
   - 检查异常值：使用IQR方法识别
   - 检查多重共线性：计算特征间相关系数

2. **特征工程**：
   - **特征选择**：选择与目标变量相关性高的特征
   - **特征变换**：对数变换、平方根变换处理非线性
   - **特征标准化**：Z-score标准化提高数值稳定性

3. **数据分割**：
   - 训练集：70-80%
   - 验证集：10-15%
   - 测试集：10-15%

### 7.2 模型训练

1. **参数估计**：
   - 使用最小二乘法估计参数
   - 检查参数的统计显著性（t检验）

2. **模型诊断**：
   - **残差分析**：检查残差的正态性、独立性、同方差性
   - **Q-Q图**：可视化残差的正态性
   - **残差图**：检查残差与预测值的关系

3. **模型选择**：
   - 使用AIC/BIC进行模型比较
   - 使用交叉验证评估泛化能力
   - 平衡模型复杂度和拟合度

### 7.3 模型评估

1. **评估指标**：
   - **R²**：解释方差比例
   - **调整R²**：考虑自由度的R²
   - **RMSE**：预测误差大小
   - **MAE**：平均绝对误差

2. **交叉验证**：
   - k折交叉验证（通常k=5或k=10）
   - 留一法交叉验证（LOOCV）
   - 时间序列交叉验证（时间序列数据）

3. **模型比较**：
   - 比较不同模型的R²、RMSE
   - 使用F检验比较嵌套模型
   - 考虑模型的复杂度和可解释性

### 7.4 假设检验

1. **参数显著性检验**：
   - t检验：检验单个回归系数是否显著
   - F检验：检验整体模型是否显著

2. **模型假设检验**：
   - **正态性检验**：Shapiro-Wilk检验、Kolmogorov-Smirnov检验
   - **同方差性检验**：Breusch-Pagan检验、White检验
   - **独立性检验**：Durbin-Watson检验（时间序列）

### 7.5 SQL实现注意事项

1. **数值稳定性**：
   - 使用NUMERIC类型保持精度
   - 注意除零错误（使用NULLIF）
   - 注意矩阵求逆的数值稳定性

2. **大规模数据**：
   - 使用采样方法
   - 使用增量计算
   - 考虑使用MADlib扩展

3. **矩阵运算**：
   - PostgreSQL原生不支持矩阵运算
   - 考虑使用PL/Python调用NumPy
   - 或使用MADlib扩展

---

## 📚 参考资源

### 学术文献

1. **Gauss, C.F. (1809)**: "Theoria Motus Corporum Coelestium", 最小二乘法的奠基工作

2. **Legendre, A.M. (1805)**: "Nouvelles méthodes pour la détermination des orbites des comètes", 独立提出最小二乘法

3. **《统计学习方法》**（李航，2012）- 第1章 统计学习及监督学习概论

4. **《The Elements of Statistical Learning》**（Hastie et al., 2009）- Chapter 3: Linear Methods for Regression

5. **《An Introduction to Statistical Learning》**（James et al., 2013）- Chapter 3: Linear Regression

### 在线资源

- **scikit-learn线性回归**: <https://scikit-learn.org/stable/modules/linear_model.html>
- **PostgreSQL MADlib扩展**: <https://madlib.apache.org/>
- **NumPy线性代数**: <https://numpy.org/doc/stable/reference/routines.linalg.html>
- **R语言lm函数**: <https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm>

### 相关算法

- **逻辑回归**：分类问题的线性模型
- **多项式回归**：非线性关系的线性化
- **岭回归**：L2正则化线性回归
- **Lasso回归**：L1正则化线性回归
- **弹性网络**：L1+L2正则化
- **广义线性模型（GLM）**：线性回归的扩展

---

**最后更新**: 2025年1月
**文档状态**: ✅ 已完成
