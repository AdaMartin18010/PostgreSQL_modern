# PostgreSQL 聚类分析完整指南

> **创建日期**: 2025年1月
> **技术栈**: PostgreSQL 17+/18+ | 聚类分析 | 用户分群
> **难度级别**: ⭐⭐⭐⭐ (高级)

---

## 📋 目录

- [PostgreSQL 聚类分析完整指南](#postgresql-聚类分析完整指南)
  - [📋 目录](#-目录)
  - [聚类分析概述](#聚类分析概述)
    - [理论基础](#理论基础)
      - [聚类问题的数学定义](#聚类问题的数学定义)
      - [距离度量](#距离度量)
    - [核心聚类算法](#核心聚类算法)
  - [1. K-means聚类](#1-k-means聚类)
    - [1.1 K-means算法原理](#11-k-means算法原理)
      - [算法原理](#算法原理)
      - [初始化方法](#初始化方法)
    - [1.2 K-means完整迭代实现](#12-k-means完整迭代实现)
  - [2. DBSCAN密度聚类](#2-dbscan密度聚类)
    - [2.1 DBSCAN算法原理](#21-dbscan算法原理)
      - [2.1.1 算法原理](#211-算法原理)
    - [2.2 DBSCAN算法实现](#22-dbscan算法实现)
  - [3. 层次聚类](#3-层次聚类)
    - [3.1 层次聚类算法原理](#31-层次聚类算法原理)
      - [算法类型](#算法类型)
      - [链接准则](#链接准则)
    - [3.2 距离矩阵计算](#32-距离矩阵计算)
  - [4. 聚类评估指标](#4-聚类评估指标)
    - [4.1 轮廓系数（Silhouette Coefficient）](#41-轮廓系数silhouette-coefficient)
    - [4.2 轮廓系数计算](#42-轮廓系数计算)
    - [4.3 其他评估指标](#43-其他评估指标)
      - [4.3.1 簇内平方和（WCSS）](#431-簇内平方和wcss)
      - [4.3.2 簇间平方和（BCSS）](#432-簇间平方和bcss)
      - [4.3.3 轮廓系数、WCSS、BCSS综合评估](#433-轮廓系数wcssbcss综合评估)
  - [5. PostgreSQL 18 并行聚类增强](#5-postgresql-18-并行聚类增强)
    - [5.1 并行聚类原理](#51-并行聚类原理)
    - [5.2 并行 K-means 聚类](#52-并行-k-means-聚类)
    - [5.3 并行 DBSCAN 聚类](#53-并行-dbscan-聚类)
    - [5.4 并行层次聚类](#54-并行层次聚类)
  - [6. 基于向量的聚类（pgvector）](#6-基于向量的聚类pgvector)
    - [5.1 向量聚类概述](#51-向量聚类概述)
      - [向量聚类原理](#向量聚类原理)
      - [pgvector扩展安装](#pgvector扩展安装)
    - [5.2 向量K-means聚类实现](#52-向量k-means聚类实现)
  - [7. 实际应用案例](#7-实际应用案例)
    - [7.1 用户分群（RFM模型）](#71-用户分群rfm模型)
    - [7.2 市场细分](#72-市场细分)
    - [7.3 异常检测](#73-异常检测)
  - [7. 算法性能对比与选择](#7-算法性能对比与选择)
    - [7.1 算法对比](#71-算法对比)
    - [7.2 算法选择指南](#72-算法选择指南)
    - [7.3 性能优化建议](#73-性能优化建议)
  - [8. 最佳实践](#8-最佳实践)
    - [8.1 数据预处理](#81-数据预处理)
    - [8.2 参数调优](#82-参数调优)
    - [8.3 结果验证](#83-结果验证)
    - [8.4 常见问题与解决方案](#84-常见问题与解决方案)
  - [📚 参考资源](#-参考资源)
    - [学术文献](#学术文献)
    - [在线资源](#在线资源)
    - [相关算法](#相关算法)

---

## 聚类分析概述

**聚类分析（Cluster Analysis）**是无监督学习的核心方法，旨在将相似的数据点分组，发现数据中的潜在模式。聚类分析广泛应用于用户分群、市场细分、异常检测、图像分割等领域。

### 理论基础

#### 聚类问题的数学定义

给定数据集 $D = \{x_1, x_2, ..., x_n\}$，其中 $x_i \in \mathbb{R}^d$ 是 $d$ 维特征向量。

**聚类**：将数据集 $D$ 划分为 $k$ 个不相交的子集（簇）$C_1, C_2, ..., C_k$，使得：

- $\bigcup_{i=1}^k C_i = D$
- $C_i \cap C_j = \emptyset$（$i \neq j$）

**目标函数**：最小化簇内距离，最大化簇间距离。

#### 距离度量

**欧几里得距离**：
$$d(x_i, x_j) = \sqrt{\sum_{l=1}^d (x_{il} - x_{jl})^2}$$

**曼哈顿距离**：
$$d(x_i, x_j) = \sum_{l=1}^d |x_{il} - x_{jl}|$$

**余弦相似度**：
$$\cos(\theta) = \frac{x_i \cdot x_j}{||x_i|| \cdot ||x_j||}$$

### 核心聚类算法

| 算法 | 用途 | 复杂度 | 优点 | 缺点 |
|------|------|--------|------|------|
| **K-means** | 快速聚类，球形簇 | $O(n \cdot k \cdot i \cdot d)$ | 简单高效，收敛快 | 需要预设k，对初始值敏感 |
| **层次聚类** | 树状聚类，任意形状 | $O(n^2 \log n)$ | 不需要预设k，可视化好 | 计算复杂度高 |
| **DBSCAN** | 密度聚类，噪声处理 | $O(n \log n)$ | 自动确定簇数，处理噪声 | 对参数敏感 |
| **谱聚类** | 非凸形状簇 | $O(n^3)$ | 处理非凸簇 | 计算复杂度高 |
| **高斯混合模型** | 概率聚类 | $O(n \cdot k \cdot i \cdot d^2)$ | 概率分配，软聚类 | 假设高斯分布 |

---

## 1. K-means聚类

### 1.1 K-means算法原理

**K-means算法**是最经典的聚类算法，由MacQueen在1967年提出。

#### 算法原理

**目标函数（Within-Cluster Sum of Squares, WCSS）**：
$$J = \sum_{i=1}^k \sum_{x \in C_i} ||x - \mu_i||^2$$

其中：

- $k$ 是簇的数量
- $C_i$ 是第 $i$ 个簇
- $\mu_i = \frac{1}{|C_i|} \sum_{x \in C_i} x$ 是第 $i$ 个簇的中心（质心）

**算法步骤**：

1. **初始化**：随机选择 $k$ 个初始聚类中心 $\mu_1, \mu_2, ..., \mu_k$
2. **分配**：将每个数据点分配到最近的聚类中心
   $$C_i = \{x : ||x - \mu_i||^2 \leq ||x - \mu_j||^2, \forall j \neq i\}$$
3. **更新**：重新计算每个簇的质心
   $$\mu_i = \frac{1}{|C_i|} \sum_{x \in C_i} x$$
4. **重复**：重复步骤2-3，直到质心不再变化或达到最大迭代次数

**收敛性**：K-means算法保证收敛，因为目标函数 $J$ 在每次迭代中单调递减。

**时间复杂度**：$O(n \cdot k \cdot i \cdot d)$，其中：

- $n$ 是数据点数
- $k$ 是簇数
- $i$ 是迭代次数（通常 $i < 100$）
- $d$ 是特征维度

**空间复杂度**：$O(n \cdot d + k \cdot d)$

#### 初始化方法

1. **随机初始化**：随机选择 $k$ 个数据点作为初始中心
2. **K-means++**：选择距离已选中心最远的点，减少对初始值的敏感性
3. **Forgy方法**：随机分配数据点到簇，然后计算初始中心

### 1.2 K-means完整迭代实现

```sql
-- K-means聚类（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'data_points') THEN
            RAISE WARNING '表 data_points 不存在，无法执行K-means聚类';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行K-means聚类';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'K-means聚类准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- K-means完整迭代实现（带错误处理和性能测试）
DO $$
DECLARE
    max_iterations INTEGER := 100;
    convergence_threshold NUMERIC := 0.001;
    k_clusters INTEGER := 3;
    iteration_count INTEGER := 0;
    centers_changed BOOLEAN := TRUE;
BEGIN
    BEGIN
        -- 检查表是否存在
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'data_points') THEN
            RAISE WARNING '表 data_points 不存在，创建示例数据';
            -- 创建示例数据
            CREATE TABLE data_points (
                id SERIAL PRIMARY KEY,
                x NUMERIC NOT NULL,
                y NUMERIC NOT NULL
            );
            -- 插入示例数据（3个簇）
            INSERT INTO data_points (x, y) VALUES
                (1, 1), (1.5, 1.2), (0.8, 1.1), (1.2, 0.9),
                (5, 5), (5.5, 5.2), (4.8, 5.1), (5.2, 4.9),
                (9, 9), (9.5, 9.2), (8.8, 9.1), (9.2, 8.9);
        END IF;

        -- 创建聚类结果表
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'kmeans_result') THEN
            DROP TABLE kmeans_result CASCADE;
        END IF;

        CREATE TABLE kmeans_result (
            id INTEGER PRIMARY KEY,
            x NUMERIC NOT NULL,
            y NUMERIC NOT NULL,
            cluster_id INTEGER NOT NULL,
            iteration INTEGER NOT NULL,
            distance_to_center NUMERIC
        );

        RAISE NOTICE '开始K-means聚类，k=%, 最大迭代次数=%', k_clusters, max_iterations;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION '初始化失败: %', SQLERRM;
    END;
END $$;

-- K-means迭代算法：使用递归CTE实现多轮迭代
WITH RECURSIVE kmeans_iterations AS (
    -- 初始迭代：随机初始化聚类中心（K-means++改进）
    SELECT
        0 AS iteration,
        cluster_id,
        center_x,
        center_y
    FROM (
        WITH random_centers AS (
            SELECT DISTINCT ON (cluster_id)
                id,
                x AS center_x,
                y AS center_y,
                ROW_NUMBER() OVER (ORDER BY RANDOM()) AS cluster_id
            FROM data_points
            LIMIT 3  -- k=3
        )
        SELECT cluster_id, center_x, center_y FROM random_centers
    ) AS init_centers

    UNION ALL

    -- 迭代：分配数据点到最近中心，然后更新中心
    SELECT
        ki.iteration + 1 AS iteration,
        new_cluster_id AS cluster_id,
        new_center_x AS center_x,
        new_center_y AS center_y
    FROM kmeans_iterations ki
    CROSS JOIN LATERAL (
        WITH
        -- 计算每个点到各中心的距离
        distances AS (
            SELECT
                p.id,
                p.x,
                p.y,
                ki.cluster_id,
                SQRT(POWER(p.x - ki.center_x, 2) + POWER(p.y - ki.center_y, 2)) AS distance
            FROM data_points p
            CROSS JOIN (SELECT DISTINCT cluster_id FROM kmeans_iterations WHERE iteration = ki.iteration) AS clusters
            CROSS JOIN LATERAL (
                SELECT center_x, center_y
                FROM kmeans_iterations
                WHERE iteration = ki.iteration AND cluster_id = clusters.cluster_id
            ) AS c
        ),
        -- 分配每个点到最近的中心
        assignments AS (
            SELECT DISTINCT ON (id)
                id,
                x,
                y,
                cluster_id,
                distance
            FROM distances
            ORDER BY id, distance
        ),
        -- 计算新的聚类中心
        new_centers AS (
            SELECT
                cluster_id AS new_cluster_id,
                AVG(x) AS new_center_x,
                AVG(y) AS new_center_y,
                COUNT(*) AS cluster_size
            FROM assignments
            GROUP BY cluster_id
        )
        SELECT new_cluster_id, new_center_x, new_center_y
        FROM new_centers
    ) AS updated_centers
    WHERE ki.iteration < 100  -- 最大迭代次数
      AND EXISTS (
          -- 检查中心是否变化（收敛条件）
          SELECT 1 FROM kmeans_iterations ki2
          WHERE ki2.iteration = ki.iteration
            AND ABS(ki2.center_x - updated_centers.new_center_x) > 0.001
            AND ABS(ki2.center_y - updated_centers.new_center_y) > 0.001
      )
),
-- 提取最终聚类结果
final_centers AS (
    SELECT DISTINCT ON (cluster_id)
        cluster_id,
        center_x,
        center_y,
        iteration
    FROM kmeans_iterations
    ORDER BY cluster_id, iteration DESC
),
final_assignments AS (
    SELECT DISTINCT ON (p.id)
        p.id,
        p.x,
        p.y,
        fc.cluster_id,
        SQRT(POWER(p.x - fc.center_x, 2) + POWER(p.y - fc.center_y, 2)) AS distance_to_center
    FROM data_points p
    CROSS JOIN final_centers fc
    ORDER BY p.id, SQRT(POWER(p.x - fc.center_x, 2) + POWER(p.y - fc.center_y, 2))
)
SELECT
    id,
    x,
    y,
    cluster_id,
    ROUND(distance_to_center::numeric, 4) AS distance_to_center,
    (SELECT MAX(iteration) FROM kmeans_iterations) AS total_iterations
FROM final_assignments
ORDER BY cluster_id, id;
```

---

## 2. DBSCAN密度聚类

### 2.1 DBSCAN算法原理

**DBSCAN（Density-Based Spatial Clustering of Applications with Noise）**是一种基于密度的聚类算法，能够发现任意形状的簇并识别噪声点。

#### 2.1.1 算法原理

**核心概念**：

1. **ε-邻域**：点 $p$ 的 ε-邻域 $N_\varepsilon(p) = \{q \in D : d(p,q) \leq \varepsilon\}$
2. **核心点**：如果 $|N_\varepsilon(p)| \geq MinPts$，则 $p$ 是核心点
3. **直接密度可达**：如果 $q \in N_\varepsilon(p)$ 且 $p$ 是核心点，则 $q$ 从 $p$ 直接密度可达
4. **密度可达**：存在点序列 $p_1, p_2, ..., p_n$，使得 $p_{i+1}$ 从 $p_i$ 直接密度可达
5. **密度相连**：如果存在点 $o$，使得 $p$ 和 $q$ 都从 $o$ 密度可达，则 $p$ 和 $q$ 密度相连

**算法步骤**：

1. 标记所有点为未访问
2. 对于每个未访问点 $p$：
   - 如果 $p$ 是核心点，创建新簇 $C$，将 $p$ 的所有密度可达点加入 $C$
   - 否则标记为噪声
3. 重复直到所有点被访问

**时间复杂度**：$O(n \log n)$（使用空间索引）或 $O(n^2)$（暴力搜索）

**空间复杂度**：$O(n)$

**优点**：

- 不需要预设簇数
- 可以发现任意形状的簇
- 能够识别噪声点

**缺点**：

- 对参数 $\varepsilon$ 和 $MinPts$ 敏感
- 难以处理密度差异大的数据

### 2.2 DBSCAN算法实现

```sql
-- DBSCAN算法实现（带错误处理和性能测试）
DO $$
DECLARE
    epsilon NUMERIC := 1.5;  -- ε邻域半径
    min_points INTEGER := 3;  -- 最小点数
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'data_points') THEN
            RAISE WARNING '表 data_points 不存在';
            RETURN;
        END IF;

        RAISE NOTICE '开始DBSCAN聚类，ε=%, MinPts=%', epsilon, min_points;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION '初始化失败: %', SQLERRM;
    END;
END $$;

-- DBSCAN算法：使用递归CTE实现密度连接
WITH RECURSIVE
-- 计算所有点之间的距离
point_distances AS (
    SELECT
        p1.id AS point1_id,
        p2.id AS point2_id,
        SQRT(POWER(p1.x - p2.x, 2) + POWER(p1.y - p2.y, 2)) AS distance
    FROM data_points p1
    CROSS JOIN data_points p2
    WHERE p1.id != p2.id
),
-- 找到ε-邻域
epsilon_neighborhoods AS (
    SELECT
        point1_id AS point_id,
        point2_id AS neighbor_id,
        distance
    FROM point_distances
    WHERE distance <= 1.5  -- ε值
),
-- 识别核心点
core_points AS (
    SELECT
        point_id,
        COUNT(*) AS neighbor_count
    FROM epsilon_neighborhoods
    GROUP BY point_id
    HAVING COUNT(*) >= 3  -- MinPts
),
-- DBSCAN聚类：从核心点扩展
dbscan_clusters AS (
    -- 起始：每个核心点开始一个新簇
    SELECT DISTINCT
        cp.point_id AS cluster_seed,
        cp.point_id AS current_point,
        DENSE_RANK() OVER (ORDER BY cp.point_id) AS cluster_id,
        0 AS depth
    FROM core_points cp

    UNION ALL

    -- 递归：扩展簇（密度可达的点）
    SELECT
        dc.cluster_seed,
        en.neighbor_id AS current_point,
        dc.cluster_id,
        dc.depth + 1
    FROM dbscan_clusters dc
    JOIN epsilon_neighborhoods en ON dc.current_point = en.point_id
    WHERE dc.depth < 100  -- 限制递归深度
      AND en.neighbor_id NOT IN (
          SELECT current_point FROM dbscan_clusters WHERE cluster_id = dc.cluster_id
      )
)
SELECT DISTINCT ON (current_point)
    current_point AS point_id,
    cluster_id,
    (SELECT x FROM data_points WHERE id = current_point) AS x,
    (SELECT y FROM data_points WHERE id = current_point) AS y
FROM dbscan_clusters
ORDER BY current_point, cluster_id;
```

## 3. 层次聚类

### 3.1 层次聚类算法原理

**层次聚类（Hierarchical Clustering）**通过构建树状结构（树状图）来组织数据，不需要预设簇数。

#### 算法类型

1. **凝聚聚类（Agglomerative）**：自底向上，从单个点开始合并
2. **分裂聚类（Divisive）**：自顶向下，从所有点开始分裂

#### 链接准则

1. **单链接（Single Linkage）**：$d(C_i, C_j) = \min_{x \in C_i, y \in C_j} d(x,y)$
2. **完全链接（Complete Linkage）**：$d(C_i, C_j) = \max_{x \in C_i, y \in C_j} d(x,y)$
3. **平均链接（Average Linkage）**：$d(C_i, C_j) = \frac{1}{|C_i||C_j|} \sum_{x \in C_i} \sum_{y \in C_j} d(x,y)$
4. **Ward链接**：最小化合并后的簇内平方和增量

**时间复杂度**：$O(n^2 \log n)$（单链接）或 $O(n^3)$（其他链接）

**空间复杂度**：$O(n^2)$（距离矩阵）

### 3.2 距离矩阵计算

```sql
-- 距离矩阵计算（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'data_points') THEN
            RAISE WARNING '表 data_points 不存在，无法计算距离矩阵';
            RETURN;
        END IF;
        RAISE NOTICE '开始计算距离矩阵';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '距离矩阵计算准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT
    p1.id AS point1_id,
    p2.id AS point2_id,
    SQRT(POWER(p1.x - p2.x, 2) + POWER(p1.y - p2.y, 2)) AS distance
FROM data_points p1
CROSS JOIN data_points p2
WHERE p1.id < p2.id
ORDER BY distance;
```

---

## 4. 聚类评估指标

### 4.1 轮廓系数（Silhouette Coefficient）

**轮廓系数**评估聚类质量，衡量数据点与其所属簇的相似度相对于其他簇的相似度。

**数学定义**：

对于数据点 $i$：

- $a(i)$：点 $i$ 到同簇其他点的平均距离
- $b(i)$：点 $i$ 到最近其他簇所有点的平均距离

**轮廓系数**：
$$s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}$$

**整体轮廓系数**：
$$S = \frac{1}{n} \sum_{i=1}^n s(i)$$

**取值范围**：$[-1, 1]$

- $s(i) \approx 1$：点 $i$ 被很好地分配到簇中
- $s(i) \approx 0$：点 $i$ 在两个簇的边界上
- $s(i) \approx -1$：点 $i$ 被分配到错误的簇

### 4.2 轮廓系数计算

```sql
-- 轮廓系数计算（带错误处理和性能测试）
DO $$
DECLARE
    avg_silhouette NUMERIC;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'clustered_points') THEN
            RAISE WARNING '表 clustered_points 不存在，无法计算轮廓系数';
            RETURN;
        END IF;

        -- 计算平均轮廓系数（简化版）
        WITH intra_cluster_distances AS (
            SELECT
                cluster_id,
                AVG(SQRT(POWER(p1.x - p2.x, 2) + POWER(p1.y - p2.y, 2))) AS avg_intra_distance
            FROM clustered_points p1
            JOIN clustered_points p2 ON p1.cluster_id = p2.cluster_id
            WHERE p1.id < p2.id
            GROUP BY cluster_id
        ),
        inter_cluster_distances AS (
            SELECT
                p1.cluster_id,
                AVG(SQRT(POWER(p1.x - p2.x, 2) + POWER(p1.y - p2.y, 2))) AS avg_inter_distance
            FROM clustered_points p1
            JOIN clustered_points p2 ON p1.cluster_id != p2.cluster_id
            GROUP BY p1.cluster_id
        )
        SELECT AVG((ic.avg_inter_distance - ia.avg_intra_distance) / NULLIF(GREATEST(ic.avg_inter_distance, ia.avg_intra_distance), 0))
        INTO avg_silhouette
        FROM intra_cluster_distances ia
        JOIN inter_cluster_distances ic ON ia.cluster_id = ic.cluster_id;

        RAISE NOTICE '平均轮廓系数: % (范围: -1到1，越大越好)', avg_silhouette;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '轮廓系数计算失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

---

### 4.3 其他评估指标

#### 4.3.1 簇内平方和（WCSS）

**WCSS（Within-Cluster Sum of Squares）**：
$$WCSS = \sum_{i=1}^k \sum_{x \in C_i} ||x - \mu_i||^2$$

#### 4.3.2 簇间平方和（BCSS）

**BCSS（Between-Cluster Sum of Squares）**：
$$BCSS = \sum_{i=1}^k |C_i| \cdot ||\mu_i - \mu||^2$$

其中 $\mu$ 是全局中心。

#### 4.3.3 轮廓系数、WCSS、BCSS综合评估

```sql
-- 综合聚类评估
WITH cluster_stats AS (
    SELECT
        cluster_id,
        COUNT(*) AS cluster_size,
        AVG(x) AS center_x,
        AVG(y) AS center_y,
        -- WCSS：簇内平方和
        SUM(POWER(x - AVG(x) OVER (PARTITION BY cluster_id), 2) +
            POWER(y - AVG(y) OVER (PARTITION BY cluster_id), 2)) AS wcss
    FROM clustered_points
    GROUP BY cluster_id
),
global_stats AS (
    SELECT
        AVG(x) AS global_center_x,
        AVG(y) AS global_center_y
    FROM clustered_points
),
cluster_evaluation AS (
    SELECT
        cs.cluster_id,
        cs.cluster_size,
        cs.wcss,
        -- BCSS：簇间平方和
        cs.cluster_size * (
            POWER(cs.center_x - gs.global_center_x, 2) +
            POWER(cs.center_y - gs.global_center_y, 2)
        ) AS bcss,
        -- 轮廓系数（简化版）
        (SELECT AVG(silhouette_score) FROM (
            SELECT
                cp1.id,
                -- a(i)：同簇平均距离
                AVG(SQRT(POWER(cp1.x - cp2.x, 2) + POWER(cp1.y - cp2.y, 2))) AS a_i
            FROM clustered_points cp1
            JOIN clustered_points cp2 ON cp1.cluster_id = cp2.cluster_id
            WHERE cp1.id != cp2.id
            GROUP BY cp1.id
        ) AS intra_dist) AS avg_silhouette
    FROM cluster_stats cs
    CROSS JOIN global_stats gs
)
SELECT
    cluster_id,
    cluster_size,
    ROUND(wcss::numeric, 4) AS within_cluster_ss,
    ROUND(bcss::numeric, 4) AS between_cluster_ss,
    ROUND((bcss / NULLIF(wcss, 0))::numeric, 4) AS separation_ratio,
    ROUND(avg_silhouette::numeric, 4) AS avg_silhouette_score
FROM cluster_evaluation
ORDER BY cluster_id;
```

## 5. PostgreSQL 18 并行聚类增强

**PostgreSQL 18** 显著增强了并行聚类能力，支持并行执行 K-means、DBSCAN 和层次聚类操作，大幅提升大数据量聚类查询的性能。

### 5.1 并行聚类原理

PostgreSQL 18 的并行聚类通过以下方式实现：

1. **并行扫描**：多个工作进程并行扫描表数据
2. **并行距离计算**：每个工作进程独立计算距离矩阵
3. **并行聚类分配**：每个工作进程独立执行聚类分配
4. **结果合并**：主进程合并所有工作进程的聚类结果

### 5.2 并行 K-means 聚类

```sql
-- PostgreSQL 18 并行 K-means 聚类（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'data_points') THEN
            RAISE WARNING '表 data_points 不存在，无法执行并行K-means聚类';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行PostgreSQL 18并行K-means聚类';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '并行K-means聚类准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;

-- 并行K-means聚类：计算距离和分配聚类
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH initial_centers AS (
    SELECT
        ROW_NUMBER() OVER () AS cluster_id,
        x AS center_x,
        y AS center_y
    FROM (
        SELECT x, y FROM data_points ORDER BY RANDOM() LIMIT 3
    ) t
),
distances AS (
    SELECT
        d.id,
        d.x,
        d.y,
        c.cluster_id,
        SQRT(POWER(d.x - c.center_x, 2) + POWER(d.y - c.center_y, 2)) AS distance
    FROM data_points d
    CROSS JOIN initial_centers c
),
closest_clusters AS (
    SELECT
        id,
        x,
        y,
        cluster_id,
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY distance) AS rn
    FROM distances
)
SELECT
    id,
    x,
    y,
    cluster_id
FROM closest_clusters
WHERE rn = 1
ORDER BY cluster_id, id;
```

### 5.3 并行 DBSCAN 聚类

```sql
-- PostgreSQL 18 并行 DBSCAN 聚类（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'data_points') THEN
            RAISE WARNING '表 data_points 不存在，无法执行并行DBSCAN聚类';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行PostgreSQL 18并行DBSCAN聚类';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '并行DBSCAN聚类准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;

-- 并行DBSCAN聚类：并行计算ε-邻域
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
WITH point_distances AS (
    SELECT
        p1.id AS point_id,
        p2.id AS point2_id,
        SQRT(POWER(p1.x - p2.x, 2) + POWER(p1.y - p2.y, 2)) AS distance
    FROM data_points p1
    CROSS JOIN data_points p2
    WHERE p1.id != p2.id
),
epsilon_neighborhoods AS (
    SELECT
        point_id,
        point2_id AS neighbor_id,
        distance
    FROM point_distances
    WHERE distance <= 1.5  -- ε值
),
core_points AS (
    SELECT
        point_id,
        COUNT(*) AS neighbor_count
    FROM epsilon_neighborhoods
    GROUP BY point_id
    HAVING COUNT(*) >= 3  -- MinPts
)
SELECT
    point_id,
    neighbor_count,
    CASE
        WHEN neighbor_count >= 3 THEN 'Core Point'
        ELSE 'Border Point'
    END AS point_type
FROM core_points
ORDER BY neighbor_count DESC;
```

### 5.4 并行层次聚类

```sql
-- PostgreSQL 18 并行层次聚类：并行计算距离矩阵（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'data_points') THEN
            RAISE WARNING '表 data_points 不存在，无法执行并行层次聚类';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行PostgreSQL 18并行层次聚类';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '并行层次聚类准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;

-- 并行层次聚类：并行计算距离矩阵
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT
    p1.id AS point1_id,
    p2.id AS point2_id,
    SQRT(POWER(p1.x - p2.x, 2) + POWER(p1.y - p2.y, 2)) AS distance
FROM data_points p1
CROSS JOIN data_points p2
WHERE p1.id < p2.id
ORDER BY distance
LIMIT 100;  -- 返回最近的100对点
```

## 6. 基于向量的聚类（pgvector）

### 5.1 向量聚类概述

**基于向量的聚类（Vector-based Clustering）**：使用pgvector扩展进行高维向量数据的聚类，特别适用于文本、图像等嵌入向量的聚类。

#### 向量聚类原理

**向量聚类**：对高维向量数据进行聚类，通过向量相似度（如余弦相似度）进行分组。

**向量聚类优势**：

- 支持高维数据
- 语义相似度聚类
- 可以结合预训练模型

#### pgvector扩展安装

```sql
-- 安装pgvector扩展（需要PostgreSQL 11+）
DO $$
BEGIN
    BEGIN
        CREATE EXTENSION IF NOT EXISTS vector;
        RAISE NOTICE 'pgvector扩展已启用';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'pgvector扩展安装失败: %。请确保已安装pgvector扩展。', SQLERRM;
            RAISE;
    END;
END $$;
```

### 5.2 向量K-means聚类实现

**创建向量数据表**：

```sql
-- 创建向量数据表（带错误处理）
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'vector_data') THEN
            RAISE WARNING '表 vector_data 已存在，先删除';
            DROP TABLE vector_data CASCADE;
        END IF;

        -- 创建包含向量的数据表
        CREATE TABLE vector_data (
            id SERIAL PRIMARY KEY,
            data_label TEXT,
            -- 使用vector类型存储128维向量
            feature_vector vector(128),
            cluster_id INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );

        -- 创建向量相似度索引（HNSW索引，PostgreSQL 18+）
        CREATE INDEX idx_vector_data_vector
        ON vector_data
        USING hnsw (feature_vector vector_cosine_ops)
        WITH (m = 16, ef_construction = 64);

        RAISE NOTICE '向量数据表创建成功';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '创建向量数据表失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**向量K-means聚类**：

```sql
-- 向量K-means聚类：基于向量相似度的K-means聚类（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'vector_data') THEN
            RAISE WARNING '表 vector_data 不存在，无法执行向量聚类';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行向量K-means聚类';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '向量聚类准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 向量K-means聚类：初始化聚类中心（随机选择K个点）
WITH k_centers AS (
    SELECT
        id,
        feature_vector,
        ROW_NUMBER() OVER (ORDER BY RANDOM()) AS center_id
    FROM vector_data
    LIMIT 3  -- K=3
),
-- 计算每个点到最近聚类中心的距离
point_to_center_distances AS (
    SELECT
        vd.id,
        vd.feature_vector,
        kc.center_id,
        1 - (vd.feature_vector <=> kc.feature_vector) AS similarity
    FROM vector_data vd
    CROSS JOIN k_centers kc
),
-- 分配每个点到最近的聚类中心
cluster_assignments AS (
    SELECT DISTINCT ON (id)
        id,
        center_id AS cluster_id,
        similarity
    FROM point_to_center_distances
    ORDER BY id, similarity DESC
)
-- 更新聚类分配
UPDATE vector_data vd
SET cluster_id = ca.cluster_id
FROM cluster_assignments ca
WHERE vd.id = ca.id;
```

**向量聚类结果分析**：

```sql
-- 向量聚类结果分析：统计每个簇的特征
WITH cluster_centroids AS (
    SELECT
        cluster_id,
        AVG(feature_vector) AS centroid_vector,
        COUNT(*) AS cluster_size
    FROM vector_data
    WHERE cluster_id IS NOT NULL
    GROUP BY cluster_id
),
cluster_statistics AS (
    SELECT
        vd.cluster_id,
        cc.cluster_size,
        AVG(1 - (vd.feature_vector <=> cc.centroid_vector)) AS avg_similarity,
        MIN(1 - (vd.feature_vector <=> cc.centroid_vector)) AS min_similarity,
        MAX(1 - (vd.feature_vector <=> cc.centroid_vector)) AS max_similarity
    FROM vector_data vd
    JOIN cluster_centroids cc ON vd.cluster_id = cc.cluster_id
    GROUP BY vd.cluster_id, cc.cluster_size
)
SELECT
    cluster_id,
    cluster_size,
    ROUND(avg_similarity::numeric, 4) AS avg_similarity,
    ROUND(min_similarity::numeric, 4) AS min_similarity,
    ROUND(max_similarity::numeric, 4) AS max_similarity,
    CASE
        WHEN avg_similarity > 0.8 THEN 'High Cohesion'
        WHEN avg_similarity > 0.6 THEN 'Medium Cohesion'
        ELSE 'Low Cohesion'
    END AS cohesion_level
FROM cluster_statistics
ORDER BY cluster_id;
```

---

## 7. 实际应用案例

### 7.1 用户分群（RFM模型）

**用户分群**根据用户行为特征进行分群，用于精准营销和个性化推荐。

**RFM模型**：Recency（最近购买时间）、Frequency（购买频率）、Monetary（购买金额）

```sql
-- 用户分群：基于RFM模型的K-means聚类
DO $$
BEGIN
    BEGIN
        -- 创建用户特征表（如果不存在）
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'user_features') THEN
            CREATE TABLE user_features (
                user_id INTEGER PRIMARY KEY,
                total_orders INTEGER NOT NULL,
                total_amount NUMERIC NOT NULL,
                last_visit_days INTEGER NOT NULL,
                avg_order_value NUMERIC NOT NULL
            );

            -- 插入示例数据
            INSERT INTO user_features (user_id, total_orders, total_amount, last_visit_days, avg_order_value) VALUES
                (1, 15, 5000, 5, 333.33),
                (2, 8, 2000, 30, 250.00),
                (3, 25, 10000, 2, 400.00),
                (4, 3, 500, 60, 166.67),
                (5, 12, 4500, 10, 375.00);
        END IF;

        RAISE NOTICE '开始执行用户分群（RFM模型）';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '用户分群准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 步骤1：特征标准化（Z-score标准化）
WITH normalized_features AS (
    SELECT
        user_id,
        total_orders,
        total_amount,
        last_visit_days,
        -- Z-score标准化
        (total_orders - AVG(total_orders) OVER ()) / NULLIF(STDDEV(total_orders) OVER (), 0) AS norm_orders,
        (total_amount - AVG(total_amount) OVER ()) / NULLIF(STDDEV(total_amount) OVER (), 0) AS norm_amount,
        (last_visit_days - AVG(last_visit_days) OVER ()) / NULLIF(STDDEV(last_visit_days) OVER (), 0) AS norm_recency
    FROM user_features
),
-- 步骤2：K-means聚类（k=5，对应5个用户群体）
initial_clusters AS (
    SELECT
        user_id,
        norm_orders,
        norm_amount,
        norm_recency,
        -- 使用NTILE进行初始聚类
        NTILE(5) OVER (ORDER BY norm_orders DESC, norm_amount DESC, norm_recency ASC) AS cluster_id
    FROM normalized_features
),
-- 步骤3：计算聚类中心
cluster_centers AS (
    SELECT
        cluster_id,
        AVG(norm_orders) AS center_orders,
        AVG(norm_amount) AS center_amount,
        AVG(norm_recency) AS center_recency,
        COUNT(*) AS cluster_size
    FROM initial_clusters
    GROUP BY cluster_id
),
-- 步骤4：重新分配（迭代一次）
distances AS (
    SELECT
        ic.user_id,
        ic.norm_orders,
        ic.norm_amount,
        ic.norm_recency,
        cc.cluster_id,
        SQRT(
            POWER(ic.norm_orders - cc.center_orders, 2) +
            POWER(ic.norm_amount - cc.center_amount, 2) +
            POWER(ic.norm_recency - cc.center_recency, 2)
        ) AS distance
    FROM initial_clusters ic
    CROSS JOIN cluster_centers cc
),
final_clusters AS (
    SELECT DISTINCT ON (user_id)
        user_id,
        cluster_id,
        distance
    FROM distances
    ORDER BY user_id, distance
)
-- 步骤5：输出聚类结果和统计信息
SELECT
    fc.cluster_id,
    cc.cluster_size,
    uf.user_id,
    uf.total_orders,
    uf.total_amount,
    uf.last_visit_days,
    ROUND(uf.avg_order_value::numeric, 2) AS avg_order_value,
    CASE
        WHEN fc.cluster_id = 1 THEN '高价值活跃用户'
        WHEN fc.cluster_id = 2 THEN '高价值流失用户'
        WHEN fc.cluster_id = 3 THEN '中价值用户'
        WHEN fc.cluster_id = 4 THEN '低价值活跃用户'
        ELSE '低价值流失用户'
    END AS user_segment,
    ROUND(fc.distance::numeric, 4) AS distance_to_center
FROM final_clusters fc
JOIN user_features uf ON fc.user_id = uf.user_id
JOIN cluster_centers cc ON fc.cluster_id = cc.cluster_id
ORDER BY fc.cluster_id, uf.total_amount DESC;
```

### 7.2 市场细分

**场景**：根据客户购买行为进行市场细分，制定差异化营销策略。

```sql
-- 市场细分：基于购买行为的聚类分析
WITH customer_features AS (
    SELECT
        customer_id,
        -- 购买频率
        COUNT(DISTINCT order_date) AS purchase_frequency,
        -- 平均订单金额
        AVG(order_amount) AS avg_order_value,
        -- 产品多样性
        COUNT(DISTINCT product_id) AS product_diversity,
        -- 最近购买天数
        CURRENT_DATE - MAX(order_date) AS days_since_last_purchase
    FROM orders
    GROUP BY customer_id
),
normalized_features AS (
    SELECT
        customer_id,
        (purchase_frequency - AVG(purchase_frequency) OVER ()) / NULLIF(STDDEV(purchase_frequency) OVER (), 0) AS norm_frequency,
        (avg_order_value - AVG(avg_order_value) OVER ()) / NULLIF(STDDEV(avg_order_value) OVER (), 0) AS norm_value,
        (product_diversity - AVG(product_diversity) OVER ()) / NULLIF(STDDEV(product_diversity) OVER (), 0) AS norm_diversity,
        (days_since_last_purchase - AVG(days_since_last_purchase) OVER ()) / NULLIF(STDDEV(days_since_last_purchase) OVER (), 0) AS norm_recency
    FROM customer_features
)
-- 使用K-means进行市场细分（k=4：4个细分市场）
SELECT
    customer_id,
    NTILE(4) OVER (ORDER BY norm_frequency, norm_value, norm_diversity, norm_recency) AS market_segment
FROM normalized_features;
```

### 7.3 异常检测

**场景**：使用DBSCAN识别异常交易或异常用户行为。

```sql
-- 异常检测：使用DBSCAN识别异常交易
WITH transaction_features AS (
    SELECT
        transaction_id,
        amount,
        transaction_time,
        EXTRACT(HOUR FROM transaction_time) AS hour_of_day,
        EXTRACT(DOW FROM transaction_time) AS day_of_week
    FROM transactions
),
normalized_features AS (
    SELECT
        transaction_id,
        (amount - AVG(amount) OVER ()) / NULLIF(STDDEV(amount) OVER (), 0) AS norm_amount,
        (hour_of_day - AVG(hour_of_day) OVER ()) / NULLIF(STDDEV(hour_of_day) OVER (), 0) AS norm_hour,
        (day_of_week - AVG(day_of_week) OVER ()) / NULLIF(STDDEV(day_of_week) OVER (), 0) AS norm_day
    FROM transaction_features
)
-- DBSCAN：密度低的点标记为异常
SELECT
    transaction_id,
    amount,
    CASE
        WHEN cluster_id IS NULL THEN '异常交易'
        ELSE '正常交易'
    END AS anomaly_status
FROM normalized_features nf
LEFT JOIN dbscan_result dr ON nf.transaction_id = dr.point_id;
```

---

## 7. 算法性能对比与选择

### 7.1 算法对比

| 特性 | K-means | DBSCAN | 层次聚类 |
|------|---------|--------|---------|
| **簇形状** | 球形 | 任意形状 | 任意形状 |
| **预设簇数** | 需要 | 不需要 | 不需要 |
| **噪声处理** | 无 | 有 | 无 |
| **时间复杂度** | $O(nki)$ | $O(n \log n)$ | $O(n^2 \log n)$ |
| **空间复杂度** | $O(nd)$ | $O(n)$ | $O(n^2)$ |
| **适用场景** | 大规模数据，球形簇 | 任意形状，噪声数据 | 小规模数据，可视化 |

### 7.2 算法选择指南

**选择K-means当**：

- 数据规模大（$n > 10000$）
- 簇是球形的
- 需要快速结果
- 簇数已知或可估计

**选择DBSCAN当**：

- 簇形状不规则
- 存在噪声数据
- 簇数未知
- 需要识别异常点

**选择层次聚类当**：

- 数据规模小（$n < 1000$）
- 需要可视化树状结构
- 需要不同粒度的聚类结果
- 簇数不确定

### 7.3 性能优化建议

1. **特征标准化**：使用Z-score或Min-Max标准化
2. **降维处理**：对高维数据使用PCA降维
3. **索引优化**：在特征列上创建索引加速距离计算
4. **并行处理**：使用PostgreSQL并行查询
5. **采样策略**：对大规模数据先采样再聚类

---

## 8. 最佳实践

### 8.1 数据预处理

1. **缺失值处理**：删除或填充缺失值
2. **异常值处理**：使用IQR方法识别和处理异常值
3. **特征选择**：选择相关性高的特征
4. **特征标准化**：统一特征量纲

### 8.2 参数调优

**K-means参数**：

- $k$：使用肘部法则（Elbow Method）或轮廓系数选择
- 初始化：使用K-means++减少迭代次数

**DBSCAN参数**：

- $\varepsilon$：使用k-distance图选择
- $MinPts$：通常设为维度+1

### 8.3 结果验证

1. **内部评估**：轮廓系数、WCSS、BCSS
2. **外部评估**：如果有标签，使用调整兰德指数（ARI）、标准化互信息（NMI）
3. **可视化**：使用散点图、树状图可视化结果
4. **业务验证**：结合实际业务场景验证聚类结果

### 8.4 常见问题与解决方案

**问题1**：K-means结果不稳定

- **解决方案**：使用K-means++初始化，多次运行取最优结果

**问题2**：DBSCAN将所有点标记为噪声

- **解决方案**：减小$\varepsilon$或$MinPts$参数

**问题3**：聚类结果不符合预期

- **解决方案**：检查特征选择、标准化方法、距离度量

**问题4**：计算时间过长

- **解决方案**：使用采样、降维、索引优化

---

## 📚 参考资源

### 学术文献

1. **MacQueen, J. (1967)**: "Some Methods for Classification and Analysis of Multivariate Observations", *Proceedings of the 5th Berkeley Symposium*.

2. **Ester, M., et al. (1996)**: "A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise", *KDD*.

3. **Rousseeuw, P.J. (1987)**: "Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis", *Journal of Computational and Applied Mathematics*.

4. **Arthur, D., Vassilvitskii, S. (2007)**: "K-means++: The Advantages of Careful Seeding", *SODA*.

### 在线资源

- **scikit-learn文档**: <https://scikit-learn.org/stable/modules/clustering.html>
- **PostgreSQL官方文档**: <https://www.postgresql.org/docs/>
- **聚类算法可视化**: <https://www.naftaliharis.com/scikit-learn/cluster/>

### 相关算法

- **谱聚类**：基于图论的聚类方法
- **高斯混合模型**：概率聚类方法
- **模糊C-means**：软聚类方法
- **Mean Shift**：基于密度的聚类方法

---

**最后更新**: 2025年1月
**维护者**: PostgreSQL Modern Team
**文档状态**: ✅ 已改进完成
