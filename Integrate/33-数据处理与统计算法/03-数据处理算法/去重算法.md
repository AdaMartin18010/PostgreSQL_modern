# PostgreSQL 去重算法完整指南

> **创建日期**: 2025年1月
> **技术栈**: PostgreSQL 17+/18+ | 去重算法 | 数据清洗
> **难度级别**: ⭐⭐⭐ (中级)

---

## 📋 目录

- [PostgreSQL 去重算法完整指南](#postgresql-去重算法完整指南)
  - [📋 目录](#-目录)
  - [去重算法概述](#去重算法概述)
    - [理论基础](#理论基础)
      - [去重问题定义](#去重问题定义)
      - [去重算法分类](#去重算法分类)
      - [去重策略选择](#去重策略选择)
    - [核心去重功能](#核心去重功能)
  - [1. DISTINCT去重](#1-distinct去重)
    - [1.1 DISTINCT去重原理](#11-distinct去重原理)
      - [DISTINCT执行过程](#distinct执行过程)
      - [DISTINCT与NULL值](#distinct与null值)
    - [1.2 单列去重实现](#12-单列去重实现)
    - [1.3 多列去重实现](#13-多列去重实现)
    - [1.4 DISTINCT ON去重](#14-distinct-on去重)
  - [2. GROUP BY去重](#2-group-by去重)
    - [2.1 分组去重](#21-分组去重)
  - [3. 窗口函数去重](#3-窗口函数去重)
    - [3.1 保留第一条记录](#31-保留第一条记录)
  - [4. 去重优化策略](#4-去重优化策略)
    - [4.1 索引优化去重](#41-索引优化去重)
    - [4.2 哈希去重优化](#42-哈希去重优化)
    - [4.3 并行去重优化](#43-并行去重优化)
  - [5. 实际应用案例](#5-实际应用案例)
    - [5.1 重复订单检测](#51-重复订单检测)
    - [5.2 数据清洗去重](#52-数据清洗去重)
    - [5.3 唯一性验证](#53-唯一性验证)
    - [5.4 去重性能监控](#54-去重性能监控)
  - [6. 算法性能对比与优化](#6-算法性能对比与优化)
    - [6.1 去重方法对比](#61-去重方法对比)
    - [6.2 性能优化建议](#62-性能优化建议)
    - [6.3 常见问题与解决方案](#63-常见问题与解决方案)
  - [7. 最佳实践](#7-最佳实践)
    - [7.1 去重方法选择](#71-去重方法选择)
    - [7.2 索引设计](#72-索引设计)
    - [7.3 查询优化](#73-查询优化)
    - [7.4 SQL实现注意事项](#74-sql实现注意事项)
  - [📚 参考资源](#-参考资源)
    - [学术文献](#学术文献)
    - [PostgreSQL官方文档](#postgresql官方文档)
    - [在线资源](#在线资源)
    - [相关算法](#相关算法)

---

## 去重算法概述

**去重算法（Deduplication Algorithm）**用于去除重复记录，是数据清洗和数据处理的核心操作之一。PostgreSQL提供了多种去重方式，每种方式适用于不同的场景。

### 理论基础

#### 去重问题定义

**去重问题**：给定一个关系$R$，找到所有唯一的元组集合$R'$，使得：
$$R' = \{t \in R | \forall t' \in R', t \neq t'\}$$

对于基于列的去重，给定列集合$C = \{c_1, c_2, \ldots, c_k\}$，找到所有唯一的列值组合：
$$R' = \{t[C] | t \in R, \forall t' \in R', t[C] \neq t'[C]\}$$

#### 去重算法分类

PostgreSQL使用三种主要去重策略：

1. **DISTINCT去重**：
   - 使用排序或哈希去重
   - 时间复杂度：$O(n \log n)$（排序）或$O(n)$（哈希）
   - 空间复杂度：$O(n)$
   - 适用于简单去重

2. **GROUP BY去重**：
   - 使用分组操作去重
   - 时间复杂度：$O(n \log n)$
   - 空间复杂度：$O(n)$
   - 适用于需要聚合的去重

3. **窗口函数去重**：
   - 使用窗口函数选择记录
   - 时间复杂度：$O(n \log n)$
   - 空间复杂度：$O(n)$
   - 适用于需要选择特定记录的去重

#### 去重策略选择

PostgreSQL查询优化器根据以下因素选择去重策略：

1. **数据量**：小数据集使用排序，大数据集使用哈希
2. **内存限制**：根据work_mem配置选择策略
3. **索引可用性**：有索引时可以使用索引优化
4. **是否需要聚合**：需要聚合时使用GROUP BY

### 核心去重功能

| 功能 | 数学定义 | 用途 | 时间复杂度 | 空间复杂度 | 适用场景 |
|------|---------|------|-----------|-----------|---------|
| **DISTINCT** | $R' = \{t[C] \mid t \in R, \forall t' \in R', t[C] \neq t'[C]\}$ | 简单去重 | $O(n \log n)$ | $O(n)$ | 简单去重 |
| **GROUP BY** | $R' = \{t[C] \mid t \in R\}$ + 聚合 | 分组去重 | $O(n \log n)$ | $O(n)$ | 需要聚合 |
| **窗口函数** | $R' = \{t \mid t \in R, \text{rank}(t) = 1\}$ | 选择记录 | $O(n \log n)$ | $O(n)$ | 选择特定记录 |

---

## 1. DISTINCT去重

### 1.1 DISTINCT去重原理

**DISTINCT子句**用于去除查询结果中的重复行，是SQL标准中最常用的去重方式。

#### DISTINCT执行过程

DISTINCT的执行过程：

1. **数据获取**：从表中获取所有符合条件的记录
2. **去重操作**：根据SELECT子句中的列进行去重
3. **结果返回**：返回去重后的结果集

PostgreSQL使用两种策略实现DISTINCT：

- **排序去重**：先排序，然后去除相邻重复项
- **哈希去重**：使用哈希表记录已出现的值

#### DISTINCT与NULL值

- **NULL值处理**：多个NULL值被视为相同，只保留一个
- **NULL值比较**：使用`IS NULL`和`IS NOT NULL`判断

### 1.2 单列去重实现

**单列去重**去除单列的重复值。

```sql
-- DISTINCT单列去重（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'orders') THEN
            RAISE WARNING '表 orders 不存在，无法执行DISTINCT去重';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行DISTINCT单列去重';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'DISTINCT去重准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 单列去重：获取所有唯一的客户ID
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT customer_id
FROM orders
ORDER BY customer_id;

-- 单列去重：获取所有唯一的产品类别
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT category
FROM products
ORDER BY category;
```

### 1.3 多列去重实现

**多列去重**去除多列组合的重复值。

```sql
-- DISTINCT多列去重（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sales') THEN
            RAISE WARNING '表 sales 不存在，无法执行多列去重';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行DISTINCT多列去重';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '多列去重准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 多列去重：获取唯一的客户-产品组合
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT customer_id, product_id
FROM sales
ORDER BY customer_id, product_id;

-- 多列去重：获取唯一的日期-类别组合
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT DATE_TRUNC('day', sale_date) AS sale_day, category
FROM sales
ORDER BY sale_day, category;
```

### 1.4 DISTINCT ON去重

**DISTINCT ON**是PostgreSQL特有的语法，用于获取每个分组的第一条记录。

```sql
-- DISTINCT ON去重（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'orders') THEN
            RAISE WARNING '表 orders 不存在，无法执行DISTINCT ON去重';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行DISTINCT ON去重';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'DISTINCT ON去重准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- DISTINCT ON：每个客户的最新订单
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT ON (customer_id)
    customer_id,
    order_id,
    order_date,
    amount
FROM orders
ORDER BY customer_id, order_date DESC;
```

---

## 2. GROUP BY去重

### 2.1 分组去重

**GROUP BY去重**使用分组去除重复，同时保留其他列。

```sql
-- GROUP BY去重（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'orders') THEN
            RAISE WARNING '表 orders 不存在，无法执行GROUP BY去重';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行GROUP BY去重';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'GROUP BY去重准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT
    customer_id,
    product_id,
    MAX(order_date) AS latest_order_date,
    SUM(amount) AS total_amount
FROM orders
GROUP BY customer_id, product_id;
```

---

## 3. 窗口函数去重

### 3.1 保留第一条记录

**窗口函数去重**使用ROW_NUMBER保留每组的第一条记录。

```sql
-- 窗口函数去重（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'orders') THEN
            RAISE WARNING '表 orders 不存在，无法执行窗口函数去重';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行窗口函数去重';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '窗口函数去重准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT *
FROM (
    SELECT
        *,
        ROW_NUMBER() OVER (PARTITION BY customer_id, product_id ORDER BY order_date DESC) AS rn
    FROM orders
) AS ranked
WHERE rn = 1;
```

---

## 4. 去重优化策略

### 4.1 索引优化去重

**索引优化去重**：创建合适的索引可以加速去重操作。

```sql
-- 索引优化去重（带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'orders') THEN
            RAISE WARNING '表 orders 不存在，无法创建索引';
            RETURN;
        END IF;

        -- 创建索引优化去重
        CREATE INDEX IF NOT EXISTS idx_orders_customer_product
        ON orders(customer_id, product_id);

        RAISE NOTICE '索引创建成功';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '索引创建失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 使用索引优化去重
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT customer_id, product_id
FROM orders;
```

### 4.2 哈希去重优化

**哈希去重优化**：PostgreSQL自动选择哈希去重策略，适用于大数据集。

```sql
-- 哈希去重优化（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        -- 增加work_mem以支持哈希去重
        SET work_mem = '256MB';
        RAISE NOTICE 'work_mem已设置为256MB';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'work_mem设置失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 大数据集去重（使用哈希策略）
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT customer_id, product_id
FROM large_sales_table;
```

### 4.3 并行去重优化

**并行去重优化**：PostgreSQL支持并行去重，提高性能。

```sql
-- 并行去重优化（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        -- 启用并行查询
        SET max_parallel_workers_per_gather = 4;
        RAISE NOTICE '并行查询已启用';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '并行查询设置失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 并行去重查询
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT DISTINCT customer_id, product_id
FROM large_sales_table;
```

---

## 5. 实际应用案例

### 5.1 重复订单检测

**重复订单检测**识别并处理重复订单。

```sql
-- 重复订单检测（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'orders') THEN
            RAISE WARNING '表 orders 不存在，无法执行重复订单检测';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行重复订单检测';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '重复订单检测准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 检测重复订单
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT
    customer_id,
    product_id,
    order_date,
    COUNT(*) AS duplicate_count
FROM orders
GROUP BY customer_id, product_id, order_date
HAVING COUNT(*) > 1
ORDER BY duplicate_count DESC;

-- 删除重复订单（保留最新的一条）
DELETE FROM orders
WHERE order_id IN (
    SELECT order_id
    FROM (
        SELECT
            order_id,
            ROW_NUMBER() OVER (
                PARTITION BY customer_id, product_id, order_date
                ORDER BY order_id DESC
            ) AS rn
        FROM orders
    ) AS ranked
    WHERE rn > 1
);
```

### 5.2 数据清洗去重

**数据清洗去重**：清洗数据中的重复记录。

```sql
-- 数据清洗去重（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'raw_data') THEN
            RAISE WARNING '表 raw_data 不存在，无法执行数据清洗去重';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行数据清洗去重';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '数据清洗去重准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 创建去重后的表
CREATE TABLE cleaned_data AS
SELECT DISTINCT ON (customer_id, email)
    customer_id,
    name,
    email,
    phone,
    created_at
FROM raw_data
ORDER BY customer_id, email, created_at DESC;

-- 验证去重结果
SELECT
    COUNT(*) AS original_count,
    (SELECT COUNT(*) FROM cleaned_data) AS cleaned_count,
    COUNT(*) - (SELECT COUNT(*) FROM cleaned_data) AS duplicates_removed
FROM raw_data;
```

### 5.3 唯一性验证

**唯一性验证**：验证数据的唯一性约束。

```sql
-- 唯一性验证（带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'users') THEN
            RAISE WARNING '表 users 不存在，无法执行唯一性验证';
            RETURN;
        END IF;
        RAISE NOTICE '开始执行唯一性验证';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '唯一性验证准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 验证邮箱唯一性
SELECT
    email,
    COUNT(*) AS count
FROM users
GROUP BY email
HAVING COUNT(*) > 1
ORDER BY count DESC;

-- 验证用户名唯一性
SELECT
    username,
    COUNT(*) AS count
FROM users
GROUP BY username
HAVING COUNT(*) > 1
ORDER BY count DESC;
```

### 5.4 去重性能监控

**去重性能监控**：监控去重操作的性能。

```sql
-- 去重性能监控（带错误处理）
DO $$
BEGIN
    BEGIN
        -- 创建去重性能监控表
        CREATE TABLE IF NOT EXISTS deduplication_performance_log (
            id SERIAL PRIMARY KEY,
            query_text TEXT NOT NULL,
            table_name VARCHAR(100),
            deduplication_method VARCHAR(50),
            row_count_before BIGINT,
            row_count_after BIGINT,
            execution_time_ms NUMERIC(10, 2),
            created_at TIMESTAMPTZ DEFAULT NOW()
        );

        RAISE NOTICE '去重性能监控表已创建';
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '去重性能监控表已存在';
        WHEN OTHERS THEN
            RAISE EXCEPTION '创建去重性能监控表失败: %', SQLERRM;
    END;
END $$;

-- 分析去重性能
SELECT
    table_name,
    deduplication_method,
    AVG(execution_time_ms) AS avg_execution_time,
    AVG(row_count_before - row_count_after) AS avg_duplicates_removed,
    COUNT(*) AS query_count
FROM deduplication_performance_log
GROUP BY table_name, deduplication_method
ORDER BY avg_execution_time DESC;
```

---

## 6. 算法性能对比与优化

### 6.1 去重方法对比

| 去重方法 | 时间复杂度 | 空间复杂度 | 适用场景 | 优点 | 缺点 |
|---------|-----------|-----------|---------|------|------|
| **DISTINCT** | $O(n \log n)$ | $O(n)$ | 简单去重 | 简单直接 | 需要排序或哈希 |
| **GROUP BY** | $O(n \log n)$ | $O(n)$ | 需要聚合 | 可聚合 | 需要排序 |
| **窗口函数** | $O(n \log n)$ | $O(n)$ | 选择记录 | 灵活 | 需要排序 |
| **DISTINCT ON** | $O(n \log n)$ | $O(n)$ | 分组第一条 | PostgreSQL特有 | 需要排序 |

### 6.2 性能优化建议

1. **索引优化**：
   - 在去重列上创建索引
   - 使用复合索引优化多列去重

2. **哈希优化**：
   - 增加work_mem支持哈希去重
   - 大数据集使用哈希策略

3. **并行优化**：
   - 启用并行查询
   - 大数据集使用并行去重

4. **查询优化**：
   - 使用DISTINCT ON替代窗口函数（PostgreSQL特有）
   - 避免不必要的去重

### 6.3 常见问题与解决方案

**问题1**：去重性能慢

- **解决方案**：创建索引、增加work_mem、使用并行查询

**问题2**：内存不足

- **解决方案**：增加work_mem配置、使用外部排序

**问题3**：去重结果不符合预期

- **解决方案**：检查NULL值处理、确认去重列选择

**问题4**：需要保留特定记录

- **解决方案**：使用窗口函数或DISTINCT ON

---

## 7. 最佳实践

### 7.1 去重方法选择

1. **简单去重**：使用DISTINCT
2. **需要聚合**：使用GROUP BY
3. **选择记录**：使用窗口函数或DISTINCT ON
4. **大数据集**：使用哈希去重策略

### 7.2 索引设计

1. **单列去重**：在去重列上创建索引
2. **多列去重**：创建复合索引
3. **DISTINCT ON**：在ON列上创建索引

### 7.3 查询优化

1. **使用LIMIT**：只获取需要的记录数
2. **避免全表去重**：使用WHERE条件过滤数据
3. **使用DISTINCT ON**：PostgreSQL特有，性能更好

### 7.4 SQL实现注意事项

1. **NULL值处理**：明确NULL值的去重行为
2. **数据类型**：数值类型去重比字符串类型快
3. **性能监控**：定期检查去重性能，识别优化机会
4. **数据量**：根据数据量选择去重策略

---

## 📚 参考资源

### 学术文献

- 《数据库系统概念》（Database System Concepts）- 查询优化和去重
- 《SQL权威指南》（SQL: The Complete Reference）- DISTINCT和GROUP BY

### PostgreSQL官方文档

- [SELECT DISTINCT](https://www.postgresql.org/docs/current/sql-select.html#SQL-DISTINCT)
- [DISTINCT ON](https://www.postgresql.org/docs/current/sql-select.html#SQL-DISTINCT)
- [查询规划器](https://www.postgresql.org/docs/current/planner-optimizer.html)

### 在线资源

- PostgreSQL性能优化指南
- 去重算法最佳实践
- 数据清洗技术

### 相关算法

- [排序算法](./排序算法.md) - DISTINCT需要排序
- [分组算法](./分组算法.md) - GROUP BY去重
- [数据清洗算法](../12-数据质量算法/数据清洗算法.md) - 数据清洗中的去重

---

**最后更新**: 2025年1月
**维护者**: PostgreSQL Modern Team
