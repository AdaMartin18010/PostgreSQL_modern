---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\06-å…¨æ–‡æœç´¢ç³»ç»Ÿ\04-æ ¸å¿ƒå®ç°.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# æ¡ˆä¾‹6ï¼šå…¨æ–‡æœç´¢ç³»ç»Ÿ - æ ¸å¿ƒå®ç°

## å…ƒæ•°æ®

- **åˆ›å»ºæ—¥æœŸ**: 2025-12-04
- **æŠ€æœ¯æ ˆ**: PostgreSQL 18 + Python + FastAPI
- **æ€§èƒ½**: msçº§æœç´¢å“åº”

---

## 1. æœç´¢å¼•æ“æ¨¡å—

```python
"""
å…¨æ–‡æœç´¢å¼•æ“
"""

import psycopg2
from psycopg2.extras import RealDictCursor
from fastapi import FastAPI, Query
import time

app = FastAPI()

DB_CONFIG = {
    'dbname': 'search_db',
    'user': 'postgres',
    'host': 'localhost'
}

def get_connection():
    """è·å–æ•°æ®åº“è¿æ¥ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰"""
    try:
        return psycopg2.connect(**DB_CONFIG, cursor_factory=RealDictCursor)
    except psycopg2.OperationalError as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        raise
    except psycopg2.Error as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        raise

@app.get("/api/search")
async def search(
    q: str = Query(..., description="æœç´¢å…³é”®è¯"),
    category: str = Query(None, description="åˆ†ç±»è¿‡æ»¤"),
    limit: int = Query(20, le=100),
    offset: int = Query(0, ge=0)
):
    """
    å…¨æ–‡æœç´¢API

    æ”¯æŒ:
    - ä¸­æ–‡åˆ†è¯
    - ç›¸å…³æ€§æ’åº
    - é«˜äº®æ˜¾ç¤º
    - åˆ†ç±»è¿‡æ»¤
    """

    # å‚æ•°éªŒè¯
    if not q or not q.strip():
        from fastapi import HTTPException
        raise HTTPException(status_code=400, detail="æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º")
    if limit <= 0 or limit > 1000:
        limit = 20
    if offset < 0:
        offset = 0

    start_time = time.time()

    conn = None
    cursor = None
    try:
        conn = get_connection()
        cursor = conn.cursor()

        # æ„å»ºæŸ¥è¯¢
        if category:
            query = """
                SELECT
                    doc_id,
                    title,
                    ts_headline('zh_parser', content, query,
                        'MaxWords=50, MinWords=30, StartSel=<b>, StopSel=</b>') AS snippet,
                    ts_rank_cd(search_vector, query) AS rank
                FROM documents,
                     to_tsquery('zh_parser', %s) query
                WHERE search_vector @@ query
                  AND category = %s
                ORDER BY rank DESC, created_at DESC
                LIMIT %s OFFSET %s;
            """
            cursor.execute(query, (q, category, limit, offset))
        else:
            query = """
                SELECT
                    doc_id,
                    title,
                    ts_headline('zh_parser', content, query,
                        'MaxWords=50, MinWords=30, StartSel=<b>, StopSel=</b>') AS snippet,
                    ts_rank_cd(search_vector, query) AS rank
                FROM documents,
                     to_tsquery('zh_parser', %s) query
                WHERE search_vector @@ query
                ORDER BY rank DESC, created_at DESC
                LIMIT %s OFFSET %s;
            """
            cursor.execute(query, (q, limit, offset))

        results = cursor.fetchall()
        duration = (time.time() - start_time) * 1000

        # è®°å½•æœç´¢æ—¥å¿—
        try:
            cursor.execute("""
                INSERT INTO search_logs (query_text, result_count, duration_ms)
                VALUES (%s, %s, %s);
            """, (q, len(results), duration))
            conn.commit()
        except Exception as e:
            print(f"è®°å½•æœç´¢æ—¥å¿—å¤±è´¥: {e}")
            conn.rollback()

        return {
            'success': True,
            'results': results,
            'count': len(results),
            'duration_ms': duration
        }

    except psycopg2.OperationalError as e:
        print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=503, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
    except psycopg2.Error as e:
        print(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        if conn:
            conn.rollback()
        raise HTTPException(status_code=500, detail="æ•°æ®åº“æ“ä½œå¤±è´¥")
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail="ç³»ç»Ÿé”™è¯¯")
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

@app.get("/api/search/suggest")
async def search_suggest(q: str = Query(..., min_length=2)):
    """æœç´¢å»ºè®®ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰"""
    from fastapi import HTTPException
    import psycopg2

    conn = None
    cursor = None
    try:
        conn = get_connection()
        cursor = conn.cursor()

        # åŸºäºå†å²æœç´¢çš„å»ºè®®
        cursor.execute("""
            SELECT DISTINCT query_text, COUNT(*) as freq
            FROM search_logs
            WHERE query_text LIKE %s
            GROUP BY query_text
            ORDER BY freq DESC
            LIMIT 10;
        """, (f'{q}%',))

        suggestions = cursor.fetchall()

        return {
            'success': True,
            'suggestions': [s['query_text'] for s in suggestions]
        }

    except psycopg2.OperationalError as e:
        print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=503, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
    except psycopg2.Error as e:
        print(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ•°æ®åº“æ“ä½œå¤±è´¥")
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail="ç³»ç»Ÿé”™è¯¯")
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
```

---

## 2. ç´¢å¼•ç®¡ç†æ¨¡å—

```python
class SearchIndexManager:
    """æœç´¢ç´¢å¼•ç®¡ç†å™¨"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def rebuild_search_index(self):
        """é‡å»ºæœç´¢ç´¢å¼•ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰"""
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            self.cursor.execute("""
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'documents';
            """)
            if not self.cursor.fetchone():
                raise ValueError("è¡¨ documents ä¸å­˜åœ¨")

            # 1. åˆ é™¤æ—§ç´¢å¼•
            self.cursor.execute("DROP INDEX IF EXISTS idx_documents_search;")

            # 2. é‡æ–°åˆ›å»ºï¼ˆPostgreSQL 18å¹¶è¡Œæ„å»ºï¼‰
            self.cursor.execute("""
                CREATE INDEX idx_documents_search
                ON documents
                USING GIN (search_vector);
            """)

            self.conn.commit()
            print("âœ… æœç´¢ç´¢å¼•é‡å»ºå®Œæˆ")
        except psycopg2.ProgrammingError as e:
            print(f"âŒ é‡å»ºç´¢å¼•å¤±è´¥ï¼ˆè¯­æ³•é”™è¯¯ï¼‰: {e}")
            self.conn.rollback()
            raise
        except psycopg2.OperationalError as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
            self.conn.rollback()
            raise
        except psycopg2.Error as e:
            print(f"âŒ é‡å»ºç´¢å¼•å¤±è´¥: {e}")
            self.conn.rollback()
            raise
        except Exception as e:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
            self.conn.rollback()
            raise

    def get_index_stats(self):
        """è·å–ç´¢å¼•ç»Ÿè®¡ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰"""
        try:
            self.cursor.execute("""
                SELECT
                    pg_size_pretty(pg_relation_size('idx_documents_search')) AS index_size,
                    pg_stat_get_numscans('idx_documents_search'::regclass) AS scan_count
            """)

            return self.cursor.fetchone()
        except psycopg2.ProgrammingError as e:
            print(f"âŒ æŸ¥è¯¢ç´¢å¼•ç»Ÿè®¡å¤±è´¥ï¼ˆç´¢å¼•ä¸å­˜åœ¨æˆ–è¯­æ³•é”™è¯¯ï¼‰: {e}")
            return {'index_size': 'N/A', 'scan_count': 0}
        except psycopg2.OperationalError as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
            raise
        except psycopg2.Error as e:
            print(f"âŒ æŸ¥è¯¢ç´¢å¼•ç»Ÿè®¡å¤±è´¥: {e}")
            raise
        except Exception as e:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
            raise
```

---

---

## 3. é«˜çº§æœç´¢åŠŸèƒ½

### 3.1 å¤šå­—æ®µæœç´¢

**å¤šå­—æ®µæœç´¢å®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
@app.get("/api/search/multi-field")
async def multi_field_search(
    q: str = Query(..., description="æœç´¢å…³é”®è¯"),
    fields: str = Query("title,content", description="æœç´¢å­—æ®µï¼Œé€—å·åˆ†éš”"),
    limit: int = Query(20, le=100)
):
    """å¤šå­—æ®µæœç´¢"""

    start_time = time.time()
    conn = get_connection()
    cursor = conn.cursor()

    try:
        # è§£æå­—æ®µåˆ—è¡¨
        field_list = [f.strip() for f in fields.split(',')]

        # æ„å»ºå¤šå­—æ®µtsvector
        tsvector_expr = " || ".join([
            f"setweight(to_tsvector('zh_parser', COALESCE({field}, '')), 'A')"
            if field == 'title' else
            f"setweight(to_tsvector('zh_parser', COALESCE({field}, '')), 'B')"
            for field in field_list
        ])

        query = f"""
            SELECT
                doc_id,
                title,
                ts_headline('zh_parser', content, query,
                    'MaxWords=50, MinWords=30, StartSel=<mark>, StopSel=</mark>') AS snippet,
                ts_rank_cd(({tsvector_expr}), query) AS rank
            FROM documents,
                 to_tsquery('zh_parser', %s) query
            WHERE ({tsvector_expr}) @@ query
            ORDER BY rank DESC, created_at DESC
            LIMIT %s;
        """

        cursor.execute(query, (q, limit))
        results = cursor.fetchall()
        duration = (time.time() - start_time) * 1000

        return {
            'success': True,
            'results': results,
            'count': len(results),
            'duration_ms': duration
        }

    finally:
        cursor.close()
        conn.close()
```

### 3.2 æ¨¡ç³Šæœç´¢

**æ¨¡ç³Šæœç´¢å®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
@app.get("/api/search/fuzzy")
async def fuzzy_search(
    q: str = Query(..., description="æœç´¢å…³é”®è¯"),
    similarity_threshold: float = Query(0.7, ge=0.0, le=1.0),
    limit: int = Query(20, le=100)
):
    """æ¨¡ç³Šæœç´¢ï¼ˆä½¿ç”¨pg_trgmï¼‰"""

    start_time = time.time()
    conn = get_connection()
    cursor = conn.cursor()

    try:
        # ç¡®ä¿pg_trgmæ‰©å±•å·²å®‰è£…
        cursor.execute("CREATE EXTENSION IF NOT EXISTS pg_trgm;")

        query = """
            SELECT
                doc_id,
                title,
                content,
                similarity(title, %s) AS title_sim,
                similarity(content, %s) AS content_sim,
                GREATEST(similarity(title, %s), similarity(content, %s)) AS max_sim
            FROM documents
            WHERE similarity(title, %s) > %s
               OR similarity(content, %s) > %s
            ORDER BY max_sim DESC
            LIMIT %s;
        """

        cursor.execute(query, (q, q, q, q, q, similarity_threshold, q, similarity_threshold, limit))
        results = cursor.fetchall()
        duration = (time.time() - start_time) * 1000

        return {
            'success': True,
            'results': results,
            'count': len(results),
            'duration_ms': duration
        }

    finally:
        cursor.close()
        conn.close()
```

---

## 4. æœç´¢æ—¥å¿—åˆ†æ

### 4.1 æœç´¢æ—¥å¿—ç»Ÿè®¡

**æœç´¢æ—¥å¿—ç»Ÿè®¡å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- æœç´¢æ—¥å¿—ç»Ÿè®¡å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION get_search_statistics(
    p_start_date TIMESTAMPTZ DEFAULT NOW() - INTERVAL '7 days',
    p_end_date TIMESTAMPTZ DEFAULT NOW()
)
RETURNS TABLE (
    metric_name TEXT,
    metric_value NUMERIC,
    description TEXT
) AS $$
BEGIN
    BEGIN
        IF p_start_date IS NULL OR p_end_date IS NULL THEN
            RAISE EXCEPTION 'start_dateå’Œend_dateä¸èƒ½ä¸ºNULL';
        END IF;

        IF p_start_date > p_end_date THEN
            RAISE EXCEPTION 'start_dateä¸èƒ½å¤§äºend_date';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'search_logs') THEN
            RAISE EXCEPTION 'è¡¨ search_logs ä¸å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'å‚æ•°éªŒè¯å¤±è´¥: %', SQLERRM;
            RAISE;
    END;

    BEGIN
        -- æ€»æœç´¢æ¬¡æ•°
        RETURN QUERY SELECT
            'æ€»æœç´¢æ¬¡æ•°'::TEXT,
            COUNT(*)::NUMERIC,
            'æ—¶é—´æ®µå†…çš„æ€»æœç´¢æ¬¡æ•°'::TEXT
        FROM search_logs
        WHERE created_at BETWEEN p_start_date AND p_end_date;

        -- å¹³å‡ç»“æœæ•°
        RETURN QUERY SELECT
            'å¹³å‡ç»“æœæ•°'::TEXT,
            ROUND(AVG(result_count), 2)::NUMERIC,
            'å¹³å‡æ¯æ¬¡æœç´¢è¿”å›çš„ç»“æœæ•°'::TEXT
        FROM search_logs
        WHERE created_at BETWEEN p_start_date AND p_end_date;

        -- å¹³å‡å“åº”æ—¶é—´
        RETURN QUERY SELECT
            'å¹³å‡å“åº”æ—¶é—´(ms)'::TEXT,
            ROUND(AVG(duration_ms), 2)::NUMERIC,
            'å¹³å‡æœç´¢å“åº”æ—¶é—´'::TEXT
        FROM search_logs
        WHERE created_at BETWEEN p_start_date AND p_end_date;

        -- é›¶ç»“æœç‡
        RETURN QUERY SELECT
            'é›¶ç»“æœç‡(%)'::TEXT,
            ROUND(COUNT(*) FILTER (WHERE result_count = 0) * 100.0 / NULLIF(COUNT(*), 0), 2)::NUMERIC,
            'æ²¡æœ‰è¿”å›ç»“æœçš„æœç´¢å æ¯”'::TEXT
        FROM search_logs
        WHERE created_at BETWEEN p_start_date AND p_end_date;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æœç´¢ç»Ÿè®¡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END;
$$ LANGUAGE plpgsql;
```

### 4.2 çƒ­é—¨æœç´¢è¯

**çƒ­é—¨æœç´¢è¯æŸ¥è¯¢å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- çƒ­é—¨æœç´¢è¯å‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION get_popular_search_terms(
    p_limit INT DEFAULT 20,
    p_days INT DEFAULT 7
)
RETURNS TABLE (
    query_text TEXT,
    search_count BIGINT,
    avg_result_count NUMERIC,
    avg_duration_ms NUMERIC
) AS $$
BEGIN
    BEGIN
        -- å‚æ•°éªŒè¯
        IF p_limit IS NULL OR p_limit <= 0 THEN
            RAISE EXCEPTION 'limitå¿…é¡»å¤§äº0';
        END IF;

        IF p_days IS NULL OR p_days <= 0 THEN
            RAISE EXCEPTION 'dayså¿…é¡»å¤§äº0';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'search_logs') THEN
            RAISE EXCEPTION 'è¡¨ search_logs ä¸å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'å‚æ•°éªŒè¯å¤±è´¥: %', SQLERRM;
            RAISE;
    END;

    BEGIN
        RETURN QUERY
        SELECT
            query_text,
            COUNT(*)::BIGINT AS search_count,
            ROUND(AVG(result_count), 2) AS avg_result_count,
            ROUND(AVG(duration_ms), 2) AS avg_duration_ms
        FROM search_logs
        WHERE created_at > NOW() - (p_days || ' days')::INTERVAL
        GROUP BY query_text
        ORDER BY search_count DESC
        LIMIT p_limit;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'çƒ­é—¨æœç´¢è¯æŸ¥è¯¢å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END;
$$ LANGUAGE plpgsql;
```

---

## 5. ç´¢å¼•ç»´æŠ¤è‡ªåŠ¨åŒ–

### 5.1 è‡ªåŠ¨ç´¢å¼•ç»´æŠ¤

**è‡ªåŠ¨ç´¢å¼•ç»´æŠ¤å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class AutoIndexMaintenance:
    """è‡ªåŠ¨ç´¢å¼•ç»´æŠ¤"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def check_index_health(self):
        """æ£€æŸ¥ç´¢å¼•å¥åº·çŠ¶æ€"""

        self.cursor.execute("""
            SELECT
                schemaname,
                tablename,
                indexname,
                pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
                idx_scan AS scan_count,
                idx_tup_read AS tuples_read,
                idx_tup_fetch AS tuples_fetched,
                CASE
                    WHEN idx_scan = 0 THEN 'æœªä½¿ç”¨'
                    WHEN pg_relation_size(indexrelid) > 1073741824 THEN 'ç´¢å¼•è¿‡å¤§'
                    ELSE 'æ­£å¸¸'
                END AS health_status
            FROM pg_stat_user_indexes
            WHERE schemaname = 'public'
              AND tablename = 'documents'
            ORDER BY pg_relation_size(indexrelid) DESC;
        """)

        return self.cursor.fetchall()

    def rebuild_index_if_needed(self, index_name, min_bloat_percent=20):
        """å¦‚æœéœ€è¦åˆ™é‡å»ºç´¢å¼•"""

        # æ£€æŸ¥ç´¢å¼•è†¨èƒ€ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.cursor.execute("""
            SELECT pg_size_pretty(pg_relation_size(%s::regclass)) AS index_size
        """, (index_name,))

        index_size = self.cursor.fetchone()[0]

        # å¦‚æœç´¢å¼•è¿‡å¤§ï¼Œé‡å»º
        if self._should_rebuild_index(index_name):
            print(f"é‡å»ºç´¢å¼•: {index_name}")
            self.cursor.execute(f"REINDEX INDEX CONCURRENTLY {index_name};")
            self.conn.commit()
            print(f"âœ… ç´¢å¼•é‡å»ºå®Œæˆ: {index_name}")

    def _should_rebuild_index(self, index_name):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # å®é™…åº”è¯¥æ£€æŸ¥è†¨èƒ€ç‡ç­‰æŒ‡æ ‡
        return False
```

---

## 6. æœç´¢æ€§èƒ½ä¼˜åŒ–

### 6.1 PostgreSQL 18æœç´¢ä¼˜åŒ–

**PostgreSQL 18æœç´¢ä¼˜åŒ–ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- PostgreSQL 18å¼‚æ­¥I/Oé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = current_user AND rolsuper = true) THEN
            RAISE WARNING 'éœ€è¦è¶…çº§ç”¨æˆ·æƒé™æ¥é…ç½®ç³»ç»Ÿå‚æ•°ï¼Œè·³è¿‡é…ç½®';
            RAISE NOTICE 'å®é™…é…ç½®éœ€è¦åœ¨postgresql.confä¸­è®¾ç½®æˆ–ä½¿ç”¨ALTER SYSTEMï¼š';
            RAISE NOTICE 'ALTER SYSTEM SET io_direct = ''data'';';
            RAISE NOTICE 'ALTER SYSTEM SET io_combine_limit = ''256kB'';';
            RAISE NOTICE 'ç„¶åæ‰§è¡Œï¼šSELECT pg_reload_conf();';
            RETURN;
        END IF;

        -- å®é™…é…ç½®éœ€è¦åœ¨postgresql.confä¸­è®¾ç½®æˆ–ä½¿ç”¨ALTER SYSTEMï¼š
        -- ALTER SYSTEM SET io_direct = 'data';
        -- ALTER SYSTEM SET io_combine_limit = '256kB';
        -- ç„¶åæ‰§è¡Œï¼šSELECT pg_reload_conf();
        RAISE NOTICE 'å¼‚æ­¥I/Oé…ç½®å·²è®¾ç½®ï¼ˆéœ€è¦é‡å¯æˆ–reloadé…ç½®ï¼‰';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'é…ç½®å¼‚æ­¥I/Oå¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ€§èƒ½æå‡:
-- GINç´¢å¼•æ‰«æ: +20-25%
-- å…¨æ–‡æœç´¢æŸ¥è¯¢: +15-20%
-- ç´¢å¼•æ„å»º: +30-35%
```

### 6.2 å¹¶è¡Œæœç´¢ä¼˜åŒ–

**å¹¶è¡Œæœç´¢ä¼˜åŒ–ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        SET LOCAL max_parallel_workers_per_gather = 4;
        SET LOCAL parallel_setup_cost = 1000;
        SET LOCAL parallel_tuple_cost = 0.01;
        RAISE NOTICE 'å¹¶è¡ŒæŸ¥è¯¢å‚æ•°å·²è®¾ç½®ï¼ˆä¼šè¯çº§åˆ«ï¼‰';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'è®¾ç½®å¹¶è¡ŒæŸ¥è¯¢å‚æ•°å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- å¹¶è¡Œå…¨æ–‡æœç´¢ç¤ºä¾‹ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'documents') THEN
            RAISE WARNING 'è¡¨ documents ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡Œå¹¶è¡Œå…¨æ–‡æœç´¢';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- å…¨æ–‡æœç´¢æŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'documents') THEN
            RAISE WARNING 'è¡¨ documents ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œå…¨æ–‡æœç´¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡Œå…¨æ–‡æœç´¢æŸ¥è¯¢';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    doc_id,
    title,
    ts_rank_cd(search_vector, query) AS rank
FROM documents,
     to_tsquery('zh_parser', 'æœç´¢å…³é”®è¯') query
WHERE search_vector @@ query
ORDER BY rank DESC
LIMIT 100;

-- æ€§èƒ½æå‡:
-- å¤§è¡¨æœç´¢: +35-40%
```

---

## 7. æœç´¢ç³»ç»Ÿç›‘æ§

### 7.1 æœç´¢æ€§èƒ½ç›‘æ§

**æœç´¢æ€§èƒ½ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class SearchPerformanceMonitor:
    """æœç´¢æ€§èƒ½ç›‘æ§"""

    def __init__(self, conn_str):
        self.conn = psycopg2.connect(conn_str)
        self.cursor = self.conn.cursor()

    def log_search(self, query: str, result_count: int, duration_ms: float):
        """è®°å½•æœç´¢æ—¥å¿—"""
        self.cursor.execute("""
            INSERT INTO search_logs (
                query_text, result_count, duration_ms, created_at
            ) VALUES (%s, %s, %s, NOW())
        """, (query[:200], result_count, duration_ms))
        self.conn.commit()

    def get_search_stats(self, hours: int = 24):
        """è·å–æœç´¢ç»Ÿè®¡"""
        self.cursor.execute("""
            SELECT
                COUNT(*) AS total_searches,
                AVG(duration_ms) AS avg_duration_ms,
                PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY duration_ms) AS p95_duration_ms,
                AVG(result_count) AS avg_result_count
            FROM search_logs
            WHERE created_at > NOW() - INTERVAL '%s hours'
        """, (hours,))

        return self.cursor.fetchone()
```

### 7.2 æœç´¢è´¨é‡ç›‘æ§

**æœç´¢è´¨é‡ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
def track_search_quality(query: str, clicked_doc_id: int):
    """è·Ÿè¸ªæœç´¢è´¨é‡"""
    conn = get_db()
    cursor = conn.cursor()

    try:
        # è®°å½•ç‚¹å‡»è¡Œä¸º
        cursor.execute("""
            INSERT INTO search_clicks (
                query_text, doc_id, click_position, created_at
            ) VALUES (%s, %s, %s, NOW())
        """, (query, clicked_doc_id, 1))

        conn.commit()

        # è®¡ç®—æœç´¢è´¨é‡æŒ‡æ ‡
        cursor.execute("""
            SELECT
                COUNT(*) AS total_searches,
                COUNT(*) FILTER (WHERE EXISTS (
                    SELECT 1 FROM search_clicks sc
                    WHERE sc.query_text = sl.query_text
                )) AS searches_with_clicks,
                AVG(result_count) AS avg_result_count
            FROM search_logs sl
            WHERE created_at > NOW() - INTERVAL '7 days'
        """)

        stats = cursor.fetchone()

        click_through_rate = (
            stats['searches_with_clicks'] / stats['total_searches']
            if stats['total_searches'] > 0 else 0
        )

        return {
            'click_through_rate': click_through_rate,
            'avg_result_count': stats['avg_result_count']
        }

    finally:
        cursor.close()
        conn.close()
```

---

## 8. æœç´¢ç³»ç»Ÿæœ€ä½³å®è·µ

### 8.1 ç´¢å¼•ç»´æŠ¤æœ€ä½³å®è·µ

**ç´¢å¼•ç»´æŠ¤æœ€ä½³å®è·µï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- 1. å®šæœŸé‡å»ºGINç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE schemaname = 'public' AND indexname = 'idx_documents_search_vector') THEN
            RAISE WARNING 'ç´¢å¼• idx_documents_search_vector ä¸å­˜åœ¨ï¼Œæ— æ³•é‡å»º';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹é‡å»ºGINç´¢å¼•ï¼ˆæ³¨æ„ï¼šREINDEX CONCURRENTLYéœ€è¦åœ¨äº‹åŠ¡å¤–æ‰§è¡Œï¼‰';
        RAISE NOTICE 'å®é™…æ‰§è¡Œï¼šREINDEX INDEX CONCURRENTLY idx_documents_search_vector;';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'ç´¢å¼•é‡å»ºå‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- 2. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'documents') THEN
            RAISE WARNING 'è¡¨ documents ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°ç»Ÿè®¡ä¿¡æ¯';
            RETURN;
        END IF;
        ANALYZE documents;
        RAISE NOTICE 'ç»Ÿè®¡ä¿¡æ¯æ›´æ–°æˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 3. æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µï¼ˆå¸¦æ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        RAISE NOTICE 'å¼€å§‹æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE indexname LIKE '%search%' OR indexname LIKE '%gin%'
ORDER BY idx_scan DESC;

-- 4. ç›‘æ§ç´¢å¼•å¤§å°ï¼ˆå¸¦æ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        RAISE NOTICE 'å¼€å§‹ç›‘æ§ç´¢å¼•å¤§å°';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE indexname LIKE '%search%' OR indexname LIKE '%gin%'
ORDER BY pg_relation_size(indexrelid) DESC;
```

### 8.2 æŸ¥è¯¢ä¼˜åŒ–æœ€ä½³å®è·µ

**æŸ¥è¯¢ä¼˜åŒ–æœ€ä½³å®è·µï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- 1. ä½¿ç”¨é¢„è¿‡æ»¤ï¼ˆWHEREå­å¥ï¼Œå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'documents') THEN
            RAISE WARNING 'è¡¨ documents ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡Œé¢„è¿‡æ»¤å…¨æ–‡æœç´¢';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT doc_id, title, ts_rank_cd(search_vector, query) AS rank
FROM documents,
     to_tsquery('zh_parser', 'æœç´¢å…³é”®è¯') query
WHERE category = 'technology'  -- é¢„è¿‡æ»¤
    AND search_vector @@ query
ORDER BY rank DESC
LIMIT 10;

-- 2. åˆç†è®¾ç½®LIMITï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'documents') THEN
            RAISE WARNING 'è¡¨ documents ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡ŒLIMITä¼˜åŒ–æŸ¥è¯¢ï¼ˆæ¨èï¼š10-50ï¼‰';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- å…¨æ–‡æœç´¢æŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'documents') THEN
            RAISE WARNING 'è¡¨ documents ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œå…¨æ–‡æœç´¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡Œå…¨æ–‡æœç´¢æŸ¥è¯¢ï¼ˆå¸¦æ’åºï¼‰';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM documents
WHERE search_vector @@ to_tsquery('zh_parser', 'æœç´¢å…³é”®è¯')
ORDER BY ts_rank_cd(search_vector, to_tsquery('zh_parser', 'æœç´¢å…³é”®è¯')) DESC
LIMIT 20;  -- æ¨èï¼š10-50

-- 3. ä½¿ç”¨ç¼“å­˜ï¼ˆåº”ç”¨å±‚ï¼‰
-- Redisç¼“å­˜çƒ­é—¨æŸ¥è¯¢ç»“æœ
```

---

**å®Œæˆæ—¥æœŸ**: 2025-12-04
**æœç´¢å¼•æ“**: PostgreSQLå†…ç½®
**å“åº”æ—¶é—´**: <100ms
**å­—æ•°**: ~8,000å­—
**æ¶µç›–**: æœç´¢å¼•æ“æ¨¡å—ã€APIæ¥å£ã€é«˜çº§åŠŸèƒ½ã€æ€§èƒ½ä¼˜åŒ–ã€PostgreSQL 18ä¼˜åŒ–ã€ç›‘æ§ã€æœ€ä½³å®è·µ

**è¿”å›**: [æ¡ˆä¾‹6ä¸»é¡µ](./README.md)
