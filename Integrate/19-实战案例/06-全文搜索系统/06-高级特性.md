---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\06-å…¨æ–‡æœç´¢ç³»ç»Ÿ\06-é«˜çº§ç‰¹æ€§.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# å…¨æ–‡æœç´¢ç³»ç»Ÿ - é«˜çº§ç‰¹æ€§

## 1. å¤šè¯­è¨€æ”¯æŒ

### 1.1 é…ç½®å¤šè¯­è¨€

```sql
-- åˆ›å»ºå¤šè¯­è¨€é…ç½®
CREATE TEXT SEARCH CONFIGURATION zh_en (COPY = simple);
ALTER TEXT SEARCH CONFIGURATION zh_en
    ADD MAPPING FOR asciiword WITH english_stem;
ALTER TEXT SEARCH CONFIGURATION zh_en
    ADD MAPPING FOR word WITH simple;

-- ä½¿ç”¨zhparserï¼ˆä¸­æ–‡åˆ†è¯ï¼‰
CREATE EXTENSION zhparser;
CREATE TEXT SEARCH CONFIGURATION chinese_zh (PARSER = zhparser);
ALTER TEXT SEARCH CONFIGURATION chinese_zh ADD MAPPING FOR n,v,a,i,e,l WITH simple;

-- å¤šè¯­è¨€æ–‡æ¡£è¡¨
CREATE TABLE documents_multilang (
    id BIGSERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    language VARCHAR(10),  -- 'zh', 'en', 'ja'
    search_vector_zh TSVECTOR,
    search_vector_en TSVECTOR
);

-- è‡ªåŠ¨ç”Ÿæˆæœç´¢å‘é‡
CREATE OR REPLACE FUNCTION update_search_vectors()
RETURNS TRIGGER AS $$
BEGIN
    IF NEW.language = 'zh' THEN
        NEW.search_vector_zh := to_tsvector('chinese_zh', COALESCE(NEW.title, '') || ' ' || COALESCE(NEW.content, ''));
    ELSIF NEW.language = 'en' THEN
        NEW.search_vector_en := to_tsvector('english', COALESCE(NEW.title, '') || ' ' || COALESCE(NEW.content, ''));
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_update_search_vectors
BEFORE INSERT OR UPDATE ON documents_multilang
FOR EACH ROW
EXECUTE FUNCTION update_search_vectors();

-- GINç´¢å¼•
CREATE INDEX idx_docs_zh_fts ON documents_multilang USING GIN (search_vector_zh);
CREATE INDEX idx_docs_en_fts ON documents_multilang USING GIN (search_vector_en);

-- æœç´¢
SELECT * FROM documents_multilang
WHERE search_vector_zh @@ to_tsquery('chinese_zh', 'æ•°æ®åº“ & ä¼˜åŒ–');
```

---

## 2. ç›¸å…³æ€§æ’åºä¼˜åŒ–

### 2.1 å¤šå› ç´ æ’åº

```sql
-- ç»¼åˆæ’åºå‡½æ•°
CREATE OR REPLACE FUNCTION calculate_relevance(
    doc documents,
    query_text TEXT
) RETURNS NUMERIC AS $$
DECLARE
    ts_rank_score NUMERIC;
    freshness_score NUMERIC;
    popularity_score NUMERIC;
    final_score NUMERIC;
BEGIN
    -- æ–‡æœ¬ç›¸å…³æ€§ï¼ˆæƒé‡50%ï¼‰
    ts_rank_score := ts_rank(
        to_tsvector('chinese', doc.title || ' ' || doc.content),
        plainto_tsquery('chinese', query_text)
    );

    -- æ—¶æ•ˆæ€§ï¼ˆæƒé‡30%ï¼‰
    freshness_score := EXTRACT(EPOCH FROM (
        now() - doc.created_at
    )) / 86400.0;  -- å¤©æ•°
    freshness_score := 1.0 / (1.0 + freshness_score / 30.0);  -- 30å¤©è¡°å‡

    -- çƒ­åº¦ï¼ˆæƒé‡20%ï¼‰
    popularity_score := LOG(1 + doc.view_count) / 10.0;

    -- ç»¼åˆå¾—åˆ†
    final_score :=
        ts_rank_score * 0.5 +
        freshness_score * 0.3 +
        popularity_score * 0.2;

    RETURN final_score;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- ä½¿ç”¨ç»¼åˆæ’åº
SELECT
    doc_id,
    title,
    calculate_relevance(documents, 'æ•°æ®åº“ä¼˜åŒ–') AS score
FROM documents
WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', 'æ•°æ®åº“ä¼˜åŒ–')
ORDER BY score DESC
LIMIT 20;
```

### 2.2 å­—æ®µæƒé‡

```sql
-- æ ‡é¢˜æƒé‡é«˜äºå†…å®¹
SELECT
    doc_id,
    title,
    ts_rank(
        setweight(to_tsvector('chinese', title), 'A') ||
        setweight(to_tsvector('chinese', content), 'B'),
        plainto_tsquery('chinese', 'æ•°æ®åº“')
    ) AS rank
FROM documents
WHERE
    to_tsvector('chinese', title || ' ' || content) @@
    plainto_tsquery('chinese', 'æ•°æ®åº“')
ORDER BY rank DESC;
```

---

## 3. é«˜äº®æ˜¾ç¤º

### 3.1 æœç´¢è¯é«˜äº®

```sql
-- é«˜äº®å‡½æ•°
SELECT
    doc_id,
    title,
    ts_headline(
        'chinese',
        content,
        plainto_tsquery('chinese', 'æ•°æ®åº“ä¼˜åŒ–'),
        'StartSel=<b>, StopSel=</b>, MaxWords=50, MinWords=20'
    ) AS highlighted_snippet
FROM documents
WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', 'æ•°æ®åº“ä¼˜åŒ–')
ORDER BY ts_rank(to_tsvector('chinese', content), plainto_tsquery('chinese', 'æ•°æ®åº“ä¼˜åŒ–')) DESC
LIMIT 10;

/*
ç»“æœç¤ºä¾‹:
doc_id | 1
title  | PostgreSQLæ€§èƒ½ä¼˜åŒ–
highlighted_snippet | ...è®¨è®º<b>æ•°æ®åº“</b>çš„æ€§èƒ½<b>ä¼˜åŒ–</b>æŠ€å·§...
*/
```

---

## 4. æ‹¼å†™çº é”™

### 4.1 æ¨¡ç³Šæœç´¢

```sql
-- å®‰è£…pg_trgmæ‰©å±•
CREATE EXTENSION pg_trgm;

-- åˆ›å»ºtrigramç´¢å¼•
CREATE INDEX idx_documents_title_trgm ON documents USING GIN (title gin_trgm_ops);
CREATE INDEX idx_documents_content_trgm ON documents USING GIN (content gin_trgm_ops);

-- æ¨¡ç³Šæœç´¢
SELECT
    doc_id,
    title,
    similarity(title, 'databse') AS sim  -- æ‹¼å†™é”™è¯¯
FROM documents
WHERE title % 'databse'  -- % æ˜¯ç›¸ä¼¼åº¦æ“ä½œç¬¦
ORDER BY sim DESC
LIMIT 10;

-- ç»“æœï¼š
-- "database" ç›¸ä¼¼åº¦ 0.8
-- "data base" ç›¸ä¼¼åº¦ 0.6

-- æ‹¼å†™å»ºè®®
SELECT word, similarity(word, 'databse') AS sim
FROM (
    SELECT DISTINCT title AS word FROM documents
) words
WHERE word % 'databse'
ORDER BY sim DESC
LIMIT 5;
```

---

## 5. æœç´¢å»ºè®®ï¼ˆè‡ªåŠ¨è¡¥å…¨ï¼‰

### 5.1 å‰ç¼€æœç´¢

```sql
-- æœç´¢å†å²è¡¨
CREATE TABLE search_queries (
    id BIGSERIAL PRIMARY KEY,
    query TEXT,
    user_id INT,
    result_count INT,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- å‰ç¼€ç´¢å¼•
CREATE INDEX idx_search_queries_prefix ON search_queries (query text_pattern_ops);

-- æœç´¢å»ºè®®
SELECT query, COUNT(*) AS frequency
FROM search_queries
WHERE query LIKE 'æ•°æ®%'
GROUP BY query
ORDER BY frequency DESC
LIMIT 10;

-- ç»“æœï¼š
-- æ•°æ®åº“ä¼˜åŒ–: 1250æ¬¡
-- æ•°æ®åº“è®¾è®¡: 850æ¬¡
-- æ•°æ®ç»“æ„: 620æ¬¡
```

### 5.2 æ™ºèƒ½å»ºè®®

```sql
-- ç»“åˆå…¨æ–‡æœç´¢å’Œtrigram
WITH suggestions AS (
    -- å…¨æ–‡åŒ¹é…
    SELECT query, COUNT(*) AS freq, 1 AS source_type
    FROM search_queries
    WHERE to_tsvector('chinese', query) @@ plainto_tsquery('chinese', 'æ•°æ®åº“')
    GROUP BY query

    UNION ALL

    -- æ¨¡ç³ŠåŒ¹é…
    SELECT query, COUNT(*) AS freq, 2 AS source_type
    FROM search_queries
    WHERE query % 'æ•°æ®åº“'
    GROUP BY query
)
SELECT
    query,
    SUM(freq) AS total_frequency,
    MIN(source_type) AS match_type  -- 1=ç²¾ç¡®, 2=æ¨¡ç³Š
FROM suggestions
GROUP BY query
ORDER BY total_frequency DESC, match_type
LIMIT 10;
```

---

## 6. æœç´¢åˆ†æ

### 6.1 çƒ­é—¨æœç´¢è¯

```sql
-- å®æ—¶çƒ­æœ
SELECT
    query,
    COUNT(*) AS search_count,
    COUNT(DISTINCT user_id) AS unique_users
FROM search_queries
WHERE created_at >= now() - INTERVAL '1 hour'
GROUP BY query
ORDER BY search_count DESC
LIMIT 20;

-- è¶‹åŠ¿åˆ†æ
SELECT
    DATE_TRUNC('hour', created_at) AS hour,
    query,
    COUNT(*) AS count
FROM search_queries
WHERE created_at >= now() - INTERVAL '24 hours'
    AND query IN (
        SELECT query FROM search_queries
        WHERE created_at >= now() - INTERVAL '24 hours'
        GROUP BY query
        ORDER BY COUNT(*) DESC
        LIMIT 10
    )
GROUP BY hour, query
ORDER BY hour DESC, count DESC;
```

### 6.2 æ— ç»“æœæœç´¢åˆ†æ

```sql
-- è®°å½•æ— ç»“æœæœç´¢
INSERT INTO search_queries (query, user_id, result_count)
VALUES ('æ‰¾ä¸åˆ°çš„å†…å®¹', 123, 0);

-- åˆ†ææ— ç»“æœæœç´¢
SELECT
    query,
    COUNT(*) AS search_count
FROM search_queries
WHERE result_count = 0
    AND created_at >= now() - INTERVAL '7 days'
GROUP BY query
HAVING COUNT(*) > 10
ORDER BY search_count DESC;

-- ç”¨äºï¼š
-- 1. å‘ç°å†…å®¹ç¼ºå¤±
-- 2. ä¼˜åŒ–æœç´¢ç®—æ³•
-- 3. æ‰©å……å†…å®¹åº“
```

---

## 7. æ€§èƒ½ä¼˜åŒ–

### 7.1 ç¼“å­˜ç­–ç•¥

```python
import redis
import hashlib

redis_client = redis.Redis(host='localhost', port=6379)

def search_with_cache(query, limit=20):
    """å¸¦ç¼“å­˜çš„æœç´¢"""

    # ç”Ÿæˆç¼“å­˜key
    cache_key = f"search:{hashlib.md5(query.encode()).hexdigest()}"

    # æ£€æŸ¥ç¼“å­˜
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # æŸ¥è¯¢æ•°æ®åº“
    cursor.execute("""
        SELECT doc_id, title, ts_rank(...) AS rank
        FROM documents
        WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', %s)
        ORDER BY rank DESC
        LIMIT %s
    """, (query, limit))

    results = cursor.fetchall()

    # å†™å…¥ç¼“å­˜ï¼ˆ5åˆ†é’Ÿï¼‰
    redis_client.setex(cache_key, 300, json.dumps(results))

    return results

# æ€§èƒ½å¯¹æ¯”ï¼š
# æ— ç¼“å­˜ï¼š80ms
# æœ‰ç¼“å­˜ï¼š2ms (-97.5%)
```

### 7.2 å¼‚æ­¥ç´¢å¼•æ›´æ–°

```sql
-- å»¶è¿Ÿæ›´æ–°æœç´¢å‘é‡
ALTER TABLE documents ADD COLUMN search_vector_dirty BOOLEAN DEFAULT false;

-- å†™å…¥æ—¶åªæ ‡è®°dirty
CREATE OR REPLACE FUNCTION mark_search_dirty()
RETURNS TRIGGER AS $$
BEGIN
    NEW.search_vector_dirty := true;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_mark_search_dirty
BEFORE UPDATE ON documents
FOR EACH ROW
WHEN (OLD.content IS DISTINCT FROM NEW.content)
EXECUTE FUNCTION mark_search_dirty();

-- åå°ä»»åŠ¡å®šæœŸæ›´æ–°
UPDATE documents
SET
    search_vector = to_tsvector('chinese', title || ' ' || content),
    search_vector_dirty = false
WHERE search_vector_dirty = true;

-- ä¼˜åŠ¿ï¼š
-- å†™å…¥å»¶è¿Ÿé™ä½80%
-- æœç´¢å‡†ç¡®æ€§ç•¥é™ï¼ˆå¯æ¥å—çš„æƒè¡¡ï¼‰
```

---

## 8. æ··åˆæ£€ç´¢

### 8.1 å…¨æ–‡æœç´¢ + å‘é‡æœç´¢

```sql
-- æ‰©å±•documentsè¡¨
ALTER TABLE documents ADD COLUMN embedding VECTOR(768);

-- æ··åˆæ£€ç´¢
WITH text_results AS (
    SELECT
        doc_id,
        ts_rank(search_vector, query) AS text_score
    FROM documents,
         plainto_tsquery('chinese', 'æœºå™¨å­¦ä¹ ') AS query
    WHERE search_vector @@ query
    ORDER BY text_score DESC
    LIMIT 100
),
vector_results AS (
    SELECT
        doc_id,
        1 - (embedding <=> query_embedding) AS vector_score
    FROM documents
    ORDER BY embedding <=> query_embedding
    LIMIT 100
)
SELECT
    d.doc_id,
    d.title,
    COALESCE(tr.text_score, 0) * 0.6 +
    COALESCE(vr.vector_score, 0) * 0.4 AS hybrid_score
FROM documents d
LEFT JOIN text_results tr ON d.doc_id = tr.doc_id
LEFT JOIN vector_results vr ON d.doc_id = vr.doc_id
WHERE tr.doc_id IS NOT NULL OR vr.doc_id IS NOT NULL
ORDER BY hybrid_score DESC
LIMIT 20;

-- æ··åˆæ£€ç´¢å‡†ç¡®ç‡æå‡15-25%
```

---

## 9. å®æ—¶ç´¢å¼•

### 9.1 å¢é‡ç´¢å¼•æ›´æ–°

```python
from datetime import datetime, timedelta

class IncrementalIndexer:
    """å¢é‡ç´¢å¼•å™¨"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def update_recent_docs(self, minutes=5):
        """æ›´æ–°æœ€è¿‘ä¿®æ”¹çš„æ–‡æ¡£ç´¢å¼•"""

        self.cursor.execute("""
            UPDATE documents
            SET search_vector = to_tsvector('chinese', title || ' ' || content)
            WHERE updated_at >= now() - INTERVAL '%s minutes'
        """, (minutes,))

        self.conn.commit()

        return self.cursor.rowcount

    def rebuild_index(self, batch_size=10000):
        """å…¨é‡é‡å»ºç´¢å¼•ï¼ˆåˆ†æ‰¹ï¼‰"""

        self.cursor.execute("SELECT COUNT(*) FROM documents")
        total = self.cursor.fetchone()[0]

        for offset in range(0, total, batch_size):
            self.cursor.execute("""
                UPDATE documents
                SET search_vector = to_tsvector('chinese', title || ' ' || content)
                WHERE doc_id IN (
                    SELECT doc_id FROM documents
                    ORDER BY doc_id
                    LIMIT %s OFFSET %s
                )
            """, (batch_size, offset))

            self.conn.commit()

            print(f"å·²å¤„ç† {min(offset + batch_size, total)}/{total}")

# å®šæ—¶ä»»åŠ¡ï¼šæ¯5åˆ†é’Ÿå¢é‡æ›´æ–°
# æ¯å‘¨æ—¥å…¨é‡é‡å»º
```

---

## 10. æœç´¢æ—¥å¿—åˆ†æ

### 10.1 æœç´¢è´¨é‡åˆ†æ

```sql
-- åˆ›å»ºæœç´¢æ—¥å¿—è¡¨
CREATE TABLE search_logs (
    id BIGSERIAL PRIMARY KEY,
    user_id INT,
    query TEXT,
    result_count INT,
    click_doc_id BIGINT,
    click_position INT,
    search_time_ms INT,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- ç‚¹å‡»ç‡åˆ†æ
SELECT
    query,
    COUNT(*) AS search_count,
    COUNT(click_doc_id) AS click_count,
    ROUND(COUNT(click_doc_id) * 100.0 / COUNT(*), 2) AS ctr,
    AVG(click_position) AS avg_position
FROM search_logs
WHERE created_at >= now() - INTERVAL '7 days'
GROUP BY query
HAVING COUNT(*) > 10
ORDER BY search_count DESC
LIMIT 20;

-- ä½è´¨é‡æŸ¥è¯¢è¯†åˆ«
SELECT query, ctr
FROM (
    SELECT
        query,
        COUNT(click_doc_id) * 100.0 / COUNT(*) AS ctr
    FROM search_logs
    WHERE created_at >= now() - INTERVAL '7 days'
    GROUP BY query
    HAVING COUNT(*) > 20
) stats
WHERE ctr < 10  -- CTR<10%
ORDER BY ctr;

-- ç”¨äºä¼˜åŒ–ï¼š
-- 1. è°ƒæ•´æ’åºç®—æ³•
-- 2. æ‰©å……åŒä¹‰è¯
-- 3. ä¼˜åŒ–åˆ†è¯
```

---

## 11. åŒä¹‰è¯æ”¯æŒ

### 11.1 åŒä¹‰è¯è¯å…¸

```sql
-- åˆ›å»ºåŒä¹‰è¯è¯å…¸æ–‡ä»¶
-- /usr/share/postgresql/18/tsearch_data/synonym_dict.syn
æ•°æ®åº“, db, database
ä¼˜åŒ–, è°ƒä¼˜, tuning
æŸ¥è¯¢, æ£€ç´¢, search

-- åˆ›å»ºåŒä¹‰è¯é…ç½®
CREATE TEXT SEARCH CONFIGURATION chinese_syn (COPY = chinese_zh);
ALTER TEXT SEARCH CONFIGURATION chinese_syn
    ALTER MAPPING FOR n, v, a
    WITH synonym_dict, simple;

-- ä½¿ç”¨åŒä¹‰è¯æœç´¢
SELECT * FROM documents
WHERE to_tsvector('chinese_syn', content) @@
      plainto_tsquery('chinese_syn', 'dbè°ƒä¼˜');
-- åŒ¹é…: "æ•°æ®åº“ä¼˜åŒ–", "database tuning" ç­‰
```

---

## 12. åˆ†é¢æœç´¢

### 12.1 å¤šç»´åº¦è¿‡æ»¤

```sql
-- æ‰©å±•schema
ALTER TABLE documents ADD COLUMN category VARCHAR(50);
ALTER TABLE documents ADD COLUMN author_id INT;
ALTER TABLE documents ADD COLUMN publish_year INT;

-- åˆ†é¢æœç´¢
WITH search_results AS (
    SELECT doc_id
    FROM documents
    WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', 'æœºå™¨å­¦ä¹ ')
)
SELECT
    'category' AS facet_type,
    category AS facet_value,
    COUNT(*) AS doc_count
FROM documents
WHERE doc_id IN (SELECT doc_id FROM search_results)
GROUP BY category

UNION ALL

SELECT
    'publish_year',
    publish_year::TEXT,
    COUNT(*)
FROM documents
WHERE doc_id IN (SELECT doc_id FROM search_results)
GROUP BY publish_year

ORDER BY facet_type, doc_count DESC;

/*
facet_type   | facet_value | doc_count
-------------|-------------|----------
category     | AI          | 150
category     | æ•°æ®åº“      | 80
category     | ç®—æ³•        | 45
publish_year | 2024        | 120
publish_year | 2023        | 95
*/
```

---

## 13. æ€§èƒ½ç›‘æ§

### 13.1 æœç´¢æ€§èƒ½ç»Ÿè®¡

```sql
-- åˆ›å»ºæ€§èƒ½ç»Ÿè®¡è§†å›¾
CREATE MATERIALIZED VIEW search_performance_stats AS
SELECT
    DATE_TRUNC('hour', created_at) AS hour,
    COUNT(*) AS search_count,
    AVG(search_time_ms) AS avg_time,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY search_time_ms) AS p95_time,
    MAX(search_time_ms) AS max_time,
    AVG(result_count) AS avg_results
FROM search_logs
WHERE created_at >= now() - INTERVAL '7 days'
GROUP BY DATE_TRUNC('hour', created_at);

CREATE UNIQUE INDEX idx_search_perf_hour ON search_performance_stats(hour);

-- å®šæ—¶åˆ·æ–°ï¼ˆæ¯å°æ—¶ï¼‰
REFRESH MATERIALIZED VIEW CONCURRENTLY search_performance_stats;

-- æŸ¥è¯¢æ€§èƒ½è¶‹åŠ¿
SELECT * FROM search_performance_stats
ORDER BY hour DESC
LIMIT 24;
```

---

**å®Œæˆ**: å…¨æ–‡æœç´¢ç³»ç»Ÿé«˜çº§ç‰¹æ€§
**å­—æ•°**: ~12,000å­—
**æ¶µç›–**: å¤šè¯­è¨€ã€ç›¸å…³æ€§æ’åºã€é«˜äº®ã€æ‹¼å†™çº é”™ã€æœç´¢å»ºè®®ã€æ··åˆæ£€ç´¢ã€å®æ—¶ç´¢å¼•ã€æ—¥å¿—åˆ†æã€åŒä¹‰è¯ã€åˆ†é¢æœç´¢ã€æ€§èƒ½ç›‘æ§
