---
> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\09-æ™ºèƒ½å®¢æœç³»ç»Ÿ\05-éƒ¨ç½²è¿ç»´.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜
---
> **âš ï¸ é‡è¦æç¤º**: æœ¬æ–‡æ¡£éµå¾ªæ¡ˆä¾‹æ–‡æ¡£é€šç”¨æ¨¡æ¿æ ¼å¼ã€‚
>
> **æ¨èé˜…è¯»**:
>
> - [æ¡ˆä¾‹æ–‡æ¡£é€šç”¨æ¨¡æ¿](../æ¡ˆä¾‹æ–‡æ¡£é€šç”¨æ¨¡æ¿.md) - é€šç”¨æ¡ˆä¾‹æ–‡æ¡£æ ¼å¼å’Œæœ€ä½³å®è·µ
>
> æœ¬æ–‡æ¡£ä¿ç•™ä½œä¸ºæ™ºèƒ½å®¢æœç³»ç»Ÿçš„éƒ¨ç½²è¿ç»´å‚è€ƒã€‚
---

# æ¡ˆä¾‹9ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ - éƒ¨ç½²è¿ç»´

## å…ƒæ•°æ®

- **åˆ›å»ºæ—¥æœŸ**: 2025-12-22
- **éƒ¨ç½²æ–¹å¼**: Docker + Kubernetes
- **ç›‘æ§**: Prometheus + Grafana
- **æ—¥å¿—**: ELK Stack

---

## 1. Dockeréƒ¨ç½²é…ç½®

### 1.1 Docker Composeé…ç½®

**Docker Composeé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg18
    container_name: customer-service-db
    environment:
      POSTGRES_DB: customer_service_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=C"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./postgresql.conf:/etc/postgresql/postgresql.conf
    ports:
      - "5432:5432"
    command:
      - "postgres"
      - "-c"
      - "config_file=/etc/postgresql/postgresql.conf"
      - "-c"
      - "shared_buffers=2GB"
      - "-c"
      - "work_mem=128MB"
      - "-c"
      - "maintenance_work_mem=512MB"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "effective_cache_size=6GB"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: customer-service-api
    environment:
      DB_HOST: postgres
      DB_NAME: customer_service_db
      DB_USER: postgres
      DB_PASSWORD: ${DB_PASSWORD}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      REDIS_HOST: redis
      REDIS_PORT: 6379
    ports:
      - "8005:8005"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: customer-service-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    container_name: customer-service-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - api
    restart: unless-stopped

volumes:
  postgres-data:
  redis-data:
```

### 1.2 PostgreSQLä¼˜åŒ–é…ç½®

**PostgreSQLä¼˜åŒ–é…ç½®ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```ini
# postgresql.conf - æ™ºèƒ½å®¢æœç³»ç»Ÿä¼˜åŒ–

# å†…å­˜é…ç½®
shared_buffers = 2GB
work_mem = 128MB
maintenance_work_mem = 512MB
effective_cache_size = 6GB

# è¿æ¥é…ç½®
max_connections = 200
superuser_reserved_connections = 3

# WALé…ç½®
wal_buffers = 16MB
max_wal_size = 4GB
min_wal_size = 1GB
checkpoint_timeout = 15min
checkpoint_completion_target = 0.9

# PostgreSQL 18å¼‚æ­¥I/O
io_direct = data
io_combine_limit = 128kB

# PostgreSQL 18å†…ç½®è¿æ¥æ± 
pool_mode = transaction
pool_size = 100
pool_max_wait = 5

# æŸ¥è¯¢ä¼˜åŒ–
random_page_cost = 1.1
effective_io_concurrency = 200
default_statistics_target = 100

# æ—¥å¿—é…ç½®
log_destination = 'stderr'
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d.log'
log_rotation_age = 1d
log_rotation_size = 100MB
log_min_duration_statement = 1000  # è®°å½•>1sçš„æŸ¥è¯¢
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# pgvectoré…ç½®
shared_preload_libraries = 'vector'

# ç»Ÿè®¡ä¿¡æ¯
track_io_timing = on
track_functions = all
pg_stat_statements.track = all
```

---

## 2. Kuberneteséƒ¨ç½²é…ç½®

### 2.1 PostgreSQL StatefulSet

**PostgreSQL StatefulSeté…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: customer-service-postgres
  namespace: customer-service
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: pgvector/pgvector:pg18
        env:
        - name: POSTGRES_DB
          value: customer_service_db
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        ports:
        - containerPort: 5432
          name: postgres
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        - name: postgres-config
          mountPath: /etc/postgresql/postgresql.conf
          subPath: postgresql.conf
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: postgres-config
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 100Gi
```

### 2.2 API Deployment

**API Deploymenté…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customer-service-api
  namespace: customer-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api
        image: customer-service-api:latest
        env:
        - name: DB_HOST
          value: postgres
        - name: DB_NAME
          value: customer_service_db
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: api-key
        ports:
        - containerPort: 8005
          name: http
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1"
        livenessProbe:
          httpGet:
            path: /health
            port: 8005
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8005
          initialDelaySeconds: 10
          periodSeconds: 5
```

---

## 3. ç›‘æ§é…ç½®

### 3.1 Prometheusé…ç½®

**Prometheusé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
    metrics_path: /metrics

  - job_name: 'customer-service-api'
    static_configs:
      - targets: ['api:8005']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    metrics_path: /metrics
```

### 3.2 Grafanaä»ªè¡¨æ¿

**Grafanaä»ªè¡¨æ¿é…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```json
{
  "dashboard": {
    "title": "æ™ºèƒ½å®¢æœç³»ç»Ÿç›‘æ§",
    "panels": [
      {
        "title": "æ•°æ®åº“è¿æ¥æ•°",
        "targets": [
          {
            "expr": "pg_stat_database_numbackends{datname=\"customer_service_db\"}"
          }
        ]
      },
      {
        "title": "æŸ¥è¯¢QPS",
        "targets": [
          {
            "expr": "rate(pg_stat_statements_calls[5m])"
          }
        ]
      },
      {
        "title": "å¹³å‡å“åº”æ—¶é—´",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))"
          }
        ]
      },
      {
        "title": "å‘é‡æ£€ç´¢å»¶è¿Ÿ",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(vector_search_duration_ms_bucket[5m]))"
          }
        ]
      },
      {
        "title": "FAQå‘½ä¸­ç‡",
        "targets": [
          {
            "expr": "rate(faq_cache_hits_total[5m]) / rate(faq_queries_total[5m])"
          }
        ]
      }
    ]
  }
}
```

---

## 4. æ—¥å¿—ç®¡ç†

### 4.1 ELK Stacké…ç½®

**ELK Stacké…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
# filebeat.yml
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  processors:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"

output.elasticsearch:
  hosts: ['elasticsearch:9200']
  index: 'customer-service-%{+yyyy.MM.dd}'

# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "customer-service-api" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{GREEDYDATA:message}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "customer-service-%{+YYYY.MM.dd}"
  }
}
```

---

## 5. å¤‡ä»½ä¸æ¢å¤

### 5.1 è‡ªåŠ¨å¤‡ä»½è„šæœ¬

**è‡ªåŠ¨å¤‡ä»½è„šæœ¬ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```bash
#!/bin/bash
# backup.sh - æ™ºèƒ½å®¢æœç³»ç»Ÿè‡ªåŠ¨å¤‡ä»½

set -e

BACKUP_DIR="/backups/customer-service"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"

# æ•°æ®åº“å¤‡ä»½
echo "å¼€å§‹æ•°æ®åº“å¤‡ä»½..."
pg_dump -h postgres -U postgres -d customer_service_db \
  -F c -b -v -f "$BACKUP_DIR/db_$DATE.dump"

# éªŒè¯å¤‡ä»½
if [ $? -eq 0 ]; then
    echo "æ•°æ®åº“å¤‡ä»½æˆåŠŸ: $BACKUP_DIR/db_$DATE.dump"

    # å‹ç¼©å¤‡ä»½
    gzip "$BACKUP_DIR/db_$DATE.dump"

    # æ¸…ç†æ—§å¤‡ä»½
    find "$BACKUP_DIR" -name "db_*.dump.gz" -mtime +$RETENTION_DAYS -delete

    echo "å¤‡ä»½å®Œæˆï¼Œä¿ç•™æœ€è¿‘ $RETENTION_DAYS å¤©çš„å¤‡ä»½"
else
    echo "æ•°æ®åº“å¤‡ä»½å¤±è´¥ï¼"
    exit 1
fi
```

### 5.2 æ¢å¤è„šæœ¬

**æ¢å¤è„šæœ¬ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```bash
#!/bin/bash
# restore.sh - æ™ºèƒ½å®¢æœç³»ç»Ÿæ¢å¤

set -e

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "ç”¨æ³•: $0 <å¤‡ä»½æ–‡ä»¶>"
    exit 1
fi

# è§£å‹å¤‡ä»½æ–‡ä»¶
if [[ "$BACKUP_FILE" == *.gz ]]; then
    echo "è§£å‹å¤‡ä»½æ–‡ä»¶..."
    gunzip -c "$BACKUP_FILE" > "${BACKUP_FILE%.gz}"
    BACKUP_FILE="${BACKUP_FILE%.gz}"
fi

# æ¢å¤æ•°æ®åº“
echo "å¼€å§‹æ¢å¤æ•°æ®åº“..."
pg_restore -h postgres -U postgres -d customer_service_db \
  -c -v "$BACKUP_FILE"

if [ $? -eq 0 ]; then
    echo "æ•°æ®åº“æ¢å¤æˆåŠŸï¼"
else
    echo "æ•°æ®åº“æ¢å¤å¤±è´¥ï¼"
    exit 1
fi
```

---

## 6. æ€§èƒ½è°ƒä¼˜

### 6.1 æ•°æ®åº“æ€§èƒ½è°ƒä¼˜

**æ•°æ®åº“æ€§èƒ½è°ƒä¼˜ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- 1. åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE faqs;
ANALYZE conversations;
ANALYZE sessions;

-- 2. é‡å»ºç´¢å¼•
REINDEX INDEX CONCURRENTLY idx_faqs_embedding;
REINDEX INDEX CONCURRENTLY idx_faqs_search_vector;

-- 3. æ›´æ–°æŸ¥è¯¢è®¡åˆ’ç¼“å­˜
SELECT pg_stat_statements_reset();

-- 4. æ£€æŸ¥æ…¢æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 1000  -- >1ç§’
ORDER BY mean_exec_time DESC
LIMIT 20;

-- 5. æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;
```

### 6.2 åº”ç”¨æ€§èƒ½è°ƒä¼˜

**åº”ç”¨æ€§èƒ½è°ƒä¼˜ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
# 1. è¿æ¥æ± é…ç½®
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    "postgresql://user:pass@host/db",
    poolclass=QueuePool,
    pool_size=20,
    max_overflow=10,
    pool_pre_ping=True,
    pool_recycle=3600
)

# 2. ç¼“å­˜é…ç½®
from redis import Redis
from functools import wraps

redis_client = Redis(host='redis', port=6379, decode_responses=True)

def cache_result(ttl=300):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            result = func(*args, **kwargs)
            redis_client.setex(cache_key, ttl, json.dumps(result))
            return result
        return wrapper
    return decorator

# 3. æ‰¹é‡å¤„ç†
def batch_insert_conversations(conversations):
    """æ‰¹é‡æ’å…¥å¯¹è¯"""
    from psycopg2.extras import execute_values

    query = """
        INSERT INTO conversations (session_id, question, answer, intent)
        VALUES %s
    """

    values = [
        (c['session_id'], c['question'], c['answer'], c.get('intent'))
        for c in conversations
    ]

    execute_values(cursor, query, values)
```

---

## 7. æ•…éšœå¤„ç†

### 7.1 å¸¸è§æ•…éšœå¤„ç†

**å¸¸è§æ•…éšœå¤„ç†ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```bash
# 1. æ•°æ®åº“è¿æ¥å¤±è´¥
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker exec customer-service-db pg_isready -U postgres

# æ£€æŸ¥è¿æ¥æ•°
docker exec customer-service-db psql -U postgres -c "
    SELECT count(*) FROM pg_stat_activity WHERE datname = 'customer_service_db';
"

# 2. å‘é‡æ£€ç´¢æ…¢
# æ£€æŸ¥ç´¢å¼•
docker exec customer-service-db psql -U postgres -d customer_service_db -c "
    SELECT indexname, idx_scan, idx_tup_read
    FROM pg_stat_user_indexes
    WHERE indexname = 'idx_faqs_embedding';
"

# é‡å»ºç´¢å¼•
docker exec customer-service-db psql -U postgres -d customer_service_db -c "
    REINDEX INDEX CONCURRENTLY idx_faqs_embedding;
"

# 3. å†…å­˜ä¸è¶³
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
docker stats customer-service-db

# è°ƒæ•´shared_buffers
docker exec customer-service-db psql -U postgres -c "
    ALTER SYSTEM SET shared_buffers = '1GB';
    SELECT pg_reload_conf();
"

# 4. ç£ç›˜ç©ºé—´ä¸è¶³
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨
docker exec customer-service-db psql -U postgres -c "
    SELECT pg_size_pretty(pg_database_size('customer_service_db'));
"

# æ¸…ç†æ—§æ•°æ®
docker exec customer-service-db psql -U postgres -d customer_service_db -c "
    DELETE FROM conversations
    WHERE created_at < NOW() - INTERVAL '90 days';
"
```

---

## 8. å®‰å…¨é…ç½®

### 8.1 æ•°æ®åº“å®‰å…¨

**æ•°æ®åº“å®‰å…¨é…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- 1. åˆ›å»ºåªè¯»ç”¨æˆ·
CREATE USER readonly_user WITH PASSWORD 'secure_password';
GRANT CONNECT ON DATABASE customer_service_db TO readonly_user;
GRANT USAGE ON SCHEMA public TO readonly_user;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO readonly_user;

-- 2. åˆ›å»ºåº”ç”¨ç”¨æˆ·ï¼ˆæœ€å°æƒé™ï¼‰
CREATE USER app_user WITH PASSWORD 'secure_password';
GRANT CONNECT ON DATABASE customer_service_db TO app_user;
GRANT USAGE ON SCHEMA public TO app_user;
GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO app_user;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO app_user;

-- 3. å¯ç”¨SSL
ALTER SYSTEM SET ssl = on;
ALTER SYSTEM SET ssl_cert_file = '/etc/ssl/certs/server.crt';
ALTER SYSTEM SET ssl_key_file = '/etc/ssl/private/server.key';

-- 4. é…ç½®é˜²ç«å¢™è§„åˆ™ï¼ˆpg_hba.confï¼‰
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    customer_service_db  app_user    10.0.0.0/8            md5
host    customer_service_db  readonly_user  10.0.0.0/8          md5
hostssl all                 all           0.0.0.0/0            reject
```

---

## 9. æ‰©å®¹ç­–ç•¥

### 9.1 æ°´å¹³æ‰©å®¹

**æ°´å¹³æ‰©å®¹ç­–ç•¥ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
# 1. å¢åŠ APIå‰¯æœ¬æ•°
kubectl scale deployment customer-service-api --replicas=5

# 2. æ•°æ®åº“è¯»å†™åˆ†ç¦»ï¼ˆä½¿ç”¨pgBouncerï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pgbouncer
spec:
  replicas: 2
  template:
    spec:
      containers:
      - name: pgbouncer
        image: pgbouncer/pgbouncer:latest
        env:
        - name: DATABASES_HOST
          value: postgres
        - name: DATABASES_PORT
          value: "5432"
        - name: DATABASES_DBNAME
          value: customer_service_db
        - name: POOL_MODE
          value: transaction
        - name: MAX_CLIENT_CONN
          value: "1000"
        - name: DEFAULT_POOL_SIZE
          value: "25"
```

### 9.2 å‚ç›´æ‰©å®¹

**å‚ç›´æ‰©å®¹ç­–ç•¥ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
# å¢åŠ æ•°æ®åº“èµ„æº
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: customer-service-postgres
spec:
  template:
    spec:
      containers:
      - name: postgres
        resources:
          requests:
            memory: "8Gi"  # ä»4Giå¢åŠ åˆ°8Gi
            cpu: "4"       # ä»2å¢åŠ åˆ°4
          limits:
            memory: "16Gi" # ä»8Giå¢åŠ åˆ°16Gi
            cpu: "8"       # ä»4å¢åŠ åˆ°8
```

---

## 10. è¿ç»´æ£€æŸ¥æ¸…å•

### 10.1 æ—¥å¸¸æ£€æŸ¥

**æ—¥å¸¸æ£€æŸ¥æ¸…å•ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```bash
#!/bin/bash
# daily_check.sh - æ—¥å¸¸è¿ç»´æ£€æŸ¥

echo "=== æ™ºèƒ½å®¢æœç³»ç»Ÿæ—¥å¸¸æ£€æŸ¥ ==="

# 1. æ•°æ®åº“è¿æ¥æ£€æŸ¥
echo "1. æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
docker exec customer-service-db pg_isready -U postgres

# 2. æ•°æ®åº“å¤§å°æ£€æŸ¥
echo "2. æ£€æŸ¥æ•°æ®åº“å¤§å°..."
docker exec customer-service-db psql -U postgres -d customer_service_db -c "
    SELECT pg_size_pretty(pg_database_size('customer_service_db'));
"

# 3. è¿æ¥æ•°æ£€æŸ¥
echo "3. æ£€æŸ¥è¿æ¥æ•°..."
docker exec customer-service-db psql -U postgres -d customer_service_db -c "
    SELECT count(*) as connections FROM pg_stat_activity WHERE datname = 'customer_service_db';
"

# 4. æ…¢æŸ¥è¯¢æ£€æŸ¥
echo "4. æ£€æŸ¥æ…¢æŸ¥è¯¢..."
docker exec customer-service-db psql -U postgres -d customer_service_db -c "
    SELECT query, calls, mean_exec_time
    FROM pg_stat_statements
    WHERE mean_exec_time > 1000
    ORDER BY mean_exec_time DESC
    LIMIT 5;
"

# 5. ç´¢å¼•ä½¿ç”¨æ£€æŸ¥
echo "5. æ£€æŸ¥ç´¢å¼•ä½¿ç”¨..."
docker exec customer-service-db psql -U postgres -d customer_service_db -c "
    SELECT schemaname, tablename, indexname, idx_scan
    FROM pg_stat_user_indexes
    WHERE idx_scan = 0
    ORDER BY pg_relation_size(indexrelid) DESC
    LIMIT 5;
"

# 6. ç£ç›˜ç©ºé—´æ£€æŸ¥
echo "6. æ£€æŸ¥ç£ç›˜ç©ºé—´..."
df -h | grep postgres

# 7. æ—¥å¿—æ£€æŸ¥
echo "7. æ£€æŸ¥é”™è¯¯æ—¥å¿—..."
docker logs customer-service-db --tail 100 | grep -i error

echo "=== æ£€æŸ¥å®Œæˆ ==="
```

---

**å®Œæˆ**: æ™ºèƒ½å®¢æœç³»ç»Ÿéƒ¨ç½²è¿ç»´
**å­—æ•°**: ~8,500å­—
**æ¶µç›–**: Dockeréƒ¨ç½²ã€Kuberneteséƒ¨ç½²ã€ç›‘æ§é…ç½®ã€æ—¥å¿—ç®¡ç†ã€å¤‡ä»½æ¢å¤ã€æ€§èƒ½è°ƒä¼˜ã€æ•…éšœå¤„ç†ã€å®‰å…¨é…ç½®ã€æ‰©å®¹ç­–ç•¥ã€è¿ç»´æ£€æŸ¥

**è¿”å›**: [æ¡ˆä¾‹9ä¸»é¡µ](./README.md)
