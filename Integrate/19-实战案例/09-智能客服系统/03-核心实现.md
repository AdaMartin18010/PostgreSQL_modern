---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\09-æ™ºèƒ½å®¢æœç³»ç»Ÿ\03-æ ¸å¿ƒå®ç°.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# æ¡ˆä¾‹9ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ - æ ¸å¿ƒå®ç°

```python
"""
æ™ºèƒ½å®¢æœç³»ç»Ÿ
æŠ€æœ¯æ ˆ: PostgreSQL 18 + pgvector + LangChain
"""

import psycopg2
from psycopg2.extras import RealDictCursor
from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
import numpy as np

class CustomerServiceBot:
    """æ™ºèƒ½å®¢æœæœºå™¨äºº"""

    def __init__(self, conn_str, openai_api_key):
        self.conn = psycopg2.connect(conn_str, cursor_factory=RealDictCursor)
        self.cursor = self.conn.cursor()
        self.llm = OpenAI(api_key=openai_api_key, temperature=0.7)
        self.embeddings = OpenAIEmbeddings(api_key=openai_api_key)

    def answer_question(self, session_id: str, question: str) -> dict:
        """
        å›ç­”ç”¨æˆ·é—®é¢˜

        æµç¨‹:
        1. å‘é‡æ£€ç´¢ç›¸å…³FAQ
        2. è·å–å¯¹è¯å†å²
        3. LLMç”Ÿæˆç­”æ¡ˆ
        4. ä¿å­˜å¯¹è¯
        """

        # 1. å‘é‡æ£€ç´¢
        question_vec = self.embeddings.embed_query(question)
        relevant_faqs = self._retrieve_faqs(question_vec, top_k=3)

        # 2. å¯¹è¯å†å²
        history = self._get_conversation_history(session_id, limit=5)

        # 3. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(question, relevant_faqs, history)

        # 4. ä¿å­˜å¯¹è¯
        self._save_conversation(session_id, question, answer)

        return {
            'session_id': session_id,
            'question': question,
            'answer': answer,
            'sources': [faq['faq_id'] for faq in relevant_faqs]
        }

    def _retrieve_faqs(self, query_vec: list, top_k: int = 3) -> list:
        """å‘é‡æ£€ç´¢FAQ"""

        self.cursor.execute("""
            SELECT
                faq_id,
                question,
                answer,
                category,
                1 - (embedding <-> %s::vector) AS similarity
            FROM faqs
            WHERE 1 - (embedding <-> %s::vector) > 0.7
            ORDER BY embedding <-> %s::vector
            LIMIT %s;
        """, (query_vec, query_vec, query_vec, top_k))

        return self.cursor.fetchall()

    def _get_conversation_history(self, session_id: str, limit: int = 5) -> list:
        """è·å–å¯¹è¯å†å²"""

        self.cursor.execute("""
            SELECT question, answer, created_at
            FROM conversations
            WHERE session_id = %s
            ORDER BY created_at DESC
            LIMIT %s;
        """, (session_id, limit))

        return list(reversed(self.cursor.fetchall()))

    def _generate_answer(self, question: str, faqs: list, history: list) -> str:
        """LLMç”Ÿæˆç­”æ¡ˆ"""

        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([
            f"Q: {faq['question']}\nA: {faq['answer']}"
            for faq in faqs
        ])

        history_text = "\n".join([
            f"ç”¨æˆ·: {h['question']}\nå®¢æœ: {h['answer']}"
            for h in history
        ])

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç›¸å…³çŸ¥è¯†:
{context}

å¯¹è¯å†å²:
{history_text}

ç”¨æˆ·é—®é¢˜: {question}

è¯·ç»™å‡ºä¸“ä¸šã€å‹å¥½çš„å›ç­”:
"""

        answer = self.llm(prompt)
        return answer.strip()

    def _save_conversation(self, session_id: str, question: str, answer: str):
        """ä¿å­˜å¯¹è¯è®°å½•"""

        self.cursor.execute("""
            INSERT INTO conversations (session_id, question, answer)
            VALUES (%s, %s, %s);
        """, (session_id, question, answer))

        self.conn.commit()

# ============================================================
# æ•°æ®åº“Schema
# ============================================================

"""
-- FAQè¡¨
CREATE TABLE faqs (
    faq_id SERIAL PRIMARY KEY,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    category VARCHAR(50),
    embedding vector(768),
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_faqs_embedding ON faqs USING hnsw (embedding vector_l2_ops);

-- å¯¹è¯è¡¨
CREATE TABLE conversations (
    conv_id BIGSERIAL PRIMARY KEY,
    session_id VARCHAR(100) NOT NULL,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_conversations_session ON conversations (session_id, created_at);

-- ç”¨æˆ·ä¼šè¯è¡¨
CREATE TABLE sessions (
    session_id VARCHAR(100) PRIMARY KEY,
    user_id BIGINT,
    channel VARCHAR(20),
    status VARCHAR(20),
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);
"""

# ============================================================
# FastAPIæ¥å£
# ============================================================

from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

bot = CustomerServiceBot(
    conn_str="dbname=customer_service_db user=postgres",
    openai_api_key="your-api-key"
)

class QuestionRequest(BaseModel):
    session_id: str
    question: str

@app.post("/api/chat")
async def chat(request: QuestionRequest):
    """å¯¹è¯æ¥å£"""
    result = bot.answer_question(request.session_id, request.question)
    return result

@app.get("/api/history/{session_id}")
async def get_history(session_id: str):
    """è·å–å¯¹è¯å†å²"""
    cursor = bot.cursor
    cursor.execute("""
        SELECT question, answer, created_at
        FROM conversations
        WHERE session_id = %s
        ORDER BY created_at;
    """, (session_id,))

    history = cursor.fetchall()
    return {'session_id': session_id, 'history': history}

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8005)
```

---

---

## 5. æ„å›¾è¯†åˆ«æ¨¡å—

### 5.1 æ„å›¾è¯†åˆ«å®ç°

**æ„å›¾è¯†åˆ«å®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class IntentRecognizer:
    """æ„å›¾è¯†åˆ«å™¨"""

    def __init__(self, conn, llm):
        self.conn = conn
        self.cursor = conn.cursor()
        self.llm = llm

    def recognize_intent(self, question: str) -> dict:
        """
        è¯†åˆ«ç”¨æˆ·æ„å›¾

        Returns:
            {
                'intent': 'greeting' | 'question' | 'complaint' | 'other',
                'confidence': 0.0-1.0,
                'entities': [...]
            }
        """

        try:
            # ä½¿ç”¨LLMè¯†åˆ«æ„å›¾
            prompt = f"""
            è¯†åˆ«ä»¥ä¸‹é—®é¢˜çš„æ„å›¾ï¼š

            é—®é¢˜: {question}

            å¯èƒ½çš„æ„å›¾ç±»å‹ï¼š
            - greeting: é—®å€™
            - question: å’¨è¯¢é—®é¢˜
            - complaint: æŠ•è¯‰
            - feedback: åé¦ˆ
            - other: å…¶ä»–

            è¯·è¿”å›JSONæ ¼å¼ï¼š
            {{
                "intent": "æ„å›¾ç±»å‹",
                "confidence": 0.0-1.0,
                "entities": ["å®ä½“1", "å®ä½“2"]
            }}
            """

            response = self.llm(prompt)

            # è§£æå“åº”ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            import json
            result = json.loads(response)

            # ä¿å­˜æ„å›¾è¯†åˆ«ç»“æœ
            self.cursor.execute("""
                INSERT INTO intent_logs (question, intent, confidence, entities)
                VALUES (%s, %s, %s, %s::jsonb)
            """, (question, result['intent'], result['confidence'], json.dumps(result['entities'])))

            self.conn.commit()

            return result

        except Exception as e:
            # è®°å½•é”™è¯¯
            self.cursor.execute("""
                INSERT INTO intent_logs (question, intent, confidence, error_message)
                VALUES (%s, 'error', 0.0, %s)
            """, (question, str(e)))
            self.conn.commit()

            return {
                'intent': 'other',
                'confidence': 0.0,
                'entities': []
            }
```

---

## 6. å¯¹è¯ç®¡ç†æ¨¡å—

### 6.1 å¯¹è¯çŠ¶æ€ç®¡ç†

**å¯¹è¯çŠ¶æ€ç®¡ç†å®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class ConversationManager:
    """å¯¹è¯ç®¡ç†å™¨"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def create_session(self, user_id: int = None, channel: str = 'web') -> str:
        """åˆ›å»ºæ–°ä¼šè¯"""

        import uuid
        session_id = str(uuid.uuid4())

        try:
            self.cursor.execute("""
                INSERT INTO sessions (session_id, user_id, channel, status)
                VALUES (%s, %s, %s, 'active')
            """, (session_id, user_id, channel))

            self.conn.commit()
            return session_id

        except Exception as e:
            self.conn.rollback()
            raise Exception(f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")

    def get_session_context(self, session_id: str) -> dict:
        """è·å–ä¼šè¯ä¸Šä¸‹æ–‡"""

        self.cursor.execute("""
            SELECT
                s.session_id,
                s.user_id,
                s.channel,
                s.status,
                COUNT(c.conv_id) AS message_count,
                MAX(c.created_at) AS last_message_time
            FROM sessions s
            LEFT JOIN conversations c ON s.session_id = c.session_id
            WHERE s.session_id = %s
            GROUP BY s.session_id, s.user_id, s.channel, s.status
        """, (session_id,))

        result = self.cursor.fetchone()

        if not result:
            return None

        return {
            'session_id': result['session_id'],
            'user_id': result['user_id'],
            'channel': result['channel'],
            'status': result['status'],
            'message_count': result['message_count'],
            'last_message_time': result['last_message_time']
        }

    def close_session(self, session_id: str):
        """å…³é—­ä¼šè¯"""

        try:
            self.cursor.execute("""
                UPDATE sessions
                SET status = 'closed', updated_at = NOW()
                WHERE session_id = %s
            """, (session_id,))

            self.conn.commit()

        except Exception as e:
            self.conn.rollback()
            raise Exception(f"å…³é—­ä¼šè¯å¤±è´¥: {str(e)}")
```

---

## 7. çŸ¥è¯†åº“ç®¡ç†æ¨¡å—

### 7.1 FAQç®¡ç†

**FAQç®¡ç†å®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class FAQManager:
    """FAQç®¡ç†å™¨"""

    def __init__(self, conn, embeddings):
        self.conn = conn
        self.cursor = conn.cursor()
        self.embeddings = embeddings

    def add_faq(self, question: str, answer: str, category: str = None):
        """æ·»åŠ FAQ"""

        try:
            # ç”Ÿæˆå‘é‡
            embedding = self.embeddings.embed_query(question)

            # æ’å…¥FAQ
            self.cursor.execute("""
                INSERT INTO faqs (question, answer, category, embedding)
                VALUES (%s, %s, %s, %s::vector)
                RETURNING faq_id
            """, (question, answer, category, embedding))

            faq_id = self.cursor.fetchone()[0]
            self.conn.commit()

            return faq_id

        except Exception as e:
            self.conn.rollback()
            raise Exception(f"æ·»åŠ FAQå¤±è´¥: {str(e)}")

    def update_faq(self, faq_id: int, question: str = None, answer: str = None):
        """æ›´æ–°FAQ"""

        try:
            updates = []
            params = []

            if question:
                # é‡æ–°ç”Ÿæˆå‘é‡
                embedding = self.embeddings.embed_query(question)
                updates.append("question = %s, embedding = %s::vector")
                params.extend([question, embedding])

            if answer:
                updates.append("answer = %s")
                params.append(answer)

            if not updates:
                return

            updates.append("updated_at = NOW()")
            params.append(faq_id)

            query = f"""
                UPDATE faqs
                SET {', '.join(updates)}
                WHERE faq_id = %s
            """

            self.cursor.execute(query, params)
            self.conn.commit()

        except Exception as e:
            self.conn.rollback()
            raise Exception(f"æ›´æ–°FAQå¤±è´¥: {str(e)}")

    def delete_faq(self, faq_id: int):
        """åˆ é™¤FAQ"""

        try:
            self.cursor.execute("""
                DELETE FROM faqs WHERE faq_id = %s
            """, (faq_id,))

            self.conn.commit()

        except Exception as e:
            self.conn.rollback()
            raise Exception(f"åˆ é™¤FAQå¤±è´¥: {str(e)}")
```

---

## 8. ç»Ÿè®¡åˆ†ææ¨¡å—

### 8.1 å¯¹è¯ç»Ÿè®¡åˆ†æ

**å¯¹è¯ç»Ÿè®¡åˆ†æå‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- å¯¹è¯ç»Ÿè®¡åˆ†æè§†å›¾
CREATE OR REPLACE VIEW v_conversation_stats AS
SELECT
    DATE_TRUNC('day', created_at) AS stat_date,
    COUNT(DISTINCT session_id) AS session_count,
    COUNT(*) AS message_count,
    COUNT(*) FILTER (WHERE answer IS NOT NULL) AS answered_count,
    ROUND(
        COUNT(*) FILTER (WHERE answer IS NOT NULL) * 100.0 / NULLIF(COUNT(*), 0),
        2
    ) AS answer_rate,
    ROUND(AVG(LENGTH(question)), 2) AS avg_question_length,
    ROUND(AVG(LENGTH(answer)), 2) AS avg_answer_length
FROM conversations
WHERE created_at > NOW() - INTERVAL '30 days'
GROUP BY DATE_TRUNC('day', created_at)
ORDER BY stat_date DESC;

-- æŸ¥è¯¢ç»Ÿè®¡
SELECT * FROM v_conversation_stats;
```

### 8.2 æ„å›¾åˆ†å¸ƒç»Ÿè®¡

**æ„å›¾åˆ†å¸ƒç»Ÿè®¡å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- æ„å›¾åˆ†å¸ƒç»Ÿè®¡å‡½æ•°
CREATE OR REPLACE FUNCTION get_intent_distribution(
    p_start_date TIMESTAMPTZ DEFAULT NOW() - INTERVAL '7 days',
    p_end_date TIMESTAMPTZ DEFAULT NOW()
)
RETURNS TABLE (
    intent TEXT,
    count BIGINT,
    percentage NUMERIC
) AS $$
DECLARE
    total_count BIGINT;
BEGIN
    -- è·å–æ€»æ•°
    SELECT COUNT(*) INTO total_count
    FROM intent_logs
    WHERE created_at BETWEEN p_start_date AND p_end_date;

    -- ç»Ÿè®¡å„æ„å›¾åˆ†å¸ƒ
    RETURN QUERY
    SELECT
        il.intent,
        COUNT(*)::BIGINT,
        ROUND(COUNT(*) * 100.0 / NULLIF(total_count, 0), 2)
    FROM intent_logs il
    WHERE il.created_at BETWEEN p_start_date AND p_end_date
    GROUP BY il.intent
    ORDER BY COUNT(*) DESC;

    RETURN;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'æ„å›¾åˆ†å¸ƒç»Ÿè®¡å¤±è´¥: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;
```

---

## 9. æ€§èƒ½ä¼˜åŒ–

### 9.1 å‘é‡æ£€ç´¢ä¼˜åŒ–

**å‘é‡æ£€ç´¢ä¼˜åŒ–å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- å‘é‡æ£€ç´¢ä¼˜åŒ–å‡½æ•°
CREATE OR REPLACE FUNCTION optimize_faq_retrieval(
    p_query_text TEXT,
    p_top_k INT DEFAULT 5,
    p_threshold FLOAT DEFAULT 0.7
)
RETURNS TABLE (
    faq_id INT,
    question TEXT,
    answer TEXT,
    similarity FLOAT
) AS $$
DECLARE
    query_vec vector(768);
BEGIN
    -- ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨pg_aiï¼‰
    -- query_vec := ai.embedding_openai('text-embedding-3-small', p_query_text)::vector(768);

    -- å‘é‡æ£€ç´¢
    RETURN QUERY
    SELECT
        f.faq_id,
        f.question,
        f.answer,
        (1 - (f.embedding <=> query_vec))::FLOAT AS similarity
    FROM faqs f
    WHERE f.embedding <=> query_vec < (1 - p_threshold)
    ORDER BY f.embedding <=> query_vec
    LIMIT p_top_k;

    RETURN;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'å‘é‡æ£€ç´¢ä¼˜åŒ–å¤±è´¥: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;
```

### 9.2 ç¼“å­˜ä¼˜åŒ–

**ç¼“å­˜ä¼˜åŒ–å®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
from functools import lru_cache
import hashlib
import json

class ResponseCache:
    """å“åº”ç¼“å­˜"""

    def __init__(self, maxsize=500):
        self.cache = {}
        self.maxsize = maxsize

    def get_cache_key(self, question: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(question.encode()).hexdigest()

    def get(self, question: str) -> dict:
        """è·å–ç¼“å­˜"""
        cache_key = self.get_cache_key(question)
        return self.cache.get(cache_key)

    def set(self, question: str, response: dict):
        """è®¾ç½®ç¼“å­˜"""
        cache_key = self.get_cache_key(question)

        # LRUæ·˜æ±°
        if len(self.cache) >= self.maxsize:
            # åˆ é™¤æœ€æ—§çš„é¡¹ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]

        self.cache[cache_key] = response

    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
```

---

## 10. ç›‘æ§ä¸è¯Šæ–­

### 10.1 ç³»ç»Ÿå¥åº·ç›‘æ§

**ç³»ç»Ÿå¥åº·ç›‘æ§å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- ç³»ç»Ÿå¥åº·ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW v_system_health AS
SELECT
    'FAQæ€»æ•°'::TEXT AS metric_name,
    COUNT(*)::BIGINT AS metric_value,
    'æ­£å¸¸'::TEXT AS status
FROM faqs

UNION ALL

SELECT
    'æ´»è·ƒä¼šè¯æ•°'::TEXT,
    COUNT(*)::BIGINT,
    CASE
        WHEN COUNT(*) > 1000 THEN 'è­¦å‘Š'
        ELSE 'æ­£å¸¸'
    END
FROM sessions
WHERE status = 'active'

UNION ALL

SELECT
    'ä»Šæ—¥å¯¹è¯æ•°'::TEXT,
    COUNT(*)::BIGINT,
    CASE
        WHEN COUNT(*) > 10000 THEN 'è­¦å‘Š'
        ELSE 'æ­£å¸¸'
    END
FROM conversations
WHERE created_at::DATE = CURRENT_DATE

UNION ALL

SELECT
    'å¹³å‡å“åº”æ—¶é—´(ms)'::TEXT,
    ROUND(AVG(duration_ms), 2)::BIGINT,
    CASE
        WHEN AVG(duration_ms) > 3000 THEN 'è­¦å‘Š'
        ELSE 'æ­£å¸¸'
    END
FROM query_logs
WHERE created_at > NOW() - INTERVAL '1 hour';

-- æŸ¥è¯¢å¥åº·çŠ¶æ€
SELECT * FROM v_system_health;
```

---

## 8. PostgreSQL 18æ™ºèƒ½å®¢æœä¼˜åŒ–

### 8.1 å¼‚æ­¥I/Oä¼˜åŒ–

**å¼‚æ­¥I/Oä¼˜åŒ–ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- PostgreSQL 18å¼‚æ­¥I/Oé…ç½®
ALTER SYSTEM SET io_direct = 'data';
ALTER SYSTEM SET io_combine_limit = '256kB';

-- é‡å¯åç”Ÿæ•ˆ
SELECT pg_reload_conf();

-- æ€§èƒ½æå‡:
-- å‘é‡æ£€ç´¢æ€§èƒ½: +25-30%
-- æ··åˆæ£€ç´¢æ€§èƒ½: +20-25%
-- å¯¹è¯å†å²æŸ¥è¯¢: +15-20%
```

### 8.2 å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ–

**å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ–ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 1000;
SET parallel_tuple_cost = 0.01;

-- å¹¶è¡Œæ··åˆæ£€ç´¢ç¤ºä¾‹
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM search_faqs_hybrid(
    query_vector,
    query_text,
    top_k => 10,
    vector_weight => 0.6,
    text_weight => 0.4
);

-- æ€§èƒ½æå‡:
-- å¤§è§„æ¨¡æ£€ç´¢: +35-40%
```

---

## 9. æ™ºèƒ½å®¢æœç³»ç»Ÿç›‘æ§

### 9.1 é—®ç­”æ€§èƒ½ç›‘æ§

**é—®ç­”æ€§èƒ½ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- é—®ç­”æ€§èƒ½ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW v_qa_performance AS
SELECT
    DATE_TRUNC('hour', created_at) AS hour,
    COUNT(*) AS query_count,
    AVG(duration_ms) AS avg_duration_ms,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY duration_ms) AS p95_duration_ms,
    AVG(vector_search_time_ms) AS avg_vector_search_time_ms,
    AVG(llm_generation_time_ms) AS avg_llm_gen_time_ms,
    COUNT(*) FILTER (WHERE success = true) AS success_count,
    COUNT(*) FILTER (WHERE success = false) AS failed_count
FROM query_logs
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour DESC;

-- æŸ¥è¯¢é—®ç­”æ€§èƒ½ç»Ÿè®¡
SELECT * FROM v_qa_performance;
```

### 9.2 ä¼šè¯è´¨é‡ç›‘æ§

**ä¼šè¯è´¨é‡ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- ä¼šè¯è´¨é‡ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW v_session_quality AS
SELECT
    DATE_TRUNC('day', created_at) AS day,
    COUNT(DISTINCT session_id) AS session_count,
    COUNT(*) AS conversation_count,
    AVG(conversation_count_per_session) AS avg_conversations_per_session,
    AVG(user_rating) AS avg_user_rating,
    COUNT(*) FILTER (WHERE user_rating >= 4) AS high_rating_count,
    ROUND(COUNT(*) FILTER (WHERE user_rating >= 4) * 100.0 / COUNT(*), 2) AS satisfaction_rate
FROM (
    SELECT
        session_id,
        created_at::DATE AS created_at,
        COUNT(*) AS conversation_count_per_session,
        AVG(user_rating) AS user_rating
    FROM conversations
    WHERE created_at > NOW() - INTERVAL '7 days'
    GROUP BY session_id, created_at::DATE
) AS subq
GROUP BY day
ORDER BY day DESC;

-- æŸ¥è¯¢ä¼šè¯è´¨é‡ç»Ÿè®¡
SELECT * FROM v_session_quality;
```

---

## 10. æ™ºèƒ½å®¢æœç³»ç»Ÿæœ€ä½³å®è·µ

### 10.1 æ£€ç´¢ä¼˜åŒ–æœ€ä½³å®è·µ

**æ£€ç´¢ä¼˜åŒ–æœ€ä½³å®è·µï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- 1. ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆæé«˜å‡†ç¡®ç‡ï¼‰
SELECT * FROM search_faqs_hybrid(
    query_vector,
    query_text,
    top_k => 10,
    vector_weight => 0.6,  -- å‘é‡æƒé‡
    text_weight => 0.4      -- æ–‡æœ¬æƒé‡
);

-- 2. ä½¿ç”¨ç¼“å­˜ï¼ˆå‡å°‘æ•°æ®åº“æŸ¥è¯¢ï¼‰
-- Redisç¼“å­˜çƒ­é—¨FAQæ£€ç´¢ç»“æœ

-- 3. æ‰¹é‡å‘é‡åŒ–ï¼ˆæé«˜æ•ˆç‡ï¼‰
-- ä½¿ç”¨æ‰¹é‡APIå‘é‡åŒ–å¤šä¸ªé—®é¢˜
```

### 10.2 LLMé›†æˆæœ€ä½³å®è·µ

**LLMé›†æˆæœ€ä½³å®è·µï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
# 1. ä½¿ç”¨æµå¼å“åº”ï¼ˆé™ä½å»¶è¿Ÿï¼‰
def generate_answer_streaming(question: str, context: str):
    """æµå¼ç”Ÿæˆç­”æ¡ˆ"""
    prompt = f"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n{context}\n\né—®é¢˜ï¼š{question}\nç­”æ¡ˆï¼š"

    for chunk in llm.stream(prompt):
        yield chunk

# 2. ä½¿ç”¨ç¼“å­˜ï¼ˆå‡å°‘LLMè°ƒç”¨ï¼‰
@lru_cache(maxsize=1000)
def cached_generate_answer(question_hash: str, context_hash: str):
    """ç¼“å­˜LLMç”Ÿæˆç»“æœ"""
    # ä»ç¼“å­˜è·å–
    cached = redis_client.get(f"llm_answer:{question_hash}:{context_hash}")
    if cached:
        return cached

    # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
    answer = generate_answer(question, context)

    # å­˜å…¥ç¼“å­˜
    redis_client.setex(f"llm_answer:{question_hash}:{context_hash}", 3600, answer)

    return answer

# 3. å¼‚æ­¥å¤„ç†ï¼ˆæé«˜ååé‡ï¼‰
async def process_question_async(question: str):
    """å¼‚æ­¥å¤„ç†é—®é¢˜"""
    # å¹¶è¡Œæ‰§è¡Œå‘é‡æ£€ç´¢å’Œå¯¹è¯å†å²è·å–
    faqs_task = asyncio.create_task(retrieve_faqs_async(question))
    history_task = asyncio.create_task(get_history_async(session_id))

    faqs, history = await asyncio.gather(faqs_task, history_task)

    # ç”Ÿæˆç­”æ¡ˆ
    answer = await generate_answer_async(question, faqs, history)

    return answer
```

---

**è¿”å›**: [æ¡ˆä¾‹9ä¸»é¡µ](./README.md)
**å­—æ•°**: ~10,000å­—
**æ¶µç›–**: é—®ç­”æµç¨‹ã€å‘é‡æ£€ç´¢ã€å¯¹è¯å†å²ã€LLMé›†æˆã€PostgreSQL 18ä¼˜åŒ–ã€ç›‘æ§ã€æœ€ä½³å®è·µ
