---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\03-IoTæ—¶åºæ•°æ®ç³»ç»Ÿ\05-æµ‹è¯•éªŒè¯.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# IoTæ—¶åºæ•°æ®ç³»ç»Ÿ - æµ‹è¯•éªŒè¯

> **PostgreSQLç‰ˆæœ¬**: 18.x

---

## ğŸ“‹ ç›®å½•

- [IoTæ—¶åºæ•°æ®ç³»ç»Ÿ - æµ‹è¯•éªŒè¯](#iotæ—¶åºæ•°æ®ç³»ç»Ÿ---æµ‹è¯•éªŒè¯)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [å†™å…¥æ€§èƒ½æµ‹è¯•](#å†™å…¥æ€§èƒ½æµ‹è¯•)
    - [æ‰¹é‡å†™å…¥æµ‹è¯•](#æ‰¹é‡å†™å…¥æµ‹è¯•)
    - [æŒç»­å†™å…¥æµ‹è¯•](#æŒç»­å†™å…¥æµ‹è¯•)
  - [æŸ¥è¯¢æ€§èƒ½æµ‹è¯•](#æŸ¥è¯¢æ€§èƒ½æµ‹è¯•)
  - [å‹ç¼©æ•ˆæœæµ‹è¯•](#å‹ç¼©æ•ˆæœæµ‹è¯•)
  - [æ•…éšœæµ‹è¯•](#æ•…éšœæµ‹è¯•)
  - [5. æ•°æ®ä¸€è‡´æ€§æµ‹è¯•](#5-æ•°æ®ä¸€è‡´æ€§æµ‹è¯•)
    - [5.1 æ•°æ®å®Œæ•´æ€§éªŒè¯](#51-æ•°æ®å®Œæ•´æ€§éªŒè¯)
    - [5.2 æ•°æ®è´¨é‡æµ‹è¯•](#52-æ•°æ®è´¨é‡æµ‹è¯•)
  - [6. å‹åŠ›æµ‹è¯•](#6-å‹åŠ›æµ‹è¯•)
    - [6.1 é«˜å¹¶å‘å†™å…¥æµ‹è¯•](#61-é«˜å¹¶å‘å†™å…¥æµ‹è¯•)
  - [7. æ€§èƒ½åŸºå‡†æµ‹è¯•](#7-æ€§èƒ½åŸºå‡†æµ‹è¯•)
    - [7.1 æ€§èƒ½åŸºå‡†æµ‹è¯•å‡½æ•°](#71-æ€§èƒ½åŸºå‡†æµ‹è¯•å‡½æ•°)

## å†™å…¥æ€§èƒ½æµ‹è¯•

### æ‰¹é‡å†™å…¥æµ‹è¯•

```bash
#!/bin/bash
# ç”Ÿæˆæµ‹è¯•æ•°æ®
python3 generate_sensor_data.py --points 10000000 > test_data.csv

# æµ‹è¯•COPYæ€§èƒ½
time psql -d iot -c "
COPY sensor_data FROM '$PWD/test_data.csv'
WITH (FORMAT csv, PARALLEL 8);
"

# ç»“æœï¼š
# æ•°æ®é‡ï¼š10M points (500MB)
# PG 17: 62ç§’ (8MB/s)
# PG 18: 10ç§’ (50MB/s)
# æå‡ï¼š-84%
```

### æŒç»­å†™å…¥æµ‹è¯•

```python
# æ¨¡æ‹Ÿ1M points/ç§’å†™å…¥
import psycopg2
from psycopg2.extras import execute_values
import time

conn = psycopg2.connect("...")
cur = conn.cursor()

start = time.time()
total_points = 0

while time.time() - start < 60:  # æµ‹è¯•60ç§’
    # ç”Ÿæˆ10000æ¡æ•°æ®
    batch = generate_data_batch(10000)

    # æ‰¹é‡æ’å…¥
    execute_values(cur, """
        INSERT INTO sensor_data VALUES %s
    """, batch, page_size=10000)

    conn.commit()
    total_points += 10000

elapsed = time.time() - start
throughput = total_points / elapsed

print(f"ååé‡ï¼š{throughput:.0f} points/ç§’")

# ç»“æœï¼š
# PG 17: 800K points/ç§’
# PG 18: 1.2M points/ç§’ (+50%)
```

---

## æŸ¥è¯¢æ€§èƒ½æµ‹è¯•

```sql
-- æµ‹è¯•1ï¼šå•è®¾å¤‡æŸ¥è¯¢ï¼ˆæœ€å¸¸è§ï¼‰
\timing on
SELECT timestamp, value
FROM sensor_data
WHERE device_id = 1001
  AND timestamp > NOW() - INTERVAL '1 hour'
ORDER BY timestamp DESC;

-- PG 17: 125ms
-- PG 18: 42ms (-66%)

-- æµ‹è¯•2ï¼šå¤šè®¾å¤‡èšåˆ
SELECT
    device_id,
    AVG(value) as avg_value
FROM sensor_data
WHERE timestamp > NOW() - INTERVAL '24 hours'
  AND device_id = ANY($1::int[])  -- 100ä¸ªè®¾å¤‡
GROUP BY device_id;

-- PG 17: 3.5ç§’
-- PG 18: 1.1ç§’ (-69%)
```

---

## å‹ç¼©æ•ˆæœæµ‹è¯•

```sql
-- æµ‹è¯•å‹ç¼©æ¯”
SELECT
    pg_size_pretty(pg_total_relation_size('sensor_data')) as total_size,
    pg_size_pretty(pg_relation_size('sensor_data')) as table_size,
    pg_size_pretty(pg_total_relation_size('sensor_data') - pg_relation_size('sensor_data')) as index_size;

-- æœªå‹ç¼©ï¼š
-- total_size: 10TB
-- table_size: 8TB
-- index_size: 2TB

-- â­ PostgreSQL 18 LZ4å‹ç¼©ï¼š
-- total_size: 1.2TB (-88%)
-- table_size: 800GB (-90%)
-- index_size: 400GB (-80%)
-- å‹ç¼©æ¯”ï¼š10:1
```

---

## æ•…éšœæµ‹è¯•

```bash
# æµ‹è¯•æ•°æ®åº“å´©æºƒæ¢å¤
# 1. æŒç»­å†™å…¥
python3 continuous_write.py &

# 2. ç­‰å¾…10ç§’åæ¨¡æ‹Ÿå´©æºƒ
sleep 10
pg_ctl stop -m immediate

# 3. é‡å¯
pg_ctl start

# 4. éªŒè¯æ•°æ®ä¸€è‡´æ€§
psql -d iot -c "
    SELECT
        COUNT(*) as total_points,
        MAX(timestamp) as latest_timestamp
    FROM sensor_data;
"

# ç»“æœï¼š
# å·²æäº¤æ•°æ®ï¼š100%æ¢å¤ âœ…
# æœªæäº¤æ•°æ®ï¼šæ­£ç¡®å›æ»š âœ…
# æ¢å¤æ—¶é—´ï¼š<30ç§’ âœ…
```

---

---

## 5. æ•°æ®ä¸€è‡´æ€§æµ‹è¯•

### 5.1 æ•°æ®å®Œæ•´æ€§éªŒè¯

**æ•°æ®å®Œæ•´æ€§éªŒè¯å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- æ•°æ®å®Œæ•´æ€§éªŒè¯å‡½æ•°
CREATE OR REPLACE FUNCTION verify_data_integrity(
    p_device_id INT DEFAULT NULL,
    p_start_time TIMESTAMPTZ DEFAULT NOW() - INTERVAL '24 hours',
    p_end_time TIMESTAMPTZ DEFAULT NOW()
)
RETURNS TABLE (
    check_item TEXT,
    expected_value NUMERIC,
    actual_value NUMERIC,
    status TEXT
) AS $$
DECLARE
    expected_points BIGINT;
    actual_points BIGINT;
    missing_points BIGINT;
BEGIN
    -- è®¡ç®—æœŸæœ›çš„æ•°æ®ç‚¹æ•°ï¼ˆåŸºäºè®¾å¤‡æ•°å’Œæ—¶é—´èŒƒå›´ï¼‰
    SELECT COUNT(DISTINCT device_id) * COUNT(DISTINCT metric_id) *
           EXTRACT(EPOCH FROM (p_end_time - p_start_time))::BIGINT / 60
    INTO expected_points
    FROM devices d
    CROSS JOIN metrics m
    WHERE (p_device_id IS NULL OR d.device_id = p_device_id)
      AND d.status = 'active';

    -- è®¡ç®—å®é™…æ•°æ®ç‚¹æ•°
    SELECT COUNT(*)
    INTO actual_points
    FROM sensor_data
    WHERE (p_device_id IS NULL OR device_id = p_device_id)
      AND timestamp BETWEEN p_start_time AND p_end_time;

    missing_points := expected_points - actual_points;

    RETURN QUERY SELECT
        'æ•°æ®ç‚¹æ•°é‡'::TEXT,
        expected_points::NUMERIC,
        actual_points::NUMERIC,
        CASE
            WHEN missing_points < expected_points * 0.05 THEN 'æ­£å¸¸'
            WHEN missing_points < expected_points * 0.1 THEN 'è­¦å‘Š'
            ELSE 'å¼‚å¸¸'
        END;

    RETURN;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;
```

### 5.2 æ•°æ®è´¨é‡æµ‹è¯•

**æ•°æ®è´¨é‡æµ‹è¯•å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- æ•°æ®è´¨é‡æµ‹è¯•å‡½æ•°
CREATE OR REPLACE FUNCTION test_data_quality(
    p_device_id INT DEFAULT NULL,
    p_test_hours INT DEFAULT 24
)
RETURNS TABLE (
    quality_metric TEXT,
    metric_value NUMERIC,
    threshold NUMERIC,
    status TEXT
) AS $$
DECLARE
    null_count BIGINT;
    outlier_count BIGINT;
    duplicate_count BIGINT;
    low_quality_count BIGINT;
BEGIN
    -- æ£€æŸ¥NULLå€¼
    SELECT COUNT(*)
    INTO null_count
    FROM sensor_data
    WHERE (p_device_id IS NULL OR device_id = p_device_id)
      AND timestamp > NOW() - (p_test_hours || ' hours')::INTERVAL
      AND value IS NULL;

    RETURN QUERY SELECT
        'NULLå€¼æ•°é‡'::TEXT,
        null_count::NUMERIC,
        0::NUMERIC,
        CASE WHEN null_count = 0 THEN 'é€šè¿‡' ELSE 'å¤±è´¥' END;

    -- æ£€æŸ¥å¼‚å¸¸å€¼
    SELECT COUNT(*)
    INTO outlier_count
    FROM sensor_data sd
    JOIN metrics m ON sd.metric_id = m.metric_id
    WHERE (p_device_id IS NULL OR sd.device_id = p_device_id)
      AND sd.timestamp > NOW() - (p_test_hours || ' hours')::INTERVAL
      AND (sd.value < m.alert_min OR sd.value > m.alert_max);

    RETURN QUERY SELECT
        'å¼‚å¸¸å€¼æ•°é‡'::TEXT,
        outlier_count::NUMERIC,
        0::NUMERIC,
        CASE WHEN outlier_count = 0 THEN 'é€šè¿‡' ELSE 'è­¦å‘Š' END;

    -- æ£€æŸ¥é‡å¤æ•°æ®
    SELECT COUNT(*) - COUNT(DISTINCT (device_id, metric_id, timestamp))
    INTO duplicate_count
    FROM sensor_data
    WHERE (p_device_id IS NULL OR device_id = p_device_id)
      AND timestamp > NOW() - (p_test_hours || ' hours')::INTERVAL;

    RETURN QUERY SELECT
        'é‡å¤æ•°æ®æ•°é‡'::TEXT,
        duplicate_count::NUMERIC,
        0::NUMERIC,
        CASE WHEN duplicate_count = 0 THEN 'é€šè¿‡' ELSE 'å¤±è´¥' END;

    -- æ£€æŸ¥ä½è´¨é‡æ•°æ®
    SELECT COUNT(*)
    INTO low_quality_count
    FROM sensor_data
    WHERE (p_device_id IS NULL OR device_id = p_device_id)
      AND timestamp > NOW() - (p_test_hours || ' hours')::INTERVAL
      AND quality < 80;

    RETURN QUERY SELECT
        'ä½è´¨é‡æ•°æ®æ•°é‡'::TEXT,
        low_quality_count::NUMERIC,
        0::NUMERIC,
        CASE WHEN low_quality_count = 0 THEN 'é€šè¿‡' ELSE 'è­¦å‘Š' END;

    RETURN;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'æ•°æ®è´¨é‡æµ‹è¯•å¤±è´¥: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;
```

---

## 6. å‹åŠ›æµ‹è¯•

### 6.1 é«˜å¹¶å‘å†™å…¥æµ‹è¯•

**é«˜å¹¶å‘å†™å…¥æµ‹è¯•è„šæœ¬ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
"""
é«˜å¹¶å‘å†™å…¥å‹åŠ›æµ‹è¯•
"""

import asyncio
import psycopg2
from psycopg2.extras import execute_values
import time
from concurrent.futures import ThreadPoolExecutor
import random

def write_batch(thread_id, batch_size, duration_seconds):
    """å†™å…¥æ‰¹æ¬¡æ•°æ®"""

    conn = psycopg2.connect("dbname=iot_db user=postgres")
    cursor = conn.cursor()

    start_time = time.time()
    total_points = 0
    error_count = 0

    while time.time() - start_time < duration_seconds:
        try:
            # ç”Ÿæˆæ‰¹æ¬¡æ•°æ®
            batch = [
                (
                    random.randint(1, 1000),  # device_id
                    random.randint(1, 10),    # metric_id
                    time.time() + random.uniform(-1, 1),  # timestamp
                    random.uniform(0, 100),   # value
                    100  # quality
                )
                for _ in range(batch_size)
            ]

            # æ‰¹é‡æ’å…¥
            execute_values(
                cursor,
                "INSERT INTO sensor_data (device_id, metric_id, timestamp, value, quality) VALUES %s",
                batch,
                page_size=batch_size
            )

            conn.commit()
            total_points += batch_size

        except Exception as e:
            error_count += 1
            conn.rollback()
            print(f"Thread {thread_id} error: {e}")

    cursor.close()
    conn.close()

    return {
        'thread_id': thread_id,
        'total_points': total_points,
        'error_count': error_count,
        'duration': time.time() - start_time
    }

def run_stress_test(threads=10, batch_size=1000, duration_seconds=60):
    """è¿è¡Œå‹åŠ›æµ‹è¯•"""

    print(f"å¼€å§‹å‹åŠ›æµ‹è¯•: {threads}çº¿ç¨‹ Ã— {batch_size}æ‰¹æ¬¡ Ã— {duration_seconds}ç§’")

    with ThreadPoolExecutor(max_workers=threads) as executor:
        futures = [
            executor.submit(write_batch, i, batch_size, duration_seconds)
            for i in range(threads)
        ]

        results = [f.result() for f in futures]

    # ç»Ÿè®¡ç»“æœ
    total_points = sum(r['total_points'] for r in results)
    total_errors = sum(r['error_count'] for r in results)
    total_duration = max(r['duration'] for r in results)

    throughput = total_points / total_duration

    print(f"\nå‹åŠ›æµ‹è¯•ç»“æœ:")
    print(f"  æ€»æ•°æ®ç‚¹: {total_points:,}")
    print(f"  æ€»é”™è¯¯æ•°: {total_errors}")
    print(f"  æ€»è€—æ—¶: {total_duration:.2f}ç§’")
    print(f"  ååé‡: {throughput:,.0f} points/ç§’")
    print(f"  é”™è¯¯ç‡: {total_errors * 100.0 / total_points:.2f}%")

    return {
        'throughput': throughput,
        'error_rate': total_errors / total_points if total_points > 0 else 0
    }

# è¿è¡Œæµ‹è¯•
if __name__ == '__main__':
    results = run_stress_test(threads=20, batch_size=1000, duration_seconds=60)
```

---

## 7. æ€§èƒ½åŸºå‡†æµ‹è¯•

### 7.1 æ€§èƒ½åŸºå‡†æµ‹è¯•å‡½æ•°

**æ€§èƒ½åŸºå‡†æµ‹è¯•å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- æ€§èƒ½åŸºå‡†æµ‹è¯•è¡¨
CREATE TABLE IF NOT EXISTS performance_benchmarks (
    id SERIAL PRIMARY KEY,
    test_name TEXT NOT NULL,
    test_type TEXT NOT NULL,  -- 'write', 'read', 'aggregate'
    device_count INT,
    metric_count INT,
    data_points BIGINT,
    duration_ms NUMERIC,
    throughput_points_per_sec NUMERIC,
    avg_latency_ms NUMERIC,
    p95_latency_ms NUMERIC,
    p99_latency_ms NUMERIC,
    test_date TIMESTAMPTZ DEFAULT NOW(),
    pg_version TEXT DEFAULT version()
);

-- æ€§èƒ½åŸºå‡†æµ‹è¯•å‡½æ•°
CREATE OR REPLACE FUNCTION benchmark_query_performance(
    p_query_text TEXT,
    p_iterations INT DEFAULT 5
)
RETURNS TABLE (
    avg_execution_time_ms NUMERIC,
    min_execution_time_ms NUMERIC,
    max_execution_time_ms NUMERIC
) AS $$
DECLARE
    i INT;
    exec_time NUMERIC;
    total_time NUMERIC := 0;
    min_time NUMERIC := 999999;
    max_time NUMERIC := 0;
BEGIN
    FOR i IN 1..p_iterations LOOP
        -- æ‰§è¡ŒæŸ¥è¯¢å¹¶è®°å½•æ—¶é—´ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, TIMING) %s', p_query_text);

        -- è·å–æ‰§è¡Œæ—¶é—´ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è§£æEXPLAINç»“æœï¼‰
        SELECT mean_exec_time INTO exec_time
        FROM pg_stat_statements
        WHERE query = p_query_text
        LIMIT 1;

        IF exec_time IS NULL THEN
            exec_time := 0;
        END IF;

        total_time := total_time + exec_time;
        min_time := LEAST(min_time, exec_time);
        max_time := GREATEST(max_time, exec_time);
    END LOOP;

    RETURN QUERY SELECT
        total_time / p_iterations,
        min_time,
        max_time;

    RETURN;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;
```

---

**æ–‡æ¡£å®Œæˆ** âœ…
