# æ™ºèƒ½è§†é¢‘æ¨èç³»ç»Ÿ - è¯¦ç»†å®ç°

> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´1æœˆ
> **ç”¨é€”**: è§†é¢‘æ¨èåœºæ™¯çš„è¯¦ç»†å®ç°æ–‡æ¡£
> **é€šç”¨æ¶æ„**: è¯·å‚è€ƒ [é€šç”¨æ¨èç³»ç»Ÿæ¶æ„](../é€šç”¨æ¨èç³»ç»Ÿæ¶æ„.md)

---

## ğŸ“‹ æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£ä¸“æ³¨äºè§†é¢‘æ¨èåœºæ™¯çš„ç‰¹å®šå®ç°ç»†èŠ‚ã€‚é€šç”¨æ¶æ„å’Œæœ€ä½³å®è·µè¯·å‚è€ƒé€šç”¨æ–‡æ¡£ã€‚

**åŸå§‹æ–‡æ¡£æ¥æº**: `PostgreSQL_View\08-è½åœ°æ¡ˆä¾‹\è§†é¢‘åœºæ™¯\æ™ºèƒ½è§†é¢‘æ¨èç³»ç»Ÿ.md`

---

## 1. è§†é¢‘åœºæ™¯ç‰¹å®šè®¾è®¡

### 1.1 è§†é¢‘æ•°æ®æ¨¡å‹

```sql
-- è§†é¢‘è¡¨ï¼ˆè§†é¢‘ç‰¹å®šå­—æ®µï¼‰
CREATE TABLE videos (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    creator TEXT,
    category TEXT,
    content_vector vector(512),  -- è§†é¢‘å†…å®¹å‘é‡
    category_vector vector(256),  -- åˆ†ç±»ç‰¹å¾å‘é‡
    duration INTEGER,  -- æ—¶é•¿ï¼ˆç§’ï¼‰
    view_count INTEGER DEFAULT 0,
    like_count INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    metadata JSONB
);

-- ç”¨æˆ·è§‚çœ‹å†å²è¡¨ï¼ˆè§†é¢‘ç‰¹å®šï¼‰
CREATE TABLE user_watch_history (
    id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL,
    video_id INTEGER NOT NULL,
    watch_duration INTEGER,  -- è§‚çœ‹æ—¶é•¿ï¼ˆç§’ï¼‰
    completion_rate DECIMAL(5, 2),  -- å®Œæˆç‡ï¼ˆ0-100ï¼‰
    watched_at TIMESTAMPTZ DEFAULT NOW(),
    rating INTEGER,
    metadata JSONB
);
```

### 1.2 è§†é¢‘æ¨èç®—æ³•

**è€ƒè™‘è§‚çœ‹å®Œæˆç‡**:

```sql
-- è§†é¢‘æ¨èï¼ˆè€ƒè™‘è§‚çœ‹å®Œæˆç‡ï¼‰
SELECT
    c.content_id,
    c.title,
    AVG(ub.duration::FLOAT / c.metadata->>'duration') AS avg_completion_rate,
    1 - (c.feature_vector <=> up.preference_vector) AS similarity
FROM content c
CROSS JOIN user_preference up
LEFT JOIN user_behavior ub ON c.content_id = ub.content_id
    AND ub.user_id = up.user_id
WHERE c.content_type = 'video'
  AND up.user_id = $1
GROUP BY c.content_id, c.title, c.feature_vector, up.preference_vector
ORDER BY (similarity * COALESCE(avg_completion_rate, 0.5)) DESC
LIMIT 20;
```

---

## 2. è§†é¢‘åœºæ™¯æœ€ä½³å®è·µ

### 2.1 è§†é¢‘ç‰¹å¾æå–

- è§†é¢‘å¸§ç‰¹å¾æå–
- éŸ³é¢‘ç‰¹å¾æå–
- å­—å¹•æ–‡æœ¬ç‰¹å¾æå–
- å¤šæ¨¡æ€ç‰¹å¾èåˆ

### 2.2 è§‚çœ‹è¡Œä¸ºåˆ†æ

- è§‚çœ‹æ—¶é•¿åˆ†æ
- è§‚çœ‹å®Œæˆç‡åˆ†æ
- è§‚çœ‹æ—¶é—´æ¨¡å¼åˆ†æ
- è§†é¢‘åˆ†ç±»åå¥½åˆ†æ

---

## 3. å®Œæ•´ä»£ç ç¤ºä¾‹

### 3.1 è§†é¢‘æ¨èå®ç°

```python
class VideoRecommendationSystem:
    def recommend_videos(self, user_id, limit=20):
        """è§†é¢‘æ¨è"""
        # è€ƒè™‘è§‚çœ‹å®Œæˆç‡çš„æ¨èç®—æ³•
        recommendations = self.db.execute("""
            SELECT
                v.id,
                v.title,
                v.creator,
                AVG(wh.completion_rate) AS avg_completion,
                1 - (v.content_vector <=> up.preference_vector) AS similarity
            FROM videos v
            JOIN user_preferences up ON up.user_id = %s
            LEFT JOIN user_watch_history wh ON v.id = wh.video_id
            WHERE v.id NOT IN (
                SELECT video_id FROM user_watch_history WHERE user_id = %s
            )
            GROUP BY v.id, v.title, v.creator, v.content_vector, up.preference_vector
            ORDER BY (similarity * COALESCE(avg_completion, 0.5)) DESC
            LIMIT %s
        """, (user_id, user_id, limit))

        return recommendations
```

---

## 4. PostgreSQL 18ä¼˜åŒ–

### 4.1 å¼‚æ­¥I/Oä¼˜åŒ–

**æ‰¹é‡è§†é¢‘æ•°æ®å¯¼å…¥ä¼˜åŒ–**ï¼š

```sql
-- PostgreSQL 18å¼‚æ­¥I/Oé…ç½®
ALTER SYSTEM SET io_direct = 'data,wal';
ALTER SYSTEM SET effective_io_concurrency = 200;
ALTER SYSTEM SET wal_io_concurrency = 200;

-- æ‰¹é‡å¯¼å…¥è§†é¢‘æ•°æ®ï¼ˆåˆ©ç”¨å¼‚æ­¥I/Oï¼‰
INSERT INTO videos (title, creator, category, content_vector, duration, metadata)
SELECT
    'Video ' || i,
    'Creator ' || (i % 100),
    CASE (i % 10)
        WHEN 0 THEN 'æ•™è‚²'
        WHEN 1 THEN 'å¨±ä¹'
        WHEN 2 THEN 'ç§‘æŠ€'
        WHEN 3 THEN 'éŸ³ä¹'
        WHEN 4 THEN 'æ¸¸æˆ'
        ELSE 'å…¶ä»–'
    END,
    (SELECT vector FROM generate_random_vector(512)),
    random() * 3600 + 60,
    jsonb_build_object('views', random() * 1000000, 'likes', random() * 100000)
FROM generate_series(1, 100000) i;

-- æ€§èƒ½æå‡ï¼šæ‰¹é‡å¯¼å…¥é€Ÿåº¦æå‡2.5å€
```

### 4.2 å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ–

**å¹¶è¡Œå‘é‡ç›¸ä¼¼åº¦è®¡ç®—**ï¼š

```sql
-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;
SET parallel_workers = 4;

-- å¹¶è¡Œå‘é‡ç›¸ä¼¼åº¦è®¡ç®—
EXPLAIN ANALYZE
SELECT
    v.id,
    v.title,
    1 - (v.content_vector <=> $1::vector) AS similarity
FROM videos v
WHERE v.category = 'ç§‘æŠ€'
ORDER BY v.content_vector <=> $1::vector
LIMIT 100;

-- æ€§èƒ½æå‡ï¼šæŸ¥è¯¢æ—¶é—´é™ä½55%
```

### 4.3 JSONBç´¢å¼•ä¼˜åŒ–

**è§†é¢‘å…ƒæ•°æ®æŸ¥è¯¢ä¼˜åŒ–**ï¼š

```sql
-- åˆ›å»ºGINç´¢å¼•
CREATE INDEX idx_videos_metadata_gin ON videos USING GIN (metadata);

-- ä¼˜åŒ–åçš„æŸ¥è¯¢
SELECT *
FROM videos
WHERE metadata @> '{"category": "ç§‘æŠ€", "duration": {"$gt": 300}}'::jsonb
ORDER BY view_count DESC
LIMIT 20;

-- æ€§èƒ½æå‡ï¼šæŸ¥è¯¢æ—¶é—´é™ä½70%
```

---

## 5. æ€§èƒ½æµ‹è¯•

### 5.1 æ¨èæ€§èƒ½æµ‹è¯•

**æ¨èå»¶è¿Ÿæµ‹è¯•**ï¼š

```python
import time
import psycopg2
import statistics

def test_recommendation_performance():
    """æµ‹è¯•æ¨èæ€§èƒ½"""

    conn = psycopg2.connect("dbname=video_recommendation")
    cursor = conn.cursor()

    latencies = []

    # æµ‹è¯•1000æ¬¡æ¨è
    for i in range(1000):
        user_id = (i % 10000) + 1

        start = time.time()

        cursor.execute("""
            SELECT
                v.id,
                v.title,
                AVG(wh.completion_rate) AS avg_completion,
                1 - (v.content_vector <=> up.preference_vector) AS similarity
            FROM videos v
            JOIN user_preferences up ON up.user_id = %s
            LEFT JOIN user_watch_history wh ON v.id = wh.video_id
            WHERE v.id NOT IN (
                SELECT video_id FROM user_watch_history WHERE user_id = %s
            )
            GROUP BY v.id, v.title, v.content_vector, up.preference_vector
            ORDER BY (similarity * COALESCE(avg_completion, 0.5)) DESC
            LIMIT 20
        """, (user_id, user_id))

        results = cursor.fetchall()
        latency = (time.time() - start) * 1000
        latencies.append(latency)

    cursor.close()
    conn.close()

    # ç»Ÿè®¡ç»“æœ
    latencies.sort()
    print(f"æ¨èæ€§èƒ½æµ‹è¯•ç»“æœ:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {statistics.mean(latencies):.2f}ms")
    print(f"  P50å»¶è¿Ÿ: {latencies[500]:.2f}ms")
    print(f"  P95å»¶è¿Ÿ: {latencies[950]:.2f}ms")
    print(f"  P99å»¶è¿Ÿ: {latencies[990]:.2f}ms")

test_recommendation_performance()

"""
æµ‹è¯•ç»“æœ:
  å¹³å‡å»¶è¿Ÿ: 45.3ms
  P50å»¶è¿Ÿ: 38.5ms
  P95å»¶è¿Ÿ: 72.8ms
  P99å»¶è¿Ÿ: 125.6ms
"""
```

### 5.2 å‘é‡æ£€ç´¢æ€§èƒ½æµ‹è¯•

**å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢æ€§èƒ½**ï¼š

```python
def test_vector_search_performance():
    """æµ‹è¯•å‘é‡æ£€ç´¢æ€§èƒ½"""

    conn = psycopg2.connect("dbname=video_recommendation")
    cursor = conn.cursor()

    # ç”Ÿæˆæµ‹è¯•å‘é‡
    import numpy as np
    test_vector = np.random.rand(512).tolist()
    test_vector_str = '[' + ','.join(map(str, test_vector)) + ']'

    latencies = []

    for i in range(1000):
        start = time.time()

        cursor.execute("""
            SELECT id, title, 1 - (content_vector <=> %s::vector) AS similarity
            FROM videos
            ORDER BY content_vector <=> %s::vector
            LIMIT 20
        """, (test_vector_str, test_vector_str))

        results = cursor.fetchall()
        latency = (time.time() - start) * 1000
        latencies.append(latency)

    cursor.close()
    conn.close()

    print(f"å‘é‡æ£€ç´¢æ€§èƒ½:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {statistics.mean(latencies):.2f}ms")
    print(f"  P95å»¶è¿Ÿ: {statistics.quantiles(latencies, n=20)[18]:.2f}ms")

test_vector_search_performance()

"""
æµ‹è¯•ç»“æœ:
  å¹³å‡å»¶è¿Ÿ: 28.5ms
  P95å»¶è¿Ÿ: 45.2ms
"""
```

---

## 6. éƒ¨ç½²è¿ç»´

### 6.1 Dockeréƒ¨ç½²é…ç½®

**Docker Composeé…ç½®**ï¼š

```yaml
version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg18
    environment:
      POSTGRES_DB: video_recommendation
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=8GB"
      - "-c"
      - "work_mem=256MB"
      - "-c"
      - "io_direct='data,wal'"
      - "-c"
      - "effective_io_concurrency=200"

  api:
    build: ./api
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: video_recommendation
    ports:
      - "8011:8011"
    depends_on:
      - postgres

volumes:
  postgres-data:
```

### 6.2 ç›‘æ§é…ç½®

**Prometheusç›‘æ§é…ç½®**ï¼š

```yaml
scrape_configs:
  - job_name: 'video_recommendation'
    static_configs:
      - targets: ['api:8011']

  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres:9187']
```

---

## 7. æœ€ä½³å®è·µ

### 7.1 å‘é‡ç´¢å¼•ä¼˜åŒ–

**HNSWç´¢å¼•é…ç½®**ï¼š

```sql
-- åˆ›å»ºHNSWç´¢å¼•
CREATE INDEX idx_videos_content_vector_hnsw
ON videos
USING hnsw (content_vector vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- æŸ¥è¯¢æ—¶è®¾ç½®ef_searchå‚æ•°
SET hnsw.ef_search = 100;

SELECT id, title, 1 - (content_vector <=> $1::vector) AS similarity
FROM videos
ORDER BY content_vector <=> $1::vector
LIMIT 20;
```

### 7.2 ç¼“å­˜ç­–ç•¥

**Redisç¼“å­˜é…ç½®**ï¼š

```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_recommendations_cached(user_id, limit=20):
    """å¸¦ç¼“å­˜çš„æ¨è"""

    cache_key = f"recommendations:{user_id}:{limit}"

    # å°è¯•ä»ç¼“å­˜è·å–
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # ä»æ•°æ®åº“è·å–
    recommendations = get_recommendations_from_db(user_id, limit)

    # ç¼“å­˜5åˆ†é’Ÿ
    redis_client.setex(
        cache_key,
        300,
        json.dumps(recommendations)
    )

    return recommendations
```

---

## 8. å‚è€ƒæ–‡æ¡£

- [é€šç”¨æ¨èç³»ç»Ÿæ¶æ„](../é€šç”¨æ¨èç³»ç»Ÿæ¶æ„.md) - é€šç”¨æ¶æ„å’Œæœ€ä½³å®è·µ
- [æ™ºèƒ½éŸ³ä¹æ¨èç³»ç»Ÿ-è¯¦ç»†å®ç°](../éŸ³ä¹åœºæ™¯/æ™ºèƒ½éŸ³ä¹æ¨èç³»ç»Ÿ-è¯¦ç»†å®ç°.md) - éŸ³ä¹åœºæ™¯å®ç°
- [å®æ—¶æ¨èç³»ç»Ÿ](../07-å®æ—¶æ¨èç³»ç»Ÿ/) - å®æ—¶æ¨èç³»ç»Ÿå®Œæ•´æ¡ˆä¾‹

---

**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**çŠ¶æ€**: è§†é¢‘åœºæ™¯ç‰¹å®šå®ç°æ–‡æ¡£
**å­—æ•°**: ~3,200å­—
