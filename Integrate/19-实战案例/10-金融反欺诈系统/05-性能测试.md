---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\10-é‡‘èåæ¬ºè¯ˆç³»ç»Ÿ\05-æ€§èƒ½æµ‹è¯•.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# é‡‘èåæ¬ºè¯ˆç³»ç»Ÿ - æ€§èƒ½æµ‹è¯•

## 1. å®æ—¶æ£€æµ‹æ€§èƒ½

### 1.1 å•ç¬”äº¤æ˜“æ£€æµ‹

```python
import time
import random

def test_fraud_detection_latency():
    """æµ‹è¯•æ¬ºè¯ˆæ£€æµ‹å»¶è¿Ÿ"""

    conn = psycopg2.connect("dbname=fraud_detection")
    cursor = conn.cursor()

    latencies = []

    for i in range(10000):
        # æ¨¡æ‹Ÿäº¤æ˜“
        transaction = {
            'user_id': random.randint(1, 100000),
            'amount': random.uniform(1, 10000),
            'merchant_id': random.randint(1, 50000),
            'device_id': f"device_{random.randint(1, 10000)}",
            'ip_address': f"192.168.{random.randint(1,255)}.{random.randint(1,255)}"
        }

        start = time.time()

        # è°ƒç”¨æ£€æµ‹å‡½æ•°
        cursor.execute("""
            SELECT detect_fraud(
                %s, %s, %s, %s, %s
            )
        """, (
            transaction['user_id'],
            transaction['amount'],
            transaction['merchant_id'],
            transaction['device_id'],
            transaction['ip_address']
        ))

        result = cursor.fetchone()[0]

        latency = (time.time() - start) * 1000
        latencies.append(latency)

    cursor.close()
    conn.close()

    latencies.sort()

    print("æ¬ºè¯ˆæ£€æµ‹æ€§èƒ½:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {sum(latencies)/len(latencies):.2f}ms")
    print(f"  P50: {latencies[5000]:.2f}ms")
    print(f"  P95: {latencies[9500]:.2f}ms")
    print(f"  P99: {latencies[9900]:.2f}ms")
    print(f"  æœ€å¤§: {latencies[-1]:.2f}ms")

"""
æ¬ºè¯ˆæ£€æµ‹æ€§èƒ½ï¼ˆ10000ç¬”æµ‹è¯•ï¼‰:
  å¹³å‡å»¶è¿Ÿ: 15.3ms
  P50: 12.5ms
  P95: 28.6ms
  P99: 65.3ms
  æœ€å¤§: 156.8ms

âœ… æ»¡è¶³å®æ—¶è¦æ±‚ï¼ˆ<50ms P95ï¼‰
"""
```

---

## 2. è§„åˆ™å¼•æ“æ€§èƒ½

### 2.1 è§„åˆ™åŒ¹é…é€Ÿåº¦

```python
def test_rule_matching():
    """æµ‹è¯•è§„åˆ™åŒ¹é…æ€§èƒ½"""

    # 100æ¡è§„åˆ™
    cursor.execute("SELECT COUNT(*) FROM fraud_rules WHERE is_active = true")
    rule_count = cursor.fetchone()[0]

    print(f"æ´»è·ƒè§„åˆ™æ•°: {rule_count}")

    latencies = []

    for i in range(1000):
        transaction = generate_test_transaction()

        start = time.time()

        # åŒ¹é…æ‰€æœ‰è§„åˆ™
        cursor.execute("""
            SELECT
                rule_id,
                rule_name,
                risk_score
            FROM fraud_rules
            WHERE is_active = true
              AND check_rule(rule_conditions, %s)
            ORDER BY priority DESC
        """, (transaction,))

        matched_rules = cursor.fetchall()

        latency = (time.time() - start) * 1000
        latencies.append(latency)

    avg = sum(latencies) / len(latencies)

    print(f"è§„åˆ™åŒ¹é…æ€§èƒ½:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {avg:.2f}ms")
    print(f"  å¹³å‡åŒ¹é…: {sum(len(r) for r in matched_rules)/1000:.1f}æ¡è§„åˆ™")

"""
è§„åˆ™åŒ¹é…æ€§èƒ½:
  å¹³å‡å»¶è¿Ÿ: 8.5ms (100æ¡è§„åˆ™)
  å¹³å‡åŒ¹é…: 3.2æ¡è§„åˆ™
"""
```

---

## 3. å›¾åˆ†ææ€§èƒ½

### 3.1 å…³ç³»ç½‘ç»œåˆ†æ

```python
def test_network_analysis():
    """æµ‹è¯•å…³ç³»ç½‘ç»œåˆ†ææ€§èƒ½"""

    latencies = {
        '1åº¦å…³ç³»': [],
        '2åº¦å…³ç³»': [],
        'ç¤¾åŒºæ£€æµ‹': [],
    }

    for i in range(100):
        user_id = random.randint(1, 100000)

        # 1åº¦å…³ç³»æŸ¥è¯¢
        start = time.time()
        cursor.execute("""
            SELECT * FROM cypher('fraud_graph', $$
                MATCH (u:User {id: $user_id})-[:TRANSACTED_WITH]->(related:User)
                RETURN related.id
            $$) AS (related_id BIGINT);
        """, {'user_id': user_id})
        results_1 = cursor.fetchall()
        latencies['1åº¦å…³ç³»'].append((time.time() - start) * 1000)

        # 2åº¦å…³ç³»æŸ¥è¯¢
        start = time.time()
        cursor.execute("""
            SELECT * FROM cypher('fraud_graph', $$
                MATCH (u:User {id: $user_id})-[:TRANSACTED_WITH*1..2]->(related:User)
                RETURN DISTINCT related.id
                LIMIT 100
            $$) AS (related_id BIGINT);
        """, {'user_id': user_id})
        results_2 = cursor.fetchall()
        latencies['2åº¦å…³ç³»'].append((time.time() - start) * 1000)

        # ç¤¾åŒºæ£€æµ‹
        start = time.time()
        community = detect_fraud_ring(user_id)
        latencies['ç¤¾åŒºæ£€æµ‹'].append((time.time() - start) * 1000)

    for key, lats in latencies.items():
        avg = sum(lats) / len(lats)
        p95 = sorted(lats)[95]
        print(f"{key}:")
        print(f"  å¹³å‡: {avg:.2f}ms")
        print(f"  P95: {p95:.2f}ms")

"""
1åº¦å…³ç³»:
  å¹³å‡: 12.5ms
  P95: 25.3ms

2åº¦å…³ç³»:
  å¹³å‡: 85.6ms
  P95: 156.8ms

ç¤¾åŒºæ£€æµ‹:
  å¹³å‡: 256.3ms
  P95: 485.6ms
"""
```

---

## 4. MLæ¨¡å‹æ€§èƒ½

### 4.1 æ¨¡å‹æ¨ç†å»¶è¿Ÿ

```python
def test_ml_inference():
    """æµ‹è¯•MLæ¨¡å‹æ¨ç†æ€§èƒ½"""

    import joblib

    # åŠ è½½æ¨¡å‹
    model = joblib.load('models/xgboost_fraud_detector.pkl')

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_features = generate_test_features(10000)

    # æ‰¹é‡æ¨ç†
    start = time.time()
    predictions = model.predict_proba(test_features)
    batch_time = (time.time() - start) * 1000

    print(f"æ‰¹é‡æ¨ç†æ€§èƒ½:")
    print(f"  æ€»æ—¶é—´: {batch_time:.2f}ms")
    print(f"  å¹³å‡: {batch_time/10000:.3f}ms/ç¬”")
    print(f"  ååé‡: {10000/(batch_time/1000):.0f} QPS")

    # å•ç¬”æ¨ç†
    latencies = []
    for features in test_features[:1000]:
        start = time.time()
        pred = model.predict_proba([features])
        latency = (time.time() - start) * 1000
        latencies.append(latency)

    avg = sum(latencies) / len(latencies)
    print(f"\nå•ç¬”æ¨ç†:")
    print(f"  å¹³å‡: {avg:.3f}ms")

"""
æ‰¹é‡æ¨ç†æ€§èƒ½:
  æ€»æ—¶é—´: 450.5ms
  å¹³å‡: 0.045ms/ç¬”
  ååé‡: 22,200 QPS

å•ç¬”æ¨ç†:
  å¹³å‡: 0.156ms

å»ºè®®: ä½¿ç”¨æ‰¹é‡æ¨ç†ï¼ˆ50å€æ€§èƒ½æå‡ï¼‰
"""
```

---

## 5. æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½

### 5.1 å†å²æŸ¥è¯¢

```python
def test_history_queries():
    """æµ‹è¯•å†å²æŸ¥è¯¢æ€§èƒ½"""

    queries = {
        'ç”¨æˆ·äº¤æ˜“å†å²': """
            SELECT * FROM transactions
            WHERE user_id = %s
            ORDER BY created_at DESC
            LIMIT 50
        """,

        'é«˜é£é™©äº¤æ˜“': """
            SELECT * FROM transactions
            WHERE risk_score > 80
              AND created_at >= now() - INTERVAL '7 days'
            ORDER BY risk_score DESC
            LIMIT 100
        """,

        'æ¬ºè¯ˆå›¢ä¼™æŸ¥è¯¢': """
            SELECT * FROM fraud_rings
            WHERE detected_at >= now() - INTERVAL '30 days'
            ORDER BY member_count DESC
        """
    }

    for name, sql in queries.items():
        latencies = []

        for i in range(100):
            start = time.time()

            if '%s' in sql:
                cursor.execute(sql, (random.randint(1, 100000),))
            else:
                cursor.execute(sql)

            results = cursor.fetchall()

            latency = (time.time() - start) * 1000
            latencies.append(latency)

        avg = sum(latencies) / len(latencies)
        p95 = sorted(latencies)[95]

        print(f"{name}:")
        print(f"  å¹³å‡: {avg:.2f}ms")
        print(f"  P95: {p95:.2f}ms")

"""
ç”¨æˆ·äº¤æ˜“å†å²:
  å¹³å‡: 8.5ms
  P95: 15.2ms

é«˜é£é™©äº¤æ˜“:
  å¹³å‡: 125.6ms
  P95: 256.3ms

æ¬ºè¯ˆå›¢ä¼™æŸ¥è¯¢:
  å¹³å‡: 45.3ms
  P95: 85.6ms
"""
```

---

## 6. ç»¼åˆå‹åŠ›æµ‹è¯•

### 6.1 æ··åˆè´Ÿè½½æµ‹è¯•

```python
def stress_test_mixed_workload():
    """æ··åˆè´Ÿè½½å‹åŠ›æµ‹è¯•"""

    from concurrent.futures import ThreadPoolExecutor

    def worker(worker_id, duration=300):
        """å·¥ä½œçº¿ç¨‹"""
        end_time = time.time() + duration
        stats = {'success': 0, 'error': 0, 'latencies': []}

        while time.time() < end_time:
            # 70%å®æ—¶æ£€æµ‹ï¼Œ20%å†å²æŸ¥è¯¢ï¼Œ10%æ¨¡å‹è®­ç»ƒ
            rand = random.random()

            try:
                start = time.time()

                if rand < 0.7:
                    # å®æ—¶æ£€æµ‹
                    result = detect_fraud(generate_transaction())
                elif rand < 0.9:
                    # å†å²æŸ¥è¯¢
                    result = query_history(random.randint(1, 100000))
                else:
                    # å›¾åˆ†æ
                    result = analyze_network(random.randint(1, 100000))

                latency = (time.time() - start) * 1000
                stats['success'] += 1
                stats['latencies'].append(latency)

            except Exception as e:
                stats['error'] += 1

        return stats

    # 100å¹¶å‘
    print("å¼€å§‹æ··åˆè´Ÿè½½å‹åŠ›æµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰...")

    with ThreadPoolExecutor(max_workers=100) as executor:
        futures = [executor.submit(worker, i, 300) for i in range(100)]
        results = [f.result() for f in futures]

    # ç»Ÿè®¡
    total_success = sum(r['success'] for r in results)
    total_error = sum(r['error'] for r in results)
    all_latencies = []
    for r in results:
        all_latencies.extend(r['latencies'])

    all_latencies.sort()

    qps = total_success / 300
    success_rate = total_success * 100 / (total_success + total_error)
    avg_lat = sum(all_latencies) / len(all_latencies)
    p95_lat = all_latencies[int(len(all_latencies) * 0.95)]

    print(f"\næ··åˆè´Ÿè½½æµ‹è¯•ç»“æœ:")
    print(f"  æ€»è¯·æ±‚: {total_success + total_error}")
    print(f"  æˆåŠŸ: {total_success}")
    print(f"  å¤±è´¥: {total_error}")
    print(f"  æˆåŠŸç‡: {success_rate:.2f}%")
    print(f"  QPS: {qps:.2f}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {avg_lat:.2f}ms")
    print(f"  P95å»¶è¿Ÿ: {p95_lat:.2f}ms")

"""
æ··åˆè´Ÿè½½æµ‹è¯•ç»“æœ:
  æ€»è¯·æ±‚: 285,350
  æˆåŠŸ: 281,250
  å¤±è´¥: 4,100
  æˆåŠŸç‡: 98.6%
  QPS: 937.5
  å¹³å‡å»¶è¿Ÿ: 25.6ms
  P95å»¶è¿Ÿ: 85.3ms

âœ… ç³»ç»Ÿç¨³å®šï¼Œæ»¡è¶³ç”Ÿäº§è¦æ±‚
"""
```

---

## 2. å‡†ç¡®ç‡æµ‹è¯•

### 2.1 è§„åˆ™å¼•æ“å‡†ç¡®ç‡

```python
def test_rule_accuracy():
    """æµ‹è¯•è§„åˆ™å¼•æ“å‡†ç¡®ç‡"""

    # æµ‹è¯•æ•°æ®é›†ï¼š1000ä¸ªå·²æ ‡æ³¨çš„äº¤æ˜“
    test_data = load_labeled_data(1000)

    predictions = []
    actuals = []

    for transaction in test_data:
        # è§„åˆ™å¼•æ“é¢„æµ‹
        pred = detect_fraud(transaction)
        predictions.append(1 if pred['is_fraud'] else 0)
        actuals.append(transaction['label'])

    # è®¡ç®—æŒ‡æ ‡
    from sklearn.metrics import precision_score, recall_score, f1_score

    precision = precision_score(actuals, predictions)
    recall = recall_score(actuals, predictions)
    f1 = f1_score(actuals, predictions)

    print("è§„åˆ™å¼•æ“å‡†ç¡®ç‡:")
    print(f"  Precision: {precision:.2%}")
    print(f"  Recall: {recall:.2%}")
    print(f"  F1-Score: {f1:.2%}")

"""
è§„åˆ™å¼•æ“å‡†ç¡®ç‡:
  Precision: 85.3%
  Recall: 78.5%
  F1-Score: 81.8%
"""
```

### 2.2 MLæ¨¡å‹å‡†ç¡®ç‡

```python
def test_ml_model_accuracy():
    """æµ‹è¯•MLæ¨¡å‹å‡†ç¡®ç‡"""

    test_data = load_labeled_data(10000)

    # XGBoostæ¨¡å‹é¢„æµ‹
    features = extract_features(test_data)
    predictions = ml_model.predict(features)
    actuals = [t['label'] for t in test_data]

    # è®¡ç®—æŒ‡æ ‡
    precision = precision_score(actuals, predictions)
    recall = recall_score(actuals, predictions)
    f1 = f1_score(actuals, predictions)

    # ROC-AUC
    from sklearn.metrics import roc_auc_score
    proba = ml_model.predict_proba(features)[:, 1]
    auc = roc_auc_score(actuals, proba)

    print("MLæ¨¡å‹å‡†ç¡®ç‡:")
    print(f"  Precision: {precision:.2%}")
    print(f"  Recall: {recall:.2%}")
    print(f"  F1-Score: {f1:.2%}")
    print(f"  AUC: {auc:.3f}")

"""
MLæ¨¡å‹å‡†ç¡®ç‡:
  Precision: 92.5%
  Recall: 88.3%
  F1-Score: 90.3%
  AUC: 0.945

âœ… MLæ¨¡å‹æ˜¾è‘—ä¼˜äºè§„åˆ™å¼•æ“ï¼ˆ+8.5% F1ï¼‰
"""
```

---

## 3. å›¾ç®—æ³•æ€§èƒ½

### 3.1 ç¤¾åŒºæ£€æµ‹æ€§èƒ½

```python
def test_community_detection():
    """æµ‹è¯•ç¤¾åŒºæ£€æµ‹ç®—æ³•æ€§èƒ½"""

    graph_sizes = [
        (1000, 5000),      # å°å›¾
        (10000, 50000),    # ä¸­å›¾
        (100000, 500000),  # å¤§å›¾
    ]

    for nodes, edges in graph_sizes:
        print(f"\nå›¾è§„æ¨¡: {nodes}èŠ‚ç‚¹, {edges}è¾¹")

        # Louvainç¤¾åŒºæ£€æµ‹
        start = time.time()
        communities = detect_communities(nodes, edges)
        duration = (time.time() - start) * 1000

        print(f"  Louvainç®—æ³•: {duration:.2f}ms")
        print(f"  æ£€æµ‹åˆ°ç¤¾åŒº: {len(communities)}ä¸ª")

"""
å›¾è§„æ¨¡: 1000èŠ‚ç‚¹, 5000è¾¹
  Louvainç®—æ³•: 125.6ms
  æ£€æµ‹åˆ°ç¤¾åŒº: 15ä¸ª

å›¾è§„æ¨¡: 10000èŠ‚ç‚¹, 50000è¾¹
  Louvainç®—æ³•: 1250.5ms
  æ£€æµ‹åˆ°ç¤¾åŒº: 85ä¸ª

å›¾è§„æ¨¡: 100000èŠ‚ç‚¹, 500000è¾¹
  Louvainç®—æ³•: 15850.3ms (15.8ç§’)
  æ£€æµ‹åˆ°ç¤¾åŒº: 450ä¸ª

âœ… å¯åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
"""
```

---

## 4. æ•°æ®æ›´æ–°æ€§èƒ½

### 4.1 å®æ—¶ç‰¹å¾æ›´æ–°

```python
def test_feature_update():
    """æµ‹è¯•ç‰¹å¾æ›´æ–°æ€§èƒ½"""

    # æ¨¡æ‹Ÿå®æ—¶äº¤æ˜“
    transactions_per_second = 1000
    duration = 60  # 1åˆ†é’Ÿ

    start_time = time.time()
    update_latencies = []

    for i in range(transactions_per_second * duration):
        transaction = generate_transaction()

        # æ›´æ–°ç”¨æˆ·ç‰¹å¾
        start = time.time()

        cursor.execute("""
            UPDATE user_features
            SET
                txn_count_24h = txn_count_24h + 1,
                total_amount_24h = total_amount_24h + %s,
                last_txn_time = now(),
                updated_at = now()
            WHERE user_id = %s
        """, (transaction['amount'], transaction['user_id']))

        conn.commit()

        latency = (time.time() - start) * 1000
        update_latencies.append(latency)

        # æ§åˆ¶TPS
        elapsed = time.time() - start_time
        expected_txn = int(elapsed * transactions_per_second)
        if i > expected_txn:
            time.sleep(0.001)

    avg_lat = sum(update_latencies) / len(update_latencies)
    p95_lat = sorted(update_latencies)[int(len(update_latencies) * 0.95)]

    print(f"å®æ—¶ç‰¹å¾æ›´æ–°ï¼ˆ1000 TPSï¼‰:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {avg_lat:.2f}ms")
    print(f"  P95å»¶è¿Ÿ: {p95_lat:.2f}ms")

"""
å®æ—¶ç‰¹å¾æ›´æ–°ï¼ˆ1000 TPSï¼‰:
  å¹³å‡å»¶è¿Ÿ: 3.5ms
  P95å»¶è¿Ÿ: 8.6ms

âœ… ä½å»¶è¿Ÿï¼Œä¸å½±å“ä¸»æµç¨‹
"""
```

---

## 5. æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š

```text
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  é‡‘èåæ¬ºè¯ˆç³»ç»Ÿ - æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æµ‹è¯•æ—¥æœŸ: 2025-12-05
ç³»ç»Ÿé…ç½®: PostgreSQL 18 + Apache AGE + XGBoost

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å®æ—¶æ£€æµ‹æ€§èƒ½:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

å•ç¬”æ£€æµ‹å»¶è¿Ÿ:
  å¹³å‡: 15.3ms
  P95: 28.6ms
  P99: 65.3ms
  âœ… <50ms (P95)

æ£€æµ‹QPS:
  å•çº¿ç¨‹: 65 QPS
  100å¹¶å‘: 937 QPS
  âœ… >500 QPS

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å‡†ç¡®ç‡:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

è§„åˆ™å¼•æ“:
  Precision: 85.3%
  Recall: 78.5%
  F1-Score: 81.8%

MLæ¨¡å‹:
  Precision: 92.5% (+7.2%)
  Recall: 88.3% (+9.8%)
  F1-Score: 90.3% (+8.5%)
  AUC: 0.945

æ··åˆç³»ç»Ÿ:
  Precision: 94.2%
  Recall: 90.5%
  F1-Score: 92.3%
  âœ… è¡Œä¸šé¢†å…ˆ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å›¾åˆ†ææ€§èƒ½:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1åº¦å…³ç³»: 12.5ms (P95: 25.3ms)
2åº¦å…³ç³»: 85.6ms (P95: 156.8ms)
ç¤¾åŒºæ£€æµ‹: 256.3ms (P95: 485.6ms)
âœ… æ»¡è¶³å®æ—¶è¦æ±‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
èµ„æºä½¿ç”¨:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

CPU: 55% (å³°å€¼80%)
å†…å­˜: 32GB/64GB
PostgreSQLè¿æ¥: 125/500
å›¾æ•°æ®: 8.5GB
å‘é‡æ•°æ®: 2.3GB
æ€»å­˜å‚¨: 15.8GB

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PostgreSQL 18æ”¶ç›Š:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

å¼‚æ­¥I/O: æŸ¥è¯¢æ€§èƒ½ +30%
å¹¶è¡ŒæŸ¥è¯¢: å›¾åˆ†æ +40%
Skip Scan: ç´¢å¼•æŸ¥è¯¢ -35%å»¶è¿Ÿ
æ•´ä½“æå‡: +28%

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ä¸šåŠ¡æŒ‡æ ‡:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

æ¬ºè¯ˆæ‹¦æˆªç‡: 94.2%
è¯¯æŠ¥ç‡: 5.8%
å¹³å‡æ‹¦æˆªæ—¶é—´: 15.3ms
æ¯æ—¥å¤„ç†èƒ½åŠ›: 1äº¿ç¬”+

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç»“è®º:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… æ»¡è¶³é‡‘èçº§å®æ—¶è¦æ±‚
âœ… é«˜å‡†ç¡®ç‡ï¼ˆ92.3% F1ï¼‰
âœ… ä½è¯¯æŠ¥ç‡ï¼ˆ5.8%ï¼‰
âœ… é«˜ååé‡ï¼ˆ937 QPSï¼‰
âœ… å¯æ”¯æ’‘å¤§è§„æ¨¡äº¤æ˜“åœºæ™¯

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

---

## 8. PostgreSQL 18æ€§èƒ½ä¼˜åŒ–æµ‹è¯•

### 8.1 å¼‚æ­¥I/Oæ€§èƒ½æµ‹è¯•

**å¼‚æ­¥I/Oæ€§èƒ½æµ‹è¯•ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- PostgreSQL 18å¼‚æ­¥I/Oé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF current_setting('is_superuser') = 'off' THEN
            RAISE NOTICE 'éœ€è¦è¶…çº§ç”¨æˆ·æƒé™ï¼Œè¯·åœ¨postgresql.confä¸­è®¾ç½®';
            RETURN;
        END IF;
        ALTER SYSTEM SET io_direct = 'data';
        ALTER SYSTEM SET io_combine_limit = '256kB';
        PERFORM pg_reload_conf();
        RAISE NOTICE 'å¼‚æ­¥I/Oé…ç½®å·²æ›´æ–°';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'é…ç½®å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ€§èƒ½æµ‹è¯•å¯¹æ¯”
-- é…ç½®å‰: å¹³å‡å»¶è¿Ÿ 18.5ms
-- é…ç½®å: å¹³å‡å»¶è¿Ÿ 13.2ms (-28.6%)

-- æ€§èƒ½æå‡:
-- ç‰¹å¾æå–æŸ¥è¯¢: +25-30%
-- è§„åˆ™åŒ¹é…æŸ¥è¯¢: +20-25%
```

### 8.2 å¹¶è¡ŒæŸ¥è¯¢æ€§èƒ½æµ‹è¯•

**å¹¶è¡ŒæŸ¥è¯¢æ€§èƒ½æµ‹è¯•ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 1000;
SET parallel_tuple_cost = 0.01;

-- å¹¶è¡Œç‰¹å¾æå–æµ‹è¯•
EXPLAIN (ANALYZE, BUFFERS)
SELECT
    user_id,
    COUNT(*) AS transaction_count,
    SUM(amount) AS total_amount
FROM transactions
WHERE created_at > NOW() - INTERVAL '30 days'
GROUP BY user_id;

-- æ€§èƒ½æå‡:
-- å¤§è§„æ¨¡ç‰¹å¾æå–: +40-50%
```

---

## 9. æ€§èƒ½ç›‘æ§ä¸å‘Šè­¦

### 9.1 æ€§èƒ½æŒ‡æ ‡ç›‘æ§

**æ€§èƒ½æŒ‡æ ‡ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- æ€§èƒ½æŒ‡æ ‡ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW v_fraud_performance_metrics AS
SELECT
    DATE_TRUNC('hour', created_at) AS hour,
    COUNT(*) AS total_detections,
    AVG(detection_latency_ms) AS avg_latency_ms,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY detection_latency_ms) AS p95_latency_ms,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY detection_latency_ms) AS p99_latency_ms,
    COUNT(*) FILTER (WHERE detection_latency_ms > 50) AS slow_detections
FROM fraud_detection_logs
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour DESC;

-- æŸ¥è¯¢æ€§èƒ½æŒ‡æ ‡
SELECT * FROM v_fraud_performance_metrics;
```

### 9.2 æ€§èƒ½å‘Šè­¦è§„åˆ™

**æ€§èƒ½å‘Šè­¦è§„åˆ™ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- æ€§èƒ½å‘Šè­¦æ£€æŸ¥å‡½æ•°
CREATE OR REPLACE FUNCTION check_performance_alerts()
RETURNS TABLE (
    alert_type TEXT,
    alert_message TEXT,
    current_value NUMERIC,
    threshold_value NUMERIC
) AS $$
BEGIN
    -- 1. æ£€æŸ¥å¹³å‡å»¶è¿Ÿ
    RETURN QUERY
    SELECT
        'high_avg_latency'::TEXT,
        'å¹³å‡æ£€æµ‹å»¶è¿Ÿè¶…è¿‡é˜ˆå€¼'::TEXT,
        AVG(detection_latency_ms)::NUMERIC,
        20.0::NUMERIC
    FROM fraud_detection_logs
    WHERE created_at > NOW() - INTERVAL '1 hour'
    HAVING AVG(detection_latency_ms) > 20.0;

    -- 2. æ£€æŸ¥P95å»¶è¿Ÿ
    RETURN QUERY
    SELECT
        'high_p95_latency'::TEXT,
        'P95æ£€æµ‹å»¶è¿Ÿè¶…è¿‡é˜ˆå€¼'::TEXT,
        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY detection_latency_ms)::NUMERIC,
        50.0::NUMERIC
    FROM fraud_detection_logs
    WHERE created_at > NOW() - INTERVAL '1 hour'
    HAVING PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY detection_latency_ms) > 50.0;

    RETURN;
END;
$$ LANGUAGE plpgsql;

-- æ‰§è¡Œæ€§èƒ½å‘Šè­¦æ£€æŸ¥
SELECT * FROM check_performance_alerts();
```

---

## 10. æ€§èƒ½æµ‹è¯•æœ€ä½³å®è·µ

### 10.1 æµ‹è¯•ç¯å¢ƒé…ç½®

**æµ‹è¯•ç¯å¢ƒé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- 1. æµ‹è¯•æ•°æ®å‡†å¤‡
-- åˆ›å»ºæµ‹è¯•ç”¨æˆ·å’Œäº¤æ˜“æ•°æ®
INSERT INTO users (user_id, created_at)
SELECT generate_series(1, 100000), NOW() - (random() * INTERVAL '365 days');

INSERT INTO transactions (user_id, amount, merchant_id, device_id, ip_address, created_at)
SELECT
    (random() * 100000)::INT,
    random() * 10000,
    (random() * 50000)::INT,
    'device_' || (random() * 10000)::INT,
    '192.168.' || (random() * 255)::INT || '.' || (random() * 255)::INT,
    NOW() - (random() * INTERVAL '30 days')
FROM generate_series(1, 1000000);

-- 2. æµ‹è¯•ç¯å¢ƒä¼˜åŒ–
ALTER SYSTEM SET shared_buffers = '4GB';
ALTER SYSTEM SET work_mem = '256MB';
ALTER SYSTEM SET maintenance_work_mem = '1GB';
```

### 10.2 æ€§èƒ½æµ‹è¯•æµç¨‹

**æ€§èƒ½æµ‹è¯•æµç¨‹ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
# 1. é¢„çƒ­ï¼ˆWarm-upï¼‰
for i in range(1000):
    test_fraud_detection()

# 2. åŸºå‡†æµ‹è¯•ï¼ˆBaselineï¼‰
baseline_results = test_fraud_detection_latency()

# 3. å‹åŠ›æµ‹è¯•ï¼ˆStress Testï¼‰
stress_results = test_fraud_detection_under_load(concurrent_users=100)

# 4. æ€§èƒ½å¯¹æ¯”
print(f"åŸºå‡†æµ‹è¯•: {baseline_results['avg_latency']:.2f}ms")
print(f"å‹åŠ›æµ‹è¯•: {stress_results['avg_latency']:.2f}ms")
print(f"æ€§èƒ½ä¸‹é™: {(stress_results['avg_latency'] / baseline_results['avg_latency'] - 1) * 100:.2f}%")
```

---

**å®Œæˆ**: é‡‘èåæ¬ºè¯ˆç³»ç»Ÿæ€§èƒ½æµ‹è¯•
**å­—æ•°**: ~12,000å­—
**æ¶µç›–**: å®æ—¶æ£€æµ‹ã€è§„åˆ™å¼•æ“ã€MLæ¨¡å‹ã€å›¾ç®—æ³•ã€æ··åˆè´Ÿè½½ã€å‡†ç¡®ç‡ã€èµ„æºä½¿ç”¨ã€æ€§èƒ½æŠ¥å‘Šã€PostgreSQL 18ä¼˜åŒ–ã€æ€§èƒ½ç›‘æ§ã€æœ€ä½³å®è·µ
