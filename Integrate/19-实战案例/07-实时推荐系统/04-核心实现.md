---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\07-å®æ—¶æ¨èç³»ç»Ÿ\04-æ ¸å¿ƒå®ç°.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# æ¡ˆä¾‹7ï¼šå®æ—¶æ¨èç³»ç»Ÿ - æ ¸å¿ƒå®ç°

```python
"""
å®æ—¶æ¨èç³»ç»Ÿ
æŠ€æœ¯æ ˆ: PostgreSQL 18 + pgvector + FastAPI
"""

import psycopg2
from psycopg2.extras import RealDictCursor
import numpy as np
from fastapi import FastAPI, Query
from typing import List
import redis
import json
import time

app = FastAPI()

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'dbname': 'recommendation_db',
    'user': 'postgres',
    'host': 'localhost'
}

# Redisé…ç½®
redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

def get_db():
    return psycopg2.connect(**DB_CONFIG, cursor_factory=RealDictCursor)

# ============================================================
# æ¨èAPI
# ============================================================

@app.get("/api/recommend/{user_id}")
async def get_recommendations(
    user_id: int,
    limit: int = Query(50, le=100),
    use_cache: bool = True
):
    """
    è·å–ç”¨æˆ·æ¨è

    æµç¨‹:
    1. æ£€æŸ¥ç¼“å­˜
    2. å¤šè·¯å¬å› (User CF + Item CF + Vector + Popular)
    3. æ’åºæ‰“åˆ†
    4. è¿”å›Top-N
    """

    start_time = time.time()

    # 1. æ£€æŸ¥ç¼“å­˜
    if use_cache:
        cache_key = f"recommend:{user_id}"
        cached = redis_client.get(cache_key)
        if cached:
            result = json.loads(cached)
            result['from_cache'] = True
            result['latency_ms'] = (time.time() - start_time) * 1000
            return result

    # 2. æ•°æ®åº“å¬å›
    conn = get_db()
    cursor = conn.cursor()

    try:
        cursor.execute("""
            SELECT item_id, final_score
            FROM recommend_items(%s, %s);
        """, (user_id, limit))

        recommendations = cursor.fetchall()

        # 3. è¡¥å……å•†å“ä¿¡æ¯
        item_ids = [r['item_id'] for r in recommendations]

        cursor.execute("""
            SELECT item_id, title, price, rating, sales_count
            FROM items
            WHERE item_id = ANY(%s);
        """, (item_ids,))

        items_info = {item['item_id']: item for item in cursor.fetchall()}

        # 4. åˆå¹¶ç»“æœ
        result = []
        for rec in recommendations:
            item = items_info.get(rec['item_id'])
            if item:
                result.append({
                    'item_id': rec['item_id'],
                    'title': item['title'],
                    'price': float(item['price']),
                    'rating': float(item['rating']),
                    'sales': item['sales_count'],
                    'score': float(rec['final_score'])
                })

        response = {
            'user_id': user_id,
            'recommendations': result,
            'count': len(result),
            'from_cache': False,
            'latency_ms': (time.time() - start_time) * 1000
        }

        # 5. å†™å…¥ç¼“å­˜ï¼ˆ5åˆ†é’Ÿï¼‰
        if use_cache:
            redis_client.setex(
                f"recommend:{user_id}",
                300,
                json.dumps(response)
            )

        return response

    finally:
        cursor.close()
        conn.close()

# ============================================================
# è¡Œä¸ºè®°å½•API
# ============================================================

@app.post("/api/behavior")
async def record_behavior(
    user_id: int,
    item_id: int,
    behavior_type: str  # view/click/cart/buy
):
    """
    è®°å½•ç”¨æˆ·è¡Œä¸º
    å¼‚æ­¥å†™å…¥ï¼Œç«‹å³è¿”å›
    """

    conn = get_db()
    cursor = conn.cursor()

    try:
        cursor.execute("""
            INSERT INTO user_behavior (user_id, item_id, behavior_type)
            VALUES (%s, %s, %s);
        """, (user_id, item_id, behavior_type))

        conn.commit()

        # æ¸…é™¤ç”¨æˆ·æ¨èç¼“å­˜
        redis_client.delete(f"recommend:{user_id}")

        # å¼‚æ­¥æ›´æ–°ç”¨æˆ·ç”»åƒï¼ˆå®é™…åº”è¯¥ç”¨æ¶ˆæ¯é˜Ÿåˆ—ï¼‰
        if behavior_type == 'buy':
            update_user_profile_async(user_id, item_id)

        return {'success': True}

    finally:
        cursor.close()
        conn.close()

# ============================================================
# ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆç¦»çº¿ä»»åŠ¡ï¼‰
# ============================================================

class SimilarityCalculator:
    """ç›¸ä¼¼åº¦è®¡ç®—å™¨"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def calculate_item_similarity(self, min_common_users=5):
        """
        è®¡ç®—å•†å“ç›¸ä¼¼åº¦ï¼ˆItem-Based CFï¼‰
        åŸºäºå…±åŒè´­ä¹°ç”¨æˆ·çš„Jaccardç›¸ä¼¼åº¦
        """

        print("å¼€å§‹è®¡ç®—å•†å“ç›¸ä¼¼åº¦...")

        # 1. è·å–çƒ­é—¨å•†å“ï¼ˆè®¡ç®—é‡å¤§ï¼Œåªç®—Topå•†å“ï¼‰
        self.cursor.execute("""
            SELECT item_id FROM items
            WHERE sales_count > 10
            ORDER BY sales_count DESC
            LIMIT 10000;
        """)

        popular_items = [row[0] for row in self.cursor.fetchall()]

        # 2. æ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦
        batch_size = 100
        for i in range(0, len(popular_items), batch_size):
            batch = popular_items[i:i+batch_size]

            self.cursor.execute("""
                WITH item_users AS (
                    SELECT item_id, array_agg(DISTINCT user_id) AS users
                    FROM user_behavior
                    WHERE item_id = ANY(%s)
                      AND behavior_type IN ('buy', 'cart')
                      AND timestamp > CURRENT_TIMESTAMP - INTERVAL '90 days'
                    GROUP BY item_id
                ),
                pairs AS (
                    SELECT
                        a.item_id AS item_a,
                        b.item_id AS item_b,
                        a.users AS users_a,
                        b.users AS users_b
                    FROM item_users a
                    CROSS JOIN item_users b
                    WHERE a.item_id < b.item_id
                ),
                similarities AS (
                    SELECT
                        item_a,
                        item_b,
                        cardinality(users_a & users_b)::NUMERIC /
                        NULLIF(cardinality(users_a | users_b), 0) AS jaccard_sim
                    FROM pairs
                    WHERE cardinality(users_a & users_b) >= %s
                )
                INSERT INTO item_similarity (item_id, similar_item_id, similarity_score)
                SELECT item_a, item_b, jaccard_sim FROM similarities
                UNION ALL
                SELECT item_b, item_a, jaccard_sim FROM similarities
                ON CONFLICT (item_id, similar_item_id) DO UPDATE
                SET similarity_score = EXCLUDED.similarity_score;
            """, (batch, min_common_users))

            self.conn.commit()
            print(f"å·²å¤„ç† {i+len(batch)}/{len(popular_items)} ä¸ªå•†å“")

        print("âœ… å•†å“ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ")

    def calculate_user_similarity(self):
        """
        è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦ï¼ˆUser-Based CFï¼‰
        åŸºäºä½™å¼¦ç›¸ä¼¼åº¦
        """

        print("å¼€å§‹è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦...")

        # æ´»è·ƒç”¨æˆ·ï¼ˆæœ€è¿‘30å¤©æœ‰è¡Œä¸ºï¼‰
        self.cursor.execute("""
            WITH active_users AS (
                SELECT DISTINCT user_id
                FROM user_behavior
                WHERE timestamp > CURRENT_TIMESTAMP - INTERVAL '30 days'
                LIMIT 50000
            ),
            user_vectors AS (
                SELECT
                    ub.user_id,
                    array_agg(ub.item_id) AS items
                FROM user_behavior ub
                JOIN active_users au ON ub.user_id = au.user_id
                WHERE ub.behavior_type IN ('buy', 'cart')
                  AND ub.timestamp > CURRENT_TIMESTAMP - INTERVAL '90 days'
                GROUP BY ub.user_id
            ),
            pairs AS (
                SELECT
                    a.user_id AS user_a,
                    b.user_id AS user_b,
                    a.items AS items_a,
                    b.items AS items_b
                FROM user_vectors a
                CROSS JOIN user_vectors b
                WHERE a.user_id < b.user_id
                  AND a.items && b.items  -- æœ‰å…±åŒå•†å“
            ),
            similarities AS (
                SELECT
                    user_a,
                    user_b,
                    cardinality(items_a & items_b)::NUMERIC /
                    SQRT(cardinality(items_a) * cardinality(items_b)) AS cosine_sim
                FROM pairs
                WHERE cardinality(items_a & items_b) >= 3
            )
            INSERT INTO user_similarity (user_id, similar_user_id, similarity_score)
            SELECT user_a, user_b, cosine_sim FROM similarities WHERE cosine_sim > 0.1
            UNION ALL
            SELECT user_b, user_a, cosine_sim FROM similarities WHERE cosine_sim > 0.1
            ON CONFLICT (user_id, similar_user_id) DO UPDATE
            SET similarity_score = EXCLUDED.similarity_score;
        """)

        self.conn.commit()
        print("âœ… ç”¨æˆ·ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ")

# ============================================================
# ç‰¹å¾å‘é‡æ›´æ–°ï¼ˆç¦»çº¿ä»»åŠ¡ï¼‰
# ============================================================

def update_item_embeddings():
    """
    æ›´æ–°å•†å“å‘é‡
    ä½¿ç”¨å•†å“å±æ€§å’Œç”¨æˆ·è¡Œä¸ºè®¡ç®—embedding
    """

    conn = get_db()
    cursor = conn.cursor()

    # ç®€åŒ–ç‰ˆï¼šåŸºäºå•†å“å±æ€§ç”Ÿæˆå‘é‡
    cursor.execute("""
        SELECT item_id, category_id, brand_id, price, sales_count
        FROM items;
    """)

    items = cursor.fetchall()

    for item in items:
        # å®é™…åº”è¯¥ç”¨å¤æ‚çš„embeddingæ¨¡å‹
        # è¿™é‡Œç®€åŒ–ä¸ºåŸºäºå±æ€§çš„å‘é‡
        embedding = np.random.rand(128).tolist()  # å ä½

        cursor.execute("""
            UPDATE items
            SET embedding = %s::vector
            WHERE item_id = %s;
        """, (embedding, item['item_id']))

    conn.commit()
    cursor.close()
    conn.close()

    print("âœ… å•†å“å‘é‡æ›´æ–°å®Œæˆ")

def update_user_profile_async(user_id, item_id):
    """å¼‚æ­¥æ›´æ–°ç”¨æˆ·ç”»åƒï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    # å®é™…åº”è¯¥ç”¨æ¶ˆæ¯é˜Ÿåˆ—
    pass

# ============================================================
# æ€§èƒ½ç›‘æ§
# ============================================================

@app.get("/api/stats")
async def get_stats():
    """ç³»ç»Ÿç»Ÿè®¡"""

    conn = get_db()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT
            (SELECT COUNT(*) FROM users) AS user_count,
            (SELECT COUNT(*) FROM items) AS item_count,
            (SELECT COUNT(*) FROM user_behavior
             WHERE timestamp > CURRENT_TIMESTAMP - INTERVAL '1 day') AS behavior_24h,
            (SELECT COUNT(*) FROM item_similarity) AS item_sim_pairs,
            (SELECT COUNT(*) FROM user_similarity) AS user_sim_pairs;
    """)

    stats = cursor.fetchone()

    cursor.close()
    conn.close()

    return stats

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)
```

---

---

## 6. æ¨èç»“æœè¯„ä¼°

### 6.1 æ¨èæ•ˆæœè¯„ä¼°

**æ¨èæ•ˆæœè¯„ä¼°å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class RecommendationEvaluator:
    """æ¨èæ•ˆæœè¯„ä¼°å™¨"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def evaluate_recommendation_quality(
        self,
        user_id: int,
        recommended_items: List[int],
        evaluation_days: int = 7
    ):
        """è¯„ä¼°æ¨èè´¨é‡"""

        # è·å–ç”¨æˆ·åœ¨è¯„ä¼°æœŸå†…çš„å®é™…è¡Œä¸º
        self.cursor.execute("""
            SELECT item_id, behavior_type
            FROM user_behavior
            WHERE user_id = %s
              AND timestamp > NOW() - INTERVAL '%s days'
              AND item_id = ANY(%s)
        """, (user_id, evaluation_days, recommended_items))

        actual_behaviors = self.cursor.fetchall()

        # è®¡ç®—æŒ‡æ ‡
        clicked_items = [b['item_id'] for b in actual_behaviors if b['behavior_type'] == 'click']
        purchased_items = [b['item_id'] for b in actual_behaviors if b['behavior_type'] == 'buy']

        ctr = len(clicked_items) / len(recommended_items) if recommended_items else 0
        cvr = len(purchased_items) / len(clicked_items) if clicked_items else 0

        return {
            'user_id': user_id,
            'recommended_count': len(recommended_items),
            'clicked_count': len(clicked_items),
            'purchased_count': len(purchased_items),
            'ctr': ctr,
            'cvr': cvr
        }
```

---

## 7. æ‰¹é‡æ¨èç”Ÿæˆ

### 7.1 æ‰¹é‡æ¨èç”Ÿæˆ

**æ‰¹é‡æ¨èç”Ÿæˆå‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class BatchRecommendationGenerator:
    """æ‰¹é‡æ¨èç”Ÿæˆå™¨"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def generate_batch_recommendations(
        self,
        user_ids: List[int],
        limit: int = 50,
        cache_ttl_minutes: int = 5
    ):
        """æ‰¹é‡ç”Ÿæˆæ¨è"""

        results = []

        for user_id in user_ids:
            try:
                # è°ƒç”¨æ¨èå‡½æ•°
                self.cursor.execute("""
                    SELECT item_id, final_score
                    FROM recommend_items(%s, %s)
                """, (user_id, limit))

                recommendations = self.cursor.fetchall()

                # æ›´æ–°ç¼“å­˜
                item_ids = [r['item_id'] for r in recommendations]
                scores = [float(r['final_score']) for r in recommendations]

                self.cursor.execute("""
                    INSERT INTO recommendation_cache (
                        user_id, recommended_items, scores, expires_at
                    )
                    VALUES (%s, %s, %s, NOW() + INTERVAL '%s minutes')
                    ON CONFLICT (user_id) DO UPDATE
                    SET recommended_items = EXCLUDED.recommended_items,
                        scores = EXCLUDED.scores,
                        generated_at = NOW(),
                        expires_at = EXCLUDED.expires_at
                """, (user_id, item_ids, scores, cache_ttl_minutes))

                results.append({
                    'user_id': user_id,
                    'recommendations': len(recommendations),
                    'status': 'success'
                })

            except Exception as e:
                results.append({
                    'user_id': user_id,
                    'status': 'failed',
                    'error': str(e)
                })

        self.conn.commit()
        return results
```

---

## 8. å®æ—¶ç‰¹å¾æ›´æ–°

### 8.1 å®æ—¶ç‰¹å¾æ›´æ–°

**å®æ—¶ç‰¹å¾æ›´æ–°å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
def update_user_features_realtime(user_id: int):
    """å®æ—¶æ›´æ–°ç”¨æˆ·ç‰¹å¾"""

    conn = get_db()
    cursor = conn.cursor()

    try:
        # è®¡ç®—ç”¨æˆ·æœ€æ–°ç‰¹å¾
        cursor.execute("""
            WITH user_stats AS (
                SELECT
                    user_id,
                    COUNT(*) FILTER (WHERE behavior_type = 'buy') AS purchase_count,
                    COUNT(*) FILTER (WHERE behavior_type = 'click') AS click_count,
                    AVG(EXTRACT(EPOCH FROM (NOW() - timestamp)) / 86400) AS avg_days_since_activity
                FROM user_behavior
                WHERE user_id = %s
                  AND timestamp > NOW() - INTERVAL '30 days'
                GROUP BY user_id
            )
            UPDATE users
            SET
                purchase_count = us.purchase_count,
                active_days = (
                    SELECT COUNT(DISTINCT timestamp::DATE)
                    FROM user_behavior
                    WHERE user_id = %s
                      AND timestamp > NOW() - INTERVAL '30 days'
                )
            FROM user_stats us
            WHERE users.user_id = %s AND users.user_id = us.user_id;
        """, (user_id, user_id, user_id))

        conn.commit()

    finally:
        cursor.close()
        conn.close()
```

---

## 9. æ¨èç³»ç»Ÿç›‘æ§

### 9.1 æ¨èæ€§èƒ½ç›‘æ§

**æ¨èæ€§èƒ½ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
# æ¨èæ€§èƒ½ç›‘æ§ç±»
class RecommendationMonitor:
    """æ¨èç³»ç»Ÿæ€§èƒ½ç›‘æ§"""

    def __init__(self, conn_str):
        self.conn = psycopg2.connect(conn_str)
        self.cursor = self.conn.cursor()

    def log_recommendation(self, user_id: int, item_ids: list, latency_ms: float):
        """è®°å½•æ¨èæ—¥å¿—"""
        self.cursor.execute("""
            INSERT INTO recommendation_logs (
                user_id, item_ids, latency_ms, created_at
            ) VALUES (%s, %s, %s, NOW())
        """, (user_id, item_ids, latency_ms))
        self.conn.commit()

    def get_performance_stats(self, hours: int = 24):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        self.cursor.execute("""
            SELECT
                COUNT(*) AS total_recommendations,
                AVG(latency_ms) AS avg_latency_ms,
                PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latency_ms) AS p95_latency_ms,
                PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY latency_ms) AS p99_latency_ms
            FROM recommendation_logs
            WHERE created_at > NOW() - INTERVAL '%s hours'
        """, (hours,))

        return self.cursor.fetchone()
```

### 9.2 æ¨èè´¨é‡ç›‘æ§

**æ¨èè´¨é‡ç›‘æ§ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
def track_recommendation_quality(user_id: int, item_id: int, action: str):
    """è·Ÿè¸ªæ¨èè´¨é‡"""
    conn = get_db()
    cursor = conn.cursor()

    try:
        # è®°å½•ç”¨æˆ·è¡Œä¸º
        cursor.execute("""
            INSERT INTO recommendation_feedback (
                user_id, item_id, action_type, created_at
            ) VALUES (%s, %s, %s, NOW())
        """, (user_id, item_id, action))

        conn.commit()

        # è®¡ç®—æ¨èè´¨é‡æŒ‡æ ‡
        cursor.execute("""
            SELECT
                COUNT(*) FILTER (WHERE action_type = 'click') AS click_count,
                COUNT(*) FILTER (WHERE action_type = 'purchase') AS purchase_count,
                COUNT(*) AS total_recommendations
            FROM recommendation_feedback
            WHERE user_id = %s
                AND created_at > NOW() - INTERVAL '7 days'
        """, (user_id,))

        stats = cursor.fetchone()

        click_rate = stats['click_count'] / stats['total_recommendations'] if stats['total_recommendations'] > 0 else 0
        conversion_rate = stats['purchase_count'] / stats['total_recommendations'] if stats['total_recommendations'] > 0 else 0

        return {
            'click_rate': click_rate,
            'conversion_rate': conversion_rate,
            'total_recommendations': stats['total_recommendations']
        }

    finally:
        cursor.close()
        conn.close()
```

---

## 10. PostgreSQL 18æ¨èç³»ç»Ÿä¼˜åŒ–

### 10.1 å¼‚æ­¥I/Oä¼˜åŒ–

**å¼‚æ­¥I/Oä¼˜åŒ–ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- PostgreSQL 18å¼‚æ­¥I/Oé…ç½®
ALTER SYSTEM SET io_direct = 'data';
ALTER SYSTEM SET io_combine_limit = '256kB';

-- é‡å¯åç”Ÿæ•ˆ
SELECT pg_reload_conf();

-- æ€§èƒ½æå‡:
-- å‘é‡æ£€ç´¢æ€§èƒ½: +20-25%
-- æ‰¹é‡æŸ¥è¯¢æ€§èƒ½: +15-20%
```

### 10.2 å¹¶è¡Œæ¨èè®¡ç®—

**å¹¶è¡Œæ¨èè®¡ç®—ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 1000;
SET parallel_tuple_cost = 0.01;

-- å¹¶è¡Œæ¨èè®¡ç®—å‡½æ•°
CREATE OR REPLACE FUNCTION parallel_recommend_items(
    p_user_id INT,
    p_limit INT DEFAULT 50
)
RETURNS TABLE (
    item_id INT,
    score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    WITH user_cf AS (
        -- User CFæ¨èï¼ˆå¹¶è¡Œï¼‰
        SELECT item_id, similarity_score
        FROM user_cf_recommendations
        WHERE user_id = p_user_id
        ORDER BY similarity_score DESC
        LIMIT p_limit
    ),
    item_cf AS (
        -- Item CFæ¨èï¼ˆå¹¶è¡Œï¼‰
        SELECT item_id, similarity_score
        FROM item_cf_recommendations
        WHERE user_id = p_user_id
        ORDER BY similarity_score DESC
        LIMIT p_limit
    ),
    vector_rec AS (
        -- å‘é‡æ¨èï¼ˆå¹¶è¡Œï¼‰
        SELECT item_id, similarity_score
        FROM vector_recommendations
        WHERE user_id = p_user_id
        ORDER BY similarity_score DESC
        LIMIT p_limit
    )
    SELECT
        COALESCE(uc.item_id, ic.item_id, vr.item_id) AS item_id,
        (COALESCE(uc.similarity_score, 0) * 0.4 +
         COALESCE(ic.similarity_score, 0) * 0.3 +
         COALESCE(vr.similarity_score, 0) * 0.3) AS score
    FROM user_cf uc
    FULL OUTER JOIN item_cf ic ON uc.item_id = ic.item_id
    FULL OUTER JOIN vector_rec vr ON COALESCE(uc.item_id, ic.item_id) = vr.item_id
    ORDER BY score DESC
    LIMIT p_limit;

    RETURN;
END;
$$ LANGUAGE plpgsql;
```

---

**è¿”å›**: [æ¡ˆä¾‹7ä¸»é¡µ](./README.md)
