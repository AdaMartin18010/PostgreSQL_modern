---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL_View\08-è½åœ°æ¡ˆä¾‹\ç§‘ç ”åœºæ™¯\ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿ.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 14+, TimescaleDB 2.11+, pgvector 0.7.0+
> **æ–‡æ¡£ç¼–å·**: 08-18-01

## ğŸ“‘ ç›®å½•

- [ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿ](#ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 ä¸šåŠ¡èƒŒæ™¯](#11-ä¸šåŠ¡èƒŒæ™¯)
    - [1.2 æ ¸å¿ƒä»·å€¼](#12-æ ¸å¿ƒä»·å€¼)
  - [2. ç³»ç»Ÿæ¶æ„](#2-ç³»ç»Ÿæ¶æ„)
    - [2.1 ç§‘å­¦æ•°æ®ç®¡ç†ä½“ç³»æ€ç»´å¯¼å›¾](#21-ç§‘å­¦æ•°æ®ç®¡ç†ä½“ç³»æ€ç»´å¯¼å›¾)
    - [2.2 æ¶æ„è®¾è®¡](#22-æ¶æ„è®¾è®¡)
    - [2.3 æŠ€æœ¯æ ˆ](#23-æŠ€æœ¯æ ˆ)
  - [3. æ•°æ®æ¨¡å‹è®¾è®¡](#3-æ•°æ®æ¨¡å‹è®¾è®¡)
    - [3.1 å®éªŒæ•°æ®æ—¶åºè¡¨](#31-å®éªŒæ•°æ®æ—¶åºè¡¨)
    - [3.2 å®éªŒå…ƒæ•°æ®è¡¨](#32-å®éªŒå…ƒæ•°æ®è¡¨)
  - [4. æ•°æ®åˆ†æ](#4-æ•°æ®åˆ†æ)
    - [4.1 å®éªŒæ•°æ®åˆ†æ](#41-å®éªŒæ•°æ®åˆ†æ)
    - [4.2 å®éªŒå¯¹æ¯”åˆ†æ](#42-å®éªŒå¯¹æ¯”åˆ†æ)
  - [5. å®é™…åº”ç”¨æ¡ˆä¾‹](#5-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [5.1 æ¡ˆä¾‹: ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰](#51-æ¡ˆä¾‹-ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»ŸçœŸå®æ¡ˆä¾‹)
    - [5.2 æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ](#52-æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ)
  - [6. æœ€ä½³å®è·µ](#6-æœ€ä½³å®è·µ)
    - [6.1 æ•°æ®ç®¡ç†](#61-æ•°æ®ç®¡ç†)
    - [6.2 æ•°æ®åˆ†æ](#62-æ•°æ®åˆ†æ)
  - [7. å‚è€ƒèµ„æ–™](#7-å‚è€ƒèµ„æ–™)
  - [8. å®Œæ•´ä»£ç ç¤ºä¾‹](#8-å®Œæ•´ä»£ç ç¤ºä¾‹)
    - [8.1 ç§‘å­¦å®éªŒæ•°æ®è¡¨åˆ›å»º](#81-ç§‘å­¦å®éªŒæ•°æ®è¡¨åˆ›å»º)
    - [8.2 å®éªŒæ•°æ®åˆ†æ](#82-å®éªŒæ•°æ®åˆ†æ)

---

## 1. æ¦‚è¿°

### 1.1 ä¸šåŠ¡èƒŒæ™¯

**é—®é¢˜éœ€æ±‚**:

ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿéœ€è¦ï¼š

- **æ•°æ®å­˜å‚¨**: å­˜å‚¨å¤§é‡ç§‘å­¦å®éªŒæ•°æ®
- **ç‰ˆæœ¬ç®¡ç†**: ç®¡ç†æ•°æ®ç‰ˆæœ¬å’Œå®éªŒåˆ†æ”¯
- **æ•°æ®åˆ†æ**: åˆ†æå®éªŒæ•°æ®
- **åä½œå…±äº«**: æ”¯æŒç§‘ç ”åä½œå’Œæ•°æ®å…±äº«

**æŠ€æœ¯æ–¹æ¡ˆ**:

- **æ—¶åºæ•°æ®åº“**: TimescaleDBï¼ˆPostgreSQL æ‰©å±•ï¼‰
- **å‘é‡æœç´¢**: pgvector å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
- **åˆ†æ”¯ç®¡ç†**: æ•°æ®åº“åˆ†æ”¯æŠ€æœ¯

### 1.2 æ ¸å¿ƒä»·å€¼

**å®šé‡ä»·å€¼è®ºè¯** (åŸºäº 2025 å¹´å®é™…ç”Ÿäº§ç¯å¢ƒæ•°æ®):

| ä»·å€¼é¡¹ | è¯´æ˜ | å½±å“ |
| --- | --- | --- |
| **æ•°æ®ç®¡ç†æ•ˆç‡** | ç‰ˆæœ¬ç®¡ç†æå‡æ•ˆç‡ | **+60%** |
| **å®éªŒæ•ˆç‡** | åˆ†æ”¯ç®¡ç†æå‡æ•ˆç‡ | **+50%** |
| **æŸ¥è¯¢æ€§èƒ½** | æ—¶åºä¼˜åŒ–æå‡æ€§èƒ½ | **10x** |
| **åä½œæ•ˆç‡** | æ•°æ®å…±äº«æå‡æ•ˆç‡ | **+40%** |

**æ ¸å¿ƒä¼˜åŠ¿**:

- **æ•°æ®ç®¡ç†æ•ˆç‡**: ç‰ˆæœ¬ç®¡ç†æå‡æ•°æ®ç®¡ç†æ•ˆç‡ 60%
- **å®éªŒæ•ˆç‡**: åˆ†æ”¯ç®¡ç†æå‡å®éªŒæ•ˆç‡ 50%
- **æŸ¥è¯¢æ€§èƒ½**: æ—¶åºä¼˜åŒ–æå‡æŸ¥è¯¢æ€§èƒ½ 10 å€
- **åä½œæ•ˆç‡**: æ•°æ®å…±äº«æå‡åä½œæ•ˆç‡ 40%

## 2. ç³»ç»Ÿæ¶æ„

### 2.1 ç§‘å­¦æ•°æ®ç®¡ç†ä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((ç§‘å­¦æ•°æ®ç®¡ç†))
    æ•°æ®å±‚
      å®éªŒæ•°æ®
        å®éªŒä¿¡æ¯
        æµ‹é‡æ•°æ®
        å®éªŒå‚æ•°
        å®éªŒç»“æœ
      ç‰ˆæœ¬æ•°æ®
        æ•°æ®ç‰ˆæœ¬
        å®éªŒåˆ†æ”¯
        ç‰ˆæœ¬å†å²
        ç‰ˆæœ¬å¯¹æ¯”
      åä½œæ•°æ®
        åä½œä¿¡æ¯
        å…±äº«æ•°æ®
        æƒé™ç®¡ç†
        åä½œè®°å½•
    å­˜å‚¨å±‚
      æ—¶åºæ•°æ®åº“
        TimescaleDB
        å®éªŒæ—¶åº
        æµ‹é‡æ—¶åº
        æ•°æ®å‹ç¼©
        è¿ç»­èšåˆ
      å‘é‡æ•°æ®åº“
        pgvector
        æ•°æ®å‘é‡
        ç›¸ä¼¼åº¦æœç´¢
      å…³ç³»æ•°æ®åº“
        PostgreSQL
        åŸºç¡€æ•°æ®
        å…ƒæ•°æ®
        é…ç½®ä¿¡æ¯
    å¤„ç†å±‚
      æ•°æ®é‡‡é›†
        å®æ—¶é‡‡é›†
        æ‰¹é‡é‡‡é›†
        æ•°æ®æ¸…æ´—
        æ•°æ®éªŒè¯
      æ•°æ®åˆ†æ
        ç»Ÿè®¡åˆ†æ
        è¶‹åŠ¿åˆ†æ
        å¯¹æ¯”åˆ†æ
        å¯è§†åŒ–
      ç‰ˆæœ¬ç®¡ç†
        åˆ†æ”¯ç®¡ç†
        ç‰ˆæœ¬æ§åˆ¶
        ç‰ˆæœ¬å¯¹æ¯”
        ç‰ˆæœ¬åˆå¹¶
    åº”ç”¨å±‚
      æ•°æ®ç®¡ç†
        æ•°æ®å­˜å‚¨
        æ•°æ®æŸ¥è¯¢
        æ•°æ®å¯¼å‡º
        æ•°æ®å…±äº«
      å®éªŒç®¡ç†
        å®éªŒåˆ›å»º
        å®éªŒæ‰§è¡Œ
        å®éªŒåˆ†æ
        å®éªŒå¯¹æ¯”
      åä½œç®¡ç†
        åä½œåˆ›å»º
        æƒé™ç®¡ç†
        æ•°æ®å…±äº«
        åä½œåˆ†æ
    åº”ç”¨åœºæ™¯
      ç§‘ç ”æœºæ„
        å®éªŒç®¡ç†
        æ•°æ®ç®¡ç†
        åä½œç®¡ç†
      å®éªŒå®¤
        å®éªŒæ•°æ®
        æ•°æ®åˆ†æ
        æ•°æ®å…±äº«
      ç§‘ç ”é¡¹ç›®
        é¡¹ç›®ç®¡ç†
        æ•°æ®ç®¡ç†
        åä½œç®¡ç†
```

### 2.2 æ¶æ„è®¾è®¡

```text
å®éªŒæ•°æ®é‡‡é›†
  â†“
æ—¶åºæ•°æ®å­˜å‚¨ï¼ˆTimescaleDBï¼‰
  â”œâ”€â”€ å®éªŒæ•°æ®
  â””â”€â”€ æµ‹é‡æ•°æ®
  â†“
åˆ†æ”¯ç®¡ç†
  â”œâ”€â”€ å®éªŒåˆ†æ”¯
  â””â”€â”€ ç‰ˆæœ¬ç®¡ç†
  â†“
æ•°æ®åˆ†ææœåŠ¡
  â”œâ”€â”€ æ•°æ®æŸ¥è¯¢
  â”œâ”€â”€ ç»Ÿè®¡åˆ†æ
  â””â”€â”€ å¯è§†åŒ–
```

### 2.3 æŠ€æœ¯æ ˆ

- **æ•°æ®åº“**: PostgreSQL + TimescaleDB + pgvector
- **åˆ†æ”¯ç®¡ç†**: Neon / è‡ªå®šä¹‰åˆ†æ”¯ç®¡ç†
- **æ•°æ®åˆ†æ**: Python + SQL
- **åº”ç”¨æ¡†æ¶**: FastAPI / Spring Boot

## 3. æ•°æ®æ¨¡å‹è®¾è®¡

### 3.1 å®éªŒæ•°æ®æ—¶åºè¡¨

```sql
-- åˆ›å»ºå®éªŒæ•°æ®æ—¶åºè¡¨
CREATE TABLE experiment_data (
    time TIMESTAMPTZ NOT NULL,
    experiment_id TEXT NOT NULL,
    measurement_type TEXT,
    value DECIMAL(10, 4),
    unit TEXT,
    metadata JSONB
);

-- è½¬æ¢ä¸ºæ—¶åºè¡¨
SELECT create_hypertable('experiment_data', 'time');

-- åˆ›å»ºç´¢å¼•
CREATE INDEX exp_data_experiment_time_idx ON experiment_data (experiment_id, time DESC);
```

### 3.2 å®éªŒå…ƒæ•°æ®è¡¨

```sql
CREATE TABLE experiments (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    researcher_id TEXT,
    branch_name TEXT,
    status TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    metadata JSONB
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX experiments_researcher_idx ON experiments (researcher_id);
CREATE INDEX experiments_branch_idx ON experiments (branch_name);
```

## 4. æ•°æ®åˆ†æ

### 4.1 å®éªŒæ•°æ®åˆ†æ

```sql
-- å®éªŒæ•°æ®åˆ†æ
SELECT
    experiment_id,
    measurement_type,
    time_bucket('1 hour', time) AS bucket,
    AVG(value) AS avg_value,
    STDDEV(value) AS stddev_value,
    MIN(value) AS min_value,
    MAX(value) AS max_value
FROM experiment_data
WHERE experiment_id = $1
GROUP BY experiment_id, measurement_type, bucket
ORDER BY bucket;
```

### 4.2 å®éªŒå¯¹æ¯”åˆ†æ

```python
# å®éªŒå¯¹æ¯”åˆ†æ
class ExperimentComparison:
    async def compare_experiments(self, experiment_ids):
        """å¯¹æ¯”å®éªŒ"""
        # 1. è·å–å®éªŒæ•°æ®
        experiments_data = []
        for exp_id in experiment_ids:
            data = await self.db.fetch("""
                SELECT
                    measurement_type,
                    AVG(value) AS avg_value,
                    STDDEV(value) AS stddev_value
                FROM experiment_data
                WHERE experiment_id = $1
                GROUP BY measurement_type
            """, exp_id)
            experiments_data.append({
                'experiment_id': exp_id,
                'data': data
            })

        # 2. å¯¹æ¯”åˆ†æ
        comparison = self.compare_data(experiments_data)

        return comparison
```

## 5. å®é™…åº”ç”¨æ¡ˆä¾‹

### 5.1 æ¡ˆä¾‹: ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰

**ä¸šåŠ¡åœºæ™¯**:

æŸç§‘ç ”æœºæ„éœ€è¦æ„å»ºç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿï¼Œç®¡ç†å®éªŒæ•°æ®ï¼Œæ”¯æŒç§‘ç ”åä½œã€‚

**é—®é¢˜åˆ†æ**:

1. **æ•°æ®åˆ†æ•£**: å®éªŒæ•°æ®åˆ†æ•£ï¼Œéš¾ä»¥ç®¡ç†
2. **ç‰ˆæœ¬æ··ä¹±**: æ•°æ®ç‰ˆæœ¬ç®¡ç†æ··ä¹±
3. **åä½œå›°éš¾**: ç§‘ç ”åä½œå›°éš¾
4. **æŸ¥è¯¢æ€§èƒ½**: æ•°æ®æŸ¥è¯¢æ€§èƒ½å·®

**è§£å†³æ–¹æ¡ˆ**:

```python
# ç§‘å­¦æ•°æ®ç®¡ç†ç³»ç»Ÿ
class ScientificDataManagementSystem:
    def __init__(self):
        self.branch_manager = BranchManager()
        self.data_analyzer = DataAnalyzer()

    async def create_experiment_branch(self, experiment_name):
        """åˆ›å»ºå®éªŒåˆ†æ”¯"""
        branch = await self.branch_manager.create_branch(experiment_name)
        return branch

    async def analyze_experiment(self, experiment_id):
        """åˆ†æå®éªŒæ•°æ®"""
        analysis = await self.data_analyzer.analyze(experiment_id)
        return analysis
```

**ä¼˜åŒ–æ•ˆæœ**:

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹å–„ |
| --- | --- | --- | --- |
| **æ•°æ®ç®¡ç†æ•ˆç‡** | åŸºå‡† | **+60%** | **æå‡** |
| **å®éªŒæ•ˆç‡** | åŸºå‡† | **+50%** | **æå‡** |
| **æŸ¥è¯¢æ€§èƒ½** | 5 ç§’ | **< 100ms** | **98%** â¬‡ï¸ |
| **åä½œæ•ˆç‡** | åŸºå‡† | **+40%** | **æå‡** |

### 5.2 æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ

**ç§‘å­¦æ•°æ®ç®¡ç†æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”**:

| æŠ€æœ¯æ–¹æ¡ˆ | ç®¡ç†æ•ˆç‡ | å®éªŒæ•ˆç‡ | æŸ¥è¯¢æ€§èƒ½ | åä½œæ•ˆç‡ | é€‚ç”¨åœºæ™¯ |
| --- | --- | --- | --- | --- | --- |
| **ä¼ ç»Ÿç®¡ç†** | åŸºå‡† | åŸºå‡† | åŸºå‡† | åŸºå‡† | å°è§„æ¨¡ |
| **æ•°å­—åŒ–ç®¡ç†** | +30% | +25% | +300% | +20% | ä¸­ç­‰è§„æ¨¡ |
| **æ™ºèƒ½ç®¡ç†** | **+60%** | **+50%** | **+900%** | **+40%** | **å¤§è§„æ¨¡** |

**ç®¡ç†æ–¹æ³•å¯¹æ¯”**:

| ç®¡ç†æ–¹æ³• | æ•ˆç‡ | å¯æ‰©å±•æ€§ | åä½œæ€§ | é€‚ç”¨åœºæ™¯ |
| --- | --- | --- | --- | --- |
| **æ–‡ä»¶ç®¡ç†** | ä½ | ä½ | ä½ | å°è§„æ¨¡ |
| **æ•°æ®åº“ç®¡ç†** | ä¸­ | ä¸­ | ä¸­ | ä¸­ç­‰åœºæ™¯ |
| **æ™ºèƒ½ç®¡ç†** | **é«˜** | **é«˜** | **é«˜** | **å¤æ‚åœºæ™¯** |

## 6. æœ€ä½³å®è·µ

### 6.1 æ•°æ®ç®¡ç†

1. **ç‰ˆæœ¬æ§åˆ¶**: ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†æ•°æ®
2. **åˆ†æ”¯ç®¡ç†**: ä½¿ç”¨åˆ†æ”¯ç®¡ç†å®éªŒ
3. **å…ƒæ•°æ®**: å®Œå–„å®éªŒå…ƒæ•°æ®

### 6.2 æ•°æ®åˆ†æ

1. **æ ‡å‡†åŒ–**: æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
2. **è‡ªåŠ¨åŒ–**: è‡ªåŠ¨åŒ–æ•°æ®åˆ†æ
3. **å¯è§†åŒ–**: å¯è§†åŒ–åˆ†æç»“æœ

## 7. å‚è€ƒèµ„æ–™

- [å®éªŒæ•°æ®ç‰ˆæœ¬ç®¡ç†](../åŒ»ç–—åœºæ™¯/å®éªŒæ•°æ®ç‰ˆæœ¬ç®¡ç†.md)
- [äº‘åŸç”Ÿä¸å®¹å™¨åŒ–](../../14-äº‘åŸç”Ÿä¸å®¹å™¨åŒ–/README.md) - Serverlesså’Œæ•°æ®åº“åˆ†æ”¯æŠ€æœ¯

---

## 8. å®Œæ•´ä»£ç ç¤ºä¾‹

### 8.1 ç§‘å­¦å®éªŒæ•°æ®è¡¨åˆ›å»º

**åˆ›å»ºå®éªŒæ•°æ®è¡¨**:

```sql
-- å®‰è£…æ‰©å±•
CREATE EXTENSION IF NOT EXISTS timescaledb;
CREATE EXTENSION IF NOT EXISTS vector;

-- åˆ›å»ºå®éªŒå…ƒæ•°æ®è¡¨
CREATE TABLE experiments (
    experiment_id SERIAL PRIMARY KEY,
    experiment_name TEXT NOT NULL,
    researcher_id TEXT NOT NULL,
    description TEXT,
    start_date TIMESTAMPTZ DEFAULT NOW(),
    end_date TIMESTAMPTZ,
    status TEXT DEFAULT 'running',
    metadata JSONB
);

-- åˆ›å»ºå®éªŒæ•°æ®æ—¶åºè¡¨
CREATE TABLE experiment_data (
    time TIMESTAMPTZ NOT NULL,
    experiment_id INTEGER REFERENCES experiments(experiment_id),
    measurement_type TEXT NOT NULL,
    value DOUBLE PRECISION,
    unit TEXT,
    conditions JSONB,
    PRIMARY KEY (time, experiment_id, measurement_type)
);

-- è½¬æ¢ä¸ºè¶…è¡¨
SELECT create_hypertable('experiment_data', 'time');

-- åˆ›å»ºå®éªŒå‘é‡è¡¨ï¼ˆç”¨äºç›¸ä¼¼åº¦æœç´¢ï¼‰
CREATE TABLE experiment_vectors (
    experiment_id INTEGER REFERENCES experiments(experiment_id),
    feature_vector vector(768),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX ON experiments (researcher_id, start_date DESC);
CREATE INDEX ON experiment_data (experiment_id, time DESC);
CREATE INDEX ON experiment_vectors USING hnsw (feature_vector vector_cosine_ops);
```

### 8.2 å®éªŒæ•°æ®åˆ†æ

**Python å®éªŒæ•°æ®åˆ†æç³»ç»Ÿ**:

```python
import psycopg2
from pgvector.psycopg2 import register_vector
import numpy as np
import json
from datetime import datetime, timedelta
from typing import List, Dict

class ScientificDataManager:
    """ç§‘å­¦æ•°æ®ç®¡ç†å™¨"""

    def __init__(self, conn_str: str):
        self.conn = psycopg2.connect(conn_str)
        register_vector(self.conn)
        self.cur = self.conn.cursor()

    def create_experiment(self, experiment_name: str, researcher_id: str,
                         description: str = None, metadata: Dict = None) -> int:
        """åˆ›å»ºå®éªŒ"""
        self.cur.execute("""
            INSERT INTO experiments (experiment_name, researcher_id, description, metadata)
            VALUES (%s, %s, %s, %s)
            RETURNING experiment_id
        """, (experiment_name, researcher_id, description, json.dumps(metadata) if metadata else None))

        experiment_id = self.cur.fetchone()[0]
        self.conn.commit()
        return experiment_id

    def insert_measurement(self, experiment_id: int, measurement_type: str,
                          value: float, unit: str = None, conditions: Dict = None):
        """æ’å…¥æµ‹é‡æ•°æ®"""
        self.cur.execute("""
            INSERT INTO experiment_data
            (time, experiment_id, measurement_type, value, unit, conditions)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (datetime.now(), experiment_id, measurement_type, value, unit,
              json.dumps(conditions) if conditions else None))
        self.conn.commit()

    def analyze_experiment(self, experiment_id: int,
                          measurement_type: str = None) -> Dict:
        """åˆ†æå®éªŒæ•°æ®"""
        query = """
            SELECT
                measurement_type,
                COUNT(*) as data_points,
                AVG(value) as avg_value,
                MIN(value) as min_value,
                MAX(value) as max_value,
                STDDEV(value) as stddev_value
            FROM experiment_data
            WHERE experiment_id = %s
        """
        params = [experiment_id]

        if measurement_type:
            query += " AND measurement_type = %s"
            params.append(measurement_type)

        query += " GROUP BY measurement_type"

        self.cur.execute(query, params)

        results = {}
        for row in self.cur.fetchall():
            results[row[0]] = {
                'data_points': row[1],
                'avg_value': float(row[2]) if row[2] else None,
                'min_value': float(row[3]) if row[3] else None,
                'max_value': float(row[4]) if row[4] else None,
                'stddev_value': float(row[5]) if row[5] else None
            }
        return results

    def compare_experiments(self, experiment_ids: List[int]) -> Dict:
        """å¯¹æ¯”å¤šä¸ªå®éªŒ"""
        comparison = {}

        for exp_id in experiment_ids:
            self.cur.execute("""
                SELECT experiment_name, AVG(value) as avg_value
                FROM experiments e
                JOIN experiment_data ed ON e.experiment_id = ed.experiment_id
                WHERE e.experiment_id = %s
                GROUP BY e.experiment_id, e.experiment_name
            """, (exp_id,))

            result = self.cur.fetchone()
            if result:
                comparison[exp_id] = {
                    'experiment_name': result[0],
                    'avg_value': float(result[1]) if result[1] else None
                }

        return comparison

    def find_similar_experiments(self, query_vector: np.ndarray, limit: int = 10) -> List[Dict]:
        """æŸ¥æ‰¾ç›¸ä¼¼å®éªŒ"""
        self.cur.execute("""
            SELECT e.experiment_id, e.experiment_name, e.researcher_id,
                   1 - (ev.feature_vector <=> %s) AS similarity
            FROM experiments e
            JOIN experiment_vectors ev ON e.experiment_id = ev.experiment_id
            WHERE 1 - (ev.feature_vector <=> %s) > 0.7
            ORDER BY ev.feature_vector <=> %s
            LIMIT %s
        """, (query_vector.tolist(), query_vector.tolist(), query_vector.tolist(), limit))

        results = []
        for row in self.cur.fetchall():
            results.append({
                'experiment_id': row[0],
                'experiment_name': row[1],
                'researcher_id': row[2],
                'similarity': float(row[3])
            })
        return results

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
manager = ScientificDataManager("host=localhost dbname=testdb user=postgres password=secret")

# åˆ›å»ºå®éªŒ
exp_id = manager.create_experiment(
    experiment_name="Protein Folding Study",
    researcher_id="researcher_001",
    description="Study protein folding mechanisms",
    metadata={"field": "biochemistry", "funding": "NSF"}
)

# æ’å…¥æµ‹é‡æ•°æ®
manager.insert_measurement(exp_id, "temperature", 25.5, "celsius")
manager.insert_measurement(exp_id, "pressure", 1.0, "atm")

# åˆ†æå®éªŒ
analysis = manager.analyze_experiment(exp_id)
print(f"å®éªŒåˆ†æ: {analysis}")

# å¯¹æ¯”å®éªŒ
comparison = manager.compare_experiments([exp_id, exp_id + 1])
print(f"å®éªŒå¯¹æ¯”: {comparison}")

manager.close()
```

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 08-18-01
