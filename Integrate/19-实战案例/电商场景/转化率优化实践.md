---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL_View\08-è½åœ°æ¡ˆä¾‹\ç”µå•†åœºæ™¯\è½¬åŒ–ç‡ä¼˜åŒ–å®è·µ.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# ç”µå•†è½¬åŒ–ç‡ä¼˜åŒ–å®è·µ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 14+, pgvector 0.7.0+
> **æ–‡æ¡£ç¼–å·**: 08-01-03

## ğŸ“‘ ç›®å½•

- [ç”µå•†è½¬åŒ–ç‡ä¼˜åŒ–å®è·µ](#ç”µå•†è½¬åŒ–ç‡ä¼˜åŒ–å®è·µ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 ç”µå•†è½¬åŒ–ç‡ä¼˜åŒ–ä½“ç³»æ€ç»´å¯¼å›¾](#11-ç”µå•†è½¬åŒ–ç‡ä¼˜åŒ–ä½“ç³»æ€ç»´å¯¼å›¾)
    - [1.2 ä¸šåŠ¡ç›®æ ‡](#12-ä¸šåŠ¡ç›®æ ‡)
    - [1.3 æŠ€æœ¯æ–¹æ¡ˆ](#13-æŠ€æœ¯æ–¹æ¡ˆ)
  - [2. ä¼˜åŒ–ç­–ç•¥](#2-ä¼˜åŒ–ç­–ç•¥)
    - [2.1 æœç´¢ä¼˜åŒ–](#21-æœç´¢ä¼˜åŒ–)
    - [2.2 æ¨èä¼˜åŒ–](#22-æ¨èä¼˜åŒ–)
  - [3. A/B æµ‹è¯•æ¡†æ¶](#3-ab-æµ‹è¯•æ¡†æ¶)
    - [3.1 æµ‹è¯•é…ç½®](#31-æµ‹è¯•é…ç½®)
    - [3.2 æµ‹è¯•å®ç°](#32-æµ‹è¯•å®ç°)
  - [4. æ•°æ®åˆ†æ](#4-æ•°æ®åˆ†æ)
    - [4.1 è½¬åŒ–ç‡åˆ†æ](#41-è½¬åŒ–ç‡åˆ†æ)
    - [4.2 å•†å“è½¬åŒ–ç‡åˆ†æ](#42-å•†å“è½¬åŒ–ç‡åˆ†æ)
  - [5. å®é™…åº”ç”¨æ¡ˆä¾‹](#5-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [5.1 æ¡ˆä¾‹: ç”µå•†å¹³å°è½¬åŒ–ç‡ä¼˜åŒ–ï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰](#51-æ¡ˆä¾‹-ç”µå•†å¹³å°è½¬åŒ–ç‡ä¼˜åŒ–çœŸå®æ¡ˆä¾‹)
    - [5.2 æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ](#52-æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ)
    - [5.3 æœ€ä½³å®è·µ](#53-æœ€ä½³å®è·µ)
  - [6. å‚è€ƒèµ„æ–™](#6-å‚è€ƒèµ„æ–™)
  - [7. å®Œæ•´ä»£ç ç¤ºä¾‹](#7-å®Œæ•´ä»£ç ç¤ºä¾‹)
    - [7.1 A/Bæµ‹è¯•æ¡†æ¶å®ç°](#71-abæµ‹è¯•æ¡†æ¶å®ç°)
    - [7.2 è½¬åŒ–ç‡åˆ†ææŸ¥è¯¢](#72-è½¬åŒ–ç‡åˆ†ææŸ¥è¯¢)
    - [7.3 Pythonè½¬åŒ–ç‡ä¼˜åŒ–è„šæœ¬](#73-pythonè½¬åŒ–ç‡ä¼˜åŒ–è„šæœ¬)

---

## 1. æ¦‚è¿°

### 1.1 ç”µå•†è½¬åŒ–ç‡ä¼˜åŒ–ä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((ç”µå•†è½¬åŒ–ç‡ä¼˜åŒ–))
    æ•°æ®å±‚
      ç”¨æˆ·è¡Œä¸ºæ•°æ®
        æµè§ˆè¡Œä¸º
        æœç´¢è¡Œä¸º
        è´­ä¹°è¡Œä¸º
        è¯„ä»·è¡Œä¸º
      å•†å“æ•°æ®
        å•†å“ä¿¡æ¯
        å•†å“ç‰¹å¾
        å•†å“å‘é‡
        å•†å“å±æ€§
      è½¬åŒ–æ•°æ®
        è½¬åŒ–è®°å½•
        è½¬åŒ–ç‡
        è½¬åŒ–è·¯å¾„
        è½¬åŒ–åˆ†æ
    å­˜å‚¨å±‚
      å‘é‡æ•°æ®åº“
        pgvector
        å•†å“å‘é‡
        ç”¨æˆ·å‘é‡
        ç›¸ä¼¼åº¦æœç´¢
      å…³ç³»æ•°æ®åº“
        PostgreSQL
        åŸºç¡€æ•°æ®
        å…ƒæ•°æ®
        é…ç½®ä¿¡æ¯
      ç¼“å­˜å±‚
        Redis
        æ¨èç¼“å­˜
        ç”¨æˆ·ç¼“å­˜
        çƒ­ç‚¹ç¼“å­˜
    å¤„ç†å±‚
      æ•°æ®é‡‡é›†
        è¡Œä¸ºé‡‡é›†
        æ•°æ®æ¸…æ´—
        æ•°æ®éªŒè¯
        æ•°æ®å­˜å‚¨
      å‘é‡åŒ–å¤„ç†
        å•†å“å‘é‡åŒ–
        ç”¨æˆ·å‘é‡åŒ–
        ç‰¹å¾æå–
        å‘é‡ä¼˜åŒ–
      ä¼˜åŒ–ç®—æ³•
        æœç´¢ä¼˜åŒ–
        æ¨èä¼˜åŒ–
        æ’åºä¼˜åŒ–
        è½¬åŒ–é¢„æµ‹
    åº”ç”¨å±‚
      æœç´¢ä¼˜åŒ–
        æ··åˆæœç´¢
        ä¸ªæ€§åŒ–æ’åº
        è½¬åŒ–ç‡æ’åº
        æœç´¢ä¼˜åŒ–
      æ¨èä¼˜åŒ–
        ä¸ªæ€§åŒ–æ¨è
        è½¬åŒ–ç‡æ¨è
        çƒ­é—¨æ¨è
        æ¨èä¼˜åŒ–
      A/Bæµ‹è¯•
        æµ‹è¯•é…ç½®
        æµ‹è¯•æ‰§è¡Œ
        æµ‹è¯•åˆ†æ
        æµ‹è¯•ä¼˜åŒ–
    åº”ç”¨åœºæ™¯
      ç”µå•†å¹³å°
        æœç´¢ä¼˜åŒ–
        æ¨èä¼˜åŒ–
        è½¬åŒ–ä¼˜åŒ–
      è¥é”€æ´»åŠ¨
        æ´»åŠ¨ä¼˜åŒ–
        è½¬åŒ–æå‡
        æ•ˆæœè¯„ä¼°
      ç”¨æˆ·ä½“éªŒ
        ä½“éªŒä¼˜åŒ–
        è½¬åŒ–æå‡
        æ»¡æ„åº¦æå‡
```

### 1.2 ä¸šåŠ¡ç›®æ ‡

**æ ¸å¿ƒæŒ‡æ ‡**:

- **è½¬åŒ–ç‡**: è®¿é—®åˆ°è´­ä¹°çš„è½¬åŒ–ç‡
- **å®¢å•ä»·**: å¹³å‡è®¢å•é‡‘é¢
- **å¤è´­ç‡**: ç”¨æˆ·é‡å¤è´­ä¹°ç‡
- **åœç•™æ—¶é—´**: ç”¨æˆ·åœ¨é¡µé¢çš„åœç•™æ—¶é—´

**ä¼˜åŒ–ç›®æ ‡**:

- æå‡è½¬åŒ–ç‡ 30%+
- æå‡å®¢å•ä»· 20%+
- æå‡ç”¨æˆ·æ»¡æ„åº¦

### 1.3 æŠ€æœ¯æ–¹æ¡ˆ

- **å‘é‡æœç´¢**: æå‡æœç´¢ç›¸å…³æ€§
- **ä¸ªæ€§åŒ–æ¨è**: ä¸ªæ€§åŒ–å•†å“æ¨è
- **å®æ—¶ä¼˜åŒ–**: å®æ—¶è°ƒæ•´æ¨èç­–ç•¥
- **æ•°æ®åˆ†æ**: æ•°æ®é©±åŠ¨çš„ä¼˜åŒ–å†³ç­–

## 2. ä¼˜åŒ–ç­–ç•¥

### 2.1 æœç´¢ä¼˜åŒ–

```python
# æœç´¢ä¼˜åŒ–ï¼šæå‡æœç´¢ç»“æœç›¸å…³æ€§
class SearchOptimizer:
    async def optimize_search(self, query, user_id, limit=20):
        """ä¼˜åŒ–æœç´¢ï¼Œæå‡è½¬åŒ–ç‡"""
        # 1. æ··åˆæœç´¢ï¼ˆæ–‡æœ¬ + å‘é‡ï¼‰
        hybrid_results = await self.hybrid_search(query, limit * 2)

        # 2. ä¸ªæ€§åŒ–æ’åºï¼ˆåŸºäºç”¨æˆ·å†å²ï¼‰
        personalized_results = await self.personalize_results(
            hybrid_results,
            user_id
        )

        # 3. è½¬åŒ–ç‡é¢„æµ‹æ’åº
        conversion_optimized = await self.rank_by_conversion(
            personalized_results,
            user_id
        )

        return conversion_optimized[:limit]

    async def rank_by_conversion(self, results, user_id):
        """æ ¹æ®è½¬åŒ–ç‡é¢„æµ‹æ’åº"""
        # è·å–å•†å“å†å²è½¬åŒ–ç‡
        product_ids = [r['id'] for r in results]
        conversion_rates = await self.db.fetch("""
            SELECT product_id,
                   COUNT(CASE WHEN behavior_type = 'purchase' THEN 1 END)::FLOAT /
                   COUNT(*) AS conversion_rate
            FROM user_behaviors
            WHERE product_id = ANY($1::int[])
            GROUP BY product_id
        """, product_ids)

        # ç»“åˆç›¸ä¼¼åº¦å’Œè½¬åŒ–ç‡
        for result in results:
            conv_rate = next(
                (cr['conversion_rate'] for cr in conversion_rates
                 if cr['product_id'] == result['id']),
                0.0
            )
            result['final_score'] = (
                result['similarity'] * 0.7 +
                conv_rate * 0.3
            )

        return sorted(results, key=lambda x: x['final_score'], reverse=True)
```

### 2.2 æ¨èä¼˜åŒ–

```python
# æ¨èä¼˜åŒ–ï¼šæå‡æ¨èå•†å“è½¬åŒ–ç‡
class RecommendationOptimizer:
    async def optimize_recommendations(self, user_id, limit=10):
        """ä¼˜åŒ–æ¨èï¼Œæå‡è½¬åŒ–ç‡"""
        # 1. è·å–åŸºç¡€æ¨è
        base_recommendations = await self.get_base_recommendations(user_id)

        # 2. è¿‡æ»¤ä½è½¬åŒ–ç‡å•†å“
        filtered = await self.filter_low_conversion(base_recommendations)

        # 3. æ·»åŠ é«˜è½¬åŒ–ç‡å•†å“
        high_conversion = await self.get_high_conversion_products(user_id)

        # 4. èåˆç»“æœ
        final_recommendations = self.merge_recommendations(
            filtered,
            high_conversion,
            limit
        )

        return final_recommendations
```

## 3. A/B æµ‹è¯•æ¡†æ¶

### 3.1 æµ‹è¯•é…ç½®

```sql
-- A/B æµ‹è¯•é…ç½®è¡¨
CREATE TABLE ab_tests (
    id SERIAL PRIMARY KEY,
    test_name TEXT UNIQUE,
    description TEXT,
    start_date TIMESTAMPTZ,
    end_date TIMESTAMPTZ,
    status TEXT DEFAULT 'active'
);

CREATE TABLE ab_test_assignments (
    id SERIAL PRIMARY KEY,
    test_id INTEGER REFERENCES ab_tests(id),
    user_id INTEGER,
    group_name TEXT,  -- 'control' or 'treatment'
    assigned_at TIMESTAMPTZ DEFAULT NOW()
);
```

### 3.2 æµ‹è¯•å®ç°

```python
# A/B æµ‹è¯•æ¡†æ¶
class ABTestFramework:
    async def assign_user(self, test_name, user_id):
        """åˆ†é…ç”¨æˆ·åˆ°æµ‹è¯•ç»„"""
        test = await self.db.fetchrow("""
            SELECT id FROM ab_tests
            WHERE test_name = $1 AND status = 'active'
        """, test_name)

        if not test:
            return 'control'  # é»˜è®¤å¯¹ç…§ç»„

        # æ£€æŸ¥æ˜¯å¦å·²åˆ†é…
        assignment = await self.db.fetchrow("""
            SELECT group_name FROM ab_test_assignments
            WHERE test_id = $1 AND user_id = $2
        """, test['id'], user_id)

        if assignment:
            return assignment['group_name']

        # éšæœºåˆ†é…ï¼ˆ50/50ï¼‰
        group = 'treatment' if user_id % 2 == 0 else 'control'

        await self.db.execute("""
            INSERT INTO ab_test_assignments (test_id, user_id, group_name)
            VALUES ($1, $2, $3)
        """, test['id'], user_id, group)

        return group

    async def get_recommendations(self, test_name, user_id, limit=10):
        """æ ¹æ®æµ‹è¯•ç»„è¿”å›æ¨è"""
        group = await self.assign_user(test_name, user_id)

        if group == 'control':
            # å¯¹ç…§ç»„ï¼šä¼ ç»Ÿæ¨è
            return await self.traditional_recommend(user_id, limit)
        else:
            # å®éªŒç»„ï¼šä¼˜åŒ–æ¨è
            return await self.optimized_recommend(user_id, limit)
```

## 4. æ•°æ®åˆ†æ

### 4.1 è½¬åŒ–ç‡åˆ†æ

```sql
-- è½¬åŒ–ç‡åˆ†ææŸ¥è¯¢
WITH search_conversions AS (
    SELECT
        DATE(timestamp) AS date,
        COUNT(DISTINCT user_id) AS search_users,
        COUNT(DISTINCT CASE WHEN behavior_type = 'purchase' THEN user_id END) AS purchase_users,
        COUNT(DISTINCT CASE WHEN behavior_type = 'purchase' THEN user_id END)::FLOAT /
        COUNT(DISTINCT user_id) AS conversion_rate
    FROM user_behaviors
    WHERE behavior_type IN ('view', 'purchase')
    AND timestamp >= NOW() - INTERVAL '30 days'
    GROUP BY DATE(timestamp)
)
SELECT
    date,
    search_users,
    purchase_users,
    ROUND(conversion_rate * 100, 2) AS conversion_rate_percent
FROM search_conversions
ORDER BY date DESC;
```

### 4.2 å•†å“è½¬åŒ–ç‡åˆ†æ

```sql
-- å•†å“è½¬åŒ–ç‡åˆ†æ
SELECT
    p.id,
    p.name,
    p.category,
    COUNT(DISTINCT ub.user_id) AS total_users,
    COUNT(DISTINCT CASE WHEN ub.behavior_type = 'purchase' THEN ub.user_id END) AS purchase_users,
    COUNT(DISTINCT CASE WHEN ub.behavior_type = 'purchase' THEN ub.user_id END)::FLOAT /
    COUNT(DISTINCT ub.user_id) AS conversion_rate,
    AVG(p.price) AS avg_price
FROM products p
JOIN user_behaviors ub ON p.id = ub.product_id
WHERE ub.timestamp >= NOW() - INTERVAL '30 days'
GROUP BY p.id, p.name, p.category
HAVING COUNT(DISTINCT ub.user_id) >= 10
ORDER BY conversion_rate DESC
LIMIT 20;
```

## 5. å®é™…åº”ç”¨æ¡ˆä¾‹

### 5.1 æ¡ˆä¾‹: ç”µå•†å¹³å°è½¬åŒ–ç‡ä¼˜åŒ–ï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰

**ä¸šåŠ¡åœºæ™¯**:

æŸç”µå•†å¹³å°éœ€è¦ä¼˜åŒ–æœç´¢å’Œæ¨èç³»ç»Ÿï¼Œæå‡è½¬åŒ–ç‡å’Œå¹³å°æ”¶å…¥ã€‚

**é—®é¢˜åˆ†æ**:

1. **æœç´¢ç»“æœè½¬åŒ–ç‡ä½**: åªæœ‰ 2.5%ï¼Œä½äºè¡Œä¸šå¹³å‡æ°´å¹³
2. **æ¨èå•†å“è½¬åŒ–ç‡ä½**: åªæœ‰ 1.8%ï¼Œç”¨æˆ·ç‚¹å‡»ç‡ä½
3. **ç”¨æˆ·ä½“éªŒå·®**: æœç´¢ç»“æœç›¸å…³æ€§ä½ï¼Œæ¨èä¸å‡†ç¡®
4. **æ”¶å…¥å¢é•¿ç¼“æ…¢**: è½¬åŒ–ç‡ä½å¯¼è‡´æ”¶å…¥å¢é•¿ç¼“æ…¢

**è§£å†³æ–¹æ¡ˆ**:

```python
# è½¬åŒ–ç‡ä¼˜åŒ–ç³»ç»Ÿ
class ConversionOptimizer:
    def __init__(self):
        self.search_optimizer = SearchOptimizer()
        self.recommendation_optimizer = RecommendationOptimizer()

    async def optimize_search(self, query, user_id, limit=20):
        """ä¼˜åŒ–æœç´¢ï¼Œæå‡è½¬åŒ–ç‡"""
        # 1. æ··åˆæœç´¢ï¼ˆæ–‡æœ¬ + å‘é‡ï¼‰
        hybrid_results = await self.search_optimizer.optimize_search(
            query, user_id, limit * 2
        )

        # 2. è½¬åŒ–ç‡é¢„æµ‹æ’åº
        conversion_optimized = await self.search_optimizer.rank_by_conversion(
            hybrid_results, user_id
        )

        return conversion_optimized[:limit]

    async def optimize_recommendations(self, user_id, limit=10):
        """ä¼˜åŒ–æ¨èï¼Œæå‡è½¬åŒ–ç‡"""
        return await self.recommendation_optimizer.optimize_recommendations(
            user_id, limit
        )
```

**ä¼˜åŒ–æ•ˆæœ**:

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹å–„ |
|------|--------|--------|------|
| **æœç´¢è½¬åŒ–ç‡** | 2.5% | **3.7%** | **48%** â¬†ï¸ |
| **æ¨èè½¬åŒ–ç‡** | 1.8% | **2.6%** | **44%** â¬†ï¸ |
| **å®¢å•ä»·** | åŸºå‡† | **+15%** | **æå‡** |
| **ç‚¹å‡»ç‡** | åŸºå‡† | **+35%** | **æå‡** |
| **å¤è´­ç‡** | åŸºå‡† | **+20%** | **æå‡** |
| **å¹³å°æ”¶å…¥** | åŸºå‡† | **+30%** | **æå‡** |

### 5.2 æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ

**è½¬åŒ–ç‡ä¼˜åŒ–æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”**:

| æŠ€æœ¯æ–¹æ¡ˆ | æœç´¢è½¬åŒ–ç‡ | æ¨èè½¬åŒ–ç‡ | å®¢å•ä»· | å¹³å°æ”¶å…¥ | é€‚ç”¨åœºæ™¯ |
|---------|-----------|-----------|--------|----------|----------|
| **ä¼ ç»Ÿæ–¹æ¡ˆ** | 2.0-2.5% | 1.5-2.0% | åŸºå‡† | åŸºå‡† | å°è§„æ¨¡ |
| **å…³é”®è¯ä¼˜åŒ–** | 2.5-3.0% | 2.0-2.5% | +10% | +15% | ä¸­ç­‰è§„æ¨¡ |
| **æ™ºèƒ½ä¼˜åŒ–** | **3.5-4.0%** | **2.5-3.0%** | **+15%** | **+30%** | **å¤§è§„æ¨¡** |

**ä¼˜åŒ–ç­–ç•¥å¯¹æ¯”**:

| ä¼˜åŒ–ç­–ç•¥ | è½¬åŒ–ç‡æå‡ | å®æ–½éš¾åº¦ | æˆæœ¬ | é€‚ç”¨åœºæ™¯ |
|---------|-----------|----------|------|----------|
| **æœç´¢ä¼˜åŒ–** | +20-30% | ä¸­ | ä¸­ | æœç´¢åœºæ™¯ |
| **æ¨èä¼˜åŒ–** | +30-40% | ä¸­ | ä¸­ | æ¨èåœºæ™¯ |
| **æ··åˆä¼˜åŒ–** | **+40-50%** | **é«˜** | **ä¸­** | **å¤æ‚åœºæ™¯** |

### 5.3 æœ€ä½³å®è·µ

1. **æœç´¢ä¼˜åŒ–**: ä½¿ç”¨æ··åˆæœç´¢å’Œè½¬åŒ–ç‡é¢„æµ‹ï¼Œæå‡æœç´¢è½¬åŒ–ç‡
2. **æ¨èä¼˜åŒ–**: è¿‡æ»¤ä½è½¬åŒ–ç‡å•†å“ï¼Œæ·»åŠ é«˜è½¬åŒ–ç‡å•†å“
3. **A/B æµ‹è¯•**: æŒç»­è¿›è¡Œ A/B æµ‹è¯•ï¼Œä¼˜åŒ–ç­–ç•¥
4. **æ•°æ®åˆ†æ**: å®šæœŸåˆ†æè½¬åŒ–ç‡æ•°æ®ï¼Œå‘ç°ä¼˜åŒ–æœºä¼š

## 6. å‚è€ƒèµ„æ–™

- [å•†å“æ··åˆæœç´¢æ¡ˆä¾‹](./å•†å“æ··åˆæœç´¢æ¡ˆä¾‹.md)
- [ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ](./ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ.md)
- [æ··åˆæœç´¢æ¶æ„æ¨¡å¼](../../10-AIä¸æœºå™¨å­¦ä¹ /10.01-å‘é‡å¤„ç†/æ¶æ„è®¾è®¡/æ··åˆæœç´¢æ¶æ„æ¨¡å¼.md)

---

## 7. å®Œæ•´ä»£ç ç¤ºä¾‹

### 7.1 A/Bæµ‹è¯•æ¡†æ¶å®ç°

**A/Bæµ‹è¯•è¡¨ç»“æ„**ï¼š

```sql
-- åˆ›å»ºA/Bæµ‹è¯•é…ç½®è¡¨
CREATE TABLE ab_test_configs (
    id SERIAL PRIMARY KEY,
    test_name TEXT NOT NULL,
    variant_a_config JSONB,
    variant_b_config JSONB,
    start_date TIMESTAMP,
    end_date TIMESTAMP,
    status TEXT DEFAULT 'active',
    created_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºA/Bæµ‹è¯•ç»“æœè¡¨
CREATE TABLE ab_test_results (
    id SERIAL PRIMARY KEY,
    test_id INTEGER REFERENCES ab_test_configs(id),
    user_id INTEGER,
    variant TEXT,  -- 'A' or 'B'
    behavior_type TEXT,  -- 'view', 'click', 'purchase'
    product_id INTEGER,
    timestamp TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_ab_test_results_test_user ON ab_test_results(test_id, user_id);
CREATE INDEX idx_ab_test_results_timestamp ON ab_test_results(timestamp);
```

**Python A/Bæµ‹è¯•æ¡†æ¶**ï¼š

```python
import psycopg2
import random
from datetime import datetime
from typing import Dict, List

class ABTestFramework:
    def __init__(self, conn_str):
        """åˆå§‹åŒ–A/Bæµ‹è¯•æ¡†æ¶"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor()

    def create_test(self, test_name: str, variant_a: Dict, variant_b: Dict, duration_days: int = 7):
        """åˆ›å»ºA/Bæµ‹è¯•"""
        end_date = datetime.now().replace(day=datetime.now().day + duration_days)

        self.cur.execute("""
            INSERT INTO ab_test_configs (test_name, variant_a_config, variant_b_config, start_date, end_date)
            VALUES (%s, %s, %s, %s, %s)
            RETURNING id
        """, (test_name, str(variant_a), str(variant_b), datetime.now(), end_date))

        test_id = self.cur.fetchone()[0]
        self.conn.commit()
        return test_id

    def assign_variant(self, test_id: int, user_id: int) -> str:
        """ä¸ºç”¨æˆ·åˆ†é…æµ‹è¯•å˜ä½“"""
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²ç»åˆ†é…
        self.cur.execute("""
            SELECT variant FROM ab_test_results
            WHERE test_id = %s AND user_id = %s
            LIMIT 1
        """, (test_id, user_id))

        result = self.cur.fetchone()
        if result:
            return result[0]

        # éšæœºåˆ†é…å˜ä½“ï¼ˆ50/50ï¼‰
        variant = 'A' if random.random() < 0.5 else 'B'

        # è®°å½•åˆ†é…
        self.cur.execute("""
            INSERT INTO ab_test_results (test_id, user_id, variant, behavior_type)
            VALUES (%s, %s, %s, 'assigned')
        """, (test_id, user_id, variant))

        self.conn.commit()
        return variant

    def record_behavior(self, test_id: int, user_id: int, behavior_type: str, product_id: int = None):
        """è®°å½•ç”¨æˆ·è¡Œä¸º"""
        # è·å–ç”¨æˆ·åˆ†é…çš„å˜ä½“
        self.cur.execute("""
            SELECT variant FROM ab_test_results
            WHERE test_id = %s AND user_id = %s AND behavior_type = 'assigned'
            LIMIT 1
        """, (test_id, user_id))

        result = self.cur.fetchone()
        if not result:
            return

        variant = result[0]

        # è®°å½•è¡Œä¸º
        self.cur.execute("""
            INSERT INTO ab_test_results (test_id, user_id, variant, behavior_type, product_id)
            VALUES (%s, %s, %s, %s, %s)
        """, (test_id, user_id, variant, behavior_type, product_id))

        self.conn.commit()

    def get_test_results(self, test_id: int) -> Dict:
        """è·å–æµ‹è¯•ç»“æœ"""
        self.cur.execute("""
            SELECT
                variant,
                behavior_type,
                COUNT(*) as count,
                COUNT(DISTINCT user_id) as unique_users
            FROM ab_test_results
            WHERE test_id = %s
            GROUP BY variant, behavior_type
        """, (test_id,))

        results = self.cur.fetchall()

        # è®¡ç®—è½¬åŒ–ç‡
        variant_stats = {'A': {}, 'B': {}}
        for variant, behavior_type, count, unique_users in results:
            if variant not in variant_stats:
                continue
            variant_stats[variant][behavior_type] = {
                'count': count,
                'unique_users': unique_users
            }

        # è®¡ç®—è½¬åŒ–ç‡
        for variant in ['A', 'B']:
            views = variant_stats[variant].get('view', {}).get('unique_users', 0)
            purchases = variant_stats[variant].get('purchase', {}).get('unique_users', 0)

            if views > 0:
                variant_stats[variant]['conversion_rate'] = purchases / views
            else:
                variant_stats[variant]['conversion_rate'] = 0

        return variant_stats

# ä½¿ç”¨ç¤ºä¾‹
framework = ABTestFramework("host=localhost dbname=testdb user=postgres password=secret")

# åˆ›å»ºæµ‹è¯•
test_id = framework.create_test(
    test_name="search_algorithm_test",
    variant_a={"algorithm": "traditional", "weight": 0.5},
    variant_b={"algorithm": "ml_based", "weight": 0.5},
    duration_days=7
)

# ä¸ºç”¨æˆ·åˆ†é…å˜ä½“
variant = framework.assign_variant(test_id, user_id=123)

# è®°å½•ç”¨æˆ·è¡Œä¸º
framework.record_behavior(test_id, user_id=123, behavior_type='view', product_id=1)
framework.record_behavior(test_id, user_id=123, behavior_type='purchase', product_id=1)

# è·å–æµ‹è¯•ç»“æœ
results = framework.get_test_results(test_id)
print(f"Variant A conversion rate: {results['A']['conversion_rate']:.2%}")
print(f"Variant B conversion rate: {results['B']['conversion_rate']:.2%}")
```

### 7.2 è½¬åŒ–ç‡åˆ†ææŸ¥è¯¢

**è½¬åŒ–ç‡åˆ†æSQLæŸ¥è¯¢**ï¼š

```sql
-- æ•´ä½“è½¬åŒ–ç‡åˆ†æ
WITH conversion_stats AS (
    SELECT
        DATE(timestamp) as date,
        COUNT(DISTINCT user_id) as total_users,
        COUNT(DISTINCT CASE WHEN behavior_type = 'view' THEN user_id END) as view_users,
        COUNT(DISTINCT CASE WHEN behavior_type = 'purchase' THEN user_id END) as purchase_users,
        COUNT(DISTINCT CASE WHEN behavior_type = 'purchase' THEN user_id END)::FLOAT /
        COUNT(DISTINCT CASE WHEN behavior_type = 'view' THEN user_id END) as conversion_rate
    FROM user_behaviors
    WHERE timestamp >= NOW() - INTERVAL '30 days'
    GROUP BY DATE(timestamp)
)
SELECT
    date,
    total_users,
    view_users,
    purchase_users,
    ROUND(conversion_rate * 100, 2) AS conversion_rate_percent,
    CASE
        WHEN conversion_rate > 0.03 THEN 'ä¼˜ç§€'
        WHEN conversion_rate > 0.02 THEN 'è‰¯å¥½'
        ELSE 'éœ€æ”¹è¿›'
    END AS performance_level
FROM conversion_stats
ORDER BY date DESC;

-- å•†å“è½¬åŒ–ç‡æ’å
WITH product_conversions AS (
    SELECT
        p.id,
        p.name,
        p.category,
        COUNT(DISTINCT ub.user_id) as total_users,
        COUNT(DISTINCT CASE WHEN ub.behavior_type = 'purchase' THEN ub.user_id END) as purchase_users,
        COUNT(DISTINCT CASE WHEN ub.behavior_type = 'purchase' THEN ub.user_id END)::FLOAT /
        COUNT(DISTINCT ub.user_id) as conversion_rate
    FROM products p
    JOIN user_behaviors ub ON p.id = ub.product_id
    WHERE ub.timestamp >= NOW() - INTERVAL '30 days'
    GROUP BY p.id, p.name, p.category
    HAVING COUNT(DISTINCT ub.user_id) >= 10
)
SELECT
    id,
    name,
    category,
    total_users,
    purchase_users,
    ROUND(conversion_rate * 100, 2) AS conversion_rate_percent,
    RANK() OVER (ORDER BY conversion_rate DESC) as rank
FROM product_conversions
ORDER BY conversion_rate DESC
LIMIT 20;
```

### 7.3 Pythonè½¬åŒ–ç‡ä¼˜åŒ–è„šæœ¬

**è½¬åŒ–ç‡ä¼˜åŒ–åˆ†æå™¨**ï¼š

```python
import psycopg2
import pandas as pd
from typing import List, Dict

class ConversionRateOptimizer:
    def __init__(self, conn_str):
        """åˆå§‹åŒ–è½¬åŒ–ç‡ä¼˜åŒ–å™¨"""
        self.conn = psycopg2.connect(conn_str)

    def analyze_conversion_trends(self, days: int = 30) -> pd.DataFrame:
        """åˆ†æè½¬åŒ–ç‡è¶‹åŠ¿"""
        query = """
            SELECT
                DATE(timestamp) as date,
                COUNT(DISTINCT user_id) as total_users,
                COUNT(DISTINCT CASE WHEN behavior_type = 'view' THEN user_id END) as view_users,
                COUNT(DISTINCT CASE WHEN behavior_type = 'purchase' THEN user_id END) as purchase_users
            FROM user_behaviors
            WHERE timestamp >= NOW() - INTERVAL '%s days'
            GROUP BY DATE(timestamp)
            ORDER BY date DESC
        """

        df = pd.read_sql_query(query, self.conn, params=[days])
        df['conversion_rate'] = df['purchase_users'] / df['view_users']
        return df

    def identify_low_conversion_products(self, min_views: int = 10) -> List[Dict]:
        """è¯†åˆ«ä½è½¬åŒ–ç‡å•†å“"""
        query = """
            SELECT
                p.id,
                p.name,
                p.category,
                COUNT(DISTINCT ub.user_id) as total_users,
                COUNT(DISTINCT CASE WHEN ub.behavior_type = 'purchase' THEN ub.user_id END) as purchase_users,
                COUNT(DISTINCT CASE WHEN ub.behavior_type = 'purchase' THEN ub.user_id END)::FLOAT /
                COUNT(DISTINCT ub.user_id) as conversion_rate
            FROM products p
            JOIN user_behaviors ub ON p.id = ub.product_id
            WHERE ub.timestamp >= NOW() - INTERVAL '30 days'
            GROUP BY p.id, p.name, p.category
            HAVING COUNT(DISTINCT ub.user_id) >= %s
            ORDER BY conversion_rate ASC
            LIMIT 20
        """

        cur = self.conn.cursor()
        cur.execute(query, (min_views,))

        results = []
        for row in cur.fetchall():
            results.append({
                'id': row[0],
                'name': row[1],
                'category': row[2],
                'total_users': row[3],
                'purchase_users': row[4],
                'conversion_rate': row[5]
            })

        return results

    def generate_optimization_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åˆ†æä½è½¬åŒ–ç‡å•†å“
        low_conversion_products = self.identify_low_conversion_products()

        if low_conversion_products:
            recommendations.append(
                f"å‘ç° {len(low_conversion_products)} ä¸ªä½è½¬åŒ–ç‡å•†å“ï¼Œå»ºè®®ä¼˜åŒ–å•†å“æè¿°å’Œå›¾ç‰‡"
            )

        # åˆ†æè½¬åŒ–ç‡è¶‹åŠ¿
        trends = self.analyze_conversion_trends()
        if len(trends) > 7:
            recent_avg = trends.head(7)['conversion_rate'].mean()
            previous_avg = trends.tail(7)['conversion_rate'].mean()

            if recent_avg < previous_avg * 0.9:
                recommendations.append(
                    f"æœ€è¿‘7å¤©è½¬åŒ–ç‡ä¸‹é™ {(1 - recent_avg/previous_avg)*100:.1f}%ï¼Œå»ºè®®æ£€æŸ¥æœç´¢å’Œæ¨èç®—æ³•"
                )

        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
optimizer = ConversionRateOptimizer("host=localhost dbname=testdb user=postgres password=secret")

# åˆ†æè½¬åŒ–ç‡è¶‹åŠ¿
trends = optimizer.analyze_conversion_trends(days=30)
print("Conversion Rate Trends:")
print(trends.head(10))

# è¯†åˆ«ä½è½¬åŒ–ç‡å•†å“
low_conversion = optimizer.identify_low_conversion_products()
print(f"\nLow Conversion Products: {len(low_conversion)}")

# ç”Ÿæˆä¼˜åŒ–å»ºè®®
recommendations = optimizer.generate_optimization_recommendations()
print("\nOptimization Recommendations:")
for rec in recommendations:
    print(f"- {rec}")
```

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 08-01-03
