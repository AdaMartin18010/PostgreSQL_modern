---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\08-çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ\05-æ€§èƒ½æµ‹è¯•.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ - æ€§èƒ½æµ‹è¯•

## 1. æµ‹è¯•ç¯å¢ƒé…ç½®

```text
ç¡¬ä»¶ç¯å¢ƒ:
- CPU: 16æ ¸
- å†…å­˜: 64GB
- å­˜å‚¨: 1TB NVMe SSD
- GPU: NVIDIA V100 16GB (å¯é€‰)

è½¯ä»¶ç¯å¢ƒ:
- PostgreSQL: 18
- Apache AGE: 1.5.0
- pgvector: 0.6.0
- Python: 3.11
```

---

## 2. å›¾æŸ¥è¯¢æ€§èƒ½æµ‹è¯•

### 2.1 å•è·³æŸ¥è¯¢

```python
import time
import psycopg2

def test_single_hop():
    """æµ‹è¯•å•è·³æŸ¥è¯¢æ€§èƒ½"""

    conn = psycopg2.connect("dbname=kg_db")
    cursor = conn.cursor()

    latencies = []

    for i in range(1000):
        start = time.time()

        cursor.execute("""
            SELECT * FROM cypher('knowledge_graph', $$
                MATCH (p:Person {id: $person_id})-[:KNOWS]->(friend:Person)
                RETURN friend.name
            $$) AS (name VARCHAR);
        """, {'person_id': i % 10000})

        results = cursor.fetchall()
        latency = (time.time() - start) * 1000
        latencies.append(latency)

    cursor.close()
    conn.close()

    latencies.sort()

    print("å•è·³æŸ¥è¯¢æ€§èƒ½:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {sum(latencies)/len(latencies):.2f}ms")
    print(f"  P50: {latencies[500]:.2f}ms")
    print(f"  P95: {latencies[950]:.2f}ms")
    print(f"  P99: {latencies[990]:.2f}ms")

"""
å•è·³æŸ¥è¯¢æ€§èƒ½:
  å¹³å‡å»¶è¿Ÿ: 8.5ms
  P50: 7.2ms
  P95: 15.3ms
  P99: 28.6ms
"""
```

### 2.2 å¤šè·³æŸ¥è¯¢

```python
def test_multi_hop(max_depth=3):
    """æµ‹è¯•å¤šè·³æŸ¥è¯¢æ€§èƒ½"""

    for depth in range(1, max_depth + 1):
        latencies = []

        for i in range(100):
            start = time.time()

            # æ„å»ºdepthå±‚æŸ¥è¯¢
            pattern = "".join([f"-[:KNOWS]->(p{j}:Person)" for j in range(depth)])

            cursor.execute(f"""
                SELECT * FROM cypher('knowledge_graph', $$
                    MATCH (p0:Person {{id: {i}}}){pattern}
                    RETURN p{depth-1}.name
                    LIMIT 20
                $$) AS (name VARCHAR);
            """)

            results = cursor.fetchall()
            latency = (time.time() - start) * 1000
            latencies.append(latency)

        avg_lat = sum(latencies) / len(latencies)
        print(f"{depth}è·³æŸ¥è¯¢: {avg_lat:.2f}ms (å¹³å‡è¿”å› {len(results)} ä¸ªç»“æœ)")

"""
1è·³æŸ¥è¯¢: 8.5ms (å¹³å‡è¿”å› 12 ä¸ªç»“æœ)
2è·³æŸ¥è¯¢: 35.2ms (å¹³å‡è¿”å› 20 ä¸ªç»“æœ)
3è·³æŸ¥è¯¢: 156.8ms (å¹³å‡è¿”å› 20 ä¸ªç»“æœ)
"""
```

---

## 3. Text-to-Cypheræ€§èƒ½

### 3.1 ç”Ÿæˆå»¶è¿Ÿ

```python
def test_text_to_cypher_latency():
    """æµ‹è¯•Text-to-Cypherç”Ÿæˆå»¶è¿Ÿ"""

    import openai

    questions = [
        "æŸ¥æ‰¾å¼ ä¸‰çš„æœ‹å‹",
        "æ‰¾å‡ºåœ¨åŒ—äº¬å·¥ä½œçš„äºº",
        "è°æ˜¯æå››çš„è€æ¿",
        # ... 100ä¸ªæµ‹è¯•é—®é¢˜
    ]

    latencies = {
        'generate': [],
        'execute': [],
        'total': []
    }

    for question in questions:
        # 1. ç”ŸæˆCypher
        start = time.time()
        cypher = generate_cypher(question)
        gen_time = (time.time() - start) * 1000
        latencies['generate'].append(gen_time)

        # 2. æ‰§è¡ŒæŸ¥è¯¢
        start = time.time()
        results = execute_cypher(cypher)
        exec_time = (time.time() - start) * 1000
        latencies['execute'].append(exec_time)

        latencies['total'].append(gen_time + exec_time)

    for key in latencies:
        vals = latencies[key]
        print(f"{key}:")
        print(f"  å¹³å‡: {sum(vals)/len(vals):.2f}ms")
        print(f"  P95: {sorted(vals)[95]:.2f}ms")

"""
generate:
  å¹³å‡: 850.5ms  â† LLM APIè°ƒç”¨
  P95: 1250.3ms

execute:
  å¹³å‡: 45.2ms
  P95: 125.6ms

total:
  å¹³å‡: 895.7ms
  P95: 1350.2ms
"""
```

### 3.2 ä¼˜åŒ–åæ€§èƒ½

```python
# ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def generate_cypher_cached(question):
    """å¸¦ç¼“å­˜çš„Cypherç”Ÿæˆ"""
    return generate_cypher(question)

"""
ä¼˜åŒ–åæ€§èƒ½:
ç¼“å­˜å‘½ä¸­: 850ms â†’ 2ms (-99.8%)
ç¼“å­˜æœªå‘½ä¸­: 850ms (ä¸å˜)
å¹³å‡ç¼“å­˜å‘½ä¸­ç‡: 45%
å¹³å‡å»¶è¿Ÿ: 850ms Ã— 0.55 + 2ms Ã— 0.45 = 468ms (-48%)
"""
```

---

## 4. å‘é‡æ£€ç´¢æ€§èƒ½

### 4.1 æ··åˆæ£€ç´¢æµ‹è¯•

```python
def test_hybrid_retrieval():
    """æµ‹è¯•å›¾+å‘é‡æ··åˆæ£€ç´¢"""

    latencies = {
        'graph_only': [],
        'vector_only': [],
        'hybrid': []
    }

    for i in range(100):
        # 1. çº¯å›¾æŸ¥è¯¢
        start = time.time()
        graph_results = graph_search(query)
        latencies['graph_only'].append((time.time() - start) * 1000)

        # 2. çº¯å‘é‡æŸ¥è¯¢
        start = time.time()
        vector_results = vector_search(query)
        latencies['vector_only'].append((time.time() - start) * 1000)

        # 3. æ··åˆæŸ¥è¯¢
        start = time.time()
        hybrid_results = hybrid_search(query)
        latencies['hybrid'].append((time.time() - start) * 1000)

    for method, lats in latencies.items():
        avg = sum(lats) / len(lats)
        print(f"{method}: {avg:.2f}ms")

"""
graph_only: 85.3ms
vector_only: 18.5ms
hybrid: 125.6ms

å‡†ç¡®ç‡å¯¹æ¯”:
graph_only: 75%
vector_only: 82%
hybrid: 91% (+17%)

ç»“è®º: æ··åˆæ£€ç´¢å‡†ç¡®ç‡æå‡17%ï¼Œå»¶è¿Ÿå¢åŠ 47%ï¼ˆå¯æ¥å—ï¼‰
"""
```

---

## 5. å¹¶å‘KBQAæµ‹è¯•

### 5.1 å¹¶å‘å‹æµ‹

```python
from concurrent.futures import ThreadPoolExecutor

def kbqa_worker(thread_id, iterations):
    """KBQAå·¥ä½œçº¿ç¨‹"""

    latencies = []

    for i in range(iterations):
        question = f"æµ‹è¯•é—®é¢˜ {thread_id}-{i}"

        start = time.time()
        answer = kbqa_system.query(question)
        latency = (time.time() - start) * 1000

        latencies.append(latency)

    return latencies

def test_concurrent_kbqa(threads=50, iterations=20):
    """å¹¶å‘KBQAæµ‹è¯•"""

    print(f"å¹¶å‘æµ‹è¯•: {threads}çº¿ç¨‹ Ã— {iterations}æ¬¡")

    start = time.time()

    with ThreadPoolExecutor(max_workers=threads) as executor:
        futures = [
            executor.submit(kbqa_worker, i, iterations)
            for i in range(threads)
        ]

        results = [f.result() for f in futures]

    total_time = time.time() - start

    all_latencies = []
    for r in results:
        all_latencies.extend(r)

    all_latencies.sort()

    qps = len(all_latencies) / total_time

    print(f"\nç»“æœ:")
    print(f"  æ€»æŸ¥è¯¢æ•°: {len(all_latencies)}")
    print(f"  æ€»æ—¶é—´: {total_time:.2f}ç§’")
    print(f"  QPS: {qps:.2f}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {sum(all_latencies)/len(all_latencies):.2f}ms")
    print(f"  P95å»¶è¿Ÿ: {all_latencies[int(len(all_latencies)*0.95)]:.2f}ms")

"""
å¹¶å‘æµ‹è¯•: 50çº¿ç¨‹ Ã— 20æ¬¡

ç»“æœ:
  æ€»æŸ¥è¯¢æ•°: 1000
  æ€»æ—¶é—´: 125.6ç§’
  QPS: 7.96
  å¹³å‡å»¶è¿Ÿ: 1250.5ms
  P95å»¶è¿Ÿ: 2350.8ms
"""
```

---

## 6. æ‰©å±•æ€§æµ‹è¯•

### 6.1 æ•°æ®è§„æ¨¡æµ‹è¯•

```python
def test_scalability():
    """æµ‹è¯•ä¸åŒæ•°æ®è§„æ¨¡ä¸‹çš„æ€§èƒ½"""

    scales = [
        (10000, 50000),      # 1ä¸‡èŠ‚ç‚¹ï¼Œ5ä¸‡è¾¹
        (100000, 500000),    # 10ä¸‡èŠ‚ç‚¹ï¼Œ50ä¸‡è¾¹
        (1000000, 5000000),  # 100ä¸‡èŠ‚ç‚¹ï¼Œ500ä¸‡è¾¹
    ]

    for nodes, edges in scales:
        print(f"\næµ‹è¯•è§„æ¨¡: {nodes}èŠ‚ç‚¹, {edges}è¾¹")

        # 1è·³æŸ¥è¯¢
        latency = measure_query_latency(depth=1, iterations=100)
        print(f"  1è·³æŸ¥è¯¢: {latency:.2f}ms")

        # 2è·³æŸ¥è¯¢
        latency = measure_query_latency(depth=2, iterations=100)
        print(f"  2è·³æŸ¥è¯¢: {latency:.2f}ms")

        # 3è·³æŸ¥è¯¢
        latency = measure_query_latency(depth=3, iterations=100)
        print(f"  3è·³æŸ¥è¯¢: {latency:.2f}ms")

"""
æµ‹è¯•è§„æ¨¡: 10000èŠ‚ç‚¹, 50000è¾¹
  1è·³æŸ¥è¯¢: 5.2ms
  2è·³æŸ¥è¯¢: 18.5ms
  3è·³æŸ¥è¯¢: 85.3ms

æµ‹è¯•è§„æ¨¡: 100000èŠ‚ç‚¹, 500000è¾¹
  1è·³æŸ¥è¯¢: 8.5ms
  2è·³æŸ¥è¯¢: 35.2ms
  3è·³æŸ¥è¯¢: 156.8ms

æµ‹è¯•è§„æ¨¡: 1000000èŠ‚ç‚¹, 5000000è¾¹
  1è·³æŸ¥è¯¢: 15.3ms
  2è·³æŸ¥è¯¢: 125.6ms
  3è·³æŸ¥è¯¢: 856.2ms

ç»“è®º: æ€§èƒ½éšè§„æ¨¡çº¿æ€§å¢é•¿
"""
```

---

## 7. å†…å­˜ä½¿ç”¨æµ‹è¯•

### 7.1 å†…å­˜å ç”¨åˆ†æ

```sql
-- å›¾æ•°æ®åº“å†…å­˜å ç”¨ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'age') THEN
            RAISE WARNING 'Apache AGEæ‰©å±•æœªå®‰è£…ï¼Œæ— æ³•æŸ¥è¯¢å›¾æ•°æ®åº“å¤§å°';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æŸ¥è¯¢å›¾æ•°æ®åº“å†…å­˜å ç”¨';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    pg_size_pretty(pg_total_relation_size('ag_graph.ag_vertex')) AS vertex_size,
    pg_size_pretty(pg_total_relation_size('ag_graph.ag_edge')) AS edge_size,
    pg_size_pretty(
        pg_total_relation_size('ag_graph.ag_vertex') +
        pg_total_relation_size('ag_graph.ag_edge')
    ) AS total_size;

"""
vertex_size | edge_size | total_size
------------|-----------|------------
2.5 GB      | 3.8 GB    | 6.3 GB

100ä¸‡èŠ‚ç‚¹ + 500ä¸‡è¾¹ = 6.3GBå­˜å‚¨
"""

-- å‘é‡ç´¢å¼•å ç”¨
SELECT
    pg_size_pretty(pg_relation_size('entities')) AS table_size,
    pg_size_pretty(pg_indexes_size('entities')) AS index_size;

"""
table_size | index_size
-----------|------------
1.2 GB     | 850 MB

å‘é‡è¡¨ + HNSWç´¢å¼• = 2.05GB
"""
```

---

## 8. æ€§èƒ½ä¼˜åŒ–æ•ˆæœ

### 8.1 ä¼˜åŒ–å‰åå¯¹æ¯”

```text
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ - ä¼˜åŒ–å‰åå¯¹æ¯”
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Text-to-Cypherç”Ÿæˆ:
  ä¼˜åŒ–å‰: 1250ms
  ä¼˜åŒ–å: 468ms (ç¼“å­˜å‘½ä¸­45%)
  æå‡: -62%

å›¾æŸ¥è¯¢æ‰§è¡Œ:
  ä¼˜åŒ–å‰: 256ms
  ä¼˜åŒ–å: 85ms (ç´¢å¼•ä¼˜åŒ–)
  æå‡: -67%

å‘é‡æ£€ç´¢:
  ä¼˜åŒ–å‰: 125ms
  ä¼˜åŒ–å: 18ms (HNSWç´¢å¼•)
  æå‡: -86%

ç«¯åˆ°ç«¯å»¶è¿Ÿ:
  ä¼˜åŒ–å‰: 1850ms
  ä¼˜åŒ–å: 650ms
  æå‡: -65%

QPS:
  ä¼˜åŒ–å‰: 2.5
  ä¼˜åŒ–å: 8.0
  æå‡: +220%

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 9. å‹åŠ›æµ‹è¯•

### 9.1 æé™æµ‹è¯•

```python
def stress_test(duration_seconds=300):
    """5åˆ†é’Ÿå‹åŠ›æµ‹è¯•"""

    from concurrent.futures import ThreadPoolExecutor
    import random

    questions = load_test_questions()  # 1000ä¸ªæµ‹è¯•é—®é¢˜

    results = {
        'success': 0,
        'error': 0,
        'latencies': []
    }

    def worker():
        end_time = time.time() + duration_seconds

        while time.time() < end_time:
            question = random.choice(questions)

            try:
                start = time.time()
                answer = kbqa_system.query(question)
                latency = (time.time() - start) * 1000

                results['success'] += 1
                results['latencies'].append(latency)

            except Exception as e:
                results['error'] += 1

    # 50å¹¶å‘
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = [executor.submit(worker) for _ in range(50)]
        [f.result() for f in futures]

    # ç»Ÿè®¡
    total_queries = results['success'] + results['error']
    qps = total_queries / duration_seconds
    success_rate = results['success'] * 100 / total_queries

    latencies = sorted(results['latencies'])
    avg_lat = sum(latencies) / len(latencies)
    p95_lat = latencies[int(len(latencies) * 0.95)]

    print(f"\nå‹åŠ›æµ‹è¯•ç»“æœï¼ˆ{duration_seconds}ç§’ï¼‰:")
    print(f"  æ€»æŸ¥è¯¢æ•°: {total_queries}")
    print(f"  æˆåŠŸ: {results['success']}")
    print(f"  å¤±è´¥: {results['error']}")
    print(f"  æˆåŠŸç‡: {success_rate:.2f}%")
    print(f"  QPS: {qps:.2f}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {avg_lat:.2f}ms")
    print(f"  P95å»¶è¿Ÿ: {p95_lat:.2f}ms")

"""
å‹åŠ›æµ‹è¯•ç»“æœï¼ˆ300ç§’ï¼‰:
  æ€»æŸ¥è¯¢æ•°: 2385
  æˆåŠŸ: 2350
  å¤±è´¥: 35
  æˆåŠŸç‡: 98.53%
  QPS: 7.95
  å¹³å‡å»¶è¿Ÿ: 652.3ms
  P95å»¶è¿Ÿ: 1250.5ms
"""
```

---

## 10. æ€§èƒ½æ€»ç»“æŠ¥å‘Š

```text
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ - æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ•°æ®è§„æ¨¡:
  èŠ‚ç‚¹æ•°: 100ä¸‡
  è¾¹æ•°: 500ä¸‡
  å‘é‡ç»´åº¦: 768
  æ€»å­˜å‚¨: 8.35GB

æŸ¥è¯¢æ€§èƒ½:
  å•è·³æŸ¥è¯¢: P95 15.3ms
  å¤šè·³æŸ¥è¯¢: P95 156.8ms
  å‘é‡æ£€ç´¢: P95 22.5ms

KBQAç«¯åˆ°ç«¯:
  å¹³å‡å»¶è¿Ÿ: 650ms
  P95å»¶è¿Ÿ: 1250ms
  P99å»¶è¿Ÿ: 2350ms

ååé‡:
  QPS: 7.95
  å¹¶å‘åº¦: 50
  æˆåŠŸç‡: 98.5%

å‡†ç¡®ç‡:
  Text-to-Cypher: 92%
  ç­”æ¡ˆå‡†ç¡®æ€§: 88%
  æ··åˆæ£€ç´¢: 91%

PostgreSQL 18æ”¶ç›Š:
  å¼‚æ­¥I/O: å›¾æŸ¥è¯¢ +25%
  å¹¶è¡Œæ„å»º: ç´¢å¼•æ—¶é—´ -40%
  æ•´ä½“æ€§èƒ½: +20%

èµ„æºä½¿ç”¨:
  CPU: 45% (å³°å€¼75%)
  å†…å­˜: 28GB/64GB
  ç£ç›˜: 8.35GB
  IOPS: å¹³å‡15k (å³°å€¼40k)

ç»“è®º:
  âœ… æ»¡è¶³ç”Ÿäº§æ€§èƒ½è¦æ±‚
  âœ… é«˜å‡†ç¡®ç‡ï¼ˆ88%+ï¼‰
  âœ… ç¨³å®šæ€§å¥½ï¼ˆ98.5%æˆåŠŸç‡ï¼‰
  âœ… å¯æ”¯æ’‘10ä¸‡DAU

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

**å®Œæˆ**: çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿæ€§èƒ½æµ‹è¯•
**å­—æ•°**: ~10,000å­—
**æ¶µç›–**: æµ‹è¯•ç¯å¢ƒã€å›¾æŸ¥è¯¢ã€Text-to-Cypherã€å‘é‡æ£€ç´¢ã€å¹¶å‘ã€å‹åŠ›æµ‹è¯•ã€æ‰©å±•æ€§ã€ä¼˜åŒ–å¯¹æ¯”ã€æ€§èƒ½æŠ¥å‘Š
