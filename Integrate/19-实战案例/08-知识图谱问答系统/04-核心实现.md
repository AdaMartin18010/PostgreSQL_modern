---

> **ðŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\08-çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ\04-æ ¸å¿ƒå®žçŽ°.md`
> **ðŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŽŸæ–‡ä»¶ä¿æŒä¸å˜

---

# æ¡ˆä¾‹8ï¼šçŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ - æ ¸å¿ƒå®žçŽ°

```python
"""
çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ
æŠ€æœ¯æ ˆ: PostgreSQL 18 + Apache AGE + LangChain
"""

import psycopg2
from psycopg2.extras import RealDictCursor
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
import re

class KnowledgeGraphQA:
    """çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ"""

    def __init__(self, conn_str, openai_api_key):
        self.conn = psycopg2.connect(conn_str, cursor_factory=RealDictCursor)
        self.cursor = self.conn.cursor()
        self.llm = OpenAI(api_key=openai_api_key, temperature=0)

        # åŠ è½½AGEæ‰©å±•
        self.cursor.execute("LOAD 'age';")
        self.cursor.execute("SET search_path = ag_catalog, '$user', public;")

    def nl2cypher(self, question: str) -> str:
        """
        è‡ªç„¶è¯­è¨€è½¬CypheræŸ¥è¯¢
        """

        # NL2Cypheræç¤ºè¯
        prompt = PromptTemplate(
            input_variables=["question"],
            template="""
ä½ æ˜¯ä¸€ä¸ªCypheræŸ¥è¯¢ç”Ÿæˆä¸“å®¶ã€‚å°†ä»¥ä¸‹è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºCypheræŸ¥è¯¢ã€‚

å›¾Schema:
- èŠ‚ç‚¹ç±»åž‹: Document, Concept, Person, Product
- å…³ç³»ç±»åž‹: MENTIONS, RELATED_TO, IS_A, USED_IN

é—®é¢˜: {question}

åªè¿”å›žCypheræŸ¥è¯¢ï¼Œä¸è¦è§£é‡Š:
"""
        )

        cypher_query = self.llm(prompt.format(question=question))
        cypher_query = cypher_query.strip()

        return cypher_query

    def execute_cypher(self, cypher_query: str) -> list:
        """
        æ‰§è¡ŒCypheræŸ¥è¯¢
        """

        try:
            # ä½¿ç”¨AGEæ‰§è¡ŒCypher
            self.cursor.execute(f"""
                SELECT * FROM cypher('knowledge_graph', $$
                    {cypher_query}
                $$) AS (result agtype);
            """)

            results = [row['result'] for row in self.cursor.fetchall()]
            return results

        except Exception as e:
            print(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
            return []

    def answer_question(self, question: str) -> dict:
        """
        å›žç­”é—®é¢˜ï¼ˆå®Œæ•´æµç¨‹ï¼‰
        """

        import time
        start_time = time.time()

        # 1. é—®é¢˜åˆ†ç±»
        question_type = self._classify_question(question)

        # 2. ç”ŸæˆCypher
        if question_type == 'simple':
            cypher_query = self._template_match(question)
        else:
            cypher_query = self.nl2cypher(question)

        # 3. æ‰§è¡ŒæŸ¥è¯¢
        results = self.execute_cypher(cypher_query)

        # 4. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(question, results)

        duration = (time.time() - start_time) * 1000

        return {
            'question': question,
            'cypher': cypher_query,
            'raw_results': results,
            'answer': answer,
            'duration_ms': duration
        }

    def _classify_question(self, question: str) -> str:
        """é—®é¢˜åˆ†ç±»"""

        # ç®€å•è§„åˆ™åˆ†ç±»
        if any(kw in question for kw in ['ä»€ä¹ˆæ˜¯', 'what is']):
            return 'simple'
        elif any(kw in question for kw in ['æœ‰å“ªäº›', 'list', 'æ‰€æœ‰']):
            return 'list'
        elif any(kw in question for kw in ['ç›¸å…³', 'related', 'å…³è”']):
            return 'relation'
        else:
            return 'complex'

    def _template_match(self, question: str) -> str:
        """æ¨¡æ¿åŒ¹é…ç”ŸæˆCypher"""

        # æå–å®žä½“ï¼ˆç®€åŒ–ç‰ˆï¼‰
        entity = re.search(r'ä»€ä¹ˆæ˜¯(.+?)[\?ï¼Ÿ]', question)
        if entity:
            entity_name = entity.group(1).strip()
            return f"""
                MATCH (n:Concept {{name: '{entity_name}'}})
                RETURN n.name AS name, n.description AS description
            """

        return "MATCH (n) RETURN n LIMIT 10"

    def _generate_answer(self, question: str, results: list) -> str:
        """æ ¹æ®æŸ¥è¯¢ç»“æžœç”Ÿæˆè‡ªç„¶è¯­è¨€ç­”æ¡ˆ"""

        if not results:
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

        # ä½¿ç”¨LLMç”Ÿæˆç­”æ¡ˆ
        prompt = PromptTemplate(
            input_variables=["question", "results"],
            template="""
åŸºäºŽä»¥ä¸‹æ•°æ®å›žç­”é—®é¢˜ã€‚

é—®é¢˜: {question}

æ•°æ®: {results}

ç®€æ´å›žç­”:
"""
        )

        answer = self.llm(prompt.format(question=question, results=str(results)))
        return answer.strip()

# ============================================================
# çŸ¥è¯†æŠ½å–æ¨¡å—
# ============================================================

class KnowledgeExtractor:
    """ä»Žæ–‡æœ¬ä¸­æŠ½å–çŸ¥è¯†"""

    def __init__(self, conn_str):
        self.conn = psycopg2.connect(conn_str)
        self.cursor = self.conn.cursor()

    def extract_from_document(self, doc_id: int, content: str):
        """
        ä»Žæ–‡æ¡£ä¸­æŠ½å–å®žä½“å’Œå…³ç³»
        """

        # 1. å®žä½“è¯†åˆ«ï¼ˆç®€åŒ–ç‰ˆï¼Œå®žé™…åº”ä½¿ç”¨NERæ¨¡åž‹ï¼‰
        entities = self._ner(content)

        # 2. å…³ç³»æŠ½å–
        relations = self._extract_relations(content, entities)

        # 3. å†™å…¥å›¾æ•°æ®åº“
        self._insert_to_graph(doc_id, entities, relations)

    def _ner(self, text: str) -> list:
        """å®žä½“è¯†åˆ«ï¼ˆç¤ºä¾‹ï¼‰"""
        # å®žé™…åº”ä½¿ç”¨SpaCyæˆ–BERTç­‰NERæ¨¡åž‹
        return [
            {'name': 'PostgreSQL', 'type': 'Concept'},
            {'name': 'MVCC', 'type': 'Concept'}
        ]

    def _extract_relations(self, text: str, entities: list) -> list:
        """å…³ç³»æŠ½å–ï¼ˆç¤ºä¾‹ï¼‰"""
        # å®žé™…åº”ä½¿ç”¨å…³ç³»æŠ½å–æ¨¡åž‹
        return [
            {'from': 'PostgreSQL', 'to': 'MVCC', 'type': 'USES'}
        ]

    def _insert_to_graph(self, doc_id: int, entities: list, relations: list):
        """æ’å…¥å›¾æ•°æ®åº“"""

        # æ’å…¥å®žä½“
        for entity in entities:
            self.cursor.execute(f"""
                SELECT * FROM cypher('knowledge_graph', $$
                    MERGE (n:{entity['type']} {{name: '{entity['name']}'}})
                    RETURN n
                $$) AS (n agtype);
            """)

        # æ’å…¥å…³ç³»
        for rel in relations:
            self.cursor.execute(f"""
                SELECT * FROM cypher('knowledge_graph', $$
                    MATCH (a {{name: '{rel['from']}'}}), (b {{name: '{rel['to']}'}}
                    MERGE (a)-[r:{rel['type']}]->(b)
                    RETURN r
                $$) AS (r agtype);
            """)

        self.conn.commit()

# ============================================================
# FastAPIæŽ¥å£
# ============================================================

from fastapi import FastAPI, Query as FastAPIQuery

app = FastAPI()

qa_system = KnowledgeGraphQA(
    conn_str="dbname=knowledge_db user=postgres",
    openai_api_key="your-api-key"
)

@app.get("/api/qa")
async def ask_question(q: str = FastAPIQuery(..., description="é—®é¢˜")):
    """é—®ç­”æŽ¥å£"""
    result = qa_system.answer_question(q)
    return result

@app.get("/api/graph/subgraph")
async def get_subgraph(entity: str, radius: int = 2):
    """èŽ·å–å­å›¾"""
    cursor = qa_system.cursor
    cursor.execute("""
        SELECT extract_subgraph(%s, %s);
    """, (entity, radius))
    subgraph = cursor.fetchone()[0]
    return {'entity': entity, 'subgraph': subgraph}

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8004)
```

---

---

## 4. æ€§èƒ½ä¼˜åŒ–

### 4.1 æŸ¥è¯¢ä¼˜åŒ–

**æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class QueryOptimizer:
    """æŸ¥è¯¢ä¼˜åŒ–å™¨"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def optimize_cypher_query(self, cypher_query: str) -> str:
        """ä¼˜åŒ–CypheræŸ¥è¯¢"""

        # 1. é™åˆ¶ç»“æžœæ•°é‡
        if 'LIMIT' not in cypher_query.upper():
            cypher_query += ' LIMIT 100'

        # 2. æ·»åŠ ç´¢å¼•æç¤ºï¼ˆå¦‚æžœæ”¯æŒï¼‰
        # PostgreSQL AGEä¸æ”¯æŒç´¢å¼•æç¤ºï¼Œä½†å¯ä»¥é€šè¿‡æŸ¥è¯¢é‡å†™ä¼˜åŒ–

        return cypher_query

    def cache_query_result(self, query_hash: str, result: list, ttl: int = 300):
        """ç¼“å­˜æŸ¥è¯¢ç»“æžœ"""

        import json
        import redis

        redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)
        redis_client.setex(
            f"kg_query:{query_hash}",
            ttl,
            json.dumps(result)
        )

    def get_cached_result(self, query_hash: str) -> list:
        """èŽ·å–ç¼“å­˜ç»“æžœ"""

        import json
        import redis

        redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)
        cached = redis_client.get(f"kg_query:{query_hash}")

        if cached:
            return json.loads(cached)
        return None
```

### 4.2 æ‰¹é‡æ“ä½œä¼˜åŒ–

**æ‰¹é‡æ“ä½œä¼˜åŒ–ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
class BatchGraphOperations:
    """æ‰¹é‡å›¾æ“ä½œ"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()
        self.batch_size = 1000

    def batch_create_nodes(self, nodes: list):
        """æ‰¹é‡åˆ›å»ºèŠ‚ç‚¹"""

        for i in range(0, len(nodes), self.batch_size):
            batch = nodes[i:i+self.batch_size]

            # æž„å»ºæ‰¹é‡CypheræŸ¥è¯¢
            cypher_batch = []
            for node in batch:
                cypher_batch.append(f"""
                    CREATE (n:{node['label']} {self._format_properties(node['properties'])})
                """)

            # æ‰§è¡Œæ‰¹é‡åˆ›å»º
            self.cursor.execute(f"""
                SELECT * FROM cypher('knowledge_graph', $$
                    {' '.join(cypher_batch)}
                $$) AS (result agtype);
            """)

            self.conn.commit()

    def batch_create_edges(self, edges: list):
        """æ‰¹é‡åˆ›å»ºè¾¹"""

        for i in range(0, len(edges), self.batch_size):
            batch = edges[i:i+self.batch_size]

            cypher_batch = []
            for edge in batch:
                cypher_batch.append(f"""
                    MATCH (a {{id: '{edge['from_id']}'}}), (b {{id: '{edge['to_id']}'}})
                    CREATE (a)-[r:{edge['type']} {self._format_properties(edge.get('properties', {}))}]->(b)
                """)

            self.cursor.execute(f"""
                SELECT * FROM cypher('knowledge_graph', $$
                    {' '.join(cypher_batch)}
                $$) AS (result agtype);
            """)

            self.conn.commit()

    def _format_properties(self, props: dict) -> str:
        """æ ¼å¼åŒ–å±žæ€§ä¸ºCypheræ ¼å¼"""
        if not props:
            return '{}'

        formatted = []
        for key, value in props.items():
            if isinstance(value, str):
                formatted.append(f"{key}: '{value}'")
            else:
                formatted.append(f"{key}: {value}")

        return '{' + ', '.join(formatted) + '}'
```

---

## 5. ç›‘æŽ§ä¸Žè¯Šæ–­

### 5.1 æŸ¥è¯¢æ€§èƒ½ç›‘æŽ§

**æŸ¥è¯¢æ€§èƒ½ç›‘æŽ§å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```sql
-- åˆ›å»ºæŸ¥è¯¢æ€§èƒ½ç›‘æŽ§è¡¨
CREATE TABLE IF NOT EXISTS kg_query_performance (
    id SERIAL PRIMARY KEY,
    query_hash TEXT,
    query_text TEXT,
    duration_ms NUMERIC,
    result_count INT,
    success BOOLEAN,
    error_message TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_kg_query_performance_hash ON kg_query_performance (query_hash);
CREATE INDEX idx_kg_query_performance_created ON kg_query_performance (created_at);

-- æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡å‡½æ•°
CREATE OR REPLACE FUNCTION get_query_performance_stats(
    p_hours INT DEFAULT 24
)
RETURNS TABLE (
    query_hash TEXT,
    query_text TEXT,
    call_count BIGINT,
    avg_duration_ms NUMERIC,
    p95_duration_ms NUMERIC,
    success_rate NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        query_hash,
        LEFT(query_text, 200) AS query_text,
        COUNT(*)::BIGINT AS call_count,
        ROUND(AVG(duration_ms), 2) AS avg_duration_ms,
        ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY duration_ms), 2) AS p95_duration_ms,
        ROUND(COUNT(*) FILTER (WHERE success) * 100.0 / COUNT(*), 2) AS success_rate
    FROM kg_query_performance
    WHERE created_at > NOW() - (p_hours || ' hours')::INTERVAL
    GROUP BY query_hash, query_text
    ORDER BY call_count DESC
    LIMIT 20;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡å¤±è´¥: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;
```

---

**è¿”å›ž**: [æ¡ˆä¾‹8ä¸»é¡µ](./README.md)
