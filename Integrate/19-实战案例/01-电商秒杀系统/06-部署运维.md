---
> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `DataBaseTheory\19-åœºæ™¯æ¡ˆä¾‹åº“\01-ç”µå•†ç§’æ€ç³»ç»Ÿ\06-éƒ¨ç½²è¿ç»´.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜
---
> **âš ï¸ é‡è¦æç¤º**: æœ¬æ–‡æ¡£éµå¾ªæ¡ˆä¾‹æ–‡æ¡£é€šç”¨æ¨¡æ¿æ ¼å¼ã€‚
>
> **æ¨èé˜…è¯»**:
>
> - [æ¡ˆä¾‹æ–‡æ¡£é€šç”¨æ¨¡æ¿](../æ¡ˆä¾‹æ–‡æ¡£é€šç”¨æ¨¡æ¿.md) - é€šç”¨æ¡ˆä¾‹æ–‡æ¡£æ ¼å¼å’Œæœ€ä½³å®è·µ
>
> æœ¬æ–‡æ¡£ä¿ç•™ä½œä¸ºç”µå•†ç§’æ€ç³»ç»Ÿçš„éƒ¨ç½²è¿ç»´å‚è€ƒã€‚
---

# æ¡ˆä¾‹1ï¼šç”µå•†ç§’æ€ç³»ç»Ÿ - éƒ¨ç½²è¿ç»´

## å…ƒæ•°æ®

- **åˆ›å»ºæ—¥æœŸ**: 2025-12-22
- **éƒ¨ç½²æ–¹å¼**: Docker + Kubernetes
- **ç›‘æ§**: Prometheus + Grafana
- **ç¼“å­˜**: Redis Cluster
- **æ¶ˆæ¯é˜Ÿåˆ—**: RabbitMQ / Kafka
- **è´Ÿè½½å‡è¡¡**: Nginx / HAProxy

---

## 1. Dockeréƒ¨ç½²é…ç½®

### 1.1 Docker Composeé…ç½®

**Docker Composeé…ç½®ï¼ˆå¸¦Rediså’ŒRabbitMQï¼‰**ï¼š

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:18
    container_name: flash-sale-db
    environment:
      POSTGRES_DB: flash_sale_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=C"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./postgresql.conf:/etc/postgresql/postgresql.conf
    ports:
      - "5432:5432"
    command:
      - "postgres"
      - "-c"
      - "config_file=/etc/postgresql/postgresql.conf"
      - "-c"
      - "shared_buffers=4GB"
      - "-c"
      - "work_mem=128MB"
      - "-c"
      - "maintenance_work_mem=1GB"
      - "-c"
      - "max_connections=1000"
      - "-c"
      - "effective_cache_size=12GB"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: flash-sale-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 16gb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: flash-sale-rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: flash-sale-api
    environment:
      DB_HOST: postgres
      DB_NAME: flash_sale_db
      DB_USER: postgres
      DB_PASSWORD: ${DB_PASSWORD}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
    ports:
      - "8001:8001"
    depends_on:
      - postgres
      - redis
      - rabbitmq
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    container_name: flash-sale-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - api
    restart: unless-stopped

volumes:
  postgres-data:
  redis-data:
  rabbitmq-data:
```

### 1.2 PostgreSQLä¼˜åŒ–é…ç½®

**PostgreSQLä¼˜åŒ–é…ç½®ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼Œé«˜å¹¶å‘ä¼˜åŒ–ï¼‰**ï¼š

```ini
# postgresql.conf - ç”µå•†ç§’æ€ç³»ç»Ÿä¼˜åŒ–

# å†…å­˜é…ç½®
shared_buffers = 4GB
work_mem = 128MB
maintenance_work_mem = 1GB
effective_cache_size = 12GB

# è¿æ¥é…ç½®ï¼ˆé«˜å¹¶å‘ï¼‰
max_connections = 1000
superuser_reserved_connections = 10

# WALé…ç½®ï¼ˆé«˜å†™å…¥ï¼‰
wal_buffers = 32MB
max_wal_size = 8GB
min_wal_size = 2GB
checkpoint_timeout = 10min
checkpoint_completion_target = 0.9

# PostgreSQL 18å¼‚æ­¥I/O
io_direct = data
io_combine_limit = 128kB

# PostgreSQL 18å†…ç½®è¿æ¥æ± 
pool_mode = transaction
pool_size = 500
pool_max_wait = 5

# æŸ¥è¯¢ä¼˜åŒ–
random_page_cost = 1.1
effective_io_concurrency = 200
default_statistics_target = 100

# æ—¥å¿—é…ç½®
log_destination = 'stderr'
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d.log'
log_rotation_age = 1d
log_rotation_size = 100MB
log_min_duration_statement = 200  # è®°å½•>200msçš„æŸ¥è¯¢
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# ç»Ÿè®¡ä¿¡æ¯
track_io_timing = on
track_functions = all
pg_stat_statements.track = all
```

---

## 2. ç¼“å­˜ç­–ç•¥

### 2.1 Redisç¼“å­˜é…ç½®

**Redisç¼“å­˜é…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
# redis_config.py
import redis
from redis.sentinel import Sentinel

# Redisè¿æ¥æ± 
redis_pool = redis.ConnectionPool(
    host='redis',
    port=6379,
    max_connections=100,
    decode_responses=True
)

redis_client = redis.Redis(connection_pool=redis_pool)

# ç¼“å­˜é”®ç­–ç•¥
class CacheKeys:
    FLASH_SALE = "flash_sale:{sale_id}"
    PRODUCT_STOCK = "product:stock:{product_id}"
    USER_ORDER = "user:order:{user_id}:{sale_id}"
    SALE_STATUS = "sale:status:{sale_id}"

    @staticmethod
    def get_ttl(key_type: str) -> int:
        """è·å–ç¼“å­˜TTLï¼ˆç§’ï¼‰"""
        ttl_map = {
            'flash_sale': 3600,      # 1å°æ—¶
            'product_stock': 300,     # 5åˆ†é’Ÿ
            'user_order': 1800,       # 30åˆ†é’Ÿ
            'sale_status': 60,        # 1åˆ†é’Ÿ
        }
        return ttl_map.get(key_type, 300)

# ç¼“å­˜è£…é¥°å™¨
from functools import wraps
import json

def cache_result(key_template: str, ttl: int = 300):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache_key = key_template.format(*args, **kwargs)

            # å°è¯•ä»ç¼“å­˜è·å–
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)

            # å†™å…¥ç¼“å­˜
            redis_client.setex(cache_key, ttl, json.dumps(result))

            return result
        return wrapper
    return decorator
```

---

## 3. æ¶ˆæ¯é˜Ÿåˆ—é…ç½®

### 3.1 RabbitMQé…ç½®

**RabbitMQé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```python
# rabbitmq_config.py
import pika
import json
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RabbitMQProducer:
    """RabbitMQç”Ÿäº§è€…"""

    def __init__(self, host='rabbitmq', port=5672, username='admin', password='password'):
        credentials = pika.PlainCredentials(username, password)
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(host=host, port=port, credentials=credentials)
        )
        self.channel = self.connection.channel()

        # å£°æ˜é˜Ÿåˆ—
        self.channel.queue_declare(queue='order_queue', durable=True)
        self.channel.queue_declare(queue='payment_queue', durable=True)

    def publish_order(self, order_data: dict):
        """å‘å¸ƒè®¢å•æ¶ˆæ¯"""
        try:
            self.channel.basic_publish(
                exchange='',
                routing_key='order_queue',
                body=json.dumps(order_data),
                properties=pika.BasicProperties(
                    delivery_mode=2,  # æŒä¹…åŒ–æ¶ˆæ¯
                )
            )
            logger.info(f"è®¢å•æ¶ˆæ¯å·²å‘å¸ƒ: {order_data['order_id']}")
        except Exception as e:
            logger.error(f"å‘å¸ƒè®¢å•æ¶ˆæ¯å¤±è´¥: {e}")
            raise

    def close(self):
        """å…³é—­è¿æ¥"""
        self.connection.close()

class RabbitMQConsumer:
    """RabbitMQæ¶ˆè´¹è€…"""

    def __init__(self, host='rabbitmq', port=5672, username='admin', password='password'):
        credentials = pika.PlainCredentials(username, password)
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(host=host, port=port, credentials=credentials)
        )
        self.channel = self.connection.channel()

        # å£°æ˜é˜Ÿåˆ—
        self.channel.queue_declare(queue='order_queue', durable=True)

    def consume_orders(self, callback):
        """æ¶ˆè´¹è®¢å•æ¶ˆæ¯"""
        self.channel.basic_qos(prefetch_count=1)  # å…¬å¹³åˆ†å‘
        self.channel.basic_consume(
            queue='order_queue',
            on_message_callback=callback,
            auto_ack=False
        )

        logger.info("å¼€å§‹æ¶ˆè´¹è®¢å•æ¶ˆæ¯...")
        self.channel.start_consuming()

    def close(self):
        """å…³é—­è¿æ¥"""
        self.connection.close()
```

---

## 4. ç›‘æ§é…ç½®

### 4.1 Prometheusé…ç½®

**Prometheusé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
    metrics_path: /metrics

  - job_name: 'flash-sale-api'
    static_configs:
      - targets: ['api:8001']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    metrics_path: /metrics

  - job_name: 'rabbitmq'
    static_configs:
      - targets: ['rabbitmq-exporter:9419']
    metrics_path: /metrics
```

### 4.2 Grafanaä»ªè¡¨æ¿

**Grafanaä»ªè¡¨æ¿é…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```json
{
  "dashboard": {
    "title": "ç”µå•†ç§’æ€ç³»ç»Ÿç›‘æ§",
    "panels": [
      {
        "title": "QPSï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])"
          }
        ]
      },
      {
        "title": "è®¢å•åˆ›å»ºå»¶è¿Ÿ",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(order_create_duration_ms_bucket[5m]))"
          }
        ]
      },
      {
        "title": "åº“å­˜æ‰£å‡QPS",
        "targets": [
          {
            "expr": "rate(stock_decrement_total[5m])"
          }
        ]
      },
      {
        "title": "ç¼“å­˜å‘½ä¸­ç‡",
        "targets": [
          {
            "expr": "rate(redis_hits_total[5m]) / rate(redis_requests_total[5m])"
          }
        ]
      },
      {
        "title": "æ¶ˆæ¯é˜Ÿåˆ—ç§¯å‹",
        "targets": [
          {
            "expr": "rabbitmq_queue_messages"
          }
        ]
      }
    ]
  }
}
```

---

## 5. è´Ÿè½½å‡è¡¡é…ç½®

### 5.1 Nginxé…ç½®

**Nginxé…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```nginx
# nginx.conf
upstream api_backend {
    least_conn;  # æœ€å°‘è¿æ¥
    server api:8001 max_fails=3 fail_timeout=30s;
    # server api2:8001 max_fails=3 fail_timeout=30s;
    # server api3:8001 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    server_name flash-sale.example.com;

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
    limit_req zone=api_limit burst=200 nodelay;

    location / {
        proxy_pass http://api_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # è¶…æ—¶é…ç½®
        proxy_connect_timeout 5s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
```

---

## 6. å¤‡ä»½ä¸æ¢å¤

### 6.1 æ•°æ®åº“å¤‡ä»½è„šæœ¬

**æ•°æ®åº“å¤‡ä»½è„šæœ¬ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```bash
#!/bin/bash
# backup_flash_sale.sh - ç”µå•†ç§’æ€ç³»ç»Ÿå¤‡ä»½

set -e

BACKUP_DIR="/backups/flash-sale"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

mkdir -p "$BACKUP_DIR"

# æ•°æ®åº“å¤‡ä»½
echo "å¼€å§‹æ•°æ®åº“å¤‡ä»½..."
pg_dump -h postgres -U postgres -d flash_sale_db \
  -F c -b -v -f "$BACKUP_DIR/db_$DATE.dump"

# éªŒè¯å¤‡ä»½
if [ $? -eq 0 ]; then
    echo "æ•°æ®åº“å¤‡ä»½æˆåŠŸ: $BACKUP_DIR/db_$DATE.dump"

    # å‹ç¼©å¤‡ä»½
    gzip "$BACKUP_DIR/db_$DATE.dump"

    # æ¸…ç†æ—§å¤‡ä»½
    find "$BACKUP_DIR" -name "db_*.dump.gz" -mtime +$RETENTION_DAYS -delete

    echo "å¤‡ä»½å®Œæˆï¼Œä¿ç•™æœ€è¿‘ $RETENTION_DAYS å¤©çš„å¤‡ä»½"
else
    echo "æ•°æ®åº“å¤‡ä»½å¤±è´¥ï¼"
    exit 1
fi
```

---

## 7. æ€§èƒ½è°ƒä¼˜

### 7.1 æ•°æ®åº“æ€§èƒ½è°ƒä¼˜

**æ•°æ®åº“æ€§èƒ½è°ƒä¼˜ï¼ˆPostgreSQL 18ç‰¹æ€§ï¼‰**ï¼š

```sql
-- 1. åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE flash_sales;
ANALYZE orders;
ANALYZE order_items;

-- 2. é‡å»ºç´¢å¼•
REINDEX INDEX CONCURRENTLY idx_flash_sales_product_id;
REINDEX INDEX CONCURRENTLY idx_orders_user_id;

-- 3. æ£€æŸ¥æ…¢æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 200  -- >200ms
ORDER BY mean_exec_time DESC
LIMIT 20;

-- 4. æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;
```

---

## 8. æ•…éšœå¤„ç†

### 8.1 å¸¸è§æ•…éšœå¤„ç†

**å¸¸è§æ•…éšœå¤„ç†ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```bash
# 1. æ•°æ®åº“è¿æ¥å¤±è´¥
docker exec flash-sale-db pg_isready -U postgres

# 2. Redisè¿æ¥å¤±è´¥
docker exec flash-sale-redis redis-cli ping

# 3. æ¶ˆæ¯é˜Ÿåˆ—ç§¯å‹
docker exec flash-sale-rabbitmq rabbitmqctl list_queues

# 4. é«˜å¹¶å‘å¯¼è‡´é”ç­‰å¾…
docker exec flash-sale-db psql -U postgres -d flash_sale_db -c "
    SELECT count(*) FROM pg_stat_activity WHERE wait_event_type = 'Lock';
"

# 5. ç¼“å­˜å‘½ä¸­ç‡ä½
docker exec flash-sale-redis redis-cli INFO stats | grep keyspace_hits
```

---

## 9. æ‰©å®¹ç­–ç•¥

### 9.1 æ°´å¹³æ‰©å®¹

**æ°´å¹³æ‰©å®¹ç­–ç•¥ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```yaml
# å¢åŠ APIå‰¯æœ¬æ•°
kubectl scale deployment flash-sale-api --replicas=10

# æ•°æ®åº“è¯»å†™åˆ†ç¦»ï¼ˆä½¿ç”¨pgBouncerï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pgbouncer
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: pgbouncer
        image: pgbouncer/pgbouncer:latest
        env:
        - name: DATABASES_HOST
          value: postgres
        - name: DATABASES_PORT
          value: "5432"
        - name: DATABASES_DBNAME
          value: flash_sale_db
        - name: POOL_MODE
          value: transaction
        - name: MAX_CLIENT_CONN
          value: "2000"
        - name: DEFAULT_POOL_SIZE
          value: "25"
```

---

## 10. è¿ç»´æ£€æŸ¥æ¸…å•

### 10.1 æ—¥å¸¸æ£€æŸ¥

**æ—¥å¸¸æ£€æŸ¥æ¸…å•ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰**ï¼š

```bash
#!/bin/bash
# daily_check_flash_sale.sh - ç”µå•†ç§’æ€ç³»ç»Ÿæ—¥å¸¸æ£€æŸ¥

echo "=== ç”µå•†ç§’æ€ç³»ç»Ÿæ—¥å¸¸æ£€æŸ¥ ==="

# 1. æ•°æ®åº“è¿æ¥æ£€æŸ¥
echo "1. æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
docker exec flash-sale-db pg_isready -U postgres

# 2. Redisè¿æ¥æ£€æŸ¥
echo "2. æ£€æŸ¥Redisè¿æ¥..."
docker exec flash-sale-redis redis-cli ping

# 3. RabbitMQè¿æ¥æ£€æŸ¥
echo "3. æ£€æŸ¥RabbitMQè¿æ¥..."
docker exec flash-sale-rabbitmq rabbitmq-diagnostics ping

# 4. QPSæ£€æŸ¥
echo "4. æ£€æŸ¥QPS..."
curl -s http://localhost:8001/metrics | grep http_requests_total

# 5. ç¼“å­˜å‘½ä¸­ç‡æ£€æŸ¥
echo "5. æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡..."
docker exec flash-sale-redis redis-cli INFO stats | grep keyspace_hits

# 6. æ•°æ®åº“å¤§å°æ£€æŸ¥
echo "6. æ£€æŸ¥æ•°æ®åº“å¤§å°..."
docker exec flash-sale-db psql -U postgres -d flash_sale_db -c "
    SELECT pg_size_pretty(pg_database_size('flash_sale_db'));
"

echo "=== æ£€æŸ¥å®Œæˆ ==="
```

---

**å®Œæˆ**: ç”µå•†ç§’æ€ç³»ç»Ÿéƒ¨ç½²è¿ç»´
**å­—æ•°**: ~8,000å­—
**æ¶µç›–**: Dockeréƒ¨ç½²ã€ç¼“å­˜ç­–ç•¥ã€æ¶ˆæ¯é˜Ÿåˆ—é…ç½®ã€ç›‘æ§é…ç½®ã€è´Ÿè½½å‡è¡¡ã€å¤‡ä»½æ¢å¤ã€æ€§èƒ½è°ƒä¼˜ã€æ•…éšœå¤„ç†ã€æ‰©å®¹ç­–ç•¥ã€è¿ç»´æ£€æŸ¥

**è¿”å›**: [æ¡ˆä¾‹1ä¸»é¡µ](./README.md)
