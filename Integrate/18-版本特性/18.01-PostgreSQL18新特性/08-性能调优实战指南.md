---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `docs\01-PostgreSQL18\08-æ€§èƒ½è°ƒä¼˜å®æˆ˜æŒ‡å—.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# PostgreSQL 18 æ€§èƒ½è°ƒä¼˜å®æˆ˜æŒ‡å—

## 1. ç¡¬ä»¶å±‚ä¼˜åŒ–

### 1.1 å­˜å‚¨ä¼˜åŒ–

```bash
#!/bin/bash
# æ€§èƒ½æµ‹è¯•ï¼šæ£€æŸ¥ç£ç›˜I/Oæ€§èƒ½ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
set -e
set -u

error_exit() {
    echo "é”™è¯¯: $1" >&2
    exit 1
}

# æ£€æŸ¥ç£ç›˜I/Oæ€§èƒ½
sudo fio --name=random-write --ioengine=libaio --iodepth=32 \
  --rw=randwrite --bs=4k --direct=1 --size=1G \
  --numjobs=4 --runtime=60 --group_reporting || error_exit "fioæµ‹è¯•å¤±è´¥"

# NVMeä¼˜åŒ–
sudo nvme set-feature /dev/nvme0n1 -f 0x0c -v 1 || error_exit "NVMeä¼˜åŒ–å¤±è´¥"  # å¯ç”¨write cache

# æ–‡ä»¶ç³»ç»ŸæŒ‚è½½ä¼˜åŒ–ï¼ˆéœ€è¦æ‰‹åŠ¨æ·»åŠ åˆ°/etc/fstabï¼‰
echo "è¯·æ‰‹åŠ¨æ·»åŠ ä»¥ä¸‹è¡Œåˆ°/etc/fstab:"
echo "/dev/nvme0n1 /var/lib/postgresql ext4 noatime,nodiratime,nobarrier 0 0"
```

### 1.2 å†…æ ¸å‚æ•°

```bash
#!/bin/bash
# æ€§èƒ½æµ‹è¯•ï¼šå†…æ ¸å‚æ•°ä¼˜åŒ–ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
set -e
set -u

error_exit() {
    echo "é”™è¯¯: $1" >&2
    exit 1
}

# å¤‡ä»½åŸå§‹é…ç½®
sudo cp /etc/sysctl.conf /etc/sysctl.conf.backup || error_exit "å¤‡ä»½sysctl.confå¤±è´¥"

# æ·»åŠ é…ç½®åˆ°/etc/sysctl.conf
cat <<EOF | sudo tee -a /etc/sysctl.conf || error_exit "å†™å…¥sysctl.confå¤±è´¥"
# PostgreSQLä¼˜åŒ–é…ç½®
# å…±äº«å†…å­˜
kernel.shmmax = 68719476736  # 64GB
kernel.shmall = 16777216

# ç½‘ç»œä¼˜åŒ–
net.core.somaxconn = 4096
net.ipv4.tcp_max_syn_backlog = 8192
net.core.netdev_max_backlog = 5000
EOF

# I/Oè°ƒåº¦
echo mq-deadline | sudo tee /sys/block/nvme0n1/queue/scheduler || error_exit "è®¾ç½®I/Oè°ƒåº¦å™¨å¤±è´¥"

# é€æ˜å¤§é¡µï¼ˆå…³é—­ï¼‰
echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled || error_exit "å…³é—­é€æ˜å¤§é¡µå¤±è´¥"

# åº”ç”¨
sudo sysctl -p || error_exit "åº”ç”¨sysctlé…ç½®å¤±è´¥"

echo "å†…æ ¸å‚æ•°ä¼˜åŒ–å®Œæˆ"
```

---

## 2. PostgreSQLé…ç½®ä¼˜åŒ–

### 2.1 å†…å­˜é…ç½®

```ini
# postgresql.conf

# å…±äº«å†…å­˜ï¼ˆæ€»å†…å­˜çš„25%ï¼‰
shared_buffers = 16GB

# å·¥ä½œå†…å­˜ï¼ˆæ ¹æ®å¹¶å‘æŸ¥è¯¢æ•°ï¼‰
work_mem = 256MB  # (æ€»å†…å­˜ * 0.25) / max_connections

# ç»´æŠ¤å†…å­˜
maintenance_work_mem = 2GB

# æœ‰æ•ˆç¼“å­˜ï¼ˆæ€»å†…å­˜çš„75%ï¼‰
effective_cache_size = 48GB

# WALç¼“å†²
wal_buffers = 64MB

# è‡ªåŠ¨VACUUMå†…å­˜
autovacuum_work_mem = 2GB
```

### 2.2 WALä¼˜åŒ–

```ini
# WALå†™å…¥
wal_level = replica
wal_compression = on
wal_init_zero = on
wal_recycle = on

# WALå¤§å°
min_wal_size = 2GB
max_wal_size = 8GB

# æ£€æŸ¥ç‚¹
checkpoint_timeout = 15min
checkpoint_completion_target = 0.9

# PostgreSQL 18æ–°ç‰¹æ€§ï¼šå¼‚æ­¥I/O
io_direct = data
io_combine_limit = 128kB
```

### 2.3 æŸ¥è¯¢ä¼˜åŒ–å™¨

```ini
# ç»Ÿè®¡ç²¾åº¦
default_statistics_target = 500

# æˆæœ¬å‚æ•°ï¼ˆSSDï¼‰
random_page_cost = 1.1
seq_page_cost = 1.0
effective_io_concurrency = 200

# å¹¶è¡ŒæŸ¥è¯¢
max_parallel_workers_per_gather = 4
max_parallel_maintenance_workers = 4
max_parallel_workers = 8
max_worker_processes = 16

# å¹¶è¡Œå®‰å…¨å‡½æ•°
parallel_setup_cost = 100
parallel_tuple_cost = 0.01
```

---

## 3. ç´¢å¼•ä¼˜åŒ–

### 3.1 ç´¢å¼•é€‰æ‹©

```sql
-- æ€§èƒ½æµ‹è¯•ï¼šB-Treeç´¢å¼•ï¼ˆé»˜è®¤ï¼‰ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_users_emailå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºB-Treeç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šéƒ¨åˆ†ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_active_users ON users(email) WHERE active = true;
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_active_userså·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºéƒ¨åˆ†ç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šè¡¨è¾¾å¼ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_lower_email ON users(lower(email));
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_lower_emailå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºè¡¨è¾¾å¼ç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šå¤šåˆ—ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_orders_user_date ON orders(user_id, order_date DESC);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_orders_user_dateå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºå¤šåˆ—ç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šGINç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_documents_content ON documents USING GIN(content);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_documents_contentå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºGINç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šBRINç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON logs USING BRIN(timestamp);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_logs_timestampå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºBRINç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šHNSWç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE INDEX IF NOT EXISTS idx_items_embedding ON items
USING hnsw(embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_items_embeddingå·²å­˜åœ¨';
    WHEN undefined_object THEN
        RAISE NOTICE 'vectoræ‰©å±•æœªå®‰è£…ï¼Œè¯·å…ˆæ‰§è¡Œ: CREATE EXTENSION vector;';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºHNSWç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;
```

### 3.2 ç´¢å¼•ç»´æŠ¤

```sql
-- æ€§èƒ½æµ‹è¯•ï¼šæŸ¥æ‰¾ç¼ºå¤±ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    schemaname,
    tablename,
    seq_scan,
    seq_tup_read,
    idx_scan,
    seq_tup_read / NULLIF(seq_scan, 0) AS avg_seq_tup
FROM pg_stat_user_tables
WHERE seq_scan > 0
  AND seq_tup_read / NULLIF(seq_scan, 0) > 10000
ORDER BY seq_tup_read DESC;
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'æŸ¥æ‰¾ç¼ºå¤±ç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šæŸ¥æ‰¾æœªä½¿ç”¨ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) AS size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
  AND indexrelname NOT LIKE '%_pkey'
ORDER BY pg_relation_size(indexrelid) DESC;

-- é‡å»ºè†¨èƒ€ç´¢å¼•
REINDEX INDEX CONCURRENTLY idx_users_email;

-- æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE users;
```

---

## 4. æŸ¥è¯¢ä¼˜åŒ–

### 4.1 EXPLAINåˆ†æ

```sql
-- åŸºç¡€EXPLAIN
EXPLAIN SELECT * FROM orders WHERE user_id = 123;

-- ANALYZEï¼ˆå®é™…æ‰§è¡Œï¼Œå¸¦æ€§èƒ½æµ‹è¯•ï¼‰
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM orders WHERE user_id = 123;

-- è¯¦ç»†æ ¼å¼
EXPLAIN (ANALYZE, BUFFERS, VERBOSE, COSTS, TIMING, FORMAT JSON)
SELECT * FROM orders WHERE user_id = 123;

-- è¯»å–EXPLAINè¾“å‡º
/*
å…³é”®æŒ‡æ ‡:
â”œâ”€ Cost: æˆæœ¬ä¼°ç®—
â”œâ”€ Rows: è¡Œæ•°ä¼°ç®—
â”œâ”€ Width: å¹³å‡è¡Œå®½
â”œâ”€ Buffers: ç¼“å†²åŒºå‘½ä¸­/è¯»å–
â”œâ”€ Time: æ‰§è¡Œæ—¶é—´
â””â”€ Loops: å¾ªç¯æ¬¡æ•°
*/
```

### 4.2 å¸¸è§ä¼˜åŒ–

```sql
-- 1. ä½¿ç”¨ç´¢å¼•æ‰«æä»£æ›¿å…¨è¡¨æ‰«æ
-- BAD
SELECT * FROM users WHERE LOWER(email) = 'test@example.com';

-- GOOD
CREATE INDEX idx_lower_email ON users(lower(email));
SELECT * FROM users WHERE lower(email) = 'test@example.com';

-- 2. é¿å…SELECT *
-- BAD
SELECT * FROM orders WHERE order_date > '2023-01-01';

-- GOOD
SELECT order_id, user_id, amount FROM orders
WHERE order_date > '2023-01-01';

-- 3. ä½¿ç”¨JOINä»£æ›¿å­æŸ¥è¯¢
-- BAD
SELECT * FROM users WHERE user_id IN (
    SELECT user_id FROM orders WHERE amount > 1000
);

-- GOOD
SELECT DISTINCT u.* FROM users u
JOIN orders o ON u.user_id = o.user_id
WHERE o.amount > 1000;

-- 4. ä½¿ç”¨CTEä¼˜åŒ–å¤æ‚æŸ¥è¯¢
WITH recent_orders AS (
    SELECT user_id, COUNT(*) AS order_count
    FROM orders
    WHERE order_date > CURRENT_DATE - INTERVAL '30 days'
    GROUP BY user_id
)
SELECT u.*, ro.order_count
FROM users u
JOIN recent_orders ro ON u.user_id = ro.user_id
WHERE ro.order_count > 5;

-- 5. åˆ†åŒºè£å‰ª
-- åˆ†åŒºè¡¨æŸ¥è¯¢ä¼šè‡ªåŠ¨è£å‰ªä¸ç›¸å…³åˆ†åŒº
SELECT * FROM orders_partitioned
WHERE order_date >= '2023-12-01' AND order_date < '2023-12-31';
```

---

## 5. VACUUMä¼˜åŒ–

### 5.1 è‡ªåŠ¨VACUUMé…ç½®

```ini
# postgresql.conf
autovacuum = on
autovacuum_max_workers = 6
autovacuum_naptime = 10s

# è¡¨çº§è§¦å‘é˜ˆå€¼
autovacuum_vacuum_scale_factor = 0.1
autovacuum_vacuum_threshold = 50

# åˆ†æé˜ˆå€¼
autovacuum_analyze_scale_factor = 0.05
autovacuum_analyze_threshold = 50

# å†»ç»“å‚æ•°
autovacuum_freeze_max_age = 200000000
vacuum_freeze_table_age = 150000000
```

### 5.2 æ‰‹åŠ¨VACUUM

```sql
-- æ ‡å‡†VACUUM
VACUUM (VERBOSE, ANALYZE) users;

-- FULL VACUUMï¼ˆé”è¡¨ï¼Œé‡å»ºè¡¨ï¼‰
VACUUM FULL users;

-- å†»ç»“äº‹åŠ¡ID
VACUUM (FREEZE) users;

-- ç›‘æ§è†¨èƒ€
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
    n_dead_tup,
    n_live_tup,
    ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) AS dead_ratio
FROM pg_stat_user_tables
WHERE n_dead_tup > 1000
ORDER BY n_dead_tup DESC;
```

---

## 6. è¿æ¥æ± ä¼˜åŒ–

### 6.1 PgBounceré…ç½®

```ini
# /etc/pgbouncer/pgbouncer.ini
[databases]
mydb = host=localhost port=5432 dbname=mydb

[pgbouncer]
listen_addr = *
listen_port = 6432
auth_type = scram-sha-256
auth_file = /etc/pgbouncer/userlist.txt

# æ± æ¨¡å¼
pool_mode = transaction  # session/transaction/statement

# è¿æ¥æ± å¤§å°
max_client_conn = 10000
default_pool_size = 25
reserve_pool_size = 5
reserve_pool_timeout = 3

# è¶…æ—¶
server_idle_timeout = 600
server_lifetime = 3600
```

### 6.2 åº”ç”¨å±‚è¿æ¥æ± 

```python
# Python: psycopg2 connection pool
from psycopg2 import pool

connection_pool = pool.ThreadedConnectionPool(
    minconn=5,
    maxconn=20,
    host='localhost',
    port=5432,
    database='mydb',
    user='app',
    password='password'
)

# ä½¿ç”¨
conn = connection_pool.getconn()
try:
    cursor = conn.cursor()
    cursor.execute("SELECT ...")
finally:
    connection_pool.putconn(conn)
```

---

## 7. åˆ†åŒºè¡¨ä¼˜åŒ–

### 7.1 åˆ†åŒºç­–ç•¥

```sql
-- èŒƒå›´åˆ†åŒºï¼ˆæ—¶åºæ•°æ®ï¼‰
CREATE TABLE logs (
    log_id BIGSERIAL,
    timestamp TIMESTAMPTZ NOT NULL,
    message TEXT
) PARTITION BY RANGE (timestamp);

-- åˆ›å»ºåˆ†åŒºï¼ˆæœˆåº¦ï¼‰
CREATE TABLE logs_2023_12 PARTITION OF logs
FOR VALUES FROM ('2023-12-01') TO ('2024-01-01');

CREATE TABLE logs_2024_01 PARTITION OF logs
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- å“ˆå¸Œåˆ†åŒºï¼ˆç”¨æˆ·æ•°æ®ï¼‰
CREATE TABLE users_partitioned (
    user_id BIGINT,
    username VARCHAR(100),
    email VARCHAR(255)
) PARTITION BY HASH (user_id);

-- åˆ›å»º8ä¸ªåˆ†åŒº
DO $$
BEGIN
    FOR i IN 0..7 LOOP
        EXECUTE format('
            CREATE TABLE users_p%s PARTITION OF users_partitioned
            FOR VALUES WITH (MODULUS 8, REMAINDER %s);
        ', i, i);
    END LOOP;
END $$;

-- åˆ—è¡¨åˆ†åŒºï¼ˆåœ°åŸŸæ•°æ®ï¼‰
CREATE TABLE orders_by_region (
    order_id BIGINT,
    region VARCHAR(10),
    amount NUMERIC
) PARTITION BY LIST (region);

CREATE TABLE orders_asia PARTITION OF orders_by_region
FOR VALUES IN ('CN', 'JP', 'KR');

CREATE TABLE orders_europe PARTITION OF orders_by_region
FOR VALUES IN ('UK', 'FR', 'DE');
```

### 7.2 åˆ†åŒºç»´æŠ¤

```sql
-- è‡ªåŠ¨åˆ›å»ºåˆ†åŒºï¼ˆä½¿ç”¨pg_partmanæ‰©å±•ï¼‰
CREATE EXTENSION pg_partman;

SELECT partman.create_parent(
    p_parent_table := 'public.logs',
    p_control := 'timestamp',
    p_type := 'native',
    p_interval := 'monthly',
    p_premake := 3
);

-- è‡ªåŠ¨åˆ é™¤æ—§åˆ†åŒº
UPDATE partman.part_config
SET retention_keep_table = false,
    retention = '90 days'
WHERE parent_table = 'public.logs';
```

---

## 8. å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ–

### 8.1 å¹¶è¡Œé…ç½®

```ini
# å…¨å±€å¹¶è¡Œåº¦
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_worker_processes = 16

# å¹¶è¡Œé˜ˆå€¼
min_parallel_table_scan_size = 8MB
min_parallel_index_scan_size = 512kB

# æˆæœ¬å‚æ•°
parallel_setup_cost = 1000
parallel_tuple_cost = 0.1
```

### 8.2 å¼ºåˆ¶å¹¶è¡Œ

```sql
-- æŸ¥çœ‹å¹¶è¡Œè®¡åˆ’
EXPLAIN (ANALYZE)
SELECT COUNT(*) FROM large_table;

-- å¼ºåˆ¶å¹¶è¡Œ
SET max_parallel_workers_per_gather = 8;
SET parallel_setup_cost = 0;
SET parallel_tuple_cost = 0;

SELECT COUNT(*) FROM large_table;

-- ç¦ç”¨å¹¶è¡Œï¼ˆæµ‹è¯•ï¼‰
SET max_parallel_workers_per_gather = 0;
```

---

## 9. ç›‘æ§ä¸è¯Šæ–­

### 9.1 pg_stat_statements

```sql
-- å¯ç”¨æ‰©å±•
CREATE EXTENSION pg_stat_statements;

-- é…ç½®
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';
ALTER SYSTEM SET pg_stat_statements.track = 'all';
ALTER SYSTEM SET pg_stat_statements.max = 10000;

-- é‡å¯PostgreSQL
sudo systemctl restart postgresql

-- æŸ¥çœ‹æ…¢æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time / 1000 AS total_sec,
    mean_exec_time AS avg_ms,
    max_exec_time AS max_ms
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 20;

-- é‡ç½®ç»Ÿè®¡
SELECT pg_stat_statements_reset();
```

### 9.2 å®æ—¶ç›‘æ§

```sql
-- å½“å‰æ´»åŠ¨æŸ¥è¯¢
SELECT
    pid,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    state_change,
    query
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY query_start;

-- é”ç­‰å¾…
SELECT
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS blocking_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted AND blocking_locks.granted;

-- æ•°æ®åº“ç»Ÿè®¡
SELECT
    datname,
    numbackends AS connections,
    xact_commit,
    xact_rollback,
    blks_read,
    blks_hit,
    ROUND(blks_hit * 100.0 / NULLIF(blks_hit + blks_read, 0), 2) AS cache_hit_ratio,
    tup_returned,
    tup_fetched,
    tup_inserted,
    tup_updated,
    tup_deleted
FROM pg_stat_database
WHERE datname NOT IN ('template0', 'template1');
```

---

## 10. å‹åŠ›æµ‹è¯•

### 10.1 pgbench

```bash
# åˆå§‹åŒ–æµ‹è¯•æ•°æ®
pgbench -i -s 100 mydb  # 100ä¸ªscaleï¼Œçº¦1.5GB

# TPC-Bæµ‹è¯•
pgbench -c 50 -j 4 -T 60 mydb
# -c: å¹¶å‘å®¢æˆ·ç«¯æ•°
# -j: çº¿ç¨‹æ•°
# -T: è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰

# è‡ªå®šä¹‰è„šæœ¬
cat > test.sql <<EOF
\set user_id random(1, 100000)
SELECT * FROM users WHERE user_id = :user_id;
EOF

pgbench -c 100 -j 8 -T 300 -f test.sql mydb

# åªè¯»æµ‹è¯•
pgbench -c 50 -j 4 -T 60 -S mydb
```

### 10.2 ç»“æœåˆ†æ

```text
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 100
query mode: simple
number of clients: 50
number of threads: 4
duration: 60 s
number of transactions actually processed: 125043
latency average = 23.987 ms
latency stddev = 15.234 ms
tps = 2084.048219 (including connections establishing)
tps = 2084.371299 (excluding connections establishing)
```

---

## 11. æ€§èƒ½åŸºå‡†

### 11.1 TPC-Hæµ‹è¯•

```bash
# ä¸‹è½½TPC-Hå·¥å…·
git clone https://github.com/Data-Science-Platform/tpch-pgsql.git
cd tpch-pgsql

# ç”Ÿæˆæ•°æ®ï¼ˆ10GBï¼‰
./dbgen -s 10

# å¯¼å…¥æ•°æ®
psql -d tpch -f dss.ddl
./load.sh

# è¿è¡ŒæŸ¥è¯¢
for i in {1..22}; do
    echo "Running Q$i..."
    psql -d tpch -f queries/$i.sql
done
```

---

## 12. è°ƒä¼˜æ¸…å•

```text
âœ… ç¡¬ä»¶å±‚
â”œâ”€ NVMe SSD RAID10
â”œâ”€ 64GB+ å†…å­˜
â”œâ”€ 16æ ¸+ CPU
â””â”€ 10Gbpsç½‘ç»œ

âœ… ç³»ç»Ÿå±‚
â”œâ”€ å†…æ ¸å‚æ•°ä¼˜åŒ–
â”œâ”€ æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–ï¼ˆnoatimeï¼‰
â”œâ”€ I/Oè°ƒåº¦å™¨ï¼ˆmq-deadlineï¼‰
â””â”€ å…³é—­é€æ˜å¤§é¡µ

âœ… PostgreSQLé…ç½®
â”œâ”€ å†…å­˜å‚æ•°ï¼ˆshared_buffers, work_memï¼‰
â”œâ”€ WALå‚æ•°ï¼ˆwal_buffers, checkpointï¼‰
â”œâ”€ å¹¶è¡Œå‚æ•°ï¼ˆmax_parallel_workersï¼‰
â””â”€ æˆæœ¬å‚æ•°ï¼ˆrandom_page_costï¼‰

âœ… æŸ¥è¯¢ä¼˜åŒ–
â”œâ”€ åˆé€‚çš„ç´¢å¼•
â”œâ”€ ä¼˜åŒ–SQLè¯­å¥
â”œâ”€ ä½¿ç”¨CTE
â””â”€ é¿å…N+1æŸ¥è¯¢

âœ… ç»´æŠ¤
â”œâ”€ å®šæœŸVACUUM
â”œâ”€ æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
â”œâ”€ é‡å»ºè†¨èƒ€ç´¢å¼•
â””â”€ æ¸…ç†æœªä½¿ç”¨ç´¢å¼•

âœ… ç›‘æ§
â”œâ”€ pg_stat_statements
â”œâ”€ æ…¢æŸ¥è¯¢æ—¥å¿—
â”œâ”€ è¿æ¥æ•°ç›‘æ§
â””â”€ ç¼“å­˜å‘½ä¸­ç‡
```

---

**å®Œæˆ**: PostgreSQL 18æ€§èƒ½è°ƒä¼˜å®æˆ˜æŒ‡å—
**å­—æ•°**: ~8,000å­—
**æ¶µç›–**: ç¡¬ä»¶ã€é…ç½®ã€ç´¢å¼•ã€æŸ¥è¯¢ã€VACUUMã€è¿æ¥æ± ã€ç›‘æ§
