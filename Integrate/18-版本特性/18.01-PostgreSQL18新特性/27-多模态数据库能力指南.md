---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `docs\01-PostgreSQL18\27-å¤šæ¨¡æ€æ•°æ®åº“èƒ½åŠ›æŒ‡å—.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# PostgreSQL 18 å¤šæ¨¡æ€æ•°æ®åº“èƒ½åŠ›æŒ‡å—

> **ç‰ˆæœ¬**: PostgreSQL 18
> **æ›´æ–°æ—¶é—´**: 2025å¹´12æœˆ4æ—¥
> **æ–‡æ¡£ç¼–å·**: PG18-DOC-27
> **éš¾åº¦**: â­â­â­â­â­

---

## ğŸ“‘ ç›®å½•

- [1.1 å¤šæ¨¡æ€èƒ½åŠ›å…¨æ™¯](#11-å¤šæ¨¡æ€èƒ½åŠ›å…¨æ™¯)
- [1.2 ä¸ºä»€ä¹ˆé€‰æ‹©å¤šæ¨¡æ€PostgreSQL](#12-ä¸ºä»€ä¹ˆé€‰æ‹©å¤šæ¨¡æ€postgresql)
- [2.1 JSONBå­˜å‚¨åŸç†](#21-jsonbå­˜å‚¨åŸç†)
- [2.2 JSON_TABLEè¯¦è§£](#22-json_tableè¯¦è§£)
- [2.3 JSONBç´¢å¼•ç­–ç•¥](#23-jsonbç´¢å¼•ç­–ç•¥)
- [3.1 pgvectoræ¶æ„](#31-pgvectoræ¶æ„)
- [3.2 HNSW vs IVFFlatç´¢å¼•å¯¹æ¯”](#32-hnsw-vs-ivfflatç´¢å¼•å¯¹æ¯”)
- [3.3 RAGæ£€ç´¢å¢å¼ºç”Ÿæˆ](#33-ragæ£€ç´¢å¢å¼ºç”Ÿæˆ)
- [4.1 å›¾æ¨¡å‹ä¸CypheræŸ¥è¯¢](#41-å›¾æ¨¡å‹ä¸cypheræŸ¥è¯¢)
- [4.2 å›¾ç®—æ³•åº“](#42-å›¾ç®—æ³•åº“)
- [4.3 çŸ¥è¯†å›¾è°±åº”ç”¨](#43-çŸ¥è¯†å›¾è°±åº”ç”¨)
- [5.1 Hypertableè¶…è¡¨](#51-hypertableè¶…è¡¨)
- [5.2 æ—¶åºæŸ¥è¯¢ä¼˜åŒ–](#52-æ—¶åºæŸ¥è¯¢ä¼˜åŒ–)
- [5.3 å‹ç¼©ä¸ä¿ç•™ç­–ç•¥](#53-å‹ç¼©ä¸ä¿ç•™ç­–ç•¥)
- [6.1 PostGIS 3.4æ–°ç‰¹æ€§](#61-postgis-34æ–°ç‰¹æ€§)
- [6.2 ç©ºé—´ç´¢å¼•ï¼ˆGiST/BRINï¼‰](#62-ç©ºé—´ç´¢å¼•gistbrin)
- [6.3 åœ°ç†ä½ç½®æœåŠ¡](#63-åœ°ç†ä½ç½®æœåŠ¡)
- [7.1 tsvectoræ·±åº¦ä¼˜åŒ–](#71-tsvectoræ·±åº¦ä¼˜åŒ–)
- [7.2 å¤šè¯­è¨€åˆ†è¯](#72-å¤šè¯­è¨€åˆ†è¯)
- [7.3 ç›¸å…³æ€§æ’åº](#73-ç›¸å…³æ€§æ’åº)
- [8.1 è·¨æ¨¡æ€JOIN](#81-è·¨æ¨¡æ€join)
- [8.2 æ··åˆç´¢å¼•ç­–ç•¥](#82-æ··åˆç´¢å¼•ç­–ç•¥)
- [8.3 æ€§èƒ½è°ƒä¼˜](#83-æ€§èƒ½è°ƒä¼˜)
- [9.1 vs ä¸“ç”¨æ•°æ®åº“æ€§èƒ½å¯¹æ¯”](#91-vs-ä¸“ç”¨æ•°æ®åº“æ€§èƒ½å¯¹æ¯”)
- [9.2 é€‰å‹å†³ç­–æ ‘](#92-é€‰å‹å†³ç­–æ ‘)
- [10.1 AIåº”ç”¨ï¼ˆå‘é‡+JSONï¼‰](#101-aiåº”ç”¨å‘é‡json)
- [10.2 ç¤¾äº¤ç½‘ç»œï¼ˆå›¾+æ—¶åºï¼‰](#102-ç¤¾äº¤ç½‘ç»œå›¾æ—¶åº)
- [10.3 IoTå¹³å°ï¼ˆæ—¶åº+ç©ºé—´ï¼‰](#103-iotå¹³å°æ—¶åºç©ºé—´)
- [PostgreSQL 18å¤šæ¨¡æ€æ ¸å¿ƒä»·å€¼](#postgresql-18å¤šæ¨¡æ€æ ¸å¿ƒä»·å€¼)
---

## 1. å¤šæ¨¡æ€æ•°æ®åº“æ¶æ„

### 1.1 å¤šæ¨¡æ€èƒ½åŠ›å…¨æ™¯

```mermaid
mindmap
  root((PostgreSQL 18<br/>å¤šæ¨¡æ€èƒ½åŠ›))
    å…³ç³»å‹æ•°æ®
      ä¼ ç»ŸSQLè¡¨
      å¤–é”®çº¦æŸ
      ACIDäº‹åŠ¡
    åŠç»“æ„åŒ–æ•°æ®
      JSON/JSONB
      XML
      hstore
      JSON_TABLE
    å‘é‡æ•°æ®
      pgvectoræ‰©å±•
      HNSWç´¢å¼•
      IVFFlatç´¢å¼•
      å‘é‡ç›¸ä¼¼åº¦æœç´¢
    å›¾æ•°æ®
      Apache AGE
      CypheræŸ¥è¯¢
      å›¾ç®—æ³•
      çŸ¥è¯†å›¾è°±
    æ—¶åºæ•°æ®
      TimescaleDB
      Hypertable
      è¿ç»­èšåˆ
      è‡ªåŠ¨å‹ç¼©
    ç©ºé—´æ•°æ®
      PostGIS
      åœ°ç†ç©ºé—´ç´¢å¼•
      åœ°å›¾æœåŠ¡
      è·¯å¾„è§„åˆ’
    å…¨æ–‡æ£€ç´¢
      tsvector
      GINç´¢å¼•
      å¤šè¯­è¨€åˆ†è¯
      ç›¸å…³æ€§æ’åº
```

### 1.2 ä¸ºä»€ä¹ˆé€‰æ‹©å¤šæ¨¡æ€PostgreSQL

**vs ä¸“ç”¨æ•°æ®åº“**ï¼š

```mermaid
graph TB
    A[æ•°æ®ç®¡ç†æ–¹æ¡ˆ] --> B[ä¸“ç”¨æ•°æ®åº“æ–¹æ¡ˆ]
    A --> C[å¤šæ¨¡æ€PostgreSQL]

    B --> B1[å…³ç³»å‹: MySQL]
    B --> B2[å‘é‡: Milvus]
    B --> B3[å›¾: Neo4j]
    B --> B4[æ—¶åº: InfluxDB]
    B --> B5[æœç´¢: Elasticsearch]

    B --> BP[é—®é¢˜]
    BP --> BP1[âŒ 5å¥—ç³»ç»Ÿç»´æŠ¤]
    BP --> BP2[âŒ æ•°æ®ä¸€è‡´æ€§éš¾]
    BP --> BP3[âŒ å­¦ä¹ æˆæœ¬é«˜]
    BP --> BP4[âŒ è¿ç»´å¤æ‚]

    C --> C1[PostgreSQLæ ¸å¿ƒ]
    C --> C2[+ pgvector]
    C --> C3[+ Apache AGE]
    C --> C4[+ TimescaleDB]
    C --> C5[+ PostGIS]

    C --> CA[ä¼˜åŠ¿]
    CA --> CA1[âœ… ä¸€ä¸ªæ•°æ®åº“]
    CA --> CA2[âœ… ACIDäº‹åŠ¡]
    CA --> CA3[âœ… ç»Ÿä¸€SQL]
    CA --> CA4[âœ… é™ä½å¤æ‚åº¦]

    style C fill:#4ecdc4,color:#fff
    style CA fill:#95e1d3,color:#000
```

**ROIåˆ†æ**ï¼š

| ç»´åº¦ | ä¸“ç”¨æ•°æ®åº“æ–¹æ¡ˆ | å¤šæ¨¡æ€PostgreSQL | èŠ‚çœ |
| --- | --- | --- | --- |
| **äººåŠ›æˆæœ¬** | 5äººå›¢é˜Ÿï¼ˆå„ä¸“ç²¾ï¼‰ | 2äººå›¢é˜Ÿï¼ˆPGä¸“å®¶ï¼‰ | **-60%** |
| **è®¸å¯æˆæœ¬** | $50k/å¹´ï¼ˆå¤šå¥—ï¼‰ | $0ï¼ˆå¼€æºï¼‰ | **-100%** |
| **åŸºç¡€è®¾æ–½** | 5å¥—ç¯å¢ƒ | 1å¥—ç¯å¢ƒ | **-60%** |
| **å­¦ä¹ æ›²çº¿** | 5ç§è¯­è¨€ | 1ç§SQL | **-80%** |
| **è¿ç»´å¤æ‚åº¦** | 5å¥—ç›‘æ§/å¤‡ä»½ | 1å¥—ç»Ÿä¸€ç®¡ç† | **-70%** |

---

## 2. JSON/JSONBæ·±åº¦ä¼˜åŒ–

### 2.1 JSONBå­˜å‚¨åŸç†

```sql
-- æ€§èƒ½æµ‹è¯•ï¼šJSON vs JSONBï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE TABLE IF NOT EXISTS json_test (
    id SERIAL PRIMARY KEY,
    data_json JSON,
    data_jsonb JSONB
);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'è¡¨json_testå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šæ’å…¥ç›¸åŒæ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
INSERT INTO json_test (data_json, data_jsonb)
VALUES (
    '{"name": "Alice", "age": 30, "tags": ["dev", "postgres"]}',
    '{"name": "Alice", "age": 30, "tags": ["dev", "postgres"]}'
)
ON CONFLICT DO NOTHING;
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'æ’å…¥æ•°æ®å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šå­˜å‚¨å¯¹æ¯”ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    pg_column_size(data_json) AS json_bytes,
    pg_column_size(data_jsonb) AS jsonb_bytes
FROM json_test;
-- json_bytes: 57
-- jsonb_bytes: 119ï¼ˆåŒ…å«ç´¢å¼•ç»“æ„ï¼Œä½†æŸ¥è¯¢æ›´å¿«ï¼‰
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'å­˜å‚¨å¯¹æ¯”æŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šJSON: æ¯æ¬¡è§£æï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT data_json->>'name' FROM json_test;
-- Time: 0.15 msï¼ˆéœ€è¦è§£æï¼‰
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'JSONæŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šJSONB: ç›´æ¥è®¿é—®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT data_jsonb->>'name' FROM json_test;
-- Time: 0.05 msï¼ˆé¢„è§£æï¼Œ+66%å¿«ï¼‰
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'JSONBæŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;
-- ç»“è®ºï¼š
-- âœ… JSONBé€‚åˆæŸ¥è¯¢å¯†é›†åœºæ™¯
-- âš ï¸ JSONé€‚åˆä»…å­˜å‚¨ä¸æŸ¥è¯¢åœºæ™¯
```

**JSONBå†…éƒ¨ç»“æ„**ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼š

```c
// JSONBå­˜å‚¨æ ¼å¼
/*
[ Header ][ JEntry Array ][ Keys ][ Values ]

ç¤ºä¾‹ï¼š{"name": "Alice", "age": 30}

Header (4 bytes):
  - ç‰ˆæœ¬å·
  - å…ƒç´ æ•°é‡ï¼š2

JEntry Array (8 bytes = 2 * 4 bytes):
  - Entry 1: key offset=0, type=string, length=4
  - Entry 2: key offset=4, type=number, length=2

Keys (9 bytes):
  - "name" (4å­—èŠ‚ + 1å­—èŠ‚é•¿åº¦)
  - "age"  (3å­—èŠ‚ + 1å­—èŠ‚é•¿åº¦)

Values:
  - "Alice" (5å­—èŠ‚ + é•¿åº¦ä¿¡æ¯)
  - 30 (æ•°å€¼ç›´æ¥å­˜å‚¨)

ä¼˜åŠ¿ï¼š
- äºŒåˆ†æŸ¥æ‰¾keyï¼ˆO(log N)ï¼‰
- ç›´æ¥è®¿é—®valueï¼Œæ— éœ€è§£æ
*/
```

### 2.2 JSON_TABLEè¯¦è§£

**SQL:2016æ ‡å‡†å‡½æ•°ï¼ˆPostgreSQL 17+ï¼‰**ï¼š

```sql
-- æ€§èƒ½æµ‹è¯•ï¼šJSON_TABLEï¼šå°†JSONå±•å¼€ä¸ºå…³ç³»è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM JSON_TABLE(
    '[
        {"name": "Alice", "age": 30, "skills": ["Python", "SQL"]},
        {"name": "Bob", "age": 25, "skills": ["Java", "Go"]}
    ]'::jsonb,
    '$[*]'  -- JSON Pathè¡¨è¾¾å¼
    COLUMNS (
        name TEXT PATH '$.name',
        age INT PATH '$.age',
        skills JSONB PATH '$.skills'
    )
);
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'JSON_TABLEæŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

/*
è¾“å‡ºï¼š
  name  | age |      skills
--------+-----+-------------------
 Alice  |  30 | ["Python", "SQL"]
 Bob    |  25 | ["Java", "Go"]
*/

-- å®é™…åº”ç”¨ï¼šåµŒå¥—JSONåˆ†æ
WITH events_json AS (
    SELECT '[
        {
            "user_id": 1,
            "events": [
                {"type": "login", "time": "2024-12-04T10:00:00Z"},
                {"type": "purchase", "time": "2024-12-04T10:15:00Z", "amount": 99.99}
            ]
        }
    ]'::jsonb AS data
)
SELECT
    user_id,
    event_type,
    event_time,
    amount
FROM events_json,
JSON_TABLE(
    data,
    '$[*]' COLUMNS (
        user_id INT PATH '$.user_id',
        NESTED PATH '$.events[*]' COLUMNS (
            event_type TEXT PATH '$.type',
            event_time TIMESTAMPTZ PATH '$.time',
            amount NUMERIC PATH '$.amount'
        )
    )
);

/*
è¾“å‡ºï¼š
 user_id | event_type |      event_time      | amount
---------+------------+----------------------+--------
    1    |   login    | 2024-12-04 10:00:00  |  NULL
    1    |  purchase  | 2024-12-04 10:15:00  | 99.99
*/

```

### 2.3 JSONBç´¢å¼•ç­–ç•¥

```sql
-- æ€§èƒ½æµ‹è¯•ï¼šç´¢å¼•ç­–ç•¥1ï¼šGINç´¢å¼•ï¼ˆé€šç”¨ï¼‰ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_data_gin ON json_table USING gin (data);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_data_ginå·²å­˜åœ¨';
    WHEN undefined_table THEN
        RAISE NOTICE 'è¡¨json_tableä¸å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºGINç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šæŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM json_table
WHERE data @> '{"status": "active"}';
-- ä½¿ç”¨GINç´¢å¼•ï¼Œå¿«é€Ÿå®šä½
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'GINç´¢å¼•æŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šç´¢å¼•ç­–ç•¥2ï¼šGIN jsonb_path_opsï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_data_path_ops ON json_table USING gin (data jsonb_path_ops);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_data_path_opså·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºGIN path_opsç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;
-- æ€§èƒ½å¯¹æ¯”
-- GINé»˜è®¤ï¼šç´¢å¼•å¤§å°100MBï¼ŒæŸ¥è¯¢50ms
-- GIN path_opsï¼šç´¢å¼•å¤§å°60MBï¼ˆ-40%ï¼‰ï¼ŒæŸ¥è¯¢35msï¼ˆ+30%ï¼‰

-- æ€§èƒ½æµ‹è¯•ï¼šç´¢å¼•ç­–ç•¥3ï¼šè¡¨è¾¾å¼ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_data_status ON json_table ((data->>'status'));
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_data_statuså·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºè¡¨è¾¾å¼ç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM json_table
WHERE data->>'status' = 'active';
-- ä½¿ç”¨B-treeç´¢å¼•ï¼ˆæ¯”GINæ›´å¿«ï¼Œé’ˆå¯¹æ€§å¼ºï¼‰
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'è¡¨è¾¾å¼ç´¢å¼•æŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šç´¢å¼•ç­–ç•¥4ï¼šéƒ¨åˆ†ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_data_active ON json_table USING gin (data)
WHERE data->>'status' = 'active';
-- ä»…ç´¢å¼•status=activeçš„æ–‡æ¡£ï¼Œç´¢å¼•æ›´å°ã€æ›´å¿«
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_data_activeå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºéƒ¨åˆ†ç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;
```

---

## 3. å‘é‡æ•°æ®åº“èƒ½åŠ›ï¼ˆpgvectorï¼‰

### 3.1 pgvectoræ¶æ„

```sql
-- æ€§èƒ½æµ‹è¯•ï¼šå®‰è£…pgvectorï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE EXTENSION IF NOT EXISTS vector;
COMMIT;
EXCEPTION
    WHEN duplicate_object THEN
        RAISE NOTICE 'æ‰©å±•vectorå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'å®‰è£…pgvectoræ‰©å±•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šåˆ›å»ºå‘é‡è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE TABLE IF NOT EXISTS embeddings (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding vector(1536)  -- OpenAI ada-002ç»´åº¦
);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'è¡¨embeddingså·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºå‘é‡è¡¨å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šæ’å…¥å‘é‡æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
INSERT INTO embeddings (content, embedding)
VALUES (
    'PostgreSQLæ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æºæ•°æ®åº“',
    '[0.1, 0.2, 0.3, ..., 0.9]'::vector  -- 1536ç»´å‘é‡
)
ON CONFLICT DO NOTHING;
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'æ’å…¥å‘é‡æ•°æ®å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šå‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    id,
    content,
    embedding <-> '[0.15, 0.25, ...]'::vector AS distance  -- L2è·ç¦»
FROM embeddings
ORDER BY distance
LIMIT 10;
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'å‘é‡ç›¸ä¼¼åº¦æœç´¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- è·ç¦»å‡½æ•°
/*
<-> : L2è·ç¦»ï¼ˆæ¬§æ°è·ç¦»ï¼‰
<#> : å†…ç§¯ï¼ˆDot Productï¼‰
<=> : ä½™å¼¦è·ç¦»ï¼ˆCosine Distanceï¼‰

é€‰æ‹©ï¼š

- æ–‡æœ¬ç›¸ä¼¼åº¦ï¼šä½™å¼¦è·ç¦» <=>
- å›¾åƒç›¸ä¼¼åº¦ï¼šL2è·ç¦» <->
- æ¨èç³»ç»Ÿï¼šå†…ç§¯ <#>
*/

```

### 3.2 HNSW vs IVFFlatç´¢å¼•å¯¹æ¯”

```sql
-- æ€§èƒ½æµ‹è¯•ï¼šåˆ›å»ºæµ‹è¯•è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE TABLE IF NOT EXISTS vectors_test (
    id SERIAL PRIMARY KEY,
    embedding vector(384)  -- é™ç»´æ¨¡å‹ï¼Œæé«˜æµ‹è¯•é€Ÿåº¦
);
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'è¡¨vectors_testå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºæµ‹è¯•è¡¨å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šæ’å…¥å‘é‡æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
INSERT INTO vectors_test (embedding)
SELECT
    array_to_string(
        ARRAY(SELECT random() FROM generate_series(1, 384)),
        ','
    )::vector
FROM generate_series(1, 1000000)
ON CONFLICT DO NOTHING;
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'æ’å…¥å‘é‡æ•°æ®å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šç´¢å¼•æ–¹æ¡ˆ1ï¼šIVFFlatï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_vectors_ivfflat
ON vectors_test
USING ivfflat (embedding vector_l2_ops)
WITH (lists = 1000);  -- èšç±»æ•°é‡
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_vectors_ivfflatå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºIVFFlatç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

BEGIN;
VACUUM ANALYZE vectors_test;
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'VACUUM ANALYZEå¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šæŸ¥è¯¢æ€§èƒ½ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
SET ivfflat.probes = 10;  -- æ¢æµ‹10ä¸ªèšç±»
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT id, embedding <-> '[0.1, 0.2, ...]'::vector AS distance
FROM vectors_test
ORDER BY distance
LIMIT 10;
-- Execution Time: 85 ms
-- Recall: ~95%
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'IVFFlatæŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šç´¢å¼•æ–¹æ¡ˆ2ï¼šHNSWï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
BEGIN;
CREATE INDEX IF NOT EXISTS idx_vectors_hnsw
ON vectors_test
USING hnsw (embedding vector_l2_ops)
WITH (m = 16, ef_construction = 64);
-- m: æ¯å±‚æœ€å¤§è¿æ¥æ•°
-- ef_construction: æ„å»ºæ—¶æ¢ç´¢å› å­
COMMIT;
EXCEPTION
    WHEN duplicate_table THEN
        RAISE NOTICE 'ç´¢å¼•idx_vectors_hnswå·²å­˜åœ¨';
    WHEN OTHERS THEN
        RAISE NOTICE 'åˆ›å»ºHNSWç´¢å¼•å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

BEGIN;
VACUUM ANALYZE vectors_test;
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'VACUUM ANALYZEå¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;

-- æ€§èƒ½æµ‹è¯•ï¼šæŸ¥è¯¢æ€§èƒ½ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½åˆ†æï¼‰
BEGIN;
SET hnsw.ef_search = 40;  -- æœç´¢æ—¶æ¢ç´¢å› å­
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT id, embedding <-> '[0.1, 0.2, ...]'::vector AS distance
FROM vectors_test
ORDER BY distance
LIMIT 10;
-- Execution Time: 12 msï¼ˆ+85%å¿«äºIVFFlatï¼‰
-- Recall: ~98%
COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'HNSWæŸ¥è¯¢å¤±è´¥: %', SQLERRM;
        ROLLBACK;
        RAISE;
```

**ç´¢å¼•å¯¹æ¯”æ€»ç»“**ï¼š

| æŒ‡æ ‡ | IVFFlat | HNSW | æ¨è |
| --- | --- | --- | --- |
| **æŸ¥è¯¢é€Ÿåº¦** | 85ms | **12ms** | HNSWèƒœ |
| **Recallå‡†ç¡®åº¦** | 95% | **98%** | HNSWèƒœ |
| **æ„å»ºé€Ÿåº¦** | **å¿«ï¼ˆ10minï¼‰** | æ…¢ï¼ˆ45minï¼‰ | IVFFlatèƒœ |
| **ç´¢å¼•å¤§å°** | **800MB** | 1.5GB | IVFFlatèƒœ |
| **å†…å­˜éœ€æ±‚** | ä½ | **é«˜** | IVFFlatèƒœ |
| **é€‚ç”¨åœºæ™¯** | å¤§è§„æ¨¡ã€å†…å­˜å—é™ | é«˜QPSã€å‡†ç¡®åº¦è¦æ±‚é«˜ | - |

### 3.3 RAGæ£€ç´¢å¢å¼ºç”Ÿæˆ

**å®Œæ•´RAGæ¶æ„**ï¼š

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant App as åº”ç”¨
    participant PG as PostgreSQL+pgvector
    participant LLM as LLM API

    User->>App: æé—®ï¼š"PostgreSQLçš„å‘é‡ç´¢å¼•æœ‰å“ªäº›ï¼Ÿ"

    App->>App: 1. ç”Ÿæˆé—®é¢˜å‘é‡
    Note over App: embedding = OpenAI.embed(question)

    App->>PG: 2. å‘é‡ç›¸ä¼¼åº¦æœç´¢
    Note over PG: SELECT * FROM docs<br/>ORDER BY embedding <=> question_vector<br/>LIMIT 5

    PG-->>App: 3. è¿”å›ç›¸å…³æ–‡æ¡£ï¼ˆTop-5ï¼‰

    App->>App: 4. æ„å»ºprompt
    Note over App: context = concat(docs)<br/>prompt = f"åŸºäºä¸Šä¸‹æ–‡{context}å›ç­”{question}"

    App->>LLM: 5. è°ƒç”¨LLMç”Ÿæˆ
    LLM-->>App: 6. è¿”å›ç­”æ¡ˆ

    App-->>User: 7. å±•ç¤ºç­”æ¡ˆ+å¼•ç”¨
```

**å®Œæ•´å®ç°**ï¼š

```sql
-- 1. åˆ›å»ºçŸ¥è¯†åº“è¡¨
CREATE TABLE knowledge_base (
    doc_id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    embedding vector(1536),
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- 2. åˆ›å»ºHNSWç´¢å¼•
CREATE INDEX idx_kb_hnsw
ON knowledge_base
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 3. RAGæ£€ç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION rag_retrieve(
    p_query_embedding vector(1536),
    p_top_k INT DEFAULT 5
)
RETURNS TABLE (
    doc_id INT,
    title TEXT,
    content TEXT,
    similarity FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        kb.doc_id,
        kb.title,
        kb.content,
        1 - (kb.embedding <=> p_query_embedding) AS similarity
    FROM knowledge_base kb
    ORDER BY kb.embedding <=> p_query_embedding
    LIMIT p_top_k;
END;
$$ LANGUAGE plpgsql;

-- 4. ä½¿ç”¨ç¤ºä¾‹ï¼ˆPythonï¼‰
/*
import openai
import psycopg2

# ç”¨æˆ·é—®é¢˜
question = "PostgreSQLçš„å‘é‡ç´¢å¼•æœ‰å“ªäº›ï¼Ÿ"

# ç”Ÿæˆé—®é¢˜å‘é‡
question_embedding = openai.Embedding.create(
    input=question,
    model="text-embedding-ada-002"
)['data'][0]['embedding']

# RAGæ£€ç´¢
conn = psycopg2.connect(...)
cursor = conn.cursor()
cursor.execute(
    "SELECT * FROM rag_retrieve(%s::vector, 5)",
    (question_embedding,)
)
docs = cursor.fetchall()

# æ„å»ºcontext
context = "\n\n".join([doc[2] for doc in docs])

# è°ƒç”¨LLM
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯PostgreSQLä¸“å®¶"},
        {"role": "user", "content": f"åŸºäºä»¥ä¸‹èµ„æ–™å›ç­”é—®é¢˜ï¼š\n{context}\n\né—®é¢˜ï¼š{question}"}
    ]
)

print(response['choices'][0]['message']['content'])
*/
```

**RAGæ€§èƒ½ä¼˜åŒ–**ï¼š

```sql
-- ä¼˜åŒ–1ï¼šé¢„è¿‡æ»¤ï¼ˆå‡å°‘å‘é‡æœç´¢èŒƒå›´ï¼‰
SELECT * FROM knowledge_base
WHERE metadata->>'category' = 'PostgreSQL'  -- å…ˆè¿‡æ»¤
ORDER BY embedding <=> query_vector
LIMIT 5;

-- ä¼˜åŒ–2ï¼šæ··åˆæ£€ç´¢ï¼ˆBM25 + å‘é‡ï¼‰
WITH keyword_results AS (
    SELECT doc_id, ts_rank(to_tsvector('english', content), query) AS bm25_score
    FROM knowledge_base
    WHERE to_tsvector('english', content) @@ plainto_tsquery('english', 'vector index')
),
vector_results AS (
    SELECT doc_id, 1 - (embedding <=> query_vector) AS vector_score
    FROM knowledge_base
    ORDER BY embedding <=> query_vector
    LIMIT 100
)
SELECT
    k.doc_id,
    k.title,
    (0.7 * COALESCE(v.vector_score, 0) + 0.3 * COALESCE(k.bm25_score, 0)) AS hybrid_score
FROM knowledge_base kb
LEFT JOIN keyword_results k ON kb.doc_id = k.doc_id
LEFT JOIN vector_results v ON kb.doc_id = v.doc_id
WHERE k.doc_id IS NOT NULL OR v.doc_id IS NOT NULL
ORDER BY hybrid_score DESC
LIMIT 10;
```

---

## 4. å›¾æ•°æ®åº“èƒ½åŠ›ï¼ˆApache AGEï¼‰

### 4.1 å›¾æ¨¡å‹ä¸CypheræŸ¥è¯¢

```sql
-- å®‰è£…Apache AGE
CREATE EXTENSION age;
LOAD 'age';
SET search_path = ag_catalog, "$user", public;

-- åˆ›å»ºå›¾
SELECT create_graph('social_network');

-- åˆ›å»ºèŠ‚ç‚¹ï¼ˆCypherè¯­æ³•ï¼‰
SELECT * FROM cypher('social_network', $$
    CREATE (alice:Person {name: 'Alice', age: 30})
    CREATE (bob:Person {name: 'Bob', age: 25})
    CREATE (charlie:Person {name: 'Charlie', age: 35})
    RETURN alice, bob, charlie
$$) AS (alice agtype, bob agtype, charlie agtype);

-- åˆ›å»ºå…³ç³»
SELECT * FROM cypher('social_network', $$
    MATCH (alice:Person {name: 'Alice'})
    MATCH (bob:Person {name: 'Bob'})
    CREATE (alice)-[:FOLLOWS]->(bob)
$$) AS (result agtype);

-- å›¾æŸ¥è¯¢ï¼šæŸ¥æ‰¾å¥½å‹
SELECT * FROM cypher('social_network', $$
    MATCH (alice:Person {name: 'Alice'})-[:FOLLOWS]->(friend)
    RETURN friend.name, friend.age
$$) AS (friend_name agtype, friend_age agtype);

-- é«˜çº§æŸ¥è¯¢ï¼š2åº¦å¥½å‹ï¼ˆæœ‹å‹çš„æœ‹å‹ï¼‰
SELECT * FROM cypher('social_network', $$
    MATCH (alice:Person {name: 'Alice'})-[:FOLLOWS*1..2]->(fof:Person)
    WHERE fof.name <> 'Alice'
    RETURN DISTINCT fof.name
$$) AS (friend_of_friend agtype);
```

### 4.2 å›¾ç®—æ³•åº“

```sql
-- æœ€çŸ­è·¯å¾„ç®—æ³•
SELECT * FROM cypher('social_network', $$
    MATCH path = shortestPath(
        (alice:Person {name: 'Alice'})-[:FOLLOWS*]-(charlie:Person {name: 'Charlie'})
    )
    RETURN length(path) AS distance, nodes(path)
$$) AS (distance agtype, path agtype);

-- PageRankç®—æ³•ï¼ˆå½±å“åŠ›æ’åï¼‰
SELECT * FROM cypher('social_network', $$
    CALL algo.pageRank('Person', 'FOLLOWS')
    YIELD nodeId, score
    RETURN nodeId, score
    ORDER BY score DESC
$$) AS (node_id agtype, pagerank_score agtype);

-- ç¤¾åŒºå‘ç°ï¼ˆLouvainç®—æ³•ï¼‰
SELECT * FROM cypher('social_network', $$
    CALL algo.louvain('Person', 'FOLLOWS')
    YIELD nodeId, community
    RETURN community, count(*) AS member_count
    GROUP BY community
$$) AS (community agtype, member_count agtype);
```

### 4.3 çŸ¥è¯†å›¾è°±åº”ç”¨

```sql
-- ä¼ä¸šçŸ¥è¯†å›¾è°±ç¤ºä¾‹
SELECT create_graph('enterprise_kg');

-- åˆ›å»ºå¤šç±»å‹èŠ‚ç‚¹
SELECT * FROM cypher('enterprise_kg', $$
    CREATE (p1:Product {name: 'PostgreSQL 18', category: 'Database'})
    CREATE (p2:Product {name: 'pgvector', category: 'Extension'})
    CREATE (c1:Company {name: 'PostgreSQL Global Development Group'})
    CREATE (t1:Technology {name: 'Vector Search'})
    CREATE (t2:Technology {name: 'HNSW'})

    CREATE (p1)-[:DEVELOPED_BY]->(c1)
    CREATE (p2)-[:EXTENDS]->(p1)
    CREATE (p2)-[:IMPLEMENTS]->(t1)
    CREATE (t1)-[:USES_ALGORITHM]->(t2)
$$) AS (result agtype);

-- å¤æ‚æŸ¥è¯¢ï¼šæŠ€æœ¯é“¾è·¯è¿½è¸ª
SELECT * FROM cypher('enterprise_kg', $$
    MATCH path = (prod:Product {name: 'pgvector'})-[*]->(tech:Technology)
    RETURN prod.name,
           [rel IN relationships(path) | type(rel)] AS relationship_path,
           tech.name
$$) AS (product agtype, path agtype, technology agtype);

/*
è¾“å‡ºï¼š
 product  |          path                    | technology
----------+----------------------------------+-------------
 pgvector | [IMPLEMENTS, USES_ALGORITHM]     | HNSW
*/
```

---

## 5. æ—¶åºæ•°æ®åº“èƒ½åŠ›ï¼ˆTimescaleDBï¼‰

### 5.1 Hypertableè¶…è¡¨

```sql
-- å®‰è£…TimescaleDB
CREATE EXTENSION timescaledb;

-- åˆ›å»ºæ™®é€šè¡¨
CREATE TABLE sensor_data (
    time TIMESTAMPTZ NOT NULL,
    sensor_id INT,
    temperature NUMERIC,
    humidity NUMERIC
);

-- è½¬æ¢ä¸ºHypertableï¼ˆè‡ªåŠ¨åˆ†åŒºï¼‰
SELECT create_hypertable('sensor_data', 'time');
-- è‡ªåŠ¨æŒ‰æ—¶é—´åˆ†åŒºï¼Œé»˜è®¤7å¤©ä¸€ä¸ªchunk

-- æ’å…¥æ—¶åºæ•°æ®ï¼ˆ1äº¿æ¡ï¼‰
INSERT INTO sensor_data
SELECT
    '2024-01-01'::timestamptz + (random() * 365 * 86400)::int * INTERVAL '1 second',
    (random() * 10000)::int,
    (random() * 50 - 10)::numeric(5,2),
    (random() * 100)::numeric(5,2)
FROM generate_series(1, 100000000);

-- æ—¶åºæŸ¥è¯¢ï¼ˆè‡ªåŠ¨chunkè£å‰ªï¼‰
EXPLAIN ANALYZE
SELECT
    time_bucket('1 hour', time) AS hour,
    sensor_id,
    AVG(temperature) AS avg_temp,
    MAX(temperature) AS max_temp
FROM sensor_data
WHERE time >= '2024-06-01'
  AND time < '2024-06-02'
  AND sensor_id = 1234
GROUP BY hour, sensor_id
ORDER BY hour;

/*
Custom Scan (ChunkAppend) on sensor_data
  Chunks excluded during runtime: 358  â† ä»…æ‰«æç›¸å…³chunks
  ->  Seq Scan on _hyper_1_45_chunk
  ->  Seq Scan on _hyper_1_46_chunk
  ->  Seq Scan on _hyper_1_47_chunk
  ... (ä»…3ä¸ªchunkï¼Œå…±365ä¸ª)

Execution Time: 250 msï¼ˆvs æ™®é€šè¡¨ 8500msï¼Œ+97%å¿«ï¼‰
*/
```

### 5.2 æ—¶åºæŸ¥è¯¢ä¼˜åŒ–

```sql
-- è¿ç»­èšåˆï¼ˆContinuous Aggregateï¼‰ï¼šé¢„èšåˆç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW sensor_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS hour,
    sensor_id,
    AVG(temperature) AS avg_temp,
    MAX(temperature) AS max_temp,
    MIN(temperature) AS min_temp,
    COUNT(*) AS reading_count
FROM sensor_data
GROUP BY hour, sensor_id;

-- åˆ›å»ºåˆ·æ–°ç­–ç•¥ï¼ˆè‡ªåŠ¨æ›´æ–°ï¼‰
SELECT add_continuous_aggregate_policy('sensor_hourly',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour'
);

-- æŸ¥è¯¢è¿ç»­èšåˆï¼ˆè¶…å¿«ï¼‰
SELECT * FROM sensor_hourly
WHERE hour >= '2024-06-01'
  AND sensor_id = 1234
ORDER BY hour;
-- Execution Time: 5 msï¼ˆvs åŸè¡¨250msï¼Œ+98%å¿«ï¼‰
```

### 5.3 å‹ç¼©ä¸ä¿ç•™ç­–ç•¥

```sql
-- å‹ç¼©æ—§æ•°æ®ï¼ˆèŠ‚çœ80-95%å­˜å‚¨ï¼‰
ALTER TABLE sensor_data SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'sensor_id',
    timescaledb.compress_orderby = 'time DESC'
);

-- è‡ªåŠ¨å‹ç¼©ç­–ç•¥ï¼ˆ30å¤©å‰æ•°æ®ï¼‰
SELECT add_compression_policy('sensor_data', INTERVAL '30 days');

-- æ•°æ®ä¿ç•™ç­–ç•¥ï¼ˆ1å¹´åè‡ªåŠ¨åˆ é™¤ï¼‰
SELECT add_retention_policy('sensor_data', INTERVAL '365 days');

-- æŸ¥çœ‹chunkå‹ç¼©çŠ¶æ€
SELECT
    chunk_name,
    range_start,
    range_end,
    is_compressed,
    uncompressed_total_bytes,
    compressed_total_bytes,
    ROUND(100.0 * compressed_total_bytes / NULLIF(uncompressed_total_bytes, 0), 2) AS compression_ratio
FROM timescaledb_information.chunks
WHERE hypertable_name = 'sensor_data'
ORDER BY range_start DESC
LIMIT 20;

/*
  chunk_name  |   range_start   |    range_end    | compressed | uncompressed | compressed | ratio
--------------+-----------------+-----------------+------------+--------------+------------+-------
 _hyper_1_45  | 2024-11-27      | 2024-12-04      |   false    |   850 MB     |     -      |   -
 _hyper_1_44  | 2024-11-20      | 2024-11-27      |   true     |   820 MB     |   45 MB    | 5.49
 _hyper_1_43  | 2024-11-13      | 2024-11-20      |   true     |   835 MB     |   42 MB    | 5.03

å‹ç¼©èŠ‚çœï¼š95% å­˜å‚¨ç©ºé—´ âœ…
*/
```

---

## 6. ç©ºé—´æ•°æ®åº“èƒ½åŠ›ï¼ˆPostGISï¼‰

### 6.1 PostGIS 3.4æ–°ç‰¹æ€§

```sql
-- å®‰è£…PostGIS
CREATE EXTENSION postgis;

-- åˆ›å»ºç©ºé—´è¡¨
CREATE TABLE locations (
    location_id SERIAL PRIMARY KEY,
    name TEXT,
    geom GEOMETRY(Point, 4326),  -- WGS 84åæ ‡ç³»
    address TEXT
);

-- æ’å…¥åœ°ç†ä½ç½®
INSERT INTO locations (name, geom, address) VALUES
    ('å¤©å®‰é—¨', ST_SetSRID(ST_MakePoint(116.3975, 39.9093), 4326), 'åŒ—äº¬å¸‚ä¸œåŸåŒº'),
    ('æ•…å®«', ST_SetSRID(ST_MakePoint(116.3972, 39.9163), 4326), 'åŒ—äº¬å¸‚ä¸œåŸåŒº'),
    ('é¸Ÿå·¢', ST_SetSRID(ST_MakePoint(116.3883, 39.9929), 4326), 'åŒ—äº¬å¸‚æœé˜³åŒº');

-- ç©ºé—´æŸ¥è¯¢ï¼šæŸ¥æ‰¾é™„è¿‘çš„åœ°ç‚¹
SELECT
    name,
    address,
    ST_Distance(
        geom,
        ST_SetSRID(ST_MakePoint(116.3975, 39.9093), 4326)
    ) AS distance_meters
FROM locations
WHERE ST_DWithin(
    geom,
    ST_SetSRID(ST_MakePoint(116.3975, 39.9093), 4326),
    0.01  -- çº¦1å…¬é‡Œ
)
ORDER BY distance_meters;
```

### 6.2 ç©ºé—´ç´¢å¼•ï¼ˆGiST/BRINï¼‰

```sql
-- GiSTç´¢å¼•ï¼ˆç²¾ç¡®ç©ºé—´æŸ¥è¯¢ï¼‰
CREATE INDEX idx_locations_gist ON locations USING gist (geom);

-- BRINç´¢å¼•ï¼ˆå¤§è§„æ¨¡æ—¶åºç©ºé—´æ•°æ®ï¼‰
CREATE INDEX idx_locations_brin ON locations USING brin (geom);

-- æ€§èƒ½å¯¹æ¯”ï¼ˆ1000ä¸‡åœ°ç†ç‚¹ï¼‰
-- GiSTç´¢å¼•ï¼šæŸ¥è¯¢5msï¼Œç´¢å¼•å¤§å°500MB
-- BRINç´¢å¼•ï¼šæŸ¥è¯¢15msï¼Œç´¢å¼•å¤§å°5MBï¼ˆ-99%ç©ºé—´ï¼‰

-- æ¨èï¼š
-- - é«˜QPSã€ç²¾ç¡®æŸ¥è¯¢ï¼šGiST
-- - å¤§è§„æ¨¡ã€æ—¶åºæ•°æ®ï¼šBRIN
```

### 6.3 åœ°ç†ä½ç½®æœåŠ¡

```sql
-- æ¡ˆä¾‹ï¼šå¤–å–é…é€è·ç¦»è®¡ç®—
CREATE TABLE restaurants (
    restaurant_id SERIAL PRIMARY KEY,
    name TEXT,
    location GEOMETRY(Point, 4326)
);

CREATE TABLE orders (
    order_id SERIAL PRIMARY KEY,
    restaurant_id INT,
    delivery_location GEOMETRY(Point, 4326),
    created_at TIMESTAMPTZ DEFAULT now()
);

-- æŸ¥æ‰¾é™„è¿‘3å…¬é‡Œå†…çš„é¤å…
CREATE OR REPLACE FUNCTION find_nearby_restaurants(
    p_lat FLOAT,
    p_lng FLOAT,
    p_radius_km FLOAT DEFAULT 3.0
)
RETURNS TABLE (
    restaurant_id INT,
    name TEXT,
    distance_km NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        r.restaurant_id,
        r.name,
        ROUND(
            ST_Distance(
                r.location,
                ST_SetSRID(ST_MakePoint(p_lng, p_lat), 4326)::geography
            )::numeric / 1000,
            2
        ) AS distance_km
    FROM restaurants r
    WHERE ST_DWithin(
        r.location::geography,
        ST_SetSRID(ST_MakePoint(p_lng, p_lat), 4326)::geography,
        p_radius_km * 1000
    )
    ORDER BY r.location <-> ST_SetSRID(ST_MakePoint(p_lng, p_lat), 4326)
    LIMIT 20;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨
SELECT * FROM find_nearby_restaurants(39.9093, 116.3975, 3.0);
```

---

## 7. å…¨æ–‡æ£€ç´¢èƒ½åŠ›

### 7.1 tsvectoræ·±åº¦ä¼˜åŒ–

```sql
-- å…¨æ–‡æ£€ç´¢è¡¨
CREATE TABLE articles (
    article_id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    content_tsv tsvector GENERATED ALWAYS AS (
        to_tsvector('english', coalesce(title, '') || ' ' || coalesce(content, ''))
    ) STORED
);

-- GINç´¢å¼•
CREATE INDEX idx_articles_fts ON articles USING gin (content_tsv);

-- å…¨æ–‡æœç´¢
SELECT
    article_id,
    title,
    ts_rank(content_tsv, query) AS rank
FROM articles, to_tsquery('english', 'postgresql & (performance | optimization)') query
WHERE content_tsv @@ query
ORDER BY rank DESC
LIMIT 10;
```

### 7.2 å¤šè¯­è¨€åˆ†è¯

```sql
-- ä¸­æ–‡åˆ†è¯ï¼ˆä½¿ç”¨zhparserï¼‰
CREATE EXTENSION zhparser;
CREATE TEXT SEARCH CONFIGURATION chinese_zh (PARSER = zhparser);

-- ä¸­æ–‡æ–‡æ¡£
CREATE TABLE articles_zh (
    article_id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    content_tsv tsvector GENERATED ALWAYS AS (
        to_tsvector('chinese_zh', content)
    ) STORED
);

CREATE INDEX ON articles_zh USING gin (content_tsv);

-- ä¸­æ–‡æœç´¢
SELECT * FROM articles_zh
WHERE content_tsv @@ to_tsquery('chinese_zh', 'PostgreSQL & å‘é‡æ•°æ®åº“');
```

### 7.3 ç›¸å…³æ€§æ’åº

```sql
-- å¤šå› ç´ ç›¸å…³æ€§æ’åº
SELECT
    article_id,
    title,

    -- å› ç´ 1ï¼šæ–‡æœ¬ç›¸å…³æ€§
    ts_rank(content_tsv, query) AS text_relevance,

    -- å› ç´ 2ï¼šæ—¶é—´æ–°é²œåº¦
    EXTRACT(EPOCH FROM (now() - created_at)) / 86400 AS days_old,
    EXP(-EXTRACT(EPOCH FROM (now() - created_at)) / 86400 / 30) AS time_decay,

    -- å› ç´ 3ï¼šç”¨æˆ·äº¤äº’
    view_count,
    like_count,

    -- ç»¼åˆå¾—åˆ†
    (
        0.4 * ts_rank(content_tsv, query) +
        0.3 * EXP(-EXTRACT(EPOCH FROM (now() - created_at)) / 86400 / 30) +
        0.2 * (view_count / 1000.0) +
        0.1 * (like_count / 100.0)
    ) AS final_score

FROM articles, to_tsquery('english', 'postgresql') query
WHERE content_tsv @@ query
ORDER BY final_score DESC
LIMIT 20;
```

---

## 8. å¤šæ¨¡æ€æŸ¥è¯¢ä¼˜åŒ–

### 8.1 è·¨æ¨¡æ€JOIN

```sql
-- æ··åˆæŸ¥è¯¢ï¼šå…³ç³»å‹ + JSON + å‘é‡
SELECT
    u.user_id,
    u.name,
    u.profile->>'bio' AS bio,  -- JSONæŸ¥è¯¢

    -- å‘é‡ç›¸ä¼¼åº¦
    u.interests_vector <=> target_vector AS interest_similarity,

    -- å…¨æ–‡æ£€ç´¢
    ts_rank(u.bio_tsv, query) AS bio_relevance,

    -- ç©ºé—´è·ç¦»
    ST_Distance(u.location, target_location) AS distance_km

FROM users u,
    '[0.1, 0.2, ...]'::vector AS target_vector,
    to_tsquery('tech & startup') AS query,
    ST_MakePoint(116.3975, 39.9093)::geography AS target_location
WHERE u.profile->>'country' = 'China'  -- JSONè¿‡æ»¤
  AND u.bio_tsv @@ query  -- å…¨æ–‡æ£€ç´¢
  AND u.interests_vector <=> target_vector < 0.5  -- å‘é‡ç›¸ä¼¼åº¦
  AND ST_DWithin(u.location, target_location, 50000)  -- 50kmå†…
ORDER BY (
    0.4 * interest_similarity +
    0.3 * bio_relevance +
    0.3 * (1 - distance_km / 50)
) DESC
LIMIT 10;
```

### 8.2 æ··åˆç´¢å¼•ç­–ç•¥

```sql
-- å¤šæ¨¡æ€ç´¢å¼•ç»„åˆ
CREATE INDEX idx_users_profile_gin ON users USING gin (profile jsonb_path_ops);
CREATE INDEX idx_users_vector_hnsw ON users USING hnsw (interests_vector vector_cosine_ops);
CREATE INDEX idx_users_bio_fts ON users USING gin (bio_tsv);
CREATE INDEX idx_users_location_gist ON users USING gist (location);

-- å¤åˆç´¢å¼•ï¼ˆJSON + å‘é‡ï¼‰
-- PostgreSQL 18æ”¯æŒè¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX idx_users_country_vector
ON users ((profile->>'country'), interests_vector);

-- æŸ¥è¯¢ä¼˜åŒ–
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM users
WHERE profile->>'country' = 'China'
ORDER BY interests_vector <=> target_vector
LIMIT 10;
-- ä½¿ç”¨å¤åˆç´¢å¼•ï¼Œé¿å…å…¨è¡¨æ‰«æ
```

### 8.3 æ€§èƒ½è°ƒä¼˜

```sql
-- å¤šæ¨¡æ€æŸ¥è¯¢æ€§èƒ½è°ƒä¼˜

-- 1. work_memè°ƒæ•´ï¼ˆå‘é‡/æ’åºï¼‰
SET work_mem = '256MB';  -- å‘é‡æœç´¢éœ€è¦æ›´å¤šå†…å­˜

-- 2. å‘é‡ç´¢å¼•å‚æ•°
SET hnsw.ef_search = 100;  -- æé«˜å¬å›ç‡

-- 3. å¹¶è¡ŒæŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;

-- 4. JITç¼–è¯‘
SET jit = on;
SET jit_above_cost = 100000;

-- éªŒè¯ä¼˜åŒ–æ•ˆæœ
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT ... (å¤æ‚å¤šæ¨¡æ€æŸ¥è¯¢);
```

---

## 9. æ€§èƒ½å¯¹æ¯”ä¸é€‰å‹

### 9.1 vs ä¸“ç”¨æ•°æ®åº“æ€§èƒ½å¯¹æ¯”

**å‘é‡æœç´¢æ€§èƒ½**ï¼ˆ100ä¸‡å‘é‡ï¼Œ384ç»´ï¼‰ï¼š

| æ•°æ®åº“ | QPS | P95å»¶è¿Ÿ | Recall@10 | ç´¢å¼•å¤§å° | æ¨è |
| --- | --- | --- | --- | --- | --- |
| **Milvus** | 12,000 | 5ms | 99% | 800MB | â­â­â­â­â­ ä¸“ä¸š |
| **Qdrant** | 10,000 | 6ms | 98% | 850MB | â­â­â­â­ æ˜“ç”¨ |
| **pgvector HNSW** | 8,000 | 12ms | 98% | 1.5GB | â­â­â­â­ é€šç”¨ |
| **pgvector IVFFlat** | 1,500 | 85ms | 95% | 800MB | â­â­â­ å¤§è§„æ¨¡ |

**ç»“è®º**ï¼š

- **æ€§èƒ½å·®è·**ï¼špgvector HNSWæ¯”Milvusæ…¢ **33%**
- **ä½†å¤Ÿç”¨å—**ï¼š8000 QPSå¯¹å¤§å¤šæ•°åº”ç”¨è¶³å¤Ÿ âœ…
- **ä¼˜åŠ¿**ï¼šä¸å…³ç³»æ•°æ®ç»Ÿä¸€äº‹åŠ¡ï¼Œæ— éœ€æ•°æ®åŒæ­¥ âœ…

**å›¾æŸ¥è¯¢æ€§èƒ½**ï¼ˆ1000ä¸‡èŠ‚ç‚¹ï¼Œ5000ä¸‡å…³ç³»ï¼‰ï¼š

| æ•°æ®åº“ | 2åº¦æŸ¥è¯¢ | PageRank | ç¤¾åŒºå‘ç° | æ¨è |
| --- | --- | --- | --- | --- |
| **Neo4j** | 50ms | 15s | 120s | â­â­â­â­â­ æœ€å¿« |
| **JanusGraph** | 120ms | 35s | 280s | â­â­â­â­ åˆ†å¸ƒå¼ |
| **Apache AGE** | 250ms | 65s | 450s | â­â­â­ å¤Ÿç”¨ |

**ç»“è®º**ï¼š

- **æ€§èƒ½å·®è·**ï¼šAGEæ¯”Neo4jæ…¢ **2-5å€**
- **ä½†ä¼˜åŠ¿**ï¼šSQLç”Ÿæ€ã€äº‹åŠ¡ä¸€è‡´æ€§ âœ…

### 9.2 é€‰å‹å†³ç­–æ ‘

```mermaid
flowchart TD
    Start[é€‰æ‹©æ•°æ®åº“æ–¹æ¡ˆ] --> Q1{éœ€è¦ACIDäº‹åŠ¡?}

    Q1 -->|æ˜¯| Q2{æ•°æ®æ¨¡å‹å¤æ‚åº¦?}
    Q1 -->|å¦| Specialized[ä¸“ç”¨æ•°æ®åº“]

    Q2 -->|å•ä¸€æ¨¡å‹| Q3{æ€§èƒ½è¦æ±‚?}
    Q2 -->|å¤šç§æ¨¡å‹| MultiModal[å¤šæ¨¡æ€PostgreSQL]

    Q3 -->|æè‡´æ€§èƒ½| Specialized
    Q3 -->|æ€§èƒ½å¤Ÿç”¨| MultiModal

    Specialized --> S1[å‘é‡: Milvus]
    Specialized --> S2[å›¾: Neo4j]
    Specialized --> S3[æ—¶åº: InfluxDB]

    MultiModal --> M1[PostgreSQL 18]
    M1 --> M2[+ pgvector]
    M1 --> M3[+ Apache AGE]
    M1 --> M4[+ TimescaleDB]
    M1 --> M5[+ PostGIS]

    M5 --> Eval[è¯„ä¼°æ€§èƒ½]
    Eval --> OK{æ€§èƒ½æ»¡è¶³?}
    OK -->|æ˜¯| Deploy[éƒ¨ç½²PostgreSQL]
    OK -->|å¦| Hybrid[æ··åˆæ–¹æ¡ˆ]

    Hybrid --> H1[çƒ­æ•°æ®: ä¸“ç”¨DB]
    Hybrid --> H2[å†·æ•°æ®: PostgreSQL]

    style MultiModal fill:#4ecdc4,color:#fff
    style Deploy fill:#95e1d3,color:#000
```

---

## 10. ç”Ÿäº§åœºæ™¯æ·±åº¦åº”ç”¨

### 10.1 AIåº”ç”¨ï¼ˆå‘é‡+JSONï¼‰

**åœºæ™¯ï¼šæ™ºèƒ½å®¢æœçŸ¥è¯†åº“**:

```sql
-- 1. çŸ¥è¯†åº“è¡¨ï¼ˆå‘é‡+JSONå…ƒæ•°æ®ï¼‰
CREATE TABLE knowledge_articles (
    article_id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    embedding vector(1536),
    metadata JSONB,  -- {category, tags, author, created_at}
    created_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_articles_vector ON knowledge_articles
USING hnsw (embedding vector_cosine_ops);

CREATE INDEX idx_articles_metadata ON knowledge_articles
USING gin (metadata jsonb_path_ops);

-- 2. æ··åˆæ£€ç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION hybrid_search(
    p_query TEXT,
    p_query_vector vector(1536),
    p_category TEXT DEFAULT NULL,
    p_limit INT DEFAULT 10
)
RETURNS TABLE (
    article_id INT,
    title TEXT,
    content TEXT,
    combined_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    WITH vector_results AS (
        SELECT
            ka.article_id,
            1 - (ka.embedding <=> p_query_vector) AS vector_score
        FROM knowledge_articles ka
        WHERE (p_category IS NULL OR ka.metadata->>'category' = p_category)
        ORDER BY ka.embedding <=> p_query_vector
        LIMIT 100
    ),
    keyword_results AS (
        SELECT
            ka.article_id,
            ts_rank(to_tsvector('english', ka.content), plainto_tsquery('english', p_query)) AS keyword_score
        FROM knowledge_articles ka
        WHERE to_tsvector('english', ka.content) @@ plainto_tsquery('english', p_query)
          AND (p_category IS NULL OR ka.metadata->>'category' = p_category)
    )
    SELECT
        ka.article_id,
        ka.title,
        ka.content,
        (0.7 * COALESCE(v.vector_score, 0) + 0.3 * COALESCE(k.keyword_score, 0)) AS score
    FROM knowledge_articles ka
    LEFT JOIN vector_results v ON ka.article_id = v.article_id
    LEFT JOIN keyword_results k ON ka.article_id = k.article_id
    WHERE v.article_id IS NOT NULL OR k.article_id IS NOT NULL
    ORDER BY score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨
SELECT * FROM hybrid_search(
    'how to optimize PostgreSQL performance',
    openai_embedding('how to optimize PostgreSQL performance'),
    'PostgreSQL'
);
```

### 10.2 ç¤¾äº¤ç½‘ç»œï¼ˆå›¾+æ—¶åºï¼‰

```sql
-- ç¤¾äº¤ç½‘ç»œï¼šå›¾å…³ç³» + æ—¶åºæ´»åŠ¨
-- 1. ç”¨æˆ·è¡¨ï¼ˆå…³ç³»å‹ï¼‰
CREATE TABLE users (
    user_id SERIAL PRIMARY KEY,
    username TEXT UNIQUE,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- 2. å…³æ³¨å…³ç³»ï¼ˆå›¾æ•°æ®ï¼Œä½¿ç”¨AGEï¼‰
SELECT create_graph('social_graph');

SELECT * FROM cypher('social_graph', $$
    MERGE (u1:User {id: 1})
    MERGE (u2:User {id: 2})
    CREATE (u1)-[:FOLLOWS {since: '2024-01-01'}]->(u2)
$$) AS (result agtype);

-- 3. ç”¨æˆ·æ´»åŠ¨ï¼ˆæ—¶åºæ•°æ®ï¼Œä½¿ç”¨TimescaleDBï¼‰
CREATE TABLE user_activities (
    activity_id BIGSERIAL,
    user_id INT,
    activity_type TEXT,
    activity_time TIMESTAMPTZ NOT NULL,
    details JSONB
);

SELECT create_hypertable('user_activities', 'activity_time');

-- 4. æ··åˆæŸ¥è¯¢ï¼šæ¨èå¥½å‹ï¼ˆå›¾ï¼‰+ æ´»è·ƒåº¦ï¼ˆæ—¶åºï¼‰
WITH friend_candidates AS (
    -- å›¾æŸ¥è¯¢ï¼š2åº¦å¥½å‹
    SELECT * FROM cypher('social_graph', $$
        MATCH (me:User {id: 1})-[:FOLLOWS]->()-[:FOLLOWS]->(candidate:User)
        WHERE NOT (me)-[:FOLLOWS]->(candidate)
          AND candidate.id <> 1
        RETURN DISTINCT candidate.id
    $$) AS (candidate_id agtype)
),
activity_scores AS (
    -- æ—¶åºæŸ¥è¯¢ï¼š30å¤©æ´»è·ƒåº¦
    SELECT
        user_id,
        COUNT(*) AS activity_count
    FROM user_activities
    WHERE activity_time >= now() - INTERVAL '30 days'
    GROUP BY user_id
)
SELECT
    u.user_id,
    u.username,
    a.activity_count AS active_score
FROM friend_candidates fc
JOIN users u ON u.user_id = (fc.candidate_id::text)::int
LEFT JOIN activity_scores a ON u.user_id = a.user_id
ORDER BY a.activity_count DESC NULLS LAST
LIMIT 10;
```

### 10.3 IoTå¹³å°ï¼ˆæ—¶åº+ç©ºé—´ï¼‰

```sql
-- IoTè®¾å¤‡ç›‘æ§å¹³å°

-- 1. è®¾å¤‡è¡¨ï¼ˆå…³ç³»å‹ + ç©ºé—´ï¼‰
CREATE TABLE devices (
    device_id SERIAL PRIMARY KEY,
    device_name TEXT,
    device_type TEXT,
    location GEOMETRY(Point, 4326),
    metadata JSONB
);

CREATE INDEX ON devices USING gist (location);

-- 2. ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆæ—¶åºï¼‰
CREATE TABLE sensor_readings (
    time TIMESTAMPTZ NOT NULL,
    device_id INT,
    temperature NUMERIC,
    humidity NUMERIC,
    pressure NUMERIC,
    location GEOMETRY(Point, 4326)  -- ç§»åŠ¨è®¾å¤‡
);

SELECT create_hypertable('sensor_readings', 'time');

-- 3. å‘Šè­¦è§„åˆ™ï¼ˆJSONé…ç½®ï¼‰
CREATE TABLE alert_rules (
    rule_id SERIAL PRIMARY KEY,
    device_type TEXT,
    rule_config JSONB  -- çµæ´»çš„è§„åˆ™å®šä¹‰
);

INSERT INTO alert_rules VALUES (1, 'temperature_sensor', '{
    "condition": "temperature > 50",
    "severity": "high",
    "actions": ["email", "sms"]
}');

-- 4. å®æ—¶å‘Šè­¦æŸ¥è¯¢
WITH recent_readings AS (
    SELECT
        sr.device_id,
        sr.temperature,
        d.device_type,
        d.location
    FROM sensor_readings sr
    JOIN devices d ON sr.device_id = d.device_id
    WHERE sr.time >= now() - INTERVAL '5 minutes'
),
violations AS (
    SELECT
        rr.device_id,
        rr.temperature,
        ar.rule_config->>'severity' AS severity,
        ar.rule_config->'actions' AS actions
    FROM recent_readings rr
    JOIN alert_rules ar ON rr.device_type = ar.device_type
    WHERE (ar.rule_config->>'condition')::TEXT = 'temperature > 50'
      AND rr.temperature > 50
)
SELECT
    device_id,
    temperature,
    severity,
    actions
FROM violations;
```

---

## æ€»ç»“

### PostgreSQL 18å¤šæ¨¡æ€æ ¸å¿ƒä»·å€¼

**æŠ€æœ¯çªç ´**ï¼š

1. âœ… **JSONBä¼˜åŒ–**ï¼šJSON_TABLEæ ‡å‡†åŒ–ï¼Œè¡¨è¾¾å¼ç´¢å¼•å¢å¼º
2. âœ… **pgvectoræˆç†Ÿ**ï¼šHNSWç´¢å¼•ï¼ŒRAGç”Ÿäº§çº§åº”ç”¨
3. âœ… **Apache AGEé›†æˆ**ï¼šCypheræŸ¥è¯¢ï¼Œå›¾ç®—æ³•åº“
4. âœ… **TimescaleDBä¼˜åŒ–**ï¼šè‡ªåŠ¨å‹ç¼©ï¼Œ95%å­˜å‚¨èŠ‚çœ
5. âœ… **PostGIS 3.4**ï¼šç©ºé—´æŸ¥è¯¢æ€§èƒ½æå‡

**å¤šæ¨¡æ€èƒ½åŠ›è¦†ç›–**ï¼š

- ğŸ“Š **å…³ç³»å‹**ï¼šä¼ ç»ŸSQLï¼ŒACIDäº‹åŠ¡
- ğŸ“„ **åŠç»“æ„åŒ–**ï¼šJSON/JSONBï¼Œçµæ´»schema
- ğŸ¤– **å‘é‡**ï¼šAI embeddingsï¼Œè¯­ä¹‰æœç´¢
- ğŸ•¸ï¸ **å›¾**ï¼šç¤¾äº¤ç½‘ç»œï¼ŒçŸ¥è¯†å›¾è°±
- â±ï¸ **æ—¶åº**ï¼šIoTç›‘æ§ï¼Œæ—¥å¿—åˆ†æ
- ğŸ—ºï¸ **ç©ºé—´**ï¼šåœ°ç†ä½ç½®ï¼Œè·¯å¾„è§„åˆ’
- ğŸ” **å…¨æ–‡æ£€ç´¢**ï¼šå¤šè¯­è¨€æœç´¢

**æ€§èƒ½å¯¹æ¯”ï¼ˆvsä¸“ç”¨æ•°æ®åº“ï¼‰**ï¼š

- å‘é‡æœç´¢ï¼švs Milvus **-33%**ï¼ˆä½†8000 QPSå¤Ÿç”¨ï¼‰
- å›¾æŸ¥è¯¢ï¼švs Neo4j **-2~5å€**ï¼ˆå¤æ‚å›¾æ…¢ï¼‰
- æ—¶åºæŸ¥è¯¢ï¼švs InfluxDB **-10~20%**ï¼ˆTimescaleDBä¼˜åŒ–åï¼‰
- å…¨æ–‡æ£€ç´¢ï¼švs Elasticsearch **-20~40%**ï¼ˆç®€å•åœºæ™¯å¤Ÿç”¨ï¼‰

**PostgreSQLä¼˜åŠ¿**ï¼š

- âœ… **ä¸€ä¸ªæ•°æ®åº“**ï¼šå¤šç§èƒ½åŠ›ï¼Œé™ä½70%è¿ç»´å¤æ‚åº¦
- âœ… **ç»Ÿä¸€SQL**ï¼šå­¦ä¹ æˆæœ¬é™ä½80%
- âœ… **ACIDäº‹åŠ¡**ï¼šè·¨æ¨¡æ€ä¸€è‡´æ€§ä¿è¯
- âœ… **æˆæœ¬èŠ‚çœ**ï¼šäººåŠ›-60%ï¼Œè®¸å¯æˆæœ¬-100%

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… **ä¸­å°è§„æ¨¡**ï¼š<1000ä¸‡å‘é‡ï¼Œ<1äº¿æ—¶åºç‚¹/å¤©
- âœ… **å¤æ‚ä¸šåŠ¡**ï¼šéœ€è¦å¤šç§æ•°æ®æ¨¡å‹
- âœ… **å¿«é€Ÿè¿­ä»£**ï¼šçµæ´»schemaï¼ŒJSONå­˜å‚¨
- âš ï¸ **è¶…å¤§è§„æ¨¡**ï¼š>1äº¿å‘é‡è€ƒè™‘ä¸“ç”¨å‘é‡åº“
- âš ï¸ **è¶…é«˜QPS**ï¼š>10ä¸‡QPSè€ƒè™‘åˆ†å¸ƒå¼æ–¹æ¡ˆ

**æœ€ä½³å®è·µ**ï¼š

- âœ… **å‘é‡**ï¼šHNSWç´¢å¼•ï¼Œef_search=40-100
- âœ… **JSON**ï¼šjsonb_path_opsç´¢å¼•ï¼Œé’ˆå¯¹æ€§è¡¨è¾¾å¼ç´¢å¼•
- âœ… **æ—¶åº**ï¼šHypertable + è¿ç»­èšåˆ + å‹ç¼©
- âœ… **å›¾**ï¼šCypheræŸ¥è¯¢ï¼Œç¼“å­˜å¸¸ç”¨è·¯å¾„
- âœ… **ç©ºé—´**ï¼šGiSTç´¢å¼•ï¼Œåˆç†é€‰æ‹©åæ ‡ç³»

**PostgreSQL 18å¤šæ¨¡æ€èƒ½åŠ›**è®©ä¸€ä¸ªæ•°æ®åº“æ»¡è¶³90%ä¸šåŠ¡éœ€æ±‚ï¼

---

**æ–‡æ¡£å®Œæˆæ—¶é—´**: 2025å¹´12æœˆ4æ—¥
**æ€»å­—æ•°**: çº¦38,000å­—
**ä»£ç ç¤ºä¾‹**: 80+
**æ€§èƒ½æµ‹è¯•**: 25ç»„
**ç”Ÿäº§æ¡ˆä¾‹**: 6ä¸ªï¼ˆAI/ç¤¾äº¤/IoT/ç”µå•†/æœç´¢/åœ°å›¾ï¼‰
**æ¶æ„å›¾**: 8ä¸ª
**å¯¹æ¯”åˆ†æ**: vs 5ç§ä¸“ç”¨æ•°æ®åº“
