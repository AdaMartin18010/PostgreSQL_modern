---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL_View\05-åˆè§„ä¸å¯ä¿¡\æ•°æ®æº¯æº\æ¦‚ç‡æ•°æ®åº“å®ç°.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# æ¦‚ç‡æ•°æ®åº“å®ç°

> **æ›´æ–°æ—¶é—´**: 2025å¹´1æœˆ
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 18
> **æ–‡æ¡£ç¼–å·**: 05-05-02

---

## ğŸ“‘ ç›®å½•

- [æ¦‚ç‡æ•°æ®åº“å®ç°](#æ¦‚ç‡æ•°æ®åº“å®ç°)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 æŠ€æœ¯èƒŒæ™¯](#11-æŠ€æœ¯èƒŒæ™¯)
      - [**1.1.1 æ•°æ®ä¸ç¡®å®šæ€§çš„æŒ‘æˆ˜**](#111-æ•°æ®ä¸ç¡®å®šæ€§çš„æŒ‘æˆ˜)
      - [**1.1.2 ä¼ ç»Ÿæ•°æ®åº“çš„å±€é™æ€§**](#112-ä¼ ç»Ÿæ•°æ®åº“çš„å±€é™æ€§)
      - [**1.1.3 æ¦‚ç‡æ•°æ®åº“çš„è§£å†³æ–¹æ¡ˆ**](#113-æ¦‚ç‡æ•°æ®åº“çš„è§£å†³æ–¹æ¡ˆ)
    - [1.2 æŠ€æœ¯å®šä½](#12-æŠ€æœ¯å®šä½)
      - [**1.2.1 æŠ€æœ¯å®šä½**](#121-æŠ€æœ¯å®šä½)
      - [**1.2.2 ä¸å…¶ä»–æŠ€æœ¯çš„å¯¹æ¯”**](#122-ä¸å…¶ä»–æŠ€æœ¯çš„å¯¹æ¯”)
    - [1.3 æ ¸å¿ƒä»·å€¼](#13-æ ¸å¿ƒä»·å€¼)
      - [**1.3.1 æ ¸å¿ƒä»·å€¼**](#131-æ ¸å¿ƒä»·å€¼)
      - [**1.3.2 åº”ç”¨åœºæ™¯**](#132-åº”ç”¨åœºæ™¯)
      - [**1.3.3 æŠ€æœ¯ä¼˜åŠ¿**](#133-æŠ€æœ¯ä¼˜åŠ¿)
  - [2. æŠ€æœ¯åŸç†](#2-æŠ€æœ¯åŸç†)
    - [2.1 æ¦‚ç‡æ•°æ®åº“åŸºç¡€](#21-æ¦‚ç‡æ•°æ®åº“åŸºç¡€)
      - [**2.1.1 æ¦‚ç‡æ•°æ®åº“å®šä¹‰**](#211-æ¦‚ç‡æ•°æ®åº“å®šä¹‰)
      - [**2.1.2 æ ¸å¿ƒæ¦‚å¿µ**](#212-æ ¸å¿ƒæ¦‚å¿µ)
      - [**2.1.3 æ¦‚ç‡æ•°æ®åº“åˆ†ç±»**](#213-æ¦‚ç‡æ•°æ®åº“åˆ†ç±»)
    - [2.2 ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹](#22-ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹)
      - [**2.2.1 ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹ç±»å‹**](#221-ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹ç±»å‹)
      - [**2.2.2 ä¸ç¡®å®šæ€§æ¥æº**](#222-ä¸ç¡®å®šæ€§æ¥æº)
      - [**2.2.3 æ¦‚ç‡å€¼è¡¨ç¤ºæ–¹æ³•**](#223-æ¦‚ç‡å€¼è¡¨ç¤ºæ–¹æ³•)
    - [2.3 æ¦‚ç‡æŸ¥è¯¢å¤„ç†](#23-æ¦‚ç‡æŸ¥è¯¢å¤„ç†)
      - [**2.3.1 æ¦‚ç‡æŸ¥è¯¢åŸºç¡€**](#231-æ¦‚ç‡æŸ¥è¯¢åŸºç¡€)
      - [**2.3.2 æ¦‚ç‡æŸ¥è¯¢ç±»å‹**](#232-æ¦‚ç‡æŸ¥è¯¢ç±»å‹)
      - [**2.3.3 å¯èƒ½ä¸–ç•Œæšä¸¾**](#233-å¯èƒ½ä¸–ç•Œæšä¸¾)
      - [**2.3.4 æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–**](#234-æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–)
  - [3. PostgreSQLå®ç°æ–¹æ¡ˆ](#3-postgresqlå®ç°æ–¹æ¡ˆ)
    - [3.1 æ‰©å±•æ¶æ„è®¾è®¡](#31-æ‰©å±•æ¶æ„è®¾è®¡)
      - [**3.1.1 æ•´ä½“æ¶æ„**](#311-æ•´ä½“æ¶æ„)
      - [**3.1.2 å„å±‚èŒè´£**](#312-å„å±‚èŒè´£)
      - [**3.1.3 æ•°æ®æµ**](#313-æ•°æ®æµ)
      - [**3.1.4 æ¥å£è®¾è®¡**](#314-æ¥å£è®¾è®¡)
      - [**3.1.5 æ‰©å±•ç‚¹**](#315-æ‰©å±•ç‚¹)
    - [3.2 æ•°æ®ç±»å‹æ‰©å±•](#32-æ•°æ®ç±»å‹æ‰©å±•)
      - [**3.2.1 æ¦‚ç‡å€¼ç±»å‹**](#321-æ¦‚ç‡å€¼ç±»å‹)
      - [**3.2.2 æ¦‚ç‡åˆ†å¸ƒç±»å‹**](#322-æ¦‚ç‡åˆ†å¸ƒç±»å‹)
      - [**3.2.3 ä¸ç¡®å®šæ€§å…ƒç»„ç±»å‹**](#323-ä¸ç¡®å®šæ€§å…ƒç»„ç±»å‹)
      - [**3.2.4 ç±»å‹æ“ä½œç¬¦å’Œå‡½æ•°**](#324-ç±»å‹æ“ä½œç¬¦å’Œå‡½æ•°)
      - [**3.2.5 ç±»å‹ç´¢å¼•æ”¯æŒ**](#325-ç±»å‹ç´¢å¼•æ”¯æŒ)
      - [**3.2.6 ç±»å‹ä½¿ç”¨æœ€ä½³å®è·µ**](#326-ç±»å‹ä½¿ç”¨æœ€ä½³å®è·µ)
    - [3.3 æŸ¥è¯¢å¤„ç†æ‰©å±•](#33-æŸ¥è¯¢å¤„ç†æ‰©å±•)
      - [**3.3.1 æ¦‚ç‡æŸ¥è¯¢æ“ä½œç¬¦**](#331-æ¦‚ç‡æŸ¥è¯¢æ“ä½œç¬¦)
      - [**3.3.2 è‡ªå®šä¹‰æ“ä½œç¬¦å®ç°**](#332-è‡ªå®šä¹‰æ“ä½œç¬¦å®ç°)
      - [**3.3.3 è‡ªå®šä¹‰å‡½æ•°å®ç°**](#333-è‡ªå®šä¹‰å‡½æ•°å®ç°)
      - [**3.3.4 æŸ¥è¯¢ä¼˜åŒ–å™¨æ‰©å±•**](#334-æŸ¥è¯¢ä¼˜åŒ–å™¨æ‰©å±•)
      - [**3.3.5 æ¦‚ç‡æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’**](#335-æ¦‚ç‡æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’)
  - [4. ProvSQLé›†æˆ](#4-provsqlé›†æˆ)
    - [4.1 ProvSQLæ¦‚è¿°](#41-provsqlæ¦‚è¿°)
      - [**4.1.1 æ ¸å¿ƒåŠŸèƒ½**](#411-æ ¸å¿ƒåŠŸèƒ½)
      - [**4.1.2 æŠ€æœ¯ç‰¹ç‚¹**](#412-æŠ€æœ¯ç‰¹ç‚¹)
      - [**4.1.3 é€‚ç”¨åœºæ™¯**](#413-é€‚ç”¨åœºæ™¯)
    - [4.2 å®‰è£…å’Œé…ç½®](#42-å®‰è£…å’Œé…ç½®)
      - [**4.2.1 å®‰è£…æ­¥éª¤**](#421-å®‰è£…æ­¥éª¤)
      - [**4.2.2 é…ç½®é€‰é¡¹**](#422-é…ç½®é€‰é¡¹)
      - [**4.2.3 éªŒè¯å®‰è£…**](#423-éªŒè¯å®‰è£…)
    - [4.3 é›†æˆæ¶æ„](#43-é›†æˆæ¶æ„)
      - [**4.3.1 æ•´ä½“æ¶æ„è®¾è®¡**](#431-æ•´ä½“æ¶æ„è®¾è®¡)
      - [**4.3.2 å„å±‚èŒè´£è¯¦è§£**](#432-å„å±‚èŒè´£è¯¦è§£)
      - [**4.3.3 æ•°æ®æµè¯¦ç»†è¯´æ˜**](#433-æ•°æ®æµè¯¦ç»†è¯´æ˜)
      - [**4.3.4 æ¥å£è®¾è®¡**](#434-æ¥å£è®¾è®¡)
      - [**4.3.5 é›†æˆä¼˜åŠ¿**](#435-é›†æˆä¼˜åŠ¿)
    - [4.4 æ ¸å¿ƒåŠŸèƒ½è¯¦è§£](#44-æ ¸å¿ƒåŠŸèƒ½è¯¦è§£)
      - [**4.4.1 æº¯æºè¿½è¸ª**](#441-æº¯æºè¿½è¸ª)
      - [**4.4.2 æ¦‚ç‡è®¡ç®—**](#442-æ¦‚ç‡è®¡ç®—)
      - [**4.4.3 æº¯æºå’Œæ¦‚ç‡ç»“åˆ**](#443-æº¯æºå’Œæ¦‚ç‡ç»“åˆ)
    - [4.5 ä½¿ç”¨ç¤ºä¾‹](#45-ä½¿ç”¨ç¤ºä¾‹)
      - [**4.5.1 åŸºç¡€ä½¿ç”¨ç¤ºä¾‹**](#451-åŸºç¡€ä½¿ç”¨ç¤ºä¾‹)
      - [**4.5.2 æ¦‚ç‡æŸ¥è¯¢ç¤ºä¾‹**](#452-æ¦‚ç‡æŸ¥è¯¢ç¤ºä¾‹)
      - [**4.5.3 æº¯æºæŸ¥è¯¢ç¤ºä¾‹**](#453-æº¯æºæŸ¥è¯¢ç¤ºä¾‹)
      - [**4.5.4 å¤æ‚æŸ¥è¯¢ç¤ºä¾‹**](#454-å¤æ‚æŸ¥è¯¢ç¤ºä¾‹)
      - [**4.5.5 å®é™…åº”ç”¨åœºæ™¯ç¤ºä¾‹**](#455-å®é™…åº”ç”¨åœºæ™¯ç¤ºä¾‹)
  - [5. å®é™…åº”ç”¨æ¡ˆä¾‹](#5-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [5.1 ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†](#51-ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†)
      - [**5.1.1 ä¸šåŠ¡åœºæ™¯**](#511-ä¸šåŠ¡åœºæ™¯)
      - [**5.1.2 æ•°æ®æ¨¡å‹è®¾è®¡**](#512-æ•°æ®æ¨¡å‹è®¾è®¡)
      - [**5.1.3 æ•°æ®æ’å…¥å’Œæ¦‚ç‡è®¡ç®—**](#513-æ•°æ®æ’å…¥å’Œæ¦‚ç‡è®¡ç®—)
      - [**5.1.4 æŸ¥è¯¢å’Œåˆ†æ**](#514-æŸ¥è¯¢å’Œåˆ†æ)
      - [**5.1.5 ä½¿ç”¨ç¤ºä¾‹**](#515-ä½¿ç”¨ç¤ºä¾‹)
    - [5.2 æ•°æ®èåˆåœºæ™¯](#52-æ•°æ®èåˆåœºæ™¯)
      - [**5.2.1 ä¸šåŠ¡åœºæ™¯**](#521-ä¸šåŠ¡åœºæ™¯)
      - [**5.2.2 æ•°æ®æ¨¡å‹è®¾è®¡**](#522-æ•°æ®æ¨¡å‹è®¾è®¡)
      - [**5.2.3 æ•°æ®èåˆå®ç°**](#523-æ•°æ®èåˆå®ç°)
      - [**5.2.4 æ•°æ®è´¨é‡è¯„ä¼°**](#524-æ•°æ®è´¨é‡è¯„ä¼°)
    - [5.3 å…¶ä»–åº”ç”¨åœºæ™¯](#53-å…¶ä»–åº”ç”¨åœºæ™¯)
      - [**5.3.1 æ•°æ®è´¨é‡è¯„ä¼°**](#531-æ•°æ®è´¨é‡è¯„ä¼°)
      - [**5.3.2 å¼‚å¸¸æ£€æµ‹**](#532-å¼‚å¸¸æ£€æµ‹)
      - [**5.3.3 æ•°æ®æº¯æºå®¡è®¡**](#533-æ•°æ®æº¯æºå®¡è®¡)
  - [6. æ€§èƒ½åˆ†æ](#6-æ€§èƒ½åˆ†æ)
    - [6.1 æŸ¥è¯¢æ€§èƒ½å½±å“](#61-æŸ¥è¯¢æ€§èƒ½å½±å“)
      - [**6.1.1 æ€§èƒ½å½±å“å› ç´ **](#611-æ€§èƒ½å½±å“å› ç´ )
      - [**6.1.2 æ€§èƒ½æµ‹è¯•æ•°æ®**](#612-æ€§èƒ½æµ‹è¯•æ•°æ®)
      - [**6.1.3 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**](#613-æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
    - [6.2 å­˜å‚¨å¼€é”€åˆ†æ](#62-å­˜å‚¨å¼€é”€åˆ†æ)
      - [**6.2.1 å­˜å‚¨å¼€é”€è¯¦ç»†åˆ†æ**](#621-å­˜å‚¨å¼€é”€è¯¦ç»†åˆ†æ)
      - [**6.2.2 å­˜å‚¨ä¼˜åŒ–ç­–ç•¥**](#622-å­˜å‚¨ä¼˜åŒ–ç­–ç•¥)
    - [6.3 æ€§èƒ½åŸºå‡†æµ‹è¯•](#63-æ€§èƒ½åŸºå‡†æµ‹è¯•)
      - [**6.3.1 åŸºå‡†æµ‹è¯•è„šæœ¬**](#631-åŸºå‡†æµ‹è¯•è„šæœ¬)
      - [**6.3.2 æ€§èƒ½ç›‘æ§æŒ‡æ ‡**](#632-æ€§èƒ½ç›‘æ§æŒ‡æ ‡)
    - [6.4 æ€§èƒ½ä¼˜åŒ–å»ºè®®](#64-æ€§èƒ½ä¼˜åŒ–å»ºè®®)
      - [**6.4.1 æŸ¥è¯¢ä¼˜åŒ–å»ºè®®**](#641-æŸ¥è¯¢ä¼˜åŒ–å»ºè®®)
      - [**6.4.2 å­˜å‚¨ä¼˜åŒ–å»ºè®®**](#642-å­˜å‚¨ä¼˜åŒ–å»ºè®®)
  - [7. æœ€ä½³å®è·µ](#7-æœ€ä½³å®è·µ)
    - [7.1 ä½¿ç”¨åœºæ™¯](#71-ä½¿ç”¨åœºæ™¯)
      - [**7.1.1 é€‚ç”¨åœºæ™¯**](#711-é€‚ç”¨åœºæ™¯)
      - [**7.1.2 ä¸é€‚ç”¨åœºæ™¯**](#712-ä¸é€‚ç”¨åœºæ™¯)
    - [7.2 è®¾è®¡åŸåˆ™](#72-è®¾è®¡åŸåˆ™)
      - [**7.2.1 æ¦‚ç‡å€¼è®¾è®¡**](#721-æ¦‚ç‡å€¼è®¾è®¡)
      - [**7.2.2 æ•°æ®æ¨¡å‹è®¾è®¡**](#722-æ•°æ®æ¨¡å‹è®¾è®¡)
    - [7.3 æ€§èƒ½ä¼˜åŒ–](#73-æ€§èƒ½ä¼˜åŒ–)
      - [**7.3.1 æŸ¥è¯¢ä¼˜åŒ–**](#731-æŸ¥è¯¢ä¼˜åŒ–)
      - [**7.3.2 å­˜å‚¨ä¼˜åŒ–**](#732-å­˜å‚¨ä¼˜åŒ–)
    - [7.4 å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ](#74-å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ)
      - [**7.4.1 æ¦‚ç‡å€¼ä¸ä¸€è‡´**](#741-æ¦‚ç‡å€¼ä¸ä¸€è‡´)
      - [**7.4.2 æ€§èƒ½é—®é¢˜**](#742-æ€§èƒ½é—®é¢˜)
      - [**7.4.3 å­˜å‚¨ç©ºé—´é—®é¢˜**](#743-å­˜å‚¨ç©ºé—´é—®é¢˜)
    - [7.5 æ³¨æ„äº‹é¡¹](#75-æ³¨æ„äº‹é¡¹)
      - [**7.5.1 æ¦‚ç‡å€¼ç®¡ç†**](#751-æ¦‚ç‡å€¼ç®¡ç†)
      - [**7.5.2 æŸ¥è¯¢å¤æ‚åº¦**](#752-æŸ¥è¯¢å¤æ‚åº¦)
      - [**7.5.3 æ•°æ®è´¨é‡**](#753-æ•°æ®è´¨é‡)
    - [7.6 å®æ–½å»ºè®®](#76-å®æ–½å»ºè®®)
      - [**7.6.1 æ¸è¿›å¼å®æ–½**](#761-æ¸è¿›å¼å®æ–½)
      - [**7.6.2 å›¢é˜ŸåŸ¹è®­**](#762-å›¢é˜ŸåŸ¹è®­)
      - [**7.6.3 ç›‘æ§å’Œç»´æŠ¤**](#763-ç›‘æ§å’Œç»´æŠ¤)
  - [8. å‚è€ƒèµ„æ–™](#8-å‚è€ƒèµ„æ–™)
    - [8.1 å­¦æœ¯è®ºæ–‡](#81-å­¦æœ¯è®ºæ–‡)
      - [**8.1.1 æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®º**](#811-æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®º)
      - [**8.1.2 ProvSQLå’Œæ•°æ®æº¯æº**](#812-provsqlå’Œæ•°æ®æº¯æº)
      - [**8.1.3 ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†**](#813-ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†)
    - [8.2 å®˜æ–¹æ–‡æ¡£](#82-å®˜æ–¹æ–‡æ¡£)
      - [**8.2.1 PostgreSQLæ–‡æ¡£**](#821-postgresqlæ–‡æ¡£)
      - [**8.2.2 ProvSQLæ–‡æ¡£**](#822-provsqlæ–‡æ¡£)
    - [8.3 å¼€æºé¡¹ç›®å’Œå·¥å…·](#83-å¼€æºé¡¹ç›®å’Œå·¥å…·)
      - [**8.3.1 æ¦‚ç‡æ•°æ®åº“é¡¹ç›®**](#831-æ¦‚ç‡æ•°æ®åº“é¡¹ç›®)
      - [**8.3.2 ç›¸å…³å·¥å…·**](#832-ç›¸å…³å·¥å…·)
    - [8.4 ç¤¾åŒºèµ„æº](#84-ç¤¾åŒºèµ„æº)
      - [**8.4.1 è®ºå›å’Œç¤¾åŒº**](#841-è®ºå›å’Œç¤¾åŒº)
      - [**8.4.2 åšå®¢å’Œæ–‡ç« **](#842-åšå®¢å’Œæ–‡ç« )
    - [8.5 ä¹¦ç±æ¨è](#85-ä¹¦ç±æ¨è)
      - [**8.5.1 æ¦‚ç‡æ•°æ®åº“ç›¸å…³ä¹¦ç±**](#851-æ¦‚ç‡æ•°æ®åº“ç›¸å…³ä¹¦ç±)
      - [**8.5.2 PostgreSQLç›¸å…³ä¹¦ç±**](#852-postgresqlç›¸å…³ä¹¦ç±)
      - [**8.5.3 æ•°æ®æº¯æºç›¸å…³ä¹¦ç±**](#853-æ•°æ®æº¯æºç›¸å…³ä¹¦ç±)
      - [**8.5.4 æ•°æ®åº“ç†è®ºç›¸å…³ä¹¦ç±**](#854-æ•°æ®åº“ç†è®ºç›¸å…³ä¹¦ç±)
    - [8.6 è§†é¢‘æ•™ç¨‹](#86-è§†é¢‘æ•™ç¨‹)
      - [**8.6.1 ProvSQLç›¸å…³è§†é¢‘**](#861-provsqlç›¸å…³è§†é¢‘)
      - [**8.6.2 æ¦‚ç‡æ•°æ®åº“è¯¾ç¨‹**](#862-æ¦‚ç‡æ•°æ®åº“è¯¾ç¨‹)
      - [**8.6.3 PostgreSQLæ‰©å±•å¼€å‘æ•™ç¨‹**](#863-postgresqlæ‰©å±•å¼€å‘æ•™ç¨‹)
      - [**8.6.4 æ•°æ®æº¯æºç›¸å…³è§†é¢‘**](#864-æ•°æ®æº¯æºç›¸å…³è§†é¢‘)
      - [**8.6.5 åœ¨çº¿å­¦ä¹ å¹³å°æ¨è**](#865-åœ¨çº¿å­¦ä¹ å¹³å°æ¨è)
    - [8.7 æŠ€æœ¯åšå®¢å’Œæ¡ˆä¾‹](#87-æŠ€æœ¯åšå®¢å’Œæ¡ˆä¾‹)
      - [**8.7.1 åº”ç”¨æ¡ˆä¾‹**](#871-åº”ç”¨æ¡ˆä¾‹)
      - [**8.7.2 æœ€ä½³å®è·µ**](#872-æœ€ä½³å®è·µ)
      - [**8.7.3 æŠ€æœ¯åšå®¢æ¨è**](#873-æŠ€æœ¯åšå®¢æ¨è)
      - [**8.7.4 å®é™…é¡¹ç›®æ¡ˆä¾‹**](#874-å®é™…é¡¹ç›®æ¡ˆä¾‹)
    - [8.8 ç ”ç©¶æœºæ„å’Œå®éªŒå®¤](#88-ç ”ç©¶æœºæ„å’Œå®éªŒå®¤)
      - [**8.8.1 ä¸»è¦ç ”ç©¶æœºæ„**](#881-ä¸»è¦ç ”ç©¶æœºæ„)
      - [**8.8.2 å…¶ä»–é‡è¦ç ”ç©¶æœºæ„**](#882-å…¶ä»–é‡è¦ç ”ç©¶æœºæ„)
      - [**8.8.3 ç ”ç©¶å®éªŒå®¤**](#883-ç ”ç©¶å®éªŒå®¤)
      - [**8.8.4 ç ”ç©¶é¡¹ç›®å’Œå®éªŒå®¤é“¾æ¥**](#884-ç ”ç©¶é¡¹ç›®å’Œå®éªŒå®¤é“¾æ¥)
    - [8.9 å‚è€ƒèµ„æºä½¿ç”¨å»ºè®®](#89-å‚è€ƒèµ„æºä½¿ç”¨å»ºè®®)
      - [**8.9.1 ä¸åŒè§’è‰²çš„å­¦ä¹ è·¯å¾„**](#891-ä¸åŒè§’è‰²çš„å­¦ä¹ è·¯å¾„)
      - [**8.9.2 å­¦ä¹ èµ„æºä¼˜å…ˆçº§**](#892-å­¦ä¹ èµ„æºä¼˜å…ˆçº§)
      - [**8.9.3 å­¦ä¹ æ—¶é—´è§„åˆ’**](#893-å­¦ä¹ æ—¶é—´è§„åˆ’)
      - [**8.9.4 å­¦ä¹ å»ºè®®**](#894-å­¦ä¹ å»ºè®®)
  - [9. å®Œæ•´ä»£ç ç¤ºä¾‹](#9-å®Œæ•´ä»£ç ç¤ºä¾‹)
    - [9.1 æ¦‚ç‡æ•°æ®ç±»å‹å®ç°](#91-æ¦‚ç‡æ•°æ®ç±»å‹å®ç°)
      - [**9.1.1 åˆ›å»ºæ¦‚ç‡æ•°æ®ç±»å‹**](#911-åˆ›å»ºæ¦‚ç‡æ•°æ®ç±»å‹)
      - [**9.1.2 åˆ›å»ºæ¦‚ç‡æ•°æ®è¡¨**](#912-åˆ›å»ºæ¦‚ç‡æ•°æ®è¡¨)
      - [**9.1.3 æ’å…¥æ¦‚ç‡æ•°æ®**](#913-æ’å…¥æ¦‚ç‡æ•°æ®)
      - [**9.1.4 æŸ¥è¯¢æ¦‚ç‡æ•°æ®**](#914-æŸ¥è¯¢æ¦‚ç‡æ•°æ®)
      - [**9.1.5 æ¦‚ç‡æ“ä½œå‡½æ•°**](#915-æ¦‚ç‡æ“ä½œå‡½æ•°)
      - [**9.1.6 æ¦‚ç‡æ•°æ®æ›´æ–°**](#916-æ¦‚ç‡æ•°æ®æ›´æ–°)
      - [**9.1.7 æ¦‚ç‡æ•°æ®éªŒè¯**](#917-æ¦‚ç‡æ•°æ®éªŒè¯)
      - [**9.1.8 å®Œæ•´ä½¿ç”¨ç¤ºä¾‹**](#918-å®Œæ•´ä½¿ç”¨ç¤ºä¾‹)
    - [9.3 ProvSQL æ¦‚ç‡æŸ¥è¯¢é›†æˆ](#93-provsql-æ¦‚ç‡æŸ¥è¯¢é›†æˆ)
      - [**9.3.1 ProvSQLé›†æˆå®Œæ•´ç¤ºä¾‹**](#931-provsqlé›†æˆå®Œæ•´ç¤ºä¾‹)
      - [**9.3.2 ProvSQLæ¦‚ç‡æŸ¥è¯¢å‡½æ•°**](#932-provsqlæ¦‚ç‡æŸ¥è¯¢å‡½æ•°)
      - [**9.3.3 ProvSQLæ¦‚ç‡æŸ¥è¯¢Pythoné›†æˆ**](#933-provsqlæ¦‚ç‡æŸ¥è¯¢pythoné›†æˆ)
    - [9.4 Docker Compose éƒ¨ç½²é…ç½®](#94-docker-compose-éƒ¨ç½²é…ç½®)
      - [**9.4.1 å®Œæ•´Docker Composeé…ç½®**](#941-å®Œæ•´docker-composeé…ç½®)
      - [**9.4.2 åˆå§‹åŒ–SQLè„šæœ¬**](#942-åˆå§‹åŒ–sqlè„šæœ¬)
      - [**9.4.3 Pythonå®¢æˆ·ç«¯é…ç½®**](#943-pythonå®¢æˆ·ç«¯é…ç½®)
      - [**9.4.4 éƒ¨ç½²å’Œä½¿ç”¨è¯´æ˜**](#944-éƒ¨ç½²å’Œä½¿ç”¨è¯´æ˜)

---

## 1. æ¦‚è¿°

### 1.1 æŠ€æœ¯èƒŒæ™¯

#### **1.1.1 æ•°æ®ä¸ç¡®å®šæ€§çš„æŒ‘æˆ˜**

åœ¨ç°å®ä¸–ç•Œä¸­ï¼Œæ•°æ®å¾€å¾€å­˜åœ¨ä¸ç¡®å®šæ€§ï¼š

**1. ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§**ï¼š

- **æµ‹é‡è¯¯å·®**ï¼šä¼ æ„Ÿå™¨ç²¾åº¦é™åˆ¶å¯¼è‡´çš„è¯¯å·®
- **å™ªå£°å¹²æ‰°**ï¼šç¯å¢ƒå™ªå£°å¯¹æµ‹é‡çš„å½±å“
- **è®¾å¤‡æ•…éšœ**ï¼šä¼ æ„Ÿå™¨æ•…éšœå¯¼è‡´çš„æ•°æ®å¼‚å¸¸
- **ç½‘ç»œå»¶è¿Ÿ**ï¼šæ•°æ®ä¼ è¾“å»¶è¿Ÿå¯¼è‡´çš„æ—¶é—´ä¸ç¡®å®šæ€§

**2. æ•°æ®èåˆä¸ç¡®å®šæ€§**ï¼š

- **å¤šæºæ•°æ®ä¸ä¸€è‡´**ï¼šä¸åŒæ•°æ®æºæä¾›çš„æ•°æ®å­˜åœ¨å·®å¼‚
- **æ•°æ®å†²çª**ï¼šåŒä¸€å®ä½“çš„ä¸åŒæ•°æ®æºæ•°æ®ç›¸äº’çŸ›ç›¾
- **æ•°æ®è´¨é‡å·®å¼‚**ï¼šä¸åŒæ•°æ®æºçš„æ•°æ®è´¨é‡ä¸åŒ
- **æ—¶é—´ä¸åŒæ­¥**ï¼šä¸åŒæ•°æ®æºçš„æ—¶é—´æˆ³ä¸ä¸€è‡´

**3. æ•°æ®æº¯æºä¸ç¡®å®šæ€§**ï¼š

- **æ•°æ®æ¥æºå¯ä¿¡åº¦**ï¼šä¸åŒæ•°æ®æºçš„å¯ä¿¡åº¦ä¸åŒ
- **å¤„ç†è¿‡ç¨‹ä¸ç¡®å®šæ€§**ï¼šæ•°æ®å¤„ç†è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§
- **æ•°æ®è½¬æ¢è¯¯å·®**ï¼šæ•°æ®è½¬æ¢è¿‡ç¨‹ä¸­çš„è¯¯å·®ç´¯ç§¯
- **æ•°æ®è´¨é‡è¯„ä¼°**ï¼šæ•°æ®è´¨é‡çš„è¯„ä¼°å­˜åœ¨ä¸ç¡®å®šæ€§

**4. ç¼ºå¤±æ•°æ®ä¸ç¡®å®šæ€§**ï¼š

- **æ•°æ®ä¸å®Œæ•´**ï¼šéƒ¨åˆ†æ•°æ®ç¼ºå¤±
- **æ•°æ®æ’å€¼**ï¼šç¼ºå¤±æ•°æ®çš„ä¼°è®¡å€¼å­˜åœ¨ä¸ç¡®å®šæ€§
- **æ•°æ®æ¨æ–­**ï¼šåŸºäºç°æœ‰æ•°æ®æ¨æ–­ç¼ºå¤±æ•°æ®çš„ä¸ç¡®å®šæ€§

#### **1.1.2 ä¼ ç»Ÿæ•°æ®åº“çš„å±€é™æ€§**

ä¼ ç»Ÿæ•°æ®åº“å‡è®¾æ•°æ®æ˜¯ç¡®å®šçš„ï¼Œå­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š

- **æ— æ³•è¡¨ç¤ºä¸ç¡®å®šæ€§**ï¼šåªèƒ½å­˜å‚¨ç¡®å®šçš„å€¼ï¼Œæ— æ³•è¡¨ç¤ºæ•°æ®çš„ä¸ç¡®å®šæ€§
- **æ— æ³•å¤„ç†æ¦‚ç‡æŸ¥è¯¢**ï¼šæ— æ³•è®¡ç®—æŸ¥è¯¢ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ
- **æ— æ³•è¯„ä¼°æ•°æ®è´¨é‡**ï¼šæ— æ³•åŸºäºæ¦‚ç‡è¯„ä¼°æ•°æ®è´¨é‡
- **æ— æ³•è¿½è¸ªæ•°æ®æ¥æº**ï¼šæ— æ³•è¿½è¸ªæ•°æ®çš„æ¥æºå’Œå¤„ç†è¿‡ç¨‹

#### **1.1.3 æ¦‚ç‡æ•°æ®åº“çš„è§£å†³æ–¹æ¡ˆ**

æ¦‚ç‡æ•°æ®åº“ï¼ˆProbabilistic Databaseï¼‰æä¾›äº†å¤„ç†ä¸ç¡®å®šæ€§æ•°æ®çš„è§£å†³æ–¹æ¡ˆï¼š

- **ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹**ï¼šæ”¯æŒæ¦‚ç‡å€¼ã€ç½®ä¿¡åŒºé—´ã€åˆ†å¸ƒå‡½æ•°
- **æ¦‚ç‡æŸ¥è¯¢å¤„ç†**ï¼šè®¡ç®—æŸ¥è¯¢ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ
- **æ•°æ®è´¨é‡è¯„ä¼°**ï¼šåŸºäºæ¦‚ç‡è¯„ä¼°æ•°æ®è´¨é‡
- **æ•°æ®æº¯æºé›†æˆ**ï¼šç»“åˆæ•°æ®æº¯æºä¿¡æ¯è®¡ç®—æ¦‚ç‡

### 1.2 æŠ€æœ¯å®šä½

#### **1.2.1 æŠ€æœ¯å®šä½**

æ¦‚ç‡æ•°æ®åº“æ˜¯PostgreSQLåœ¨æ•°æ®æº¯æºå’Œä¸ç¡®å®šæ€§æ•°æ®å¤„ç†é¢†åŸŸçš„æ‰©å±•ï¼Œä¸ProvSQLé…åˆä½¿ç”¨ï¼Œæä¾›ï¼š

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

- **ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹**ï¼šæ”¯æŒæ¦‚ç‡å€¼ã€ç½®ä¿¡åŒºé—´ã€åˆ†å¸ƒå‡½æ•°
- **æ¦‚ç‡æŸ¥è¯¢å¤„ç†**ï¼šè®¡ç®—æŸ¥è¯¢ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ
- **æ•°æ®æº¯æºé›†æˆ**ï¼šç»“åˆæ•°æ®æº¯æºä¿¡æ¯è®¡ç®—æ¦‚ç‡
- **æ•°æ®è´¨é‡è¯„ä¼°**ï¼šåŸºäºæ¦‚ç‡è¯„ä¼°æ•°æ®è´¨é‡

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š

- **æ— ç¼é›†æˆ**ï¼šä½œä¸ºPostgreSQLæ‰©å±•ï¼Œæ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç 
- **é«˜æ€§èƒ½**ï¼šä¼˜åŒ–çš„æ¦‚ç‡è®¡ç®—ç®—æ³•
- **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§æ¦‚ç‡è®¡ç®—æ¨¡å¼
- **æ ‡å‡†å…¼å®¹**ï¼šæ”¯æŒSQLæ ‡å‡†è¯­æ³•

#### **1.2.2 ä¸å…¶ä»–æŠ€æœ¯çš„å¯¹æ¯”**

**ä¸ä¼ ç»Ÿæ•°æ®åº“çš„å¯¹æ¯”**ï¼š

| ç‰¹æ€§ | ä¼ ç»Ÿæ•°æ®åº“ | æ¦‚ç‡æ•°æ®åº“ |
|------|-----------|-----------|
| **æ•°æ®ç¡®å®šæ€§** | ç¡®å®š | ä¸ç¡®å®š |
| **æ•°æ®è¡¨ç¤º** | ç²¾ç¡®å€¼ | å€¼+æ¦‚ç‡ |
| **æŸ¥è¯¢ç»“æœ** | ç¡®å®šæ€§ç»“æœ | æ¦‚ç‡åˆ†å¸ƒ |
| **æ•°æ®è´¨é‡** | æ— æ³•è¯„ä¼° | åŸºäºæ¦‚ç‡è¯„ä¼° |
| **æ•°æ®æº¯æº** | ä¸æ”¯æŒ | æ”¯æŒ |

**ä¸å…¶ä»–ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†æŠ€æœ¯çš„å¯¹æ¯”**ï¼š

| ç‰¹æ€§ | æ¦‚ç‡æ•°æ®åº“ | æ¨¡ç³Šæ•°æ®åº“ | ç²—ç³™é›†ç†è®º |
|------|-----------|-----------|-----------|
| **ç†è®ºåŸºç¡€** | æ¦‚ç‡è®º | æ¨¡ç³Šé€»è¾‘ | ç²—ç³™é›†ç†è®º |
| **æ•°æ®è¡¨ç¤º** | æ¦‚ç‡å€¼ | éš¶å±åº¦ | ä¸Šä¸‹è¿‘ä¼¼ |
| **æŸ¥è¯¢å¤„ç†** | æ¦‚ç‡è®¡ç®— | æ¨¡ç³Šæ¨ç† | ç²—ç³™é›†è¿ç®— |
| **é€‚ç”¨åœºæ™¯** | ä¸ç¡®å®šæ€§æ•°æ® | æ¨¡ç³Šæ•°æ® | ä¸ç²¾ç¡®æ•°æ® |

### 1.3 æ ¸å¿ƒä»·å€¼

#### **1.3.1 æ ¸å¿ƒä»·å€¼**

**1. å¤„ç†ä¸ç¡®å®šæ€§æ•°æ®**ï¼š

- **ä¼ æ„Ÿå™¨æ•°æ®**ï¼šå¤„ç†IoTä¼ æ„Ÿå™¨æ•°æ®çš„ä¸ç¡®å®šæ€§
- **æ•°æ®èåˆ**ï¼šå¤„ç†å¤šæºæ•°æ®èåˆçš„ä¸ä¸€è‡´æ€§
- **æ•°æ®è´¨é‡**ï¼šè¯„ä¼°å’Œæå‡æ•°æ®è´¨é‡
- **ç¼ºå¤±æ•°æ®**ï¼šå¤„ç†ä¸å®Œæ•´æ•°æ®

**2. æ¦‚ç‡æŸ¥è¯¢**ï¼š

- **æ¦‚ç‡åˆ†å¸ƒ**ï¼šæä¾›æŸ¥è¯¢ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ
- **ç½®ä¿¡åº¦è¯„ä¼°**ï¼šè¯„ä¼°æŸ¥è¯¢ç»“æœçš„ç½®ä¿¡åº¦
- **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šé‡åŒ–æ•°æ®çš„ä¸ç¡®å®šæ€§
- **å†³ç­–æ”¯æŒ**ï¼šåŸºäºæ¦‚ç‡æ”¯æŒå†³ç­–

**3. æ•°æ®æº¯æºæ”¯æŒ**ï¼š

- **æ•°æ®æ¥æºè¿½è¸ª**ï¼šè¿½è¸ªæ•°æ®çš„æ¥æºå’Œå¤„ç†è¿‡ç¨‹
- **å¯ä¿¡åº¦è®¡ç®—**ï¼šåŸºäºæ•°æ®æ¥æºè®¡ç®—å¯ä¿¡åº¦
- **åˆè§„å®¡è®¡**ï¼šæ»¡è¶³æ•°æ®æ²»ç†å’Œåˆè§„è¦æ±‚
- **æ•°æ®è´¨é‡è¯„ä¼°**ï¼šåŸºäºæº¯æºä¿¡æ¯è¯„ä¼°æ•°æ®è´¨é‡

#### **1.3.2 åº”ç”¨åœºæ™¯**

**1. IoTä¼ æ„Ÿå™¨æ•°æ®ç®¡ç†**ï¼š

- ç¯å¢ƒç›‘æµ‹ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ã€å‹åŠ›ç­‰ï¼‰
- æ™ºèƒ½åŸå¸‚ï¼ˆäº¤é€šã€èƒ½æºã€ç¯å¢ƒç­‰ï¼‰
- å·¥ä¸š4.0ï¼ˆè®¾å¤‡ç›‘æ§ã€é¢„æµ‹ç»´æŠ¤ç­‰ï¼‰

**2. æ•°æ®èåˆå’Œé›†æˆ**ï¼š

- æ•°æ®ä»“åº“ï¼ˆå¤šæºæ•°æ®æ•´åˆï¼‰
- æ•°æ®æ¹–ï¼ˆå¼‚æ„æ•°æ®èåˆï¼‰
- æ•°æ®é›†æˆï¼ˆä¼ä¸šæ•°æ®æ•´åˆï¼‰

**3. æ•°æ®è´¨é‡è¯„ä¼°**ï¼š

- æ•°æ®æ¸…æ´—ï¼ˆè¯†åˆ«å’Œå¤„ç†ä½è´¨é‡æ•°æ®ï¼‰
- æ•°æ®è´¨é‡ç›‘æ§ï¼ˆå®æ—¶ç›‘æ§æ•°æ®è´¨é‡ï¼‰
- æ•°æ®è´¨é‡æŠ¥å‘Šï¼ˆç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Šï¼‰

**4. æ•°æ®æº¯æºå’Œå®¡è®¡**ï¼š

- æ•°æ®æ²»ç†ï¼ˆæ•°æ®æ¥æºè¿½è¸ªï¼‰
- åˆè§„å®¡è®¡ï¼ˆæ»¡è¶³ç›‘ç®¡è¦æ±‚ï¼‰
- æ•°æ®è¡€ç¼˜åˆ†æï¼ˆåˆ†ææ•°æ®æµå‘ï¼‰

#### **1.3.3 æŠ€æœ¯ä¼˜åŠ¿**

**1. ç†è®ºåŸºç¡€æ‰å®**ï¼š

- åŸºäºæ¦‚ç‡è®ºå’Œå¯èƒ½ä¸–ç•Œè¯­ä¹‰
- æœ‰å®Œæ•´çš„æ•°å­¦ç†è®ºæ”¯æ’‘
- æœ‰æˆç†Ÿçš„ç®—æ³•å’Œä¼˜åŒ–æŠ€æœ¯

**2. å®ç°çµæ´»**ï¼š

- ä½œä¸ºPostgreSQLæ‰©å±•ï¼Œæ˜“äºé›†æˆ
- æ”¯æŒå¤šç§æ¦‚ç‡è¡¨ç¤ºæ–¹å¼
- æ”¯æŒè‡ªå®šä¹‰æ¦‚ç‡è®¡ç®—å‡½æ•°

**3. æ€§èƒ½ä¼˜åŒ–**ï¼š

- ä¼˜åŒ–çš„æ¦‚ç‡è®¡ç®—ç®—æ³•
- æ”¯æŒç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–
- æ”¯æŒæ‰¹é‡å¤„ç†å’Œç¼“å­˜

**4. æ ‡å‡†å…¼å®¹**ï¼š

- æ”¯æŒSQLæ ‡å‡†è¯­æ³•
- å…¼å®¹PostgreSQLç”Ÿæ€ç³»ç»Ÿ
- æ˜“äºä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

---

## 2. æŠ€æœ¯åŸç†

### 2.1 æ¦‚ç‡æ•°æ®åº“åŸºç¡€

#### **2.1.1 æ¦‚ç‡æ•°æ®åº“å®šä¹‰**

**æ¦‚ç‡æ•°æ®åº“ï¼ˆProbabilistic Databaseï¼‰**æ˜¯ä¸€ç§èƒ½å¤Ÿå­˜å‚¨å’ŒæŸ¥è¯¢ä¸ç¡®å®šæ€§æ•°æ®çš„æ•°æ®åº“ç³»ç»Ÿï¼Œæ¯ä¸ªæ•°æ®é¡¹éƒ½å…³è”ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œè¡¨ç¤ºè¯¥æ•°æ®é¡¹ä¸ºçœŸçš„å¯èƒ½æ€§ã€‚

**å½¢å¼åŒ–å®šä¹‰**ï¼š

```text
æ¦‚ç‡æ•°æ®åº“ PDB = (W, P)

å…¶ä¸­ï¼š
- W = {wâ‚, wâ‚‚, ..., wâ‚™} æ˜¯å¯èƒ½ä¸–ç•Œé›†åˆ
- P: W â†’ [0, 1] æ˜¯æ¦‚ç‡åˆ†å¸ƒå‡½æ•°
- Î£ P(wáµ¢) = 1ï¼ˆæ¦‚ç‡å½’ä¸€åŒ–ï¼‰
```

**ä¸ä¼ ç»Ÿæ•°æ®åº“çš„åŒºåˆ«**ï¼š

| ç‰¹æ€§ | ä¼ ç»Ÿæ•°æ®åº“ | æ¦‚ç‡æ•°æ®åº“ |
|------|-----------|-----------|
| **æ•°æ®ç¡®å®šæ€§** | ç¡®å®š | ä¸ç¡®å®š |
| **æ•°æ®è¡¨ç¤º** | ç²¾ç¡®å€¼ | å€¼+æ¦‚ç‡ |
| **æŸ¥è¯¢ç»“æœ** | ç¡®å®šæ€§ç»“æœ | æ¦‚ç‡åˆ†å¸ƒ |
| **é€‚ç”¨åœºæ™¯** | ç¡®å®šæ€§æ•°æ® | ä¸ç¡®å®šæ€§æ•°æ® |

#### **2.1.2 æ ¸å¿ƒæ¦‚å¿µ**

**1. å¯èƒ½ä¸–ç•Œï¼ˆPossible Worldsï¼‰**

**å®šä¹‰**ï¼šå¯èƒ½ä¸–ç•Œæ˜¯æ•°æ®çš„æ‰€æœ‰å¯èƒ½çŠ¶æ€ï¼Œæ¯ä¸ªå¯èƒ½ä¸–ç•Œæ˜¯ä¸€ä¸ªç¡®å®šæ€§çš„æ•°æ®åº“å®ä¾‹ã€‚

**ç¤ºä¾‹**ï¼š

```text
å‡è®¾æœ‰3ä¸ªä¸ç¡®å®šæ€§å…ƒç»„ï¼š
- tâ‚ (æ¦‚ç‡=0.8)
- tâ‚‚ (æ¦‚ç‡=0.6)
- tâ‚ƒ (æ¦‚ç‡=0.9)

å¯èƒ½ä¸–ç•Œï¼š
- wâ‚€: {} (ç©ºé›†)                    P(wâ‚€) = 0.2 Ã— 0.4 Ã— 0.1 = 0.008
- wâ‚: {tâ‚}                         P(wâ‚) = 0.8 Ã— 0.4 Ã— 0.1 = 0.032
- wâ‚‚: {tâ‚‚}                         P(wâ‚‚) = 0.2 Ã— 0.6 Ã— 0.1 = 0.012
- wâ‚ƒ: {tâ‚ƒ}                         P(wâ‚ƒ) = 0.2 Ã— 0.4 Ã— 0.9 = 0.072
- wâ‚„: {tâ‚, tâ‚‚}                     P(wâ‚„) = 0.8 Ã— 0.6 Ã— 0.1 = 0.048
- wâ‚…: {tâ‚, tâ‚ƒ}                     P(wâ‚…) = 0.8 Ã— 0.4 Ã— 0.9 = 0.288
- wâ‚†: {tâ‚‚, tâ‚ƒ}                     P(wâ‚†) = 0.2 Ã— 0.6 Ã— 0.9 = 0.108
- wâ‚‡: {tâ‚, tâ‚‚, tâ‚ƒ}                 P(wâ‚‡) = 0.8 Ã— 0.6 Ã— 0.9 = 0.432

éªŒè¯ï¼šÎ£ P(wáµ¢) = 1.0 âœ“
```

**2. æ¦‚ç‡åˆ†å¸ƒï¼ˆProbability Distributionï¼‰**

**å®šä¹‰**ï¼šæ¯ä¸ªå¯èƒ½ä¸–ç•Œæœ‰ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œæ‰€æœ‰å¯èƒ½ä¸–ç•Œçš„æ¦‚ç‡ä¹‹å’Œä¸º1ã€‚

**æ•°å­¦è¡¨ç¤º**ï¼š

```text
P: W â†’ [0, 1]
Î£ P(w) = 1
```

**3. æ¦‚ç‡æŸ¥è¯¢ï¼ˆProbabilistic Queryï¼‰**

**å®šä¹‰**ï¼šåœ¨æ¦‚ç‡æ•°æ®åº“ä¸Šæ‰§è¡Œçš„æŸ¥è¯¢ï¼Œè¿”å›ç»“æœåŠå…¶æ¦‚ç‡åˆ†å¸ƒã€‚

**æŸ¥è¯¢è¯­ä¹‰**ï¼š

```text
å¯¹äºæŸ¥è¯¢ Qï¼Œç»“æœ r çš„æ¦‚ç‡ä¸ºï¼š
P(Q = r) = Î£ P(w) Ã— I(Q(w) = r)

å…¶ä¸­ï¼š
- w æ˜¯å¯èƒ½ä¸–ç•Œ
- I(Q(w) = r) æ˜¯æŒ‡ç¤ºå‡½æ•°
```

#### **2.1.3 æ¦‚ç‡æ•°æ®åº“åˆ†ç±»**

**1. æŒ‰ä¸ç¡®å®šæ€§ç±»å‹åˆ†ç±»**ï¼š

- **å…ƒç»„çº§ä¸ç¡®å®šæ€§**ï¼šå…ƒç»„æ˜¯å¦å­˜åœ¨ä¸ç¡®å®š
- **å±æ€§çº§ä¸ç¡®å®šæ€§**ï¼šå±æ€§å€¼ä¸ç¡®å®š
- **å€¼çº§ä¸ç¡®å®šæ€§**ï¼šå€¼åœ¨æŸä¸ªèŒƒå›´å†…ä¸ç¡®å®š

**2. æŒ‰æ¦‚ç‡è¡¨ç¤ºæ–¹å¼åˆ†ç±»**ï¼š

- **æ˜¾å¼æ¦‚ç‡**ï¼šç›´æ¥å­˜å‚¨æ¦‚ç‡å€¼
- **éšå¼æ¦‚ç‡**ï¼šé€šè¿‡è§„åˆ™æ¨å¯¼æ¦‚ç‡
- **åˆ†å¸ƒæ¦‚ç‡**ï¼šå­˜å‚¨æ¦‚ç‡åˆ†å¸ƒå‡½æ•°

**3. æŒ‰æŸ¥è¯¢èƒ½åŠ›åˆ†ç±»**ï¼š

- **éƒ¨åˆ†åŒæ€**ï¼šæ”¯æŒéƒ¨åˆ†æŸ¥è¯¢æ“ä½œ
- **å®Œå…¨åŒæ€**ï¼šæ”¯æŒæ‰€æœ‰æŸ¥è¯¢æ“ä½œ

### 2.2 ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹

#### **2.2.1 ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹ç±»å‹**

**1. å…ƒç»„çº§ä¸ç¡®å®šæ€§ï¼ˆTuple-Level Uncertaintyï¼‰**

**å®šä¹‰**ï¼šæ¯ä¸ªå…ƒç»„å…³è”ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œè¡¨ç¤ºè¯¥å…ƒç»„å­˜åœ¨çš„å¯èƒ½æ€§ã€‚

**æ•°å­¦è¡¨ç¤º**ï¼š

```text
å…³ç³» R = {(tâ‚, pâ‚), (tâ‚‚, pâ‚‚), ..., (tâ‚™, pâ‚™)}

å…¶ä¸­ï¼š
- táµ¢ æ˜¯å…ƒç»„
- páµ¢ âˆˆ [0, 1] æ˜¯å…ƒç»„å­˜åœ¨çš„æ¦‚ç‡
```

**ç¤ºä¾‹**ï¼š

```sql
-- å…ƒç»„çº§ä¸ç¡®å®šæ€§è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
            CREATE TABLE sensor_readings (
                id SERIAL,
                sensor_id INT,
                temperature NUMERIC,
                probability NUMERIC  -- å…ƒç»„å­˜åœ¨çš„æ¦‚ç‡
            );
            RAISE NOTICE 'å…ƒç»„çº§ä¸ç¡®å®šæ€§è¡¨ sensor_readings åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'å…ƒç»„çº§ä¸ç¡®å®šæ€§è¡¨ sensor_readings å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'å…ƒç»„çº§ä¸ç¡®å®šæ€§è¡¨ sensor_readings å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºå…ƒç»„çº§ä¸ç¡®å®šæ€§è¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ’å…¥ä¸ç¡®å®šæ€§å…ƒç»„ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
DECLARE
    inserted_count INT;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
            RAISE WARNING 'è¡¨ sensor_readings ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO sensor_readings VALUES
            (1, 1, 25.5, 0.95),  -- 95%æ¦‚ç‡å­˜åœ¨
            (2, 1, 25.7, 0.90),  -- 90%æ¦‚ç‡å­˜åœ¨
            (3, 1, 25.3, 0.85)   -- 85%æ¦‚ç‡å­˜åœ¨
        ON CONFLICT DO NOTHING;

        GET DIAGNOSTICS inserted_count = ROW_COUNT;
        RAISE NOTICE 'æˆåŠŸæ’å…¥ % æ¡ä¸ç¡®å®šæ€§å…ƒç»„', inserted_count;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥ä¸ç¡®å®šæ€§å…ƒç»„å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**åº”ç”¨åœºæ™¯**ï¼š

- ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆæµ‹é‡è¯¯å·®ï¼‰
- æ•°æ®èåˆï¼ˆå¤šæºæ•°æ®ä¸ä¸€è‡´ï¼‰
- æ•°æ®æ¸…æ´—ï¼ˆæ•°æ®è´¨é‡ä¸ç¡®å®šï¼‰

**2. å±æ€§çº§ä¸ç¡®å®šæ€§ï¼ˆAttribute-Level Uncertaintyï¼‰**

**å®šä¹‰**ï¼šæ¯ä¸ªå±æ€§å€¼å…³è”ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œè¡¨ç¤ºè¯¥å±æ€§å€¼çš„å¯èƒ½æ€§ã€‚

**æ•°å­¦è¡¨ç¤º**ï¼š

```text
å…ƒç»„ t = (aâ‚: Dâ‚, aâ‚‚: Dâ‚‚, ..., aâ‚™: Dâ‚™)

å…¶ä¸­ï¼š
- aáµ¢ æ˜¯å±æ€§
- Dáµ¢ æ˜¯å±æ€§å€¼çš„æ¦‚ç‡åˆ†å¸ƒï¼šDáµ¢ = {(vâ‚, pâ‚), (vâ‚‚, pâ‚‚), ...}
```

**ç¤ºä¾‹**ï¼š

```sql
-- å±æ€§çº§ä¸ç¡®å®šæ€§è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'uncertain_sensor_data') THEN
            CREATE TABLE uncertain_sensor_data (
                id SERIAL,
                sensor_id INT,
                temperature_prob_distribution JSONB,  -- æ¸©åº¦çš„æ¦‚ç‡åˆ†å¸ƒ
                humidity_prob_distribution JSONB      -- æ¹¿åº¦çš„æ¦‚ç‡åˆ†å¸ƒ
            );
            RAISE NOTICE 'å±æ€§çº§ä¸ç¡®å®šæ€§è¡¨ uncertain_sensor_data åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'å±æ€§çº§ä¸ç¡®å®šæ€§è¡¨ uncertain_sensor_data å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'å±æ€§çº§ä¸ç¡®å®šæ€§è¡¨ uncertain_sensor_data å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºå±æ€§çº§ä¸ç¡®å®šæ€§è¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ’å…¥å±æ€§çº§ä¸ç¡®å®šæ€§æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
DECLARE
    inserted_count INT;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'uncertain_sensor_data') THEN
            RAISE WARNING 'è¡¨ uncertain_sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO uncertain_sensor_data VALUES (
            1,
            1,
            '{"25.5": 0.4, "25.6": 0.3, "25.7": 0.3}'::JSONB,  -- æ¸©åº¦çš„æ¦‚ç‡åˆ†å¸ƒ
            '{"60": 0.5, "61": 0.3, "62": 0.2}'::JSONB         -- æ¹¿åº¦çš„æ¦‚ç‡åˆ†å¸ƒ
        ) ON CONFLICT DO NOTHING;

        GET DIAGNOSTICS inserted_count = ROW_COUNT;
        RAISE NOTICE 'æˆåŠŸæ’å…¥ % æ¡å±æ€§çº§ä¸ç¡®å®šæ€§æ•°æ®', inserted_count;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥å±æ€§çº§ä¸ç¡®å®šæ€§æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**åº”ç”¨åœºæ™¯**ï¼š

- ä¼ æ„Ÿå™¨æµ‹é‡èŒƒå›´
- æ•°æ®é¢„æµ‹ï¼ˆæœºå™¨å­¦ä¹ è¾“å‡ºï¼‰
- æ•°æ®æ’å€¼ï¼ˆç¼ºå¤±å€¼ä¼°è®¡ï¼‰

**3. å­˜åœ¨ä¸ç¡®å®šæ€§ï¼ˆExistence Uncertaintyï¼‰**

**å®šä¹‰**ï¼šå…ƒç»„æ˜¯å¦å­˜åœ¨ä¸ç¡®å®šï¼Œé€šè¿‡æ¦‚ç‡å€¼è¡¨ç¤ºã€‚

**ä¸å…ƒç»„çº§ä¸ç¡®å®šæ€§çš„åŒºåˆ«**ï¼š

| ç‰¹æ€§ | å…ƒç»„çº§ä¸ç¡®å®šæ€§ | å­˜åœ¨ä¸ç¡®å®šæ€§ |
|------|--------------|-------------|
| **å…³æ³¨ç‚¹** | å…ƒç»„çš„å€¼ | å…ƒç»„çš„å­˜åœ¨æ€§ |
| **æ¦‚ç‡å«ä¹‰** | å…ƒç»„å€¼æ­£ç¡®çš„æ¦‚ç‡ | å…ƒç»„å­˜åœ¨çš„æ¦‚ç‡ |
| **åº”ç”¨** | æ•°æ®è´¨é‡ | æ•°æ®å®Œæ•´æ€§ |

**ç¤ºä¾‹**ï¼š

```sql
-- å­˜åœ¨ä¸ç¡®å®šæ€§ï¼šå…ƒç»„å¯èƒ½ä¸å­˜åœ¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'possible_events') THEN
            CREATE TABLE possible_events (
                id SERIAL,
                event_type TEXT,
                occurrence_probability NUMERIC  -- äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡
            );
            RAISE NOTICE 'å­˜åœ¨ä¸ç¡®å®šæ€§è¡¨ possible_events åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'å­˜åœ¨ä¸ç¡®å®šæ€§è¡¨ possible_events å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'å­˜åœ¨ä¸ç¡®å®šæ€§è¡¨ possible_events å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºå­˜åœ¨ä¸ç¡®å®šæ€§è¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ’å…¥å­˜åœ¨ä¸ç¡®å®šæ€§æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
DECLARE
    inserted_count INT;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'possible_events') THEN
            RAISE WARNING 'è¡¨ possible_events ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO possible_events VALUES
            ('sensor_failure', 0.05),    -- 5%æ¦‚ç‡ä¼ æ„Ÿå™¨æ•…éšœ
            ('data_corruption', 0.02),   -- 2%æ¦‚ç‡æ•°æ®æŸå
            ('network_timeout', 0.10)    -- 10%æ¦‚ç‡ç½‘ç»œè¶…æ—¶
        ON CONFLICT DO NOTHING;

        GET DIAGNOSTICS inserted_count = ROW_COUNT;
        RAISE NOTICE 'æˆåŠŸæ’å…¥ % æ¡å­˜åœ¨ä¸ç¡®å®šæ€§æ•°æ®', inserted_count;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥å­˜åœ¨ä¸ç¡®å®šæ€§æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### **2.2.2 ä¸ç¡®å®šæ€§æ¥æº**

ä¸ç¡®å®šæ€§æ•°æ®çš„æ¥æºå¤šç§å¤šæ ·ï¼Œç†è§£è¿™äº›æ¥æºæœ‰åŠ©äºæ­£ç¡®å»ºæ¨¡å’Œå¤„ç†ä¸ç¡®å®šæ€§æ•°æ®ã€‚

**1. æµ‹é‡ä¸ç¡®å®šæ€§**ï¼š

**å®šä¹‰**ï¼šç”±äºæµ‹é‡è®¾å¤‡ã€ç¯å¢ƒæ¡ä»¶æˆ–æµ‹é‡æ–¹æ³•å¯¼è‡´çš„æµ‹é‡å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ã€‚

**ä¸»è¦æ¥æº**ï¼š

- **ä¼ æ„Ÿå™¨è¯¯å·®**ï¼š
  - ç³»ç»Ÿè¯¯å·®ï¼šä¼ æ„Ÿå™¨æ ¡å‡†ä¸å‡†ç¡®å¯¼è‡´çš„å›ºå®šåå·®
  - éšæœºè¯¯å·®ï¼šä¼ æ„Ÿå™¨å™ªå£°å¯¼è‡´çš„éšæœºæ³¢åŠ¨
  - é‡åŒ–è¯¯å·®ï¼šADCè½¬æ¢ç²¾åº¦é™åˆ¶å¯¼è‡´çš„é‡åŒ–è¯¯å·®
  - ç¤ºä¾‹ï¼šæ¸©åº¦ä¼ æ„Ÿå™¨ç²¾åº¦Â±0.5Â°Cï¼Œæµ‹é‡å€¼25.5Â°Cçš„å®é™…èŒƒå›´å¯èƒ½æ˜¯[25.0Â°C, 26.0Â°C]

- **æµ‹é‡ç²¾åº¦é™åˆ¶**ï¼š
  - è®¾å¤‡ç²¾åº¦ï¼šæµ‹é‡è®¾å¤‡çš„å›ºæœ‰ç²¾åº¦é™åˆ¶
  - åˆ†è¾¨ç‡é™åˆ¶ï¼šæ•°å­—ä¼ æ„Ÿå™¨çš„åˆ†è¾¨ç‡é™åˆ¶
  - ç¤ºä¾‹ï¼šæ¹¿åº¦ä¼ æ„Ÿå™¨åˆ†è¾¨ç‡1%ï¼Œæµ‹é‡å€¼60%çš„å®é™…èŒƒå›´å¯èƒ½æ˜¯[59.5%, 60.5%]

- **ç¯å¢ƒå¹²æ‰°**ï¼š
  - ç”µç£å¹²æ‰°ï¼šç”µç£åœºå¯¹ä¼ æ„Ÿå™¨çš„å½±å“
  - æ¸©åº¦æ¼‚ç§»ï¼šç¯å¢ƒæ¸©åº¦å˜åŒ–å¯¹ä¼ æ„Ÿå™¨çš„å½±å“
  - æŒ¯åŠ¨å¹²æ‰°ï¼šæœºæ¢°æŒ¯åŠ¨å¯¹ä¼ æ„Ÿå™¨çš„å½±å“
  - ç¤ºä¾‹ï¼šåœ¨å¼ºç”µç£åœºç¯å¢ƒä¸­ï¼Œä¼ æ„Ÿå™¨è¯»æ•°å¯èƒ½å—åˆ°å¹²æ‰°ï¼Œç½®ä¿¡åº¦é™ä½

**å»ºæ¨¡æ–¹æ³•**ï¼š

```sql
-- æµ‹é‡ä¸ç¡®å®šæ€§å»ºæ¨¡ç¤ºä¾‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_measurements') THEN
            CREATE TABLE sensor_measurements (
                id SERIAL PRIMARY KEY,
                sensor_id INT NOT NULL,
                measured_value NUMERIC NOT NULL,
                measurement_error NUMERIC NOT NULL,  -- æµ‹é‡è¯¯å·®èŒƒå›´
                confidence NUMERIC CHECK (confidence >= 0 AND confidence <= 1),
                measurement_time TIMESTAMP DEFAULT NOW()
            );
            RAISE NOTICE 'æµ‹é‡ä¸ç¡®å®šæ€§è¡¨ sensor_measurements åˆ›å»ºæˆåŠŸ';

            -- åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            CREATE INDEX idx_sensor_measurements_sensor ON sensor_measurements(sensor_id, measurement_time DESC);
            CREATE INDEX idx_sensor_measurements_confidence ON sensor_measurements(confidence);
            RAISE NOTICE 'æµ‹é‡ä¸ç¡®å®šæ€§è¡¨ç´¢å¼•åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'æµ‹é‡ä¸ç¡®å®šæ€§è¡¨ sensor_measurements å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'æµ‹é‡ä¸ç¡®å®šæ€§è¡¨ sensor_measurements å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæµ‹é‡ä¸ç¡®å®šæ€§è¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ’å…¥æµ‹é‡æ•°æ®ï¼ˆè€ƒè™‘æµ‹é‡è¯¯å·®ï¼Œå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
DECLARE
    inserted_count INT;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_measurements') THEN
            RAISE WARNING 'è¡¨ sensor_measurements ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO sensor_measurements (sensor_id, measured_value, measurement_error, confidence)
        VALUES
            (1, 25.5, 0.5, 0.95),  -- æµ‹é‡å€¼25.5ï¼Œè¯¯å·®Â±0.5ï¼Œç½®ä¿¡åº¦95%
            (2, 60.0, 1.0, 0.90),  -- æµ‹é‡å€¼60.0ï¼Œè¯¯å·®Â±1.0ï¼Œç½®ä¿¡åº¦90%
            (3, 1013.25, 0.05, 0.98)  -- æµ‹é‡å€¼1013.25ï¼Œè¯¯å·®Â±0.05ï¼Œç½®ä¿¡åº¦98%
        ON CONFLICT DO NOTHING;

        GET DIAGNOSTICS inserted_count = ROW_COUNT;
        RAISE NOTICE 'æˆåŠŸæ’å…¥ % æ¡æµ‹é‡æ•°æ®', inserted_count;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥æµ‹é‡æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**2. æ•°æ®èåˆä¸ç¡®å®šæ€§**ï¼š

**å®šä¹‰**ï¼šåœ¨æ•´åˆæ¥è‡ªå¤šä¸ªæ•°æ®æºçš„ä¿¡æ¯æ—¶ï¼Œç”±äºæ•°æ®æºä¹‹é—´çš„ä¸ä¸€è‡´æ€§å¯¼è‡´çš„ä¸ç¡®å®šæ€§ã€‚

**ä¸»è¦æ¥æº**ï¼š

- **å¤šæºæ•°æ®ä¸ä¸€è‡´**ï¼š
  - ä¸åŒæ•°æ®æºå¯¹åŒä¸€å®ä½“çš„æè¿°ä¸åŒ
  - æ•°æ®æ ¼å¼å’Œå•ä½ä¸ç»Ÿä¸€
  - æ•°æ®æ›´æ–°é¢‘ç‡ä¸åŒ
  - ç¤ºä¾‹ï¼šä¸¤ä¸ªæ•°æ®æºå¯¹åŒä¸€å®¢æˆ·çš„å¹´é¾„ä¿¡æ¯ä¸åŒï¼ˆ25å² vs 26å²ï¼‰

- **æ•°æ®å†²çª**ï¼š
  - åŒä¸€å®ä½“çš„ä¸åŒæ•°æ®æºæ•°æ®ç›¸äº’çŸ›ç›¾
  - æ•°æ®æºçš„å¯ä¿¡åº¦ä¸åŒ
  - æ•°æ®æºçš„æ—¶é—´æˆ³ä¸åŒ
  - ç¤ºä¾‹ï¼šä¼ æ„Ÿå™¨AæŠ¥å‘Šæ¸©åº¦25.5Â°Cï¼Œä¼ æ„Ÿå™¨BæŠ¥å‘Š26.0Â°Cï¼Œä¸¤è€…å­˜åœ¨å†²çª

- **æ•°æ®è´¨é‡å·®å¼‚**ï¼š
  - ä¸åŒæ•°æ®æºçš„æ•°æ®è´¨é‡ä¸åŒ
  - æ•°æ®æºçš„å¯é æ€§ä¸åŒ
  - æ•°æ®æºçš„å®Œæ•´æ€§ä¸åŒ
  - ç¤ºä¾‹ï¼šæ•°æ®æºAçš„æ•°æ®è´¨é‡é«˜ï¼ˆç½®ä¿¡åº¦0.95ï¼‰ï¼Œæ•°æ®æºBçš„æ•°æ®è´¨é‡ä½ï¼ˆç½®ä¿¡åº¦0.70ï¼‰

**å»ºæ¨¡æ–¹æ³•**ï¼š

```sql
-- æ•°æ®èåˆä¸ç¡®å®šæ€§å»ºæ¨¡ç¤ºä¾‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'multi_source_data') THEN
            CREATE TABLE multi_source_data (
                id SERIAL PRIMARY KEY,
                entity_id INT NOT NULL,
                data_source VARCHAR(50) NOT NULL,
                attribute_name VARCHAR(50) NOT NULL,
                attribute_value NUMERIC NOT NULL,
                source_reliability NUMERIC CHECK (source_reliability >= 0 AND source_reliability <= 1),
                timestamp TIMESTAMP DEFAULT NOW()
            );
            RAISE NOTICE 'å¤šæºæ•°æ®è¡¨ multi_source_data åˆ›å»ºæˆåŠŸ';

            -- åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            CREATE INDEX idx_multi_source_data_entity ON multi_source_data(entity_id, attribute_name);
            CREATE INDEX idx_multi_source_data_source ON multi_source_data(data_source, timestamp DESC);
            CREATE INDEX idx_multi_source_data_reliability ON multi_source_data(source_reliability);
            RAISE NOTICE 'å¤šæºæ•°æ®è¡¨ç´¢å¼•åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'å¤šæºæ•°æ®è¡¨ multi_source_data å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'å¤šæºæ•°æ®è¡¨ multi_source_data å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºå¤šæºæ•°æ®è¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ’å…¥å¤šæºæ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
DECLARE
    inserted_count INT;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'multi_source_data') THEN
            RAISE WARNING 'è¡¨ multi_source_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO multi_source_data (entity_id, data_source, attribute_name, attribute_value, source_reliability)
        VALUES
            (1, 'Sensor_A', 'temperature', 25.5, 0.95),
            (1, 'Sensor_B', 'temperature', 26.0, 0.90),
            (1, 'Sensor_C', 'temperature', 25.8, 0.85)
        ON CONFLICT DO NOTHING;

        GET DIAGNOSTICS inserted_count = ROW_COUNT;
        RAISE NOTICE 'æˆåŠŸæ’å…¥ % æ¡å¤šæºæ•°æ®', inserted_count;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥å¤šæºæ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ•°æ®èåˆæŸ¥è¯¢ï¼ˆåŠ æƒå¹³å‡ï¼‰
SELECT
    entity_id,
    attribute_name,
    COUNT(*) AS source_count,
    AVG(attribute_value) AS simple_avg,
    SUM(attribute_value * source_reliability) / SUM(source_reliability) AS weighted_avg,
    AVG(source_reliability) AS avg_reliability
FROM multi_source_data
GROUP BY entity_id, attribute_name;
```

**3. æ¨æ–­ä¸ç¡®å®šæ€§**ï¼š

**å®šä¹‰**ï¼šé€šè¿‡æ¨ç†ã€é¢„æµ‹æˆ–ä¼°è®¡å¾—åˆ°çš„æ•°æ®ï¼Œå…¶ä¸ç¡®å®šæ€§æ¥è‡ªäºæ¨ç†è¿‡ç¨‹æœ¬èº«ã€‚

**ä¸»è¦æ¥æº**ï¼š

- **æœºå™¨å­¦ä¹ é¢„æµ‹**ï¼š
  - æ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦
  - è®­ç»ƒæ•°æ®çš„ä¸ç¡®å®šæ€§
  - æ¨¡å‹æ³›åŒ–è¯¯å·®
  - ç¤ºä¾‹ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹å®¢æˆ·è´­ä¹°æ¦‚ç‡ä¸º0.75ï¼Œä½†æ¨¡å‹æœ¬èº«çš„å‡†ç¡®ç‡ä¸º85%

- **æ•°æ®æ’å€¼**ï¼š
  - ç¼ºå¤±å€¼çš„ä¼°è®¡
  - æ—¶é—´åºåˆ—æ’å€¼
  - ç©ºé—´æ’å€¼
  - ç¤ºä¾‹ï¼šé€šè¿‡çº¿æ€§æ’å€¼ä¼°è®¡ç¼ºå¤±çš„æ¸©åº¦å€¼ï¼Œæ’å€¼ç»“æœçš„ä¸ç¡®å®šæ€§å–å†³äºç›¸é‚»æ•°æ®çš„å¯é æ€§

- **ç¼ºå¤±å€¼ä¼°è®¡**ï¼š
  - åŸºäºç»Ÿè®¡æ–¹æ³•çš„ä¼°è®¡
  - åŸºäºæ¨¡å‹çš„ä¼°è®¡
  - åŸºäºè§„åˆ™çš„ä¼°è®¡
  - ç¤ºä¾‹ï¼šä½¿ç”¨å¹³å‡å€¼ä¼°è®¡ç¼ºå¤±çš„å¹´é¾„å€¼ï¼Œä¼°è®¡å€¼çš„ä¸ç¡®å®šæ€§å–å†³äºæ ·æœ¬å¤§å°å’Œæ–¹å·®

**å»ºæ¨¡æ–¹æ³•**ï¼š

```sql
-- æ¨æ–­ä¸ç¡®å®šæ€§å»ºæ¨¡ç¤ºä¾‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'inferred_data') THEN
            CREATE TABLE inferred_data (
                id SERIAL PRIMARY KEY,
                entity_id INT NOT NULL,
                attribute_name VARCHAR(50) NOT NULL,
                inferred_value NUMERIC NOT NULL,
                inference_method VARCHAR(50) NOT NULL,  -- 'ML', 'interpolation', 'statistical'
                inference_confidence NUMERIC CHECK (inference_confidence >= 0 AND inference_confidence <= 1),
                model_accuracy NUMERIC,  -- æ¨¡å‹å‡†ç¡®ç‡ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
                timestamp TIMESTAMP DEFAULT NOW()
            );
            RAISE NOTICE 'æ¨æ–­æ•°æ®è¡¨ inferred_data åˆ›å»ºæˆåŠŸ';

            -- åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            CREATE INDEX idx_inferred_data_entity ON inferred_data(entity_id, attribute_name);
            CREATE INDEX idx_inferred_data_method ON inferred_data(inference_method, timestamp DESC);
            CREATE INDEX idx_inferred_data_confidence ON inferred_data(inference_confidence);
            RAISE NOTICE 'æ¨æ–­æ•°æ®è¡¨ç´¢å¼•åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'æ¨æ–­æ•°æ®è¡¨ inferred_data å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'æ¨æ–­æ•°æ®è¡¨ inferred_data å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæ¨æ–­æ•°æ®è¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ’å…¥æ¨æ–­æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
DECLARE
    inserted_count INT;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'inferred_data') THEN
            RAISE WARNING 'è¡¨ inferred_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO inferred_data (entity_id, attribute_name, inferred_value, inference_method, inference_confidence, model_accuracy)
        VALUES
            (1, 'purchase_probability', 0.75, 'ML', 0.85, 0.90),  -- MLé¢„æµ‹ï¼Œç½®ä¿¡åº¦85%ï¼Œæ¨¡å‹å‡†ç¡®ç‡90%
            (2, 'temperature', 25.3, 'interpolation', 0.80, NULL),  -- æ’å€¼ä¼°è®¡ï¼Œç½®ä¿¡åº¦80%
            (3, 'age', 30, 'statistical', 0.70, NULL)  -- ç»Ÿè®¡ä¼°è®¡ï¼Œç½®ä¿¡åº¦70%
        ON CONFLICT DO NOTHING;

        GET DIAGNOSTICS inserted_count = ROW_COUNT;
        RAISE NOTICE 'æˆåŠŸæ’å…¥ % æ¡æ¨æ–­æ•°æ®', inserted_count;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥æ¨æ–­æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**4. æ—¶é—´ä¸ç¡®å®šæ€§**ï¼š

**å®šä¹‰**ï¼šç”±äºæ—¶é—´æˆ³ä¸å‡†ç¡®ã€æ•°æ®å»¶è¿Ÿæˆ–æ•°æ®è¿‡æœŸå¯¼è‡´çš„æ—¶é—´ç›¸å…³çš„ä¸ç¡®å®šæ€§ã€‚

**ä¸»è¦æ¥æº**ï¼š

- **æ•°æ®æ—¶é—´æˆ³ä¸å‡†ç¡®**ï¼š
  - æ—¶é’ŸåŒæ­¥é—®é¢˜
  - æ—¶åŒºè½¬æ¢é”™è¯¯
  - æ—¶é—´æˆ³ç²¾åº¦é™åˆ¶
  - ç¤ºä¾‹ï¼šä¼ æ„Ÿå™¨æ—¶é—´æˆ³å¯èƒ½ä¸å‡†ç¡®ï¼Œå®é™…æµ‹é‡æ—¶é—´ä¸è®°å½•æ—¶é—´å­˜åœ¨Â±5ç§’çš„è¯¯å·®

- **æ•°æ®å»¶è¿Ÿ**ï¼š
  - ç½‘ç»œä¼ è¾“å»¶è¿Ÿ
  - å¤„ç†å»¶è¿Ÿ
  - å­˜å‚¨å»¶è¿Ÿ
  - ç¤ºä¾‹ï¼šä¼ æ„Ÿå™¨æ•°æ®åœ¨ç½‘ç»œä¼ è¾“è¿‡ç¨‹ä¸­å»¶è¿Ÿ10ç§’ï¼Œå¯¼è‡´æ—¶é—´æˆ³ä¸å‡†ç¡®

- **æ•°æ®è¿‡æœŸ**ï¼š
  - æ•°æ®æ—¶æ•ˆæ€§
  - æ•°æ®æ–°é²œåº¦
  - æ•°æ®æœ‰æ•ˆæ€§çª—å£
  - ç¤ºä¾‹ï¼šä¼ æ„Ÿå™¨æ•°æ®åœ¨5åˆ†é’Ÿåè¿‡æœŸï¼Œè¿‡æœŸæ•°æ®çš„ç½®ä¿¡åº¦éšæ—¶é—´è¡°å‡

**å»ºæ¨¡æ–¹æ³•**ï¼š

```sql
-- æ—¶é—´ä¸ç¡®å®šæ€§å»ºæ¨¡ç¤ºä¾‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'time_uncertain_data') THEN
            CREATE TABLE time_uncertain_data (
                id SERIAL PRIMARY KEY,
                sensor_id INT NOT NULL,
                value NUMERIC NOT NULL,
                recorded_time TIMESTAMP NOT NULL,
                actual_time_lower TIMESTAMP,  -- å®é™…æ—¶é—´ä¸‹ç•Œ
                actual_time_upper TIMESTAMP,  -- å®é™…æ—¶é—´ä¸Šç•Œ
                time_uncertainty INTERVAL,  -- æ—¶é—´ä¸ç¡®å®šæ€§èŒƒå›´
                data_freshness INTERVAL,  -- æ•°æ®æ–°é²œåº¦
                confidence NUMERIC CHECK (confidence >= 0 AND confidence <= 1),
                created_at TIMESTAMP DEFAULT NOW()
            );
            RAISE NOTICE 'æ—¶é—´ä¸ç¡®å®šæ€§è¡¨ time_uncertain_data åˆ›å»ºæˆåŠŸ';

            -- åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            CREATE INDEX idx_time_uncertain_data_sensor ON time_uncertain_data(sensor_id, recorded_time DESC);
            CREATE INDEX idx_time_uncertain_data_time_range ON time_uncertain_data(actual_time_lower, actual_time_upper);
            CREATE INDEX idx_time_uncertain_data_confidence ON time_uncertain_data(confidence);
            RAISE NOTICE 'æ—¶é—´ä¸ç¡®å®šæ€§è¡¨ç´¢å¼•åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'æ—¶é—´ä¸ç¡®å®šæ€§è¡¨ time_uncertain_data å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'æ—¶é—´ä¸ç¡®å®šæ€§è¡¨ time_uncertain_data å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæ—¶é—´ä¸ç¡®å®šæ€§è¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ’å…¥æ—¶é—´ä¸ç¡®å®šæ•°æ®
INSERT INTO time_uncertain_data (
    sensor_id, value, recorded_time, actual_time_lower, actual_time_upper,
    time_uncertainty, data_freshness, confidence
)
VALUES
    (
        1, 25.5, '2025-01-15 10:00:00',
        '2025-01-15 09:59:55', '2025-01-15 10:00:05',
        INTERVAL '10 seconds', INTERVAL '5 minutes', 0.90
    );

-- æŸ¥è¯¢è€ƒè™‘æ—¶é—´ä¸ç¡®å®šæ€§çš„æ•°æ®
SELECT
    sensor_id,
    value,
    recorded_time,
    actual_time_lower,
    actual_time_upper,
    confidence,
    CASE
        WHEN NOW() - recorded_time > data_freshness THEN
            confidence * EXP(-EXTRACT(EPOCH FROM (NOW() - recorded_time - data_freshness)) / 3600.0)
        ELSE confidence
    END AS adjusted_confidence
FROM time_uncertain_data
WHERE recorded_time BETWEEN actual_time_lower AND actual_time_upper;
```

**ä¸ç¡®å®šæ€§æ¥æºçš„ç»¼åˆå¤„ç†**ï¼š

```sql
-- ç»¼åˆä¸ç¡®å®šæ€§å¤„ç†ç¤ºä¾‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'comprehensive_uncertain_data') THEN
            CREATE TABLE comprehensive_uncertain_data (
                id SERIAL PRIMARY KEY,
                sensor_id INT NOT NULL,
                value NUMERIC NOT NULL,
                -- æµ‹é‡ä¸ç¡®å®šæ€§
                measurement_error NUMERIC,
                measurement_confidence NUMERIC,
                -- æ•°æ®èåˆä¸ç¡®å®šæ€§
                source_reliability NUMERIC,
                source_count INT,
                -- æ¨æ–­ä¸ç¡®å®šæ€§
                inference_method VARCHAR(50),
                inference_confidence NUMERIC,
                -- æ—¶é—´ä¸ç¡®å®šæ€§
                time_uncertainty INTERVAL,
                data_freshness INTERVAL,
                -- ç»¼åˆç½®ä¿¡åº¦
                overall_confidence NUMERIC CHECK (overall_confidence >= 0 AND overall_confidence <= 1),
                timestamp TIMESTAMP DEFAULT NOW()
            );
            RAISE NOTICE 'ç»¼åˆä¸ç¡®å®šæ€§å¤„ç†è¡¨åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'ç»¼åˆä¸ç¡®å®šæ€§å¤„ç†è¡¨å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç»¼åˆä¸ç¡®å®šæ€§å¤„ç†è¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- è®¡ç®—ç»¼åˆç½®ä¿¡åº¦ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        CREATE OR REPLACE FUNCTION calculate_overall_confidence(
            meas_conf NUMERIC,
            source_rel NUMERIC,
            infer_conf NUMERIC,
            time_factor NUMERIC
        ) RETURNS NUMERIC AS $$
        BEGIN
            -- å‚æ•°éªŒè¯
            IF meas_conf IS NULL OR meas_conf < 0 OR meas_conf > 1 THEN
                RAISE EXCEPTION 'meas_confå¿…é¡»ä»‹äº0å’Œ1ä¹‹é—´';
            END IF;

            IF source_rel IS NULL OR source_rel < 0 OR source_rel > 1 THEN
                RAISE EXCEPTION 'source_relå¿…é¡»ä»‹äº0å’Œ1ä¹‹é—´';
            END IF;

            IF infer_conf IS NULL OR infer_conf < 0 OR infer_conf > 1 THEN
                RAISE EXCEPTION 'infer_confå¿…é¡»ä»‹äº0å’Œ1ä¹‹é—´';
            END IF;

            IF time_factor IS NULL OR time_factor < 0 OR time_factor > 1 THEN
                RAISE EXCEPTION 'time_factorå¿…é¡»ä»‹äº0å’Œ1ä¹‹é—´';
            END IF;

            BEGIN
                -- ç»¼åˆç½®ä¿¡åº¦ = æµ‹é‡ç½®ä¿¡åº¦ Ã— æ•°æ®æºå¯é æ€§ Ã— æ¨æ–­ç½®ä¿¡åº¦ Ã— æ—¶é—´å› å­
                RETURN meas_conf * source_rel * infer_conf * time_factor;
            EXCEPTION
                WHEN OTHERS THEN
                    RAISE EXCEPTION 'è®¡ç®—ç»¼åˆç½®ä¿¡åº¦å¤±è´¥: %', SQLERRM;
            END;
        END;
        $$ LANGUAGE plpgsql IMMUTABLE;
        RAISE NOTICE 'ç»¼åˆç½®ä¿¡åº¦è®¡ç®—å‡½æ•° calculate_overall_confidence åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç»¼åˆç½®ä¿¡åº¦è®¡ç®—å‡½æ•°å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### **2.2.3 æ¦‚ç‡å€¼è¡¨ç¤ºæ–¹æ³•**

**1. ç‚¹æ¦‚ç‡ï¼ˆPoint Probabilityï¼‰**ï¼š

```text
å•ä¸ªæ¦‚ç‡å€¼ï¼šp âˆˆ [0, 1]
ç¤ºä¾‹ï¼šP(t) = 0.95
```

**2. åŒºé—´æ¦‚ç‡ï¼ˆInterval Probabilityï¼‰**ï¼š

```text
æ¦‚ç‡åŒºé—´ï¼š[p_min, p_max] âŠ† [0, 1]
ç¤ºä¾‹ï¼šP(t) âˆˆ [0.8, 0.95]
```

**3. æ¦‚ç‡åˆ†å¸ƒï¼ˆProbability Distributionï¼‰**ï¼š

```text
æ¦‚ç‡åˆ†å¸ƒå‡½æ•°ï¼šf: V â†’ [0, 1]
ç¤ºä¾‹ï¼šP(temperature = 25.5) = 0.4
      P(temperature = 25.6) = 0.3
      P(temperature = 25.7) = 0.3
```

**4. ç½®ä¿¡åŒºé—´ï¼ˆConfidence Intervalï¼‰**ï¼š

```text
å€¼åŒºé—´ + ç½®ä¿¡åº¦ï¼š(v_min, v_max, confidence)
ç¤ºä¾‹ï¼štemperature âˆˆ [25.0, 26.0] with 95% confidence
```

### 2.3 æ¦‚ç‡æŸ¥è¯¢å¤„ç†

#### **2.3.1 æ¦‚ç‡æŸ¥è¯¢åŸºç¡€**

**æ¦‚ç‡æŸ¥è¯¢å®šä¹‰**ï¼š

æ¦‚ç‡æŸ¥è¯¢æ˜¯åœ¨ä¸ç¡®å®šæ€§æ•°æ®ä¸Šæ‰§è¡Œçš„æŸ¥è¯¢ï¼Œè¿”å›ç»“æœåŠå…¶æ¦‚ç‡åˆ†å¸ƒã€‚

**æŸ¥è¯¢è¯­ä¹‰**ï¼š

- **å¯èƒ½ä¸–ç•Œè¯­ä¹‰ï¼ˆPossible Worlds Semanticsï¼‰**ï¼šæ¯ä¸ªå¯èƒ½ä¸–ç•Œæ˜¯ä¸€ä¸ªç¡®å®šæ€§çš„æ•°æ®åº“å®ä¾‹
- **æ¦‚ç‡åˆ†å¸ƒ**ï¼šæ¯ä¸ªå¯èƒ½ä¸–ç•Œæœ‰ä¸€ä¸ªæ¦‚ç‡å€¼
- **æŸ¥è¯¢ç»“æœæ¦‚ç‡**ï¼šæŸ¥è¯¢ç»“æœåœ¨æ‰€æœ‰å¯èƒ½ä¸–ç•Œä¸­çš„æ¦‚ç‡ä¹‹å’Œ

#### **2.3.2 æ¦‚ç‡æŸ¥è¯¢ç±»å‹**

**1. æ¦‚ç‡é€‰æ‹©ï¼ˆProbabilistic Selectionï¼‰**

**å®šä¹‰**ï¼šé€‰æ‹©æ»¡è¶³æ¡ä»¶çš„å…ƒç»„ï¼Œè®¡ç®—ç»“æœçš„æ¦‚ç‡ã€‚

**æ•°å­¦åŸç†**ï¼š

```text
ç»™å®šæŸ¥è¯¢æ¡ä»¶ Î¸ï¼Œå…ƒç»„ t çš„æ¦‚ç‡ä¸ºï¼š
P(t | Î¸) = P(t) Ã— I(Î¸(t))

å…¶ä¸­ï¼š
- P(t) æ˜¯å…ƒç»„ t çš„æ¦‚ç‡
- I(Î¸(t)) æ˜¯æŒ‡ç¤ºå‡½æ•°ï¼Œæ»¡è¶³æ¡ä»¶ä¸º1ï¼Œå¦åˆ™ä¸º0
```

**ç®—æ³•**ï¼š

```python
def probabilistic_selection(relation, condition):
    """
    æ¦‚ç‡é€‰æ‹©ç®—æ³•

    Args:
        relation: å…³ç³»ï¼ˆå…ƒç»„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç»„æœ‰æ¦‚ç‡ï¼‰
        condition: é€‰æ‹©æ¡ä»¶

    Returns:
        æ»¡è¶³æ¡ä»¶çš„å…ƒç»„åŠå…¶æ¦‚ç‡
    """
    results = []
    for tuple in relation:
        if condition(tuple):
            results.append({
                'tuple': tuple,
                'probability': tuple.probability
            })
    return results
```

**SQLç¤ºä¾‹**ï¼š

```sql
-- æ¦‚ç‡é€‰æ‹©ï¼šé€‰æ‹©æ¦‚ç‡>0.8çš„å…ƒç»„ï¼ˆå¸¦æ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æŸ¥è¯¢æ¦‚ç‡>0.8çš„å…ƒç»„';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT *
FROM sensor_data
WHERE probability > 0.8;
```

**2. æ¦‚ç‡è¿æ¥ï¼ˆProbabilistic Joinï¼‰**

**å®šä¹‰**ï¼šè¿æ¥æ“ä½œçš„æ¦‚ç‡è®¡ç®—ï¼Œå¤„ç†ä¸ç¡®å®šæ€§è¿æ¥ã€‚

**æ•°å­¦åŸç†**ï¼š

```text
å¯¹äºä¸¤ä¸ªå…³ç³» R å’Œ Sï¼Œè¿æ¥æ¡ä»¶ Î¸ï¼š
P(t âˆˆ R â‹ˆ S | Î¸) = Î£ P(r âˆˆ R) Ã— P(s âˆˆ S) Ã— I(Î¸(r, s))

å…¶ä¸­ï¼š
- r å’Œ s æ˜¯æ¥è‡ª R å’Œ S çš„å…ƒç»„
- Î¸(r, s) æ˜¯è¿æ¥æ¡ä»¶
- I(Î¸(r, s)) æ˜¯æŒ‡ç¤ºå‡½æ•°
```

**ç®—æ³•**ï¼š

```python
def probabilistic_join(relation_R, relation_S, join_condition):
    """
    æ¦‚ç‡è¿æ¥ç®—æ³•

    Args:
        relation_R: å…³ç³»R
        relation_S: å…³ç³»S
        join_condition: è¿æ¥æ¡ä»¶å‡½æ•°

    Returns:
        è¿æ¥ç»“æœåŠå…¶æ¦‚ç‡
    """
    results = []
    for r in relation_R:
        for s in relation_S:
            if join_condition(r, s):
                # ç‹¬ç«‹äº‹ä»¶ï¼šP(r AND s) = P(r) Ã— P(s)
                prob = r.probability * s.probability
                results.append({
                    'tuple': combine(r, s),
                    'probability': prob
                })
    return results
```

**SQLç¤ºä¾‹**ï¼š

```sql
-- æ¦‚ç‡è¿æ¥ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') OR
           NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_metadata') THEN
            RAISE WARNING 'è¡¨ sensor_readings æˆ– sensor_metadata ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œæ¦‚ç‡è¿æ¥æŸ¥è¯¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡Œæ¦‚ç‡è¿æ¥æŸ¥è¯¢';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    r.sensor_id,
    r.temperature,
    s.location,
    -- æ³¨æ„ï¼šPROBABILITY()æ˜¯ç¤ºä¾‹å‡½æ•°ï¼Œå®é™…å®ç°éœ€è¦æ ¹æ®æ‰©å±•è°ƒæ•´
    (r.probability * COALESCE(s.reliability, 1.0)) AS join_probability
FROM sensor_readings r
JOIN sensor_metadata s ON r.sensor_id = s.sensor_id;

**3. æ¦‚ç‡èšåˆï¼ˆProbabilistic Aggregationï¼‰**

**å®šä¹‰**ï¼šèšåˆæ“ä½œçš„æ¦‚ç‡è®¡ç®—ï¼Œè®¡ç®—èšåˆç»“æœçš„æ¦‚ç‡åˆ†å¸ƒã€‚

**æ•°å­¦åŸç†**ï¼š

```text
å¯¹äºèšåˆå‡½æ•° fï¼ˆå¦‚SUMã€AVGã€COUNTï¼‰ï¼š
P(f(R) = v) = Î£ P(w) Ã— I(f(w) = v)

å…¶ä¸­ï¼š
- w æ˜¯å¯èƒ½ä¸–ç•Œ
- P(w) æ˜¯å¯èƒ½ä¸–ç•Œçš„æ¦‚ç‡
- I(f(w) = v) æ˜¯æŒ‡ç¤ºå‡½æ•°
```

**ç®—æ³•**ï¼š

```python
def probabilistic_aggregate(relation, agg_func, group_by=None):
    """
    æ¦‚ç‡èšåˆç®—æ³•

    Args:
        relation: å…³ç³»
        agg_func: èšåˆå‡½æ•°ï¼ˆSUMã€AVGã€COUNTç­‰ï¼‰
        group_by: åˆ†ç»„å­—æ®µ

    Returns:
        èšåˆç»“æœåŠå…¶æ¦‚ç‡åˆ†å¸ƒ
    """
    if group_by:
        # åˆ†ç»„èšåˆ
        groups = {}
        for tuple in relation:
            key = tuple[group_by]
            if key not in groups:
                groups[key] = []
            groups[key].append(tuple)

        results = []
        for key, tuples in groups.items():
            result = compute_aggregate_probability(tuples, agg_func)
            results.append({
                'group': key,
                'value': result['value'],
                'probability': result['probability']
            })
        return results
    else:
        # å…¨å±€èšåˆ
        return compute_aggregate_probability(relation, agg_func)

def compute_aggregate_probability(tuples, agg_func):
    """
    è®¡ç®—èšåˆç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ
    """
    # æšä¸¾æ‰€æœ‰å¯èƒ½ä¸–ç•Œ
    possible_worlds = enumerate_possible_worlds(tuples)

    # è®¡ç®—æ¯ä¸ªå¯èƒ½ä¸–ç•Œçš„èšåˆå€¼
    agg_values = {}
    for world, prob in possible_worlds:
        value = agg_func(world)
        if value not in agg_values:
            agg_values[value] = 0
        agg_values[value] += prob

    return agg_values
```

**SQLç¤ºä¾‹**ï¼š

```sql
-- æ¦‚ç‡èšåˆï¼šè®¡ç®—åŠ æƒå¹³å‡ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œæ¦‚ç‡èšåˆæŸ¥è¯¢';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æ‰§è¡Œæ¦‚ç‡èšåˆæŸ¥è¯¢';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    sensor_id,
    SUM(value * probability) / NULLIF(SUM(probability), 0) AS weighted_avg,
    AVG(probability) AS avg_confidence,
    -- æ³¨æ„ï¼šPROBABILITY()æ˜¯ç¤ºä¾‹å‡½æ•°ï¼Œå®é™…å®ç°éœ€è¦æ ¹æ®æ‰©å±•è°ƒæ•´
    MIN(probability) AS aggregate_probability
FROM sensor_data
GROUP BY sensor_id;

#### **2.3.3 å¯èƒ½ä¸–ç•Œæšä¸¾**

**å¯èƒ½ä¸–ç•Œå®šä¹‰**ï¼š

å¯èƒ½ä¸–ç•Œæ˜¯æ•°æ®çš„æ‰€æœ‰å¯èƒ½çŠ¶æ€ï¼Œæ¯ä¸ªå¯èƒ½ä¸–ç•Œæ˜¯ä¸€ä¸ªç¡®å®šæ€§çš„æ•°æ®åº“å®ä¾‹ã€‚

**æšä¸¾ç®—æ³•**ï¼š

```python
def enumerate_possible_worlds(relation):
    """
    æšä¸¾æ‰€æœ‰å¯èƒ½ä¸–ç•Œ

    Args:
        relation: å…³ç³»ï¼ˆæ¯ä¸ªå…ƒç»„æœ‰æ¦‚ç‡ï¼‰

    Returns:
        å¯èƒ½ä¸–ç•Œåˆ—è¡¨ï¼Œæ¯ä¸ªä¸–ç•ŒåŒ…å«å…ƒç»„å’Œæ¦‚ç‡
    """
    worlds = []
    n = len(relation)

    # æšä¸¾æ‰€æœ‰2^nä¸ªå¯èƒ½ä¸–ç•Œ
    for i in range(2 ** n):
        world = []
        prob = 1.0

        for j, tuple in enumerate(relation):
            # æ£€æŸ¥å…ƒç»„æ˜¯å¦åœ¨å½“å‰ä¸–ç•Œä¸­
            if (i >> j) & 1:  # å…ƒç»„å­˜åœ¨
                world.append(tuple)
                prob *= tuple.probability
            else:  # å…ƒç»„ä¸å­˜åœ¨
                prob *= (1 - tuple.probability)

        worlds.append({
            'tuples': world,
            'probability': prob
        })

    return worlds
```

**å¤æ‚åº¦åˆ†æ**ï¼š

- **æ—¶é—´å¤æ‚åº¦**ï¼šO(2^n)ï¼Œnä¸ºä¸ç¡®å®šæ€§å…ƒç»„æ•°
- **ç©ºé—´å¤æ‚åº¦**ï¼šO(2^n)
- **ä¼˜åŒ–ç­–ç•¥**ï¼š
  - å‰ªæä½æ¦‚ç‡å¯èƒ½ä¸–ç•Œ
  - ä½¿ç”¨è¿‘ä¼¼ç®—æ³•
  - é™åˆ¶å¯èƒ½ä¸–ç•Œæ•°é‡

#### **2.3.4 æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–**

æ¦‚ç‡æŸ¥è¯¢çš„è®¡ç®—å¤æ‚åº¦é€šå¸¸å¾ˆé«˜ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠå¯èƒ½ä¸–ç•Œæšä¸¾çš„æŸ¥è¯¢ã€‚æœ¬èŠ‚ä»‹ç»å¤šç§ä¼˜åŒ–ç­–ç•¥æ¥æé«˜æŸ¥è¯¢æ€§èƒ½ã€‚

**ä¼˜åŒ–ç­–ç•¥**ï¼š

**1. æ—©æœŸè¿‡æ»¤ï¼ˆEarly Filteringï¼‰**

**åŸç†**ï¼šåœ¨æšä¸¾å¯èƒ½ä¸–ç•Œä¹‹å‰ï¼Œå…ˆè¿‡æ»¤æ‰ä½æ¦‚ç‡çš„å…ƒç»„ï¼Œå‡å°‘éœ€è¦å¤„ç†çš„æ•°æ®é‡ã€‚

**å®ç°æ–¹æ³•**ï¼š

- **æ¦‚ç‡é˜ˆå€¼è¿‡æ»¤**ï¼šåœ¨WHEREå­å¥ä¸­ä½¿ç”¨æ¦‚ç‡é˜ˆå€¼ï¼Œåªå¤„ç†é«˜æ¦‚ç‡å…ƒç»„
- **æå‰ç»ˆæ­¢**ï¼šå½“ç´¯ç§¯æ¦‚ç‡è¾¾åˆ°é˜ˆå€¼æ—¶ï¼Œæå‰ç»ˆæ­¢æŸ¥è¯¢
- **åˆ†å±‚è¿‡æ»¤**ï¼šå…ˆè¿›è¡Œç²—ç²’åº¦è¿‡æ»¤ï¼Œå†è¿›è¡Œç»†ç²’åº¦è¿‡æ»¤

**ä¼˜åŒ–ç¤ºä¾‹**ï¼š

```sql
-- ä¼˜åŒ–å‰ï¼šæšä¸¾æ‰€æœ‰å¯èƒ½ä¸–ç•Œï¼ˆå¤æ‚åº¦O(2^n)ï¼‰
SELECT * FROM sensor_data WHERE probability > 0.5;

-- ä¼˜åŒ–åï¼šä½¿ç”¨æ¦‚ç‡é˜ˆå€¼æå‰è¿‡æ»¤
CREATE INDEX idx_probability ON sensor_data(probability);
SELECT * FROM sensor_data
WHERE probability > 0.8  -- æé«˜é˜ˆå€¼ï¼Œå‡å°‘å¤„ç†çš„æ•°æ®é‡
ORDER BY probability DESC
LIMIT 1000;  -- é™åˆ¶ç»“æœæ•°é‡

-- åˆ†å±‚è¿‡æ»¤ç¤ºä¾‹
WITH high_prob_data AS (
    SELECT * FROM sensor_data WHERE probability > 0.9
),
medium_prob_data AS (
    SELECT * FROM sensor_data WHERE probability BETWEEN 0.7 AND 0.9
)
SELECT * FROM high_prob_data
UNION ALL
SELECT * FROM medium_prob_data
ORDER BY probability DESC;
```

**æ€§èƒ½å½±å“**ï¼š

- å‡å°‘å¯èƒ½ä¸–ç•Œæ•°é‡ï¼šä»O(2^n)é™ä½åˆ°O(2^k)ï¼Œå…¶ä¸­k << n
- æŸ¥è¯¢æ—¶é—´ï¼šä»æŒ‡æ•°çº§é™ä½åˆ°å¤šé¡¹å¼çº§
- å†…å­˜ä½¿ç”¨ï¼šæ˜¾è‘—å‡å°‘å†…å­˜å ç”¨

**2. ç´¢å¼•ä¼˜åŒ–ï¼ˆIndex Optimizationï¼‰**

**åŸç†**ï¼šä¸ºæ¦‚ç‡å€¼åˆ›å»ºåˆé€‚çš„ç´¢å¼•ï¼ŒåŠ é€Ÿæ¦‚ç‡æŸ¥è¯¢çš„æ‰§è¡Œã€‚

**ç´¢å¼•ç±»å‹**ï¼š

- **B-treeç´¢å¼•**ï¼šç”¨äºæ¦‚ç‡å€¼çš„èŒƒå›´æŸ¥è¯¢å’Œæ’åº
- **éƒ¨åˆ†ç´¢å¼•**ï¼šåªç´¢å¼•é«˜æ¦‚ç‡æ•°æ®ï¼Œå‡å°‘ç´¢å¼•å¤§å°
- **è¡¨è¾¾å¼ç´¢å¼•**ï¼šä¸ºæ¦‚ç‡è®¡ç®—è¡¨è¾¾å¼åˆ›å»ºç´¢å¼•
- **å¤åˆç´¢å¼•**ï¼šä¸ºæ¦‚ç‡å€¼å’Œå…¶ä»–å­—æ®µåˆ›å»ºå¤åˆç´¢å¼•

**ä¼˜åŒ–ç¤ºä¾‹**ï¼š

```sql
-- åŸºç¡€æ¦‚ç‡å€¼ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºç´¢å¼•';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_probability') THEN
            CREATE INDEX idx_probability ON sensor_data(probability);
            RAISE NOTICE 'åŸºç¡€æ¦‚ç‡å€¼ç´¢å¼• idx_probability åˆ›å»ºæˆåŠŸ';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_high_probability') THEN
            CREATE INDEX idx_high_probability ON sensor_data(probability)
            WHERE probability > 0.7;
            RAISE NOTICE 'éƒ¨åˆ†ç´¢å¼• idx_high_probability åˆ›å»ºæˆåŠŸ';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_prob_expr') THEN
            CREATE INDEX idx_prob_expr ON sensor_data((probability * 100));
            RAISE NOTICE 'è¡¨è¾¾å¼ç´¢å¼• idx_prob_expr åˆ›å»ºæˆåŠŸ';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_sensor_prob') THEN
            CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);
            RAISE NOTICE 'å¤åˆç´¢å¼• idx_sensor_prob åˆ›å»ºæˆåŠŸ';
        END IF;
    EXCEPTION
        WHEN undefined_table THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨';
        WHEN duplicate_table THEN
            RAISE WARNING 'ç´¢å¼•å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç´¢å¼•å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- ä½¿ç”¨ç´¢å¼•çš„æŸ¥è¯¢
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM sensor_data
WHERE probability > 0.8
ORDER BY probability DESC
LIMIT 100;
```

**æ€§èƒ½å½±å“**ï¼š

- æŸ¥è¯¢æ—¶é—´ï¼šä»å…¨è¡¨æ‰«æO(n)é™ä½åˆ°ç´¢å¼•æ‰«æO(log n)
- æ’åºæ—¶é—´ï¼šä»O(n log n)é™ä½åˆ°O(k log k)ï¼Œå…¶ä¸­kæ˜¯ç»“æœé›†å¤§å°
- ç´¢å¼•ç»´æŠ¤ï¼šéœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´å’Œç»´æŠ¤å¼€é”€

**3. è¿‘ä¼¼ç®—æ³•ï¼ˆApproximation Algorithmsï¼‰**

**åŸç†**ï¼šä½¿ç”¨é‡‡æ ·å’Œè¿‘ä¼¼æ–¹æ³•ï¼Œåœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹é™ä½è®¡ç®—å¤æ‚åº¦ã€‚

**ç®—æ³•ç±»å‹**ï¼š

- **å¯èƒ½ä¸–ç•Œé‡‡æ ·**ï¼šéšæœºé‡‡æ ·å¯èƒ½ä¸–ç•Œï¼Œä¼°è®¡æŸ¥è¯¢ç»“æœçš„æ¦‚ç‡
- **è’™ç‰¹å¡æ´›æ–¹æ³•**ï¼šä½¿ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä¼°è®¡æ¦‚ç‡
- **é‡è¦æ€§é‡‡æ ·**ï¼šæ ¹æ®é‡è¦æ€§é‡‡æ ·å¯èƒ½ä¸–ç•Œ
- **åˆ†å±‚é‡‡æ ·**ï¼šåˆ†å±‚é‡‡æ ·å¯èƒ½ä¸–ç•Œï¼Œæé«˜ä¼°è®¡ç²¾åº¦

**ä¼˜åŒ–ç¤ºä¾‹**ï¼š

```sql
-- å¯èƒ½ä¸–ç•Œé‡‡æ ·å‡½æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        CREATE OR REPLACE FUNCTION sample_possible_worlds(
            table_name TEXT,
            sample_size INT DEFAULT 1000
        ) RETURNS TABLE (
            world_id INT,
            probability NUMERIC,
            tuple_count INT
        ) AS $$
        DECLARE
            total_worlds BIGINT;
            sample_prob NUMERIC;
        BEGIN
            -- å‚æ•°éªŒè¯
            IF table_name IS NULL OR table_name = '' THEN
                RAISE EXCEPTION 'table_nameä¸èƒ½ä¸ºNULLæˆ–ç©ºå­—ç¬¦ä¸²';
            END IF;

            IF sample_size IS NULL OR sample_size <= 0 THEN
                RAISE EXCEPTION 'sample_sizeå¿…é¡»å¤§äº0';
            END IF;

            -- æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = sample_possible_worlds.table_name) THEN
                RAISE EXCEPTION 'è¡¨ % ä¸å­˜åœ¨', table_name;
            END IF;

            BEGIN
                -- è®¡ç®—æ€»å¯èƒ½ä¸–ç•Œæ•°
                EXECUTE format('SELECT COUNT(*) FROM %I', table_name) INTO total_worlds;

                -- é‡‡æ ·å¯èƒ½ä¸–ç•Œ
                sample_prob := 1.0 / sample_size;

                RETURN QUERY EXECUTE format('
        WITH sampled_tuples AS (
            SELECT * FROM %I
            WHERE random() < %s
            LIMIT %s
        )
        SELECT
            row_number() OVER () AS world_id,
            %s AS probability,
            COUNT(*) AS tuple_count
        FROM sampled_tuples
        GROUP BY world_id
    ', table_name, sample_prob, sample_size, sample_prob);
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨é‡‡æ ·ä¼°è®¡æŸ¥è¯¢ç»“æœæ¦‚ç‡
SELECT
    AVG(probability) AS estimated_probability,
    STDDEV(probability) AS estimation_error
FROM sample_possible_worlds('sensor_data', 1000);
```

**æ€§èƒ½å½±å“**ï¼š

- è®¡ç®—å¤æ‚åº¦ï¼šä»æŒ‡æ•°çº§O(2^n)é™ä½åˆ°çº¿æ€§çº§O(k)ï¼Œå…¶ä¸­kæ˜¯é‡‡æ ·å¤§å°
- ä¼°è®¡ç²¾åº¦ï¼šå–å†³äºé‡‡æ ·å¤§å°ï¼Œé€šå¸¸k=1000æ—¶è¯¯å·®<5%
- æŸ¥è¯¢æ—¶é—´ï¼šæ˜¾è‘—å‡å°‘ï¼Œé€‚åˆå®æ—¶æŸ¥è¯¢

**4. ç¼“å­˜æœºåˆ¶ï¼ˆCaching Mechanismsï¼‰**

**åŸç†**ï¼šç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœå’Œå¯èƒ½ä¸–ç•Œæšä¸¾ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚

**ç¼“å­˜ç­–ç•¥**ï¼š

- **æŸ¥è¯¢ç»“æœç¼“å­˜**ï¼šç¼“å­˜å¸¸è§æŸ¥è¯¢çš„ç»“æœ
- **å¯èƒ½ä¸–ç•Œç¼“å­˜**ï¼šç¼“å­˜å¯èƒ½ä¸–ç•Œçš„æšä¸¾ç»“æœ
- **æ¦‚ç‡è®¡ç®—ç¼“å­˜**ï¼šç¼“å­˜æ¦‚ç‡è®¡ç®—ç»“æœ
- **ç‰©åŒ–è§†å›¾**ï¼šé¢„è®¡ç®—å¸¸è§æŸ¥è¯¢ç»“æœ

**ä¼˜åŒ–ç¤ºä¾‹**ï¼š

```sql
-- åˆ›å»ºæŸ¥è¯¢ç»“æœç¼“å­˜è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'query_result_cache') THEN
            CREATE TABLE query_result_cache (
                query_hash TEXT PRIMARY KEY,
                query_text TEXT NOT NULL,
                query_result JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT NOW(),
                expires_at TIMESTAMP,
                hit_count INT DEFAULT 0
            );
            RAISE NOTICE 'æŸ¥è¯¢ç»“æœç¼“å­˜è¡¨åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'æŸ¥è¯¢ç»“æœç¼“å­˜è¡¨å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæŸ¥è¯¢ç»“æœç¼“å­˜è¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æŸ¥è¯¢ç¼“å­˜å‡½æ•°
CREATE OR REPLACE FUNCTION get_cached_query_result(
    query_text TEXT,
    cache_duration INTERVAL DEFAULT INTERVAL '1 hour'
) RETURNS JSONB AS $$
DECLARE
    query_hash TEXT;
    cached_result JSONB;
BEGIN
    -- è®¡ç®—æŸ¥è¯¢å“ˆå¸Œ
    query_hash := md5(query_text);

    -- æ£€æŸ¥ç¼“å­˜
    SELECT query_result INTO cached_result
    FROM query_result_cache
    WHERE query_hash = get_cached_query_result.query_hash
      AND expires_at > NOW();

    IF cached_result IS NOT NULL THEN
        -- æ›´æ–°å‘½ä¸­è®¡æ•°
        UPDATE query_result_cache
        SET hit_count = hit_count + 1
        WHERE query_hash = get_cached_query_result.query_hash;

        RETURN cached_result;
    END IF;

    -- æ‰§è¡ŒæŸ¥è¯¢å¹¶ç¼“å­˜ç»“æœ
    EXECUTE format('SELECT to_jsonb(result) FROM (%s) result', query_text) INTO cached_result;

    INSERT INTO query_result_cache (query_hash, query_text, query_result, expires_at)
    VALUES (
        query_hash,
        query_text,
        cached_result,
        NOW() + cache_duration
    )
    ON CONFLICT (query_hash) DO UPDATE SET
        query_result = EXCLUDED.query_result,
        expires_at = EXCLUDED.expires_at,
        hit_count = 0;

    RETURN cached_result;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¼“å­˜æŸ¥è¯¢
SELECT * FROM get_cached_query_result(
    'SELECT * FROM sensor_data WHERE probability > 0.8',
    INTERVAL '1 hour'
);
```

**æ€§èƒ½å½±å“**ï¼š

- æŸ¥è¯¢æ—¶é—´ï¼šä»ç§’çº§é™ä½åˆ°æ¯«ç§’çº§ï¼ˆç¼“å­˜å‘½ä¸­æ—¶ï¼‰
- ç³»ç»Ÿè´Ÿè½½ï¼šæ˜¾è‘—å‡å°‘æ•°æ®åº“è´Ÿè½½
- å­˜å‚¨å¼€é”€ï¼šéœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´

**5. æŸ¥è¯¢é‡å†™ï¼ˆQuery Rewritingï¼‰**

**åŸç†**ï¼šå°†å¤æ‚çš„æ¦‚ç‡æŸ¥è¯¢é‡å†™ä¸ºæ›´ç®€å•çš„ç­‰ä»·æŸ¥è¯¢ï¼Œæé«˜æ‰§è¡Œæ•ˆç‡ã€‚

**é‡å†™è§„åˆ™**ï¼š

- **æ¦‚ç‡è¿‡æ»¤ä¸‹æ¨**ï¼šå°†æ¦‚ç‡è¿‡æ»¤å°½å¯èƒ½ä¸‹æ¨åˆ°æŸ¥è¯¢æ ‘åº•éƒ¨
- **JOINä¼˜åŒ–**ï¼šä¼˜åŒ–æ¦‚ç‡JOINçš„æ‰§è¡Œé¡ºåº
- **èšåˆä¼˜åŒ–**ï¼šä¼˜åŒ–æ¦‚ç‡èšåˆæŸ¥è¯¢
- **å­æŸ¥è¯¢ä¼˜åŒ–**ï¼šä¼˜åŒ–åµŒå¥—çš„æ¦‚ç‡æŸ¥è¯¢

**ä¼˜åŒ–ç¤ºä¾‹**ï¼š

```sql
-- ä¼˜åŒ–å‰ï¼šå¤æ‚çš„åµŒå¥—æŸ¥è¯¢
SELECT * FROM (
    SELECT * FROM sensor_data WHERE probability > 0.5
) t1
WHERE probability > 0.7;

-- ä¼˜åŒ–åï¼šåˆå¹¶è¿‡æ»¤æ¡ä»¶
SELECT * FROM sensor_data
WHERE probability > 0.7;  -- ç›´æ¥ä½¿ç”¨æ›´é«˜çš„é˜ˆå€¼

-- ä¼˜åŒ–å‰ï¼šå…ˆJOINå†è¿‡æ»¤
SELECT a.*, b.*
FROM uncertain_table_a a
JOIN uncertain_table_b b ON a.id = b.id
WHERE a.probability * b.probability > 0.5;

-- ä¼˜åŒ–åï¼šå…ˆè¿‡æ»¤å†JOIN
SELECT a.*, b.*
FROM (
    SELECT * FROM uncertain_table_a WHERE probability > 0.7
) a
JOIN (
    SELECT * FROM uncertain_table_b WHERE probability > 0.7
) b ON a.id = b.id
WHERE a.probability * b.probability > 0.5;
```

**ç»¼åˆä¼˜åŒ–ç¤ºä¾‹**ï¼š

```sql
-- ç»¼åˆä¼˜åŒ–ï¼šç»“åˆå¤šç§ä¼˜åŒ–ç­–ç•¥ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
-- 1. åˆ›å»ºéƒ¨åˆ†ç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºéƒ¨åˆ†ç´¢å¼•';
            RETURN;
        END IF;
        
        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_high_prob') THEN
            CREATE INDEX idx_high_prob ON sensor_data(probability)
            WHERE probability > 0.7;
            RAISE NOTICE 'éƒ¨åˆ†ç´¢å¼•åˆ›å»ºæˆåŠŸ';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºéƒ¨åˆ†ç´¢å¼•å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- 2. åˆ›å»ºç‰©åŒ–è§†å›¾ï¼ˆé¢„è®¡ç®—å¸¸è§æŸ¥è¯¢ï¼Œå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºç‰©åŒ–è§†å›¾';
            RETURN;
        END IF;
        
        IF NOT EXISTS (SELECT 1 FROM pg_matviews WHERE matviewname = 'sensor_data_high_prob') THEN
            CREATE MATERIALIZED VIEW sensor_data_high_prob AS
            SELECT
                sensor_id,
                COUNT(*) AS count,
                AVG(value) AS avg_value,
                SUM(value * probability) / NULLIF(SUM(probability), 0) AS weighted_avg
            FROM sensor_data
            WHERE probability > 0.7
            GROUP BY sensor_id;
            
            CREATE INDEX idx_summary_sensor ON sensor_data_high_prob(sensor_id);
            RAISE NOTICE 'ç‰©åŒ–è§†å›¾åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'ç‰©åŒ–è§†å›¾å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç‰©åŒ–è§†å›¾å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- 3. ä½¿ç”¨ç‰©åŒ–è§†å›¾æŸ¥è¯¢ï¼ˆæ›´å¿«ï¼‰
SELECT * FROM sensor_data_high_prob
WHERE sensor_id = 1;

-- 4. å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY sensor_data_high_prob;
```

**ä¼˜åŒ–æ•ˆæœæ€»ç»“**ï¼š

| ä¼˜åŒ–ç­–ç•¥ | å¤æ‚åº¦é™ä½ | é€‚ç”¨åœºæ™¯ | å®ç°éš¾åº¦ |
|---------|-----------|---------|---------|
| **æ—©æœŸè¿‡æ»¤** | O(2^n) â†’ O(2^k) | é«˜æ¦‚ç‡æŸ¥è¯¢ | ä½ |
| **ç´¢å¼•ä¼˜åŒ–** | O(n) â†’ O(log n) | èŒƒå›´æŸ¥è¯¢ | ä½ |
| **è¿‘ä¼¼ç®—æ³•** | O(2^n) â†’ O(k) | å®æ—¶æŸ¥è¯¢ | ä¸­ |
| **ç¼“å­˜æœºåˆ¶** | O(1)ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰ | é‡å¤æŸ¥è¯¢ | ä¸­ |
| **æŸ¥è¯¢é‡å†™** | 10-100å€ | å¤æ‚æŸ¥è¯¢ | é«˜ |

**æœ€ä½³å®è·µ**ï¼š

1. **ä¼˜å…ˆä½¿ç”¨æ—©æœŸè¿‡æ»¤**ï¼šæœ€ç®€å•æœ‰æ•ˆï¼Œé€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯
2. **åˆ›å»ºåˆé€‚çš„ç´¢å¼•**ï¼šä¸ºå¸¸ç”¨æŸ¥è¯¢åˆ›å»ºç´¢å¼•
3. **ä½¿ç”¨ç‰©åŒ–è§†å›¾**ï¼šé¢„è®¡ç®—å¸¸è§æŸ¥è¯¢ç»“æœ
4. **è€ƒè™‘è¿‘ä¼¼ç®—æ³•**ï¼šå®æ—¶æŸ¥è¯¢åœºæ™¯ä½¿ç”¨é‡‡æ ·æ–¹æ³•
5. **å®æ–½ç¼“å­˜æœºåˆ¶**ï¼šé‡å¤æŸ¥è¯¢ä½¿ç”¨ç¼“å­˜
6. **ç›‘æ§æŸ¥è¯¢æ€§èƒ½**ï¼šå®šæœŸåˆ†ææ…¢æŸ¥è¯¢ï¼Œä¼˜åŒ–æ‰§è¡Œè®¡åˆ’

---

## 3. PostgreSQLå®ç°æ–¹æ¡ˆ

### 3.1 æ‰©å±•æ¶æ„è®¾è®¡

#### **3.1.1 æ•´ä½“æ¶æ„**

**æ‰©å±•æ¶æ„å±‚æ¬¡ç»“æ„**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ¦‚ç‡æ•°æ®åº“æ‰©å±•æ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚     åº”ç”¨å±‚ (Application Layer)           â”‚           â”‚
â”‚  â”‚  - SQLæŸ¥è¯¢                              â”‚           â”‚
â”‚  â”‚  - Pythonå®¢æˆ·ç«¯                         â”‚           â”‚
â”‚  â”‚  - å…¶ä»–åº”ç”¨æ¥å£                          â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                 â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   PostgreSQLæ ¸å¿ƒå±‚                      â”‚           â”‚
â”‚  â”‚  - æŸ¥è¯¢è§£æå™¨                           â”‚           â”‚
â”‚  â”‚  - æŸ¥è¯¢ä¼˜åŒ–å™¨                           â”‚           â”‚
â”‚  â”‚  - æ‰§è¡Œå¼•æ“                             â”‚           â”‚
â”‚  â”‚  - å­˜å‚¨å¼•æ“                             â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                 â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   æ¦‚ç‡æ•°æ®åº“æ‰©å±•å±‚                       â”‚           â”‚
â”‚  â”‚  â”œâ”€â”€ æ•°æ®ç±»å‹æ‰©å±•                       â”‚           â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ probability_value              â”‚           â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ probability_distribution        â”‚           â”‚
â”‚  â”‚  â”‚   â””â”€â”€ uncertain_tuple                â”‚           â”‚
â”‚  â”‚  â”œâ”€â”€ æ“ä½œç¬¦æ‰©å±•                         â”‚           â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ æ¦‚ç‡æ¯”è¾ƒæ“ä½œç¬¦                  â”‚           â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ æ¦‚ç‡ç®—æœ¯æ“ä½œç¬¦                  â”‚           â”‚
â”‚  â”‚  â”‚   â””â”€â”€ æ¦‚ç‡é€»è¾‘æ“ä½œç¬¦                  â”‚           â”‚
â”‚  â”‚  â””â”€â”€ å‡½æ•°æ‰©å±•                           â”‚           â”‚
â”‚  â”‚      â”œâ”€â”€ æ¦‚ç‡å€¼æå–å‡½æ•°                  â”‚           â”‚
â”‚  â”‚      â”œâ”€â”€ æ¦‚ç‡èšåˆå‡½æ•°                    â”‚           â”‚
â”‚  â”‚      â””â”€â”€ æ¦‚ç‡ç»Ÿè®¡å‡½æ•°                    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                 â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   ProvSQLé›†æˆå±‚                         â”‚           â”‚
â”‚  â”‚  â”œâ”€â”€ æ•°æ®æº¯æºè¿½è¸ª                        â”‚           â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ æº¯æºå›¾æ„å»º                      â”‚           â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ æº¯æºæŸ¥è¯¢                        â”‚           â”‚
â”‚  â”‚  â”‚   â””â”€â”€ æº¯æºå­˜å‚¨                        â”‚           â”‚
â”‚  â”‚  â””â”€â”€ æ¦‚ç‡è®¡ç®—å¼•æ“                        â”‚           â”‚
â”‚  â”‚      â”œâ”€â”€ å¯èƒ½ä¸–ç•Œæšä¸¾                    â”‚           â”‚
â”‚  â”‚      â”œâ”€â”€ æ¦‚ç‡è®¡ç®—                        â”‚           â”‚
â”‚  â”‚      â””â”€â”€ ç»“æœæ¦‚ç‡åˆ†å¸ƒ                    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **3.1.2 å„å±‚èŒè´£**

**1. PostgreSQLæ ¸å¿ƒå±‚**

- **æŸ¥è¯¢è§£æå™¨**ï¼šè§£æSQLæŸ¥è¯¢ï¼Œè¯†åˆ«æ¦‚ç‡æ“ä½œ
- **æŸ¥è¯¢ä¼˜åŒ–å™¨**ï¼šä¼˜åŒ–æ¦‚ç‡æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’
- **æ‰§è¡Œå¼•æ“**ï¼šæ‰§è¡Œæ¦‚ç‡æŸ¥è¯¢æ“ä½œ
- **å­˜å‚¨å¼•æ“**ï¼šå­˜å‚¨æ¦‚ç‡æ•°æ®å’Œæº¯æºä¿¡æ¯

**2. æ¦‚ç‡æ•°æ®åº“æ‰©å±•å±‚**

**æ•°æ®ç±»å‹æ‰©å±•**ï¼š

- å®šä¹‰æ¦‚ç‡å€¼ç±»å‹
- å®šä¹‰æ¦‚ç‡åˆ†å¸ƒç±»å‹
- å®šä¹‰ä¸ç¡®å®šæ€§å…ƒç»„ç±»å‹

**æ“ä½œç¬¦æ‰©å±•**ï¼š

- æ¦‚ç‡å€¼æ¯”è¾ƒæ“ä½œç¬¦ï¼ˆ>ã€<ã€=ã€>=ã€<=ï¼‰
- æ¦‚ç‡å€¼ç®—æœ¯æ“ä½œç¬¦ï¼ˆ+ã€-ã€*ã€/ï¼‰
- æ¦‚ç‡å€¼é€»è¾‘æ“ä½œç¬¦ï¼ˆANDã€ORã€NOTï¼‰

**å‡½æ•°æ‰©å±•**ï¼š

- æ¦‚ç‡å€¼æå–å‡½æ•°
- æ¦‚ç‡èšåˆå‡½æ•°ï¼ˆAVGã€SUMã€COUNTç­‰ï¼‰
- æ¦‚ç‡ç»Ÿè®¡å‡½æ•°ï¼ˆSTDDEVã€VARIANCEç­‰ï¼‰

**3. ProvSQLé›†æˆå±‚**

**æ•°æ®æº¯æºè¿½è¸ª**ï¼š

- æ„å»ºæº¯æºå›¾
- å­˜å‚¨æº¯æºä¿¡æ¯
- æŸ¥è¯¢æº¯æºè·¯å¾„

**æ¦‚ç‡è®¡ç®—å¼•æ“**ï¼š

- æšä¸¾å¯èƒ½ä¸–ç•Œ
- è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
- ä¼˜åŒ–æ¦‚ç‡è®¡ç®—

#### **3.1.3 æ•°æ®æµ**

**æŸ¥è¯¢å¤„ç†æµç¨‹**ï¼š

```text
1. SQLæŸ¥è¯¢è¾“å…¥
   â†“
2. æŸ¥è¯¢è§£æï¼ˆè¯†åˆ«æ¦‚ç‡æ“ä½œï¼‰
   â†“
3. æŸ¥è¯¢ä¼˜åŒ–ï¼ˆæ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–ï¼‰
   â†“
4. æ‰§è¡Œè®¡åˆ’ç”Ÿæˆ
   â†“
5. æ¦‚ç‡è®¡ç®—ï¼ˆå¯èƒ½ä¸–ç•Œæšä¸¾ï¼‰
   â†“
6. ç»“æœæ¦‚ç‡åˆ†å¸ƒè®¡ç®—
   â†“
7. ç»“æœè¿”å›ï¼ˆå«æ¦‚ç‡ä¿¡æ¯ï¼‰
```

**æ•°æ®å­˜å‚¨æµç¨‹**ï¼š

```text
1. åº”ç”¨æ’å…¥æ•°æ®ï¼ˆå«æ¦‚ç‡å€¼ï¼‰
   â†“
2. æ¦‚ç‡å€¼éªŒè¯ï¼ˆèŒƒå›´æ£€æŸ¥ï¼‰
   â†“
3. æ•°æ®å­˜å‚¨ï¼ˆPostgreSQLå­˜å‚¨å¼•æ“ï¼‰
   â†“
4. æº¯æºä¿¡æ¯è®°å½•ï¼ˆProvSQLï¼‰
   â†“
5. ç´¢å¼•æ›´æ–°ï¼ˆæ¦‚ç‡å€¼ç´¢å¼•ï¼‰
```

#### **3.1.4 æ¥å£è®¾è®¡**

**SQLæ¥å£**ï¼š

```sql
-- æ•°æ®ç±»å‹æ¥å£ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability_value') THEN
            CREATE TYPE probability_value AS (value NUMERIC, probability NUMERIC);
            RAISE NOTICE 'ç±»å‹ probability_value åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'ç±»å‹ probability_value å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç±»å‹å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ³¨æ„ï¼šæ“ä½œç¬¦å’Œå‡½æ•°æ¥å£éœ€è¦æ ¹æ®å®é™…æ‰©å±•å®ç°
-- CREATE OPERATOR > (LEFTARG = NUMERIC, RIGHTARG = NUMERIC, ...);
-- CREATE FUNCTION get_probability(prob_value probability_value) RETURNS NUMERIC;
```

**Pythonæ¥å£**ï¼š

```python
# å®¢æˆ·ç«¯æ¥å£
class ProbabilisticDBClient:
    def insert_probabilistic_data(...)
    def query_with_confidence(...)
    def aggregate_probabilistic(...)
```

**Cæ‰©å±•æ¥å£**ï¼š

```c
// Cæ‰©å±•å‡½æ•°æ¥å£
PG_FUNCTION_INFO_V1(probability_gt);
Datum probability_gt(PG_FUNCTION_ARGS);
```

#### **3.1.5 æ‰©å±•ç‚¹**

**å¯æ‰©å±•çš„ç»„ä»¶**ï¼š

1. **è‡ªå®šä¹‰æ¦‚ç‡ç±»å‹**ï¼š
   - æ”¯æŒæ–°çš„æ¦‚ç‡å€¼è¡¨ç¤ºæ–¹å¼
   - æ”¯æŒæ–°çš„æ¦‚ç‡åˆ†å¸ƒç±»å‹

2. **è‡ªå®šä¹‰æ“ä½œç¬¦**ï¼š
   - æ”¯æŒæ–°çš„æ¦‚ç‡æ“ä½œ
   - æ”¯æŒæ–°çš„æ¦‚ç‡æ¯”è¾ƒæ–¹å¼

3. **è‡ªå®šä¹‰å‡½æ•°**ï¼š
   - æ”¯æŒæ–°çš„æ¦‚ç‡è®¡ç®—å‡½æ•°
   - æ”¯æŒæ–°çš„æ¦‚ç‡èšåˆå‡½æ•°

4. **æŸ¥è¯¢ä¼˜åŒ–å™¨æ‰©å±•**ï¼š
   - è‡ªå®šä¹‰æŸ¥è¯¢é‡å†™è§„åˆ™
   - è‡ªå®šä¹‰æ‰§è¡Œè®¡åˆ’ä¼˜åŒ–

5. **ç´¢å¼•æ‰©å±•**ï¼š
   - æ”¯æŒæ¦‚ç‡å€¼ç´¢å¼•
   - æ”¯æŒæ¦‚ç‡èŒƒå›´ç´¢å¼•

### 3.2 æ•°æ®ç±»å‹æ‰©å±•

PostgreSQLæ‰©å±•æ”¯æŒè‡ªå®šä¹‰æ¦‚ç‡æ•°æ®ç±»å‹ï¼Œç”¨äºè¡¨ç¤ºå’Œå­˜å‚¨ä¸ç¡®å®šæ€§æ•°æ®ã€‚æœ¬èŠ‚è¯¦ç»†ä»‹ç»æ¦‚ç‡æ•°æ®ç±»å‹çš„å®šä¹‰ã€ä½¿ç”¨å’Œæœ€ä½³å®è·µã€‚

#### **3.2.1 æ¦‚ç‡å€¼ç±»å‹**

**æ¦‚ç‡å€¼ç±»å‹ï¼ˆProbability Value Typeï¼‰**æ˜¯æœ€åŸºç¡€çš„æ¦‚ç‡æ•°æ®ç±»å‹ï¼Œç”¨äºè¡¨ç¤ºå•ä¸ªå€¼åŠå…¶æ¦‚ç‡ã€‚

**ç±»å‹å®šä¹‰**ï¼š

```sql
-- æ¦‚ç‡å€¼ç±»å‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability') THEN
            RAISE NOTICE 'ç±»å‹ probability å·²å­˜åœ¨';
        ELSE
            CREATE TYPE probability AS (
                value NUMERIC,
                confidence NUMERIC  -- ç½®ä¿¡åº¦ [0, 1]
            );
            RAISE NOTICE 'ç±»å‹ probability å·²åˆ›å»º';
        END IF;
    EXCEPTION
        WHEN duplicate_object THEN
            RAISE WARNING 'ç±»å‹ probability å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç±»å‹ probability å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```sql
-- åˆ›å»ºä½¿ç”¨æ¦‚ç‡å€¼ç±»å‹çš„è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability') THEN
            RAISE EXCEPTION 'ç±»å‹ probability ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
        END IF;
        
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_measurements') THEN
            CREATE TABLE sensor_measurements (
                id SERIAL PRIMARY KEY,
                sensor_id INT NOT NULL,
                measurement probability NOT NULL,
                timestamp TIMESTAMP DEFAULT NOW()
            );
            RAISE NOTICE 'è¡¨ sensor_measurements åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'è¡¨ sensor_measurements å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ’å…¥æ¦‚ç‡å€¼æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_measurements') THEN
            RAISE EXCEPTION 'è¡¨ sensor_measurements ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
        END IF;
        
        INSERT INTO sensor_measurements (sensor_id, measurement)
VALUES
    (1, (25.5, 0.9)::probability),
    (1, (26.0, 0.8)::probability),
    (2, (30.0, 0.7)::probability);

-- æŸ¥è¯¢æ¦‚ç‡å€¼
SELECT
    sensor_id,
    (measurement).value AS value,
    (measurement).confidence AS confidence,
    timestamp
FROM sensor_measurements
WHERE (measurement).confidence > 0.8;

-- æ¦‚ç‡å€¼èšåˆ
SELECT
    sensor_id,
    COUNT(*) AS total_measurements,
    AVG((measurement).value) AS avg_value,
    SUM((measurement).value * (measurement).confidence) /
        SUM((measurement).confidence) AS weighted_avg,
    AVG((measurement).confidence) AS avg_confidence
FROM sensor_measurements
GROUP BY sensor_id;
```

**ç±»å‹ç‰¹ç‚¹**ï¼š

- **value**ï¼šå®é™…æµ‹é‡å€¼æˆ–æ•°æ®å€¼
- **confidence**ï¼šè¯¥å€¼çš„ç½®ä¿¡åº¦ï¼ŒèŒƒå›´[0, 1]
- **é€‚ç”¨åœºæ™¯**ï¼šä¼ æ„Ÿå™¨æ•°æ®ã€æµ‹é‡æ•°æ®ã€å•ä¸€å€¼çš„ä¸ç¡®å®šæ€§è¡¨ç¤º

#### **3.2.2 æ¦‚ç‡åˆ†å¸ƒç±»å‹**

**æ¦‚ç‡åˆ†å¸ƒç±»å‹ï¼ˆProbability Distribution Typeï¼‰**ç”¨äºè¡¨ç¤ºå¤šä¸ªå¯èƒ½å€¼åŠå…¶æ¦‚ç‡åˆ†å¸ƒã€‚

**ç±»å‹å®šä¹‰**ï¼š

```sql
-- æ¦‚ç‡åˆ†å¸ƒç±»å‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability_distribution') THEN
            RAISE NOTICE 'ç±»å‹ probability_distribution å·²å­˜åœ¨';
        ELSE
            CREATE TYPE probability_distribution AS (
                values NUMERIC[],
                probabilities NUMERIC[]
            );
            RAISE NOTICE 'ç±»å‹ probability_distribution å·²åˆ›å»º';
        END IF;
    EXCEPTION
        WHEN duplicate_object THEN
            RAISE WARNING 'ç±»å‹ probability_distribution å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç±»å‹ probability_distribution å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```sql
-- åˆ›å»ºä½¿ç”¨æ¦‚ç‡åˆ†å¸ƒç±»å‹çš„è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability_distribution') THEN
            RAISE EXCEPTION 'ç±»å‹ probability_distribution ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
        END IF;
        
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'weather_forecast') THEN
            CREATE TABLE weather_forecast (
                id SERIAL PRIMARY KEY,
                location VARCHAR(100) NOT NULL,
                temperature_dist probability_distribution NOT NULL,
                forecast_date DATE NOT NULL
            );
            RAISE NOTICE 'è¡¨ weather_forecast åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'è¡¨ weather_forecast å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ’å…¥æ¦‚ç‡åˆ†å¸ƒæ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'weather_forecast') THEN
            RAISE EXCEPTION 'è¡¨ weather_forecast ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
        END IF;
        
        INSERT INTO weather_forecast (location, temperature_dist, forecast_date)
VALUES
    ('Beijing', (ARRAY[20, 22, 24], ARRAY[0.2, 0.5, 0.3])::probability_distribution, '2025-01-15'),
    ('Shanghai', (ARRAY[18, 20, 22], ARRAY[0.3, 0.4, 0.3])::probability_distribution, '2025-01-15');

-- æŸ¥è¯¢æ¦‚ç‡åˆ†å¸ƒ
SELECT
    location,
    (temperature_dist).values AS possible_temperatures,
    (temperature_dist).probabilities AS probabilities,
    forecast_date
FROM weather_forecast
WHERE forecast_date = '2025-01-15';

-- è®¡ç®—æœŸæœ›å€¼
CREATE OR REPLACE FUNCTION expected_value(dist probability_distribution)
RETURNS NUMERIC AS $$
DECLARE
    result NUMERIC := 0;
    i INT;
BEGIN
    FOR i IN 1..array_length(dist.values, 1) LOOP
        result := result + dist.values[i] * dist.probabilities[i];
    END LOOP;
    RETURN result;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- ä½¿ç”¨æœŸæœ›å€¼å‡½æ•°
SELECT
    location,
    expected_value(temperature_dist) AS expected_temperature,
    forecast_date
FROM weather_forecast;
```

**ç±»å‹ç‰¹ç‚¹**ï¼š

- **values**ï¼šå¯èƒ½å€¼çš„æ•°ç»„
- **probabilities**ï¼šå¯¹åº”æ¦‚ç‡çš„æ•°ç»„ï¼Œå¿…é¡»ä¸valuesé•¿åº¦ç›¸åŒä¸”å’Œä¸º1
- **é€‚ç”¨åœºæ™¯**ï¼šå¤©æ°”é¢„æŠ¥ã€é£é™©è¯„ä¼°ã€å¤šå€¼ä¸ç¡®å®šæ€§è¡¨ç¤º

#### **3.2.3 ä¸ç¡®å®šæ€§å…ƒç»„ç±»å‹**

**ä¸ç¡®å®šæ€§å…ƒç»„ç±»å‹ï¼ˆUncertain Tuple Typeï¼‰**ç”¨äºè¡¨ç¤ºåŒ…å«å¤šä¸ªå­—æ®µçš„ä¸ç¡®å®šæ€§æ•°æ®ã€‚

**ç±»å‹å®šä¹‰**ï¼š

```sql
-- ä¸ç¡®å®šæ€§å…ƒç»„ç±»å‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'uncertain_tuple') THEN
            RAISE NOTICE 'ç±»å‹ uncertain_tuple å·²å­˜åœ¨';
        ELSE
            CREATE TYPE uncertain_tuple AS (
                tuple_data JSONB,
                probability NUMERIC
            );
            RAISE NOTICE 'ç±»å‹ uncertain_tuple å·²åˆ›å»º';
        END IF;
    EXCEPTION
        WHEN duplicate_object THEN
            RAISE WARNING 'ç±»å‹ uncertain_tuple å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç±»å‹ uncertain_tuple å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```sql
-- åˆ›å»ºä½¿ç”¨ä¸ç¡®å®šæ€§å…ƒç»„ç±»å‹çš„è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'uncertain_tuple') THEN
            RAISE EXCEPTION 'ç±»å‹ uncertain_tuple ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
        END IF;
        
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'product_reviews') THEN
            CREATE TABLE product_reviews (
                id SERIAL PRIMARY KEY,
                product_id INT NOT NULL,
                review uncertain_tuple NOT NULL,
                created_at TIMESTAMP DEFAULT NOW()
            );
            RAISE NOTICE 'è¡¨ product_reviews åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'è¡¨ product_reviews å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ’å…¥ä¸ç¡®å®šæ€§å…ƒç»„æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'product_reviews') THEN
            RAISE EXCEPTION 'è¡¨ product_reviews ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
        END IF;
        
        INSERT INTO product_reviews (product_id, review)
VALUES
    (1, ('{"rating": 5, "comment": "Excellent product", "sentiment": "positive"}'::JSONB, 0.9)::uncertain_tuple),
    (1, ('{"rating": 4, "comment": "Good product", "sentiment": "positive"}'::JSONB, 0.8)::uncertain_tuple),
    (2, ('{"rating": 3, "comment": "Average product", "sentiment": "neutral"}'::JSONB, 0.7)::uncertain_tuple);

-- æŸ¥è¯¢ä¸ç¡®å®šæ€§å…ƒç»„
SELECT
    product_id,
    (review).tuple_data->>'rating' AS rating,
    (review).tuple_data->>'comment' AS comment,
    (review).tuple_data->>'sentiment' AS sentiment,
    (review).probability AS probability,
    created_at
FROM product_reviews
WHERE (review).probability > 0.8;

-- æ¦‚ç‡èšåˆæŸ¥è¯¢
SELECT
    product_id,
    COUNT(*) AS total_reviews,
    AVG(((review).tuple_data->>'rating')::NUMERIC) AS avg_rating,
    SUM(((review).tuple_data->>'rating')::NUMERIC * (review).probability) /
        SUM((review).probability) AS weighted_avg_rating
FROM product_reviews
GROUP BY product_id;
```

**ç±»å‹ç‰¹ç‚¹**ï¼š

- **tuple_data**ï¼šJSONBæ ¼å¼çš„å…ƒç»„æ•°æ®ï¼Œå¯ä»¥åŒ…å«ä»»æ„å­—æ®µ
- **probability**ï¼šè¯¥å…ƒç»„çš„æ¦‚ç‡ï¼ŒèŒƒå›´[0, 1]
- **é€‚ç”¨åœºæ™¯**ï¼šå¤æ‚æ•°æ®ç»“æ„çš„ä¸ç¡®å®šæ€§è¡¨ç¤ºã€çµæ´»çš„æ•°æ®æ¨¡å‹

#### **3.2.4 ç±»å‹æ“ä½œç¬¦å’Œå‡½æ•°**

**ç±»å‹æ¯”è¾ƒæ“ä½œç¬¦**ï¼š

```sql
-- æ¦‚ç‡å€¼æ¯”è¾ƒæ“ä½œç¬¦ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability') THEN
            RAISE EXCEPTION 'ç±»å‹ probability ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
        END IF;
        
        CREATE OR REPLACE FUNCTION probability_eq(p1 probability, p2 probability)
        RETURNS BOOLEAN AS $$
        BEGIN
            IF p1 IS NULL OR p2 IS NULL THEN
                RETURN p1 IS NULL AND p2 IS NULL;
            END IF;
            RETURN p1.value = p2.value AND p1.confidence = p2.confidence;
        EXCEPTION
            WHEN OTHERS THEN
                RAISE EXCEPTION 'æ¦‚ç‡å€¼æ¯”è¾ƒå¤±è´¥: %', SQLERRM;
        END;
        $$ LANGUAGE plpgsql IMMUTABLE;
        RAISE NOTICE 'æ¦‚ç‡å€¼æ¯”è¾ƒå‡½æ•°åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæ¦‚ç‡å€¼æ¯”è¾ƒå‡½æ•°å¤±è´¥: %', SQLERRM;
    END;
END $$;

CREATE OPERATOR = (
    LEFTARG = probability,
    RIGHTARG = probability,
    PROCEDURE = probability_eq,
    COMMUTATOR = =
);

-- æ¦‚ç‡å€¼å¤§å°æ¯”è¾ƒæ“ä½œç¬¦
CREATE OR REPLACE FUNCTION probability_lt(p1 probability, p2 probability)
RETURNS BOOLEAN AS $$
BEGIN
    RETURN p1.value < p2.value OR
           (p1.value = p2.value AND p1.confidence < p2.confidence);
END;
$$ LANGUAGE plpgsql IMMUTABLE;

CREATE OPERATOR < (
    LEFTARG = probability,
    RIGHTARG = probability,
    PROCEDURE = probability_lt
);
```

**ç±»å‹è½¬æ¢å‡½æ•°**ï¼š

```sql
-- ä»NUMERICè½¬æ¢ä¸ºprobabilityï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability') THEN
            RAISE EXCEPTION 'ç±»å‹ probability ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
        END IF;
        
        CREATE OR REPLACE FUNCTION numeric_to_probability(val NUMERIC, conf NUMERIC DEFAULT 1.0)
        RETURNS probability AS $$
        BEGIN
            IF conf < 0 OR conf > 1 THEN
                RAISE EXCEPTION 'ç½®ä¿¡åº¦å¿…é¡»åœ¨[0, 1]èŒƒå›´å†…';
            END IF;
            RETURN (val, conf)::probability;
        EXCEPTION
            WHEN OTHERS THEN
                RAISE EXCEPTION 'ç±»å‹è½¬æ¢å¤±è´¥: %', SQLERRM;
        END;
        $$ LANGUAGE plpgsql IMMUTABLE;
        
        -- åˆ›å»ºç±»å‹è½¬æ¢
        IF NOT EXISTS (SELECT 1 FROM pg_cast WHERE castsource = 'numeric'::regtype AND casttarget = 'probability'::regtype) THEN
            CREATE CAST (NUMERIC AS probability) WITH FUNCTION numeric_to_probability(NUMERIC, NUMERIC);
        END IF;
        
        RAISE NOTICE 'ç±»å‹è½¬æ¢å‡½æ•°åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç±»å‹è½¬æ¢å‡½æ•°å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- ä»probabilityè½¬æ¢ä¸ºNUMERICï¼ˆè¿”å›æœŸæœ›å€¼ï¼‰
CREATE OR REPLACE FUNCTION probability_to_numeric(p probability)
RETURNS NUMERIC AS $$
BEGIN
    RETURN p.value * p.confidence;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

CREATE CAST (probability AS NUMERIC) WITH FUNCTION probability_to_numeric(probability);
```

**ç±»å‹éªŒè¯å‡½æ•°**ï¼š

```sql
-- éªŒè¯æ¦‚ç‡å€¼æœ‰æ•ˆæ€§ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability') THEN
            RAISE EXCEPTION 'ç±»å‹ probability ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
        END IF;
        
        CREATE OR REPLACE FUNCTION validate_probability(p probability)
        RETURNS BOOLEAN AS $$
        BEGIN
            IF p IS NULL THEN
                RETURN FALSE;
            END IF;
            RETURN p.confidence >= 0 AND p.confidence <= 1;
        EXCEPTION
            WHEN OTHERS THEN
                RETURN FALSE;
        END;
        $$ LANGUAGE plpgsql IMMUTABLE;
        RAISE NOTICE 'æ¦‚ç‡å€¼éªŒè¯å‡½æ•°åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæ¦‚ç‡å€¼éªŒè¯å‡½æ•°å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- éªŒè¯æ¦‚ç‡åˆ†å¸ƒæœ‰æ•ˆæ€§
CREATE OR REPLACE FUNCTION validate_distribution(dist probability_distribution)
RETURNS BOOLEAN AS $$
DECLARE
    prob_sum NUMERIC;
BEGIN
    -- æ£€æŸ¥æ•°ç»„é•¿åº¦æ˜¯å¦ç›¸åŒ
    IF array_length(dist.values, 1) != array_length(dist.probabilities, 1) THEN
        RETURN FALSE;
    END IF;

    -- æ£€æŸ¥æ¦‚ç‡å’Œæ˜¯å¦ä¸º1
    SELECT SUM(prob) INTO prob_sum
    FROM unnest(dist.probabilities) AS prob;

    RETURN ABS(prob_sum - 1.0) < 0.0001;
END;
$$ LANGUAGE plpgsql IMMUTABLE;
```

#### **3.2.5 ç±»å‹ç´¢å¼•æ”¯æŒ**

```sql
-- ä¸ºæ¦‚ç‡å€¼ç±»å‹åˆ›å»ºGISTç´¢å¼•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_measurements') THEN
            RAISE WARNING 'è¡¨ sensor_measurements ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºç´¢å¼•';
        ELSIF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_measurement_gist') THEN
            CREATE INDEX idx_measurement_gist ON sensor_measurements
            USING GIST (measurement);
            RAISE NOTICE 'GISTç´¢å¼•åˆ›å»ºæˆåŠŸ';
        END IF;
        
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'weather_forecast') THEN
            RAISE WARNING 'è¡¨ weather_forecast ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºç´¢å¼•';
        ELSIF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_temperature_dist_gin') THEN
            CREATE INDEX idx_temperature_dist_gin ON weather_forecast
            USING GIN ((temperature_dist).values);
            RAISE NOTICE 'GINç´¢å¼•åˆ›å»ºæˆåŠŸ';
        END IF;
        
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'product_reviews') THEN
            RAISE WARNING 'è¡¨ product_reviews ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºç´¢å¼•';
        ELSIF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'idx_review_gin') THEN
            CREATE INDEX idx_review_gin ON product_reviews
USING GIN ((review).tuple_data);
```

#### **3.2.6 ç±»å‹ä½¿ç”¨æœ€ä½³å®è·µ**

**1. ç±»å‹é€‰æ‹©åŸåˆ™**ï¼š

- **å•ä¸€å€¼ä¸ç¡®å®šæ€§**ï¼šä½¿ç”¨`probability`ç±»å‹
- **å¤šå€¼æ¦‚ç‡åˆ†å¸ƒ**ï¼šä½¿ç”¨`probability_distribution`ç±»å‹
- **å¤æ‚æ•°æ®ç»“æ„**ï¼šä½¿ç”¨`uncertain_tuple`ç±»å‹

**2. æ€§èƒ½ä¼˜åŒ–**ï¼š

- ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µåˆ›å»ºç´¢å¼•
- ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—æ¦‚ç‡èšåˆ
- é¿å…åœ¨WHEREå­å¥ä¸­ä½¿ç”¨å¤æ‚ç±»å‹æ“ä½œ

**3. æ•°æ®éªŒè¯**ï¼š

- ä½¿ç”¨CHECKçº¦æŸéªŒè¯æ¦‚ç‡å€¼èŒƒå›´
- ä½¿ç”¨è§¦å‘å™¨è‡ªåŠ¨éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
- å®šæœŸæ£€æŸ¥æ•°æ®è´¨é‡

**4. æŸ¥è¯¢ä¼˜åŒ–**ï¼š

- å…ˆè¿‡æ»¤å†èšåˆ
- ä½¿ç”¨ç‰©åŒ–è§†å›¾åŠ é€ŸæŸ¥è¯¢
- é¿å…æ·±åº¦åµŒå¥—çš„ç±»å‹æ“ä½œ

### 3.3 æŸ¥è¯¢å¤„ç†æ‰©å±•

#### **3.3.1 æ¦‚ç‡æŸ¥è¯¢æ“ä½œç¬¦**

**æ¦‚ç‡æ¯”è¾ƒæ“ä½œç¬¦**ï¼š

```sql
-- æ¦‚ç‡é€‰æ‹©ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ£€æŸ¥è¡¨å­˜åœ¨æ€§å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM sensor_data
WHERE probability > 0.8;

-- æ¦‚ç‡èŒƒå›´æŸ¥è¯¢
SELECT * FROM sensor_data
WHERE probability BETWEEN 0.7 AND 0.9;

-- æ¦‚ç‡æ’åºæŸ¥è¯¢
SELECT * FROM sensor_data
ORDER BY probability DESC
LIMIT 100;
```

**æ¦‚ç‡è¿æ¥æ“ä½œç¬¦**ï¼š

```sql
-- æ¦‚ç‡è¿æ¥ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'uncertain_table_a') OR
           NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'uncertain_table_b') THEN
            RAISE WARNING 'è¡¨ uncertain_table_a æˆ– uncertain_table_b ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ£€æŸ¥è¡¨å­˜åœ¨æ€§å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT a.*, b.*
FROM uncertain_table_a a
JOIN uncertain_table_b b
ON a.id = b.id
WHERE probability(a) * probability(b) > 0.5;

-- æ¦‚ç‡å†…è¿æ¥ï¼ˆåªè¿”å›é«˜æ¦‚ç‡ç»“æœï¼‰
SELECT a.*, b.*
FROM uncertain_table_a a
INNER JOIN uncertain_table_b b
ON a.id = b.id
WHERE a.probability > 0.8 AND b.probability > 0.8;
```

**æ¦‚ç‡èšåˆæ“ä½œç¬¦**ï¼š

```sql
-- æ¦‚ç‡èšåˆï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;

        -- æ£€æŸ¥æ˜¯å¦æœ‰probabilityç›¸å…³çš„å‡½æ•°
        IF NOT EXISTS (SELECT 1 FROM pg_proc WHERE proname IN ('prob_avg', 'prob_stddev')) THEN
            RAISE WARNING 'æ¦‚ç‡èšåˆå‡½æ•°PROB_AVGæˆ–PROB_STDDEVä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦å®‰è£…ProvSQLæ‰©å±•';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ£€æŸ¥å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    sensor_id,
    PROB_AVG(temperature) AS avg_temp,
    PROB_STDDEV(temperature) AS stddev_temp
FROM sensor_data
GROUP BY sensor_id;
```

#### **3.3.2 è‡ªå®šä¹‰æ“ä½œç¬¦å®ç°**

**æ¦‚ç‡å€¼æ¯”è¾ƒæ“ä½œç¬¦**ï¼š

```sql
-- åˆ›å»ºæ¦‚ç‡å€¼æ¯”è¾ƒæ“ä½œç¬¦ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        CREATE OR REPLACE FUNCTION probability_gt(
            prob1 NUMERIC,
            prob2 NUMERIC
        ) RETURNS BOOLEAN AS $$
        BEGIN
            IF prob1 IS NULL OR prob2 IS NULL THEN
                RETURN FALSE;
            END IF;
            RETURN prob1 > prob2;
        EXCEPTION
            WHEN OTHERS THEN
                RETURN FALSE;
        END;
        $$ LANGUAGE plpgsql IMMUTABLE;
        RAISE NOTICE 'æ¦‚ç‡å€¼æ¯”è¾ƒæ“ä½œç¬¦åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæ¦‚ç‡å€¼æ¯”è¾ƒæ“ä½œç¬¦å¤±è´¥: %', SQLERRM;
    END;
END $$;

CREATE OPERATOR > (
    LEFTARG = NUMERIC,
    RIGHTARG = NUMERIC,
    PROCEDURE = probability_gt,
    COMMUTATOR = <
);

-- ä½¿ç”¨è‡ªå®šä¹‰æ“ä½œç¬¦
SELECT * FROM sensor_data
WHERE probability > 0.8;
```

**æ¦‚ç‡å€¼ç®—æœ¯æ“ä½œç¬¦**ï¼š

```sql
-- æ¦‚ç‡å€¼ä¹˜æ³•æ“ä½œç¬¦ï¼ˆç”¨äºè¿æ¥æ¦‚ç‡è®¡ç®—ï¼Œå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        CREATE OR REPLACE FUNCTION probability_multiply(
            prob1 NUMERIC,
            prob2 NUMERIC
        ) RETURNS NUMERIC AS $$
        BEGIN
            IF prob1 IS NULL OR prob2 IS NULL THEN
                RETURN NULL;
            END IF;
            
            IF prob1 < 0 OR prob1 > 1 OR prob2 < 0 OR prob2 > 1 THEN
                RAISE EXCEPTION 'æ¦‚ç‡å€¼å¿…é¡»åœ¨[0, 1]èŒƒå›´å†…';
            END IF;
            
            -- ç¡®ä¿ç»“æœåœ¨[0, 1]èŒƒå›´å†…
            RETURN GREATEST(0, LEAST(1, prob1 * prob2));
        EXCEPTION
            WHEN OTHERS THEN
                RAISE EXCEPTION 'æ¦‚ç‡å€¼ä¹˜æ³•è®¡ç®—å¤±è´¥: %', SQLERRM;
        END;
        $$ LANGUAGE plpgsql IMMUTABLE;
        RAISE NOTICE 'æ¦‚ç‡å€¼ä¹˜æ³•æ“ä½œç¬¦åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæ¦‚ç‡å€¼ä¹˜æ³•æ“ä½œç¬¦å¤±è´¥: %', SQLERRM;
    END;
END $$;

CREATE OPERATOR * (
    LEFTARG = NUMERIC,
    RIGHTARG = NUMERIC,
    PROCEDURE = probability_multiply
);

-- ä½¿ç”¨æ¦‚ç‡ä¹˜æ³•
SELECT
    a.id,
    a.probability * b.probability AS joint_probability
FROM uncertain_table_a a
JOIN uncertain_table_b b ON a.id = b.id;
```

#### **3.3.3 è‡ªå®šä¹‰å‡½æ•°å®ç°**

**æ¦‚ç‡å€¼æå–å‡½æ•°**ï¼š

```sql
-- æå–æ¦‚ç‡å€¼ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability_value') THEN
            RAISE EXCEPTION 'ç±»å‹ probability_value ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
        END IF;
        
        CREATE OR REPLACE FUNCTION get_probability(
            prob_value probability_value
        ) RETURNS NUMERIC AS $$
        BEGIN
            IF prob_value IS NULL THEN
                RETURN NULL;
            END IF;
            RETURN prob_value.confidence;
        EXCEPTION
            WHEN OTHERS THEN
                RAISE EXCEPTION 'æå–æ¦‚ç‡å€¼å¤±è´¥: %', SQLERRM;
        END;
        $$ LANGUAGE plpgsql IMMUTABLE;
        RAISE NOTICE 'æ¦‚ç‡å€¼æå–å‡½æ•°åˆ›å»ºæˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæ¦‚ç‡å€¼æå–å‡½æ•°å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æå–å€¼
CREATE OR REPLACE FUNCTION get_value(
    prob_value probability_value
) RETURNS NUMERIC AS $$
BEGIN
    RETURN prob_value.value;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- ä½¿ç”¨å‡½æ•°
SELECT
    id,
    get_value(temperature) AS temp_value,
    get_probability(temperature) AS temp_probability
FROM sensor_readings;
```

**æ¦‚ç‡èšåˆå‡½æ•°**ï¼š

```sql
-- æ¦‚ç‡åŠ æƒå¹³å‡ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        CREATE OR REPLACE FUNCTION prob_weighted_avg(
            values NUMERIC[],
            probabilities NUMERIC[]
        ) RETURNS NUMERIC AS $$
        DECLARE
            weighted_sum NUMERIC := 0;
            prob_sum NUMERIC := 0;
            i INTEGER;
        BEGIN
            -- å‚æ•°éªŒè¯
            IF values IS NULL OR probabilities IS NULL THEN
                RAISE EXCEPTION 'æ•°ç»„å‚æ•°ä¸èƒ½ä¸ºç©º';
            END IF;
            
            IF array_length(values, 1) != array_length(probabilities, 1) THEN
                RAISE EXCEPTION 'æ•°ç»„é•¿åº¦å¿…é¡»ç›¸ç­‰';
            END IF;
    IF array_length(values, 1) != array_length(probabilities, 1) THEN
        RAISE EXCEPTION 'æ•°ç»„é•¿åº¦ä¸åŒ¹é…';
    END IF;

    FOR i IN 1..array_length(values, 1) LOOP
        weighted_sum := weighted_sum + values[i] * probabilities[i];
        prob_sum := prob_sum + probabilities[i];
    END LOOP;

    IF prob_sum = 0 THEN
        RETURN NULL;
    END IF;

    RETURN weighted_sum / prob_sum;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨æ¦‚ç‡åŠ æƒå¹³å‡
SELECT
    sensor_id,
    prob_weighted_avg(
        ARRAY_AGG(value),
        ARRAY_AGG(probability)
    ) AS weighted_avg
FROM sensor_data
GROUP BY sensor_id;
```

**æ¦‚ç‡ç»Ÿè®¡å‡½æ•°**ï¼š

```sql
-- æ¦‚ç‡æœ€å¤§å€¼
CREATE OR REPLACE FUNCTION prob_max(
    prob_value probability_value
) RETURNS probability_value AS $$
BEGIN
    RETURN prob_value;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- æ¦‚ç‡æœ€å°å€¼
CREATE OR REPLACE FUNCTION prob_min(
    prob_value probability_value
) RETURNS probability_value AS $$
BEGIN
    RETURN prob_value;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- æ¦‚ç‡æ ‡å‡†å·®
CREATE OR REPLACE FUNCTION prob_stddev(
    values NUMERIC[],
    probabilities NUMERIC[]
) RETURNS NUMERIC AS $$
DECLARE
    mean NUMERIC;
    variance NUMERIC := 0;
    prob_sum NUMERIC := 0;
    i INTEGER;
BEGIN
    -- è®¡ç®—åŠ æƒå¹³å‡
    mean := prob_weighted_avg(values, probabilities);

    -- è®¡ç®—åŠ æƒæ–¹å·®
    FOR i IN 1..array_length(values, 1) LOOP
        variance := variance + probabilities[i] * POWER(values[i] - mean, 2);
        prob_sum := prob_sum + probabilities[i];
    END LOOP;

    IF prob_sum = 0 THEN
        RETURN NULL;
    END IF;

    RETURN SQRT(variance / prob_sum);
END;
$$ LANGUAGE plpgsql;
```

#### **3.3.4 æŸ¥è¯¢ä¼˜åŒ–å™¨æ‰©å±•**

**æ¦‚ç‡æŸ¥è¯¢é‡å†™è§„åˆ™**ï¼š

```sql
-- åˆ›å»ºæŸ¥è¯¢é‡å†™å‡½æ•°
CREATE OR REPLACE FUNCTION optimize_probability_query(
    query_text TEXT
) RETURNS TEXT AS $$
DECLARE
    optimized_query TEXT;
BEGIN
    -- ç¤ºä¾‹ï¼šå°†æ¦‚ç‡è¿‡æ»¤æå‰
    optimized_query := query_text;

    -- å¦‚æœæŸ¥è¯¢åŒ…å«æ¦‚ç‡è¿‡æ»¤ï¼Œæå‰æ‰§è¡Œ
    IF query_text LIKE '%probability%' THEN
        -- æ·»åŠ ç´¢å¼•æç¤º
        optimized_query := REPLACE(
            optimized_query,
            'WHERE',
            'WHERE probability > 0.5 AND'
        );
    END IF;

    RETURN optimized_query;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨æŸ¥è¯¢ä¼˜åŒ–
SELECT optimize_probability_query('
    SELECT * FROM sensor_data
    WHERE sensor_id = 1
    AND probability > 0.8
');
```

**æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥**ï¼š

1. **æ¦‚ç‡è¿‡æ»¤æå‰**ï¼š
   - å°†æ¦‚ç‡è¿‡æ»¤æ¡ä»¶æå‰æ‰§è¡Œ
   - å‡å°‘åç»­å¤„ç†çš„æ•°æ®é‡
   - åˆ©ç”¨æ¦‚ç‡ç´¢å¼•åŠ é€ŸæŸ¥è¯¢

2. **æ¦‚ç‡èšåˆä¼˜åŒ–**ï¼š
   - ä½¿ç”¨å¢é‡è®¡ç®—
   - ç¼“å­˜ä¸­é—´ç»“æœ
   - å¹¶è¡Œè®¡ç®—æ¦‚ç‡èšåˆ

3. **æ¦‚ç‡è¿æ¥ä¼˜åŒ–**ï¼š
   - é€‰æ‹©æœ€ä¼˜è¿æ¥é¡ºåº
   - ä½¿ç”¨æ¦‚ç‡ç´¢å¼•åŠ é€Ÿè¿æ¥
   - å‡å°‘å¯èƒ½ä¸–ç•Œæšä¸¾

**æ¦‚ç‡ç´¢å¼•æ”¯æŒ**ï¼š

```sql
-- åˆ›å»ºæ¦‚ç‡å€¼B-treeç´¢å¼•ï¼ˆç”¨äºç²¾ç¡®æŸ¥è¯¢ï¼‰
CREATE INDEX idx_probability_btree ON sensor_data(probability);

-- åˆ›å»ºæ¦‚ç‡å€¼GINç´¢å¼•ï¼ˆç”¨äºèŒƒå›´æŸ¥è¯¢ï¼‰
CREATE INDEX idx_probability_gin ON sensor_data USING GIN(
    probability_range int4range(
        FLOOR(probability * 100)::int,
        CEIL(probability * 100)::int
    )
);

-- åˆ›å»ºå¤åˆç´¢å¼•ï¼ˆæ¦‚ç‡+å…¶ä»–å­—æ®µï¼‰
CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);

-- åˆ›å»ºéƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•é«˜æ¦‚ç‡æ•°æ®ï¼‰
CREATE INDEX idx_high_probability ON sensor_data(probability)
WHERE probability > 0.8;

-- ä½¿ç”¨ç´¢å¼•æç¤º
SET enable_seqscan = off;
SELECT * FROM sensor_data
WHERE probability > 0.8
ORDER BY probability DESC;
SET enable_seqscan = on;
```

**æŸ¥è¯¢ä¼˜åŒ–å™¨é…ç½®**ï¼š

```sql
-- é…ç½®æŸ¥è¯¢ä¼˜åŒ–å™¨å‚æ•°ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = current_user AND rolsuper = true) THEN
            RAISE WARNING 'éœ€è¦è¶…çº§ç”¨æˆ·æƒé™æ¥é…ç½®ç³»ç»Ÿå‚æ•°ï¼Œè·³è¿‡é…ç½®';
            RETURN;
        END IF;
        
        ALTER SYSTEM SET random_page_cost = 1.1;  -- é™ä½éšæœºI/Oæˆæœ¬
        ALTER SYSTEM SET cpu_tuple_cost = 0.01;   -- é™ä½CPUæˆæœ¬
        ALTER SYSTEM SET effective_cache_size = '4GB';  -- è®¾ç½®ç¼“å­˜å¤§å°
        ALTER SYSTEM SET max_parallel_workers_per_gather = 4;
        ALTER SYSTEM SET parallel_setup_cost = 1000;
        ALTER SYSTEM SET parallel_tuple_cost = 0.1;
        
        SELECT pg_reload_conf();
        RAISE NOTICE 'æŸ¥è¯¢ä¼˜åŒ–å™¨å‚æ•°é…ç½®æˆåŠŸ';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'é…ç½®æŸ¥è¯¢ä¼˜åŒ–å™¨å‚æ•°å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–é…ç½®
SET enable_probability_optimization = on;
SET probability_threshold = 0.5;  -- æ¦‚ç‡é˜ˆå€¼
SET max_possible_worlds = 10000;  -- æœ€å¤§å¯èƒ½ä¸–ç•Œæ•°
```

**è‡ªå®šä¹‰æŸ¥è¯¢é‡å†™è§„åˆ™**ï¼š

```sql
-- åˆ›å»ºæŸ¥è¯¢é‡å†™è§„åˆ™è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'query_rewrite_rules') THEN
            CREATE TABLE query_rewrite_rules (
                id SERIAL PRIMARY KEY,
                pattern TEXT NOT NULL,
                replacement TEXT NOT NULL,
                enabled BOOLEAN DEFAULT TRUE,
                priority INTEGER DEFAULT 0
            );
            RAISE NOTICE 'æŸ¥è¯¢é‡å†™è§„åˆ™è¡¨åˆ›å»ºæˆåŠŸ';
        ELSE
            RAISE NOTICE 'æŸ¥è¯¢é‡å†™è§„åˆ™è¡¨å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºæŸ¥è¯¢é‡å†™è§„åˆ™è¡¨å¤±è´¥: %', SQLERRM;
    END;
END $$;

-- æ’å…¥é‡å†™è§„åˆ™ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'query_rewrite_rules') THEN
            RAISE EXCEPTION 'è¡¨ query_rewrite_rules ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥è§„åˆ™';
        END IF;
        
        -- æ’å…¥ç¤ºä¾‹è§„åˆ™
INSERT INTO query_rewrite_rules (pattern, replacement, priority)
VALUES
    (
        'SELECT.*FROM.*WHERE.*probability.*>.*(\d+\.?\d*)',
        'SELECT * FROM $1 WHERE probability > $2 AND probability > 0.5',
        10
    ),
    (
        'SELECT.*AVG.*probability',
        'SELECT prob_weighted_avg(value, probability) AS avg_value',
        5
    );

-- æŸ¥è¯¢é‡å†™å‡½æ•°
CREATE OR REPLACE FUNCTION apply_query_rewrite_rules(
    query_text TEXT
) RETURNS TEXT AS $$
DECLARE
    rule_record RECORD;
    rewritten_query TEXT := query_text;
BEGIN
    FOR rule_record IN
        SELECT pattern, replacement
        FROM query_rewrite_rules
        WHERE enabled = TRUE
        ORDER BY priority DESC
    LOOP
        -- åº”ç”¨é‡å†™è§„åˆ™ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
        IF rewritten_query ~ rule_record.pattern THEN
            rewritten_query := regexp_replace(
                rewritten_query,
                rule_record.pattern,
                rule_record.replacement,
                'g'
            );
        END IF;
    END LOOP;

    RETURN rewritten_query;
END;
$$ LANGUAGE plpgsql;
```

#### **3.3.5 æ¦‚ç‡æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’**

**æŸ¥çœ‹æ¦‚ç‡æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’**ï¼š

```sql
-- åŸºç¡€æ‰§è¡Œè®¡åˆ’ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_data') THEN
            RAISE WARNING 'è¡¨ sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æŸ¥çœ‹æ‰§è¡Œè®¡åˆ’';
            RETURN;
        END IF;
        RAISE NOTICE 'å¼€å§‹æŸ¥çœ‹åŸºç¡€æ‰§è¡Œè®¡åˆ’';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æŸ¥è¯¢å‡†å¤‡å¤±è´¥: %', SQLERRM;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM sensor_data WHERE probability > 0.8;

-- è¯¦ç»†æ‰§è¡Œè®¡åˆ’ï¼ˆåŒ…å«æˆæœ¬ï¼Œå¸¦é”™è¯¯å¤„ç†ï¼‰
EXPLAIN (ANALYZE, BUFFERS, TIMING, VERBOSE)
SELECT
    sensor_id,
    AVG(value * probability) / NULLIF(AVG(probability), 0) AS weighted_avg
FROM sensor_data
GROUP BY sensor_id;

-- æ¦‚ç‡JOINæ‰§è¡Œè®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS)
SELECT a.*, b.*
FROM uncertain_table_a a
JOIN uncertain_table_b b ON a.id = b.id
WHERE a.probability * b.probability > 0.5;
```

**æ‰§è¡Œè®¡åˆ’åˆ†æ**ï¼š

**1. æ‰§è¡Œè®¡åˆ’ç»“æ„**ï¼š

```sql
-- æŸ¥çœ‹å®Œæ•´æ‰§è¡Œè®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS, VERBOSE, COSTS, TIMING, FORMAT JSON)
SELECT
    sensor_id,
    SUM(value * probability) / SUM(probability) AS weighted_avg,
    AVG(probability) AS avg_probability
FROM sensor_data
WHERE probability > 0.8
GROUP BY sensor_id;

-- æ‰§è¡Œè®¡åˆ’ç¤ºä¾‹è¾“å‡ºï¼š
-- HashAggregate (cost=... rows=...)
--   -> Seq Scan on sensor_data (cost=... rows=...)
--         Filter: (probability > 0.8)
```

**2. æ‰§è¡Œè®¡åˆ’ä¼˜åŒ–**ï¼š

```sql
-- ä½¿ç”¨ç´¢å¼•çš„æ‰§è¡Œè®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM sensor_data
WHERE probability > 0.8
ORDER BY probability DESC;

-- ä¼˜åŒ–åçš„æ‰§è¡Œè®¡åˆ’ï¼š
-- Index Scan using idx_probability_btree on sensor_data
--   Index Cond: (probability > 0.8)
--   Order By: probability DESC
```

**3. æ¦‚ç‡æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ç‰¹ç‚¹**ï¼š

- **æ¦‚ç‡è®¡ç®—èŠ‚ç‚¹**ï¼šæ‰§è¡Œè®¡åˆ’ä¸­åŒ…å«æ¦‚ç‡è®¡ç®—èŠ‚ç‚¹
- **å¯èƒ½ä¸–ç•Œæšä¸¾**ï¼šå¯¹äºå¤æ‚æŸ¥è¯¢ï¼Œå¯èƒ½åŒ…å«å¯èƒ½ä¸–ç•Œæšä¸¾èŠ‚ç‚¹
- **æ¦‚ç‡èšåˆèŠ‚ç‚¹**ï¼šåŒ…å«æ¦‚ç‡èšåˆè®¡ç®—èŠ‚ç‚¹
- **æº¯æºè¿½è¸ªèŠ‚ç‚¹**ï¼šå¦‚æœå¯ç”¨æº¯æºï¼ŒåŒ…å«æº¯æºè¿½è¸ªèŠ‚ç‚¹

**4. æ‰§è¡Œè®¡åˆ’ä¼˜åŒ–å»ºè®®**ï¼š

```sql
-- 1. ä½¿ç”¨ç´¢å¼•åŠ é€Ÿæ¦‚ç‡è¿‡æ»¤
CREATE INDEX idx_probability ON sensor_data(probability);
EXPLAIN SELECT * FROM sensor_data WHERE probability > 0.8;

-- 2. ä½¿ç”¨éƒ¨åˆ†ç´¢å¼•å‡å°‘ç´¢å¼•å¤§å°
CREATE INDEX idx_high_prob ON sensor_data(probability)
WHERE probability > 0.7;

-- 3. ä½¿ç”¨å¤åˆç´¢å¼•ä¼˜åŒ–å¤šæ¡ä»¶æŸ¥è¯¢
CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);
EXPLAIN SELECT * FROM sensor_data
WHERE sensor_id = 1 AND probability > 0.8;

-- 4. ä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢åŠ é€Ÿå¤§æ•°æ®é‡æŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;
EXPLAIN (ANALYZE) SELECT * FROM sensor_data WHERE probability > 0.8;

-- 5. è°ƒæ•´æˆæœ¬å‚æ•°ä¼˜åŒ–æ‰§è¡Œè®¡åˆ’
SET random_page_cost = 1.1;
SET cpu_tuple_cost = 0.01;
EXPLAIN SELECT * FROM sensor_data WHERE probability > 0.8;
```

**5. æ‰§è¡Œè®¡åˆ’ç›‘æ§**ï¼š

```sql
-- åˆ›å»ºæ‰§è¡Œè®¡åˆ’ç›‘æ§è¡¨
CREATE TABLE IF NOT EXISTS query_plan_log (
    id SERIAL PRIMARY KEY,
    query_text TEXT,
    execution_plan TEXT,
    execution_time INTERVAL,
    rows_returned BIGINT,
    created_at TIMESTAMP DEFAULT NOW()
) WITH PROVENANCE;

-- è®°å½•æ‰§è¡Œè®¡åˆ’å‡½æ•°
CREATE OR REPLACE FUNCTION log_query_plan(
    query_text TEXT
) RETURNS TEXT AS $$
DECLARE
    plan_text TEXT;
    exec_time INTERVAL;
    row_count BIGINT;
BEGIN
    -- è·å–æ‰§è¡Œè®¡åˆ’
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, TIMING) %s', query_text) INTO plan_text;

    -- è®°å½•æ‰§è¡Œè®¡åˆ’
    INSERT INTO query_plan_log (query_text, execution_plan)
    VALUES (query_text, plan_text);

    RETURN plan_text;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨æ‰§è¡Œè®¡åˆ’ç›‘æ§
SELECT log_query_plan('
    SELECT * FROM sensor_data WHERE probability > 0.8
');

-- æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’å†å²
SELECT
    id,
    query_text,
    execution_time,
    rows_returned,
    created_at
FROM query_plan_log
ORDER BY created_at DESC
LIMIT 10;
```

**6. æ‰§è¡Œè®¡åˆ’å¯¹æ¯”åˆ†æ**ï¼š

```sql
-- å¯¹æ¯”ä¸åŒæŸ¥è¯¢çš„æ‰§è¡Œè®¡åˆ’
-- æŸ¥è¯¢1ï¼šä¸ä½¿ç”¨ç´¢å¼•
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM sensor_data WHERE probability > 0.8;

-- æŸ¥è¯¢2ï¼šä½¿ç”¨ç´¢å¼•
CREATE INDEX idx_probability ON sensor_data(probability);
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM sensor_data WHERE probability > 0.8;

-- æŸ¥è¯¢3ï¼šä½¿ç”¨éƒ¨åˆ†ç´¢å¼•
CREATE INDEX idx_high_prob ON sensor_data(probability)
WHERE probability > 0.7;
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM sensor_data WHERE probability > 0.8;
```

**æ‰§è¡Œè®¡åˆ’ä¼˜åŒ–å»ºè®®æ€»ç»“**ï¼š

1. **ä½¿ç”¨ç´¢å¼•**ï¼šä¸ºæ¦‚ç‡å€¼åˆ›å»ºç´¢å¼•ï¼ŒåŠ é€Ÿæ¦‚ç‡è¿‡æ»¤
2. **æå‰è¿‡æ»¤**ï¼šåœ¨JOINå‰è¿‡æ»¤ä½æ¦‚ç‡æ•°æ®ï¼Œå‡å°‘è¿æ¥æ•°æ®é‡
3. **æ‰¹é‡å¤„ç†**ï¼šä½¿ç”¨æ‰¹é‡æ“ä½œå‡å°‘å¼€é”€
4. **ç‰©åŒ–è§†å›¾**ï¼šé¢„è®¡ç®—å¸¸è§æ¦‚ç‡æŸ¥è¯¢ï¼ŒåŠ é€ŸæŸ¥è¯¢
5. **å¹¶è¡ŒæŸ¥è¯¢**ï¼šå¯¹äºå¤§æ•°æ®é‡æŸ¥è¯¢ï¼Œä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢åŠ é€Ÿ
6. **æˆæœ¬å‚æ•°è°ƒä¼˜**ï¼šæ ¹æ®å®é™…ç¡¬ä»¶ç¯å¢ƒè°ƒæ•´æˆæœ¬å‚æ•°
7. **æ‰§è¡Œè®¡åˆ’ç›‘æ§**ï¼šå®šæœŸç›‘æ§æ‰§è¡Œè®¡åˆ’ï¼Œè¯†åˆ«æ€§èƒ½é—®é¢˜

---

## 4. ProvSQLé›†æˆ

### 4.1 ProvSQLæ¦‚è¿°

**ProvSQL**æ˜¯ä¸€ä¸ªPostgreSQLæ‰©å±•ï¼Œç”¨äºè¿½è¸ªæ•°æ®çš„æº¯æºï¼ˆProvenanceï¼‰å’Œæ¦‚ç‡ï¼ˆProbabilityï¼‰ã€‚

#### **4.1.1 æ ¸å¿ƒåŠŸèƒ½**

- **æ•°æ®æº¯æºè¿½è¸ª**ï¼šè¿½è¸ªæ•°æ®çš„æ¥æºå’Œè½¬æ¢è¿‡ç¨‹
- **æ¦‚ç‡è®¡ç®—**ï¼šåŸºäºæº¯æºä¿¡æ¯è®¡ç®—æ¦‚ç‡
- **ä¸ç¡®å®šæ€§ç®¡ç†**ï¼šç®¡ç†ä¸ç¡®å®šæ€§æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒ
- **æŸ¥è¯¢ç»“æœæ¦‚ç‡**ï¼šè®¡ç®—æŸ¥è¯¢ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ

#### **4.1.2 æŠ€æœ¯ç‰¹ç‚¹**

- **æ— ç¼é›†æˆ**ï¼šä½œä¸ºPostgreSQLæ‰©å±•ï¼Œæ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç 
- **é«˜æ€§èƒ½**ï¼šä¼˜åŒ–çš„æ¦‚ç‡è®¡ç®—ç®—æ³•
- **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§æ¦‚ç‡è®¡ç®—æ¨¡å¼
- **æ ‡å‡†å…¼å®¹**ï¼šæ”¯æŒSQLæ ‡å‡†è¯­æ³•

#### **4.1.3 é€‚ç”¨åœºæ™¯**

- ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†
- æ•°æ®èåˆå’Œé›†æˆ
- æ•°æ®è´¨é‡è¯„ä¼°
- æ•°æ®æº¯æºå’Œå®¡è®¡

### 4.2 å®‰è£…å’Œé…ç½®

#### **4.2.1 å®‰è£…æ­¥éª¤**

**ä»æºç ç¼–è¯‘å®‰è£…**ï¼š

```bash
# 1. å…‹éš†ProvSQLä»“åº“
git clone https://github.com/PierreSenellart/provsql.git
cd provsql

# 2. ç¼–è¯‘å’Œå®‰è£…
make
sudo make install

# 3. åœ¨PostgreSQLä¸­å¯ç”¨æ‰©å±•
psql -d your_database -c "CREATE EXTENSION provsql;"
```

**ä½¿ç”¨Dockerå®‰è£…**ï¼š

```dockerfile
FROM postgres:18

# å®‰è£…ä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    postgresql-server-dev-18

# å…‹éš†å’Œç¼–è¯‘ProvSQL
RUN git clone https://github.com/PierreSenellart/provsql.git /tmp/provsql && \
    cd /tmp/provsql && \
    make && \
    make install

# æ¸…ç†
RUN rm -rf /tmp/provsql && \
    apt-get clean
```

#### **4.2.2 é…ç½®é€‰é¡¹**

```sql
-- æŸ¥çœ‹ProvSQLé…ç½®
SHOW provsql.enable_provenance;
SHOW provsql.probability_mode;

-- å¯ç”¨æº¯æºè¿½è¸ª
SET provsql.enable_provenance = on;

-- è®¾ç½®æ¦‚ç‡è®¡ç®—æ¨¡å¼
SET provsql.probability_mode = 'default';  -- 'default', 'optimized', 'exact'
```

#### **4.2.3 éªŒè¯å®‰è£…**

```sql
-- æ£€æŸ¥æ‰©å±•æ˜¯å¦å®‰è£…
SELECT * FROM pg_extension WHERE extname = 'provsql';

-- æ£€æŸ¥å¯ç”¨å‡½æ•°
SELECT proname, prosrc
FROM pg_proc
WHERE proname LIKE 'provsql%';

-- æµ‹è¯•åŸºæœ¬åŠŸèƒ½
SELECT provsql_provenance_of(
    SELECT 1
);
```

### 4.3 é›†æˆæ¶æ„

#### **4.3.1 æ•´ä½“æ¶æ„è®¾è®¡**

**ProvSQLä¸æ¦‚ç‡æ•°æ®åº“é›†æˆæ¶æ„**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ProvSQLé›†æˆæ¶æ„                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ç”¨æˆ·æŸ¥è¯¢ï¼ˆSQL + æ¦‚ç‡æ“ä½œï¼‰                              â”‚
â”‚    â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   PostgreSQLæŸ¥è¯¢è§£æå±‚              â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ SQLè§£æ                        â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ æŸ¥è¯¢é‡å†™                       â”‚                â”‚
â”‚  â”‚  â””â”€â”€ æ‰§è¡Œè®¡åˆ’ç”Ÿæˆ                   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚    â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   ProvSQLæº¯æºè¿½è¸ªå±‚                 â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ è¿½è¸ªæ•°æ®æ¥æº                   â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ è®°å½•è½¬æ¢è¿‡ç¨‹                   â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ æ„å»ºæº¯æºå›¾                     â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ æº¯æºä¿¡æ¯å­˜å‚¨                   â”‚                â”‚
â”‚  â”‚  â””â”€â”€ æº¯æºæŸ¥è¯¢æ¥å£                   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚    â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   æ¦‚ç‡æ•°æ®åº“æŸ¥è¯¢å¤„ç†å±‚               â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–                   â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ æ¦‚ç‡è®¡ç®—å¼•æ“                   â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ å¯èƒ½ä¸–ç•Œæšä¸¾                   â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ æ¦‚ç‡èšåˆè®¡ç®—                   â”‚                â”‚
â”‚  â”‚  â””â”€â”€ ç»“æœæ¦‚ç‡åˆ†å¸ƒ                   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚    â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   ç»“æœæ•´åˆå±‚                        â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ åˆå¹¶æº¯æºä¿¡æ¯                   â”‚                â”‚
â”‚  â”‚  â”œâ”€â”€ åˆå¹¶æ¦‚ç‡ä¿¡æ¯                   â”‚                â”‚
â”‚  â”‚  â””â”€â”€ æ ¼å¼åŒ–è¾“å‡º                     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚    â†“                                                     â”‚
â”‚  æŸ¥è¯¢ç»“æœï¼ˆå«æ¦‚ç‡ä¿¡æ¯å’Œæº¯æºä¿¡æ¯ï¼‰                        â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **4.3.2 å„å±‚èŒè´£è¯¦è§£**

**1. PostgreSQLæŸ¥è¯¢è§£æå±‚**ï¼š

- **èŒè´£**ï¼š
  - è§£ææ ‡å‡†SQLæŸ¥è¯¢
  - è¯†åˆ«æ¦‚ç‡ç›¸å…³æ“ä½œï¼ˆWITH PROBABILITYã€PROBABILITY()ç­‰ï¼‰
  - æŸ¥è¯¢é‡å†™å’Œä¼˜åŒ–
  - ç”Ÿæˆæ‰§è¡Œè®¡åˆ’

- **å…³é”®ç»„ä»¶**ï¼š
  - SQLè§£æå™¨ï¼šè§£æSQLè¯­æ³•
  - æŸ¥è¯¢é‡å†™å™¨ï¼šé‡å†™æ¦‚ç‡æŸ¥è¯¢
  - è®¡åˆ’ç”Ÿæˆå™¨ï¼šç”Ÿæˆæ‰§è¡Œè®¡åˆ’

**2. ProvSQLæº¯æºè¿½è¸ªå±‚**ï¼š

- **èŒè´£**ï¼š
  - è¿½è¸ªæ•°æ®æ¥æºï¼šè®°å½•æ•°æ®çš„åŸå§‹æ¥æº
  - è®°å½•è½¬æ¢è¿‡ç¨‹ï¼šè®°å½•æ•°æ®è½¬æ¢å’Œå¤„ç†çš„æ¯ä¸€æ­¥
  - æ„å»ºæº¯æºå›¾ï¼šæ„å»ºå®Œæ•´çš„æ•°æ®æº¯æºå›¾
  - å­˜å‚¨æº¯æºä¿¡æ¯ï¼šæŒä¹…åŒ–å­˜å‚¨æº¯æºä¿¡æ¯
  - æä¾›æº¯æºæŸ¥è¯¢æ¥å£ï¼šæä¾›æŸ¥è¯¢æº¯æºä¿¡æ¯çš„æ¥å£

- **å…³é”®ç»„ä»¶**ï¼š
  - æº¯æºè¿½è¸ªå™¨ï¼šè‡ªåŠ¨è¿½è¸ªæ•°æ®æ¥æº
  - æº¯æºå›¾æ„å»ºå™¨ï¼šæ„å»ºå’Œå­˜å‚¨æº¯æºå›¾
  - æº¯æºæŸ¥è¯¢å¼•æ“ï¼šæŸ¥è¯¢å’Œæ£€ç´¢æº¯æºä¿¡æ¯

**3. æ¦‚ç‡æ•°æ®åº“æŸ¥è¯¢å¤„ç†å±‚**ï¼š

- **èŒè´£**ï¼š
  - æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–ï¼šä¼˜åŒ–æ¦‚ç‡æŸ¥è¯¢çš„æ‰§è¡Œ
  - æ¦‚ç‡è®¡ç®—å¼•æ“ï¼šè®¡ç®—æ¦‚ç‡å€¼
  - å¯èƒ½ä¸–ç•Œæšä¸¾ï¼šæšä¸¾æ‰€æœ‰å¯èƒ½ä¸–ç•Œ
  - æ¦‚ç‡èšåˆè®¡ç®—ï¼šè®¡ç®—æ¦‚ç‡èšåˆç»“æœ
  - ç»“æœæ¦‚ç‡åˆ†å¸ƒï¼šç”Ÿæˆç»“æœçš„æ¦‚ç‡åˆ†å¸ƒ

- **å…³é”®ç»„ä»¶**ï¼š
  - æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–å™¨ï¼šä¼˜åŒ–æ¦‚ç‡æŸ¥è¯¢
  - æ¦‚ç‡è®¡ç®—å¼•æ“ï¼šæ‰§è¡Œæ¦‚ç‡è®¡ç®—
  - å¯èƒ½ä¸–ç•Œæšä¸¾å™¨ï¼šæšä¸¾å¯èƒ½ä¸–ç•Œ
  - æ¦‚ç‡èšåˆå™¨ï¼šèšåˆæ¦‚ç‡å€¼

**4. ç»“æœæ•´åˆå±‚**ï¼š

- **èŒè´£**ï¼š
  - åˆå¹¶æº¯æºä¿¡æ¯ï¼šå°†æº¯æºä¿¡æ¯åˆå¹¶åˆ°æŸ¥è¯¢ç»“æœ
  - åˆå¹¶æ¦‚ç‡ä¿¡æ¯ï¼šå°†æ¦‚ç‡ä¿¡æ¯åˆå¹¶åˆ°æŸ¥è¯¢ç»“æœ
  - æ ¼å¼åŒ–è¾“å‡ºï¼šæ ¼å¼åŒ–æœ€ç»ˆè¾“å‡ºç»“æœ

- **å…³é”®ç»„ä»¶**ï¼š
  - ç»“æœåˆå¹¶å™¨ï¼šåˆå¹¶å„ç§ä¿¡æ¯
  - æ ¼å¼åŒ–å™¨ï¼šæ ¼å¼åŒ–è¾“å‡º

#### **4.3.3 æ•°æ®æµè¯¦ç»†è¯´æ˜**

**æŸ¥è¯¢å¤„ç†æµç¨‹**ï¼š

1. **æŸ¥è¯¢è§£æé˜¶æ®µ**ï¼š
   - ç”¨æˆ·æäº¤SQLæŸ¥è¯¢ï¼ˆå¯èƒ½åŒ…å«æ¦‚ç‡æ“ä½œï¼‰
   - PostgreSQLè§£æå™¨è§£æSQL
   - è¯†åˆ«æ¦‚ç‡ç›¸å…³æ“ä½œå’Œè¯­æ³•
   - ç”ŸæˆæŸ¥è¯¢æ ‘

2. **æŸ¥è¯¢é‡å†™é˜¶æ®µ**ï¼š
   - è¯†åˆ«æ¦‚ç‡æŸ¥è¯¢æ¨¡å¼
   - é‡å†™æŸ¥è¯¢ä»¥æ”¯æŒæ¦‚ç‡è®¡ç®—
   - æ·»åŠ æº¯æºè¿½è¸ªä»£ç 
   - ä¼˜åŒ–æŸ¥è¯¢ç»“æ„

3. **æ‰§è¡Œè®¡åˆ’ç”Ÿæˆé˜¶æ®µ**ï¼š
   - ç”ŸæˆåŒ…å«æ¦‚ç‡è®¡ç®—çš„æ‰§è¡Œè®¡åˆ’
   - æ·»åŠ æº¯æºè¿½è¸ªèŠ‚ç‚¹
   - ä¼˜åŒ–æ‰§è¡Œè®¡åˆ’
   - é€‰æ‹©æœ€ä¼˜æ‰§è¡Œç­–ç•¥

4. **æŸ¥è¯¢æ‰§è¡Œé˜¶æ®µ**ï¼š
   - æ‰§è¡Œæ•°æ®æŸ¥è¯¢
   - å¹¶è¡Œæ‰§è¡Œæº¯æºè¿½è¸ª
   - æ‰§è¡Œæ¦‚ç‡è®¡ç®—
   - åˆå¹¶ä¸­é—´ç»“æœ

5. **ç»“æœç”Ÿæˆé˜¶æ®µ**ï¼š
   - åˆå¹¶æº¯æºä¿¡æ¯
   - åˆå¹¶æ¦‚ç‡ä¿¡æ¯
   - æ ¼å¼åŒ–è¾“å‡º
   - è¿”å›æœ€ç»ˆç»“æœ

**æ•°æ®æµç¤ºä¾‹**ï¼š

```sql
-- ç”¨æˆ·æŸ¥è¯¢
SELECT
    sensor_id,
    AVG(value) AS avg_value,
    PROBABILITY() AS prob,
    provsql_provenance_of(
        SELECT * FROM sensor_data WHERE sensor_id = sensor_data.sensor_id
    ) AS provenance
FROM sensor_data
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY sensor_id;

-- æ‰§è¡Œæµç¨‹ï¼š
-- 1. è§£ææŸ¥è¯¢ï¼Œè¯†åˆ«PROBABILITY()å’Œprovsql_provenance_of()
-- 2. é‡å†™æŸ¥è¯¢ï¼Œæ·»åŠ æ¦‚ç‡è®¡ç®—å’Œæº¯æºè¿½è¸ª
-- 3. ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼ŒåŒ…å«æ¦‚ç‡è®¡ç®—èŠ‚ç‚¹å’Œæº¯æºè¿½è¸ªèŠ‚ç‚¹
-- 4. æ‰§è¡ŒæŸ¥è¯¢ï¼š
--    - æŸ¥è¯¢sensor_dataè¡¨
--    - å¹¶è¡Œè¿½è¸ªæ•°æ®æ¥æº
--    - è®¡ç®—æ¦‚ç‡å€¼
--    - è®¡ç®—å¹³å‡å€¼
-- 5. åˆå¹¶ç»“æœï¼š
--    - åˆå¹¶å¹³å‡å€¼
--    - åˆå¹¶æ¦‚ç‡å€¼
--    - åˆå¹¶æº¯æºä¿¡æ¯
-- 6. è¿”å›æœ€ç»ˆç»“æœ
```

#### **4.3.4 æ¥å£è®¾è®¡**

**ProvSQLæ¥å£**ï¼š

1. **æº¯æºè¿½è¸ªæ¥å£**ï¼š

   ```sql
   -- å¯ç”¨æº¯æºè¿½è¸ª
   CREATE TABLE table_name (...) WITH PROVENANCE;

   -- æŸ¥è¯¢æº¯æºä¿¡æ¯
   provsql_provenance_of(query)
   ```

2. **æ¦‚ç‡è®¡ç®—æ¥å£**ï¼š

   ```sql
   -- æ’å…¥å¸¦æ¦‚ç‡çš„æ•°æ®
   INSERT INTO table_name VALUES (...) WITH PROBABILITY 0.9;

   -- æŸ¥è¯¢æ¦‚ç‡å€¼
   PROBABILITY()
   ```

3. **é…ç½®æ¥å£**ï¼š

   ```sql
   -- é…ç½®æ¦‚ç‡è®¡ç®—æ¨¡å¼
   SET provsql.probability_mode = 'default';

   -- å¯ç”¨/ç¦ç”¨æº¯æºè¿½è¸ª
   SET provsql.enable_provenance = on;
   ```

**æ¦‚ç‡æ•°æ®åº“æ¥å£**ï¼š

1. **æ•°æ®ç±»å‹æ¥å£**ï¼š

   ```sql
   -- æ¦‚ç‡å€¼ç±»å‹
   CREATE TYPE probability_value AS (value NUMERIC, confidence NUMERIC);
   ```

2. **æ“ä½œç¬¦æ¥å£**ï¼š

   ```sql
   -- æ¦‚ç‡æ¯”è¾ƒæ“ä½œç¬¦
   CREATE OPERATOR > (LEFTARG = NUMERIC, RIGHTARG = NUMERIC, ...);
   ```

3. **å‡½æ•°æ¥å£**ï¼š

   ```sql
   -- æ¦‚ç‡èšåˆå‡½æ•°
   CREATE FUNCTION prob_weighted_avg(...) RETURNS NUMERIC;
   ```

#### **4.3.5 é›†æˆä¼˜åŠ¿**

**1. æ— ç¼é›†æˆ**ï¼š

- ä½œä¸ºPostgreSQLæ‰©å±•ï¼Œæ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç 
- æ”¯æŒæ ‡å‡†SQLè¯­æ³•
- å…¼å®¹ç°æœ‰PostgreSQLåŠŸèƒ½

**2. é«˜æ€§èƒ½**ï¼š

- ä¼˜åŒ–çš„æ¦‚ç‡è®¡ç®—ç®—æ³•
- å¹¶è¡Œæº¯æºè¿½è¸ª
- é«˜æ•ˆçš„æŸ¥è¯¢æ‰§è¡Œ

**3. çµæ´»é…ç½®**ï¼š

- å¯é…ç½®çš„æ¦‚ç‡è®¡ç®—æ¨¡å¼
- å¯é€‰çš„æº¯æºè¿½è¸ª
- çµæ´»çš„æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥

**4. æ˜“äºä½¿ç”¨**ï¼š

- ç®€å•çš„SQLè¯­æ³•
- ä¸°å¯Œçš„å‡½æ•°å’Œæ“ä½œç¬¦
- å®Œå–„çš„æ–‡æ¡£å’Œç¤ºä¾‹

### 4.4 æ ¸å¿ƒåŠŸèƒ½è¯¦è§£

#### **4.4.1 æº¯æºè¿½è¸ª**

```sql
-- åˆ›å»ºå¸¦æº¯æºçš„è¡¨
CREATE TABLE sensor_data (
    id SERIAL,
    sensor_id INT,
    value NUMERIC,
    timestamp TIMESTAMP
) WITH PROVENANCE;

-- æ’å…¥æ•°æ®ï¼ˆè‡ªåŠ¨è®°å½•æº¯æºï¼‰
INSERT INTO sensor_data (sensor_id, value, timestamp)
VALUES (1, 25.5, NOW());

-- æŸ¥è¯¢æº¯æºä¿¡æ¯
SELECT provsql_provenance_of(
    SELECT * FROM sensor_data WHERE sensor_id = 1
);
```

#### **4.4.2 æ¦‚ç‡è®¡ç®—**

```sql
-- æ’å…¥å¸¦æ¦‚ç‡çš„æ•°æ®
INSERT INTO sensor_data (sensor_id, value, timestamp)
VALUES (1, 25.5, NOW())
WITH PROBABILITY 0.95;

-- æŸ¥è¯¢æ¦‚ç‡
SELECT
    sensor_id,
    AVG(value) AS avg_value,
    PROBABILITY() AS probability
FROM sensor_data
GROUP BY sensor_id;
```

#### **4.4.3 æº¯æºå’Œæ¦‚ç‡ç»“åˆ**

```sql
-- æŸ¥è¯¢æº¯æºå’Œæ¦‚ç‡
SELECT
    provsql_provenance_of(
        SELECT * FROM sensor_data WHERE sensor_id = 1
    ) AS provenance,
    PROBABILITY() AS probability
FROM sensor_data
WHERE sensor_id = 1;
```

### 4.5 ä½¿ç”¨ç¤ºä¾‹

#### **4.5.1 åŸºç¡€ä½¿ç”¨ç¤ºä¾‹**

**ç¤ºä¾‹1ï¼šåˆ›å»ºå¸¦æº¯æºå’Œæ¦‚ç‡çš„è¡¨**

```sql
-- å¯ç”¨ProvSQLæ‰©å±•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'provsql') THEN
            CREATE EXTENSION provsql;
            RAISE NOTICE 'ProvSQLæ‰©å±•å·²åˆ›å»º';
        ELSE
            RAISE NOTICE 'ProvSQLæ‰©å±•å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN undefined_file THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…';
        WHEN insufficient_privilege THEN
            RAISE WARNING 'æƒé™ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºæ‰©å±•';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºProvSQLæ‰©å±•å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- åˆ›å»ºå¸¦æº¯æºçš„è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'provsql') THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æœªå®‰è£…ï¼Œè¯·å…ˆæ‰§è¡Œ: CREATE EXTENSION provsql;';
            RETURN;
        END IF;

        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
            RAISE NOTICE 'è¡¨ sensor_readings å·²å­˜åœ¨';
        ELSE
            CREATE TABLE sensor_readings (
                id SERIAL,
                sensor_id INT,
                temperature NUMERIC,
                timestamp TIMESTAMP
            ) WITH PROVENANCE;
            RAISE NOTICE 'è¡¨ sensor_readings å·²åˆ›å»ºå¹¶å¯ç”¨æº¯æº';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'è¡¨ sensor_readings å·²å­˜åœ¨';
        WHEN undefined_object THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æœªå®‰è£…æˆ–WITH PROVENANCEè¯­æ³•ä¸æ”¯æŒ';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**ç¤ºä¾‹2ï¼šæ’å…¥å¸¦æ¦‚ç‡çš„æ•°æ®**

```sql
-- æ’å…¥æ•°æ®ï¼ˆå¸¦æ¦‚ç‡ï¼Œå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
            RAISE WARNING 'è¡¨ sensor_readings ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'provsql') THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨WITH PROBABILITYè¯­æ³•';
            RETURN;
        END IF;

        -- æ’å…¥å¤šæ¡å¸¦æ¦‚ç‡çš„æ•°æ®
        INSERT INTO sensor_readings (sensor_id, temperature, timestamp)
        VALUES
            (1, 25.5, NOW()) WITH PROBABILITY 0.95,
            (1, 25.7, NOW()) WITH PROBABILITY 0.90,
            (1, 25.3, NOW()) WITH PROBABILITY 0.85;

        RAISE NOTICE 'å·²æ’å…¥3æ¡å¸¦æ¦‚ç‡çš„æ•°æ®';
    EXCEPTION
        WHEN undefined_table THEN
            RAISE WARNING 'è¡¨ sensor_readings ä¸å­˜åœ¨';
        WHEN syntax_error THEN
            RAISE WARNING 'WITH PROBABILITYè¯­æ³•ä¸æ”¯æŒï¼Œè¯·ç¡®ä¿ProvSQLæ‰©å±•å·²æ­£ç¡®å®‰è£…';
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### **4.5.2 æ¦‚ç‡æŸ¥è¯¢ç¤ºä¾‹**

**ç¤ºä¾‹3ï¼šåŸºç¡€æ¦‚ç‡æŸ¥è¯¢**

```sql
-- æ¦‚ç‡æŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
            RAISE WARNING 'è¡¨ sensor_readings ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'provsql') THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨PROBABILITYå‡½æ•°';
            RETURN;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ£€æŸ¥å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    sensor_id,
    AVG(temperature) AS avg_temp,
    PROBABILITY() AS prob
FROM sensor_readings
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY sensor_id;
```

**ç¤ºä¾‹4ï¼šæ¦‚ç‡è¿‡æ»¤æŸ¥è¯¢**

```sql
-- æŸ¥è¯¢é«˜æ¦‚ç‡æ•°æ®ï¼ˆæ¦‚ç‡>0.9ï¼‰
SELECT
    sensor_id,
    temperature,
    timestamp,
    PROBABILITY() AS probability
FROM sensor_readings
WHERE PROBABILITY() > 0.9
ORDER BY PROBABILITY() DESC;
```

**ç¤ºä¾‹5ï¼šæ¦‚ç‡èšåˆæŸ¥è¯¢**

```sql
-- è®¡ç®—åŠ æƒå¹³å‡æ¸©åº¦ï¼ˆæ¦‚ç‡åŠ æƒï¼‰
SELECT
    sensor_id,
    SUM(temperature * PROBABILITY()) / SUM(PROBABILITY()) AS weighted_avg_temp,
    AVG(PROBABILITY()) AS avg_confidence,
    COUNT(*) AS reading_count
FROM sensor_readings
WHERE timestamp > NOW() - INTERVAL '24 hours'
GROUP BY sensor_id
HAVING AVG(PROBABILITY()) > 0.8;
```

#### **4.5.3 æº¯æºæŸ¥è¯¢ç¤ºä¾‹**

**ç¤ºä¾‹6ï¼šæŸ¥è¯¢æ•°æ®æº¯æº**

```sql
-- æŸ¥è¯¢æ•°æ®çš„æº¯æºä¿¡æ¯
SELECT
    id,
    sensor_id,
    temperature,
    provsql_provenance_of(
        SELECT * FROM sensor_readings WHERE id = sensor_readings.id
    ) AS provenance
FROM sensor_readings
WHERE sensor_id = 1
LIMIT 10;
```

**ç¤ºä¾‹7ï¼šæº¯æºå’Œæ¦‚ç‡ç»“åˆæŸ¥è¯¢**

```sql
-- æŸ¥è¯¢æº¯æºå’Œæ¦‚ç‡
SELECT
    sensor_id,
    AVG(temperature) AS avg_temp,
    provsql_provenance_of(
        SELECT * FROM sensor_readings WHERE sensor_id = sensor_readings.sensor_id
    ) AS provenance,
    PROBABILITY() AS probability
FROM sensor_readings
GROUP BY sensor_id;
```

#### **4.5.4 å¤æ‚æŸ¥è¯¢ç¤ºä¾‹**

**ç¤ºä¾‹8ï¼šå¤šè¡¨æ¦‚ç‡JOINæŸ¥è¯¢**

```sql
-- åˆ›å»ºç¬¬äºŒä¸ªè¡¨
CREATE TABLE IF NOT EXISTS sensor_metadata (
    sensor_id INT PRIMARY KEY,
    location TEXT,
    sensor_type TEXT
) WITH PROVENANCE;

-- æ’å…¥å…ƒæ•°æ®
INSERT INTO sensor_metadata (sensor_id, location, sensor_type)
VALUES
    (1, 'Building A', 'Temperature') WITH PROBABILITY 0.98,
    (2, 'Building B', 'Humidity') WITH PROBABILITY 0.95;

-- æ¦‚ç‡JOINæŸ¥è¯¢
SELECT
    sr.sensor_id,
    sm.location,
    sm.sensor_type,
    AVG(sr.temperature) AS avg_temp,
    PROBABILITY() AS join_probability
FROM sensor_readings sr
JOIN sensor_metadata sm ON sr.sensor_id = sm.sensor_id
WHERE sr.timestamp > NOW() - INTERVAL '1 hour'
GROUP BY sr.sensor_id, sm.location, sm.sensor_type;
```

**ç¤ºä¾‹9ï¼šæ¦‚ç‡å­æŸ¥è¯¢**

```sql
-- ä½¿ç”¨æ¦‚ç‡å­æŸ¥è¯¢
SELECT
    sensor_id,
    temperature,
    timestamp,
    PROBABILITY() AS probability,
    (SELECT AVG(temperature)
     FROM sensor_readings sr2
     WHERE sr2.sensor_id = sensor_readings.sensor_id
       AND PROBABILITY() > 0.8
    ) AS high_confidence_avg
FROM sensor_readings
WHERE timestamp > NOW() - INTERVAL '1 hour';
```

**ç¤ºä¾‹10ï¼šæ¦‚ç‡çª—å£å‡½æ•°**

```sql
-- ä½¿ç”¨æ¦‚ç‡çª—å£å‡½æ•°
SELECT
    sensor_id,
    temperature,
    timestamp,
    PROBABILITY() AS probability,
    AVG(temperature) OVER (
        PARTITION BY sensor_id
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) AS moving_avg,
    AVG(PROBABILITY()) OVER (
        PARTITION BY sensor_id
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) AS moving_avg_prob
FROM sensor_readings
WHERE timestamp > NOW() - INTERVAL '24 hours'
ORDER BY sensor_id, timestamp;
```

#### **4.5.5 å®é™…åº”ç”¨åœºæ™¯ç¤ºä¾‹**

**ç¤ºä¾‹11ï¼šæ•°æ®è´¨é‡è¯„ä¼°**

```sql
-- è¯„ä¼°æ•°æ®è´¨é‡ï¼ˆåŸºäºæ¦‚ç‡ï¼‰
SELECT
    sensor_id,
    COUNT(*) AS total_readings,
    COUNT(*) FILTER (WHERE PROBABILITY() > 0.9) AS high_quality_readings,
    COUNT(*) FILTER (WHERE PROBABILITY() BETWEEN 0.7 AND 0.9) AS medium_quality_readings,
    COUNT(*) FILTER (WHERE PROBABILITY() < 0.7) AS low_quality_readings,
    AVG(PROBABILITY()) AS avg_quality_score
FROM sensor_readings
WHERE timestamp > NOW() - INTERVAL '24 hours'
GROUP BY sensor_id
ORDER BY avg_quality_score DESC;
```

**ç¤ºä¾‹12ï¼šå¼‚å¸¸æ£€æµ‹ï¼ˆä½æ¦‚ç‡æ•°æ®ï¼‰**

```sql
-- æ£€æµ‹å¼‚å¸¸æ•°æ®ï¼ˆä½æ¦‚ç‡å€¼ï¼‰
SELECT
    id,
    sensor_id,
    temperature,
    timestamp,
    PROBABILITY() AS probability,
    provsql_provenance_of(
        SELECT * FROM sensor_readings WHERE id = sensor_readings.id
    ) AS provenance
FROM sensor_readings
WHERE PROBABILITY() < 0.5  -- ä½æ¦‚ç‡æ•°æ®å¯èƒ½æ˜¯å¼‚å¸¸
ORDER BY PROBABILITY() ASC
LIMIT 20;
```

**ç¤ºä¾‹13ï¼šæ•°æ®èåˆæŸ¥è¯¢**

```sql
-- å¤šæºæ•°æ®èåˆï¼ˆä½¿ç”¨æ¦‚ç‡åŠ æƒï¼‰
WITH source_a AS (
    SELECT sensor_id, temperature, PROBABILITY() AS prob
    FROM sensor_readings
    WHERE timestamp > NOW() - INTERVAL '1 hour'
),
source_b AS (
    SELECT sensor_id, temperature, PROBABILITY() AS prob
    FROM sensor_readings_backup
    WHERE timestamp > NOW() - INTERVAL '1 hour'
)
SELECT
    COALESCE(a.sensor_id, b.sensor_id) AS sensor_id,
    COALESCE(a.temperature, b.temperature) AS temperature,
    GREATEST(COALESCE(a.prob, 0), COALESCE(b.prob, 0)) AS fused_probability
FROM source_a a
FULL OUTER JOIN source_b b ON a.sensor_id = b.sensor_id
WHERE GREATEST(COALESCE(a.prob, 0), COALESCE(b.prob, 0)) > 0.7;
```

---

## 5. å®é™…åº”ç”¨æ¡ˆä¾‹

### 5.1 ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†

#### **5.1.1 ä¸šåŠ¡åœºæ™¯**

**åœºæ™¯æè¿°**ï¼š
IoTä¼ æ„Ÿå™¨ç½‘ç»œæ”¶é›†ç¯å¢ƒæ•°æ®ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ã€å‹åŠ›ç­‰ï¼‰ï¼Œç”±äºä¼ æ„Ÿå™¨ç²¾åº¦é™åˆ¶ã€ç¯å¢ƒå¹²æ‰°ã€ç½‘ç»œå»¶è¿Ÿç­‰å› ç´ ï¼Œæµ‹é‡æ•°æ®å­˜åœ¨ä¸ç¡®å®šæ€§ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

1. å­˜å‚¨ä¸ç¡®å®šçš„ä¼ æ„Ÿå™¨æ•°æ®
2. è¯„ä¼°æ•°æ®å¯ä¿¡åº¦
3. åŸºäºæ¦‚ç‡è¿›è¡Œæ•°æ®åˆ†æå’Œå†³ç­–
4. è¿½è¸ªæ•°æ®æ¥æºå’Œå¤„ç†è¿‡ç¨‹

**æŒ‘æˆ˜**ï¼š

- ä¼ æ„Ÿå™¨æµ‹é‡è¯¯å·®
- ç¯å¢ƒå™ªå£°å¹²æ‰°
- æ•°æ®ä¸¢å¤±æˆ–å»¶è¿Ÿ
- å¤šä¼ æ„Ÿå™¨æ•°æ®ä¸ä¸€è‡´

#### **5.1.2 æ•°æ®æ¨¡å‹è®¾è®¡**

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
-- åˆ›å»ºä¼ æ„Ÿå™¨æ•°æ®è¡¨ï¼ˆå¸¦æ¦‚ç‡ï¼Œå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'provsql') THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æœªå®‰è£…ï¼Œè¯·å…ˆæ‰§è¡Œ: CREATE EXTENSION provsql;';
            RETURN;
        END IF;

        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'iot_sensor_data') THEN
            RAISE NOTICE 'è¡¨ iot_sensor_data å·²å­˜åœ¨';
        ELSE
            CREATE TABLE iot_sensor_data (
                id SERIAL PRIMARY KEY,
                sensor_id INT NOT NULL,
                sensor_type VARCHAR(50),  -- ä¼ æ„Ÿå™¨ç±»å‹ï¼štemperature, humidity, pressure
                value NUMERIC NOT NULL,
                probability NUMERIC CHECK (probability >= 0 AND probability <= 1),  -- æ•°æ®å¯ä¿¡åº¦
                unit VARCHAR(10),  -- å•ä½ï¼šCelsius, Percent, Pascal
                timestamp TIMESTAMP NOT NULL DEFAULT NOW(),
                location VARCHAR(100),  -- ä¼ æ„Ÿå™¨ä½ç½®
                quality_score NUMERIC  -- æ•°æ®è´¨é‡è¯„åˆ†
            ) WITH PROVENANCE;

            -- åˆ›å»ºç´¢å¼•
            CREATE INDEX idx_sensor_id ON iot_sensor_data(sensor_id);
            CREATE INDEX idx_timestamp ON iot_sensor_data(timestamp);
            CREATE INDEX idx_probability ON iot_sensor_data(probability);
            CREATE INDEX idx_sensor_prob ON iot_sensor_data(sensor_id, probability);

            RAISE NOTICE 'è¡¨ iot_sensor_data å·²åˆ›å»ºå¹¶å¯ç”¨æº¯æº';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'è¡¨ iot_sensor_data å·²å­˜åœ¨';
        WHEN undefined_object THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æœªå®‰è£…æˆ–WITH PROVENANCEè¯­æ³•ä¸æ”¯æŒ';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### **5.1.3 æ•°æ®æ’å…¥å’Œæ¦‚ç‡è®¡ç®—**

**æ’å…¥ä¸ç¡®å®šæ•°æ®**ï¼š

```sql
-- æ’å…¥ä¸ç¡®å®šæ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'iot_sensor_data') THEN
            RAISE WARNING 'è¡¨ iot_sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        -- æ’å…¥æ¸©åº¦ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆä¸åŒå¯ä¿¡åº¦ï¼‰
        INSERT INTO iot_sensor_data (sensor_id, sensor_type, value, probability, unit, location)
        VALUES
            (1, 'temperature', 25.3, 0.95, 'Celsius', 'Building A Floor 1'),
            (1, 'temperature', 25.5, 0.90, 'Celsius', 'Building A Floor 1'),
            (1, 'temperature', 25.1, 0.85, 'Celsius', 'Building A Floor 1'),
            (2, 'humidity', 60.0, 0.92, 'Percent', 'Building A Floor 2'),
            (2, 'humidity', 61.0, 0.88, 'Percent', 'Building A Floor 2'),
            (3, 'pressure', 1013.25, 0.98, 'Pascal', 'Building B Floor 1');

        RAISE NOTICE 'å·²æ’å…¥6æ¡ä¸ç¡®å®šæ•°æ®åˆ°iot_sensor_dataè¡¨';
    EXCEPTION
        WHEN undefined_table THEN
            RAISE WARNING 'è¡¨ iot_sensor_data ä¸å­˜åœ¨';
        WHEN check_violation THEN
            RAISE WARNING 'æ¦‚ç‡å€¼è¶…å‡ºèŒƒå›´[0, 1]';
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**æ¦‚ç‡è®¡ç®—å‡½æ•°**ï¼š

```sql
-- è®¡ç®—ä¼ æ„Ÿå™¨æ•°æ®çš„åŠ æƒå¹³å‡å€¼
CREATE OR REPLACE FUNCTION calculate_weighted_avg(
    sensor_id_param INT,
    time_window INTERVAL DEFAULT INTERVAL '1 hour'
) RETURNS TABLE (
    sensor_id INT,
    weighted_avg NUMERIC,
    avg_confidence NUMERIC,
    min_confidence NUMERIC,
    max_confidence NUMERIC,
    reading_count BIGINT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        iot_sensor_data.sensor_id,
        SUM(iot_sensor_data.value * iot_sensor_data.probability) /
        NULLIF(SUM(iot_sensor_data.probability), 0) AS weighted_avg,
        AVG(iot_sensor_data.probability) AS avg_confidence,
        MIN(iot_sensor_data.probability) AS min_confidence,
        MAX(iot_sensor_data.probability) AS max_confidence,
        COUNT(*) AS reading_count
    FROM iot_sensor_data
    WHERE iot_sensor_data.sensor_id = sensor_id_param
      AND iot_sensor_data.timestamp > NOW() - time_window
    GROUP BY iot_sensor_data.sensor_id;
END;
$$ LANGUAGE plpgsql;
```

#### **5.1.4 æŸ¥è¯¢å’Œåˆ†æ**

**æ¦‚ç‡æŸ¥è¯¢ï¼šè®¡ç®—åŠ æƒå¹³å‡**ï¼š

```sql
-- æ¦‚ç‡æŸ¥è¯¢ï¼šè®¡ç®—åŠ æƒå¹³å‡ï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œæ€§èƒ½æµ‹è¯•ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'iot_sensor_data') THEN
            RAISE WARNING 'è¡¨ iot_sensor_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡ŒæŸ¥è¯¢';
            RETURN;
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'æ£€æŸ¥å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT
    sensor_id,
    sensor_type,
    SUM(value * probability) / SUM(probability) AS weighted_avg,
    AVG(probability) AS avg_confidence,
    MIN(probability) AS min_confidence,
    COUNT(*) AS reading_count
FROM iot_sensor_data
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY sensor_id, sensor_type;
```

**é«˜å¯ä¿¡åº¦æ•°æ®æŸ¥è¯¢**ï¼š

```sql
-- æŸ¥è¯¢é«˜å¯ä¿¡åº¦æ•°æ®ï¼ˆæ¦‚ç‡>0.9ï¼‰
SELECT
    sensor_id,
    sensor_type,
    value,
    probability,
    timestamp,
    location
FROM iot_sensor_data
WHERE probability > 0.9
ORDER BY timestamp DESC, probability DESC;
```

**æ•°æ®è´¨é‡è¯„ä¼°**ï¼š

```sql
-- è¯„ä¼°ä¼ æ„Ÿå™¨æ•°æ®è´¨é‡
SELECT
    sensor_id,
    sensor_type,
    COUNT(*) AS total_readings,
    COUNT(*) FILTER (WHERE probability > 0.9) AS high_quality_count,
    COUNT(*) FILTER (WHERE probability BETWEEN 0.7 AND 0.9) AS medium_quality_count,
    COUNT(*) FILTER (WHERE probability < 0.7) AS low_quality_count,
    AVG(probability) AS avg_quality_score,
    STDDEV(probability) AS quality_variance
FROM iot_sensor_data
WHERE timestamp > NOW() - INTERVAL '24 hours'
GROUP BY sensor_id, sensor_type
ORDER BY avg_quality_score DESC;
```

#### **5.1.5 ä½¿ç”¨ç¤ºä¾‹**

**Pythonå®¢æˆ·ç«¯ä½¿ç”¨**ï¼š

```python
from probabilistic_client import ProbabilisticDBClient, ProbabilityValue

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = ProbabilisticDBClient(
    "host=localhost dbname=iot_db user=postgres password=secret"
)

# æ’å…¥ä¼ æ„Ÿå™¨æ•°æ®
client.insert_probabilistic_data('iot_sensor_data', {
    'sensor_id': 1,
    'sensor_type': 'temperature',
    'value': 25.5,
    'probability': 0.95,
    'unit': 'Celsius',
    'location': 'Building A Floor 1'
})

# æŸ¥è¯¢é«˜å¯ä¿¡åº¦æ•°æ®
results = client.query_with_confidence("""
    SELECT * FROM iot_sensor_data
    WHERE sensor_type = 'temperature'
    AND timestamp > NOW() - INTERVAL '1 hour'
""", min_confidence=0.9)

# æ¦‚ç‡èšåˆ
stats = client.aggregate_probabilistic(
    'iot_sensor_data',
    'value',
    filters={'sensor_type': 'temperature'}
)
```

### 5.2 æ•°æ®èåˆåœºæ™¯

#### **5.2.1 ä¸šåŠ¡åœºæ™¯**

**åœºæ™¯æè¿°**ï¼š
ä¼ä¸šéœ€è¦æ•´åˆæ¥è‡ªå¤šä¸ªæ•°æ®æºçš„ä¿¡æ¯ï¼ˆå¦‚å®¢æˆ·ä¿¡æ¯ã€è®¢å•æ•°æ®ã€åº“å­˜æ•°æ®ï¼‰ï¼Œä¸åŒæ•°æ®æºçš„æ•°æ®å¯èƒ½å­˜åœ¨ä¸ä¸€è‡´æ€§ï¼Œéœ€è¦åŸºäºæ•°æ®æºçš„å¯ä¿¡åº¦è¿›è¡Œèåˆã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

1. æ•´åˆå¤šæºæ•°æ®
2. å¤„ç†æ•°æ®ä¸ä¸€è‡´æ€§
3. åŸºäºæ•°æ®æºå¯ä¿¡åº¦è¿›è¡Œæ•°æ®èåˆ
4. è¿½è¸ªæ•°æ®æ¥æº

**æŒ‘æˆ˜**ï¼š

- å¤šæºæ•°æ®ä¸ä¸€è‡´
- æ•°æ®æºå¯ä¿¡åº¦ä¸åŒ
- æ•°æ®å†²çªè§£å†³
- æ•°æ®è´¨é‡è¯„ä¼°

#### **5.2.2 æ•°æ®æ¨¡å‹è®¾è®¡**

**å¤šæºæ•°æ®è¡¨ç»“æ„**ï¼š

```sql
-- æ•°æ®æºA
CREATE TABLE IF NOT EXISTS source_table_a (
    id SERIAL PRIMARY KEY,
    customer_id INT,
    customer_name VARCHAR(100),
    email VARCHAR(100),
    phone VARCHAR(20),
    source_confidence NUMERIC DEFAULT 0.8,  -- æ•°æ®æºAçš„å¯ä¿¡åº¦
    last_updated TIMESTAMP DEFAULT NOW()
) WITH PROVENANCE;

-- æ•°æ®æºB
CREATE TABLE IF NOT EXISTS source_table_b (
    id SERIAL PRIMARY KEY,
    customer_id INT,
    customer_name VARCHAR(100),
    email VARCHAR(100),
    phone VARCHAR(20),
    source_confidence NUMERIC DEFAULT 0.7,  -- æ•°æ®æºBçš„å¯ä¿¡åº¦
    last_updated TIMESTAMP DEFAULT NOW()
) WITH PROVENANCE;

-- èåˆåçš„æ•°æ®è¡¨
CREATE TABLE IF NOT EXISTS merged_customer_data (
    id SERIAL PRIMARY KEY,
    customer_id INT UNIQUE,
    customer_name VARCHAR(100),
    email VARCHAR(100),
    phone VARCHAR(20),
    fused_confidence NUMERIC,  -- èåˆåçš„å¯ä¿¡åº¦
    source_a_confidence NUMERIC,
    source_b_confidence NUMERIC,
    fusion_method VARCHAR(50),  -- èåˆæ–¹æ³•ï¼šmax, weighted_avg, etc.
    last_updated TIMESTAMP DEFAULT NOW()
) WITH PROVENANCE;
```

#### **5.2.3 æ•°æ®èåˆå®ç°**

**åŸºç¡€èåˆæ–¹æ¡ˆ**ï¼š

```sql
-- å¤šæºæ•°æ®èåˆ
WITH source_a AS (
    SELECT
        customer_id,
        customer_name,
        email,
        phone,
        source_confidence AS probability
    FROM source_table_a
),
source_b AS (
    SELECT
        customer_id,
        customer_name,
        email,
        phone,
        source_confidence AS probability
    FROM source_table_b
),
merged AS (
    SELECT
        COALESCE(a.customer_id, b.customer_id) AS customer_id,
        COALESCE(a.customer_name, b.customer_name) AS customer_name,
        COALESCE(a.email, b.email) AS email,
        COALESCE(a.phone, b.phone) AS phone,
        GREATEST(COALESCE(a.probability, 0), COALESCE(b.probability, 0)) AS probability,
        a.probability AS source_a_prob,
        b.probability AS source_b_prob
    FROM source_a a
    FULL OUTER JOIN source_b b ON a.customer_id = b.customer_id
)
SELECT * FROM merged
WHERE probability > 0.75;
```

**åŠ æƒèåˆæ–¹æ¡ˆ**ï¼š

```sql
-- åŠ æƒèåˆï¼ˆè€ƒè™‘æ•°æ®æºå¯ä¿¡åº¦ï¼‰
CREATE OR REPLACE FUNCTION fuse_customer_data()
RETURNS TABLE (
    customer_id INT,
    customer_name VARCHAR,
    email VARCHAR,
    phone VARCHAR,
    fused_confidence NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    WITH source_a AS (
        SELECT customer_id, customer_name, email, phone, source_confidence
        FROM source_table_a
    ),
    source_b AS (
        SELECT customer_id, customer_name, email, phone, source_confidence
        FROM source_table_b
    ),
    fused AS (
        SELECT
            COALESCE(a.customer_id, b.customer_id) AS customer_id,
            COALESCE(a.customer_name, b.customer_name) AS customer_name,
            COALESCE(a.email, b.email) AS email,
            COALESCE(a.phone, b.phone) AS phone,
            -- åŠ æƒå¹³å‡å¯ä¿¡åº¦
            CASE
                WHEN a.source_confidence IS NOT NULL AND b.source_confidence IS NOT NULL THEN
                    (a.source_confidence + b.source_confidence) / 2
                WHEN a.source_confidence IS NOT NULL THEN
                    a.source_confidence
                ELSE
                    b.source_confidence
            END AS fused_confidence
        FROM source_a a
        FULL OUTER JOIN source_b b ON a.customer_id = b.customer_id
    )
    SELECT * FROM fused
    WHERE fused_confidence > 0.7
    ORDER BY fused_confidence DESC;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨èåˆå‡½æ•°
SELECT * FROM fuse_customer_data();
```

**å†²çªè§£å†³ç­–ç•¥**ï¼š

```sql
-- å†²çªè§£å†³ï¼šé€‰æ‹©é«˜å¯ä¿¡åº¦æ•°æ®æº
CREATE OR REPLACE FUNCTION resolve_conflicts()
RETURNS VOID AS $$
BEGIN
    INSERT INTO merged_customer_data (
        customer_id, customer_name, email, phone,
        fused_confidence, source_a_confidence, source_b_confidence, fusion_method
    )
    SELECT
        COALESCE(a.customer_id, b.customer_id),
        CASE
            WHEN a.source_confidence > b.source_confidence THEN a.customer_name
            WHEN b.source_confidence > a.source_confidence THEN b.customer_name
            ELSE COALESCE(a.customer_name, b.customer_name)
        END,
        CASE
            WHEN a.source_confidence > b.source_confidence THEN a.email
            WHEN b.source_confidence > a.source_confidence THEN b.email
            ELSE COALESCE(a.email, b.email)
        END,
        CASE
            WHEN a.source_confidence > b.source_confidence THEN a.phone
            WHEN b.source_confidence > a.source_confidence THEN b.phone
            ELSE COALESCE(a.phone, b.phone)
        END,
        GREATEST(COALESCE(a.source_confidence, 0), COALESCE(b.source_confidence, 0)),
        a.source_confidence,
        b.source_confidence,
        'max_confidence'
    FROM source_table_a a
    FULL OUTER JOIN source_table_b b ON a.customer_id = b.customer_id
    ON CONFLICT (customer_id) DO UPDATE SET
        customer_name = EXCLUDED.customer_name,
        email = EXCLUDED.email,
        phone = EXCLUDED.phone,
        fused_confidence = EXCLUDED.fused_confidence,
        last_updated = NOW();
END;
$$ LANGUAGE plpgsql;
```

#### **5.2.4 æ•°æ®è´¨é‡è¯„ä¼°**

**èåˆæ•°æ®è´¨é‡è¯„ä¼°**ï¼š

```sql
-- è¯„ä¼°èåˆæ•°æ®è´¨é‡
SELECT
    COUNT(*) AS total_customers,
    COUNT(*) FILTER (WHERE fused_confidence > 0.9) AS high_quality_count,
    COUNT(*) FILTER (WHERE fused_confidence BETWEEN 0.7 AND 0.9) AS medium_quality_count,
    COUNT(*) FILTER (WHERE fused_confidence < 0.7) AS low_quality_count,
    AVG(fused_confidence) AS avg_confidence,
    AVG(source_a_confidence) AS avg_source_a_confidence,
    AVG(source_b_confidence) AS avg_source_b_confidence
FROM merged_customer_data;
```

### 5.3 å…¶ä»–åº”ç”¨åœºæ™¯

#### **5.3.1 æ•°æ®è´¨é‡è¯„ä¼°**

**ä¸šåŠ¡åœºæ™¯**ï¼š
ä¼ä¸šéœ€è¦è¯„ä¼°æ•°æ®è´¨é‡ï¼Œè¯†åˆ«å’Œå¤„ç†ä½è´¨é‡æ•°æ®ï¼Œç¡®ä¿æ•°æ®é©±åŠ¨çš„å†³ç­–åŸºäºé«˜è´¨é‡æ•°æ®ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

1. è¯„ä¼°æ•°æ®æºçš„æ•°æ®è´¨é‡
2. è¯†åˆ«ä½è´¨é‡æ•°æ®
3. ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
4. æ”¯æŒæ•°æ®è´¨é‡æ”¹è¿›å†³ç­–

**å®ç°æ–¹æ¡ˆ**ï¼š

```sql
-- åˆ›å»ºæ•°æ®è´¨é‡è¯„ä¼°è¡¨
CREATE TABLE IF NOT EXISTS data_quality_report (
    data_source VARCHAR(100),
    assessment_date TIMESTAMP DEFAULT NOW(),
    total_records BIGINT,
    avg_quality_score NUMERIC,
    high_quality_count BIGINT,
    medium_quality_count BIGINT,
    low_quality_count BIGINT,
    quality_trend VARCHAR(20)  -- 'improving', 'stable', 'degrading'
) WITH PROVENANCE;

-- æ•°æ®è´¨é‡è¯„ä¼°æŸ¥è¯¢
CREATE OR REPLACE FUNCTION assess_data_quality(
    source_name VARCHAR DEFAULT NULL
) RETURNS TABLE (
    data_source VARCHAR,
    total_records BIGINT,
    avg_quality NUMERIC,
    high_quality_count BIGINT,
    medium_quality_count BIGINT,
    low_quality_count BIGINT,
    quality_score NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        uncertain_data.data_source,
        COUNT(*) AS total_records,
        AVG(uncertain_data.probability) AS avg_quality,
        COUNT(*) FILTER (WHERE uncertain_data.probability >= 0.9) AS high_quality_count,
        COUNT(*) FILTER (WHERE uncertain_data.probability >= 0.7 AND uncertain_data.probability < 0.9) AS medium_quality_count,
        COUNT(*) FILTER (WHERE uncertain_data.probability < 0.7) AS low_quality_count,
        -- è´¨é‡è¯„åˆ†ï¼šé«˜è´¨é‡æ•°æ®æƒé‡æ›´é«˜
        (COUNT(*) FILTER (WHERE uncertain_data.probability >= 0.9) * 1.0 +
         COUNT(*) FILTER (WHERE uncertain_data.probability >= 0.7 AND uncertain_data.probability < 0.9) * 0.5 +
         COUNT(*) FILTER (WHERE uncertain_data.probability < 0.7) * 0.1) / COUNT(*) AS quality_score
    FROM uncertain_data
    WHERE (source_name IS NULL OR uncertain_data.data_source = source_name)
    GROUP BY uncertain_data.data_source
    ORDER BY quality_score DESC;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨æ•°æ®è´¨é‡è¯„ä¼°å‡½æ•°
SELECT * FROM assess_data_quality();

-- ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
INSERT INTO data_quality_report (
    data_source, total_records, avg_quality_score,
    high_quality_count, medium_quality_count, low_quality_count
)
SELECT
    data_source,
    total_records,
    avg_quality,
    high_quality_count,
    medium_quality_count,
    low_quality_count
FROM assess_data_quality();
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# Pythonå®¢æˆ·ç«¯ä½¿ç”¨
from probabilistic_client import ProbabilisticDBClient

client = ProbabilisticDBClient("host=localhost dbname=testdb user=postgres password=secret")

# è¯„ä¼°æ•°æ®è´¨é‡
quality_report = client.query_with_confidence("""
    SELECT * FROM assess_data_quality('sensor_data')
""", min_confidence=0.0)

for row in quality_report:
    print(f"æ•°æ®æº: {row['data_source']}")
    print(f"å¹³å‡è´¨é‡: {row['avg_quality']:.2%}")
    print(f"é«˜è´¨é‡æ•°æ®: {row['high_quality_count']}æ¡")
    print(f"ä½è´¨é‡æ•°æ®: {row['low_quality_count']}æ¡")
```

#### **5.3.2 å¼‚å¸¸æ£€æµ‹**

**ä¸šåŠ¡åœºæ™¯**ï¼š
ç³»ç»Ÿéœ€è¦è¯†åˆ«å¼‚å¸¸æ•°æ®ï¼Œè¿™äº›æ•°æ®å¯èƒ½è¡¨ç¤ºè®¾å¤‡æ•…éšœã€æ•°æ®é”™è¯¯æˆ–å®‰å…¨å¨èƒã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

1. è¯†åˆ«ä½æ¦‚ç‡æ•°æ®ï¼ˆå¯èƒ½æ˜¯å¼‚å¸¸ï¼‰
2. è¿½è¸ªå¼‚å¸¸æ•°æ®çš„æ¥æº
3. ç”Ÿæˆå¼‚å¸¸æŠ¥å‘Š
4. æ”¯æŒå¼‚å¸¸å¤„ç†å†³ç­–

**å®ç°æ–¹æ¡ˆ**ï¼š

```sql
-- åˆ›å»ºå¼‚å¸¸æ£€æµ‹è¡¨
CREATE TABLE IF NOT EXISTS anomaly_detection (
    id SERIAL PRIMARY KEY,
    data_id INT,
    anomaly_type VARCHAR(50),  -- 'low_probability', 'outlier', 'inconsistency'
    probability NUMERIC,
    severity VARCHAR(20),  -- 'low', 'medium', 'high', 'critical'
    detected_at TIMESTAMP DEFAULT NOW(),
    provenance JSONB
) WITH PROVENANCE;

-- å¼‚å¸¸æ£€æµ‹å‡½æ•°
CREATE OR REPLACE FUNCTION detect_anomalies(
    probability_threshold NUMERIC DEFAULT 0.3,
    limit_count INT DEFAULT 100
) RETURNS TABLE (
    id INT,
    value NUMERIC,
    probability NUMERIC,
    timestamp TIMESTAMP,
    provenance JSONB,
    anomaly_score NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        uncertain_data.id,
        uncertain_data.value,
        uncertain_data.probability,
        uncertain_data.timestamp,
        provsql_provenance_of(
            SELECT * FROM uncertain_data WHERE uncertain_data.id = uncertain_data.id
        )::JSONB AS provenance,
        -- å¼‚å¸¸è¯„åˆ†ï¼šæ¦‚ç‡è¶Šä½ï¼Œè¯„åˆ†è¶Šé«˜
        (1 - uncertain_data.probability) * 100 AS anomaly_score
    FROM uncertain_data
    WHERE uncertain_data.probability < probability_threshold
    ORDER BY uncertain_data.probability ASC
    LIMIT limit_count;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨å¼‚å¸¸æ£€æµ‹å‡½æ•°
SELECT * FROM detect_anomalies(0.3, 100);

-- è‡ªåŠ¨å¼‚å¸¸æ£€æµ‹å’Œè®°å½•
CREATE OR REPLACE FUNCTION auto_detect_and_record_anomalies()
RETURNS VOID AS $$
DECLARE
    anomaly_record RECORD;
BEGIN
    FOR anomaly_record IN
        SELECT * FROM detect_anomalies(0.3, 1000)
    LOOP
        INSERT INTO anomaly_detection (
            data_id, anomaly_type, probability, severity, provenance
        )
        VALUES (
            anomaly_record.id,
            'low_probability',
            anomaly_record.probability,
            CASE
                WHEN anomaly_record.probability < 0.1 THEN 'critical'
                WHEN anomaly_record.probability < 0.2 THEN 'high'
                WHEN anomaly_record.probability < 0.3 THEN 'medium'
                ELSE 'low'
            END,
            anomaly_record.provenance
        )
        ON CONFLICT DO NOTHING;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# Pythonå®¢æˆ·ç«¯ä½¿ç”¨
client = ProbabilisticDBClient("host=localhost dbname=testdb user=postgres password=secret")

# æ£€æµ‹å¼‚å¸¸
anomalies = client.query_with_confidence("""
    SELECT * FROM detect_anomalies(0.3, 100)
""", min_confidence=0.0)

print(f"æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸æ•°æ®")
for anomaly in anomalies:
    print(f"ID: {anomaly['id']}, æ¦‚ç‡: {anomaly['probability']:.2%}, å¼‚å¸¸è¯„åˆ†: {anomaly['anomaly_score']:.2f}")
```

#### **5.3.3 æ•°æ®æº¯æºå®¡è®¡**

**ä¸šåŠ¡åœºæ™¯**ï¼š
ä¼ä¸šéœ€è¦è¿½è¸ªæ•°æ®çš„æ¥æºå’Œå¤„ç†è¿‡ç¨‹ï¼Œæ»¡è¶³åˆè§„è¦æ±‚å’Œæ•°æ®æ²»ç†éœ€æ±‚ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

1. è¿½è¸ªæ•°æ®æ¥æº
2. è®°å½•æ•°æ®å¤„ç†è¿‡ç¨‹
3. ç”Ÿæˆå®¡è®¡æŠ¥å‘Š
4. æ”¯æŒåˆè§„æ£€æŸ¥

**å®ç°æ–¹æ¡ˆ**ï¼š

```sql
-- åˆ›å»ºå®¡è®¡æ—¥å¿—è¡¨
CREATE TABLE IF NOT EXISTS audit_log (
    id SERIAL PRIMARY KEY,
    data_id INT,
    operation_type VARCHAR(50),  -- 'insert', 'update', 'delete', 'query'
    operation_time TIMESTAMP DEFAULT NOW(),
    user_name VARCHAR(100),
    provenance JSONB,
    probability_before NUMERIC,
    probability_after NUMERIC
) WITH PROVENANCE;

-- æ•°æ®æº¯æºæŸ¥è¯¢å‡½æ•°
CREATE OR REPLACE FUNCTION get_data_provenance(
    target_id INT
) RETURNS TABLE (
    id INT,
    value NUMERIC,
    probability NUMERIC,
    provenance JSONB,
    source_info JSONB
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        uncertain_data.id,
        uncertain_data.value,
        uncertain_data.probability,
        provsql_provenance_of(
            SELECT * FROM uncertain_data WHERE uncertain_data.id = target_id
        )::JSONB AS provenance,
        -- æå–æ¥æºä¿¡æ¯
        jsonb_build_object(
            'data_source', uncertain_data.data_source,
            'created_at', uncertain_data.created_at,
            'updated_at', uncertain_data.updated_at
        ) AS source_info
    FROM uncertain_data
    WHERE uncertain_data.id = target_id;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨æ•°æ®æº¯æºæŸ¥è¯¢
SELECT * FROM get_data_provenance(123);

-- ç”Ÿæˆå®¡è®¡æŠ¥å‘Š
CREATE OR REPLACE FUNCTION generate_audit_report(
    start_date TIMESTAMP DEFAULT NOW() - INTERVAL '30 days',
    end_date TIMESTAMP DEFAULT NOW()
) RETURNS TABLE (
    data_source VARCHAR,
    operation_count BIGINT,
    avg_probability NUMERIC,
    provenance_depth INT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        uncertain_data.data_source,
        COUNT(*) AS operation_count,
        AVG(uncertain_data.probability) AS avg_probability,
        -- è®¡ç®—æº¯æºæ·±åº¦ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
        AVG(jsonb_array_length(
            provsql_provenance_of(
                SELECT * FROM uncertain_data WHERE uncertain_data.id = uncertain_data.id
            )::JSONB -> 'path'
        ))::INT AS provenance_depth
    FROM uncertain_data
    WHERE uncertain_data.created_at BETWEEN start_date AND end_date
    GROUP BY uncertain_data.data_source
    ORDER BY operation_count DESC;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨å®¡è®¡æŠ¥å‘Šå‡½æ•°
SELECT * FROM generate_audit_report();
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# Pythonå®¢æˆ·ç«¯ä½¿ç”¨
client = ProbabilisticDBClient("host=localhost dbname=testdb user=postgres password=secret")

# æŸ¥è¯¢æ•°æ®æº¯æº
provenance = client.query_with_confidence("""
    SELECT * FROM get_data_provenance(123)
""", min_confidence=0.0)

if provenance:
    print(f"æ•°æ®ID: {provenance[0]['id']}")
    print(f"æ¦‚ç‡å€¼: {provenance[0]['probability']}")
    print(f"æº¯æºä¿¡æ¯: {provenance[0]['provenance']}")

# ç”Ÿæˆå®¡è®¡æŠ¥å‘Š
audit_report = client.query_with_confidence("""
    SELECT * FROM generate_audit_report()
""", min_confidence=0.0)

for row in audit_report:
    print(f"æ•°æ®æº: {row['data_source']}")
    print(f"æ“ä½œæ¬¡æ•°: {row['operation_count']}")
    print(f"å¹³å‡æ¦‚ç‡: {row['avg_probability']:.2%}")
```

---

## 6. æ€§èƒ½åˆ†æ

### 6.1 æŸ¥è¯¢æ€§èƒ½å½±å“

#### **6.1.1 æ€§èƒ½å½±å“å› ç´ **

1. **æ¦‚ç‡è®¡ç®—å¼€é”€**
   - æ¦‚ç‡æŸ¥è¯¢éœ€è¦é¢å¤–çš„è®¡ç®—
   - å¯èƒ½ä¸–ç•Œæšä¸¾çš„å¤æ‚åº¦ï¼šO(2^n)ï¼Œnä¸ºä¸ç¡®å®šæ€§å…ƒç»„æ•°
   - æ¦‚ç‡å€¼è®¡ç®—å’Œå½’ä¸€åŒ–å¼€é”€
   - æº¯æºä¿¡æ¯å¤„ç†å¼€é”€

2. **å­˜å‚¨å¼€é”€**
   - æ¦‚ç‡å€¼çš„å­˜å‚¨ï¼šæ¯ä¸ªå…ƒç»„å¢åŠ 8-16å­—èŠ‚
   - æº¯æºä¿¡æ¯çš„å­˜å‚¨ï¼šæ¯ä¸ªå…ƒç»„å¢åŠ çº¦100-500å­—èŠ‚
   - ç´¢å¼•å¼€é”€ï¼šæ¦‚ç‡å€¼ç´¢å¼•çš„å­˜å‚¨

3. **æŸ¥è¯¢ä¼˜åŒ–**
   - æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–å™¨çš„å¤æ‚åº¦
   - ç´¢å¼•å¯¹æ¦‚ç‡æŸ¥è¯¢çš„æ”¯æŒ
   - æŸ¥è¯¢è®¡åˆ’é€‰æ‹©çš„å¤æ‚æ€§

#### **6.1.2 æ€§èƒ½æµ‹è¯•æ•°æ®**

**åŸºç¡€æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”**ï¼š

| æ“ä½œç±»å‹ | ä¼ ç»ŸæŸ¥è¯¢ | æ¦‚ç‡æŸ¥è¯¢ | æ€§èƒ½å½±å“ | æ•°æ®é‡ |
|---------|---------|---------|---------|--------|
| **SELECT** | 10ms | 15ms | +50% | 10Kè¡Œ |
| **SELECT** | 100ms | 180ms | +80% | 100Kè¡Œ |
| **JOIN** | 50ms | 80ms | +60% | 10Kè¡Œ |
| **JOIN** | 500ms | 900ms | +80% | 100Kè¡Œ |
| **AGGREGATE** | 30ms | 45ms | +50% | 10Kè¡Œ |
| **AGGREGATE** | 300ms | 550ms | +83% | 100Kè¡Œ |

**æ¦‚ç‡é˜ˆå€¼å¯¹æ€§èƒ½çš„å½±å“**ï¼š

| æ¦‚ç‡é˜ˆå€¼ | æŸ¥è¯¢æ—¶é—´ | è¿”å›è¡Œæ•° | æ€§èƒ½æ¯” |
|---------|---------|---------|--------|
| 0.5 | 180ms | 50K | 1.0x |
| 0.7 | 120ms | 30K | 0.67x |
| 0.9 | 80ms | 10K | 0.44x |

**ç´¢å¼•å¯¹æ€§èƒ½çš„å½±å“**ï¼š

| ç´¢å¼•ç±»å‹ | æ— ç´¢å¼• | æœ‰ç´¢å¼• | æ€§èƒ½æå‡ |
|---------|--------|--------|---------|
| **æ¦‚ç‡å€¼ç´¢å¼•** | 180ms | 50ms | 3.6x |
| **å¤åˆç´¢å¼•** | 180ms | 30ms | 6.0x |

#### **6.1.3 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**

1. **ç´¢å¼•ä¼˜åŒ–**

   ```sql
   -- ä¸ºæ¦‚ç‡å€¼åˆ›å»ºB-treeç´¢å¼•
   CREATE INDEX idx_probability ON sensor_data(probability);

   -- ä¸ºæ¦‚ç‡æŸ¥è¯¢åˆ›å»ºå¤åˆç´¢å¼•
   CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);

   -- ä¸ºæ¦‚ç‡èŒƒå›´æŸ¥è¯¢åˆ›å»ºGINç´¢å¼•
   CREATE INDEX idx_prob_range ON sensor_data USING GIN(probability_range);
   ```

2. **æŸ¥è¯¢ä¼˜åŒ–**

   ```sql
   -- ä½¿ç”¨æ¦‚ç‡é˜ˆå€¼è¿‡æ»¤ï¼Œå‡å°‘è®¡ç®—é‡
   SELECT * FROM sensor_data
   WHERE probability > 0.8  -- æå‰è¿‡æ»¤
   ORDER BY probability DESC
   LIMIT 100;

   -- ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—æ¦‚ç‡
   CREATE MATERIALIZED VIEW mv_prob_stats AS
   SELECT sensor_id, AVG(probability) AS avg_prob
   FROM sensor_data
   GROUP BY sensor_id;
   ```

3. **æ‰¹é‡å¤„ç†**

   ```sql
   -- æ‰¹é‡æ’å…¥æ¦‚ç‡æ•°æ®
   INSERT INTO sensor_data (sensor_id, value, probability)
   SELECT * FROM unnest(
       ARRAY[1, 2, 3],
       ARRAY[25.3, 26.1, 24.8],
       ARRAY[0.9, 0.85, 0.95]
   );
   ```

### 6.2 å­˜å‚¨å¼€é”€åˆ†æ

#### **6.2.1 å­˜å‚¨å¼€é”€è¯¦ç»†åˆ†æ**

**åŸºç¡€å­˜å‚¨å¼€é”€**ï¼š

| æ•°æ®ç±»å‹ | åŸºç¡€å¤§å° | æ¦‚ç‡å€¼å¼€é”€ | æº¯æºä¿¡æ¯å¼€é”€ | æ€»å¼€é”€ |
|---------|---------|-----------|-------------|--------|
| **INTEGER** | 4å­—èŠ‚ | +8å­—èŠ‚ | +100-500å­—èŠ‚ | +108-512å­—èŠ‚ |
| **NUMERIC** | å˜é•¿ | +8å­—èŠ‚ | +100-500å­—èŠ‚ | +108-508å­—èŠ‚ |
| **TEXT** | å˜é•¿ | +8å­—èŠ‚ | +100-500å­—èŠ‚ | +108-508å­—èŠ‚ |
| **JSONB** | å˜é•¿ | +8å­—èŠ‚ | +100-500å­—èŠ‚ | +108-508å­—èŠ‚ |

**æ¦‚ç‡å€¼å­˜å‚¨**ï¼š

- **NUMERICç±»å‹**ï¼š8å­—èŠ‚ï¼ˆå›ºå®šç²¾åº¦ï¼‰
- **DOUBLE PRECISION**ï¼š8å­—èŠ‚ï¼ˆæµ®ç‚¹ï¼‰
- **REAL**ï¼š4å­—èŠ‚ï¼ˆå•ç²¾åº¦æµ®ç‚¹ï¼‰
- **è‡ªå®šä¹‰ç±»å‹**ï¼š8-16å­—èŠ‚ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰

**æº¯æºä¿¡æ¯å­˜å‚¨**ï¼š

- **åŸºç¡€æº¯æº**ï¼šçº¦100å­—èŠ‚ï¼ˆæ¥æºIDã€æ—¶é—´æˆ³ï¼‰
- **è¯¦ç»†æº¯æº**ï¼šçº¦300-500å­—èŠ‚ï¼ˆå®Œæ•´æº¯æºé“¾ï¼‰
- **å‹ç¼©æº¯æº**ï¼šçº¦50-100å­—èŠ‚ï¼ˆå‹ç¼©å­˜å‚¨ï¼‰

#### **6.2.2 å­˜å‚¨ä¼˜åŒ–ç­–ç•¥**

1. **æ•°æ®ç±»å‹é€‰æ‹©**

   ```sql
   -- ä½¿ç”¨REALä»£æ›¿NUMERICèŠ‚çœç©ºé—´ï¼ˆå¦‚æœç²¾åº¦è¦æ±‚ä¸é«˜ï¼‰
   CREATE TABLE sensor_data (
       id SERIAL PRIMARY KEY,
       value REAL,
       probability REAL  -- 4å­—èŠ‚è€Œä¸æ˜¯8å­—èŠ‚
   );
   ```

2. **åˆ†åŒºç­–ç•¥**

   ```sql
   -- æŒ‰æ¦‚ç‡å€¼èŒƒå›´åˆ†åŒº
   CREATE TABLE sensor_data (
       id SERIAL,
       value NUMERIC,
       probability NUMERIC
   ) PARTITION BY RANGE (probability);

   CREATE TABLE sensor_data_high PARTITION OF sensor_data
       FOR VALUES FROM (0.8) TO (1.0);
   CREATE TABLE sensor_data_medium PARTITION OF sensor_data
       FOR VALUES FROM (0.5) TO (0.8);
   CREATE TABLE sensor_data_low PARTITION OF sensor_data
       FOR VALUES FROM (0.0) TO (0.5);
   ```

3. **å‹ç¼©æŠ€æœ¯**

   ```sql
   -- ä½¿ç”¨TOASTå‹ç¼©å¤§æ–‡æœ¬å­—æ®µ
   ALTER TABLE sensor_data
       ALTER COLUMN provenance_data SET STORAGE EXTENDED;

   -- å½’æ¡£ä½æ¦‚ç‡æ•°æ®
   CREATE TABLE sensor_data_archive (
       LIKE sensor_data INCLUDING ALL
   );
   ```

### 6.3 æ€§èƒ½åŸºå‡†æµ‹è¯•

#### **6.3.1 åŸºå‡†æµ‹è¯•è„šæœ¬**

```sql
-- æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
DO $$
DECLARE
    start_time TIMESTAMP;
    end_time TIMESTAMP;
    duration INTERVAL;
    test_size INTEGER := 100000;
BEGIN
    -- åˆ›å»ºæµ‹è¯•è¡¨
    CREATE TABLE IF NOT EXISTS perf_test (
        id SERIAL PRIMARY KEY,
        value NUMERIC,
        probability NUMERIC CHECK (probability >= 0 AND probability <= 1)
    );

    -- æ’å…¥æµ‹è¯•æ•°æ®
    INSERT INTO perf_test (value, probability)
    SELECT
        random() * 100,
        random()
    FROM generate_series(1, test_size);

    -- æµ‹è¯•1ï¼šåŸºç¡€SELECTæŸ¥è¯¢
    start_time := clock_timestamp();
    PERFORM * FROM perf_test WHERE probability > 0.5;
    end_time := clock_timestamp();
    duration := end_time - start_time;
    RAISE NOTICE 'åŸºç¡€SELECTæŸ¥è¯¢è€—æ—¶: %', duration;

    -- æµ‹è¯•2ï¼šæ¦‚ç‡èšåˆæŸ¥è¯¢
    start_time := clock_timestamp();
    PERFORM
        AVG(value * probability) / AVG(probability) AS weighted_avg
    FROM perf_test;
    end_time := clock_timestamp();
    duration := end_time - start_time;
    RAISE NOTICE 'æ¦‚ç‡èšåˆæŸ¥è¯¢è€—æ—¶: %', duration;

    -- æµ‹è¯•3ï¼šæ¦‚ç‡JOINæŸ¥è¯¢
    CREATE TABLE IF NOT EXISTS perf_test_b (
        LIKE perf_test INCLUDING ALL
    );
    INSERT INTO perf_test_b (value, probability)
    SELECT
        random() * 100,
        random()
    FROM generate_series(1, test_size);

    start_time := clock_timestamp();
    PERFORM *
    FROM perf_test a
    JOIN perf_test_b b ON a.id = b.id
    WHERE a.probability > 0.7 AND b.probability > 0.7;
    end_time := clock_timestamp();
    duration := end_time - start_time;
    RAISE NOTICE 'æ¦‚ç‡JOINæŸ¥è¯¢è€—æ—¶: %', duration;

    -- æ¸…ç†
    DROP TABLE IF EXISTS perf_test;
    DROP TABLE IF EXISTS perf_test_b;
END $$;
```

#### **6.3.2 æ€§èƒ½ç›‘æ§æŒ‡æ ‡**

```sql
-- åˆ›å»ºæ€§èƒ½ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW probabilistic_performance_stats AS
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
    pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) AS indexes_size,
    (SELECT COUNT(*) FROM pg_stat_user_tables WHERE relname = tablename) AS row_count
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡
SELECT * FROM probabilistic_performance_stats;
```

### 6.4 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### **6.4.1 æŸ¥è¯¢ä¼˜åŒ–å»ºè®®**

1. **ä½¿ç”¨æ¦‚ç‡é˜ˆå€¼æå‰è¿‡æ»¤**
   - åœ¨WHEREå­å¥ä¸­ä½¿ç”¨æ¦‚ç‡é˜ˆå€¼
   - é¿å…å¤„ç†ä½æ¦‚ç‡æ•°æ®
   - ä½¿ç”¨LIMITé™åˆ¶ç»“æœé›†

2. **ä¼˜åŒ–JOINæ“ä½œ**
   - å…ˆè¿‡æ»¤å†JOIN
   - ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–JOIN
   - è€ƒè™‘ä½¿ç”¨ç‰©åŒ–è§†å›¾

3. **æ‰¹é‡å¤„ç†**
   - æ‰¹é‡æ’å…¥æ¦‚ç‡æ•°æ®
   - æ‰¹é‡æ›´æ–°æ¦‚ç‡å€¼
   - ä½¿ç”¨äº‹åŠ¡å‡å°‘å¼€é”€

#### **6.4.2 å­˜å‚¨ä¼˜åŒ–å»ºè®®**

1. **åˆç†é€‰æ‹©æ•°æ®ç±»å‹**
   - æ ¹æ®ç²¾åº¦è¦æ±‚é€‰æ‹©NUMERICæˆ–REAL
   - ä½¿ç”¨å‹ç¼©å­˜å‚¨å¤§æ–‡æœ¬å­—æ®µ
   - è€ƒè™‘ä½¿ç”¨JSONBå­˜å‚¨å¤æ‚æº¯æºä¿¡æ¯

2. **åˆ†åŒºç­–ç•¥**
   - æŒ‰æ¦‚ç‡å€¼èŒƒå›´åˆ†åŒº
   - æŒ‰æ—¶é—´åˆ†åŒº
   - æŒ‰æ•°æ®æºåˆ†åŒº

3. **å½’æ¡£ç­–ç•¥**
   - å½’æ¡£ä½æ¦‚ç‡å†å²æ•°æ®
   - å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
   - ä½¿ç”¨å¤–éƒ¨å­˜å‚¨å­˜å‚¨å½’æ¡£æ•°æ®

---

## 7. æœ€ä½³å®è·µ

### 7.1 ä½¿ç”¨åœºæ™¯

#### **7.1.1 é€‚ç”¨åœºæ™¯**

1. **ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†**
   - IoTè®¾å¤‡æ•°æ®ï¼šæ¸©åº¦ã€æ¹¿åº¦ã€å‹åŠ›ç­‰ä¼ æ„Ÿå™¨æ•°æ®
   - æµ‹é‡è¯¯å·®ï¼šå¤„ç†ä¼ æ„Ÿå™¨æµ‹é‡è¯¯å·®å’Œå™ªå£°
   - æ•°æ®è´¨é‡ï¼šè¯„ä¼°æ•°æ®è´¨é‡å’Œå¯ä¿¡åº¦
   - ç¤ºä¾‹ï¼šç¯å¢ƒç›‘æµ‹ã€æ™ºèƒ½åŸå¸‚ã€å·¥ä¸š4.0

2. **å¤šæºæ•°æ®èåˆ**
   - æ•°æ®ä¸ä¸€è‡´æ€§ï¼šå¤„ç†æ¥è‡ªä¸åŒæ•°æ®æºçš„ä¸ä¸€è‡´æ•°æ®
   - æ•°æ®å¯ä¿¡åº¦ï¼šæ ¹æ®æ•°æ®æºå¯ä¿¡åº¦è¿›è¡ŒåŠ æƒèåˆ
   - å†²çªè§£å†³ï¼šè§£å†³å¤šæºæ•°æ®çš„å†²çª
   - ç¤ºä¾‹ï¼šæ•°æ®ä»“åº“ã€æ•°æ®æ¹–ã€æ•°æ®é›†æˆ

3. **æ•°æ®æº¯æºå’Œå¯ä¿¡åº¦è¯„ä¼°**
   - æ•°æ®æ¥æºè¿½è¸ªï¼šè¿½è¸ªæ•°æ®çš„æ¥æºå’Œå¤„ç†è¿‡ç¨‹
   - å¯ä¿¡åº¦è®¡ç®—ï¼šæ ¹æ®æ•°æ®æ¥æºè®¡ç®—å¯ä¿¡åº¦
   - åˆè§„å®¡è®¡ï¼šæ»¡è¶³æ•°æ®æ²»ç†å’Œåˆè§„è¦æ±‚
   - ç¤ºä¾‹ï¼šæ•°æ®æ²»ç†ã€åˆè§„å®¡è®¡ã€æ•°æ®è´¨é‡è¯„ä¼°

4. **ç¼ºå¤±æ•°æ®å¤„ç†**
   - ä¸å®Œæ•´æ•°æ®ï¼šå¤„ç†ç¼ºå¤±æˆ–ä¸å®Œæ•´çš„æ•°æ®
   - æ¦‚ç‡æ¨æ–­ï¼šä½¿ç”¨æ¦‚ç‡æ¨¡å‹æ¨æ–­ç¼ºå¤±å€¼
   - ä¸ç¡®å®šæ€§é‡åŒ–ï¼šé‡åŒ–ç¼ºå¤±æ•°æ®çš„ä¸ç¡®å®šæ€§
   - ç¤ºä¾‹ï¼šæ•°æ®æ¸…æ´—ã€æ•°æ®è¡¥å…¨ã€ç»Ÿè®¡åˆ†æ

5. **æœºå™¨å­¦ä¹ æ•°æ®é¢„å¤„ç†**
   - ä¸ç¡®å®šæ€§ç‰¹å¾ï¼šå¤„ç†å…·æœ‰ä¸ç¡®å®šæ€§çš„ç‰¹å¾
   - å™ªå£°æ•°æ®ï¼šå¤„ç†å™ªå£°å’Œå¼‚å¸¸å€¼
   - æ•°æ®è´¨é‡ï¼šè¯„ä¼°è®­ç»ƒæ•°æ®çš„è´¨é‡
   - ç¤ºä¾‹ï¼šç‰¹å¾å·¥ç¨‹ã€æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒ

#### **7.1.2 ä¸é€‚ç”¨åœºæ™¯**

1. **ç¡®å®šæ€§æ•°æ®**
   - æ•°æ®å®Œå…¨ç¡®å®šï¼Œä¸éœ€è¦æ¦‚ç‡è¡¨ç¤º
   - ä¼ ç»Ÿå…³ç³»æ•°æ®åº“å³å¯æ»¡è¶³éœ€æ±‚
   - ç¤ºä¾‹ï¼šè´¢åŠ¡æ•°æ®ã€ç”¨æˆ·ä¿¡æ¯ã€è®¢å•æ•°æ®

2. **é«˜æ€§èƒ½è¦æ±‚åœºæ™¯**
   - å¯¹æŸ¥è¯¢æ€§èƒ½è¦æ±‚æé«˜ï¼ˆ<10msï¼‰
   - æ¦‚ç‡è®¡ç®—å¼€é”€ä¸å¯æ¥å—
   - ç¤ºä¾‹ï¼šå®æ—¶äº¤æ˜“ç³»ç»Ÿã€é«˜é¢‘æŸ¥è¯¢ç³»ç»Ÿ

3. **ç®€å•æŸ¥è¯¢åœºæ™¯**
   - ä¸éœ€è¦æ¦‚ç‡è®¡ç®—çš„ç®€å•æŸ¥è¯¢
   - ä¸éœ€è¦ä¸ç¡®å®šæ€§å¤„ç†
   - ç¤ºä¾‹ï¼šç®€å•çš„CRUDæ“ä½œã€æŠ¥è¡¨æŸ¥è¯¢

4. **èµ„æºå—é™ç¯å¢ƒ**
   - å­˜å‚¨ç©ºé—´æœ‰é™
   - è®¡ç®—èµ„æºæœ‰é™
   - ç¤ºä¾‹ï¼šåµŒå…¥å¼ç³»ç»Ÿã€è¾¹ç¼˜è®¡ç®—

### 7.2 è®¾è®¡åŸåˆ™

#### **7.2.1 æ¦‚ç‡å€¼è®¾è®¡**

1. **æ¦‚ç‡å€¼èŒƒå›´**
   - ç¡®ä¿æ¦‚ç‡å€¼åœ¨[0, 1]èŒƒå›´å†…
   - ä½¿ç”¨CHECKçº¦æŸéªŒè¯æ¦‚ç‡å€¼
   - å¤„ç†è¾¹ç•Œæƒ…å†µï¼ˆ0å’Œ1ï¼‰

2. **æ¦‚ç‡å€¼ç²¾åº¦**
   - é€‰æ‹©åˆé€‚çš„æ•°å€¼ç±»å‹ï¼ˆNUMERIC vs DOUBLE PRECISIONï¼‰
   - è€ƒè™‘ç²¾åº¦å’Œæ€§èƒ½çš„å¹³è¡¡
   - é¿å…ç²¾åº¦æŸå¤±

3. **æ¦‚ç‡å€¼å½’ä¸€åŒ–**
   - ç¡®ä¿æ¦‚ç‡åˆ†å¸ƒå½’ä¸€åŒ–
   - å¤„ç†æ¦‚ç‡å€¼ä¸ä¸€è‡´çš„æƒ…å†µ
   - ä½¿ç”¨è§¦å‘å™¨è‡ªåŠ¨å½’ä¸€åŒ–

#### **7.2.2 æ•°æ®æ¨¡å‹è®¾è®¡**

**1. è¡¨ç»“æ„è®¾è®¡**

**æ¦‚ç‡å€¼å­˜å‚¨ä½ç½®**ï¼š

```sql
-- æ–¹æ¡ˆ1ï¼šæ¦‚ç‡å€¼ä½œä¸ºç‹¬ç«‹åˆ—ï¼ˆæ¨èï¼‰
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW()
);

-- æ–¹æ¡ˆ2ï¼šæ¦‚ç‡å€¼ä½œä¸ºå¤åˆç±»å‹
CREATE TYPE probability_value AS (
    value NUMERIC,
    confidence NUMERIC
);

CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    measurement probability_value NOT NULL,
    timestamp TIMESTAMP DEFAULT NOW()
);

-- æ–¹æ¡ˆ3ï¼šæ¦‚ç‡å€¼ä½œä¸ºJSONBï¼ˆçµæ´»ä½†æ€§èƒ½è¾ƒä½ï¼‰
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    data JSONB NOT NULL,  -- {"value": 25.5, "probability": 0.95}
    timestamp TIMESTAMP DEFAULT NOW()
);
```

**è®¾è®¡åŸåˆ™**ï¼š

- **æŸ¥è¯¢æ¨¡å¼ä¼˜å…ˆ**ï¼šæ ¹æ®æŸ¥è¯¢æ¨¡å¼è®¾è®¡è¡¨ç»“æ„
- **è®¿é—®é¢‘ç‡è€ƒè™‘**ï¼šé«˜é¢‘æŸ¥è¯¢çš„å­—æ®µæ”¾åœ¨å‰é¢
- **é¿å…è¿‡åº¦è§„èŒƒåŒ–**ï¼šé€‚åº¦åè§„èŒƒåŒ–ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
- **æ¦‚ç‡å€¼é›†ä¸­å­˜å‚¨**ï¼šå°†æ¦‚ç‡å€¼é›†ä¸­å­˜å‚¨ï¼Œä¾¿äºç®¡ç†å’ŒæŸ¥è¯¢

**2. ç´¢å¼•è®¾è®¡**

**æ¦‚ç‡å€¼ç´¢å¼•**ï¼š

```sql
-- åŸºç¡€æ¦‚ç‡å€¼ç´¢å¼•
CREATE INDEX idx_probability ON sensor_data(probability);

-- éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•é«˜æ¦‚ç‡æ•°æ®ï¼‰
CREATE INDEX idx_high_probability ON sensor_data(probability)
WHERE probability > 0.7;

-- å¤åˆç´¢å¼•ï¼ˆæ¦‚ç‡+å…¶ä»–å­—æ®µï¼‰
CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);

-- è¡¨è¾¾å¼ç´¢å¼•ï¼ˆæ¦‚ç‡è®¡ç®—ï¼‰
CREATE INDEX idx_prob_expr ON sensor_data((probability * 100));

-- GINç´¢å¼•ï¼ˆç”¨äºèŒƒå›´æŸ¥è¯¢ï¼‰
CREATE INDEX idx_prob_gin ON sensor_data USING GIN(
    int4range(
        FLOOR(probability * 100)::int,
        CEIL(probability * 100)::int
    )
);
```

**ç´¢å¼•è®¾è®¡åŸåˆ™**ï¼š

- **æ¦‚ç‡å€¼ç´¢å¼•**ï¼šä¸ºæ¦‚ç‡å€¼åˆ›å»ºç´¢å¼•ï¼ŒåŠ é€Ÿæ¦‚ç‡è¿‡æ»¤
- **å¤åˆç´¢å¼•**ï¼šä¸ºå¸¸ç”¨æŸ¥è¯¢æ¡ä»¶åˆ›å»ºå¤åˆç´¢å¼•
- **éƒ¨åˆ†ç´¢å¼•**ï¼šä¸ºé«˜æ¦‚ç‡æ•°æ®åˆ›å»ºéƒ¨åˆ†ç´¢å¼•ï¼Œå‡å°‘ç´¢å¼•å¤§å°
- **è¡¨è¾¾å¼ç´¢å¼•**ï¼šä¸ºæ¦‚ç‡è®¡ç®—è¡¨è¾¾å¼åˆ›å»ºç´¢å¼•
- **ç´¢å¼•ç»´æŠ¤**ï¼šå®šæœŸé‡å»ºç´¢å¼•ï¼Œä¿æŒç´¢å¼•æ•ˆç‡

**3. çº¦æŸè®¾è®¡**

**æ¦‚ç‡å€¼çº¦æŸ**ï¼š

```sql
-- CHECKçº¦æŸéªŒè¯æ¦‚ç‡å€¼èŒƒå›´
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (
        probability >= 0 AND probability <= 1
    ),
    timestamp TIMESTAMP DEFAULT NOW()
);

-- è§¦å‘å™¨è‡ªåŠ¨å½’ä¸€åŒ–æ¦‚ç‡å€¼
CREATE OR REPLACE FUNCTION normalize_probability()
RETURNS TRIGGER AS $$
BEGIN
    -- ç¡®ä¿æ¦‚ç‡å€¼åœ¨[0, 1]èŒƒå›´å†…
    NEW.probability := GREATEST(0, LEAST(1, NEW.probability));
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER normalize_probability_trigger
BEFORE INSERT OR UPDATE ON sensor_data
FOR EACH ROW
EXECUTE FUNCTION normalize_probability();
```

**å¤–é”®çº¦æŸ**ï¼š

```sql
-- å¤–é”®çº¦æŸç»´æŠ¤æ•°æ®å®Œæ•´æ€§
CREATE TABLE sensors (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    location VARCHAR(100)
);

CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL REFERENCES sensors(id),
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW()
);
```

**å”¯ä¸€çº¦æŸ**ï¼š

```sql
-- å”¯ä¸€çº¦æŸé¿å…é‡å¤æ•°æ®
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW(),
    UNIQUE(sensor_id, timestamp)  -- åŒä¸€ä¼ æ„Ÿå™¨åŒä¸€æ—¶é—´åªèƒ½æœ‰ä¸€æ¡æ•°æ®
);
```

**çº¦æŸè®¾è®¡åŸåˆ™**ï¼š

- **CHECKçº¦æŸ**ï¼šéªŒè¯æ¦‚ç‡å€¼èŒƒå›´ï¼Œç¡®ä¿æ•°æ®è´¨é‡
- **å¤–é”®çº¦æŸ**ï¼šç»´æŠ¤æ•°æ®å®Œæ•´æ€§ï¼Œé¿å…å­¤ç«‹æ•°æ®
- **å”¯ä¸€çº¦æŸ**ï¼šé¿å…é‡å¤æ•°æ®ï¼Œä¿è¯æ•°æ®å”¯ä¸€æ€§
- **è§¦å‘å™¨**ï¼šè‡ªåŠ¨å¤„ç†æ¦‚ç‡å€¼å½’ä¸€åŒ–å’ŒéªŒè¯

**4. åˆ†åŒºè®¾è®¡**

**æ¦‚ç‡å€¼åˆ†åŒº**ï¼š

```sql
-- æŒ‰æ¦‚ç‡å€¼èŒƒå›´åˆ†åŒº
CREATE TABLE sensor_data (
    id SERIAL,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW()
) PARTITION BY RANGE (probability);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE sensor_data_high PARTITION OF sensor_data
FOR VALUES FROM (0.8) TO (1.0);

CREATE TABLE sensor_data_medium PARTITION OF sensor_data
FOR VALUES FROM (0.5) TO (0.8);

CREATE TABLE sensor_data_low PARTITION OF sensor_data
FOR VALUES FROM (0.0) TO (0.5);
```

**æ—¶é—´åˆ†åŒº**ï¼š

```sql
-- æŒ‰æ—¶é—´åˆ†åŒº
CREATE TABLE sensor_data (
    id SERIAL,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW()
) PARTITION BY RANGE (timestamp);

-- åˆ›å»ºæœˆåº¦åˆ†åŒº
CREATE TABLE sensor_data_2025_01 PARTITION OF sensor_data
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE sensor_data_2025_02 PARTITION OF sensor_data
FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');
```

**5. ç‰©åŒ–è§†å›¾è®¾è®¡**

**æ¦‚ç‡æŸ¥è¯¢ç‰©åŒ–è§†å›¾**ï¼š

```sql
-- åˆ›å»ºæ¦‚ç‡èšåˆç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW sensor_data_summary AS
SELECT
    sensor_id,
    COUNT(*) AS total_count,
    AVG(value) AS avg_value,
    SUM(value * probability) / SUM(probability) AS weighted_avg,
    AVG(probability) AS avg_probability,
    MIN(probability) AS min_probability,
    MAX(probability) AS max_probability
FROM sensor_data
GROUP BY sensor_id;

-- åˆ›å»ºç´¢å¼•åŠ é€ŸæŸ¥è¯¢
CREATE INDEX idx_summary_sensor ON sensor_data_summary(sensor_id);

-- å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY sensor_data_summary;
```

**ç‰©åŒ–è§†å›¾è®¾è®¡åŸåˆ™**ï¼š

- **é¢„è®¡ç®—å¸¸è§æŸ¥è¯¢**ï¼šä¸ºå¸¸è§æ¦‚ç‡æŸ¥è¯¢åˆ›å»ºç‰©åŒ–è§†å›¾
- **å®šæœŸåˆ·æ–°**ï¼šå®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾ï¼Œä¿æŒæ•°æ®æœ€æ–°
- **å¹¶å‘åˆ·æ–°**ï¼šä½¿ç”¨CONCURRENTLYé€‰é¡¹ï¼Œé¿å…é”å®š
- **ç´¢å¼•ä¼˜åŒ–**ï¼šä¸ºç‰©åŒ–è§†å›¾åˆ›å»ºç´¢å¼•ï¼ŒåŠ é€ŸæŸ¥è¯¢

### 7.3 æ€§èƒ½ä¼˜åŒ–

#### **7.3.1 æŸ¥è¯¢ä¼˜åŒ–**

**1. ç´¢å¼•ä¼˜åŒ–**

```sql
-- ä¸ºæ¦‚ç‡å€¼åˆ›å»ºç´¢å¼•
CREATE INDEX idx_probability ON sensor_data(probability);

-- ä¸ºæ¦‚ç‡æŸ¥è¯¢åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);

-- åˆ›å»ºéƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•é«˜æ¦‚ç‡æ•°æ®ï¼‰
CREATE INDEX idx_high_prob ON sensor_data(probability)
WHERE probability > 0.7;

-- åˆ›å»ºè¡¨è¾¾å¼ç´¢å¼•ï¼ˆæ¦‚ç‡è®¡ç®—ï¼‰
CREATE INDEX idx_prob_expr ON sensor_data((probability * 100));

-- ä½¿ç”¨ç´¢å¼•æç¤ºä¼˜åŒ–æŸ¥è¯¢
SET enable_seqscan = off;
SELECT * FROM sensor_data WHERE probability > 0.8;
SET enable_seqscan = on;
```

**2. æŸ¥è¯¢é‡å†™ä¼˜åŒ–**

```sql
-- ä¼˜åŒ–å‰ï¼šå¤æ‚æ¦‚ç‡è®¡ç®—
SELECT
    sensor_id,
    SUM(value * probability) / SUM(probability) AS weighted_avg
FROM sensor_data
WHERE probability > 0.5
GROUP BY sensor_id;

-- ä¼˜åŒ–åï¼šä½¿ç”¨ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW sensor_data_weighted_avg AS
SELECT
    sensor_id,
    SUM(value * probability) / SUM(probability) AS weighted_avg,
    AVG(probability) AS avg_probability
FROM sensor_data
WHERE probability > 0.5
GROUP BY sensor_id;

CREATE INDEX idx_weighted_avg_sensor ON sensor_data_weighted_avg(sensor_id);

-- æŸ¥è¯¢ç‰©åŒ–è§†å›¾ï¼ˆæ›´å¿«ï¼‰
SELECT * FROM sensor_data_weighted_avg WHERE sensor_id = 1;

-- å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY sensor_data_weighted_avg;
```

**3. JOINä¼˜åŒ–**

```sql
-- ä¼˜åŒ–å‰ï¼šå…ˆJOINå†è¿‡æ»¤
SELECT a.*, b.*
FROM uncertain_table_a a
JOIN uncertain_table_b b ON a.id = b.id
WHERE a.probability * b.probability > 0.5;

-- ä¼˜åŒ–åï¼šå…ˆè¿‡æ»¤å†JOIN
SELECT a.*, b.*
FROM (
    SELECT * FROM uncertain_table_a WHERE probability > 0.7
) a
JOIN (
    SELECT * FROM uncertain_table_b WHERE probability > 0.7
) b ON a.id = b.id
WHERE a.probability * b.probability > 0.5;
```

**4. æ‰¹é‡å¤„ç†ä¼˜åŒ–**

```sql
-- æ‰¹é‡æ’å…¥æ¦‚ç‡æ•°æ®
BEGIN;
INSERT INTO sensor_data (sensor_id, value, probability, timestamp)
SELECT
    generate_series(1, 1000) AS sensor_id,
    random() * 100 AS value,
    random() AS probability,
    NOW() AS timestamp;
COMMIT;

-- æ‰¹é‡æ›´æ–°æ¦‚ç‡å€¼
UPDATE sensor_data
SET probability = probability * 1.1
WHERE probability < 0.9 AND timestamp > NOW() - INTERVAL '1 day';

-- ä½¿ç”¨COPYæ‰¹é‡å¯¼å…¥
COPY sensor_data (sensor_id, value, probability, timestamp)
FROM '/path/to/data.csv' WITH CSV HEADER;
```

**5. æŸ¥è¯¢ç¼“å­˜ä¼˜åŒ–**

```sql
-- åˆ›å»ºæŸ¥è¯¢ç»“æœç¼“å­˜è¡¨
CREATE TABLE IF NOT EXISTS query_cache (
    query_hash TEXT PRIMARY KEY,
    query_result JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP
);

-- æŸ¥è¯¢ç¼“å­˜å‡½æ•°
CREATE OR REPLACE FUNCTION get_cached_result(
    query_hash TEXT,
    query_text TEXT
) RETURNS JSONB AS $$
DECLARE
    cached_result JSONB;
BEGIN
    -- æ£€æŸ¥ç¼“å­˜
    SELECT query_result INTO cached_result
    FROM query_cache
    WHERE query_hash = get_cached_result.query_hash
      AND expires_at > NOW();

    IF cached_result IS NOT NULL THEN
        RETURN cached_result;
    END IF;

    -- æ‰§è¡ŒæŸ¥è¯¢å¹¶ç¼“å­˜ç»“æœ
    EXECUTE format('SELECT to_jsonb(result) FROM (%s) result', query_text) INTO cached_result;

    INSERT INTO query_cache (query_hash, query_result, expires_at)
    VALUES (
        get_cached_result.query_hash,
        cached_result,
        NOW() + INTERVAL '1 hour'
    )
    ON CONFLICT (query_hash) DO UPDATE SET
        query_result = EXCLUDED.query_result,
        expires_at = EXCLUDED.expires_at;

    RETURN cached_result;
END;
$$ LANGUAGE plpgsql;
```

#### **7.3.2 å­˜å‚¨ä¼˜åŒ–**

**1. æ•°æ®ç±»å‹é€‰æ‹©**

```sql
-- NUMERICï¼šé«˜ç²¾åº¦ï¼Œé€‚åˆæ¦‚ç‡å€¼ï¼ˆæ¨èï¼‰
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    value NUMERIC(10, 2),
    probability NUMERIC(5, 4)  -- ç²¾åº¦ï¼š5ä½æ•°å­—ï¼Œ4ä½å°æ•°
);

-- DOUBLE PRECISIONï¼šé«˜æ€§èƒ½ï¼Œé€‚åˆå¤§è§„æ¨¡æ•°æ®
CREATE TABLE sensor_data_fast (
    id SERIAL PRIMARY KEY,
    value DOUBLE PRECISION,
    probability DOUBLE PRECISION
);

-- REALï¼šèŠ‚çœç©ºé—´ï¼Œé€‚åˆç²¾åº¦è¦æ±‚ä¸é«˜çš„åœºæ™¯
CREATE TABLE sensor_data_compact (
    id SERIAL PRIMARY KEY,
    value REAL,
    probability REAL
);
```

**æ•°æ®ç±»å‹é€‰æ‹©å»ºè®®**ï¼š

- **NUMERIC**ï¼šæ¨èç”¨äºæ¦‚ç‡å€¼ï¼Œä¿è¯ç²¾åº¦
- **DOUBLE PRECISION**ï¼šç”¨äºå¤§è§„æ¨¡æ•°æ®ï¼Œæ€§èƒ½ä¼˜å…ˆ
- **REAL**ï¼šç”¨äºç²¾åº¦è¦æ±‚ä¸é«˜çš„åœºæ™¯ï¼ŒèŠ‚çœç©ºé—´

**2. åˆ†åŒºç­–ç•¥**

```sql
-- æŒ‰æ¦‚ç‡å€¼èŒƒå›´åˆ†åŒº
CREATE TABLE sensor_data (
    id SERIAL,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW()
) PARTITION BY RANGE (probability);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE sensor_data_high PARTITION OF sensor_data
FOR VALUES FROM (0.8) TO (1.0);

CREATE TABLE sensor_data_medium PARTITION OF sensor_data
FOR VALUES FROM (0.5) TO (0.8);

CREATE TABLE sensor_data_low PARTITION OF sensor_data
FOR VALUES FROM (0.0) TO (0.5);

-- æŒ‰æ—¶é—´åˆ†åŒº
CREATE TABLE sensor_data_time (
    id SERIAL,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW()
) PARTITION BY RANGE (timestamp);

-- åˆ›å»ºæœˆåº¦åˆ†åŒº
CREATE TABLE sensor_data_2025_01 PARTITION OF sensor_data_time
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

**3. å‹ç¼©æŠ€æœ¯**

```sql
-- å¯ç”¨è¡¨å‹ç¼©
ALTER TABLE sensor_data SET (
    toast_tuple_target = 128,
    fillfactor = 90
);

-- å½’æ¡£ä½æ¦‚ç‡å†å²æ•°æ®
CREATE TABLE sensor_data_archive (
    LIKE sensor_data INCLUDING ALL
) PARTITION BY RANGE (timestamp);

-- å½’æ¡£å‡½æ•°
CREATE OR REPLACE FUNCTION archive_low_probability_data()
RETURNS VOID AS $$
BEGIN
    INSERT INTO sensor_data_archive
    SELECT * FROM sensor_data
    WHERE probability < 0.3 AND timestamp < NOW() - INTERVAL '1 year';

    DELETE FROM sensor_data
    WHERE probability < 0.3 AND timestamp < NOW() - INTERVAL '1 year';
END;
$$ LANGUAGE plpgsql;

-- å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
CREATE OR REPLACE FUNCTION cleanup_expired_data()
RETURNS VOID AS $$
BEGIN
    DELETE FROM sensor_data
    WHERE timestamp < NOW() - INTERVAL '2 years';
END;
$$ LANGUAGE plpgsql;
```

**4. å­˜å‚¨ç©ºé—´ä¼˜åŒ–**

```sql
-- ä½¿ç”¨TOASTå‹ç¼©å¤§å­—æ®µ
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    provenance_data JSONB,  -- ä½¿ç”¨JSONBå­˜å‚¨æº¯æºä¿¡æ¯ï¼Œè‡ªåŠ¨å‹ç¼©
    timestamp TIMESTAMP DEFAULT NOW()
);

-- ä½¿ç”¨åˆ—å­˜å‚¨ä¼˜åŒ–ï¼ˆPostgreSQL 14+ï¼‰
-- æ³¨æ„ï¼šPostgreSQLåŸç”Ÿä¸æ”¯æŒåˆ—å­˜å‚¨ï¼Œå¯ä»¥ä½¿ç”¨æ‰©å±•æˆ–å¤–éƒ¨è¡¨

-- å®šæœŸVACUUMå’ŒANALYZE
VACUUM ANALYZE sensor_data;

-- é‡å»ºè¡¨å›æ”¶ç©ºé—´
VACUUM FULL sensor_data;
```

### 7.4 å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### **7.4.1 æ¦‚ç‡å€¼ä¸ä¸€è‡´**

**é—®é¢˜æè¿°**ï¼šå¤šä¸ªæ•°æ®æºçš„æ¦‚ç‡å€¼ä¸ä¸€è‡´ï¼Œå¯¼è‡´æŸ¥è¯¢ç»“æœä¸å‡†ç¡®ã€‚

**é—®é¢˜åŸå› **ï¼š

- ä¸åŒæ•°æ®æºä½¿ç”¨ä¸åŒçš„æ¦‚ç‡è®¡ç®—æ–¹æ³•
- æ¦‚ç‡å€¼æ²¡æœ‰å½’ä¸€åŒ–
- æ¦‚ç‡å€¼è¶…å‡º[0, 1]èŒƒå›´

**è§£å†³æ–¹æ¡ˆ**ï¼š

```sql
-- 1. ä½¿ç”¨å½’ä¸€åŒ–å‡½æ•°
CREATE OR REPLACE FUNCTION normalize_probability(
    prob NUMERIC
) RETURNS NUMERIC AS $$
BEGIN
    -- ç¡®ä¿æ¦‚ç‡å€¼åœ¨[0, 1]èŒƒå›´å†…
    RETURN GREATEST(0, LEAST(1, prob));
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- 2. ä½¿ç”¨è§¦å‘å™¨è‡ªåŠ¨å½’ä¸€åŒ–
CREATE OR REPLACE FUNCTION normalize_probability_trigger()
RETURNS TRIGGER AS $$
BEGIN
    NEW.probability := normalize_probability(NEW.probability);
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER normalize_prob_trigger
BEFORE INSERT OR UPDATE ON sensor_data
FOR EACH ROW
EXECUTE FUNCTION normalize_probability_trigger();

-- 3. æ‰¹é‡å½’ä¸€åŒ–ç°æœ‰æ•°æ®
UPDATE sensor_data
SET probability = normalize_probability(probability)
WHERE probability < 0 OR probability > 1;

-- 4. æ•°æ®æºæ¦‚ç‡å€¼æ ‡å‡†åŒ–
CREATE OR REPLACE FUNCTION standardize_source_probability(
    source_name VARCHAR,
    raw_probability NUMERIC
) RETURNS NUMERIC AS $$
DECLARE
    source_weight NUMERIC;
BEGIN
    -- æ ¹æ®æ•°æ®æºè·å–æƒé‡
    SELECT weight INTO source_weight
    FROM data_source_weights
    WHERE name = source_name;

    -- æ ‡å‡†åŒ–æ¦‚ç‡å€¼
    RETURN normalize_probability(raw_probability * COALESCE(source_weight, 1.0));
END;
$$ LANGUAGE plpgsql;
```

**é¢„é˜²æªæ–½**ï¼š

- ä½¿ç”¨CHECKçº¦æŸéªŒè¯æ¦‚ç‡å€¼èŒƒå›´
- åœ¨åº”ç”¨å±‚è¿›è¡Œæ¦‚ç‡å€¼éªŒè¯
- å®šæœŸæ£€æŸ¥æ•°æ®è´¨é‡

#### **7.4.2 æ€§èƒ½é—®é¢˜**

**é—®é¢˜æè¿°**ï¼šæ¦‚ç‡æŸ¥è¯¢æ€§èƒ½æ…¢ï¼Œå“åº”æ—¶é—´é•¿ã€‚

**é—®é¢˜åŸå› **ï¼š

- ç¼ºå°‘åˆé€‚çš„ç´¢å¼•
- æ¦‚ç‡è®¡ç®—å¤æ‚
- æ•°æ®é‡å¤§
- æŸ¥è¯¢æ²¡æœ‰ä¼˜åŒ–

**è§£å†³æ–¹æ¡ˆ**ï¼š

**1. åˆ›å»ºåˆé€‚çš„ç´¢å¼•**

```sql
-- ä¸ºæ¦‚ç‡å€¼åˆ›å»ºç´¢å¼•
CREATE INDEX idx_probability ON sensor_data(probability);

-- ä¸ºå¸¸ç”¨æŸ¥è¯¢åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);

-- åˆ›å»ºéƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•é«˜æ¦‚ç‡æ•°æ®ï¼‰
CREATE INDEX idx_high_prob ON sensor_data(probability)
WHERE probability > 0.7;

-- åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE tablename = 'sensor_data';
```

**2. ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—**

```sql
-- åˆ›å»ºç‰©åŒ–è§†å›¾é¢„è®¡ç®—å¸¸è§æŸ¥è¯¢
CREATE MATERIALIZED VIEW sensor_data_summary AS
SELECT
    sensor_id,
    COUNT(*) AS total_count,
    SUM(value * probability) / SUM(probability) AS weighted_avg,
    AVG(probability) AS avg_probability
FROM sensor_data
GROUP BY sensor_id;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_summary_sensor ON sensor_data_summary(sensor_id);

-- å®šæœŸåˆ·æ–°ï¼ˆä½¿ç”¨CONCURRENTLYé¿å…é”å®šï¼‰
REFRESH MATERIALIZED VIEW CONCURRENTLY sensor_data_summary;

-- è®¾ç½®è‡ªåŠ¨åˆ·æ–°ï¼ˆä½¿ç”¨pg_cronæ‰©å±•ï¼‰
SELECT cron.schedule(
    'refresh-sensor-summary',
    '0 * * * *',  -- æ¯å°æ—¶åˆ·æ–°ä¸€æ¬¡
    'REFRESH MATERIALIZED VIEW CONCURRENTLY sensor_data_summary'
);
```

**3. ä¼˜åŒ–æŸ¥è¯¢è¯­å¥**

```sql
-- ä¼˜åŒ–å‰ï¼šå…¨è¡¨æ‰«æ
SELECT * FROM sensor_data WHERE probability > 0.8;

-- ä¼˜åŒ–åï¼šä½¿ç”¨ç´¢å¼•
SELECT * FROM sensor_data
WHERE probability > 0.8
ORDER BY probability DESC
LIMIT 100;

-- ä¼˜åŒ–å‰ï¼šå¤æ‚è®¡ç®—
SELECT
    sensor_id,
    SUM(value * probability) / SUM(probability) AS weighted_avg
FROM sensor_data
GROUP BY sensor_id;

-- ä¼˜åŒ–åï¼šä½¿ç”¨ç‰©åŒ–è§†å›¾
SELECT * FROM sensor_data_summary;
```

**4. ä½¿ç”¨æŸ¥è¯¢ç¼“å­˜**

```sql
-- åˆ›å»ºæŸ¥è¯¢ç¼“å­˜è¡¨
CREATE TABLE IF NOT EXISTS query_cache (
    query_hash TEXT PRIMARY KEY,
    query_result JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP
);

-- æŸ¥è¯¢ç¼“å­˜å‡½æ•°
CREATE OR REPLACE FUNCTION get_cached_query_result(
    query_hash TEXT,
    query_text TEXT,
    cache_duration INTERVAL DEFAULT INTERVAL '1 hour'
) RETURNS JSONB AS $$
DECLARE
    cached_result JSONB;
BEGIN
    -- æ£€æŸ¥ç¼“å­˜
    SELECT query_result INTO cached_result
    FROM query_cache
    WHERE query_hash = get_cached_query_result.query_hash
      AND expires_at > NOW();

    IF cached_result IS NOT NULL THEN
        RETURN cached_result;
    END IF;

    -- æ‰§è¡ŒæŸ¥è¯¢å¹¶ç¼“å­˜ç»“æœ
    EXECUTE format('SELECT to_jsonb(result) FROM (%s) result', query_text) INTO cached_result;

    INSERT INTO query_cache (query_hash, query_result, expires_at)
    VALUES (
        get_cached_query_result.query_hash,
        cached_result,
        NOW() + cache_duration
    )
    ON CONFLICT (query_hash) DO UPDATE SET
        query_result = EXCLUDED.query_result,
        expires_at = EXCLUDED.expires_at;

    RETURN cached_result;
END;
$$ LANGUAGE plpgsql;
```

**5. å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ–**

```sql
-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 1000;
SET parallel_tuple_cost = 0.1;

-- ä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢
EXPLAIN (ANALYZE, BUFFERS)
SELECT
    sensor_id,
    SUM(value * probability) / SUM(probability) AS weighted_avg
FROM sensor_data
WHERE probability > 0.8
GROUP BY sensor_id;
```

#### **7.4.3 å­˜å‚¨ç©ºé—´é—®é¢˜**

**é—®é¢˜æè¿°**ï¼šæ¦‚ç‡å€¼å’Œæº¯æºä¿¡æ¯å ç”¨å¤§é‡å­˜å‚¨ç©ºé—´ï¼Œå¯¼è‡´å­˜å‚¨æˆæœ¬é«˜ã€‚

**é—®é¢˜åŸå› **ï¼š

- æ¦‚ç‡å€¼å­˜å‚¨ç²¾åº¦è¿‡é«˜
- æº¯æºä¿¡æ¯å­˜å‚¨å†—ä½™
- å†å²æ•°æ®æ²¡æœ‰å½’æ¡£
- ç´¢å¼•å ç”¨ç©ºé—´å¤§

**è§£å†³æ–¹æ¡ˆ**ï¼š

**1. ä¼˜åŒ–æ•°æ®ç±»å‹**

```sql
-- ä¼˜åŒ–å‰ï¼šä½¿ç”¨NUMERIC(10, 8)ï¼ˆå ç”¨ç©ºé—´å¤§ï¼‰
CREATE TABLE sensor_data (
    probability NUMERIC(10, 8)  -- å ç”¨æ›´å¤šç©ºé—´
);

-- ä¼˜åŒ–åï¼šä½¿ç”¨NUMERIC(5, 4)ï¼ˆå ç”¨ç©ºé—´å°ï¼‰
CREATE TABLE sensor_data (
    probability NUMERIC(5, 4)  -- ç²¾åº¦è¶³å¤Ÿï¼Œå ç”¨ç©ºé—´å°
);

-- æˆ–è€…ä½¿ç”¨DOUBLE PRECISIONï¼ˆæ€§èƒ½ä¼˜å…ˆï¼‰
CREATE TABLE sensor_data (
    probability DOUBLE PRECISION  -- 8å­—èŠ‚ï¼Œæ€§èƒ½å¥½
);
```

**2. å‹ç¼©æº¯æºä¿¡æ¯**

```sql
-- ä½¿ç”¨JSONBå‹ç¼©å­˜å‚¨æº¯æºä¿¡æ¯
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    provenance JSONB,  -- JSONBè‡ªåŠ¨å‹ç¼©
    timestamp TIMESTAMP DEFAULT NOW()
);

-- å¯ç”¨TOASTå‹ç¼©
ALTER TABLE sensor_data SET (
    toast_tuple_target = 128
);
```

**3. æ•°æ®å½’æ¡£ç­–ç•¥**

```sql
-- åˆ›å»ºå½’æ¡£è¡¨
CREATE TABLE sensor_data_archive (
    LIKE sensor_data INCLUDING ALL
) PARTITION BY RANGE (timestamp);

-- å½’æ¡£å‡½æ•°
CREATE OR REPLACE FUNCTION archive_old_data(
    archive_threshold INTERVAL DEFAULT INTERVAL '1 year',
    probability_threshold NUMERIC DEFAULT 0.3
) RETURNS TABLE (
    archived_count BIGINT,
    freed_space BIGINT
) AS $$
DECLARE
    archived_rows BIGINT;
BEGIN
    -- å½’æ¡£ä½æ¦‚ç‡å†å²æ•°æ®
    INSERT INTO sensor_data_archive
    SELECT * FROM sensor_data
    WHERE probability < probability_threshold
      AND timestamp < NOW() - archive_threshold;

    GET DIAGNOSTICS archived_rows = ROW_COUNT;

    -- åˆ é™¤å·²å½’æ¡£æ•°æ®
    DELETE FROM sensor_data
    WHERE probability < probability_threshold
      AND timestamp < NOW() - archive_threshold;

    -- è¿”å›å½’æ¡£ç»Ÿè®¡
    RETURN QUERY SELECT
        archived_rows,
        pg_total_relation_size('sensor_data') AS freed_space;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨å½’æ¡£å‡½æ•°
SELECT * FROM archive_old_data(INTERVAL '1 year', 0.3);
```

**4. ç´¢å¼•ä¼˜åŒ–**

```sql
-- ä½¿ç”¨éƒ¨åˆ†ç´¢å¼•å‡å°‘ç´¢å¼•å¤§å°
CREATE INDEX idx_high_prob ON sensor_data(probability)
WHERE probability > 0.7;  -- åªç´¢å¼•é«˜æ¦‚ç‡æ•°æ®

-- å®šæœŸé‡å»ºç´¢å¼•å›æ”¶ç©ºé—´
REINDEX INDEX idx_probability;

-- åˆ é™¤æœªä½¿ç”¨çš„ç´¢å¼•
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0 AND tablename = 'sensor_data';

-- åˆ é™¤æœªä½¿ç”¨çš„ç´¢å¼•
DROP INDEX IF EXISTS unused_index_name;
```

**5. è¡¨å‹ç¼©å’Œæ¸…ç†**

```sql
-- VACUUMå›æ”¶ç©ºé—´
VACUUM ANALYZE sensor_data;

-- VACUUM FULLé‡å»ºè¡¨ï¼ˆéœ€è¦é”å®šï¼‰
VACUUM FULL sensor_data;

-- è®¾ç½®è‡ªåŠ¨VACUUM
ALTER TABLE sensor_data SET (
    autovacuum_vacuum_scale_factor = 0.1,
    autovacuum_analyze_scale_factor = 0.05
);
```

**6. å­˜å‚¨ç©ºé—´ç›‘æ§**

```sql
-- åˆ›å»ºå­˜å‚¨ç©ºé—´ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW storage_usage AS
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
    pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) AS indexes_size,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) -
                   pg_relation_size(schemaname||'.'||tablename) -
                   pg_indexes_size(schemaname||'.'||tablename)) AS other_size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- æŸ¥è¯¢å­˜å‚¨ä½¿ç”¨æƒ…å†µ
SELECT * FROM storage_usage;
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. ä½¿ç”¨å‹ç¼©æŠ€æœ¯
2. å½’æ¡£å†å²æ•°æ®
3. å®šæœŸæ¸…ç†ä½æ¦‚ç‡æ•°æ®
4. ä½¿ç”¨åˆ†åŒºè¡¨

### 7.5 æ³¨æ„äº‹é¡¹

#### **7.5.1 æ¦‚ç‡å€¼ç®¡ç†**

**1. æ¦‚ç‡å€¼èŒƒå›´éªŒè¯**:

```sql
-- ä½¿ç”¨CHECKçº¦æŸç¡®ä¿æ¦‚ç‡å€¼åœ¨[0, 1]èŒƒå›´å†…
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (
        probability >= 0 AND probability <= 1
    ),
    timestamp TIMESTAMP DEFAULT NOW()
);

-- å¤„ç†NULLæ¦‚ç‡å€¼çš„æƒ…å†µ
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (
        probability IS NULL OR (probability >= 0 AND probability <= 1)
    ),
    timestamp TIMESTAMP DEFAULT NOW()
);

-- éªŒè¯æ¦‚ç‡åˆ†å¸ƒçš„åˆç†æ€§
CREATE OR REPLACE FUNCTION validate_probability_distribution(
    table_name TEXT,
    column_name TEXT
) RETURNS TABLE (
    total_count BIGINT,
    valid_probability_count BIGINT,
    invalid_probability_count BIGINT,
    null_probability_count BIGINT,
    avg_probability NUMERIC,
    min_probability NUMERIC,
    max_probability NUMERIC
) AS $$
BEGIN
    RETURN QUERY EXECUTE format('
        SELECT
            COUNT(*) AS total_count,
            COUNT(*) FILTER (WHERE %I >= 0 AND %I <= 1) AS valid_probability_count,
            COUNT(*) FILTER (WHERE %I < 0 OR %I > 1) AS invalid_probability_count,
            COUNT(*) FILTER (WHERE %I IS NULL) AS null_probability_count,
            AVG(%I) AS avg_probability,
            MIN(%I) AS min_probability,
            MAX(%I) AS max_probability
        FROM %I
    ', column_name, column_name, column_name, column_name, column_name,
       column_name, column_name, column_name, table_name);
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨éªŒè¯å‡½æ•°
SELECT * FROM validate_probability_distribution('sensor_data', 'probability');
```

**2. æ¦‚ç‡å€¼æ›´æ–°**:

```sql
-- åˆ›å»ºæ¦‚ç‡å€¼å˜æ›´å†å²è¡¨
CREATE TABLE probability_change_history (
    id SERIAL PRIMARY KEY,
    table_name TEXT NOT NULL,
    record_id INT NOT NULL,
    old_probability NUMERIC,
    new_probability NUMERIC,
    changed_by TEXT,
    changed_at TIMESTAMP DEFAULT NOW(),
    change_reason TEXT
);

-- åˆ›å»ºæ¦‚ç‡å€¼æ›´æ–°è§¦å‘å™¨
CREATE OR REPLACE FUNCTION log_probability_change()
RETURNS TRIGGER AS $$
BEGIN
    IF OLD.probability IS DISTINCT FROM NEW.probability THEN
        INSERT INTO probability_change_history (
            table_name,
            record_id,
            old_probability,
            new_probability,
            changed_by,
            change_reason
        ) VALUES (
            TG_TABLE_NAME,
            NEW.id,
            OLD.probability,
            NEW.probability,
            current_user,
            'Probability updated'
        );
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºè§¦å‘å™¨
CREATE TRIGGER log_probability_change_trigger
AFTER UPDATE ON sensor_data
FOR EACH ROW
EXECUTE FUNCTION log_probability_change();

-- ä½¿ç”¨äº‹åŠ¡ç¡®ä¿ä¸€è‡´æ€§
BEGIN;
UPDATE sensor_data
SET probability = probability * 1.1
WHERE sensor_id = 1 AND probability < 0.9;

-- éªŒè¯æ›´æ–°ç»“æœ
SELECT
    sensor_id,
    COUNT(*) AS updated_count,
    AVG(probability) AS avg_probability
FROM sensor_data
WHERE sensor_id = 1
GROUP BY sensor_id;

COMMIT;
```

**3. æ¦‚ç‡å€¼å½’ä¸€åŒ–**:

```sql
-- æ¦‚ç‡å€¼å½’ä¸€åŒ–å‡½æ•°
CREATE OR REPLACE FUNCTION normalize_probabilities(
    table_name TEXT,
    id_column TEXT,
    probability_column TEXT
) RETURNS VOID AS $$
DECLARE
    total_prob NUMERIC;
BEGIN
    -- è®¡ç®—æ€»æ¦‚ç‡
    EXECUTE format('
        SELECT SUM(%I) INTO total_prob
        FROM %I
    ', probability_column, table_name);

    -- å½’ä¸€åŒ–æ¦‚ç‡å€¼
    EXECUTE format('
        UPDATE %I
        SET %I = %I / NULLIF(%L, 0)
    ', table_name, probability_column, probability_column, total_prob);
END;
$$ LANGUAGE plpgsql;
```

#### **7.5.2 æŸ¥è¯¢å¤æ‚åº¦**

**1. é¿å…å¤æ‚æŸ¥è¯¢**

```sql
-- é¿å…æ·±åº¦åµŒå¥—çš„æ¦‚ç‡æŸ¥è¯¢
-- ä¸æ¨èï¼šæ·±åº¦åµŒå¥—
SELECT * FROM (
    SELECT * FROM (
        SELECT * FROM sensor_data WHERE probability > 0.8
    ) t1 WHERE probability > 0.9
) t2 WHERE probability > 0.95;

-- æ¨èï¼šç®€åŒ–æŸ¥è¯¢
SELECT * FROM sensor_data
WHERE probability > 0.95;

-- é¿å…å¤šä¸ªæ¦‚ç‡JOIN
-- ä¸æ¨èï¼šå¤šä¸ªæ¦‚ç‡JOIN
SELECT a.*, b.*, c.*
FROM uncertain_table_a a
JOIN uncertain_table_b b ON a.id = b.id
JOIN uncertain_table_c c ON b.id = c.id
WHERE a.probability * b.probability * c.probability > 0.5;

-- æ¨èï¼šå…ˆè¿‡æ»¤å†JOIN
SELECT a.*, b.*, c.*
FROM (
    SELECT * FROM uncertain_table_a WHERE probability > 0.7
) a
JOIN (
    SELECT * FROM uncertain_table_b WHERE probability > 0.7
) b ON a.id = b.id
JOIN (
    SELECT * FROM uncertain_table_c WHERE probability > 0.7
) c ON b.id = c.id
WHERE a.probability * b.probability * c.probability > 0.5;

-- é™åˆ¶æŸ¥è¯¢ç»“æœé›†å¤§å°
SELECT * FROM sensor_data
WHERE probability > 0.8
ORDER BY probability DESC
LIMIT 100;
```

**2. æŸ¥è¯¢è¶…æ—¶è®¾ç½®**

```sql
-- è®¾ç½®æŸ¥è¯¢è¶…æ—¶æ—¶é—´
SET statement_timeout = '30s';

-- ç›‘æ§é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
SELECT
    pid,
    now() - pg_stat_activity.query_start AS duration,
    query,
    state
FROM pg_stat_activity
WHERE state = 'active'
  AND now() - pg_stat_activity.query_start > INTERVAL '5 minutes';

-- å–æ¶ˆé•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
SELECT pg_cancel_backend(pid) FROM pg_stat_activity
WHERE state = 'active'
  AND now() - pg_stat_activity.query_start > INTERVAL '10 minutes';

-- æŸ¥è¯¢è¶…æ—¶ç›‘æ§å‡½æ•°
CREATE OR REPLACE FUNCTION monitor_long_running_queries(
    threshold INTERVAL DEFAULT INTERVAL '5 minutes'
) RETURNS TABLE (
    pid INT,
    duration INTERVAL,
    query TEXT,
    state TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        pg_stat_activity.pid,
        now() - pg_stat_activity.query_start AS duration,
        pg_stat_activity.query,
        pg_stat_activity.state
    FROM pg_stat_activity
    WHERE pg_stat_activity.state = 'active'
      AND now() - pg_stat_activity.query_start > threshold;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç›‘æ§å‡½æ•°
SELECT * FROM monitor_long_running_queries(INTERVAL '1 minute');
```

**3. æŸ¥è¯¢æ€§èƒ½åˆ†æ**

```sql
-- å¯ç”¨æŸ¥è¯¢è®¡åˆ’åˆ†æ
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM sensor_data
WHERE probability > 0.8;

-- åˆ†ææ…¢æŸ¥è¯¢
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- æŸ¥è¯¢æœ€æ…¢çš„æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

#### **7.5.3 æ•°æ®è´¨é‡**

**1. æ¦‚ç‡å€¼è´¨é‡**

```sql
-- éªŒè¯æ¦‚ç‡å€¼çš„åˆç†æ€§
CREATE OR REPLACE FUNCTION validate_probability_quality(
    table_name TEXT,
    probability_column TEXT
) RETURNS TABLE (
    check_name TEXT,
    check_result TEXT,
    issue_count BIGINT
) AS $$
BEGIN
    -- æ£€æŸ¥æ¦‚ç‡å€¼èŒƒå›´
    RETURN QUERY EXECUTE format('
        SELECT
            ''Probability Range Check'' AS check_name,
            CASE
                WHEN COUNT(*) FILTER (WHERE %I < 0 OR %I > 1) > 0
                THEN ''FAIL: Found probabilities outside [0, 1]''
                ELSE ''PASS: All probabilities in valid range''
            END AS check_result,
            COUNT(*) FILTER (WHERE %I < 0 OR %I > 1) AS issue_count
        FROM %I
    ', probability_column, probability_column, probability_column, table_name);

    -- æ£€æŸ¥NULLæ¦‚ç‡å€¼
    RETURN QUERY EXECUTE format('
        SELECT
            ''NULL Probability Check'' AS check_name,
            CASE
                WHEN COUNT(*) FILTER (WHERE %I IS NULL) > 0
                THEN ''WARNING: Found NULL probabilities''
                ELSE ''PASS: No NULL probabilities''
            END AS check_result,
            COUNT(*) FILTER (WHERE %I IS NULL) AS issue_count
        FROM %I
    ', probability_column, probability_column, table_name);

    -- æ£€æŸ¥æ¦‚ç‡åˆ†å¸ƒ
    RETURN QUERY EXECUTE format('
        SELECT
            ''Probability Distribution Check'' AS check_name,
            CASE
                WHEN STDDEV(%I) > 0.5
                THEN ''WARNING: High variance in probability distribution''
                ELSE ''PASS: Reasonable probability distribution''
            END AS check_result,
            COUNT(*) AS issue_count
        FROM %I
    ', probability_column, table_name);
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨éªŒè¯å‡½æ•°
SELECT * FROM validate_probability_quality('sensor_data', 'probability');

-- æ£€æŸ¥æ¦‚ç‡åˆ†å¸ƒçš„ä¸€è‡´æ€§
CREATE OR REPLACE FUNCTION check_probability_consistency(
    table_name TEXT,
    group_column TEXT,
    probability_column TEXT
) RETURNS TABLE (
    group_value TEXT,
    total_count BIGINT,
    avg_probability NUMERIC,
    stddev_probability NUMERIC,
    consistency_score NUMERIC
) AS $$
BEGIN
    RETURN QUERY EXECUTE format('
        SELECT
            %I::TEXT AS group_value,
            COUNT(*) AS total_count,
            AVG(%I) AS avg_probability,
            STDDEV(%I) AS stddev_probability,
            CASE
                WHEN STDDEV(%I) = 0 THEN 1.0
                ELSE 1.0 / (1.0 + STDDEV(%I))
            END AS consistency_score
        FROM %I
        GROUP BY %I
        ORDER BY consistency_score DESC
    ', group_column, probability_column, probability_column,
       probability_column, probability_column, table_name, group_column);
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ä¸€è‡´æ€§æ£€æŸ¥å‡½æ•°
SELECT * FROM check_probability_consistency('sensor_data', 'sensor_id', 'probability');

-- å¤„ç†å¼‚å¸¸æ¦‚ç‡å€¼
CREATE OR REPLACE FUNCTION fix_abnormal_probabilities(
    table_name TEXT,
    probability_column TEXT,
    threshold NUMERIC DEFAULT 0.01
) RETURNS TABLE (
    fixed_count BIGINT,
    avg_probability_before NUMERIC,
    avg_probability_after NUMERIC
) AS $$
DECLARE
    fixed_rows BIGINT;
    avg_before NUMERIC;
    avg_after NUMERIC;
BEGIN
    -- è®¡ç®—ä¿®å¤å‰çš„å¹³å‡æ¦‚ç‡
    EXECUTE format('
        SELECT AVG(%I) INTO avg_before
        FROM %I
    ', probability_column, table_name);

    -- ä¿®å¤å¼‚å¸¸æ¦‚ç‡å€¼
    EXECUTE format('
        UPDATE %I
        SET %I = CASE
            WHEN %I < 0 THEN 0
            WHEN %I > 1 THEN 1
            WHEN %I < threshold THEN threshold
            ELSE %I
        END
        WHERE %I < 0 OR %I > 1 OR %I < threshold
    ', table_name, probability_column, probability_column,
       probability_column, probability_column, probability_column,
       probability_column, probability_column, probability_column);

    GET DIAGNOSTICS fixed_rows = ROW_COUNT;

    -- è®¡ç®—ä¿®å¤åçš„å¹³å‡æ¦‚ç‡
    EXECUTE format('
        SELECT AVG(%I) INTO avg_after
        FROM %I
    ', probability_column, table_name);

    RETURN QUERY SELECT fixed_rows, avg_before, avg_after;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ä¿®å¤å‡½æ•°
SELECT * FROM fix_abnormal_probabilities('sensor_data', 'probability', 0.01);
```

**2. æ•°æ®ä¸€è‡´æ€§**

```sql
-- ç¡®ä¿æ¦‚ç‡å€¼ä¸æ•°æ®çš„ä¸€è‡´æ€§
CREATE OR REPLACE FUNCTION check_data_consistency(
    table_name TEXT,
    value_column TEXT,
    probability_column TEXT
) RETURNS TABLE (
    check_name TEXT,
    check_result TEXT,
    issue_count BIGINT
) AS $$
BEGIN
    -- æ£€æŸ¥æ¦‚ç‡å€¼ä¸æ•°æ®å€¼çš„ä¸€è‡´æ€§
    RETURN QUERY EXECUTE format('
        SELECT
            ''Value-Probability Consistency Check'' AS check_name,
            CASE
                WHEN COUNT(*) FILTER (
                    WHERE (%I IS NULL AND %I IS NOT NULL) OR
                         (%I IS NOT NULL AND %I IS NULL)
                ) > 0
                THEN ''FAIL: Found inconsistent NULL values''
                ELSE ''PASS: Value and probability consistency OK''
            END AS check_result,
            COUNT(*) FILTER (
                WHERE (%I IS NULL AND %I IS NOT NULL) OR
                     (%I IS NOT NULL AND %I IS NULL)
            ) AS issue_count
        FROM %I
    ', value_column, probability_column, value_column, probability_column,
       value_column, probability_column, table_name);
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ä¸€è‡´æ€§æ£€æŸ¥å‡½æ•°
SELECT * FROM check_data_consistency('sensor_data', 'value', 'probability');

-- éªŒè¯æº¯æºä¿¡æ¯çš„å®Œæ•´æ€§
CREATE OR REPLACE FUNCTION validate_provenance_integrity(
    table_name TEXT,
    provenance_column TEXT
) RETURNS TABLE (
    check_name TEXT,
    check_result TEXT,
    issue_count BIGINT
) AS $$
BEGIN
    RETURN QUERY EXECUTE format('
        SELECT
            ''Provenance Integrity Check'' AS check_name,
            CASE
                WHEN COUNT(*) FILTER (WHERE %I IS NULL) > 0
                THEN ''WARNING: Found records without provenance''
                ELSE ''PASS: All records have provenance''
            END AS check_result,
            COUNT(*) FILTER (WHERE %I IS NULL) AS issue_count
        FROM %I
    ', provenance_column, provenance_column, table_name);
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨æº¯æºå®Œæ•´æ€§æ£€æŸ¥å‡½æ•°
SELECT * FROM validate_provenance_integrity('sensor_data', 'provenance');

-- æ£€æŸ¥æ•°æ®å®Œæ•´æ€§çº¦æŸ
CREATE OR REPLACE FUNCTION check_integrity_constraints(
    table_name TEXT
) RETURNS TABLE (
    constraint_name TEXT,
    constraint_type TEXT,
    status TEXT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        conname::TEXT AS constraint_name,
        contype::TEXT AS constraint_type,
        CASE
            WHEN contype = 'c' THEN ''CHECK constraint''
            WHEN contype = 'f' THEN ''FOREIGN KEY constraint''
            WHEN contype = 'u' THEN ''UNIQUE constraint''
            WHEN contype = 'p' THEN ''PRIMARY KEY constraint''
            ELSE ''Other constraint''
        END AS status
    FROM pg_constraint
    WHERE conrelid = table_name::regclass;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨å®Œæ•´æ€§çº¦æŸæ£€æŸ¥å‡½æ•°
SELECT * FROM check_integrity_constraints('sensor_data');
```

### 7.6 å®æ–½å»ºè®®

#### **7.6.1 æ¸è¿›å¼å®æ–½**

**ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€å®ç°ï¼ˆ1-2å‘¨ï¼‰**

**ç›®æ ‡**ï¼šå»ºç«‹åŸºæœ¬çš„æ¦‚ç‡æ•°æ®åº“åŠŸèƒ½

**ä»»åŠ¡æ¸…å•**ï¼š

```sql
-- 1. åˆ›å»ºåŸºç¡€æ¦‚ç‡æ•°æ®ç±»å‹
CREATE TYPE probability_value AS (
    value NUMERIC,
    probability NUMERIC
);

-- 2. åˆ›å»ºåŸºç¡€è¡¨ç»“æ„
CREATE TABLE sensor_data (
    id SERIAL PRIMARY KEY,
    sensor_id INT NOT NULL,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1),
    timestamp TIMESTAMP DEFAULT NOW()
);

-- 3. å®ç°åŸºç¡€æ¦‚ç‡æŸ¥è¯¢å‡½æ•°
CREATE OR REPLACE FUNCTION probability_select(
    min_prob NUMERIC DEFAULT 0.5
) RETURNS TABLE (
    id INT,
    sensor_id INT,
    value NUMERIC,
    probability NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        sensor_data.id,
        sensor_data.sensor_id,
        sensor_data.value,
        sensor_data.probability
    FROM sensor_data
    WHERE sensor_data.probability >= min_prob;
END;
$$ LANGUAGE plpgsql;

-- 4. åˆ›å»ºåŸºç¡€ç´¢å¼•
CREATE INDEX idx_probability ON sensor_data(probability);
CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);

-- 5. æµ‹è¯•åŸºæœ¬åŠŸèƒ½
-- æ’å…¥æµ‹è¯•æ•°æ®
INSERT INTO sensor_data (sensor_id, value, probability)
VALUES
    (1, 25.5, 0.9),
    (1, 26.0, 0.8),
    (2, 30.0, 0.7);

-- æµ‹è¯•æ¦‚ç‡æŸ¥è¯¢
SELECT * FROM probability_select(0.8);
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- âœ… èƒ½å¤Ÿå­˜å‚¨æ¦‚ç‡æ•°æ®
- âœ… èƒ½å¤Ÿæ‰§è¡ŒåŸºç¡€æ¦‚ç‡æŸ¥è¯¢
- âœ… æ¦‚ç‡å€¼éªŒè¯æ­£å¸¸å·¥ä½œ
- âœ… åŸºç¡€ç´¢å¼•åˆ›å»ºæˆåŠŸ

**ç¬¬äºŒé˜¶æ®µï¼šä¼˜åŒ–ï¼ˆ2-3å‘¨ï¼‰**

**ç›®æ ‡**ï¼šä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½å’Œå­˜å‚¨ç»“æ„

**ä»»åŠ¡æ¸…å•**ï¼š

```sql
-- 1. ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
-- åˆ›å»ºç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW sensor_data_summary AS
SELECT
    sensor_id,
    COUNT(*) AS total_count,
    AVG(value) AS avg_value,
    SUM(value * probability) / SUM(probability) AS weighted_avg,
    AVG(probability) AS avg_probability
FROM sensor_data
GROUP BY sensor_id;

CREATE INDEX idx_summary_sensor ON sensor_data_summary(sensor_id);

-- 2. ä¼˜åŒ–å­˜å‚¨ç»“æ„
-- å®ç°è¡¨åˆ†åŒº
CREATE TABLE sensor_data_partitioned (
    LIKE sensor_data INCLUDING ALL
) PARTITION BY RANGE (probability);

CREATE TABLE sensor_data_high PARTITION OF sensor_data_partitioned
FOR VALUES FROM (0.8) TO (1.0);

CREATE TABLE sensor_data_medium PARTITION OF sensor_data_partitioned
FOR VALUES FROM (0.5) TO (0.8);

CREATE TABLE sensor_data_low PARTITION OF sensor_data_partitioned
FOR VALUES FROM (0.0) TO (0.5);

-- 3. å®ç°é«˜çº§åŠŸèƒ½
-- æ¦‚ç‡èšåˆå‡½æ•°
CREATE OR REPLACE FUNCTION probability_aggregate(
    values NUMERIC[],
    probabilities NUMERIC[]
) RETURNS NUMERIC AS $$
DECLARE
    weighted_sum NUMERIC := 0;
    total_prob NUMERIC := 0;
    i INT;
BEGIN
    FOR i IN 1..array_length(values, 1) LOOP
        weighted_sum := weighted_sum + values[i] * probabilities[i];
        total_prob := total_prob + probabilities[i];
    END LOOP;

    RETURN weighted_sum / NULLIF(total_prob, 0);
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- 4. æ€§èƒ½æµ‹è¯•
-- åŸºå‡†æµ‹è¯•è„šæœ¬
CREATE OR REPLACE FUNCTION benchmark_probability_queries()
RETURNS TABLE (
    query_name TEXT,
    execution_time INTERVAL,
    rows_returned BIGINT
) AS $$
DECLARE
    start_time TIMESTAMP;
    end_time TIMESTAMP;
    row_count BIGINT;
BEGIN
    -- æµ‹è¯•1ï¼šåŸºç¡€æ¦‚ç‡æŸ¥è¯¢
    start_time := clock_timestamp();
    SELECT COUNT(*) INTO row_count
    FROM sensor_data
    WHERE probability > 0.8;
    end_time := clock_timestamp();

    RETURN QUERY SELECT
        'Basic Probability Query'::TEXT,
        end_time - start_time,
        row_count;

    -- æµ‹è¯•2ï¼šæ¦‚ç‡èšåˆæŸ¥è¯¢
    start_time := clock_timestamp();
    SELECT COUNT(*) INTO row_count
    FROM sensor_data_summary;
    end_time := clock_timestamp();

    RETURN QUERY SELECT
        'Probability Aggregate Query'::TEXT,
        end_time - start_time,
        row_count;
END;
$$ LANGUAGE plpgsql;

-- è¿è¡ŒåŸºå‡†æµ‹è¯•
SELECT * FROM benchmark_probability_queries();
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- âœ… æŸ¥è¯¢æ€§èƒ½æå‡50%ä»¥ä¸Š
- âœ… å­˜å‚¨ç©ºé—´ä¼˜åŒ–20%ä»¥ä¸Š
- âœ… ç‰©åŒ–è§†å›¾æ­£å¸¸å·¥ä½œ
- âœ… åˆ†åŒºè¡¨æ­£å¸¸å·¥ä½œ
- âœ… é«˜çº§åŠŸèƒ½æµ‹è¯•é€šè¿‡

**ç¬¬ä¸‰é˜¶æ®µï¼šç”Ÿäº§éƒ¨ç½²ï¼ˆ1-2å‘¨ï¼‰**

**ç›®æ ‡**ï¼šéƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶æŒç»­ä¼˜åŒ–

**ä»»åŠ¡æ¸…å•**ï¼š

```sql
-- 1. ç”Ÿäº§ç¯å¢ƒé…ç½®
-- è®¾ç½®åˆç†çš„è¿æ¥æ± å¤§å°
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_buffers = '4GB';
ALTER SYSTEM SET effective_cache_size = '12GB';
ALTER SYSTEM SET maintenance_work_mem = '1GB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET default_statistics_target = 100;
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET effective_io_concurrency = 200;
ALTER SYSTEM SET work_mem = '16MB';
ALTER SYSTEM SET min_wal_size = '1GB';
ALTER SYSTEM SET max_wal_size = '4GB';

-- 2. ç›‘æ§æ€§èƒ½æŒ‡æ ‡
-- åˆ›å»ºæ€§èƒ½ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW performance_metrics AS
SELECT
    'Query Performance' AS metric_category,
    COUNT(*) AS total_queries,
    AVG(mean_exec_time) AS avg_execution_time,
    MAX(max_exec_time) AS max_execution_time
FROM pg_stat_statements
WHERE query LIKE '%sensor_data%';

-- 3. è®¾ç½®è‡ªåŠ¨ç»´æŠ¤ä»»åŠ¡
-- åˆ›å»ºè‡ªåŠ¨VACUUMé…ç½®
ALTER TABLE sensor_data SET (
    autovacuum_vacuum_scale_factor = 0.1,
    autovacuum_analyze_scale_factor = 0.05,
    autovacuum_vacuum_cost_delay = 20
);

-- 4. åˆ›å»ºç›‘æ§å‘Šè­¦
CREATE OR REPLACE FUNCTION check_performance_alerts()
RETURNS TABLE (
    alert_type TEXT,
    alert_message TEXT,
    severity TEXT
) AS $$
BEGIN
    -- æ£€æŸ¥æ…¢æŸ¥è¯¢
    RETURN QUERY
    SELECT
        'Slow Query'::TEXT,
        format('Query execution time: %s ms', mean_exec_time),
        CASE
            WHEN mean_exec_time > 1000 THEN 'HIGH'
            WHEN mean_exec_time > 500 THEN 'MEDIUM'
            ELSE 'LOW'
        END
    FROM pg_stat_statements
    WHERE mean_exec_time > 500
    ORDER BY mean_exec_time DESC
    LIMIT 10;

    -- æ£€æŸ¥å­˜å‚¨ç©ºé—´
    RETURN QUERY
    SELECT
        'Storage Space'::TEXT,
        format('Table size: %s', pg_size_pretty(pg_total_relation_size('sensor_data'))),
        CASE
            WHEN pg_total_relation_size('sensor_data') > 10737418240 THEN 'HIGH'  -- 10GB
            WHEN pg_total_relation_size('sensor_data') > 5368709120 THEN 'MEDIUM'  -- 5GB
            ELSE 'LOW'
        END;
END;
$$ LANGUAGE plpgsql;

-- è¿è¡Œç›‘æ§å‘Šè­¦
SELECT * FROM check_performance_alerts();
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- âœ… ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æˆåŠŸ
- âœ… æ€§èƒ½ç›‘æ§æ­£å¸¸å·¥ä½œ
- âœ… è‡ªåŠ¨ç»´æŠ¤ä»»åŠ¡é…ç½®æˆåŠŸ
- âœ… ç›‘æ§å‘Šè­¦æ­£å¸¸å·¥ä½œ
- âœ… ç³»ç»Ÿç¨³å®šè¿è¡Œ

#### **7.6.2 å›¢é˜ŸåŸ¹è®­**

**1. æŠ€æœ¯åŸ¹è®­**

**åŸ¹è®­å†…å®¹**ï¼š

**æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®ºï¼ˆ4å°æ—¶ï¼‰**

- æ¦‚ç‡æ•°æ®åº“æ¦‚å¿µå’ŒåŸç†
- ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹
- æ¦‚ç‡æŸ¥è¯¢å¤„ç†
- å¯èƒ½ä¸–ç•Œè¯­ä¹‰

**PostgreSQLæ‰©å±•å¼€å‘ï¼ˆ8å°æ—¶ï¼‰**

- PostgreSQLæ‰©å±•æ¶æ„
- è‡ªå®šä¹‰æ•°æ®ç±»å‹å¼€å‘
- è‡ªå®šä¹‰æ“ä½œç¬¦å’Œå‡½æ•°å¼€å‘
- æŸ¥è¯¢ä¼˜åŒ–å™¨æ‰©å±•

**ProvSQLä½¿ç”¨ï¼ˆ4å°æ—¶ï¼‰**

- ProvSQLå®‰è£…å’Œé…ç½®
- ProvSQLæ ¸å¿ƒåŠŸèƒ½
- ProvSQLä½¿ç”¨ç¤ºä¾‹
- ProvSQLæœ€ä½³å®è·µ

**åŸ¹è®­ææ–™**ï¼š

```sql
-- åŸ¹è®­ç¤ºä¾‹ï¼šæ¦‚ç‡æ•°æ®åº“åŸºç¡€
-- 1. åˆ›å»ºæ¦‚ç‡æ•°æ®è¡¨
CREATE TABLE training_data (
    id SERIAL PRIMARY KEY,
    value NUMERIC NOT NULL,
    probability NUMERIC CHECK (probability >= 0 AND probability <= 1)
);

-- 2. æ’å…¥ç¤ºä¾‹æ•°æ®
INSERT INTO training_data (value, probability)
VALUES
    (10, 0.9),
    (20, 0.8),
    (30, 0.7);

-- 3. æ¦‚ç‡æŸ¥è¯¢ç¤ºä¾‹
SELECT
    value,
    probability,
    value * probability AS weighted_value
FROM training_data
WHERE probability > 0.75;

-- 4. æ¦‚ç‡èšåˆç¤ºä¾‹
SELECT
    COUNT(*) AS total_count,
    AVG(value) AS avg_value,
    SUM(value * probability) / SUM(probability) AS weighted_avg
FROM training_data;
```

**2. æœ€ä½³å®è·µåŸ¹è®­**

**åŸ¹è®­å†…å®¹**ï¼š

**è®¾è®¡åŸåˆ™ï¼ˆ2å°æ—¶ï¼‰**

- æ¦‚ç‡å€¼è®¾è®¡åŸåˆ™
- æ•°æ®æ¨¡å‹è®¾è®¡åŸåˆ™
- ç´¢å¼•è®¾è®¡åŸåˆ™
- çº¦æŸè®¾è®¡åŸåˆ™

**æ€§èƒ½ä¼˜åŒ–æŠ€å·§ï¼ˆ4å°æ—¶ï¼‰**

- æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§
- å­˜å‚¨ä¼˜åŒ–æŠ€å·§
- ç´¢å¼•ä¼˜åŒ–æŠ€å·§
- ç¼“å­˜ç­–ç•¥

**å¸¸è§é—®é¢˜è§£å†³ï¼ˆ2å°æ—¶ï¼‰**

- æ¦‚ç‡å€¼ä¸ä¸€è‡´é—®é¢˜
- æ€§èƒ½é—®é¢˜
- å­˜å‚¨ç©ºé—´é—®é¢˜
- æ•°æ®è´¨é‡é—®é¢˜

**åŸ¹è®­ææ–™**ï¼š

```sql
-- åŸ¹è®­ç¤ºä¾‹ï¼šæ€§èƒ½ä¼˜åŒ–
-- 1. æŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹
-- ä¼˜åŒ–å‰
SELECT * FROM sensor_data WHERE probability > 0.8;

-- ä¼˜åŒ–å
SELECT * FROM sensor_data
WHERE probability > 0.8
ORDER BY probability DESC
LIMIT 100;

-- 2. ç´¢å¼•ä¼˜åŒ–ç¤ºä¾‹
CREATE INDEX idx_probability ON sensor_data(probability);
CREATE INDEX idx_sensor_prob ON sensor_data(sensor_id, probability);

-- 3. ç‰©åŒ–è§†å›¾ä¼˜åŒ–ç¤ºä¾‹
CREATE MATERIALIZED VIEW sensor_data_summary AS
SELECT
    sensor_id,
    COUNT(*) AS total_count,
    AVG(value) AS avg_value
FROM sensor_data
GROUP BY sensor_id;
```

#### **7.6.3 ç›‘æ§å’Œç»´æŠ¤**

**1. æ€§èƒ½ç›‘æ§**

```sql
-- åˆ›å»ºæ€§èƒ½ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW performance_monitoring AS
SELECT
    'Query Performance' AS metric_type,
    COUNT(*) AS total_queries,
    AVG(mean_exec_time) AS avg_execution_time_ms,
    MAX(max_exec_time) AS max_execution_time_ms,
    SUM(calls) AS total_calls
FROM pg_stat_statements
WHERE query LIKE '%sensor_data%';

-- æŸ¥è¯¢æ€§èƒ½ç›‘æ§
SELECT * FROM performance_monitoring;

-- åˆ›å»ºå­˜å‚¨ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW storage_monitoring AS
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
    pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) AS indexes_size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- æŸ¥è¯¢å­˜å‚¨ç›‘æ§
SELECT * FROM storage_monitoring;

-- åˆ›å»ºç³»ç»Ÿèµ„æºç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW system_resource_monitoring AS
SELECT
    'Database Connections' AS resource_type,
    COUNT(*) AS current_connections,
    (SELECT setting::INT FROM pg_settings WHERE name = 'max_connections') AS max_connections,
    ROUND(COUNT(*)::NUMERIC / (SELECT setting::INT FROM pg_settings WHERE name = 'max_connections') * 100, 2) AS connection_usage_percent
FROM pg_stat_activity
WHERE datname = current_database();

-- æŸ¥è¯¢ç³»ç»Ÿèµ„æºç›‘æ§
SELECT * FROM system_resource_monitoring;
```

**2. æ•°æ®è´¨é‡ç›‘æ§**

```sql
-- åˆ›å»ºæ•°æ®è´¨é‡ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW data_quality_monitoring AS
SELECT
    'Probability Quality' AS quality_metric,
    COUNT(*) AS total_records,
    COUNT(*) FILTER (WHERE probability >= 0 AND probability <= 1) AS valid_probability_count,
    COUNT(*) FILTER (WHERE probability < 0 OR probability > 1) AS invalid_probability_count,
    COUNT(*) FILTER (WHERE probability IS NULL) AS null_probability_count,
    AVG(probability) AS avg_probability,
    STDDEV(probability) AS stddev_probability
FROM sensor_data;

-- æŸ¥è¯¢æ•°æ®è´¨é‡ç›‘æ§
SELECT * FROM data_quality_monitoring;

-- åˆ›å»ºæ•°æ®ä¸€è‡´æ€§ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW data_consistency_monitoring AS
SELECT
    'Data Consistency' AS consistency_metric,
    COUNT(*) AS total_records,
    COUNT(*) FILTER (WHERE value IS NOT NULL AND probability IS NOT NULL) AS consistent_records,
    COUNT(*) FILTER (WHERE (value IS NULL AND probability IS NOT NULL) OR
                            (value IS NOT NULL AND probability IS NULL)) AS inconsistent_records
FROM sensor_data;

-- æŸ¥è¯¢æ•°æ®ä¸€è‡´æ€§ç›‘æ§
SELECT * FROM data_consistency_monitoring;

-- åˆ›å»ºæº¯æºä¿¡æ¯å®Œæ•´æ€§ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW provenance_integrity_monitoring AS
SELECT
    'Provenance Integrity' AS integrity_metric,
    COUNT(*) AS total_records,
    COUNT(*) FILTER (WHERE provenance IS NOT NULL) AS records_with_provenance,
    COUNT(*) FILTER (WHERE provenance IS NULL) AS records_without_provenance
FROM sensor_data;

-- æŸ¥è¯¢æº¯æºä¿¡æ¯å®Œæ•´æ€§ç›‘æ§
SELECT * FROM provenance_integrity_monitoring;
```

**3. å®šæœŸç»´æŠ¤**

```sql
-- åˆ›å»ºå®šæœŸç»´æŠ¤å‡½æ•°
CREATE OR REPLACE FUNCTION perform_maintenance()
RETURNS TABLE (
    maintenance_task TEXT,
    status TEXT,
    execution_time INTERVAL
) AS $$
DECLARE
    start_time TIMESTAMP;
    end_time TIMESTAMP;
BEGIN
    -- 1. ä¼˜åŒ–ç´¢å¼•
    start_time := clock_timestamp();
    REINDEX INDEX CONCURRENTLY idx_probability;
    REINDEX INDEX CONCURRENTLY idx_sensor_prob;
    end_time := clock_timestamp();

    RETURN QUERY SELECT
        'Index Optimization'::TEXT,
        'COMPLETED'::TEXT,
        end_time - start_time;

    -- 2. æ¸…ç†æ•°æ®
    start_time := clock_timestamp();
    DELETE FROM sensor_data
    WHERE timestamp < NOW() - INTERVAL '2 years'
      AND probability < 0.1;
    end_time := clock_timestamp();

    RETURN QUERY SELECT
        'Data Cleanup'::TEXT,
        'COMPLETED'::TEXT,
        end_time - start_time;

    -- 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    start_time := clock_timestamp();
    ANALYZE sensor_data;
    end_time := clock_timestamp();

    RETURN QUERY SELECT
        'Statistics Update'::TEXT,
        'COMPLETED'::TEXT,
        end_time - start_time;

    -- 4. åˆ·æ–°ç‰©åŒ–è§†å›¾
    start_time := clock_timestamp();
    REFRESH MATERIALIZED VIEW CONCURRENTLY sensor_data_summary;
    end_time := clock_timestamp();

    RETURN QUERY SELECT
        'Materialized View Refresh'::TEXT,
        'COMPLETED'::TEXT,
        end_time - start_time;

    -- 5. VACUUM
    start_time := clock_timestamp();
    VACUUM ANALYZE sensor_data;
    end_time := clock_timestamp();

    RETURN QUERY SELECT
        'VACUUM'::TEXT,
        'COMPLETED'::TEXT,
        end_time - start_time;
END;
$$ LANGUAGE plpgsql;

-- æ‰§è¡Œå®šæœŸç»´æŠ¤
SELECT * FROM perform_maintenance();

-- åˆ›å»ºè‡ªåŠ¨ç»´æŠ¤è®¡åˆ’ï¼ˆä½¿ç”¨pg_cronæ‰©å±•ï¼‰
-- æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œç»´æŠ¤ä»»åŠ¡
SELECT cron.schedule(
    'daily-maintenance',
    '0 2 * * *',
    'SELECT * FROM perform_maintenance()'
);
```

---

## 8. å‚è€ƒèµ„æ–™

### 8.1 å­¦æœ¯è®ºæ–‡

#### **8.1.1 æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®º**

1. **Foundations of Probabilistic Databases**
   - ä½œè€…: Suciu, D., Olteanu, D., RÃ©, C., & Koch, C.
   - æœŸåˆŠ: VLDB Journal, 20(5), 659-684, 2011
   - æ‘˜è¦: æ¦‚ç‡æ•°æ®åº“çš„åŸºç¡€ç†è®ºå’Œæ¨¡å‹
   - é‡è¦æ€§: â­â­â­â­â­ æ¦‚ç‡æ•°æ®åº“é¢†åŸŸçš„ç»å…¸è®ºæ–‡

2. **Efficient Query Evaluation on Probabilistic Databases**
   - ä½œè€…: Dalvi, N., & Suciu, D.
   - ä¼šè®®: VLDB 2007
   - æ‘˜è¦: æ¦‚ç‡æ•°æ®åº“æŸ¥è¯¢è¯„ä¼°çš„ä¼˜åŒ–æ–¹æ³•
   - é‡è¦æ€§: â­â­â­â­â­ æŸ¥è¯¢ä¼˜åŒ–çš„é‡è¦è®ºæ–‡

3. **Probabilistic Databases: The Diamonds and the Rough**
   - ä½œè€…: Suciu, D., & Olteanu, D.
   - ä¼šè®®: CIDR 2011
   - æ‘˜è¦: æ¦‚ç‡æ•°æ®åº“çš„æŒ‘æˆ˜å’Œæœºé‡

#### **8.1.2 ProvSQLå’Œæ•°æ®æº¯æº**

1. **ProvSQL: Provenance and Probability Management in PostgreSQL**
   - ä½œè€…: Senellart, P., Jaudoin, H., & Galland, A.
   - ä¼šè®®: SIGMOD 2018
   - æ‘˜è¦: ProvSQLåœ¨PostgreSQLä¸­çš„å®ç°
   - GitHub: [https://github.com/PierreSenellart/provsql](https://github.com/PierreSenellart/provsql)
   - é‡è¦æ€§: â­â­â­â­â­ ProvSQLçš„æ ¸å¿ƒè®ºæ–‡

2. **Provenance in Databases: Why, How, and Where**
   - ä½œè€…: Cheney, J., Chiticariu, L., & Tan, W. C.
   - æœŸåˆŠ: Foundations and Trends in Databases, 2009
   - æ‘˜è¦: æ•°æ®åº“æº¯æºçš„åŸºç¡€ç†è®º

3. **Provenance Semirings**
   - ä½œè€…: Green, T. J., Karvounarakis, G., & Tannen, V.
   - ä¼šè®®: PODS 2007
   - æ‘˜è¦: æº¯æºåŠç¯ç†è®º

#### **8.1.3 ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†**

1. **Managing Uncertainty in Data Integration**
   - ä½œè€…: Dong, X. L., & Srivastava, D.
   - ä¼šè®®: ICDE 2013
   - æ‘˜è¦: æ•°æ®é›†æˆä¸­çš„ä¸ç¡®å®šæ€§ç®¡ç†

2. **Probabilistic Data Integration**
   - ä½œè€…: Re, C., & Suciu, D.
   - ä¼šè®®: ICDT 2008
   - æ‘˜è¦: æ¦‚ç‡æ•°æ®é›†æˆæ–¹æ³•

### 8.2 å®˜æ–¹æ–‡æ¡£

#### **8.2.1 PostgreSQLæ–‡æ¡£**

1. **PostgreSQL Extension Development**
   - é“¾æ¥: [https://www.postgresql.org/docs/current/extend.html](https://www.postgresql.org/docs/current/extend.html)
   - å†…å®¹: PostgreSQLæ‰©å±•å¼€å‘æŒ‡å—
   - ç« èŠ‚:
     - æ‰©å±•æ¶æ„
     - æ•°æ®ç±»å‹æ‰©å±•
     - å‡½æ•°å’Œæ“ä½œç¬¦
     - ç´¢å¼•æ‰©å±•

2. **PostgreSQL Data Types**
   - é“¾æ¥: [https://www.postgresql.org/docs/current/datatype.html](https://www.postgresql.org/docs/current/datatype.html)
   - å†…å®¹: PostgreSQLæ•°æ®ç±»å‹æ–‡æ¡£

3. **PostgreSQL Functions and Operators**
   - é“¾æ¥: [https://www.postgresql.org/docs/current/functions.html](https://www.postgresql.org/docs/current/functions.html)
   - å†…å®¹: PostgreSQLå‡½æ•°å’Œæ“ä½œç¬¦æ–‡æ¡£

#### **8.2.2 ProvSQLæ–‡æ¡£**

1. **ProvSQL GitHub Repository**
   - é“¾æ¥: [https://github.com/PierreSenellart/provsql](https://github.com/PierreSenellart/provsql)
   - å†…å®¹: ProvSQLæºä»£ç å’Œæ–‡æ¡£
   - åŠŸèƒ½:
     - æ•°æ®æº¯æºç®¡ç†
     - æ¦‚ç‡è®¡ç®—
     - PostgreSQLé›†æˆ

2. **ProvSQL Documentation**
   - é“¾æ¥: [https://github.com/PierreSenellart/provsql/blob/master/README.md](https://github.com/PierreSenellart/provsql/blob/master/README.md)
   - å†…å®¹: ProvSQLä½¿ç”¨æ–‡æ¡£å’Œç¤ºä¾‹

### 8.3 å¼€æºé¡¹ç›®å’Œå·¥å…·

#### **8.3.1 æ¦‚ç‡æ•°æ®åº“é¡¹ç›®**

1. **ProvSQL**
   - GitHub: [https://github.com/PierreSenellart/provsql](https://github.com/PierreSenellart/provsql)
   - è¯­è¨€: C/C++
   - åŠŸèƒ½: PostgreSQLçš„æº¯æºå’Œæ¦‚ç‡ç®¡ç†æ‰©å±•
   - çŠ¶æ€: âœ… æ´»è·ƒç»´æŠ¤

2. **MystiQ**
   - GitHub: [https://github.com/dan-suciu/mystiq](https://github.com/dan-suciu/mystiq)
   - è¯­è¨€: C++
   - åŠŸèƒ½: æ¦‚ç‡æŸ¥è¯¢å¤„ç†å¼•æ“
   - çŠ¶æ€: âœ… æ´»è·ƒç»´æŠ¤

3. **MayBMS**
   - é¡¹ç›®: æ¦‚ç‡æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ
   - åŠŸèƒ½: å®Œæ•´çš„æ¦‚ç‡æ•°æ®åº“ç³»ç»Ÿ
   - çŠ¶æ€: âš ï¸ å·²åœæ­¢ç»´æŠ¤

#### **8.3.2 ç›¸å…³å·¥å…·**

1. **PostgreSQLæ‰©å±•å¼€å‘å·¥å…·**
   - **pgxs**: PostgreSQLæ‰©å±•æ„å»ºç³»ç»Ÿ
     - æ–‡æ¡£: [https://www.postgresql.org/docs/current/extend-pgxs.html](https://www.postgresql.org/docs/current/extend-pgxs.html)
     - åŠŸèƒ½: ç®€åŒ–PostgreSQLæ‰©å±•çš„æ„å»ºå’Œå®‰è£…
     - ç”¨é€”: å¼€å‘PostgreSQLæ‰©å±•

   - **pg_config**: PostgreSQLé…ç½®å·¥å…·
     - åŠŸèƒ½: æŸ¥è¯¢PostgreSQLé…ç½®ä¿¡æ¯
     - ç”¨é€”: è·å–ç¼–è¯‘å’Œé“¾æ¥ä¿¡æ¯

   - **pg_regress**: PostgreSQLå›å½’æµ‹è¯•å·¥å…·
     - åŠŸèƒ½: è¿è¡Œå›å½’æµ‹è¯•
     - ç”¨é€”: æµ‹è¯•PostgreSQLæ‰©å±•

2. **æ•°æ®æº¯æºå·¥å…·**
   - **OpenProvenance**: å¼€æºæº¯æºå·¥å…·
     - é“¾æ¥: [http://openprovenance.org/](http://openprovenance.org/)
     - åŠŸèƒ½: æ•°æ®æº¯æºç®¡ç†å’Œå¯è§†åŒ–
     - ç”¨é€”: æ•°æ®æº¯æºç ”ç©¶å’Œåº”ç”¨

   - **W3C PROV**: æº¯æºæ•°æ®æ¨¡å‹æ ‡å‡†
     - é“¾æ¥: [https://www.w3.org/TR/prov-overview/](https://www.w3.org/TR/prov-overview/)
     - åŠŸèƒ½: æ ‡å‡†åŒ–çš„æº¯æºæ•°æ®æ¨¡å‹
     - ç”¨é€”: æ•°æ®æº¯æºæ ‡å‡†åŒ–

3. **æ¦‚ç‡è®¡ç®—å·¥å…·**
   - **NumPy/SciPy**: Pythonç§‘å­¦è®¡ç®—åº“
     - åŠŸèƒ½: æ¦‚ç‡è®¡ç®—å’Œç»Ÿè®¡åˆ†æ
     - ç”¨é€”: æ¦‚ç‡è®¡ç®—å’Œæ•°æ®åˆ†æ

   - **R**: ç»Ÿè®¡è®¡ç®—è¯­è¨€
     - åŠŸèƒ½: æ¦‚ç‡ç»Ÿè®¡å’Œæ•°æ®åˆ†æ
     - ç”¨é€”: æ¦‚ç‡åˆ†æå’Œç»Ÿè®¡å»ºæ¨¡

4. **æ•°æ®åº“ç®¡ç†å·¥å…·**
   - **pgAdmin**: PostgreSQLç®¡ç†å·¥å…·
     - é“¾æ¥: [https://www.pgadmin.org/](https://www.pgadmin.org/)
     - åŠŸèƒ½: PostgreSQLå¯è§†åŒ–ç®¡ç†
     - ç”¨é€”: æ•°æ®åº“ç®¡ç†å’ŒæŸ¥è¯¢

   - **DBeaver**: é€šç”¨æ•°æ®åº“ç®¡ç†å·¥å…·
     - é“¾æ¥: [https://dbeaver.io/](https://dbeaver.io/)
     - åŠŸèƒ½: å¤šæ•°æ®åº“ç®¡ç†å·¥å…·
     - ç”¨é€”: æ•°æ®åº“ç®¡ç†å’ŒæŸ¥è¯¢

5. **æ€§èƒ½åˆ†æå·¥å…·**
   - **pg_stat_statements**: PostgreSQLæŸ¥è¯¢ç»Ÿè®¡æ‰©å±•
     - åŠŸèƒ½: æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡å’Œåˆ†æ
     - ç”¨é€”: æ€§èƒ½åˆ†æå’Œä¼˜åŒ–

   - **EXPLAIN (ANALYZE, BUFFERS, TIMING)**: PostgreSQLæ‰§è¡Œè®¡åˆ’åˆ†æ
     - åŠŸèƒ½: æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’åˆ†æ
     - ç”¨é€”: æŸ¥è¯¢ä¼˜åŒ–

### 8.4 ç¤¾åŒºèµ„æº

#### **8.4.1 è®ºå›å’Œç¤¾åŒº**

1. **PostgreSQLå®˜æ–¹è®ºå›**
   - é“¾æ¥: [https://www.postgresql.org/list/](https://www.postgresql.org/list/)
   - å†…å®¹: PostgreSQLé‚®ä»¶åˆ—è¡¨å’Œè®ºå›
   - æ ‡ç­¾: extension, probabilistic

2. **Stack Overflow**
   - æ ‡ç­¾: [postgresql](https://stackoverflow.com/questions/tagged/postgresql), [probabilistic-database](https://stackoverflow.com/questions/tagged/probabilistic-database)
   - å†…å®¹: æŠ€æœ¯é—®ç­”

3. **Reddit - r/PostgreSQL**
   - é“¾æ¥: [https://www.reddit.com/r/PostgreSQL/](https://www.reddit.com/r/PostgreSQL/)
   - å†…å®¹: PostgreSQLç¤¾åŒºè®¨è®º

#### **8.4.2 åšå®¢å’Œæ–‡ç« **

1. **æ¦‚ç‡æ•°æ®åº“åšå®¢**
   - **å†…å®¹**: æ¦‚ç‡æ•°æ®åº“åº”ç”¨æ¡ˆä¾‹å’Œæœ€ä½³å®è·µ
   - **æ¨èåšå®¢**:
     - [Towards Data Science - Probabilistic Databases](https://towardsdatascience.com/tagged/probabilistic-database)
     - [KDnuggets - Uncertainty in Data](https://www.kdnuggets.com/tag/uncertainty)
   - **æ›´æ–°é¢‘ç‡**: å®šæœŸæ›´æ–°
   - **é‡è¦æ€§**: â­â­â­â­ æ¦‚ç‡æ•°æ®åº“åº”ç”¨å®è·µ

2. **æ•°æ®æº¯æºåšå®¢**
   - **å†…å®¹**: æ•°æ®æº¯æºæŠ€æœ¯å’Œåº”ç”¨
   - **æ¨èåšå®¢**:
     - [Data Provenance Blog](https://example.com/data-provenance-blog)
     - [W3C PROV Blog](https://www.w3.org/blog/prov/)
   - **æ›´æ–°é¢‘ç‡**: å®šæœŸæ›´æ–°
   - **é‡è¦æ€§**: â­â­â­â­ æ•°æ®æº¯æºæŠ€æœ¯å®è·µ

3. **PostgreSQLæ‰©å±•å¼€å‘åšå®¢**
   - **å†…å®¹**: PostgreSQLæ‰©å±•å¼€å‘æ•™ç¨‹
   - **æ¨èåšå®¢**:
     - [Planet PostgreSQL](https://planet.postgresql.org/)
     - [PostgreSQL Weekly](https://postgresweekly.com/)
   - **æ›´æ–°é¢‘ç‡**: å®šæœŸæ›´æ–°
   - **é‡è¦æ€§**: â­â­â­â­ PostgreSQLæ‰©å±•å¼€å‘å®è·µ

4. **æ•°æ®åº“æŠ€æœ¯åšå®¢**
   - **å†…å®¹**: æ•°æ®åº“æŠ€æœ¯æ–‡ç« å’Œæœ€ä½³å®è·µ
   - **æ¨èåšå®¢**:
     - [High Scalability](http://highscalability.com/)
     - [Database Journal](https://www.databasejournal.com/)
   - **æ›´æ–°é¢‘ç‡**: å®šæœŸæ›´æ–°
   - **é‡è¦æ€§**: â­â­â­ æ•°æ®åº“æŠ€æœ¯å‚è€ƒ

5. **æ•°æ®ç§‘å­¦åšå®¢**
   - **å†…å®¹**: æ•°æ®ç§‘å­¦å’Œä¸ç¡®å®šæ€§æ•°æ®å¤„ç†
   - **æ¨èåšå®¢**:
     - [Towards Data Science](https://towardsdatascience.com/)
     - [KDnuggets](https://www.kdnuggets.com/)
   - **æ›´æ–°é¢‘ç‡**: å®šæœŸæ›´æ–°
   - **é‡è¦æ€§**: â­â­â­ æ•°æ®ç§‘å­¦ç›¸å…³å†…å®¹

### 8.5 ä¹¦ç±æ¨è

#### **8.5.1 æ¦‚ç‡æ•°æ®åº“ç›¸å…³ä¹¦ç±**

1. **ã€Šæ¦‚ç‡æ•°æ®åº“åŸºç¡€ã€‹ï¼ˆFoundations of Probabilistic Databasesï¼‰**
   - ä½œè€…: Suciu, D., Olteanu, D., RÃ©, C., & Koch, C.
   - å‡ºç‰ˆç¤¾: Morgan & Claypool Publishers
   - å‡ºç‰ˆå¹´ä»½: 2011
   - ISBN: 978-1608456802
   - å†…å®¹: æ¦‚ç‡æ•°æ®åº“ç†è®ºå’Œå®è·µï¼ŒåŒ…æ‹¬å¯èƒ½ä¸–ç•Œè¯­ä¹‰ã€æ¦‚ç‡æŸ¥è¯¢å¤„ç†ã€ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹
   - é€‚åˆ: ç ”ç©¶äººå‘˜å’Œé«˜çº§å¼€å‘è€…
   - é‡è¦æ€§: â­â­â­â­â­ æ¦‚ç‡æ•°æ®åº“é¢†åŸŸçš„ç»å…¸æ•™æ

2. **ã€Šä¸ç¡®å®šæ€§æ•°æ®ç®¡ç†ã€‹ï¼ˆManaging and Mining Uncertain Dataï¼‰**
   - ä½œè€…: Aggarwal, C. C.
   - å‡ºç‰ˆç¤¾: Springer
   - å‡ºç‰ˆå¹´ä»½: 2009
   - ISBN: 978-1441901968
   - å†…å®¹: ä¸ç¡®å®šæ€§æ•°æ®ç®¡ç†æŠ€æœ¯ï¼ŒåŒ…æ‹¬æ•°æ®æ¨¡å‹ã€æŸ¥è¯¢å¤„ç†ã€æŒ–æ˜ç®—æ³•
   - é€‚åˆ: ç ”ç©¶äººå‘˜å’Œé«˜çº§å¼€å‘è€…
   - é‡è¦æ€§: â­â­â­â­ ä¸ç¡®å®šæ€§æ•°æ®ç®¡ç†é¢†åŸŸçš„æƒå¨å‚è€ƒ

#### **8.5.2 PostgreSQLç›¸å…³ä¹¦ç±**

1. **ã€ŠPostgreSQLæ‰©å±•å¼€å‘ã€‹ï¼ˆPostgreSQL Extension Developmentï¼‰**
   - ä½œè€…: PostgreSQLç¤¾åŒº
   - å†…å®¹: PostgreSQLæ‰©å±•å¼€å‘å®è·µï¼ŒåŒ…æ‹¬æ•°æ®ç±»å‹ã€å‡½æ•°ã€æ“ä½œç¬¦ã€ç´¢å¼•æ‰©å±•
   - é€‚åˆ: å¼€å‘è€…
   - é‡è¦æ€§: â­â­â­â­ PostgreSQLæ‰©å±•å¼€å‘å®˜æ–¹æŒ‡å—

2. **ã€ŠPostgreSQLï¼šé«˜çº§SQLç¼–ç¨‹ã€‹ï¼ˆPostgreSQL: Up and Runningï¼‰**
   - ä½œè€…: Obe, R., & Hsu, L.
   - å‡ºç‰ˆç¤¾: O'Reilly Media
   - å‡ºç‰ˆå¹´ä»½: 2017
   - ISBN: 978-1491963418
   - å†…å®¹: PostgreSQLé«˜çº§ç‰¹æ€§ï¼ŒåŒ…æ‹¬æ‰©å±•ã€æ€§èƒ½ä¼˜åŒ–ã€é«˜çº§SQL
   - é€‚åˆ: å¼€å‘è€…
   - é‡è¦æ€§: â­â­â­â­ PostgreSQLå®ç”¨æŒ‡å—

3. **ã€ŠPostgreSQLæ€§èƒ½ä¼˜åŒ–ã€‹ï¼ˆPostgreSQL High Performanceï¼‰**
   - ä½œè€…: Krosing, G., & Roybal, K.
   - å‡ºç‰ˆç¤¾: Packt Publishing
   - å‡ºç‰ˆå¹´ä»½: 2018
   - ISBN: 978-1788624331
   - å†…å®¹: PostgreSQLæ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ï¼ŒåŒ…æ‹¬æŸ¥è¯¢ä¼˜åŒ–ã€ç´¢å¼•ä¼˜åŒ–ã€é…ç½®è°ƒä¼˜
   - é€‚åˆ: DBAå’Œæ€§èƒ½ä¼˜åŒ–å·¥ç¨‹å¸ˆ
   - é‡è¦æ€§: â­â­â­â­ PostgreSQLæ€§èƒ½ä¼˜åŒ–å‚è€ƒ

#### **8.5.3 æ•°æ®æº¯æºç›¸å…³ä¹¦ç±**

1. **ã€Šæ•°æ®æº¯æºï¼šç†è®ºä¸å®è·µã€‹ï¼ˆData Provenance: Theory and Practiceï¼‰**
   - ä½œè€…: Buneman, P., & Tan, W. C.
   - å†…å®¹: æ•°æ®æº¯æºç†è®ºå’Œå®è·µï¼ŒåŒ…æ‹¬æº¯æºæ¨¡å‹ã€æŸ¥è¯¢å¤„ç†ã€åº”ç”¨åœºæ™¯
   - é€‚åˆ: ç ”ç©¶äººå‘˜
   - é‡è¦æ€§: â­â­â­â­ æ•°æ®æº¯æºé¢†åŸŸçš„ç»å…¸å‚è€ƒ

2. **ã€Šæ•°æ®æ²»ç†ï¼šç†è®ºä¸å®è·µã€‹ï¼ˆData Governance: Theory and Practiceï¼‰**
   - ä½œè€…: Seiner, R. S.
   - å‡ºç‰ˆç¤¾: Technics Publications
   - å‡ºç‰ˆå¹´ä»½: 2014
   - ISBN: 978-1634620005
   - å†…å®¹: æ•°æ®æ²»ç†ç†è®ºå’Œå®è·µï¼ŒåŒ…æ‹¬æ•°æ®è´¨é‡ã€æ•°æ®æº¯æºã€åˆè§„æ€§
   - é€‚åˆ: æ•°æ®æ²»ç†ä¸“å®¶å’Œä¼ä¸šç”¨æˆ·
   - é‡è¦æ€§: â­â­â­â­ æ•°æ®æ²»ç†å®ç”¨æŒ‡å—

#### **8.5.4 æ•°æ®åº“ç†è®ºç›¸å…³ä¹¦ç±**

1. **ã€Šæ•°æ®åº“ç³»ç»Ÿæ¦‚å¿µã€‹ï¼ˆDatabase System Conceptsï¼‰**
   - ä½œè€…: Silberschatz, A., Korth, H. F., & Sudarshan, S.
   - å‡ºç‰ˆç¤¾: McGraw-Hill Education
   - å‡ºç‰ˆå¹´ä»½: 2019 (ç¬¬7ç‰ˆ)
   - ISBN: 978-0078022159
   - å†…å®¹: æ•°æ®åº“ç³»ç»ŸåŸºç¡€ç†è®ºï¼ŒåŒ…æ‹¬æ•°æ®æ¨¡å‹ã€æŸ¥è¯¢å¤„ç†ã€äº‹åŠ¡ç®¡ç†
   - é€‚åˆ: å­¦ç”Ÿå’Œç ”ç©¶äººå‘˜
   - é‡è¦æ€§: â­â­â­â­â­ æ•°æ®åº“ç³»ç»Ÿç»å…¸æ•™æ

2. **ã€Šæ•°æ®åº“ç³»ç»Ÿå®ç°ã€‹ï¼ˆDatabase System Implementationï¼‰**
   - ä½œè€…: Garcia-Molina, H., Ullman, J. D., & Widom, J.
   - å‡ºç‰ˆç¤¾: Prentice Hall
   - å‡ºç‰ˆå¹´ä»½: 2008
   - ISBN: 978-0130402648
   - å†…å®¹: æ•°æ®åº“ç³»ç»Ÿå®ç°æŠ€æœ¯ï¼ŒåŒ…æ‹¬å­˜å‚¨ç®¡ç†ã€æŸ¥è¯¢å¤„ç†ã€äº‹åŠ¡å¤„ç†
   - é€‚åˆ: é«˜çº§å¼€å‘è€…å’Œç ”ç©¶äººå‘˜
   - é‡è¦æ€§: â­â­â­â­â­ æ•°æ®åº“ç³»ç»Ÿå®ç°æƒå¨å‚è€ƒ

### 8.6 è§†é¢‘æ•™ç¨‹

#### **8.6.1 ProvSQLç›¸å…³è§†é¢‘**

1. **ProvSQLæ¼”ç¤ºè§†é¢‘**
   - å¹³å°: YouTube / ä¼šè®®è§†é¢‘
   - å†…å®¹: ProvSQLä½¿ç”¨æ¼”ç¤ºå’Œæ•™ç¨‹
   - é“¾æ¥: [ProvSQL GitHub](https://github.com/PierreSenellart/provsql) (æŸ¥çœ‹READMEä¸­çš„æ¼”ç¤ºé“¾æ¥)
   - æ—¶é•¿: 30-60åˆ†é’Ÿ
   - é€‚åˆ: åˆå­¦è€…å’Œå¼€å‘è€…

2. **SIGMOD 2018 - ProvSQLæ¼”ç¤º**
   - å¹³å°: ACM SIGMODä¼šè®®è§†é¢‘
   - å†…å®¹: ProvSQLåœ¨SIGMOD 2018çš„æ¼”ç¤ºå’Œè®ºæ–‡ä»‹ç»
   - é€‚åˆ: ç ”ç©¶äººå‘˜å’Œé«˜çº§å¼€å‘è€…
   - é‡è¦æ€§: â­â­â­â­â­ ProvSQLå®˜æ–¹æ¼”ç¤º

#### **8.6.2 æ¦‚ç‡æ•°æ®åº“è¯¾ç¨‹**

1. **ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†è¯¾ç¨‹**
   - å¹³å°: Coursera / edX
   - è¯¾ç¨‹åç§°: "Uncertainty in Data Management"
   - å†…å®¹: ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†è¯¾ç¨‹ï¼ŒåŒ…æ‹¬æ¦‚ç‡æ•°æ®åº“ã€ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹ã€æ¦‚ç‡æŸ¥è¯¢å¤„ç†
   - æ—¶é•¿: 6-8å‘¨
   - é€‚åˆ: å­¦ç”Ÿå’Œç ”ç©¶äººå‘˜
   - é‡è¦æ€§: â­â­â­â­ ç³»ç»Ÿæ€§å­¦ä¹ ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†

2. **æ¦‚ç‡æ•°æ®åº“ç†è®ºè¯¾ç¨‹**
   - å¹³å°: å¤§å­¦åœ¨çº¿è¯¾ç¨‹
   - å†…å®¹: æ¦‚ç‡æ•°æ®åº“ç†è®ºåŸºç¡€ï¼ŒåŒ…æ‹¬å¯èƒ½ä¸–ç•Œè¯­ä¹‰ã€æ¦‚ç‡æŸ¥è¯¢å¤„ç†ã€ç®—æ³•å®ç°
   - é€‚åˆ: ç ”ç©¶äººå‘˜
   - é‡è¦æ€§: â­â­â­â­ æ¦‚ç‡æ•°æ®åº“ç†è®ºæ·±å…¥å­¦ä¹ 

#### **8.6.3 PostgreSQLæ‰©å±•å¼€å‘æ•™ç¨‹**

1. **PostgreSQLæ‰©å±•å¼€å‘å®è·µ**
   - å¹³å°: YouTube / åœ¨çº¿è¯¾ç¨‹
   - å†…å®¹: PostgreSQLæ‰©å±•å¼€å‘å®è·µï¼ŒåŒ…æ‹¬æ•°æ®ç±»å‹æ‰©å±•ã€å‡½æ•°æ‰©å±•ã€æ“ä½œç¬¦æ‰©å±•
   - æ—¶é•¿: 2-4å°æ—¶
   - é€‚åˆ: å¼€å‘è€…
   - é‡è¦æ€§: â­â­â­â­ PostgreSQLæ‰©å±•å¼€å‘å®ç”¨æ•™ç¨‹

2. **PostgreSQLé«˜çº§ç‰¹æ€§æ•™ç¨‹**
   - å¹³å°: PostgreSQLå®˜æ–¹è§†é¢‘ / ç¤¾åŒºæ•™ç¨‹
   - å†…å®¹: PostgreSQLé«˜çº§ç‰¹æ€§ï¼ŒåŒ…æ‹¬æ‰©å±•ç³»ç»Ÿã€è‡ªå®šä¹‰ç±»å‹ã€æŸ¥è¯¢ä¼˜åŒ–
   - é€‚åˆ: é«˜çº§å¼€å‘è€…
   - é‡è¦æ€§: â­â­â­â­ PostgreSQLé«˜çº§ç‰¹æ€§å­¦ä¹ 

#### **8.6.4 æ•°æ®æº¯æºç›¸å…³è§†é¢‘**

1. **æ•°æ®æº¯æºæŠ€æœ¯ä»‹ç»**
   - å¹³å°: YouTube / æŠ€æœ¯ä¼šè®®
   - å†…å®¹: æ•°æ®æº¯æºæŠ€æœ¯ä»‹ç»ï¼ŒåŒ…æ‹¬æº¯æºæ¨¡å‹ã€æŸ¥è¯¢å¤„ç†ã€åº”ç”¨åœºæ™¯
   - é€‚åˆ: åˆå­¦è€…å’Œå¼€å‘è€…
   - é‡è¦æ€§: â­â­â­ æ•°æ®æº¯æºå…¥é—¨

2. **æ•°æ®æ²»ç†å’Œåˆè§„è§†é¢‘**
   - å¹³å°: ä¼ä¸šåŸ¹è®­å¹³å° / åœ¨çº¿è¯¾ç¨‹
   - å†…å®¹: æ•°æ®æ²»ç†å’Œåˆè§„å®è·µï¼ŒåŒ…æ‹¬æ•°æ®æº¯æºã€æ•°æ®è´¨é‡ã€åˆè§„è¦æ±‚
   - é€‚åˆ: ä¼ä¸šç”¨æˆ·å’Œæ•°æ®æ²»ç†ä¸“å®¶
   - é‡è¦æ€§: â­â­â­â­ æ•°æ®æ²»ç†å®è·µæŒ‡å—

#### **8.6.5 åœ¨çº¿å­¦ä¹ å¹³å°æ¨è**

1. **Coursera**
   - é“¾æ¥: [https://www.coursera.org](https://www.coursera.org)
   - å†…å®¹: æ•°æ®åº“ç³»ç»Ÿã€æ•°æ®ç®¡ç†ç›¸å…³è¯¾ç¨‹
   - ç‰¹ç‚¹: ç³»ç»Ÿæ€§å­¦ä¹ ï¼Œæœ‰è¯ä¹¦

2. **edX**
   - é“¾æ¥: [https://www.edx.org](https://www.edx.org)
   - å†…å®¹: æ•°æ®åº“ç³»ç»Ÿã€æ•°æ®ç§‘å­¦ç›¸å…³è¯¾ç¨‹
   - ç‰¹ç‚¹: å¤§å­¦è¯¾ç¨‹ï¼Œé«˜è´¨é‡å†…å®¹

3. **YouTube**
   - å†…å®¹: æŠ€æœ¯æ•™ç¨‹ã€ä¼šè®®è§†é¢‘ã€æ¼”ç¤ºè§†é¢‘
   - ç‰¹ç‚¹: å…è´¹ï¼Œå†…å®¹ä¸°å¯Œ

4. **PostgreSQLå®˜æ–¹è§†é¢‘**
   - é“¾æ¥: [PostgreSQL YouTubeé¢‘é“](https://www.youtube.com/user/PostgreSQLChannel)
   - å†…å®¹: PostgreSQLå®˜æ–¹æ•™ç¨‹ã€ä¼šè®®è§†é¢‘
   - ç‰¹ç‚¹: å®˜æ–¹å†…å®¹ï¼Œæƒå¨æ€§å¼º

### 8.7 æŠ€æœ¯åšå®¢å’Œæ¡ˆä¾‹

#### **8.7.1 åº”ç”¨æ¡ˆä¾‹**

1. **ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†**
   - **åœºæ™¯**: IoTä¼ æ„Ÿå™¨æ•°æ®çš„ä¸ç¡®å®šæ€§ç®¡ç†
   - **æŠ€æœ¯**: æ¦‚ç‡æ•°æ®åº“ã€æ•°æ®æº¯æº
   - **æ¡ˆä¾‹**: ç¯å¢ƒç›‘æµ‹ã€æ™ºèƒ½åŸå¸‚
   - **è¯¦ç»†æè¿°**:
     - ç¯å¢ƒç›‘æµ‹ç³»ç»Ÿä½¿ç”¨æ¦‚ç‡æ•°æ®åº“å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®çš„ä¸ç¡®å®šæ€§
     - æ™ºèƒ½åŸå¸‚é¡¹ç›®ä½¿ç”¨æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–å†³ç­–æ”¯æŒç³»ç»Ÿ
     - å·¥ä¸š4.0åœºæ™¯ä¸­ä½¿ç”¨æ¦‚ç‡æ•°æ®åº“è¿›è¡Œè®¾å¤‡çŠ¶æ€é¢„æµ‹
   - **å‚è€ƒé“¾æ¥**:
     - [IoTæ•°æ®ä¸ç¡®å®šæ€§å¤„ç†æ¡ˆä¾‹ç ”ç©¶](https://example.com/iot-probabilistic)
     - [æ™ºèƒ½åŸå¸‚æ•°æ®ç®¡ç†æœ€ä½³å®è·µ](https://example.com/smart-city)

2. **æ•°æ®èåˆåœºæ™¯**
   - **åœºæ™¯**: å¤šæºæ•°æ®èåˆçš„ä¸ä¸€è‡´æ€§å¤„ç†
   - **æŠ€æœ¯**: æ¦‚ç‡æŸ¥è¯¢ã€æ•°æ®æº¯æº
   - **æ¡ˆä¾‹**: æ•°æ®ä»“åº“ã€æ•°æ®æ¹–
   - **è¯¦ç»†æè¿°**:
     - ä¼ä¸šæ•°æ®ä»“åº“ä½¿ç”¨æ¦‚ç‡æ•°æ®åº“èåˆå¤šä¸ªæ•°æ®æº
     - æ•°æ®æ¹–é¡¹ç›®ä½¿ç”¨æ¦‚ç‡æŸ¥è¯¢å¤„ç†å¼‚æ„æ•°æ®
     - æ•°æ®é›†æˆå¹³å°ä½¿ç”¨æ¦‚ç‡è®¡ç®—è¯„ä¼°æ•°æ®è´¨é‡
   - **å‚è€ƒé“¾æ¥**:
     - [æ•°æ®èåˆæœ€ä½³å®è·µ](https://example.com/data-fusion)
     - [æ•°æ®ä»“åº“æ¦‚ç‡æŸ¥è¯¢åº”ç”¨](https://example.com/data-warehouse)

3. **æ•°æ®æº¯æºåº”ç”¨**
   - **åœºæ™¯**: æ•°æ®æ¥æºè¿½è¸ªå’Œå¯ä¿¡åº¦è¯„ä¼°
   - **æŠ€æœ¯**: ProvSQLã€æ¦‚ç‡è®¡ç®—
   - **æ¡ˆä¾‹**: æ•°æ®æ²»ç†ã€åˆè§„å®¡è®¡
   - **è¯¦ç»†æè¿°**:
     - é‡‘èæœºæ„ä½¿ç”¨æ•°æ®æº¯æºæ»¡è¶³ç›‘ç®¡è¦æ±‚
     - åŒ»ç–—ç³»ç»Ÿä½¿ç”¨æ¦‚ç‡æ•°æ®åº“è¿½è¸ªæ•°æ®æ¥æº
     - ä¼ä¸šæ•°æ®æ²»ç†å¹³å°ä½¿ç”¨ProvSQLè¿›è¡Œæ•°æ®å®¡è®¡
   - **å‚è€ƒé“¾æ¥**:
     - [æ•°æ®æ²»ç†å®è·µæ¡ˆä¾‹](https://example.com/data-governance)
     - [åˆè§„å®¡è®¡æ•°æ®æº¯æºåº”ç”¨](https://example.com/compliance-audit)

4. **æ•°æ®è´¨é‡è¯„ä¼°**
   - **åœºæ™¯**: æ•°æ®è´¨é‡è¯„ä¼°å’Œç›‘æ§
   - **æŠ€æœ¯**: æ¦‚ç‡æ•°æ®åº“ã€æ•°æ®è´¨é‡æŒ‡æ ‡
   - **æ¡ˆä¾‹**: æ•°æ®è´¨é‡å¹³å°ã€æ•°æ®æ¸…æ´—ç³»ç»Ÿ
   - **è¯¦ç»†æè¿°**:
     - æ•°æ®è´¨é‡å¹³å°ä½¿ç”¨æ¦‚ç‡å€¼è¯„ä¼°æ•°æ®å¯ä¿¡åº¦
     - æ•°æ®æ¸…æ´—ç³»ç»Ÿä½¿ç”¨æ¦‚ç‡æŸ¥è¯¢è¯†åˆ«ä½è´¨é‡æ•°æ®
     - æ•°æ®ç›‘æ§ç³»ç»Ÿä½¿ç”¨æ¦‚ç‡è®¡ç®—å®æ—¶è¯„ä¼°æ•°æ®è´¨é‡
   - **å‚è€ƒé“¾æ¥**:
     - [æ•°æ®è´¨é‡è¯„ä¼°æœ€ä½³å®è·µ](https://example.com/data-quality)
     - [æ•°æ®æ¸…æ´—æ¦‚ç‡æ–¹æ³•](https://example.com/data-cleaning)

#### **8.7.2 æœ€ä½³å®è·µ**

1. **æ¦‚ç‡æ•°æ®åº“è®¾è®¡æœ€ä½³å®è·µ**
   - **å†…å®¹**: æ¦‚ç‡å€¼å­˜å‚¨ã€æŸ¥è¯¢ä¼˜åŒ–ã€æ€§èƒ½è°ƒä¼˜
   - **è¯¦ç»†å»ºè®®**:
     - ä½¿ç”¨NUMERICç±»å‹å­˜å‚¨æ¦‚ç‡å€¼ï¼Œç¡®ä¿ç²¾åº¦
     - ä¸ºæ¦‚ç‡å€¼åˆ›å»ºç´¢å¼•ï¼ŒåŠ é€ŸæŸ¥è¯¢
     - ä½¿ç”¨æ¦‚ç‡é˜ˆå€¼æå‰è¿‡æ»¤ï¼Œå‡å°‘è®¡ç®—é‡
     - åˆç†è®¾è®¡æ¦‚ç‡å€¼èŒƒå›´ï¼Œé¿å…è¿‡åº¦å­˜å‚¨
   - **å‚è€ƒé“¾æ¥**:
     - [æ¦‚ç‡æ•°æ®åº“è®¾è®¡æŒ‡å—](https://example.com/probabilistic-design)
     - [æ¦‚ç‡æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§](https://example.com/query-optimization)

2. **ProvSQLé›†æˆæœ€ä½³å®è·µ**
   - **å†…å®¹**: ProvSQLå®‰è£…ã€é…ç½®ã€ä½¿ç”¨æŠ€å·§
   - **è¯¦ç»†å»ºè®®**:
     - ä»æºç ç¼–è¯‘å®‰è£…ï¼Œç¡®ä¿ç‰ˆæœ¬å…¼å®¹æ€§
     - åˆç†é…ç½®æ¦‚ç‡è®¡ç®—æ¨¡å¼ï¼Œå¹³è¡¡æ€§èƒ½å’Œç²¾åº¦
     - ä½¿ç”¨WITH PROVENANCEè¯­æ³•å¯ç”¨æº¯æºè¿½è¸ª
     - å®šæœŸæ£€æŸ¥ProvSQLæ‰©å±•çŠ¶æ€ï¼Œç¡®ä¿æ­£å¸¸è¿è¡Œ
   - **å‚è€ƒé“¾æ¥**:
     - [ProvSQLé›†æˆæŒ‡å—](https://example.com/provsql-integration)
     - [ProvSQLé…ç½®æœ€ä½³å®è·µ](https://example.com/provsql-config)

3. **ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†æœ€ä½³å®è·µ**
   - **å†…å®¹**: ä¸ç¡®å®šæ€§æ•°æ®å»ºæ¨¡ã€æŸ¥è¯¢å¤„ç†ã€ç»“æœè§£é‡Š
   - **è¯¦ç»†å»ºè®®**:
     - æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¦‚ç‡è¡¨ç¤ºæ–¹å¼
     - ä½¿ç”¨æ¦‚ç‡é˜ˆå€¼è¿‡æ»¤ä½æ¦‚ç‡æ•°æ®
     - æä¾›æ¦‚ç‡å€¼çš„è§£é‡Šå’Œè¯´æ˜
     - å®šæœŸè¯„ä¼°å’Œæ›´æ–°æ¦‚ç‡å€¼
   - **å‚è€ƒé“¾æ¥**:
     - [ä¸ç¡®å®šæ€§æ•°æ®å»ºæ¨¡æŒ‡å—](https://example.com/uncertainty-modeling)
     - [æ¦‚ç‡æŸ¥è¯¢ç»“æœè§£é‡Š](https://example.com/probability-interpretation)

#### **8.7.3 æŠ€æœ¯åšå®¢æ¨è**

1. **PostgreSQLå®˜æ–¹åšå®¢**
   - é“¾æ¥: [https://www.postgresql.org/about/newsarchive/](https://www.postgresql.org/about/newsarchive/)
   - å†…å®¹: PostgreSQLæœ€æ–°åŠ¨æ€ã€æŠ€æœ¯æ–‡ç« ã€æœ€ä½³å®è·µ
   - æ›´æ–°é¢‘ç‡: å®šæœŸæ›´æ–°
   - é‡è¦æ€§: â­â­â­â­â­ PostgreSQLå®˜æ–¹å†…å®¹

2. **æ•°æ®åº“æŠ€æœ¯åšå®¢**
   - å†…å®¹: æ•°æ®åº“æŠ€æœ¯æ–‡ç« ã€æ€§èƒ½ä¼˜åŒ–ã€æœ€ä½³å®è·µ
   - æ¨èåšå®¢:
     - [Planet PostgreSQL](https://planet.postgresql.org/) - PostgreSQLç¤¾åŒºåšå®¢èšåˆ
     - [PostgreSQL Weekly](https://postgresweekly.com/) - PostgreSQLå‘¨æŠ¥
   - é‡è¦æ€§: â­â­â­â­ ç¤¾åŒºæŠ€æœ¯å†…å®¹

3. **æ•°æ®ç§‘å­¦åšå®¢**
   - å†…å®¹: æ•°æ®ç§‘å­¦ã€ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†ã€æ¦‚ç‡æ–¹æ³•
   - æ¨èåšå®¢:
     - [Towards Data Science](https://towardsdatascience.com/) - æ•°æ®ç§‘å­¦æ–‡ç« 
     - [KDnuggets](https://www.kdnuggets.com/) - æ•°æ®æŒ–æ˜å’Œæœºå™¨å­¦ä¹ 
   - é‡è¦æ€§: â­â­â­â­ æ•°æ®ç§‘å­¦ç›¸å…³å†…å®¹

#### **8.7.4 å®é™…é¡¹ç›®æ¡ˆä¾‹**

1. **å¼€æºé¡¹ç›®æ¡ˆä¾‹**
   - **MystiQé¡¹ç›®**
     - æè¿°: æ¦‚ç‡æŸ¥è¯¢å¤„ç†å¼•æ“
     - é“¾æ¥: [https://github.com/dan-suciu/mystiq](https://github.com/dan-suciu/mystiq)
     - æŠ€æœ¯æ ˆ: C++
     - åº”ç”¨åœºæ™¯: æ¦‚ç‡æŸ¥è¯¢å¤„ç†ã€ä¸ç¡®å®šæ€§æ•°æ®ç®¡ç†

   - **ProvSQLé¡¹ç›®**
     - æè¿°: PostgreSQLçš„æº¯æºå’Œæ¦‚ç‡ç®¡ç†æ‰©å±•
     - é“¾æ¥: [https://github.com/PierreSenellart/provsql](https://github.com/PierreSenellart/provsql)
     - æŠ€æœ¯æ ˆ: C/C++
     - åº”ç”¨åœºæ™¯: æ•°æ®æº¯æºã€æ¦‚ç‡è®¡ç®—

2. **ä¼ä¸šåº”ç”¨æ¡ˆä¾‹**
   - **é‡‘èè¡Œä¸š**
     - åº”ç”¨: é£é™©è¯„ä¼°ã€æ•°æ®è´¨é‡è¯„ä¼°
     - æŠ€æœ¯: æ¦‚ç‡æ•°æ®åº“ã€æ•°æ®æº¯æº
     - æ¡ˆä¾‹: é“¶è¡Œæ•°æ®æ²»ç†ã€ä¿é™©é£é™©è¯„ä¼°

   - **åŒ»ç–—è¡Œä¸š**
     - åº”ç”¨: åŒ»ç–—æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†ã€æ•°æ®æº¯æº
     - æŠ€æœ¯: æ¦‚ç‡æ•°æ®åº“ã€ProvSQL
     - æ¡ˆä¾‹: åŒ»ç–—æ•°æ®è´¨é‡è¯„ä¼°ã€æ•°æ®åˆè§„å®¡è®¡

   - **IoTè¡Œä¸š**
     - åº”ç”¨: ä¼ æ„Ÿå™¨æ•°æ®ä¸ç¡®å®šæ€§å¤„ç†
     - æŠ€æœ¯: æ¦‚ç‡æ•°æ®åº“ã€å®æ—¶æŸ¥è¯¢
     - æ¡ˆä¾‹: ç¯å¢ƒç›‘æµ‹ã€æ™ºèƒ½åŸå¸‚ã€å·¥ä¸š4.0

### 8.8 ç ”ç©¶æœºæ„å’Œå®éªŒå®¤

#### **8.8.1 ä¸»è¦ç ”ç©¶æœºæ„**

1. **University of Washington - Database Group**
   - **é“¾æ¥**: [https://db.cs.washington.edu/](https://db.cs.washington.edu/)
   - **ç ”ç©¶æ–¹å‘**: æ¦‚ç‡æ•°æ®åº“ã€æ•°æ®æº¯æºã€ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†
   - **ä¸»è¦è´¡çŒ®**:
     - MystiQé¡¹ç›®ï¼šæ¦‚ç‡æŸ¥è¯¢å¤„ç†å¼•æ“
     - æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®ºç ”ç©¶
     - ä¸ç¡®å®šæ€§æ•°æ®ç®¡ç†ç®—æ³•
   - **é‡è¦äººç‰©**: Dan Suciu, Nilesh Dalvi
   - **é‡è¦è®ºæ–‡**:
     - "Foundations of Probabilistic Databases" (VLDB Journal 2011)
     - "Efficient Query Evaluation on Probabilistic Databases" (VLDB 2007)
   - **é‡è¦æ€§**: â­â­â­â­â­ æ¦‚ç‡æ•°æ®åº“é¢†åŸŸçš„é¢†å…ˆç ”ç©¶æœºæ„

2. **University of Pennsylvania - Database Group**
   - **ç ”ç©¶æ–¹å‘**: æ¦‚ç‡æ•°æ®åº“ç†è®ºã€ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹
   - **ä¸»è¦è´¡çŒ®**:
     - æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®º
     - å¯èƒ½ä¸–ç•Œè¯­ä¹‰ç ”ç©¶
     - æ¦‚ç‡æŸ¥è¯¢å¤„ç†ç®—æ³•
   - **é‡è¦äººç‰©**: Dan Suciu, Val Tannen
   - **é‡è¦è®ºæ–‡**:
     - "Probabilistic Databases: The Diamonds and the Rough" (CIDR 2011)
   - **é‡è¦æ€§**: â­â­â­â­â­ æ¦‚ç‡æ•°æ®åº“ç†è®ºç ”ç©¶çš„å…ˆé©±

3. **Ã‰cole normale supÃ©rieure (ENS) - Database Group**
   - **ç ”ç©¶æ–¹å‘**: ProvSQLã€æ•°æ®æº¯æºã€æ¦‚ç‡è®¡ç®—
   - **ä¸»è¦è´¡çŒ®**:
     - ProvSQLé¡¹ç›®ï¼šPostgreSQLçš„æº¯æºå’Œæ¦‚ç‡ç®¡ç†æ‰©å±•
     - æ•°æ®æº¯æºç†è®ºç ”ç©¶
     - æ¦‚ç‡è®¡ç®—å¼•æ“å¼€å‘
   - **é‡è¦äººç‰©**: Pierre Senellart
   - **é‡è¦è®ºæ–‡**:
     - "ProvSQL: Provenance and Probability Management in PostgreSQL" (SIGMOD 2018)
   - **é‡è¦æ€§**: â­â­â­â­â­ ProvSQLé¡¹ç›®çš„å¼€å‘æœºæ„

#### **8.8.2 å…¶ä»–é‡è¦ç ”ç©¶æœºæ„**

1. **Stanford University - Database Group**
   - **ç ”ç©¶æ–¹å‘**: æ•°æ®åº“ç³»ç»Ÿã€æ•°æ®ç®¡ç†ã€ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†
   - **ä¸»è¦è´¡çŒ®**:
     - æ•°æ®åº“ç³»ç»Ÿç†è®ºç ”ç©¶
     - æ•°æ®ç®¡ç†æŠ€æœ¯
   - **é‡è¦æ€§**: â­â­â­â­ æ•°æ®åº“ç³»ç»Ÿç ”ç©¶çš„é¢†å…ˆæœºæ„

2. **MIT CSAIL - Database Group**
   - **ç ”ç©¶æ–¹å‘**: æ•°æ®åº“ç³»ç»Ÿã€æ•°æ®ç®¡ç†ã€æ•°æ®ç§‘å­¦
   - **ä¸»è¦è´¡çŒ®**:
     - æ•°æ®åº“ç³»ç»Ÿåˆ›æ–°ç ”ç©¶
     - æ•°æ®ç®¡ç†æŠ€æœ¯
   - **é‡è¦æ€§**: â­â­â­â­ æ•°æ®åº“ç³»ç»Ÿç ”ç©¶çš„é‡è¦æœºæ„

3. **Microsoft Research - Database Group**
   - **ç ”ç©¶æ–¹å‘**: æ•°æ®åº“ç³»ç»Ÿã€æ•°æ®ç®¡ç†ã€äº‘æ•°æ®åº“
   - **ä¸»è¦è´¡çŒ®**:
     - SQL Serverç›¸å…³ç ”ç©¶
     - äº‘æ•°æ®åº“æŠ€æœ¯
   - **é‡è¦æ€§**: â­â­â­â­ ä¼ä¸šæ•°æ®åº“ç ”ç©¶çš„é‡è¦æœºæ„

#### **8.8.3 ç ”ç©¶å®éªŒå®¤**

1. **UW Database Lab**
   - **æœºæ„**: University of Washington
   - **ç ”ç©¶æ–¹å‘**: æ¦‚ç‡æ•°æ®åº“ã€æ•°æ®æº¯æºã€ä¸ç¡®å®šæ€§æ•°æ®å¤„ç†
   - **é¡¹ç›®**: MystiQ, Probabilistic Database Systems
   - **é‡è¦æ€§**: â­â­â­â­â­ æ¦‚ç‡æ•°æ®åº“ç ”ç©¶çš„æ ¸å¿ƒå®éªŒå®¤

2. **ENS Database Lab**
   - **æœºæ„**: Ã‰cole normale supÃ©rieure
   - **ç ”ç©¶æ–¹å‘**: ProvSQLã€æ•°æ®æº¯æºã€æ¦‚ç‡è®¡ç®—
   - **é¡¹ç›®**: ProvSQL, Data Provenance Systems
   - **é‡è¦æ€§**: â­â­â­â­â­ ProvSQLé¡¹ç›®çš„æ ¸å¿ƒå®éªŒå®¤

3. **UPenn Database Lab**
   - **æœºæ„**: University of Pennsylvania
   - **ç ”ç©¶æ–¹å‘**: æ¦‚ç‡æ•°æ®åº“ç†è®ºã€ä¸ç¡®å®šæ€§æ•°æ®æ¨¡å‹
   - **é¡¹ç›®**: Probabilistic Database Theory
   - **é‡è¦æ€§**: â­â­â­â­â­ æ¦‚ç‡æ•°æ®åº“ç†è®ºç ”ç©¶çš„é‡è¦å®éªŒå®¤

#### **8.8.4 ç ”ç©¶é¡¹ç›®å’Œå®éªŒå®¤é“¾æ¥**

1. **MystiQé¡¹ç›®**
   - GitHub: [https://github.com/dan-suciu/mystiq](https://github.com/dan-suciu/mystiq)
   - æœºæ„: University of Washington
   - çŠ¶æ€: âœ… æ´»è·ƒç»´æŠ¤

2. **ProvSQLé¡¹ç›®**
   - GitHub: [https://github.com/PierreSenellart/provsql](https://github.com/PierreSenellart/provsql)
   - æœºæ„: Ã‰cole normale supÃ©rieure
   - çŠ¶æ€: âœ… æ´»è·ƒç»´æŠ¤

3. **æ¦‚ç‡æ•°æ®åº“ç ”ç©¶èµ„æº**
   - ç ”ç©¶è®ºæ–‡: [DBLP - Probabilistic Databases](https://dblp.org/search?q=probabilistic+database)
   - ä¼šè®®: VLDB, SIGMOD, ICDE, PODS
   - é‡è¦æ€§: â­â­â­â­â­ æ¦‚ç‡æ•°æ®åº“ç ”ç©¶èµ„æº

### 8.9 å‚è€ƒèµ„æºä½¿ç”¨å»ºè®®

#### **8.9.1 ä¸åŒè§’è‰²çš„å­¦ä¹ è·¯å¾„**

**ğŸ“š åˆå­¦è€…å­¦ä¹ è·¯å¾„**ï¼š

1. **ç¬¬ä¸€æ­¥ï¼šç†è§£åŸºç¡€æ¦‚å¿µ**
   - é˜…è¯»æœ¬æ–‡æ¡£çš„"1. æ¦‚è¿°"å’Œ"2. æŠ€æœ¯åŸç†"ç« èŠ‚
   - ç†è§£æ¦‚ç‡æ•°æ®åº“çš„åŸºæœ¬æ¦‚å¿µå’ŒåŸç†
   - äº†è§£ä¸ç¡®å®šæ€§æ•°æ®çš„æ¥æºå’Œå¤„ç†æ–¹æ³•

2. **ç¬¬äºŒæ­¥ï¼šå­¦ä¹ ç†è®ºåŸºç¡€**
   - é˜…è¯»"8.1 å­¦æœ¯è®ºæ–‡"ä¸­çš„åŸºç¡€ç†è®ºè®ºæ–‡
   - ç†è§£å¯èƒ½ä¸–ç•Œè¯­ä¹‰å’Œæ¦‚ç‡æŸ¥è¯¢å¤„ç†
   - å­¦ä¹ æ¦‚ç‡æ•°æ®åº“çš„æ•°å­¦åŸºç¡€

3. **ç¬¬ä¸‰æ­¥ï¼šå®è·µæ“ä½œ**
   - æŒ‰ç…§"4. ProvSQLé›†æˆ"ç« èŠ‚å®‰è£…å’Œé…ç½®ProvSQL
   - è¿è¡Œ"9. å®Œæ•´ä»£ç ç¤ºä¾‹"ä¸­çš„ç¤ºä¾‹ä»£ç 
   - å°è¯•å®ç°ç®€å•çš„æ¦‚ç‡æŸ¥è¯¢

4. **æ¨èèµ„æº**ï¼š
   - æœ¬æ–‡æ¡£çš„"1. æ¦‚è¿°"å’Œ"2. æŠ€æœ¯åŸç†"ç« èŠ‚
   - "8.1.1 æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®º"ä¸­çš„ç»å…¸è®ºæ–‡
   - "8.2 å®˜æ–¹æ–‡æ¡£"ä¸­çš„PostgreSQLå’ŒProvSQLæ–‡æ¡£
   - "8.6 è§†é¢‘æ•™ç¨‹"ä¸­çš„å…¥é—¨æ•™ç¨‹

**ğŸ”§ å¼€å‘è€…å­¦ä¹ è·¯å¾„**ï¼š

1. **ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿä¸Šæ‰‹**
   - é˜…è¯»"4. ProvSQLé›†æˆ"ç« èŠ‚ï¼Œäº†è§£ProvSQLçš„å®‰è£…å’Œé…ç½®
   - å‚è€ƒ"9. å®Œæ•´ä»£ç ç¤ºä¾‹"ï¼Œå¿«é€Ÿå®ç°åŸºç¡€åŠŸèƒ½
   - ç†è§£ProvSQLçš„APIå’Œæ¥å£

2. **ç¬¬äºŒæ­¥ï¼šæ·±å…¥å­¦ä¹ **
   - é˜…è¯»"3. PostgreSQLå®ç°æ–¹æ¡ˆ"ï¼Œäº†è§£æ‰©å±•å¼€å‘
   - å­¦ä¹ "3.3 æŸ¥è¯¢å¤„ç†æ‰©å±•"ï¼Œå®ç°è‡ªå®šä¹‰åŠŸèƒ½
   - å‚è€ƒ"7. æœ€ä½³å®è·µ"ï¼Œéµå¾ªæœ€ä½³å®è·µ

3. **ç¬¬ä¸‰æ­¥ï¼šæ€§èƒ½ä¼˜åŒ–**
   - é˜…è¯»"6. æ€§èƒ½åˆ†æ"ï¼Œäº†è§£æ€§èƒ½å½±å“å› ç´ 
   - å­¦ä¹ "6.4 æ€§èƒ½ä¼˜åŒ–å»ºè®®"ï¼Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
   - å‚è€ƒ"7.3 æ€§èƒ½ä¼˜åŒ–"ï¼Œåº”ç”¨ä¼˜åŒ–æŠ€å·§

4. **æ¨èèµ„æº**ï¼š
   - "4. ProvSQLé›†æˆ"ç« èŠ‚
   - "9. å®Œæ•´ä»£ç ç¤ºä¾‹"ç« èŠ‚
   - "8.2.1 PostgreSQLæ–‡æ¡£"ä¸­çš„æ‰©å±•å¼€å‘æ–‡æ¡£
   - "8.2.2 ProvSQLæ–‡æ¡£"ä¸­çš„APIæ–‡æ¡£
   - "8.6.3 PostgreSQLæ‰©å±•å¼€å‘æ•™ç¨‹"

**ğŸ¢ ä¼ä¸šç”¨æˆ·å­¦ä¹ è·¯å¾„**ï¼š

1. **ç¬¬ä¸€æ­¥ï¼šäº†è§£åº”ç”¨åœºæ™¯**
   - é˜…è¯»"1.3.2 åº”ç”¨åœºæ™¯"ï¼Œäº†è§£é€‚ç”¨åœºæ™¯
   - é˜…è¯»"5. å®é™…åº”ç”¨æ¡ˆä¾‹"ï¼Œäº†è§£å®é™…åº”ç”¨
   - é˜…è¯»"7.1 ä½¿ç”¨åœºæ™¯"ï¼Œäº†è§£é€‚ç”¨å’Œä¸é€‚ç”¨åœºæ™¯

2. **ç¬¬äºŒæ­¥ï¼šè¯„ä¼°å’Œè§„åˆ’**
   - é˜…è¯»"7.6 å®æ–½å»ºè®®"ï¼Œåˆ¶å®šå®æ–½è®¡åˆ’
   - å‚è€ƒ"6. æ€§èƒ½åˆ†æ"ï¼Œè¯„ä¼°æ€§èƒ½å½±å“
   - é˜…è¯»"7.4 å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ"ï¼Œäº†è§£å¸¸è§é—®é¢˜

3. **ç¬¬ä¸‰æ­¥ï¼šå®æ–½å’Œä¼˜åŒ–**
   - æŒ‰ç…§"7.6.1 æ¸è¿›å¼å®æ–½"é€æ­¥å®æ–½
   - å‚è€ƒ"7.2 è®¾è®¡åŸåˆ™"ï¼Œè®¾è®¡æ•°æ®æ¨¡å‹
   - åº”ç”¨"7.3 æ€§èƒ½ä¼˜åŒ–"ï¼Œä¼˜åŒ–æ€§èƒ½

4. **æ¨èèµ„æº**ï¼š
   - "5. å®é™…åº”ç”¨æ¡ˆä¾‹"ç« èŠ‚
   - "7. æœ€ä½³å®è·µ"ç« èŠ‚
   - "8.7 æŠ€æœ¯åšå®¢å’Œæ¡ˆä¾‹"ä¸­çš„ä¼ä¸šåº”ç”¨æ¡ˆä¾‹
   - "8.5 ä¹¦ç±æ¨è"ä¸­çš„æ•°æ®æ²»ç†ç›¸å…³ä¹¦ç±

**ğŸ”¬ ç ”ç©¶è€…å­¦ä¹ è·¯å¾„**ï¼š

1. **ç¬¬ä¸€æ­¥ï¼šç†è®ºåŸºç¡€**
   - é˜…è¯»"8.1 å­¦æœ¯è®ºæ–‡"ä¸­çš„æ‰€æœ‰è®ºæ–‡
   - æ·±å…¥ç†è§£æ¦‚ç‡æ•°æ®åº“çš„ç†è®ºåŸºç¡€
   - å­¦ä¹ å¯èƒ½ä¸–ç•Œè¯­ä¹‰å’Œæ¦‚ç‡æŸ¥è¯¢å¤„ç†ç®—æ³•

2. **ç¬¬äºŒæ­¥ï¼šç ”ç©¶å‰æ²¿**
   - å…³æ³¨"8.8 ç ”ç©¶æœºæ„å’Œå®éªŒå®¤"çš„æœ€æ–°ç ”ç©¶
   - é˜…è¯»æœ€æ–°çš„å­¦æœ¯è®ºæ–‡
   - äº†è§£æ¦‚ç‡æ•°æ®åº“çš„æœ€æ–°è¿›å±•

3. **ç¬¬ä¸‰æ­¥ï¼šå®è·µç ”ç©¶**
   - ä½¿ç”¨"8.3 å¼€æºé¡¹ç›®å’Œå·¥å…·"è¿›è¡Œç ”ç©¶
   - å‚è€ƒ"8.8 ç ”ç©¶æœºæ„å’Œå®éªŒå®¤"çš„ç ”ç©¶æ–¹æ³•
   - è´¡çŒ®å¼€æºé¡¹ç›®æˆ–å‘è¡¨ç ”ç©¶æˆæœ

4. **æ¨èèµ„æº**ï¼š
   - "8.1 å­¦æœ¯è®ºæ–‡"ä¸­çš„æ‰€æœ‰è®ºæ–‡
   - "8.8 ç ”ç©¶æœºæ„å’Œå®éªŒå®¤"çš„ç ”ç©¶èµ„æº
   - "8.5.1 æ¦‚ç‡æ•°æ®åº“ç›¸å…³ä¹¦ç±"ä¸­çš„ç†è®ºä¹¦ç±
   - "8.5.4 æ•°æ®åº“ç†è®ºç›¸å…³ä¹¦ç±"ä¸­çš„ç»å…¸æ•™æ

#### **8.9.2 å­¦ä¹ èµ„æºä¼˜å…ˆçº§**

**é«˜ä¼˜å…ˆçº§èµ„æº**ï¼ˆå¿…é¡»é˜…è¯»ï¼‰ï¼š

1. æœ¬æ–‡æ¡£çš„"1. æ¦‚è¿°"å’Œ"2. æŠ€æœ¯åŸç†"ç« èŠ‚
2. "4. ProvSQLé›†æˆ"ç« èŠ‚
3. "9. å®Œæ•´ä»£ç ç¤ºä¾‹"ç« èŠ‚
4. ProvSQLå®˜æ–¹æ–‡æ¡£

**ä¸­ä¼˜å…ˆçº§èµ„æº**ï¼ˆæ¨èé˜…è¯»ï¼‰ï¼š

1. "5. å®é™…åº”ç”¨æ¡ˆä¾‹"ç« èŠ‚
2. "7. æœ€ä½³å®è·µ"ç« èŠ‚
3. "6. æ€§èƒ½åˆ†æ"ç« èŠ‚
4. "8.1.1 æ¦‚ç‡æ•°æ®åº“åŸºç¡€ç†è®º"ä¸­çš„ç»å…¸è®ºæ–‡

**ä½ä¼˜å…ˆçº§èµ„æº**ï¼ˆå¯é€‰é˜…è¯»ï¼‰ï¼š

1. "8.5 ä¹¦ç±æ¨è"ä¸­çš„ç›¸å…³ä¹¦ç±
2. "8.6 è§†é¢‘æ•™ç¨‹"ä¸­çš„è§†é¢‘
3. "8.7 æŠ€æœ¯åšå®¢å’Œæ¡ˆä¾‹"ä¸­çš„åšå®¢æ–‡ç« 
4. "8.8 ç ”ç©¶æœºæ„å’Œå®éªŒå®¤"çš„ç ”ç©¶èµ„æº

#### **8.9.3 å­¦ä¹ æ—¶é—´è§„åˆ’**

**åˆå­¦è€…**ï¼š

- ç¬¬1å‘¨ï¼šé˜…è¯»åŸºç¡€æ¦‚å¿µå’Œç†è®ºï¼ˆ"1. æ¦‚è¿°"å’Œ"2. æŠ€æœ¯åŸç†"ï¼‰
- ç¬¬2å‘¨ï¼šå®‰è£…å’Œé…ç½®ProvSQLï¼ˆ"4. ProvSQLé›†æˆ"ï¼‰
- ç¬¬3å‘¨ï¼šå®è·µä»£ç ç¤ºä¾‹ï¼ˆ"9. å®Œæ•´ä»£ç ç¤ºä¾‹"ï¼‰
- ç¬¬4å‘¨ï¼šæ·±å…¥å­¦ä¹ ç†è®ºï¼ˆ"8.1 å­¦æœ¯è®ºæ–‡"ï¼‰

**å¼€å‘è€…**ï¼š

- ç¬¬1å‘¨ï¼šå¿«é€Ÿä¸Šæ‰‹ProvSQLï¼ˆ"4. ProvSQLé›†æˆ"å’Œ"9. å®Œæ•´ä»£ç ç¤ºä¾‹"ï¼‰
- ç¬¬2å‘¨ï¼šå­¦ä¹ æ‰©å±•å¼€å‘ï¼ˆ"3. PostgreSQLå®ç°æ–¹æ¡ˆ"ï¼‰
- ç¬¬3å‘¨ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆ"6. æ€§èƒ½åˆ†æ"å’Œ"7.3 æ€§èƒ½ä¼˜åŒ–"ï¼‰
- ç¬¬4å‘¨ï¼šæœ€ä½³å®è·µï¼ˆ"7. æœ€ä½³å®è·µ"ï¼‰

**ä¼ä¸šç”¨æˆ·**ï¼š

- ç¬¬1å‘¨ï¼šäº†è§£åº”ç”¨åœºæ™¯ï¼ˆ"1.3.2 åº”ç”¨åœºæ™¯"å’Œ"5. å®é™…åº”ç”¨æ¡ˆä¾‹"ï¼‰
- ç¬¬2å‘¨ï¼šè¯„ä¼°å’Œè§„åˆ’ï¼ˆ"7.6 å®æ–½å»ºè®®"å’Œ"6. æ€§èƒ½åˆ†æ"ï¼‰
- ç¬¬3å‘¨ï¼šå®æ–½å‡†å¤‡ï¼ˆ"7.2 è®¾è®¡åŸåˆ™"å’Œ"7.4 å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ"ï¼‰
- ç¬¬4å‘¨ï¼šå¼€å§‹å®æ–½ï¼ˆ"7.6.1 æ¸è¿›å¼å®æ–½"ï¼‰

**ç ”ç©¶è€…**ï¼š

- ç¬¬1-2å‘¨ï¼šç†è®ºåŸºç¡€ï¼ˆ"8.1 å­¦æœ¯è®ºæ–‡"å’Œ"8.5.1 æ¦‚ç‡æ•°æ®åº“ç›¸å…³ä¹¦ç±"ï¼‰
- ç¬¬3-4å‘¨ï¼šç ”ç©¶å‰æ²¿ï¼ˆ"8.8 ç ”ç©¶æœºæ„å’Œå®éªŒå®¤"çš„æœ€æ–°ç ”ç©¶ï¼‰
- ç¬¬5-6å‘¨ï¼šå®è·µç ”ç©¶ï¼ˆ"8.3 å¼€æºé¡¹ç›®å’Œå·¥å…·"ï¼‰

#### **8.9.4 å­¦ä¹ å»ºè®®**

1. **å¾ªåºæ¸è¿›**ï¼šæŒ‰ç…§å­¦ä¹ è·¯å¾„é€æ­¥å­¦ä¹ ï¼Œä¸è¦è·³è·ƒ
2. **ç†è®ºä¸å®è·µç»“åˆ**ï¼šç†è®ºå­¦ä¹ åç«‹å³å®è·µï¼ŒåŠ æ·±ç†è§£
3. **å¤šå‚è€ƒèµ„æº**ï¼šä¸è¦åªä¾èµ–å•ä¸€èµ„æºï¼Œå¤šå‚è€ƒä¸åŒèµ„æº
4. **æŒç»­å­¦ä¹ **ï¼šå…³æ³¨æœ€æ–°è¿›å±•ï¼ŒæŒç»­æ›´æ–°çŸ¥è¯†
5. **å®è·µä¸ºä¸»**ï¼šå¤šå†™ä»£ç ï¼Œå¤šå®è·µï¼Œå¤šæ€»ç»“
6. **ç¤¾åŒºå‚ä¸**ï¼šå‚ä¸ç¤¾åŒºè®¨è®ºï¼Œåˆ†äº«ç»éªŒï¼Œè·å–å¸®åŠ©

---

## 9. å®Œæ•´ä»£ç ç¤ºä¾‹

### 9.1 æ¦‚ç‡æ•°æ®ç±»å‹å®ç°

æœ¬èŠ‚æä¾›å®Œæ•´çš„æ¦‚ç‡æ•°æ®ç±»å‹å®ç°ä»£ç ï¼ŒåŒ…æ‹¬ç±»å‹å®šä¹‰ã€è¡¨åˆ›å»ºã€æ•°æ®æ’å…¥ã€æŸ¥è¯¢å’Œæ“ä½œå‡½æ•°ã€‚

#### **9.1.1 åˆ›å»ºæ¦‚ç‡æ•°æ®ç±»å‹**

**æ¦‚ç‡å€¼ç±»å‹å®šä¹‰**ï¼š

```sql
-- åˆ›å»ºæ¦‚ç‡å€¼ç±»å‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability_value') THEN
            RAISE NOTICE 'ç±»å‹ probability_value å·²å­˜åœ¨';
        ELSE
            CREATE TYPE probability_value AS (
                value NUMERIC,
                probability NUMERIC
            );
            RAISE NOTICE 'ç±»å‹ probability_value å·²åˆ›å»º';
        END IF;
    EXCEPTION
        WHEN duplicate_object THEN
            RAISE WARNING 'ç±»å‹ probability_value å·²å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºç±»å‹ probability_value å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**ç±»å‹è¯´æ˜**ï¼š

- **value**ï¼šå®é™…æ•°æ®å€¼ï¼ˆNUMERICç±»å‹ï¼‰
- **probability**ï¼šè¯¥å€¼çš„æ¦‚ç‡/ç½®ä¿¡åº¦ï¼ˆNUMERICç±»å‹ï¼ŒèŒƒå›´[0, 1]ï¼‰

#### **9.1.2 åˆ›å»ºæ¦‚ç‡æ•°æ®è¡¨**

**ä¼ æ„Ÿå™¨æ•°æ®è¡¨ç¤ºä¾‹**ï¼š

```sql
-- åˆ›å»ºæ¦‚ç‡è¡¨ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability_value') THEN
            RAISE WARNING 'ç±»å‹ probability_value ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¯¥ç±»å‹';
            RETURN;
        END IF;

        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
            RAISE NOTICE 'è¡¨ sensor_readings å·²å­˜åœ¨';
        ELSE
            CREATE TABLE sensor_readings (
                id SERIAL PRIMARY KEY,
                sensor_id INTEGER NOT NULL,
                temperature probability_value NOT NULL,
                humidity probability_value NOT NULL,
                timestamp TIMESTAMP DEFAULT NOW(),
                CONSTRAINT check_probability_range CHECK (
                    (temperature).probability >= 0 AND (temperature).probability <= 1 AND
                    (humidity).probability >= 0 AND (humidity).probability <= 1
                )
            );
            RAISE NOTICE 'è¡¨ sensor_readings å·²åˆ›å»º';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING 'è¡¨ sensor_readings å·²å­˜åœ¨';
        WHEN undefined_object THEN
            RAISE WARNING 'ç±»å‹ probability_value ä¸å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºè¡¨å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_sensor_id ON sensor_readings(sensor_id);
CREATE INDEX IF NOT EXISTS idx_timestamp ON sensor_readings(timestamp);
CREATE INDEX IF NOT EXISTS idx_temperature_prob ON sensor_readings(((temperature).probability));
CREATE INDEX IF NOT EXISTS idx_humidity_prob ON sensor_readings(((humidity).probability));
```

#### **9.1.3 æ’å…¥æ¦‚ç‡æ•°æ®**

**å•æ¡æ•°æ®æ’å…¥**ï¼š

```sql
-- æ’å…¥æ¦‚ç‡æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'sensor_readings') THEN
            RAISE WARNING 'è¡¨ sensor_readings ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'probability_value') THEN
            RAISE WARNING 'ç±»å‹ probability_value ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO sensor_readings (sensor_id, temperature, humidity, timestamp)
        VALUES (
            1,
            ROW(25.5, 0.95)::probability_value,  -- æ¸©åº¦25.5åº¦ï¼Œç½®ä¿¡åº¦95%
            ROW(60.0, 0.90)::probability_value,  -- æ¹¿åº¦60%ï¼Œç½®ä¿¡åº¦90%
            NOW()
        );

        RAISE NOTICE 'æ•°æ®æ’å…¥æˆåŠŸ';
    EXCEPTION
        WHEN check_violation THEN
            RAISE WARNING 'æ¦‚ç‡å€¼è¶…å‡ºèŒƒå›´[0, 1]';
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;
```

**æ‰¹é‡æ•°æ®æ’å…¥**ï¼š

```sql
-- æ‰¹é‡æ’å…¥æ¦‚ç‡æ•°æ®
INSERT INTO sensor_readings (sensor_id, temperature, humidity, timestamp)
SELECT
    generate_series(1, 100) AS sensor_id,
    ROW(
        20 + random() * 10,  -- æ¸©åº¦èŒƒå›´20-30åº¦
        0.8 + random() * 0.2  -- ç½®ä¿¡åº¦èŒƒå›´0.8-1.0
    )::probability_value AS temperature,
    ROW(
        50 + random() * 20,  -- æ¹¿åº¦èŒƒå›´50-70%
        0.8 + random() * 0.2  -- ç½®ä¿¡åº¦èŒƒå›´0.8-1.0
    )::probability_value AS humidity,
    NOW() - (random() * INTERVAL '7 days') AS timestamp;
```

#### **9.1.4 æŸ¥è¯¢æ¦‚ç‡æ•°æ®**

**åŸºç¡€æŸ¥è¯¢**ï¼š

```sql
-- æŸ¥è¯¢æ‰€æœ‰æ¦‚ç‡æ•°æ®
SELECT
    id,
    sensor_id,
    (temperature).value AS temp_value,
    (temperature).probability AS temp_prob,
    (humidity).value AS hum_value,
    (humidity).probability AS hum_prob,
    timestamp
FROM sensor_readings
ORDER BY timestamp DESC;

-- æŸ¥è¯¢é«˜ç½®ä¿¡åº¦æ•°æ®ï¼ˆæ¦‚ç‡>0.9ï¼‰
SELECT
    id,
    sensor_id,
    (temperature).value AS temp_value,
    (temperature).probability AS temp_prob,
    (humidity).value AS hum_value,
    (humidity).probability AS hum_prob
FROM sensor_readings
WHERE (temperature).probability > 0.9 AND (humidity).probability > 0.9
ORDER BY (temperature).probability DESC, (humidity).probability DESC;
```

**æ¦‚ç‡èšåˆæŸ¥è¯¢**ï¼š

```sql
-- æŒ‰ä¼ æ„Ÿå™¨IDèšåˆï¼Œè®¡ç®—åŠ æƒå¹³å‡å€¼
SELECT
    sensor_id,
    COUNT(*) AS total_readings,
    AVG((temperature).value) AS avg_temperature,
    SUM((temperature).value * (temperature).probability) /
        SUM((temperature).probability) AS weighted_avg_temperature,
    AVG((humidity).value) AS avg_humidity,
    SUM((humidity).value * (humidity).probability) /
        SUM((humidity).probability) AS weighted_avg_humidity,
    AVG((temperature).probability) AS avg_temp_confidence,
    AVG((humidity).probability) AS avg_hum_confidence
FROM sensor_readings
GROUP BY sensor_id
ORDER BY sensor_id;
```

#### **9.1.5 æ¦‚ç‡æ“ä½œå‡½æ•°**

**æ¦‚ç‡å€¼æ“ä½œå‡½æ•°**ï¼š

```sql
-- è®¡ç®—æ¦‚ç‡å€¼çš„æœŸæœ›å€¼
CREATE OR REPLACE FUNCTION expected_value(pv probability_value)
RETURNS NUMERIC AS $$
BEGIN
    RETURN (pv).value * (pv).probability;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- è®¡ç®—ä¸¤ä¸ªæ¦‚ç‡å€¼çš„è”åˆæ¦‚ç‡
CREATE OR REPLACE FUNCTION joint_probability(
    pv1 probability_value,
    pv2 probability_value
) RETURNS NUMERIC AS $$
BEGIN
    RETURN (pv1).probability * (pv2).probability;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- æ¦‚ç‡å€¼æ¯”è¾ƒå‡½æ•°ï¼ˆæŒ‰æœŸæœ›å€¼ï¼‰
CREATE OR REPLACE FUNCTION compare_by_expected_value(
    pv1 probability_value,
    pv2 probability_value
) RETURNS INTEGER AS $$
BEGIN
    IF expected_value(pv1) > expected_value(pv2) THEN
        RETURN 1;
    ELSIF expected_value(pv1) < expected_value(pv2) THEN
        RETURN -1;
    ELSE
        RETURN 0;
    END IF;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT
    sensor_id,
    expected_value(temperature) AS temp_expected_value,
    expected_value(humidity) AS hum_expected_value,
    joint_probability(temperature, humidity) AS joint_prob
FROM sensor_readings
WHERE sensor_id = 1
ORDER BY expected_value(temperature) DESC;
```

**æ¦‚ç‡è¿‡æ»¤å‡½æ•°**ï¼š

```sql
-- æ¦‚ç‡é˜ˆå€¼è¿‡æ»¤å‡½æ•°
CREATE OR REPLACE FUNCTION filter_by_probability(
    pv probability_value,
    min_prob NUMERIC DEFAULT 0.5
) RETURNS BOOLEAN AS $$
BEGIN
    RETURN (pv).probability >= min_prob;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT
    id,
    sensor_id,
    (temperature).value AS temp_value,
    (temperature).probability AS temp_prob
FROM sensor_readings
WHERE filter_by_probability(temperature, 0.9)
ORDER BY (temperature).probability DESC;
```

#### **9.1.6 æ¦‚ç‡æ•°æ®æ›´æ–°**

**æ›´æ–°æ¦‚ç‡å€¼**ï¼š

```sql
-- æ›´æ–°æ¦‚ç‡å€¼ï¼ˆå¸¦éªŒè¯ï¼‰
CREATE OR REPLACE FUNCTION update_probability_value(
    table_name TEXT,
    record_id INTEGER,
    column_name TEXT,
    new_value NUMERIC,
    new_probability NUMERIC
) RETURNS BOOLEAN AS $$
DECLARE
    sql_text TEXT;
BEGIN
    -- éªŒè¯æ¦‚ç‡å€¼èŒƒå›´
    IF new_probability < 0 OR new_probability > 1 THEN
        RAISE EXCEPTION 'æ¦‚ç‡å€¼å¿…é¡»åœ¨[0, 1]èŒƒå›´å†…';
    END IF;

    -- æ„å»ºæ›´æ–°SQL
    sql_text := format(
        'UPDATE %I SET %I = ROW(%s, %s)::probability_value WHERE id = %s',
        table_name,
        column_name,
        new_value,
        new_probability,
        record_id
    );

    EXECUTE sql_text;

    RETURN TRUE;
EXCEPTION
    WHEN OTHERS THEN
        RAISE WARNING 'æ›´æ–°å¤±è´¥: %', SQLERRM;
        RETURN FALSE;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT update_probability_value('sensor_readings', 1, 'temperature', 26.0, 0.95);
```

#### **9.1.7 æ¦‚ç‡æ•°æ®éªŒè¯**

**æ•°æ®è´¨é‡æ£€æŸ¥å‡½æ•°**ï¼š

```sql
-- æ£€æŸ¥æ¦‚ç‡æ•°æ®è´¨é‡
CREATE OR REPLACE FUNCTION check_probability_data_quality()
RETURNS TABLE (
    check_name TEXT,
    status TEXT,
    issue_count BIGINT,
    details TEXT
) AS $$
BEGIN
    -- æ£€æŸ¥æ¦‚ç‡å€¼èŒƒå›´
    RETURN QUERY
    SELECT
        'Probability Range Check'::TEXT,
        CASE
            WHEN COUNT(*) FILTER (WHERE (temperature).probability < 0 OR (temperature).probability > 1 OR
                                         (humidity).probability < 0 OR (humidity).probability > 1) > 0
            THEN 'FAIL'
            ELSE 'PASS'
        END,
        COUNT(*) FILTER (WHERE (temperature).probability < 0 OR (temperature).probability > 1 OR
                                (humidity).probability < 0 OR (humidity).probability > 1),
        format('Found %s records with invalid probability values',
               COUNT(*) FILTER (WHERE (temperature).probability < 0 OR (temperature).probability > 1 OR
                                       (humidity).probability < 0 OR (humidity).probability > 1))
    FROM sensor_readings;

    -- æ£€æŸ¥NULLå€¼
    RETURN QUERY
    SELECT
        'NULL Value Check'::TEXT,
        CASE
            WHEN COUNT(*) FILTER (WHERE temperature IS NULL OR humidity IS NULL) > 0
            THEN 'WARNING'
            ELSE 'PASS'
        END,
        COUNT(*) FILTER (WHERE temperature IS NULL OR humidity IS NULL),
        format('Found %s records with NULL probability values',
               COUNT(*) FILTER (WHERE temperature IS NULL OR humidity IS NULL))
    FROM sensor_readings;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM check_probability_data_quality();
```

#### **9.1.8 å®Œæ•´ä½¿ç”¨ç¤ºä¾‹**

**å®Œæ•´çš„å·¥ä½œæµç¨‹**ï¼š

```sql
-- 1. åˆ›å»ºç±»å‹å’Œè¡¨
-- ï¼ˆä½¿ç”¨ä¸Šé¢çš„ä»£ç ï¼‰

-- 2. æ’å…¥æµ‹è¯•æ•°æ®
INSERT INTO sensor_readings (sensor_id, temperature, humidity, timestamp)
VALUES
    (1, ROW(25.5, 0.95)::probability_value, ROW(60.0, 0.90)::probability_value, NOW()),
    (1, ROW(26.0, 0.88)::probability_value, ROW(61.0, 0.85)::probability_value, NOW()),
    (2, ROW(24.5, 0.92)::probability_value, ROW(58.0, 0.88)::probability_value, NOW());

-- 3. æŸ¥è¯¢é«˜ç½®ä¿¡åº¦æ•°æ®
SELECT
    sensor_id,
    (temperature).value AS temp,
    (temperature).probability AS temp_conf,
    (humidity).value AS hum,
    (humidity).probability AS hum_conf
FROM sensor_readings
WHERE (temperature).probability > 0.9 AND (humidity).probability > 0.85
ORDER BY (temperature).probability DESC;

-- 4. æ¦‚ç‡èšåˆåˆ†æ
SELECT
    sensor_id,
    COUNT(*) AS readings,
    AVG((temperature).value) AS avg_temp,
    SUM((temperature).value * (temperature).probability) /
        SUM((temperature).probability) AS weighted_avg_temp,
    AVG((temperature).probability) AS avg_confidence
FROM sensor_readings
GROUP BY sensor_id;

-- 5. æ•°æ®è´¨é‡æ£€æŸ¥
SELECT * FROM check_probability_data_quality();
```

```

### 9.2 Python æ¦‚ç‡æ•°æ®åº“å®¢æˆ·ç«¯

**å®Œæ•´çš„æ¦‚ç‡æ•°æ®åº“æ“ä½œç±»ï¼ˆå¸¦é”™è¯¯å¤„ç†ã€è¿æ¥æ± ã€äº‹åŠ¡ç®¡ç†ï¼‰**ï¼š

```python
# probabilistic_client.py
import psycopg2
from psycopg2 import pool
from psycopg2.extras import RealDictCursor
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass
from contextlib import contextmanager
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ProbabilityValue:
    """æ¦‚ç‡å€¼æ•°æ®ç±»"""
    value: float
    probability: float

    def __post_init__(self):
        """éªŒè¯æ¦‚ç‡å€¼èŒƒå›´"""
        if not 0 <= self.probability <= 1:
            raise ValueError(f"æ¦‚ç‡å€¼å¿…é¡»åœ¨[0, 1]èŒƒå›´å†…ï¼Œå½“å‰å€¼: {self.probability}")

class ProbabilisticDBClient:
    """æ¦‚ç‡æ•°æ®åº“å®¢æˆ·ç«¯ï¼ˆå®Œæ•´ç‰ˆï¼‰"""

    def __init__(self, conn_str: str, min_conn: int = 1, max_conn: int = 10):
        """
        åˆå§‹åŒ–æ¦‚ç‡æ•°æ®åº“å®¢æˆ·ç«¯

        Args:
            conn_str: PostgreSQLè¿æ¥å­—ç¬¦ä¸²
            min_conn: è¿æ¥æ± æœ€å°è¿æ¥æ•°
            max_conn: è¿æ¥æ± æœ€å¤§è¿æ¥æ•°
        """
        try:
            self.conn_pool = psycopg2.pool.ThreadedConnectionPool(
                min_conn, max_conn, conn_str
            )
            logger.info("æ•°æ®åº“è¿æ¥æ± åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆ›å»ºè¿æ¥æ± å¤±è´¥: {e}")
            raise

    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        conn = None
        try:
            conn = self.conn_pool.getconn()
            yield conn
            conn.commit()
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise
        finally:
            if conn:
                self.conn_pool.putconn(conn)

    def insert_probabilistic_data(
        self,
        table_name: str,
        data: Dict,
        batch_size: int = 1000
    ) -> int:
        """
        æ’å…¥æ¦‚ç‡æ•°æ®ï¼ˆæ”¯æŒæ‰¹é‡æ’å…¥ï¼‰

        Args:
            table_name: è¡¨å
            data: æ•°æ®å­—å…¸æˆ–æ•°æ®åˆ—è¡¨
            batch_size: æ‰¹é‡æ’å…¥å¤§å°

        Returns:
            æ’å…¥çš„è¡Œæ•°
        """
        if isinstance(data, dict):
            data = [data]

        inserted_count = 0

        with self.get_connection() as conn:
            with conn.cursor() as cur:
                try:
                    # æ‰¹é‡æ’å…¥
                    for i in range(0, len(data), batch_size):
                        batch = data[i:i + batch_size]
                        placeholders = []
                        values_list = []

                        for row in batch:
                            cols = []
                            vals = []
                            for col, val in row.items():
                                if isinstance(val, ProbabilityValue):
                                    cols.append(col)
                                    vals.append(f"ROW(%s, %s)::probability_value")
                                    placeholders.append((val.value, val.probability))
                                elif col == 'timestamp' and val == 'NOW()':
                                    cols.append(col)
                                    vals.append('NOW()')
                                else:
                                    cols.append(col)
                                    vals.append('%s')
                                    placeholders.append(val)

                            columns_str = ', '.join(cols)
                            values_str = ', '.join(vals)

                            query = f"""
                                INSERT INTO {table_name} ({columns_str})
                                VALUES ({values_str})
                            """

                            cur.execute(query, tuple(placeholders))
                            inserted_count += 1

                        conn.commit()
                        logger.info(f"æ‰¹é‡æ’å…¥ {len(batch)} æ¡æ•°æ®æˆåŠŸ")

                except psycopg2.Error as e:
                    logger.error(f"æ’å…¥æ•°æ®å¤±è´¥: {e}")
                    conn.rollback()
                    raise

        return inserted_count

    def query_with_confidence(
        self,
        query: str,
        min_confidence: float = 0.8,
        params: Optional[Tuple] = None
    ) -> List[Dict]:
        """
        æ‰§è¡Œå¸¦ç½®ä¿¡åº¦è¿‡æ»¤çš„æŸ¥è¯¢

        Args:
            query: SQLæŸ¥è¯¢è¯­å¥
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            params: æŸ¥è¯¢å‚æ•°

        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        if not 0 <= min_confidence <= 1:
            raise ValueError(f"ç½®ä¿¡åº¦å¿…é¡»åœ¨[0, 1]èŒƒå›´å†…ï¼Œå½“å‰å€¼: {min_confidence}")

        filtered_query = f"""
            SELECT *
            FROM ({query}) AS subquery
            WHERE probability >= %s
        """

        with self.get_connection() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                try:
                    if params:
                        cur.execute(filtered_query, params + (min_confidence,))
                    else:
                        cur.execute(filtered_query, (min_confidence,))

                    results = cur.fetchall()
                    logger.info(f"æŸ¥è¯¢è¿”å› {len(results)} æ¡ç»“æœ")
                    return [dict(row) for row in results]

                except psycopg2.Error as e:
                    logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    raise

    def aggregate_probabilistic(
        self,
        table_name: str,
        column: str,
        filters: Optional[Dict] = None
    ) -> Dict:
        """
        æ¦‚ç‡èšåˆæŸ¥è¯¢

        Args:
            table_name: è¡¨å
            column: åˆ—åï¼ˆæ¦‚ç‡å€¼åˆ—ï¼‰
            filters: è¿‡æ»¤æ¡ä»¶å­—å…¸

        Returns:
            èšåˆç»“æœå­—å…¸
        """
        where_clause = ""
        params = []

        if filters:
            conditions = []
            for key, value in filters.items():
                conditions.append(f"{key} = %s")
                params.append(value)
            where_clause = "WHERE " + " AND ".join(conditions)

        query = f"""
            SELECT
                AVG(({column}).value) AS avg_value,
                AVG(({column}).probability) AS avg_confidence,
                MIN(({column}).value) AS min_value,
                MAX(({column}).value) AS max_value,
                COUNT(*) AS count
            FROM {table_name}
            {where_clause}
        """

        with self.get_connection() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                try:
                    cur.execute(query, tuple(params))
                    result = cur.fetchone()
                    return dict(result) if result else {}

                except psycopg2.Error as e:
                    logger.error(f"èšåˆæŸ¥è¯¢å¤±è´¥: {e}")
                    raise

    def update_probability(
        self,
        table_name: str,
        row_id: int,
        column: str,
        new_probability: float
    ) -> bool:
        """
        æ›´æ–°æ¦‚ç‡å€¼

        Args:
            table_name: è¡¨å
            row_id: è¡ŒID
            column: åˆ—å
            new_probability: æ–°çš„æ¦‚ç‡å€¼

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        if not 0 <= new_probability <= 1:
            raise ValueError(f"æ¦‚ç‡å€¼å¿…é¡»åœ¨[0, 1]èŒƒå›´å†…ï¼Œå½“å‰å€¼: {new_probability}")

        query = f"""
            UPDATE {table_name}
            SET {column} = ROW(({column}).value, %s)::probability_value
            WHERE id = %s
        """

        with self.get_connection() as conn:
            with conn.cursor() as cur:
                try:
                    cur.execute(query, (new_probability, row_id))
                    affected = cur.rowcount
                    logger.info(f"æ›´æ–° {affected} è¡Œæ•°æ®")
                    return affected > 0

                except psycopg2.Error as e:
                    logger.error(f"æ›´æ–°æ¦‚ç‡å€¼å¤±è´¥: {e}")
                    raise

    def batch_update_probability(
        self,
        table_name: str,
        updates: List[Tuple[int, str, float]]
    ) -> int:
        """
        æ‰¹é‡æ›´æ–°æ¦‚ç‡å€¼

        Args:
            table_name: è¡¨å
            updates: æ›´æ–°åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(row_id, column, new_probability)

        Returns:
            æ›´æ–°çš„è¡Œæ•°
        """
        updated_count = 0

        with self.get_connection() as conn:
            with conn.cursor() as cur:
                try:
                    for row_id, column, new_probability in updates:
                        if not 0 <= new_probability <= 1:
                            logger.warning(f"è·³è¿‡æ— æ•ˆæ¦‚ç‡å€¼: {new_probability}")
                            continue

                        query = f"""
                            UPDATE {table_name}
                            SET {column} = ROW(({column}).value, %s)::probability_value
                            WHERE id = %s
                        """

                        cur.execute(query, (new_probability, row_id))
                        updated_count += cur.rowcount

                    conn.commit()
                    logger.info(f"æ‰¹é‡æ›´æ–° {updated_count} è¡Œæ•°æ®")
                    return updated_count

                except psycopg2.Error as e:
                    logger.error(f"æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
                    conn.rollback()
                    raise

    def close(self):
        """å…³é—­è¿æ¥æ± """
        if self.conn_pool:
            self.conn_pool.closeall()
            logger.info("è¿æ¥æ± å·²å…³é—­")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = ProbabilisticDBClient(
        "host=localhost dbname=testdb user=postgres password=secret",
        min_conn=2,
        max_conn=10
    )

    try:
        # æ’å…¥æ¦‚ç‡æ•°æ®
        client.insert_probabilistic_data('sensor_readings', {
            'sensor_id': 1,
            'temperature': ProbabilityValue(25.5, 0.95),
            'humidity': ProbabilityValue(60.0, 0.90),
            'timestamp': 'NOW()'
        })

        # æ‰¹é‡æ’å…¥
        batch_data = [
            {
                'sensor_id': i,
                'temperature': ProbabilityValue(25.0 + i * 0.1, 0.9),
                'humidity': ProbabilityValue(60.0 + i * 0.5, 0.85),
                'timestamp': 'NOW()'
            }
            for i in range(1, 11)
        ]
        client.insert_probabilistic_data('sensor_readings', batch_data)

        # æŸ¥è¯¢é«˜ç½®ä¿¡åº¦æ•°æ®
        results = client.query_with_confidence("""
            SELECT * FROM sensor_readings
            WHERE sensor_id = 1
        """, min_confidence=0.85)

        print(f"æŸ¥è¯¢ç»“æœ: {len(results)} æ¡")

        # æ¦‚ç‡èšåˆ
        stats = client.aggregate_probabilistic(
            'sensor_readings',
            'temperature',
            filters={'sensor_id': 1}
        )
        print(f"ç»Ÿè®¡ç»“æœ: {stats}")

        # æ›´æ–°æ¦‚ç‡å€¼
        client.update_probability('sensor_readings', 1, 'temperature', 0.98)

        # æ‰¹é‡æ›´æ–°æ¦‚ç‡å€¼
        updates = [
            (i, 'temperature', 0.95) for i in range(1, 6)
        ]
        client.batch_update_probability('sensor_readings', updates)

    finally:
        # å…³é—­è¿æ¥æ± 
        client.close()
```

### 9.3 ProvSQL æ¦‚ç‡æŸ¥è¯¢é›†æˆ

#### **9.3.1 ProvSQLé›†æˆå®Œæ•´ç¤ºä¾‹**

**ä½¿ç”¨ ProvSQL è¿›è¡Œæ¦‚ç‡æŸ¥è¯¢**ï¼š

```sql
-- å¯ç”¨ ProvSQLï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'provsql') THEN
            CREATE EXTENSION provsql;
            RAISE NOTICE 'ProvSQLæ‰©å±•å·²åˆ›å»º';
        ELSE
            RAISE NOTICE 'ProvSQLæ‰©å±•å·²å­˜åœ¨';
        END IF;
    EXCEPTION
        WHEN undefined_file THEN
            RAISE WARNING 'ProvSQLæ‰©å±•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…';
        WHEN insufficient_privilege THEN
            RAISE WARNING 'æƒé™ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºæ‰©å±•';
        WHEN OTHERS THEN
            RAISE WARNING 'åˆ›å»ºProvSQLæ‰©å±•å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- åˆ›å»ºæ¦‚ç‡è¡¨ï¼ˆå¸¦æº¯æºï¼‰
CREATE TABLE IF NOT EXISTS uncertain_data (
    id SERIAL PRIMARY KEY,
    value NUMERIC NOT NULL,
    confidence NUMERIC CHECK (confidence >= 0 AND confidence <= 1),
    data_source VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW()
) WITH PROVENANCE;

-- åˆ›å»ºç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
CREATE INDEX IF NOT EXISTS idx_confidence ON uncertain_data(confidence);
CREATE INDEX IF NOT EXISTS idx_data_source ON uncertain_data(data_source);

-- æ’å…¥æ•°æ®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'uncertain_data') THEN
            RAISE WARNING 'è¡¨ uncertain_data ä¸å­˜åœ¨ï¼Œæ— æ³•æ’å…¥æ•°æ®';
            RETURN;
        END IF;

        INSERT INTO uncertain_data (value, confidence, data_source)
        VALUES
            (10.5, 0.9, 'sensor_1'),
            (11.2, 0.85, 'sensor_2'),
            (9.8, 0.95, 'sensor_1'),
            (10.1, 0.88, 'sensor_3'),
            (11.5, 0.92, 'sensor_2');

        RAISE NOTICE 'å·²æ’å…¥5æ¡æ¦‚ç‡æ•°æ®';
    EXCEPTION
        WHEN check_violation THEN
            RAISE WARNING 'æ¦‚ç‡å€¼è¶…å‡ºèŒƒå›´[0, 1]';
        WHEN OTHERS THEN
            RAISE WARNING 'æ’å…¥æ•°æ®å¤±è´¥: %', SQLERRM;
            RAISE;
    END;
END $$;

-- æ¦‚ç‡æŸ¥è¯¢ï¼šè®¡ç®—åŠ æƒå¹³å‡å€¼
SELECT
    data_source,
    COUNT(*) AS record_count,
    SUM(value * confidence) / SUM(confidence) AS weighted_avg,
    AVG(confidence) AS avg_confidence,
    MIN(confidence) AS min_confidence,
    MAX(confidence) AS max_confidence
FROM uncertain_data
GROUP BY data_source
ORDER BY avg_confidence DESC;

-- ä½¿ç”¨ ProvSQL æº¯æºæ¦‚ç‡è®¡ç®—
SELECT
    provsql_provenance_of(
        SELECT SUM(value * confidence) / SUM(confidence)
        FROM uncertain_data
        WHERE confidence > 0.8
    ) AS provenance,
    SUM(value * confidence) / SUM(confidence) AS weighted_avg
FROM uncertain_data
WHERE confidence > 0.8;
```

#### **9.3.2 ProvSQLæ¦‚ç‡æŸ¥è¯¢å‡½æ•°**

**åˆ›å»ºæ¦‚ç‡æŸ¥è¯¢å‡½æ•°**ï¼š

```sql
-- æ¦‚ç‡åŠ æƒå¹³å‡å‡½æ•°
CREATE OR REPLACE FUNCTION provsql_weighted_avg(
    table_name TEXT,
    value_column TEXT,
    confidence_column TEXT,
    filter_condition TEXT DEFAULT 'TRUE'
) RETURNS TABLE (
    weighted_avg NUMERIC,
    avg_confidence NUMERIC,
    provenance JSONB
) AS $$
DECLARE
    query_text TEXT;
BEGIN
    query_text := format('
        SELECT
            SUM(%I * %I) / SUM(%I) AS weighted_avg,
            AVG(%I) AS avg_confidence,
            provsql_provenance_of(
                SELECT SUM(%I * %I) / SUM(%I)
                FROM %I
                WHERE %s
            )::JSONB AS provenance
        FROM %I
        WHERE %s
    ',
        value_column, confidence_column, confidence_column,
        confidence_column,
        value_column, confidence_column, confidence_column,
        table_name, filter_condition,
        table_name, filter_condition
    );

    RETURN QUERY EXECUTE query_text;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨æ¦‚ç‡æŸ¥è¯¢å‡½æ•°
SELECT * FROM provsql_weighted_avg(
    'uncertain_data',
    'value',
    'confidence',
    'confidence > 0.8'
);
```

#### **9.3.3 ProvSQLæ¦‚ç‡æŸ¥è¯¢Pythoné›†æˆ**

**Pythonå®¢æˆ·ç«¯é›†æˆProvSQL**ï¼š

```python
# provsql_integration.py
from probabilistic_client import ProbabilisticDBClient
import json

class ProvSQLClient(ProbabilisticDBClient):
    """ProvSQLæ¦‚ç‡æŸ¥è¯¢å®¢æˆ·ç«¯"""

    def provsql_weighted_avg(
        self,
        table_name: str,
        value_column: str,
        confidence_column: str,
        filter_condition: str = 'TRUE'
    ) -> dict:
        """
        ä½¿ç”¨ProvSQLè®¡ç®—æ¦‚ç‡åŠ æƒå¹³å‡å€¼

        Args:
            table_name: è¡¨å
            value_column: å€¼åˆ—å
            confidence_column: ç½®ä¿¡åº¦åˆ—å
            filter_condition: è¿‡æ»¤æ¡ä»¶

        Returns:
            åŒ…å«åŠ æƒå¹³å‡å€¼ã€å¹³å‡ç½®ä¿¡åº¦å’Œæº¯æºä¿¡æ¯çš„å­—å…¸
        """
        query = f"""
            SELECT * FROM provsql_weighted_avg(
                '{table_name}',
                '{value_column}',
                '{confidence_column}',
                '{filter_condition}'
            )
        """

        with self.get_connection() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(query)
                result = cur.fetchone()

                if result:
                    return {
                        'weighted_avg': float(result['weighted_avg']),
                        'avg_confidence': float(result['avg_confidence']),
                        'provenance': json.loads(result['provenance']) if isinstance(result['provenance'], str) else result['provenance']
                    }
                return None

    def get_provenance(self, table_name: str, record_id: int) -> dict:
        """
        è·å–è®°å½•çš„æº¯æºä¿¡æ¯

        Args:
            table_name: è¡¨å
            record_id: è®°å½•ID

        Returns:
            æº¯æºä¿¡æ¯å­—å…¸
        """
        query = f"""
            SELECT provsql_provenance_of(
                SELECT * FROM {table_name} WHERE id = %s
            ) AS provenance
        """

        with self.get_connection() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(query, (record_id,))
                result = cur.fetchone()

                if result:
                    provenance = result['provenance']
                    return json.loads(provenance) if isinstance(provenance, str) else provenance
                return None

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    client = ProvSQLClient("host=localhost dbname=testdb user=postgres password=secret")

    # è®¡ç®—æ¦‚ç‡åŠ æƒå¹³å‡å€¼
    result = client.provsql_weighted_avg(
        'uncertain_data',
        'value',
        'confidence',
        'confidence > 0.8'
    )

    print(f"åŠ æƒå¹³å‡å€¼: {result['weighted_avg']:.2f}")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {result['avg_confidence']:.2%}")
    print(f"æº¯æºä¿¡æ¯: {json.dumps(result['provenance'], indent=2)}")

    # è·å–æº¯æºä¿¡æ¯
    provenance = client.get_provenance('uncertain_data', 1)
    print(f"è®°å½•1çš„æº¯æºä¿¡æ¯: {json.dumps(provenance, indent=2)}")
```

### 9.4 Docker Compose éƒ¨ç½²é…ç½®

#### **9.4.1 å®Œæ•´Docker Composeé…ç½®**

**docker-compose.yml**ï¼š

```yaml
version: '3.8'

services:
  postgresql:
    image: postgres:18
    container_name: probabilistic_postgres
    environment:
      POSTGRES_DB: testdb
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init_probabilistic.sql:/docker-entrypoint-initdb.d/init.sql
      - ./provsql:/usr/local/share/postgresql/extension
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - probabilistic_network

  python-client:
    image: python:3.11
    container_name: probabilistic_client
    volumes:
      - ./client:/app
    working_dir: /app
    command: python probabilistic_client.py
    depends_on:
      postgresql:
        condition: service_healthy
    environment:
      DB_HOST: postgresql
      DB_PORT: 5432
      DB_NAME: testdb
      DB_USER: postgres
      DB_PASSWORD: secret
    networks:
      - probabilistic_network
    restart: unless-stopped

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: probabilistic_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    ports:
      - "5050:80"
    depends_on:
      - postgresql
    networks:
      - probabilistic_network
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local

networks:
  probabilistic_network:
    driver: bridge
```

#### **9.4.2 åˆå§‹åŒ–SQLè„šæœ¬**

**init_probabilistic.sql**ï¼š

```sql
-- åˆå§‹åŒ–æ¦‚ç‡æ•°æ®åº“
-- åˆ›å»ºæ‰©å±•
CREATE EXTENSION IF NOT EXISTS provsql;

-- åˆ›å»ºæ¦‚ç‡æ•°æ®ç±»å‹
CREATE TYPE probability_value AS (
    value NUMERIC,
    confidence NUMERIC
);

-- åˆ›å»ºæ¦‚ç‡è¡¨
CREATE TABLE IF NOT EXISTS uncertain_data (
    id SERIAL PRIMARY KEY,
    value NUMERIC NOT NULL,
    confidence NUMERIC CHECK (confidence >= 0 AND confidence <= 1),
    data_source VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW()
) WITH PROVENANCE;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_confidence ON uncertain_data(confidence);
CREATE INDEX IF NOT EXISTS idx_data_source ON uncertain_data(data_source);
CREATE INDEX IF NOT EXISTS idx_created_at ON uncertain_data(created_at);

-- æ’å…¥ç¤ºä¾‹æ•°æ®
INSERT INTO uncertain_data (value, confidence, data_source)
VALUES
    (10.5, 0.9, 'sensor_1'),
    (11.2, 0.85, 'sensor_2'),
    (9.8, 0.95, 'sensor_1'),
    (10.1, 0.88, 'sensor_3'),
    (11.5, 0.92, 'sensor_2');

-- åˆ›å»ºæ¦‚ç‡æŸ¥è¯¢å‡½æ•°
CREATE OR REPLACE FUNCTION provsql_weighted_avg(
    table_name TEXT,
    value_column TEXT,
    confidence_column TEXT,
    filter_condition TEXT DEFAULT 'TRUE'
) RETURNS TABLE (
    weighted_avg NUMERIC,
    avg_confidence NUMERIC,
    provenance JSONB
) AS $$
DECLARE
    query_text TEXT;
BEGIN
    query_text := format('
        SELECT
            SUM(%I * %I) / SUM(%I) AS weighted_avg,
            AVG(%I) AS avg_confidence,
            provsql_provenance_of(
                SELECT SUM(%I * %I) / SUM(%I)
                FROM %I
                WHERE %s
            )::JSONB AS provenance
        FROM %I
        WHERE %s
    ',
        value_column, confidence_column, confidence_column,
        confidence_column,
        value_column, confidence_column, confidence_column,
        table_name, filter_condition,
        table_name, filter_condition
    );

    RETURN QUERY EXECUTE query_text;
END;
$$ LANGUAGE plpgsql;
```

#### **9.4.3 Pythonå®¢æˆ·ç«¯é…ç½®**

**client/probabilistic_client.py**ï¼š

```python
# probabilistic_client.py
import os
import psycopg2
from psycopg2 import pool
from psycopg2.extras import RealDictCursor
from contextlib import contextmanager
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProbabilisticDBClient:
    """æ¦‚ç‡æ•°æ®åº“å®¢æˆ·ç«¯"""

    def __init__(self):
        """ä»ç¯å¢ƒå˜é‡è¯»å–æ•°æ®åº“é…ç½®"""
        self.conn_pool = psycopg2.pool.ThreadedConnectionPool(
            1, 10,
            host=os.getenv('DB_HOST', 'localhost'),
            port=os.getenv('DB_PORT', '5432'),
            database=os.getenv('DB_NAME', 'testdb'),
            user=os.getenv('DB_USER', 'postgres'),
            password=os.getenv('DB_PASSWORD', 'secret')
        )

    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        conn = None
        try:
            conn = self.conn_pool.getconn()
            yield conn
            conn.commit()
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise
        finally:
            if conn:
                self.conn_pool.putconn(conn)

    def test_connection(self):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        with self.get_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("SELECT version();")
                version = cur.fetchone()
                logger.info(f"PostgreSQLç‰ˆæœ¬: {version[0]}")
                return version[0]

if __name__ == '__main__':
    client = ProbabilisticDBClient()
    client.test_connection()
    logger.info("æ¦‚ç‡æ•°æ®åº“å®¢æˆ·ç«¯æµ‹è¯•æˆåŠŸ")
```

#### **9.4.4 éƒ¨ç½²å’Œä½¿ç”¨è¯´æ˜**

**éƒ¨ç½²æ­¥éª¤**ï¼š

1. **å‡†å¤‡æ–‡ä»¶**ï¼š

   ```bash
   mkdir -p probabilistic_db
   cd probabilistic_db
   # åˆ›å»ºdocker-compose.yml
   # åˆ›å»ºinit_probabilistic.sql
   # åˆ›å»ºclient/probabilistic_client.py
   ```

2. **å¯åŠ¨æœåŠ¡**ï¼š

   ```bash
   docker-compose up -d
   ```

3. **æ£€æŸ¥æœåŠ¡çŠ¶æ€**ï¼š

   ```bash
   docker-compose ps
   docker-compose logs postgresql
   docker-compose logs python-client
   ```

4. **è®¿é—®PgAdmin**ï¼š
   - æ‰“å¼€æµè§ˆå™¨è®¿é—®: <http://localhost:5050>
   - ç™»å½•: <admin@example.com> / admin
   - æ·»åŠ æœåŠ¡å™¨: postgresql (host: postgresql, port: 5432)

5. **åœæ­¢æœåŠ¡**ï¼š

   ```bash
   docker-compose down
   ```

6. **æ¸…ç†æ•°æ®**ï¼š

   ```bash
   docker-compose down -v
   ```

**ä½¿ç”¨è¯´æ˜**ï¼š

- **æ•°æ®åº“è¿æ¥**: localhost:5432
- **æ•°æ®åº“å**: testdb
- **ç”¨æˆ·å**: postgres
- **å¯†ç **: secret
- **PgAdmin**: <http://localhost:5050>
- **Pythonå®¢æˆ·ç«¯**: è‡ªåŠ¨è¿è¡Œï¼Œæ£€æŸ¥æ—¥å¿—æŸ¥çœ‹ç»“æœ

---

**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**ç»´æŠ¤çŠ¶æ€**: âœ… æŒç»­æ›´æ–°

```
