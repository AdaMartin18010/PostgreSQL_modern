---

> **📋 文档来源**: `MVCC-ACID-CAP\03-场景实践\日志系统\高频写入完整案例.md`
> **📅 复制日期**: 2025-12-22
> **⚠️ 注意**: 本文档为复制版本，原文件保持不变

---

# 日志系统高频写入完整案例

> **文档编号**: SCENARIO-LOG-001
> **主题**: 日志系统高频写入
> **版本**: PostgreSQL 17 & 18

---

## 📑 目录

- [日志系统高频写入完整案例](#日志系统高频写入完整案例)
  - [📑 目录](#-目录)
  - [📋 概述](#-概述)
  - [🔍 第一部分：业务场景分析](#-第一部分业务场景分析)
    - [1.1 业务需求](#11-业务需求)
      - [核心需求](#核心需求)
      - [性能要求](#性能要求)
      - [存储要求](#存储要求)
    - [1.2 写入场景](#12-写入场景)
      - [高频写入](#高频写入)
      - [批量写入](#批量写入)
      - [表膨胀问题](#表膨胀问题)
  - [🚀 第二部分：数据库设计](#-第二部分数据库设计)
    - [2.1 分区表设计](#21-分区表设计)
      - [按时间分区](#按时间分区)
      - [分区策略](#分区策略)
      - [自动分区管理](#自动分区管理)
    - [2.2 表结构设计](#22-表结构设计)
      - [日志表设计](#日志表设计)
      - [索引设计](#索引设计)
    - [2.3 MVCC优化设计](#23-mvcc优化设计)
      - [fillfactor设置](#fillfactor设置)
      - [VACUUM策略](#vacuum策略)
  - [📊 第三部分：写入实现方案](#-第三部分写入实现方案)
    - [3.1 方案1：批量插入](#31-方案1批量插入)
      - [实现代码](#实现代码)
    - [3.2 方案2：COPY命令](#32-方案2copy命令)
      - [3.2.1 实现代码](#321-实现代码)
    - [3.3 方案](#33-方案)
      - [实现代码](#实现代码-1)
  - [🔧 第四部分：多语言实现](#-第四部分多语言实现)
    - [4.1 Python实现](#41-python实现)
    - [4.2 Java实现](#42-java实现)
    - [4.3 Go实现](#43-go实现)
  - [📈 第五部分：性能优化](#-第五部分性能优化)
    - [5.1 COPY命令优化](#51-copy命令优化)
    - [5.2 连接池优化](#52-连接池优化)
    - [5.3 批量大小优化](#53-批量大小优化)
  - [🎯 第六部分：归档和清理](#-第六部分归档和清理)
    - [6.1 归档策略](#61-归档策略)
    - [6.2 清理策略](#62-清理策略)
  - [📝 总结](#-总结)
    - [核心方案](#核心方案)
    - [最佳实践](#最佳实践)
    - [性能指标](#性能指标)

---

## 📋 概述

日志系统高频写入是典型的时序数据场景，需要支持高并发写入、高效查询和自动归档。
本文档提供完整的解决方案，涵盖分区表设计、批量写入、性能优化和归档策略。

---

## 🔍 第一部分：业务场景分析

### 1.1 业务需求

#### 核心需求

```sql
-- 业务场景：应用日志写入
-- 要求：
-- 1. 高并发写入（10000+ QPS）
-- 2. 低延迟（<10ms）
-- 3. 数据持久化
-- 4. 按时间查询
-- 5. 自动归档和清理
```

#### 性能要求

- **写入QPS**: 10000+
- **写入延迟**: P99 < 10ms
- **查询性能**: 时间范围查询 < 100ms
- **存储成本**: 优化存储空间

#### 存储要求

- **数据保留**: 30天热数据，1年冷数据
- **存储压缩**: 支持压缩存储
- **自动归档**: 自动归档旧数据

### 1.2 写入场景

#### 高频写入

```sql
-- 场景：10000个应用实例同时写入日志
-- 问题：如何保证写入性能？
```

#### 批量写入

```sql
-- 场景：应用批量收集日志后写入
-- 问题：如何优化批量写入性能？
```

#### 表膨胀问题

```sql
-- 问题：高频写入导致表快速膨胀
-- 解决：分区表 + 定期清理
```

---

## 🚀 第二部分：数据库设计

### 2.1 分区表设计

#### 按时间分区

```sql
-- 日志表（分区表，带错误处理）
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE NOTICE '表 app_logs 已存在';
        ELSE
            CREATE TABLE app_logs (
                id BIGSERIAL,
                app_name VARCHAR(100) NOT NULL,
                level VARCHAR(20) NOT NULL,
                message TEXT NOT NULL,
                metadata JSONB,
                created_at TIMESTAMP NOT NULL DEFAULT NOW(),
                PRIMARY KEY (id, created_at)
            ) PARTITION BY RANGE (created_at);
            RAISE NOTICE '表 app_logs 创建成功（分区表）';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '表 app_logs 已存在';
        WHEN OTHERS THEN
            RAISE WARNING '创建表失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 创建分区（按月，带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法创建分区';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_tables WHERE schemaname = 'public' AND tablename = 'app_logs_2024_01') THEN
            CREATE TABLE app_logs_2024_01 PARTITION OF app_logs
            FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
            RAISE NOTICE '分区 app_logs_2024_01 创建成功';
        ELSE
            RAISE NOTICE '分区 app_logs_2024_01 已存在';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_tables WHERE schemaname = 'public' AND tablename = 'app_logs_2024_02') THEN
            CREATE TABLE app_logs_2024_02 PARTITION OF app_logs
            FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
            RAISE NOTICE '分区 app_logs_2024_02 创建成功';
        ELSE
            RAISE NOTICE '分区 app_logs_2024_02 已存在';
        END IF;
        -- ... 其他月份分区
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '部分分区已存在';
        WHEN OTHERS THEN
            RAISE WARNING '创建分区失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### 分区策略

```sql
-- 分区策略（带错误处理）：
-- 1. 按月分区（适合中等规模）
-- 2. 按周分区（适合大规模）
-- 3. 按日分区（适合超大规模）

-- 按日分区示例（带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法创建按日分区';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_tables WHERE schemaname = 'public' AND tablename = 'app_logs_2024_01_01') THEN
            CREATE TABLE app_logs_2024_01_01 PARTITION OF app_logs
            FOR VALUES FROM ('2024-01-01') TO ('2024-01-02');
            RAISE NOTICE '按日分区 app_logs_2024_01_01 创建成功';
        ELSE
            RAISE NOTICE '按日分区 app_logs_2024_01_01 已存在';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '分区已存在';
        WHEN OTHERS THEN
            RAISE WARNING '创建按日分区失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### 自动分区管理

```sql
-- 自动创建分区函数（带完整错误处理）
CREATE OR REPLACE FUNCTION create_partition_if_not_exists(
    table_name TEXT,
    start_date DATE,
    end_date DATE
) RETURNS VOID AS $$
DECLARE
    partition_name TEXT;
    table_exists BOOLEAN;
BEGIN
    BEGIN
        -- 检查表是否存在
        SELECT EXISTS (
            SELECT 1 FROM information_schema.tables
            WHERE table_schema = 'public'
            AND table_name = create_partition_if_not_exists.table_name
        ) INTO table_exists;

        IF NOT table_exists THEN
            RAISE EXCEPTION '表 % 不存在，无法创建分区', table_name;
        END IF;

        -- 生成分区名称
        partition_name := table_name || '_' || to_char(start_date, 'YYYY_MM_DD');

        -- 检查分区是否已存在
        IF EXISTS (
            SELECT 1 FROM pg_tables
            WHERE schemaname = 'public'
            AND tablename = partition_name
        ) THEN
            RAISE NOTICE '分区 % 已存在，跳过创建', partition_name;
            RETURN;
        END IF;

        -- 创建分区
        BEGIN
            EXECUTE format('
                CREATE TABLE IF NOT EXISTS %I PARTITION OF %I
                FOR VALUES FROM (%L) TO (%L)',
                partition_name, table_name, start_date, end_date
            );
            RAISE NOTICE '分区 % 创建成功', partition_name;
        EXCEPTION
            WHEN duplicate_table THEN
                RAISE NOTICE '分区 % 已存在，跳过创建', partition_name;
            WHEN OTHERS THEN
                RAISE WARNING '创建分区 % 失败: %', partition_name, SQLERRM;
                RAISE;
        END;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'create_partition_if_not_exists执行失败: %', SQLERRM;
    END;
END;
$$ LANGUAGE plpgsql;

-- 自动创建下个月的分区（带错误处理）
DO $$
DECLARE
    v_start_date DATE;
    v_end_date DATE;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'create_partition_if_not_exists') THEN
            RAISE WARNING '函数 create_partition_if_not_exists 不存在，无法创建分区';
            RETURN;
        END IF;

        BEGIN
            v_start_date := date_trunc('month', NOW() + interval '1 month')::DATE;
            v_end_date := date_trunc('month', NOW() + interval '2 month')::DATE;

            PERFORM create_partition_if_not_exists(
                'app_logs',
                v_start_date,
                v_end_date
            );
            RAISE NOTICE '分区创建成功: % 至 %', v_start_date, v_end_date;
        EXCEPTION
            WHEN OTHERS THEN
                RAISE WARNING '创建分区失败: %', SQLERRM;
                RAISE;
        END;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '操作失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

### 2.2 表结构设计

#### 日志表设计

```sql
-- 日志表（优化设计，带错误处理）
DO $$
BEGIN
    BEGIN
        IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE NOTICE '表 app_logs 已存在';
        ELSE
            CREATE TABLE app_logs (
                id BIGSERIAL,
                app_name VARCHAR(100) NOT NULL,
                level VARCHAR(20) NOT NULL,
                message TEXT NOT NULL,
                metadata JSONB,
                created_at TIMESTAMP NOT NULL DEFAULT NOW(),
                PRIMARY KEY (id, created_at)
            ) PARTITION BY RANGE (created_at);
            RAISE NOTICE '表 app_logs 创建成功（优化设计）';
        END IF;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE WARNING '表 app_logs 已存在';
        WHEN OTHERS THEN
            RAISE WARNING '创建表失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- 索引（只在分区上创建，带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法创建索引';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE schemaname = 'public' AND tablename = 'app_logs' AND indexname = 'idx_app_logs_app_name') THEN
            CREATE INDEX idx_app_logs_app_name ON app_logs(app_name, created_at);
            RAISE NOTICE '索引 idx_app_logs_app_name 创建成功';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE schemaname = 'public' AND tablename = 'app_logs' AND indexname = 'idx_app_logs_level') THEN
            CREATE INDEX idx_app_logs_level ON app_logs(level, created_at);
            RAISE NOTICE '索引 idx_app_logs_level 创建成功';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE schemaname = 'public' AND tablename = 'app_logs' AND indexname = 'idx_app_logs_created_at') THEN
            CREATE INDEX idx_app_logs_created_at ON app_logs(created_at);
            RAISE NOTICE '索引 idx_app_logs_created_at 创建成功';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE schemaname = 'public' AND tablename = 'app_logs' AND indexname = 'idx_app_logs_metadata') THEN
            CREATE INDEX idx_app_logs_metadata ON app_logs USING GIN(metadata);
            RAISE NOTICE 'GIN索引 idx_app_logs_metadata 创建成功';
        END IF;
    EXCEPTION
        WHEN undefined_table THEN
            RAISE WARNING '表 app_logs 不存在';
        WHEN duplicate_table THEN
            RAISE WARNING '部分索引已存在';
        WHEN OTHERS THEN
            RAISE WARNING '创建索引失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### 索引设计

```sql
-- 分区索引策略（带错误处理）：
-- 1. 主键索引：自动创建
-- 2. 查询索引：按需创建
-- 3. 避免过多索引（影响写入性能）

-- 只创建必要的索引（带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法创建索引';
            RETURN;
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE schemaname = 'public' AND tablename = 'app_logs' AND indexname = 'idx_app_logs_app_time') THEN
            CREATE INDEX idx_app_logs_app_time ON app_logs(app_name, created_at DESC);
            RAISE NOTICE '索引 idx_app_logs_app_time 创建成功';
        ELSE
            RAISE NOTICE '索引 idx_app_logs_app_time 已存在';
        END IF;
    EXCEPTION
        WHEN undefined_table THEN
            RAISE WARNING '表 app_logs 不存在';
        WHEN duplicate_table THEN
            RAISE WARNING '索引 idx_app_logs_app_time 已存在';
        WHEN OTHERS THEN
            RAISE WARNING '创建索引失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

### 2.3 MVCC优化设计

#### fillfactor设置

```sql
-- 日志表：只插入，不更新（带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法设置fillfactor';
        ELSE
            ALTER TABLE app_logs SET (fillfactor = 100);
            RAISE NOTICE '表 app_logs 的fillfactor设置为 100';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs_2024_01') THEN
            RAISE WARNING '分区 app_logs_2024_01 不存在，无法设置fillfactor';
        ELSE
            ALTER TABLE app_logs_2024_01 SET (fillfactor = 100);
            RAISE NOTICE '分区 app_logs_2024_01 的fillfactor设置为 100';
        END IF;
    EXCEPTION
        WHEN undefined_table THEN
            RAISE WARNING '表或分区不存在';
        WHEN OTHERS THEN
            RAISE WARNING '设置fillfactor失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

#### VACUUM策略

```sql
-- 日志表：较少VACUUM（只插入，带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法配置VACUUM';
        ELSE
            ALTER TABLE app_logs SET (
                autovacuum_vacuum_scale_factor = 0.2,
                autovacuum_analyze_scale_factor = 0.1
            );
            RAISE NOTICE '表 app_logs 的VACUUM配置完成';
        END IF;

        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs_2024_12') THEN
            RAISE WARNING '分区 app_logs_2024_12 不存在，无法配置VACUUM';
        ELSE
            ALTER TABLE app_logs_2024_12 SET (
                autovacuum_analyze_scale_factor = 0.05
            );
            RAISE NOTICE '分区 app_logs_2024_12 的VACUUM配置完成（更频繁ANALYZE）';
        END IF;
    EXCEPTION
        WHEN undefined_table THEN
            RAISE WARNING '表或分区不存在';
        WHEN OTHERS THEN
            RAISE WARNING '配置VACUUM失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

---

## 📊 第三部分：写入实现方案

### 3.1 方案1：批量插入

#### 实现代码

```sql
-- 批量插入（推荐，带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法执行批量插入';
            RETURN;
        END IF;
        RAISE NOTICE '开始批量插入测试';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '批量插入准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
INSERT INTO app_logs (app_name, level, message, metadata, created_at)
VALUES
    ('app1', 'INFO', 'message1', '{}', NOW()),
    ('app2', 'ERROR', 'message2', '{}', NOW())
    -- ... 更多记录
ON CONFLICT DO NOTHING;

#### 性能分析

```sql
-- 性能特点：
-- 优点：
-- 1. 事务开销小
-- 2. 性能好
--
-- 缺点：
-- 1. 批量大小有限制
--
-- 性能指标：
-- QPS: 5000-10000（批量1000条）
-- P99延迟: 5-10ms
```

### 3.2 方案2：COPY命令

#### 3.2.1 实现代码

```sql
-- COPY命令（性能最优，带错误处理）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法执行COPY';
            RETURN;
        END IF;
        RAISE NOTICE 'COPY命令需要从STDIN或文件读取数据';
        RAISE NOTICE '示例: COPY app_logs (app_name, level, message, metadata, created_at) FROM STDIN WITH (FORMAT CSV);';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'COPY准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

-- COPY app_logs (app_name, level, message, metadata, created_at)
-- FROM STDIN WITH (FORMAT CSV);

#### 性能分析

```sql
-- 性能特点：
-- 优点：
-- 1. 性能最优
-- 2. 支持大批量
--
-- 缺点：
-- 1. 需要文件或流
--
-- 性能指标：
-- QPS: 10000-20000（批量10000条）
-- P99延迟: 2-5ms
```

### 3.3 方案

#### 实现代码

```sql
-- 时间范围查询（分区裁剪，带错误处理和性能测试）
DO $$
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'app_logs') THEN
            RAISE WARNING '表 app_logs 不存在，无法执行时间范围查询';
            RETURN;
        END IF;
        RAISE NOTICE '开始时间范围查询（分区裁剪）';
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '查询准备失败: %', SQLERRM;
            RAISE;
    END;
END $$;

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM app_logs
WHERE created_at >= '2024-01-01'
  AND created_at < '2024-02-01'
  AND app_name = 'myapp'
ORDER BY created_at DESC
LIMIT 100;

#### 性能分析

```sql
-- 性能特点：
-- 优点：
-- 1. 分区裁剪
-- 2. 查询快速
--
-- 性能指标：
-- 查询时间: < 100ms（单分区）
```

---

## 🔧 第四部分：多语言实现

### 4.1 Python实现

```python
import psycopg2
from psycopg2.extras import execute_batch

def batch_insert_logs(logs):
    """批量插入日志"""
    conn = connection_pool.getconn()
    try:
        cur = conn.cursor()

        # 批量插入
        execute_batch(cur, """
            INSERT INTO app_logs (app_name, level, message, metadata, created_at)
            VALUES (%s, %s, %s, %s, %s)
        """, logs, page_size=1000)

        conn.commit()
        return True

    except Exception as e:
        conn.rollback()
        raise
    finally:
        cur.close()
        connection_pool.putconn(conn)

# COPY命令实现
def copy_insert_logs(logs):
    """使用COPY命令插入日志（性能最优）"""
    conn = connection_pool.getconn()
    try:
        cur = conn.cursor()

        # 使用COPY
        from io import StringIO
        f = StringIO()
        for log in logs:
            f.write(f"{log[0]}\t{log[1]}\t{log[2]}\t{log[3]}\t{log[4]}\n")
        f.seek(0)

        cur.copy_from(f, 'app_logs', columns=('app_name', 'level', 'message', 'metadata', 'created_at'))

        conn.commit()
        return True

    except Exception as e:
        conn.rollback()
        raise
    finally:
        cur.close()
        connection_pool.putconn(conn)
```

### 4.2 Java实现

```java
public void batchInsertLogs(List<Log> logs) {
    String sql = "INSERT INTO app_logs (app_name, level, message, metadata, created_at) VALUES (?, ?, ?, ?, ?)";

    try (Connection conn = dataSource.getConnection();
         PreparedStatement stmt = conn.prepareStatement(sql)) {

        conn.setAutoCommit(false);

        for (Log log : logs) {
            stmt.setString(1, log.getAppName());
            stmt.setString(2, log.getLevel());
            stmt.setString(3, log.getMessage());
            stmt.setString(4, log.getMetadata());
            stmt.setTimestamp(5, log.getCreatedAt());
            stmt.addBatch();

            if (stmt.getParameterMetaData().getParameterCount() % 1000 == 0) {
                stmt.executeBatch();
            }
        }

        stmt.executeBatch();
        conn.commit();
    }
}
```

### 4.3 Go实现

```go
func BatchInsertLogs(ctx context.Context, pool *pgxpool.Pool, logs []Log) error {
    batch := &pgx.Batch{}

    for _, log := range logs {
        batch.Queue(
            "INSERT INTO app_logs (app_name, level, message, metadata, created_at) VALUES ($1, $2, $3, $4, $5)",
            log.AppName, log.Level, log.Message, log.Metadata, log.CreatedAt,
        )
    }

    return pool.SendBatch(ctx, batch).Close()
}
```

---

## 📈 第五部分：性能优化

### 5.1 COPY命令优化

```python
# COPY命令优化（性能最优）
def optimized_copy_insert(logs):
    """优化的COPY插入"""
    conn = connection_pool.getconn()
    try:
        cur = conn.cursor()

        # 使用COPY FROM
        with cur.copy("COPY app_logs (app_name, level, message, metadata, created_at) FROM STDIN") as copy:
            for log in logs:
                copy.write_row([log.app_name, log.level, log.message, log.metadata, log.created_at])

        conn.commit()
        return True

    except Exception as e:
        conn.rollback()
        raise
    finally:
        cur.close()
        connection_pool.putconn(conn)
```

### 5.2 连接池优化

```python
# 日志系统连接池配置（高并发）
connection_pool = psycopg2.pool.ThreadedConnectionPool(
    minconn=20,
    maxconn=100,  # 高并发写入
    host="localhost",
    database="logs",
    user="postgres",
    password="password",
)
```

### 5.3 批量大小优化

```python
# 批量大小优化
BATCH_SIZE = 1000  # 推荐批量大小

def insert_logs_optimized(logs):
    """优化的批量插入"""
    for i in range(0, len(logs), BATCH_SIZE):
        batch = logs[i:i+BATCH_SIZE]
        batch_insert_logs(batch)
```

---

## 🎯 第六部分：归档和清理

### 6.1 归档策略

```sql
-- 归档函数（带完整错误处理）
CREATE OR REPLACE FUNCTION archive_old_logs(archive_date DATE)
RETURNS VOID AS $$
DECLARE
    partition_name TEXT;
    partition_exists BOOLEAN;
BEGIN
    BEGIN
        -- 归档30天前的数据
        partition_name := 'app_logs_' || to_char(archive_date, 'YYYY_MM');

        -- 检查分区是否存在
        SELECT EXISTS (
            SELECT 1 FROM information_schema.tables
            WHERE table_schema = 'public'
            AND table_name = partition_name
        ) INTO partition_exists;

        IF NOT partition_exists THEN
            RAISE WARNING '分区 % 不存在，无法归档', partition_name;
            RETURN;
        END IF;

        RAISE NOTICE '开始归档分区: %', partition_name;

        -- 导出到文件（需要文件系统权限）
        BEGIN
            EXECUTE format('COPY (SELECT * FROM %I) TO ''/archive/%s.csv'' CSV',
                           partition_name, partition_name);
            RAISE NOTICE '分区 % 数据已导出到文件', partition_name;
        EXCEPTION
            WHEN insufficient_privilege THEN
                RAISE WARNING '没有文件系统写权限，无法导出数据';
                RAISE;
            WHEN OTHERS THEN
                RAISE WARNING '导出数据失败: %', SQLERRM;
                RAISE;
        END;

        -- 删除分区
        BEGIN
            EXECUTE format('DROP TABLE IF EXISTS %I', partition_name);
            RAISE NOTICE '分区 % 已删除', partition_name;
        EXCEPTION
            WHEN OTHERS THEN
                RAISE WARNING '删除分区失败: %', SQLERRM;
                RAISE;
        END;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'archive_old_logs执行失败: %', SQLERRM;
    END;
END;
$$ LANGUAGE plpgsql;
END;
$$ LANGUAGE plpgsql;

-- 定期归档（带错误处理）
DO $$
DECLARE
    v_archive_date TIMESTAMP;
    v_archived_count INTEGER;
BEGIN
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'archive_old_logs') THEN
            RAISE WARNING '函数 archive_old_logs 不存在，无法执行归档';
            RETURN;
        END IF;

        BEGIN
            v_archive_date := NOW() - interval '30 days';
            PERFORM archive_old_logs(v_archive_date);
            RAISE NOTICE '归档完成，归档日期: %', v_archive_date;
        EXCEPTION
            WHEN OTHERS THEN
                RAISE WARNING '归档失败: %', SQLERRM;
                RAISE;
        END;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING '操作失败: %', SQLERRM;
            RAISE;
    END;
END $$;
```

### 6.2 清理策略

```sql
-- 清理策略（带完整错误处理）：
-- 1. 30天内：保留在数据库中
-- 2. 30-365天：归档到文件
-- 3. 365天以上：删除

-- 自动清理函数（带完整错误处理）
CREATE OR REPLACE FUNCTION auto_cleanup_logs()
RETURNS VOID AS $$
DECLARE
    archive_date DATE;
    cleanup_count INTEGER := 0;
BEGIN
    BEGIN
        -- 检查archive_old_logs函数是否存在
        IF NOT EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'archive_old_logs') THEN
            RAISE EXCEPTION '函数 archive_old_logs 不存在，无法执行自动清理';
        END IF;

        -- 归档30天前的数据
        archive_date := (NOW() - interval '30 days')::DATE;
        BEGIN
            PERFORM archive_old_logs(archive_date);
            cleanup_count := cleanup_count + 1;
            RAISE NOTICE '已归档 % 的数据', archive_date;
        EXCEPTION
            WHEN OTHERS THEN
                RAISE WARNING '归档数据失败: %', SQLERRM;
        END;

        RAISE NOTICE '自动清理完成，处理了 % 个分区', cleanup_count;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE EXCEPTION 'auto_cleanup_logs执行失败: %', SQLERRM;
    END;

    -- 删除365天前的归档文件
    -- （需要外部脚本实现）
END;
$$ LANGUAGE plpgsql;
$$ LANGUAGE plpgsql;
```

---

## 📝 总结

### 核心方案

1. **推荐方案**：分区表 + COPY命令
   - 性能最优
   - 支持高并发
   - 自动归档

2. **备选方案**：分区表 + 批量插入
   - 实现简单
   - 性能良好

### 最佳实践

1. **分区设计**：按时间分区，自动管理
2. **写入优化**：使用COPY命令或批量插入
3. **索引优化**：只创建必要索引
4. **归档策略**：自动归档旧数据
5. **监控告警**：监控写入性能和存储空间

### 性能指标

- **写入QPS**: 10000-20000（COPY命令）
- **P99延迟**: 2-5ms
- **查询性能**: < 100ms（单分区）
- **存储优化**: 分区表 + 自动归档

PostgreSQL 17/18的MVCC机制在日志系统场景下表现优异，通过分区表设计和批量写入优化，可以实现高性能、高可靠性的日志系统。
