#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»ˆæéªŒè¯ï¼šå…¨é¢æ£€æŸ¥æ–‡æ¡£çš„æ‰€æœ‰æ–¹é¢
"""

import os
import re
from pathlib import Path
from collections import defaultdict

base_path = Path(__file__).parent

folders = sorted([
    d for d in base_path.iterdir()
    if d.is_dir() and re.match(r'^\d{2}-', d.name) and
    (d / "README.md").exists()
])

print("=" * 70)
print("ğŸ” ç»ˆæéªŒè¯æŠ¥å‘Š")
print("=" * 70)

total_docs = len(folders)
perfect_docs = []
all_issues = defaultdict(list)
all_warnings = defaultdict(list)

for folder in folders:
    readme_path = folder / "README.md"
    
    try:
        with open(readme_path, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
        
        doc_issues = []
        doc_warnings = []
        
        # 1. åŸºç¡€ç»“æ„æ£€æŸ¥
        if not re.search(r'^##\s+\d+\.\s+', content, re.MULTILINE):
            doc_issues.append("ç¼ºå°‘ç« èŠ‚æ ‡é¢˜")
        
        if not re.search(r'##\s*ğŸ“‘\s*ç›®å½•', content):
            doc_issues.append("ç¼ºå°‘ç›®å½•")
        
        if not re.search(r'è¿”å›.*æ–‡æ¡£é¦–é¡µ', content):
            doc_issues.append("ç¼ºå°‘å¯¼èˆªé“¾æ¥")
        
        # 2. ç›®å½•æ ¼å¼æ£€æŸ¥
        toc_match = re.search(r'##\s*ğŸ“‘\s*ç›®å½•\s*\n(.*?)\n---', content, re.DOTALL)
        if toc_match:
            toc_content = toc_match.group(1)
            # æ£€æŸ¥åµŒå¥—
            if re.search(r'^\s{4,}-', toc_content, re.MULTILINE):
                doc_warnings.append("ç›®å½•åŒ…å«åµŒå¥—å±‚çº§")
            
            # æ£€æŸ¥ç›®å½•é¡¹
            toc_items = re.findall(r'-\s+\[(.+?)\]', toc_content)
            h3_titles = []
            for line in lines:
                h3_match = re.match(r'^###\s+(.+)$', line)
                if h3_match and not line.startswith('####'):
                    h3_titles.append(h3_match.group(1).strip())
            
            if len(toc_items) != len(h3_titles):
                doc_warnings.append(f"ç›®å½•é¡¹æ•°({len(toc_items)})â‰ H3æ ‡é¢˜æ•°({len(h3_titles)})")
        
        # 3. å†…å®¹è´¨é‡æ£€æŸ¥
        if '*æœ¬èŠ‚å†…å®¹å¾…è¡¥å……*' in content:
            placeholder_count = content.count('*æœ¬èŠ‚å†…å®¹å¾…è¡¥å……*')
            doc_warnings.append(f"åŒ…å«{placeholder_count}ä¸ªå ä½å†…å®¹")
        
        if len(content) < 500:
            doc_warnings.append(f"å†…å®¹è¾ƒçŸ­({len(content)}å­—ç¬¦)")
        
        # 4. ä»£ç å—æ£€æŸ¥
        code_blocks = re.findall(r'```', content)
        if len(code_blocks) % 2 != 0:
            doc_warnings.append("ä»£ç å—æœªæ­£ç¡®é—­åˆ")
        
        # 5. é“¾æ¥æ£€æŸ¥
        links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
        for link_text, link_url in links:
            if link_url.startswith('#') and len(link_url) > 1:
                anchor = link_url[1:]
                # æ£€æŸ¥é”šç‚¹æ˜¯å¦å­˜åœ¨
                anchor_found = False
                for line in lines:
                    if re.match(r'^#{2,3}\s+', line):
                        line_anchor = re.sub(r'[^\w\s-]', '', line.lower())
                        line_anchor = re.sub(r'[-\s]+', '-', line_anchor)
                        if anchor in line_anchor or line_anchor.endswith(anchor):
                            anchor_found = True
                            break
                if not anchor_found:
                    doc_warnings.append(f"å¯èƒ½æŸåçš„å†…éƒ¨é“¾æ¥: {link_url}")
        
        # 6. æ ¼å¼ä¸€è‡´æ€§æ£€æŸ¥
        # æ£€æŸ¥ç« èŠ‚ç¼–å·ä¸€è‡´æ€§
        chapter_match = re.search(r'^##\s+(\d+)\.\s+', content, re.MULTILINE)
        if chapter_match:
            chapter_num = int(chapter_match.group(1))
            folder_num_match = re.match(r'^(\d{2})-', folder.name)
            if folder_num_match:
                folder_num = int(folder_num_match.group(1))
                if chapter_num != folder_num:
                    doc_warnings.append(f"ç« èŠ‚å·({chapter_num})ä¸æ–‡ä»¶å¤¹å·({folder_num})ä¸ä¸€è‡´")
        
        if doc_issues:
            all_issues[folder.name] = doc_issues
        elif doc_warnings:
            all_warnings[folder.name] = doc_warnings
        else:
            perfect_docs.append(folder.name)
    
    except Exception as e:
        all_issues[folder.name] = [f"å¤„ç†å¤±è´¥: {e}"]

print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
print(f"  æ€»æ–‡æ¡£æ•°: {total_docs}")
print(f"  âœ… å®Œç¾æ–‡æ¡£: {len(perfect_docs)}")
print(f"  âš ï¸  æœ‰è­¦å‘Šçš„æ–‡æ¡£: {len(all_warnings)}")
print(f"  âŒ æœ‰é—®é¢˜çš„æ–‡æ¡£: {len(all_issues)}")

if perfect_docs:
    print(f"\nâœ… å®Œç¾æ–‡æ¡£ ({len(perfect_docs)}/{total_docs}):")
    for doc in perfect_docs:
        print(f"  âœ… {doc}")

if all_warnings:
    print(f"\nâš ï¸  è­¦å‘Šæ–‡æ¡£ ({len(all_warnings)}/{total_docs}):")
    for doc, warns in all_warnings.items():
        print(f"  âš ï¸  {doc}:")
        for warn in warns:
            print(f"     - {warn}")

if all_issues:
    print(f"\nâŒ é—®é¢˜æ–‡æ¡£ ({len(all_issues)}/{total_docs}):")
    for doc, probs in all_issues.items():
        print(f"  âŒ {doc}:")
        for prob in probs:
            print(f"     - {prob}")

completion_rate = (len(perfect_docs) / total_docs) * 100
print(f"\nğŸ“ˆ å®Œæˆåº¦: {completion_rate:.1f}%")

if len(all_issues) == 0 and len(all_warnings) == 0:
    print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰æ–‡æ¡£éƒ½ç¬¦åˆæ ‡å‡†ï¼100%å®Œæˆï¼")
elif len(all_issues) == 0:
    print("\nâœ… æ‰€æœ‰æ–‡æ¡£ç»“æ„å®Œæ•´ï¼Œéƒ¨åˆ†æ–‡æ¡£æœ‰è½»å¾®è­¦å‘Š")
else:
    print("\nâš ï¸  å‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")

print("\n" + "=" * 70)
