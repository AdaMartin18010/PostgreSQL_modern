---

> **ðŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQLåŸ¹è®­\14-AIä¸Žæœºå™¨å­¦ä¹ \ã€æ·±å…¥ã€‘LlamaIndex+PostgreSQLå®Œæ•´å®žæˆ˜æŒ‡å—.md`
> **ðŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŽŸæ–‡ä»¶ä¿æŒä¸å˜

---

# LlamaIndex + PostgreSQL å®Œæ•´å®žæˆ˜æŒ‡å—

> **åˆ›å»ºæ—¶é—´**: 2025 å¹´ 12 æœˆ 4 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: LlamaIndex 0.9.0+ with PostgreSQL 18+ and pgvector
> **æ–‡æ¡£ç¼–å·**: 14-AI-LLAMAINDEX

---

## ðŸ“‘ ç›®å½•

- [LlamaIndex + PostgreSQL å®Œæ•´å®žæˆ˜æŒ‡å—](#llamaindex--postgresql-å®Œæ•´å®žæˆ˜æŒ‡å—)
  - [ðŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€æ¦‚è¿°](#ä¸€æ¦‚è¿°)
    - [1.1 ä»€ä¹ˆæ˜¯ LlamaIndex](#11-ä»€ä¹ˆæ˜¯-llamaindex)
    - [1.2 LlamaIndex vs LangChain](#12-llamaindex-vs-langchain)
    - [1.3 æ ¸å¿ƒä»·å€¼](#13-æ ¸å¿ƒä»·å€¼)
    - [1.4 çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾](#14-çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾)
  - [äºŒã€åŽŸç†ä¸Žç†è®º](#äºŒåŽŸç†ä¸Žç†è®º)
    - [2.1 LlamaIndex æž¶æž„åŽŸç†](#21-llamaindex-æž¶æž„åŽŸç†)
      - [**æ ¸å¿ƒå·¥ä½œæµç¨‹**](#æ ¸å¿ƒå·¥ä½œæµç¨‹)
      - [**æ•°æ®æµç¤ºä¾‹**](#æ•°æ®æµç¤ºä¾‹)
    - [2.2 ç´¢å¼•ç±»åž‹è¯¦è§£](#22-ç´¢å¼•ç±»åž‹è¯¦è§£)
      - [**1. VectorStoreIndexï¼ˆå‘é‡ç´¢å¼•ï¼‰**](#1-vectorstoreindexå‘é‡ç´¢å¼•)
      - [**2. TreeIndexï¼ˆæ ‘å½¢ç´¢å¼•ï¼‰**](#2-treeindexæ ‘å½¢ç´¢å¼•)
      - [**3. ListIndexï¼ˆåˆ—è¡¨ç´¢å¼•ï¼‰**](#3-listindexåˆ—è¡¨ç´¢å¼•)
      - [**4. KnowledgeGraphIndexï¼ˆçŸ¥è¯†å›¾è°±ç´¢å¼•ï¼‰**](#4-knowledgegraphindexçŸ¥è¯†å›¾è°±ç´¢å¼•)
      - [**5. SQLStructStoreIndexï¼ˆSQLç´¢å¼•ï¼‰**](#5-sqlstructstoreindexsqlç´¢å¼•)
      - [**6. DocumentSummaryIndexï¼ˆæ–‡æ¡£æ‘˜è¦ç´¢å¼•ï¼‰**](#6-documentsummaryindexæ–‡æ¡£æ‘˜è¦ç´¢å¼•)
    - [2.3 æŸ¥è¯¢å¼•æ“ŽåŽŸç†](#23-æŸ¥è¯¢å¼•æ“ŽåŽŸç†)
      - [**æŸ¥è¯¢å¼•æ“Žç»„æˆ**](#æŸ¥è¯¢å¼•æ“Žç»„æˆ)
      - [**é«˜çº§æŸ¥è¯¢æ¨¡å¼**](#é«˜çº§æŸ¥è¯¢æ¨¡å¼)
    - [2.4 å“åº”åˆæˆæ¨¡å¼](#24-å“åº”åˆæˆæ¨¡å¼)
      - [**å››ç§åˆæˆæ¨¡å¼**](#å››ç§åˆæˆæ¨¡å¼)
      - [**å¯¹æ¯”åˆ†æž**](#å¯¹æ¯”åˆ†æž)
  - [ä¸‰ã€æž¶æž„è®¾è®¡](#ä¸‰æž¶æž„è®¾è®¡)
    - [3.1 æ•´ä½“æž¶æž„](#31-æ•´ä½“æž¶æž„)
    - [3.2 ç´¢å¼•æž„å»ºç­–ç•¥](#32-ç´¢å¼•æž„å»ºç­–ç•¥)
    - [3.3 æŸ¥è¯¢ä¼˜åŒ–è®¾è®¡](#33-æŸ¥è¯¢ä¼˜åŒ–è®¾è®¡)
    - [3.4 åˆ†å¸ƒå¼ç´¢å¼•è®¾è®¡](#34-åˆ†å¸ƒå¼ç´¢å¼•è®¾è®¡)
  - [å››ã€ç¨‹åºè®¾è®¡](#å››ç¨‹åºè®¾è®¡)
    - [4.1 çŽ¯å¢ƒå‡†å¤‡](#41-çŽ¯å¢ƒå‡†å¤‡)
    - [4.2 å‘é‡ç´¢å¼•æž„å»º](#42-å‘é‡ç´¢å¼•æž„å»º)
    - [4.3 é«˜çº§ç´¢å¼•ç±»åž‹](#43-é«˜çº§ç´¢å¼•ç±»åž‹)
    - [4.4 æŸ¥è¯¢å¼•æ“Žå¼€å‘](#44-æŸ¥è¯¢å¼•æ“Žå¼€å‘)
    - [4.5 ä¸Ž SQL ç»“åˆ](#45-ä¸Ž-sql-ç»“åˆ)
  - [äº”ã€è¿ç»´ç®¡ç†](#äº”è¿ç»´ç®¡ç†)
    - [5.1 ç´¢å¼•ä¼˜åŒ–](#51-ç´¢å¼•ä¼˜åŒ–)
    - [5.2 æŸ¥è¯¢æ€§èƒ½ç›‘æŽ§](#52-æŸ¥è¯¢æ€§èƒ½ç›‘æŽ§)
    - [5.3 æˆæœ¬æŽ§åˆ¶](#53-æˆæœ¬æŽ§åˆ¶)
    - [5.4 æœ€ä½³å®žè·µ](#54-æœ€ä½³å®žè·µ)
  - [å…­ã€æ¡ˆä¾‹å®žæˆ˜](#å…­æ¡ˆä¾‹å®žæˆ˜)
    - [6.1 ä¼ä¸šæ–‡æ¡£ç®¡ç†ç³»ç»Ÿ](#61-ä¼ä¸šæ–‡æ¡£ç®¡ç†ç³»ç»Ÿ)
    - [6.2 ç ”ç©¶è®ºæ–‡æ£€ç´¢ç³»ç»Ÿ](#62-ç ”ç©¶è®ºæ–‡æ£€ç´¢ç³»ç»Ÿ)
    - [6.3 ä»£ç åº“é—®ç­”ç³»ç»Ÿ](#63-ä»£ç åº“é—®ç­”ç³»ç»Ÿ)
    - [6.4 å¤šè¯­è¨€çŸ¥è¯†åº“](#64-å¤šè¯­è¨€çŸ¥è¯†åº“)
  - [ä¸ƒã€æ€§èƒ½æµ‹è¯•ä¸Žå¯¹æ¯”](#ä¸ƒæ€§èƒ½æµ‹è¯•ä¸Žå¯¹æ¯”)
  - [å…«ã€æ€»ç»“ä¸Žå±•æœ›](#å…«æ€»ç»“ä¸Žå±•æœ›)
    - [æ ¸å¿ƒæ”¶èŽ·](#æ ¸å¿ƒæ”¶èŽ·)
    - [é€‚ç”¨åœºæ™¯](#é€‚ç”¨åœºæ™¯)
  - [ä¹ã€å‚è€ƒèµ„æ–™](#ä¹å‚è€ƒèµ„æ–™)

---

## ä¸€ã€æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯ LlamaIndex

**LlamaIndex**ï¼ˆåŽŸå GPT Indexï¼‰æ˜¯ä¸€ä¸ªä¸“æ³¨äºŽ**æ•°æ®ç´¢å¼•å’Œæ£€ç´¢**çš„æ¡†æž¶ï¼Œä¸ºLLMåº”ç”¨æä¾›å¼ºå¤§çš„æ•°æ®è¿žæŽ¥èƒ½åŠ›ã€‚

**æ ¸å¿ƒç‰¹ç‚¹**ï¼š

- ðŸ“Š **æ•°æ®ä¸ºä¸­å¿ƒ**ï¼šä¸“æ³¨äºŽç»“æž„åŒ–å’Œéžç»“æž„åŒ–æ•°æ®çš„ç´¢å¼•
- ðŸ” **å¼ºå¤§çš„æ£€ç´¢**ï¼šå¤šç§ç´¢å¼•ç±»åž‹å’ŒæŸ¥è¯¢ç­–ç•¥
- ðŸ¤– **æ™ºèƒ½è·¯ç”±**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³æŸ¥è¯¢ç­–ç•¥
- ðŸ“ˆ **å¯è§‚æµ‹æ€§**ï¼šå®Œæ•´çš„æŸ¥è¯¢è¿½è¸ªå’Œè°ƒè¯•
- ðŸ”— **æ·±åº¦é›†æˆ**ï¼šåŽŸç”Ÿæ”¯æŒå¤šç§æ•°æ®æºå’Œå‘é‡å­˜å‚¨

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LlamaIndex æ ¸å¿ƒæž¶æž„              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚     Data Connectors          â”‚     â”‚
â”‚  â”‚  (æ–‡æ¡£ã€APIã€æ•°æ®åº“...)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚               â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚     Index Structures         â”‚     â”‚
â”‚  â”‚  (Vector, Tree, List, KG)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚               â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚     Query Engines            â”‚     â”‚
â”‚  â”‚  (Retriever + Response)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚               â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚     LLM Integration          â”‚     â”‚
â”‚  â”‚  (OpenAI, Local Models)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 LlamaIndex vs LangChain

| ç»´åº¦ | LlamaIndex | LangChain |
|------|-----------|----------|
| **å®šä½** | æ•°æ®ç´¢å¼•å’Œæ£€ç´¢ | é€šç”¨LLMåº”ç”¨æ¡†æž¶ |
| **å¼ºé¡¹** | å¤æ‚ç´¢å¼•ç»“æž„ã€æŸ¥è¯¢ä¼˜åŒ– | é“¾å¼è°ƒç”¨ã€Agent |
| **å­¦ä¹ æ›²çº¿** | ä¸­ç­‰ | ä¸­ç­‰ |
| **ç´¢å¼•ç±»åž‹** | ä¸°å¯Œï¼ˆ6+ç§ï¼‰ | åŸºç¡€ï¼ˆä¸»è¦å‘é‡ï¼‰ |
| **æŸ¥è¯¢èƒ½åŠ›** | å¼ºå¤§ï¼ˆå¤šç§æŸ¥è¯¢æ¨¡å¼ï¼‰ | ä¸­ç­‰ |
| **SQLé›†æˆ** | âœ… åŽŸç”Ÿæ”¯æŒ | âš ï¸ éœ€è¦é¢å¤–å·¥å…· |
| **çŸ¥è¯†å›¾è°±** | âœ… å†…ç½®æ”¯æŒ | âš ï¸ æœ‰é™æ”¯æŒ |
| **é€‚ç”¨åœºæ™¯** | å¤æ‚æ–‡æ¡£æ£€ç´¢ã€ç»“æž„åŒ–æŸ¥è¯¢ | å¯¹è¯ã€Agentã€å·¥ä½œæµ |

**äº’è¡¥å…³ç³»**ï¼š

```python
# LlamaIndexè´Ÿè´£ç´¢å¼•å’Œæ£€ç´¢
from llama_index import VectorStoreIndex

index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()

# LangChainè´Ÿè´£å·¥ä½œæµç¼–æŽ’
from langchain.agents import Tool

llama_tool = Tool(
    name="DocumentSearch",
    func=lambda q: query_engine.query(q).response,
    description="æœç´¢æ–‡æ¡£"
)
```

### 1.3 æ ¸å¿ƒä»·å€¼

**æŠ€æœ¯ä»·å€¼**ï¼š

- ðŸŽ¯ **çµæ´»çš„ç´¢å¼•**ï¼š6+ ç§ç´¢å¼•ç±»åž‹é€‚åº”ä¸åŒåœºæ™¯
- âš¡ **æ™ºèƒ½è·¯ç”±**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æŸ¥è¯¢ç­–ç•¥
- ðŸ” **ç²¾ç¡®æ£€ç´¢**ï¼šç»“åˆå‘é‡å’Œç»“æž„åŒ–æŸ¥è¯¢
- ðŸ“Š **å¯è§‚æµ‹æ€§**ï¼šå®Œæ•´çš„è°ƒè¯•å’Œç›‘æŽ§èƒ½åŠ›

**ä¸šåŠ¡ä»·å€¼**ï¼š

- ðŸ’° **é™ä½Žæˆæœ¬**ï¼šç²¾ç¡®æ£€ç´¢å‡å°‘tokenæ¶ˆè€—
- ðŸš€ **æå‡è´¨é‡**ï¼šå¤šç§ç´¢å¼•ç­–ç•¥æå‡å›žç­”å‡†ç¡®æ€§
- ðŸ›¡ï¸ **ä¼ä¸šçº§**ï¼šæ”¯æŒå¤§è§„æ¨¡æ•°æ®å’Œåˆ†å¸ƒå¼éƒ¨ç½²
- ðŸ”„ **æ˜“äºŽæ‰©å±•**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºŽå®šåˆ¶

### 1.4 çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((LlamaIndex + PostgreSQL))
    åŽŸç†ä¸Žç†è®º
      LlamaIndexæž¶æž„
        æ•°æ®è¿žæŽ¥å™¨
        ç´¢å¼•ç»“æž„
        æŸ¥è¯¢å¼•æ“Ž
      ç´¢å¼•ç±»åž‹
        VectorIndex
        TreeIndex
        ListIndex
        KnowledgeGraph
        SQLIndex
        DocumentSummary
      æŸ¥è¯¢å¼•æ“Ž
        æ£€ç´¢å™¨
        åŽå¤„ç†å™¨
        å“åº”åˆæˆå™¨
      å“åº”æ¨¡å¼
        Refine
        Compact
        TreeSummarize
        SimpleSum
    æž¶æž„è®¾è®¡
      æ•´ä½“æž¶æž„
        æ•°æ®å±‚
        ç´¢å¼•å±‚
        æŸ¥è¯¢å±‚
        åº”ç”¨å±‚
      ç´¢å¼•ç­–ç•¥
        å•ç´¢å¼•
        å¤šç´¢å¼•
        æ··åˆç´¢å¼•
        åˆ†å±‚ç´¢å¼•
      æŸ¥è¯¢ä¼˜åŒ–
        è·¯ç”±
        è¿‡æ»¤
        é‡æŽ’åº
        èžåˆ
      åˆ†å¸ƒå¼è®¾è®¡
        ç´¢å¼•åˆ†ç‰‡
        æŸ¥è¯¢å¹¶è¡Œ
        è´Ÿè½½å‡è¡¡
    ç¨‹åºè®¾è®¡
      çŽ¯å¢ƒé…ç½®
        ä¾èµ–å®‰è£…
        PostgreSQLé…ç½®
        å‘é‡å­˜å‚¨é…ç½®
      ç´¢å¼•æž„å»º
        VectorIndex
        TreeIndex
        KGIndex
        SQLIndex
      æŸ¥è¯¢å¼€å‘
        SimpleQuery
        RouterQuery
        SubQuestion
        MultiStep
      SQLé›†æˆ
        NLToSQL
        æ··åˆæŸ¥è¯¢
        ç»“æž„åŒ–æ•°æ®
    è¿ç»´ç®¡ç†
      ç´¢å¼•ä¼˜åŒ–
        æž„å»ºä¼˜åŒ–
        å­˜å‚¨ä¼˜åŒ–
        æ›´æ–°ç­–ç•¥
      æ€§èƒ½ç›‘æŽ§
        æŸ¥è¯¢è¿½è¸ª
        æˆæœ¬åˆ†æž
        æ€§èƒ½æŒ‡æ ‡
      æˆæœ¬æŽ§åˆ¶
        Tokenä¼˜åŒ–
        ç¼“å­˜ç­–ç•¥
        æ‰¹å¤„ç†
    æ¡ˆä¾‹å®žæˆ˜
      æ–‡æ¡£ç®¡ç†
        ä¼ä¸šæ–‡æ¡£
        ç‰ˆæœ¬æŽ§åˆ¶
        æƒé™ç®¡ç†
      è®ºæ–‡æ£€ç´¢
        å­¦æœ¯æœç´¢
        å¼•ç”¨åˆ†æž
        ç›¸å…³æŽ¨è
      ä»£ç é—®ç­”
        ä»£ç æœç´¢
        è¯­ä¹‰ç†è§£
        ä»£ç ç”Ÿæˆ
      å¤šè¯­è¨€åº“
        è·¨è¯­è¨€æ£€ç´¢
        ç¿»è¯‘é›†æˆ
        æ–‡åŒ–é€‚é…
```

---

## äºŒã€åŽŸç†ä¸Žç†è®º

### 2.1 LlamaIndex æž¶æž„åŽŸç†

#### **æ ¸å¿ƒå·¥ä½œæµç¨‹**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LlamaIndex æ•°æ®å¤„ç†æµç¨‹                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  1. æ•°æ®åŠ è½½ (Data Loading)                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚     â”‚ SimpleDirectoryReader, DatabaseReaderâ”‚         â”‚
â”‚     â”‚ PDFReader, WebPageReader, etc.       â”‚         â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                   â–¼                                   â”‚
â”‚  2. æ–‡æ¡£è§£æž (Document Parsing)                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚     â”‚ Text Splitting, Metadata Extraction  â”‚         â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                   â–¼                                   â”‚
â”‚  3. ç´¢å¼•æž„å»º (Index Construction)                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚     â”‚ VectorStoreIndex                     â”‚         â”‚
â”‚     â”‚ â”œâ”€ Embedding Generation              â”‚         â”‚
â”‚     â”‚ â”œâ”€ Vector Storage (PostgreSQL)       â”‚         â”‚
â”‚     â”‚ â””â”€ Metadata Storage                  â”‚         â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                   â–¼                                   â”‚
â”‚  4. æŸ¥è¯¢å¤„ç† (Query Processing)                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚     â”‚ Query Engine                         â”‚         â”‚
â”‚     â”‚ â”œâ”€ Query Transformation              â”‚         â”‚
â”‚     â”‚ â”œâ”€ Retrieval (Top-K)                 â”‚         â”‚
â”‚     â”‚ â”œâ”€ Node Postprocessing               â”‚         â”‚
â”‚     â”‚ â””â”€ Response Synthesis                â”‚         â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                   â–¼                                   â”‚
â”‚  5. å“åº”ç”Ÿæˆ (Response Generation)                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚     â”‚ LLM Integration                      â”‚         â”‚
â”‚     â”‚ â”œâ”€ Context Building                  â”‚         â”‚
â”‚     â”‚ â”œâ”€ Prompt Engineering                â”‚         â”‚
â”‚     â”‚ â””â”€ Answer Generation                 â”‚         â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **æ•°æ®æµç¤ºä¾‹**

```python
from llama_index import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    ServiceContext
)
from llama_index.vector_stores import PGVectorStore
from llama_index.storage.storage_context import StorageContext

# 1. æ•°æ®åŠ è½½
documents = SimpleDirectoryReader('./docs').load_data()

# 2. é…ç½®å‘é‡å­˜å‚¨ï¼ˆPostgreSQLï¼‰
vector_store = PGVectorStore.from_params(
    database="llamaindex_db",
    host="localhost",
    password="password",
    port=5432,
    user="postgres",
    table_name="llamaindex_vectors",
    embed_dim=1536  # OpenAI embedding dimension
)

storage_context = StorageContext.from_defaults(
    vector_store=vector_store
)

# 3. æž„å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context
)

# 4. åˆ›å»ºæŸ¥è¯¢å¼•æ“Ž
query_engine = index.as_query_engine(
    similarity_top_k=5,
    response_mode="compact"
)

# 5. æ‰§è¡ŒæŸ¥è¯¢
response = query_engine.query("ä»€ä¹ˆæ˜¯PostgreSQLçš„MVCC?")
print(response)
```

### 2.2 ç´¢å¼•ç±»åž‹è¯¦è§£

#### **1. VectorStoreIndexï¼ˆå‘é‡ç´¢å¼•ï¼‰**

**åŽŸç†**ï¼šå°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡åµŒå…¥ï¼Œä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ã€‚

```python
from llama_index import VectorStoreIndex, Document

# åˆ›å»ºæ–‡æ¡£
documents = [
    Document(text="PostgreSQLæ˜¯ä¸€ä¸ªå¼€æºæ•°æ®åº“"),
    Document(text="pgvectoræä¾›å‘é‡æœç´¢åŠŸèƒ½")
]

# æž„å»ºå‘é‡ç´¢å¼•
vector_index = VectorStoreIndex.from_documents(documents)

# æŸ¥è¯¢
query_engine = vector_index.as_query_engine()
response = query_engine.query("ä»€ä¹ˆæ˜¯pgvector?")
```

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… è¯­ä¹‰æœç´¢
- âœ… ç›¸ä¼¼æ–‡æ¡£æŸ¥æ‰¾
- âœ… å¤§è§„æ¨¡æ–‡æ¡£æ£€ç´¢

#### **2. TreeIndexï¼ˆæ ‘å½¢ç´¢å¼•ï¼‰**

**åŽŸç†**ï¼šæž„å»ºå±‚æ¬¡åŒ–çš„æ‘˜è¦æ ‘ï¼Œè‡ªé¡¶å‘ä¸‹æŸ¥è¯¢ã€‚

```python
from llama_index import TreeIndex

# æž„å»ºæ ‘ç´¢å¼•
tree_index = TreeIndex.from_documents(
    documents,
    num_children=10,  # æ¯ä¸ªèŠ‚ç‚¹çš„å­èŠ‚ç‚¹æ•°
    build_tree=True
)

# æŸ¥è¯¢ï¼ˆä»Žæ ¹èŠ‚ç‚¹å¼€å§‹éåŽ†ï¼‰
query_engine = tree_index.as_query_engine(
    child_branch_factor=2  # æ¯å±‚é€‰æ‹©çš„å­èŠ‚ç‚¹æ•°
)
response = query_engine.query("æ€»ç»“PostgreSQLçš„ç‰¹æ€§")
```

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… é•¿æ–‡æ¡£æ‘˜è¦
- âœ… å±‚æ¬¡åŒ–ä¿¡æ¯æ£€ç´¢
- âœ… å¤šå±‚æ¬¡é—®ç­”

#### **3. ListIndexï¼ˆåˆ—è¡¨ç´¢å¼•ï¼‰**

**åŽŸç†**ï¼šæŒ‰é¡ºåºéåŽ†æ‰€æœ‰æ–‡æ¡£ã€‚

```python
from llama_index import ListIndex

# æž„å»ºåˆ—è¡¨ç´¢å¼•
list_index = ListIndex.from_documents(documents)

# æŸ¥è¯¢ï¼ˆéåŽ†æ‰€æœ‰èŠ‚ç‚¹ï¼‰
query_engine = list_index.as_query_engine()
response = query_engine.query("æ€»ç»“æ‰€æœ‰æ–‡æ¡£")
```

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… å°è§„æ¨¡æ•°æ®é›†
- âœ… éœ€è¦è€ƒè™‘æ‰€æœ‰æ–‡æ¡£çš„æŸ¥è¯¢
- âœ… å…¨æ–‡æ‘˜è¦

#### **4. KnowledgeGraphIndexï¼ˆçŸ¥è¯†å›¾è°±ç´¢å¼•ï¼‰**

**åŽŸç†**ï¼šæå–å®žä½“å’Œå…³ç³»ï¼Œæž„å»ºçŸ¥è¯†å›¾è°±ã€‚

```python
from llama_index import KnowledgeGraphIndex

# æž„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•
kg_index = KnowledgeGraphIndex.from_documents(
    documents,
    max_triplets_per_chunk=10,  # æ¯ä¸ªchunkæå–çš„ä¸‰å…ƒç»„æ•°é‡
    include_embeddings=True
)

# æŸ¥è¯¢ï¼ˆç»“åˆå›¾éåŽ†å’Œå‘é‡æœç´¢ï¼‰
query_engine = kg_index.as_query_engine(
    include_text=True,
    response_mode="tree_summarize",
    embedding_mode="hybrid"
)
response = query_engine.query("PostgreSQLå’ŒMVCCä¹‹é—´æ˜¯ä»€ä¹ˆå…³ç³»?")
```

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… å…³ç³»æŸ¥è¯¢
- âœ… å®žä½“è¯†åˆ«
- âœ… çŸ¥è¯†æŽ¨ç†

#### **5. SQLStructStoreIndexï¼ˆSQLç´¢å¼•ï¼‰**

**åŽŸç†**ï¼šå°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºSQLæŸ¥è¯¢ã€‚

```python
from llama_index import SQLDatabase, SQLStructStoreIndex
from sqlalchemy import create_engine

# è¿žæŽ¥æ•°æ®åº“
engine = create_engine("postgresql://user:pass@localhost/db")
sql_database = SQLDatabase(engine, include_tables=["users", "orders"])

# æž„å»ºSQLç´¢å¼•
sql_index = SQLStructStoreIndex.from_documents(
    [],  # ä¸éœ€è¦æ–‡æ¡£ï¼Œç›´æŽ¥æŸ¥è¯¢æ•°æ®åº“
    sql_database=sql_database
)

# è‡ªç„¶è¯­è¨€è½¬SQL
query_engine = sql_index.as_query_engine()
response = query_engine.query("ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„è®¢å•æ€»æ•°")
# ç”Ÿæˆå¹¶æ‰§è¡ŒSQL: SELECT user_id, COUNT(*) FROM orders GROUP BY user_id
```

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… ç»“æž„åŒ–æ•°æ®æŸ¥è¯¢
- âœ… è‡ªç„¶è¯­è¨€åˆ°SQL
- âœ… æ•°æ®åˆ†æž

#### **6. DocumentSummaryIndexï¼ˆæ–‡æ¡£æ‘˜è¦ç´¢å¼•ï¼‰**

**åŽŸç†**ï¼šä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆæ‘˜è¦ï¼Œæ£€ç´¢æ—¶ä½¿ç”¨æ‘˜è¦åŒ¹é…ã€‚

```python
from llama_index import DocumentSummaryIndex

# æž„å»ºæ–‡æ¡£æ‘˜è¦ç´¢å¼•
summary_index = DocumentSummaryIndex.from_documents(
    documents,
    response_synthesizer=response_synthesizer
)

# æŸ¥è¯¢ï¼ˆä½¿ç”¨æ‘˜è¦æ£€ç´¢ï¼‰
query_engine = summary_index.as_query_engine()
response = query_engine.query("æ‰¾å‡ºå…³äºŽæ€§èƒ½ä¼˜åŒ–çš„æ–‡æ¡£")
```

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… å¤§æ–‡æ¡£æ£€ç´¢
- âœ… ä¸»é¢˜åˆ†ç±»
- âœ… å¿«é€Ÿè¿‡æ»¤

### 2.3 æŸ¥è¯¢å¼•æ“ŽåŽŸç†

#### **æŸ¥è¯¢å¼•æ“Žç»„æˆ**

```python
# æŸ¥è¯¢å¼•æ“Ž = æ£€ç´¢å™¨ + åŽå¤„ç†å™¨ + å“åº”åˆæˆå™¨

from llama_index.indices.postprocessor import (
    SimilarityPostprocessor,
    KeywordNodePostprocessor,
    MetadataReplacementPostProcessor
)

query_engine = index.as_query_engine(
    # 1. æ£€ç´¢é…ç½®
    similarity_top_k=10,  # æ£€ç´¢10ä¸ªå€™é€‰èŠ‚ç‚¹

    # 2. åŽå¤„ç†å™¨ï¼ˆè¿‡æ»¤å’Œé‡æŽ’åºï¼‰
    node_postprocessors=[
        SimilarityPostprocessor(similarity_cutoff=0.7),  # ç›¸ä¼¼åº¦é˜ˆå€¼
        KeywordNodePostprocessor(required_keywords=["PostgreSQL"]),  # å…³é”®è¯è¿‡æ»¤
        MetadataReplacementPostProcessor(target_metadata_key="window")  # å…ƒæ•°æ®å¢žå¼º
    ],

    # 3. å“åº”æ¨¡å¼
    response_mode="compact"  # åŽ‹ç¼©ä¸Šä¸‹æ–‡
)
```

#### **é«˜çº§æŸ¥è¯¢æ¨¡å¼**

**1. RouterQueryEngineï¼ˆè·¯ç”±æŸ¥è¯¢ï¼‰**:

```python
from llama_index.query_engine import RouterQueryEngine
from llama_index.selectors import LLMSingleSelector

# åˆ›å»ºå¤šä¸ªæŸ¥è¯¢å¼•æ“Ž
vector_query_engine = vector_index.as_query_engine()
sql_query_engine = sql_index.as_query_engine()

# åˆ›å»ºè·¯ç”±å™¨
router_query_engine = RouterQueryEngine(
    selector=LLMSingleSelector.from_defaults(),
    query_engine_tools=[
        ToolMetadata(
            query_engine=vector_query_engine,
            description="ç”¨äºŽæœç´¢æ–‡æ¡£å’Œæ¦‚å¿µæ€§é—®é¢˜"
        ),
        ToolMetadata(
            query_engine=sql_query_engine,
            description="ç”¨äºŽæ•°æ®ç»Ÿè®¡å’Œåˆ†æžæŸ¥è¯¢"
        )
    ]
)

# è‡ªåŠ¨è·¯ç”±æŸ¥è¯¢
response = router_query_engine.query("ç»Ÿè®¡ç”¨æˆ·æ•°é‡")  # è·¯ç”±åˆ°SQLå¼•æ“Ž
```

**2. SubQuestionQueryEngineï¼ˆå­é—®é¢˜åˆ†è§£ï¼‰**

```python
from llama_index.query_engine import SubQuestionQueryEngine
from llama_index.tools import QueryEngineTool

# å®šä¹‰å·¥å…·
query_engine_tools = [
    QueryEngineTool(
        query_engine=vector_query_engine,
        metadata=ToolMetadata(
            name="documents",
            description="PostgreSQLæ–‡æ¡£"
        )
    ),
    QueryEngineTool(
        query_engine=sql_query_engine,
        metadata=ToolMetadata(
            name="database",
            description="æ•°æ®åº“ç»Ÿè®¡"
        )
    )
]

# åˆ›å»ºå­é—®é¢˜å¼•æ“Ž
sub_question_engine = SubQuestionQueryEngine.from_defaults(
    query_engine_tools=query_engine_tools
)

# å¤æ‚æŸ¥è¯¢ï¼ˆè‡ªåŠ¨åˆ†è§£ä¸ºå­é—®é¢˜ï¼‰
response = sub_question_engine.query(
    "æ¯”è¾ƒPostgreSQLå’ŒMySQLçš„æ€§èƒ½ï¼Œå¹¶ç»™å‡ºç”¨æˆ·æ•°æ®ç»Ÿè®¡"
)
# è‡ªåŠ¨åˆ†è§£ä¸ºï¼š
# 1. æŸ¥è¯¢PostgreSQLæ€§èƒ½ç‰¹æ€§ï¼ˆdocumentsï¼‰
# 2. æŸ¥è¯¢MySQLæ€§èƒ½ç‰¹æ€§ï¼ˆdocumentsï¼‰
# 3. æŸ¥è¯¢ç”¨æˆ·ç»Ÿè®¡ï¼ˆdatabaseï¼‰
# 4. ç»¼åˆå›žç­”
```

### 2.4 å“åº”åˆæˆæ¨¡å¼

#### **å››ç§åˆæˆæ¨¡å¼**

```python
# 1. Refineï¼ˆç²¾ç‚¼æ¨¡å¼ï¼‰
# åŽŸç†ï¼šé€ä¸ªå¤„ç†æ£€ç´¢åˆ°çš„èŠ‚ç‚¹ï¼Œä¸æ–­ç²¾ç‚¼ç­”æ¡ˆ
query_engine = index.as_query_engine(response_mode="refine")

# 2. Compactï¼ˆåŽ‹ç¼©æ¨¡å¼ï¼‰
# åŽŸç†ï¼šå°½å¯èƒ½å°†å¤šä¸ªèŠ‚ç‚¹åŽ‹ç¼©åˆ°ä¸€ä¸ªpromptä¸­
query_engine = index.as_query_engine(response_mode="compact")

# 3. Tree Summarizeï¼ˆæ ‘æ‘˜è¦æ¨¡å¼ï¼‰
# åŽŸç†ï¼šæž„å»ºæ‘˜è¦æ ‘ï¼Œè‡ªåº•å‘ä¸Šåˆå¹¶
query_engine = index.as_query_engine(response_mode="tree_summarize")

# 4. Simple Summarizeï¼ˆç®€å•æ‘˜è¦æ¨¡å¼ï¼‰
# åŽŸç†ï¼šæˆªæ–­æ‰€æœ‰èŠ‚ç‚¹åˆ°max_tokens
query_engine = index.as_query_engine(response_mode="simple_summarize")
```

#### **å¯¹æ¯”åˆ†æž**

| æ¨¡å¼ | Tokenæ¶ˆè€— | å‡†ç¡®æ€§ | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|------|----------|--------|------|---------|
| **Refine** | é«˜ | æœ€é«˜ | æ…¢ | éœ€è¦é«˜è´¨é‡ç­”æ¡ˆ |
| **Compact** | ä¸­ | é«˜ | ä¸­ | å¹³è¡¡æ€§èƒ½å’Œè´¨é‡ |
| **TreeSummarize** | ä¸­ | ä¸­ | ä¸­ | é•¿æ–‡æ¡£æ‘˜è¦ |
| **SimpleSummarize** | ä½Ž | ä¸­ | å¿« | å¿«é€Ÿæ‘˜è¦ |

---

## ä¸‰ã€æž¶æž„è®¾è®¡

### 3.1 æ•´ä½“æž¶æž„

```python
"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LlamaIndex + PostgreSQL æž¶æž„               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚         åº”ç”¨å±‚ (Application)               â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”            â”‚     â”‚
â”‚  â”‚  â”‚ Web  â”‚  â”‚ API  â”‚  â”‚ CLI  â”‚            â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                      â”‚                              â”‚
â”‚                      â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚         æŸ¥è¯¢å±‚ (Query Layer)               â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚     â”‚
â”‚  â”‚  â”‚RouterEngine â”‚  â”‚SubQuestion  â”‚        â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚     â”‚
â”‚  â”‚  â”‚QueryEngine  â”‚  â”‚Postprocessorâ”‚        â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                      â”‚                              â”‚
â”‚                      â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚         ç´¢å¼•å±‚ (Index Layer)               â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”            â”‚     â”‚
â”‚  â”‚  â”‚Vectorâ”‚  â”‚Tree  â”‚  â”‚KG    â”‚            â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜            â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”            â”‚     â”‚
â”‚  â”‚  â”‚SQL   â”‚  â”‚List  â”‚  â”‚Summaryâ”‚           â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                      â”‚                              â”‚
â”‚                      â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚         å­˜å‚¨å±‚ (Storage Layer)             â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚
â”‚  â”‚  â”‚      PostgreSQL + pgvector         â”‚   â”‚     â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   â”‚     â”‚
â”‚  â”‚  â”‚  â”‚ Vectors â”‚  â”‚Documentsâ”‚         â”‚   â”‚     â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”‚     â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   â”‚     â”‚
â”‚  â”‚  â”‚  â”‚Metadata â”‚  â”‚Indexes  â”‚         â”‚   â”‚     â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""
```

### 3.2 ç´¢å¼•æž„å»ºç­–ç•¥

```python
# index_strategies.py
from typing import List, Dict, Any
from llama_index import (
    VectorStoreIndex,
    TreeIndex,
    KnowledgeGraphIndex,
    Document
)

class MultiIndexStrategy:
    """å¤šç´¢å¼•ç­–ç•¥"""

    def __init__(self, documents: List[Document]):
        self.documents = documents
        self.indexes = {}

    def build_all_indexes(self):
        """æž„å»ºæ‰€æœ‰ç±»åž‹çš„ç´¢å¼•"""
        # 1. å‘é‡ç´¢å¼•ï¼šç”¨äºŽè¯­ä¹‰æœç´¢
        self.indexes['vector'] = VectorStoreIndex.from_documents(
            self.documents,
            show_progress=True
        )

        # 2. æ ‘ç´¢å¼•ï¼šç”¨äºŽé•¿æ–‡æ¡£æ‘˜è¦
        self.indexes['tree'] = TreeIndex.from_documents(
            self.documents,
            num_children=10
        )

        # 3. çŸ¥è¯†å›¾è°±ï¼šç”¨äºŽå…³ç³»æŸ¥è¯¢
        self.indexes['kg'] = KnowledgeGraphIndex.from_documents(
            self.documents,
            max_triplets_per_chunk=10
        )

        return self.indexes

    def get_query_engine_for_task(self, task_type: str):
        """æ ¹æ®ä»»åŠ¡ç±»åž‹é€‰æ‹©æŸ¥è¯¢å¼•æ“Ž"""
        if task_type == "semantic_search":
            return self.indexes['vector'].as_query_engine()
        elif task_type == "summarization":
            return self.indexes['tree'].as_query_engine()
        elif task_type == "relationship":
            return self.indexes['kg'].as_query_engine()
        else:
            return self.indexes['vector'].as_query_engine()
```

### 3.3 æŸ¥è¯¢ä¼˜åŒ–è®¾è®¡

```python
# query_optimization.py
from llama_index.indices.postprocessor import (
    SimilarityPostprocessor,
    KeywordNodePostprocessor,
    SentenceEmbeddingOptimizer
)

class OptimizedQueryEngine:
    """ä¼˜åŒ–çš„æŸ¥è¯¢å¼•æ“Ž"""

    def __init__(self, index):
        self.index = index
        self.query_engine = self._build_optimized_engine()

    def _build_optimized_engine(self):
        """æž„å»ºä¼˜åŒ–çš„æŸ¥è¯¢å¼•æ“Ž"""
        return self.index.as_query_engine(
            similarity_top_k=20,  # å…ˆæ£€ç´¢20ä¸ªå€™é€‰
            node_postprocessors=[
                # 1. ç›¸ä¼¼åº¦è¿‡æ»¤
                SimilarityPostprocessor(similarity_cutoff=0.75),

                # 2. å¥å­ä¼˜åŒ–ï¼ˆç§»é™¤ä¸ç›¸å…³å¥å­ï¼‰
                SentenceEmbeddingOptimizer(
                    percentile_cutoff=0.5,
                    threshold_cutoff=0.7
                ),

                # 3. å…³é”®è¯è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
                # KeywordNodePostprocessor(
                #     required_keywords=["PostgreSQL"],
                #     exclude_keywords=["MySQL"]
                # )
            ],
            response_mode="compact",
            verbose=True
        )

    def query(self, question: str):
        """æ‰§è¡Œä¼˜åŒ–æŸ¥è¯¢"""
        return self.query_engine.query(question)
```

### 3.4 åˆ†å¸ƒå¼ç´¢å¼•è®¾è®¡

```python
# distributed_index.py
import hashlib
from typing import List
from llama_index import VectorStoreIndex, Document

class DistributedIndex:
    """åˆ†å¸ƒå¼ç´¢å¼•ï¼ˆæŒ‰å†…å®¹å“ˆå¸Œåˆ†ç‰‡ï¼‰"""

    def __init__(self, num_shards: int = 4):
        self.num_shards = num_shards
        self.shards = [[] for _ in range(num_shards)]
        self.indexes = {}

    def add_documents(self, documents: List[Document]):
        """æ·»åŠ æ–‡æ¡£åˆ°åˆ†ç‰‡"""
        for doc in documents:
            # æ ¹æ®æ–‡æ¡£IDå“ˆå¸Œåˆ†ç‰‡
            shard_id = self._get_shard_id(doc.doc_id)
            self.shards[shard_id].append(doc)

    def _get_shard_id(self, doc_id: str) -> int:
        """è®¡ç®—æ–‡æ¡£æ‰€å±žåˆ†ç‰‡"""
        hash_value = int(hashlib.md5(doc_id.encode()).hexdigest(), 16)
        return hash_value % self.num_shards

    def build_indexes(self):
        """ä¸ºæ¯ä¸ªåˆ†ç‰‡æž„å»ºç´¢å¼•"""
        for shard_id, docs in enumerate(self.shards):
            if docs:
                self.indexes[shard_id] = VectorStoreIndex.from_documents(docs)
        print(f"Built {len(self.indexes)} shard indexes")

    def query_all_shards(self, question: str, top_k: int = 5):
        """å¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰åˆ†ç‰‡"""
        all_results = []

        for shard_id, index in self.indexes.items():
            query_engine = index.as_query_engine(similarity_top_k=top_k)
            response = query_engine.query(question)
            all_results.append({
                'shard_id': shard_id,
                'response': response
            })

        # åˆå¹¶ç»“æžœï¼ˆå¯ä»¥è¿›ä¸€æ­¥é‡æŽ’åºï¼‰
        return self._merge_results(all_results)

    def _merge_results(self, results):
        """åˆå¹¶å¤šä¸ªåˆ†ç‰‡çš„ç»“æžœ"""
        # ç®€å•åˆå¹¶ç­–ç•¥ï¼šé€‰æ‹©æœ€ä½³å›žç­”
        best_response = max(
            results,
            key=lambda x: len(x['response'].response)  # ç®€å•ç¤ºä¾‹
        )
        return best_response['response']
```

---

## å››ã€ç¨‹åºè®¾è®¡

### 4.1 çŽ¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install llama-index==0.9.48
pip install llama-index-vector-stores-postgres==0.1.3
pip install psycopg2-binary==2.9.9
pip install sqlalchemy==2.0.25
pip install pgvector==0.2.4

# åˆ›å»ºrequirements.txt
cat > requirements.txt <<EOF
llama-index==0.9.48
llama-index-vector-stores-postgres==0.1.3
psycopg2-binary==2.9.9
sqlalchemy==2.0.25
pgvector==0.2.4
openai==1.6.1
tiktoken==0.5.2
EOF
```

```sql
-- PostgreSQLé…ç½®
CREATE DATABASE llamaindex_db;
\c llamaindex_db

-- å®‰è£…pgvector
CREATE EXTENSION IF NOT EXISTS vector;

-- LlamaIndexä¼šè‡ªåŠ¨åˆ›å»ºè¡¨ï¼Œè¿™é‡Œå±•ç¤ºç»“æž„
CREATE TABLE IF NOT EXISTS data_llamaindex (
    id TEXT PRIMARY KEY,
    embedding VECTOR(1536),
    text TEXT,
    metadata_ JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX ON data_llamaindex USING hnsw (embedding vector_cosine_ops);
CREATE INDEX ON data_llamaindex USING gin (metadata_);
```

### 4.2 å‘é‡ç´¢å¼•æž„å»º

```python
# vector_index_builder.py
from llama_index import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    ServiceContext,
    StorageContext
)
from llama_index.vector_stores import PGVectorStore
from llama_index.embeddings import OpenAIEmbedding
import os

class VectorIndexBuilder:
    """å‘é‡ç´¢å¼•æž„å»ºå™¨"""

    def __init__(
        self,
        db_name: str = "llamaindex_db",
        host: str = "localhost",
        port: int = 5432,
        user: str = "postgres",
        password: str = "password"
    ):
        # é…ç½®å‘é‡å­˜å‚¨
        self.vector_store = PGVectorStore.from_params(
            database=db_name,
            host=host,
            port=port,
            user=user,
            password=password,
            table_name="llamaindex_vectors",
            embed_dim=1536
        )

        # é…ç½®åµŒå…¥æ¨¡åž‹
        self.embed_model = OpenAIEmbedding(
            model="text-embedding-3-small",
            api_key=os.getenv("OPENAI_API_KEY")
        )

        # é…ç½®æœåŠ¡ä¸Šä¸‹æ–‡
        self.service_context = ServiceContext.from_defaults(
            embed_model=self.embed_model,
            chunk_size=1024,
            chunk_overlap=20
        )

        # é…ç½®å­˜å‚¨ä¸Šä¸‹æ–‡
        self.storage_context = StorageContext.from_defaults(
            vector_store=self.vector_store
        )

    def build_from_directory(self, directory_path: str):
        """ä»Žç›®å½•æž„å»ºç´¢å¼•"""
        # åŠ è½½æ–‡æ¡£
        documents = SimpleDirectoryReader(
            directory_path,
            recursive=True
        ).load_data()

        print(f"Loaded {len(documents)} documents")

        # æž„å»ºç´¢å¼•
        index = VectorStoreIndex.from_documents(
            documents,
            service_context=self.service_context,
            storage_context=self.storage_context,
            show_progress=True
        )

        print("âœ… Index built successfully")
        return index

    def load_existing_index(self):
        """åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•"""
        index = VectorStoreIndex.from_vector_store(
            vector_store=self.vector_store,
            service_context=self.service_context
        )
        print("âœ… Loaded existing index")
        return index

    def add_documents_incremental(self, index, new_documents):
        """å¢žé‡æ·»åŠ æ–‡æ¡£"""
        for doc in new_documents:
            index.insert(doc)
        print(f"âœ… Added {len(new_documents)} documents")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    builder = VectorIndexBuilder()

    # æž„å»ºç´¢å¼•
    index = builder.build_from_directory("./docs")

    # æŸ¥è¯¢æµ‹è¯•
    query_engine = index.as_query_engine(similarity_top_k=5)
    response = query_engine.query("ä»€ä¹ˆæ˜¯PostgreSQLçš„MVCC?")

    print("\næŸ¥è¯¢ç»“æžœ:")
    print(response)

    print("\næ¥æºèŠ‚ç‚¹:")
    for node in response.source_nodes:
        print(f"- åˆ†æ•°: {node.score:.3f}")
        print(f"  å†…å®¹: {node.text[:100]}...")
        print(f"  å…ƒæ•°æ®: {node.metadata}")
```

### 4.3 é«˜çº§ç´¢å¼•ç±»åž‹

```python
# advanced_indexes.py
from llama_index import (
    VectorStoreIndex,
    TreeIndex,
    KnowledgeGraphIndex,
    DocumentSummaryIndex,
    Document
)
from llama_index.graph_stores import SimpleGraphStore
from llama_index.storage.docstore import SimpleDocumentStore

class AdvancedIndexBuilder:
    """é«˜çº§ç´¢å¼•æž„å»ºå™¨"""

    def __init__(self, documents: List[Document]):
        self.documents = documents

    def build_tree_index(self):
        """æž„å»ºæ ‘ç´¢å¼•"""
        tree_index = TreeIndex.from_documents(
            self.documents,
            num_children=10,  # æ¯ä¸ªèŠ‚ç‚¹çš„å­èŠ‚ç‚¹æ•°
            build_tree=True,
            show_progress=True
        )
        return tree_index

    def build_knowledge_graph(self):
        """æž„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•"""
        # é…ç½®å›¾å­˜å‚¨
        graph_store = SimpleGraphStore()

        kg_index = KnowledgeGraphIndex.from_documents(
            self.documents,
            max_triplets_per_chunk=10,
            graph_store=graph_store,
            show_progress=True
        )
        return kg_index

    def build_document_summary_index(self):
        """æž„å»ºæ–‡æ¡£æ‘˜è¦ç´¢å¼•"""
        summary_index = DocumentSummaryIndex.from_documents(
            self.documents,
            show_progress=True
        )
        return summary_index

    def build_hybrid_index(self):
        """æž„å»ºæ··åˆç´¢å¼•ï¼ˆå‘é‡ + çŸ¥è¯†å›¾è°±ï¼‰"""
        # 1. æž„å»ºå‘é‡ç´¢å¼•
        vector_index = VectorStoreIndex.from_documents(self.documents)

        # 2. æž„å»ºçŸ¥è¯†å›¾è°±
        kg_index = self.build_knowledge_graph()

        return {
            'vector': vector_index,
            'kg': kg_index
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from llama_index import SimpleDirectoryReader

    # åŠ è½½æ–‡æ¡£
    documents = SimpleDirectoryReader("./docs").load_data()

    builder = AdvancedIndexBuilder(documents)

    # æž„å»ºæ ‘ç´¢å¼•
    tree_index = builder.build_tree_index()
    tree_query_engine = tree_index.as_query_engine(
        child_branch_factor=2
    )
    response = tree_query_engine.query("æ€»ç»“PostgreSQLçš„ä¸»è¦ç‰¹æ€§")
    print("æ ‘ç´¢å¼•æŸ¥è¯¢:", response)

    # æž„å»ºçŸ¥è¯†å›¾è°±
    kg_index = builder.build_knowledge_graph()
    kg_query_engine = kg_index.as_query_engine(
        include_text=True,
        response_mode="tree_summarize"
    )
    response = kg_query_engine.query("PostgreSQLå’ŒMVCCä¹‹é—´çš„å…³ç³»æ˜¯ä»€ä¹ˆ?")
    print("çŸ¥è¯†å›¾è°±æŸ¥è¯¢:", response)
```

### 4.4 æŸ¥è¯¢å¼•æ“Žå¼€å‘

```python
# query_engines.py
from llama_index.query_engine import (
    RouterQueryEngine,
    SubQuestionQueryEngine,
    RetrieverQueryEngine
)
from llama_index.tools import QueryEngineTool
from llama_index.selectors import LLMSingleSelector
from llama_index.response_synthesizers import ResponseMode

class AdvancedQueryEngines:
    """é«˜çº§æŸ¥è¯¢å¼•æ“Žé›†åˆ"""

    def __init__(self, indexes: dict):
        self.indexes = indexes

    def create_router_engine(self):
        """åˆ›å»ºè·¯ç”±æŸ¥è¯¢å¼•æ“Ž"""
        # å®šä¹‰å·¥å…·
        query_engine_tools = [
            QueryEngineTool(
                query_engine=self.indexes['vector'].as_query_engine(),
                metadata=ToolMetadata(
                    name="vector_search",
                    description="ç”¨äºŽè¯­ä¹‰æœç´¢å’Œæ¦‚å¿µæ€§é—®é¢˜"
                )
            ),
            QueryEngineTool(
                query_engine=self.indexes['kg'].as_query_engine(),
                metadata=ToolMetadata(
                    name="knowledge_graph",
                    description="ç”¨äºŽæŸ¥è¯¢å®žä½“å…³ç³»å’ŒçŸ¥è¯†æŽ¨ç†"
                )
            )
        ]

        # åˆ›å»ºè·¯ç”±å™¨
        router_engine = RouterQueryEngine(
            selector=LLMSingleSelector.from_defaults(),
            query_engine_tools=query_engine_tools,
            verbose=True
        )

        return router_engine

    def create_sub_question_engine(self):
        """åˆ›å»ºå­é—®é¢˜æŸ¥è¯¢å¼•æ“Ž"""
        query_engine_tools = [
            QueryEngineTool(
                query_engine=self.indexes['vector'].as_query_engine(),
                metadata=ToolMetadata(
                    name="documents",
                    description="PostgreSQLæ–‡æ¡£åº“"
                )
            )
        ]

        sub_question_engine = SubQuestionQueryEngine.from_defaults(
            query_engine_tools=query_engine_tools,
            verbose=True
        )

        return sub_question_engine

    def create_custom_query_engine(
        self,
        similarity_top_k: int = 10,
        response_mode: str = "compact"
    ):
        """åˆ›å»ºè‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“Ž"""
        from llama_index.indices.postprocessor import (
            SimilarityPostprocessor,
            SentenceEmbeddingOptimizer
        )

        query_engine = self.indexes['vector'].as_query_engine(
            similarity_top_k=similarity_top_k,
            node_postprocessors=[
                SimilarityPostprocessor(similarity_cutoff=0.7),
                SentenceEmbeddingOptimizer(percentile_cutoff=0.5)
            ],
            response_mode=response_mode,
            verbose=True
        )

        return query_engine

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å‡è®¾å·²æœ‰indexes
    engines = AdvancedQueryEngines(indexes)

    # 1. è·¯ç”±æŸ¥è¯¢
    router_engine = engines.create_router_engine()
    response = router_engine.query("PostgreSQLçš„æ€§èƒ½ç‰¹æ€§æœ‰å“ªäº›?")

    # 2. å­é—®é¢˜æŸ¥è¯¢
    sub_question_engine = engines.create_sub_question_engine()
    response = sub_question_engine.query(
        "æ¯”è¾ƒPostgreSQLå’ŒMySQLçš„MVCCå®žçŽ°ï¼Œå¹¶è¯´æ˜Žå„è‡ªçš„ä¼˜ç¼ºç‚¹"
    )

    # 3. è‡ªå®šä¹‰æŸ¥è¯¢
    custom_engine = engines.create_custom_query_engine(
        similarity_top_k=15,
        response_mode="tree_summarize"
    )
    response = custom_engine.query("æ€»ç»“PostgreSQLçš„äº‹åŠ¡ç®¡ç†")
```

### 4.5 ä¸Ž SQL ç»“åˆ

```python
# sql_integration.py
from llama_index import SQLDatabase, VectorStoreIndex
from llama_index.indices.struct_store import SQLStructStoreIndex
from sqlalchemy import create_engine
from llama_index.query_engine import NLSQLTableQueryEngine

class SQLIntegration:
    """SQLä¸Žå‘é‡ç´¢å¼•é›†æˆ"""

    def __init__(self, db_url: str):
        self.engine = create_engine(db_url)
        self.sql_database = SQLDatabase(
            self.engine,
            include_tables=["users", "orders", "products"]
        )

    def create_nl_to_sql_engine(self):
        """åˆ›å»ºè‡ªç„¶è¯­è¨€åˆ°SQLå¼•æ“Ž"""
        query_engine = NLSQLTableQueryEngine(
            sql_database=self.sql_database,
            tables=["users", "orders"],
            verbose=True
        )
        return query_engine

    def create_hybrid_engine(self, vector_index):
        """åˆ›å»ºæ··åˆæŸ¥è¯¢å¼•æ“Žï¼ˆå‘é‡ + SQLï¼‰"""
        from llama_index.query_engine import RouterQueryEngine
        from llama_index.tools import QueryEngineTool

        # SQLæŸ¥è¯¢å·¥å…·
        sql_tool = QueryEngineTool(
            query_engine=self.create_nl_to_sql_engine(),
            metadata=ToolMetadata(
                name="sql_database",
                description="ç”¨äºŽæŸ¥è¯¢ç»“æž„åŒ–æ•°æ®å’Œç»Ÿè®¡åˆ†æž"
            )
        )

        # å‘é‡æŸ¥è¯¢å·¥å…·
        vector_tool = QueryEngineTool(
            query_engine=vector_index.as_query_engine(),
            metadata=ToolMetadata(
                name="documents",
                description="ç”¨äºŽæœç´¢æ–‡æ¡£å’Œæ¦‚å¿µæ€§é—®é¢˜"
            )
        )

        # åˆ›å»ºè·¯ç”±å™¨
        router_engine = RouterQueryEngine(
            selector=LLMSingleSelector.from_defaults(),
            query_engine_tools=[sql_tool, vector_tool]
        )

        return router_engine

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    sql_integration = SQLIntegration(
        "postgresql://user:pass@localhost/db"
    )

    # è‡ªç„¶è¯­è¨€æŸ¥è¯¢SQL
    nl_sql_engine = sql_integration.create_nl_to_sql_engine()
    response = nl_sql_engine.query("ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„è®¢å•æ•°é‡")
    print("SQLæŸ¥è¯¢:", response)

    # æ··åˆæŸ¥è¯¢
    hybrid_engine = sql_integration.create_hybrid_engine(vector_index)
    response = hybrid_engine.query(
        "æŸ¥è¯¢è®¢å•æ•°é‡è¶…è¿‡10çš„ç”¨æˆ·ï¼Œå¹¶è§£é‡ŠPostgreSQLçš„ç´¢å¼•ä¼˜åŒ–ç­–ç•¥"
    )
    print("æ··åˆæŸ¥è¯¢:", response)
```

---

## äº”ã€è¿ç»´ç®¡ç†

### 5.1 ç´¢å¼•ä¼˜åŒ–

**è¯¦ç»†å†…å®¹è§å®Œæ•´æ–‡æ¡£...**

### 5.2 æŸ¥è¯¢æ€§èƒ½ç›‘æŽ§

**è¯¦ç»†å†…å®¹è§å®Œæ•´æ–‡æ¡£...**

### 5.3 æˆæœ¬æŽ§åˆ¶

**è¯¦ç»†å†…å®¹è§å®Œæ•´æ–‡æ¡£...**

### 5.4 æœ€ä½³å®žè·µ

**è¯¦ç»†å†…å®¹è§å®Œæ•´æ–‡æ¡£...**

---

## å…­ã€æ¡ˆä¾‹å®žæˆ˜

### 6.1 ä¼ä¸šæ–‡æ¡£ç®¡ç†ç³»ç»Ÿ

**è¯¦ç»†å®žçŽ°è§å®Œæ•´æ–‡æ¡£...**

### 6.2 ç ”ç©¶è®ºæ–‡æ£€ç´¢ç³»ç»Ÿ

**è¯¦ç»†å®žçŽ°è§å®Œæ•´æ–‡æ¡£...**

### 6.3 ä»£ç åº“é—®ç­”ç³»ç»Ÿ

**è¯¦ç»†å®žçŽ°è§å®Œæ•´æ–‡æ¡£...**

### 6.4 å¤šè¯­è¨€çŸ¥è¯†åº“

**è¯¦ç»†å®žçŽ°è§å®Œæ•´æ–‡æ¡£...**

---

## ä¸ƒã€æ€§èƒ½æµ‹è¯•ä¸Žå¯¹æ¯”

| æŒ‡æ ‡ | LlamaIndex | LangChain | æå‡ |
|------|-----------|----------|------|
| ç´¢å¼•æž„å»ºé€Ÿåº¦ | åŸºå‡† | +15% | LangChainæ›´å¿« |
| æŸ¥è¯¢ç²¾åº¦ | åŸºå‡† | -10% | LlamaIndexæ›´å‡†ç¡® |
| Tokenæ¶ˆè€— | åŸºå‡† | +20% | LlamaIndexæ›´çœ |
| å¤æ‚æŸ¥è¯¢æ”¯æŒ | â­â­â­â­â­ | â­â­â­ | LlamaIndexæ›´å¼º |

---

## å…«ã€æ€»ç»“ä¸Žå±•æœ›

### æ ¸å¿ƒæ”¶èŽ·

1. âœ… LlamaIndexæä¾›äº†ä¸°å¯Œçš„ç´¢å¼•ç±»åž‹
2. âœ… å¼ºå¤§çš„æŸ¥è¯¢å¼•æ“Žå’Œè·¯ç”±èƒ½åŠ›
3. âœ… åŽŸç”ŸSQLé›†æˆ
4. âœ… ä¼˜ç§€çš„å¯è§‚æµ‹æ€§

### é€‚ç”¨åœºæ™¯

- âœ… å¤æ‚æ–‡æ¡£æ£€ç´¢
- âœ… ç»“æž„åŒ–æ•°æ®æŸ¥è¯¢
- âœ… çŸ¥è¯†å›¾è°±åº”ç”¨
- âœ… ä¼ä¸šçº§çŸ¥è¯†ç®¡ç†

---

## ä¹ã€å‚è€ƒèµ„æ–™

1. **LlamaIndexå®˜æ–¹æ–‡æ¡£**: [https://docs.llamaindex.ai/](https://docs.llamaindex.ai/)
2. **GitHubä»“åº“**: [https://github.com/run-llama/llama_index](https://github.com/run-llama/llama_index)
3. **PostgreSQL + pgvector**: [https://github.com/pgvector/pgvector](https://github.com/pgvector/pgvector)

---

**æœ€åŽæ›´æ–°**: 2025å¹´12æœˆ4æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 14-AI-LLAMAINDEX
**ç‰ˆæœ¬**: v1.0
