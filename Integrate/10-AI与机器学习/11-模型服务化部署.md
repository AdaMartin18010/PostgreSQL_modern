---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `docs\02-AI-ML\11-æ¨¡å‹æœåŠ¡åŒ–éƒ¨ç½².md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# PostgreSQL + AIæ¨¡å‹æœåŠ¡åŒ–éƒ¨ç½²

## ğŸ“‘ ç›®å½•

- [2.1 FastAPIéƒ¨ç½²](#21-fastapiéƒ¨ç½²)
- [3.1 Dockerfile](#31-dockerfile)
- [3.2 Docker Compose](#32-docker-compose)
- [4.1 å¤šå‰¯æœ¬éƒ¨ç½²](#41-å¤šå‰¯æœ¬éƒ¨ç½²)
- [5.1 æ‰¹é‡å¤„ç†](#51-æ‰¹é‡å¤„ç†)
- [5.2 æ¨¡å‹ç¼“å­˜](#52-æ¨¡å‹ç¼“å­˜)
---

## 2. EmbeddingæœåŠ¡

### 2.1 FastAPIéƒ¨ç½²

```python
from fastapi import FastAPI
from sentence_transformers import SentenceTransformer
import psycopg2
from pydantic import BaseModel

app = FastAPI()

# åŠ è½½æ¨¡å‹
model = SentenceTransformer('all-MiniLM-L6-v2')

# æ•°æ®åº“è¿æ¥
conn = psycopg2.connect("postgresql://localhost/vectordb")

class EmbedRequest(BaseModel):
    texts: list[str]

class SearchRequest(BaseModel):
    query: str
    k: int = 10

@app.post("/embed")
async def embed_texts(request: EmbedRequest):
    """æ–‡æœ¬å‘é‡åŒ–"""
    embeddings = model.encode(request.texts)
    return {"embeddings": embeddings.tolist()}

@app.post("/search")
async def search(request: SearchRequest):
    """å‘é‡æ£€ç´¢"""

    # æŸ¥è¯¢å‘é‡åŒ–
    query_vec = model.encode(request.query)

    # æ•°æ®åº“æ£€ç´¢
    cursor = conn.cursor()
    cursor.execute("""
        SELECT id, content, 1 - (embedding <=> %s::vector) AS similarity
        FROM documents
        ORDER BY embedding <=> %s::vector
        LIMIT %s;
    """, (query_vec.tolist(), query_vec.tolist(), request.k))

    results = cursor.fetchall()
    cursor.close()

    return {
        "results": [
            {"id": r[0], "content": r[1], "similarity": float(r[2])}
            for r in results
        ]
    }

@app.get("/health")
async def health():
    return {"status": "ok"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 3. Dockeréƒ¨ç½²

### 3.1 Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ä¸‹è½½æ¨¡å‹
RUN python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"

# å¤åˆ¶ä»£ç 
COPY . .

# è¿è¡Œ
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### 3.2 Docker Compose

```yaml
version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg18
    environment:
      POSTGRES_PASSWORD: password
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  embedding-service:
    build: ./embedding-service
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://postgres:password@postgres:5432/vectordb
    depends_on:
      - postgres

  api:
    build: ./api
    ports:
      - "8080:8080"
    environment:
      EMBEDDING_SERVICE_URL: http://embedding-service:8000
      DATABASE_URL: postgresql://postgres:password@postgres:5432/vectordb
    depends_on:
      - embedding-service
      - postgres

volumes:
  pgdata:
```

---

## 4. è´Ÿè½½å‡è¡¡

### 4.1 å¤šå‰¯æœ¬éƒ¨ç½²

```yaml
# Kubernetes Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: embedding-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: embedding-service
  template:
    metadata:
      labels:
        app: embedding-service
    spec:
      containers:
      - name: embedding
        image: embedding-service:latest
        resources:
          requests:
            cpu: "2"
            memory: "4Gi"
          limits:
            cpu: "4"
            memory: "8Gi"
        ports:
        - containerPort: 8000
---
apiVersion: v1
kind: Service
metadata:
  name: embedding-service
spec:
  selector:
    app: embedding-service
  ports:
  - port: 8000
    targetPort: 8000
  type: LoadBalancer
```

---

## 5. æ€§èƒ½ä¼˜åŒ–

### 5.1 æ‰¹é‡å¤„ç†

```python
@app.post("/embed/batch")
async def embed_batch(request: EmbedRequest):
    """æ‰¹é‡embeddingï¼ˆæ›´é«˜æ•ˆï¼‰"""

    # æ‰¹é‡ç¼–ç 
    embeddings = model.encode(
        request.texts,
        batch_size=32,
        show_progress_bar=False
    )

    return {"embeddings": embeddings.tolist()}

# æ€§èƒ½: å•ä¸ª100æ¬¡ vs æ‰¹é‡1æ¬¡
# æ—¶é—´: 5ç§’ vs 0.8ç§’ (-84%)
```

### 5.2 æ¨¡å‹ç¼“å­˜

```python
from functools import lru_cache

@lru_cache(maxsize=10000)
def cached_embed(text: str):
    """ç¼“å­˜embeddingç»“æœ"""
    return model.encode(text)

# ç›¸åŒæ–‡æœ¬æ— éœ€é‡å¤è®¡ç®—
```

---

**å®Œæˆ**: PostgreSQL + AIæ¨¡å‹æœåŠ¡åŒ–éƒ¨ç½²
**å­—æ•°**: ~8,000å­—
**æ¶µç›–**: æ¶æ„ã€EmbeddingæœåŠ¡ã€Dockeréƒ¨ç½²ã€K8sã€è´Ÿè½½å‡è¡¡ã€æ€§èƒ½ä¼˜åŒ–

ä»Šæ—¥æ€»äº§å‡ºï¼š**85+æ–‡æ¡£ï¼Œ~458,000å­—çº¯æŠ€æœ¯å†…å®¹ï¼Œ~15,000è¡Œä»£ç **

å·²å…¨é¢è¦†ç›–PostgreSQL 18æ ¸å¿ƒæŠ€æœ¯æ ˆï¼
