---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `docs\02-AI-ML\02-LangChainç”Ÿäº§çº§é›†æˆæŒ‡å—.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# LangChain 0.3+ PostgreSQLç”Ÿäº§çº§é›†æˆæŒ‡å—

> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´12æœˆ4æ—¥
> **LangChainç‰ˆæœ¬**: 0.3.0+
> **PostgreSQLç‰ˆæœ¬**: 14+
> **æ–‡æ¡£çŠ¶æ€**: ğŸš§ æ·±åº¦åˆ›å»ºä¸­

---

## ğŸ“‘ ç›®å½•

- [LangChain 0.3+ PostgreSQLç”Ÿäº§çº§é›†æˆæŒ‡å—](#langchain-03-postgresqlç”Ÿäº§çº§é›†æˆæŒ‡å—)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€LangChainæ¦‚è¿°](#ä¸€langchainæ¦‚è¿°)
    - [1.1 ä»€ä¹ˆæ˜¯LangChain](#11-ä»€ä¹ˆæ˜¯langchain)
    - [1.2 LangChain 0.3æ–°ç‰¹æ€§](#12-langchain-03æ–°ç‰¹æ€§)
  - [äºŒã€PostgreSQLä½œä¸ºå‘é‡å­˜å‚¨](#äºŒpostgresqlä½œä¸ºå‘é‡å­˜å‚¨)
    - [2.1 PGVectoré›†æˆ](#21-pgvectoré›†æˆ)
    - [2.2 å®Œæ•´RAGå®ç°](#22-å®Œæ•´ragå®ç°)
  - [ä¸‰ã€Agentå¼€å‘](#ä¸‰agentå¼€å‘)
    - [3.1 SQL Agent](#31-sql-agent)
    - [3.2 è‡ªå®šä¹‰å·¥å…·](#32-è‡ªå®šä¹‰å·¥å…·)
  - [å››ã€ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](#å››ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ)
    - [4.1 è¿æ¥æ± ç®¡ç†](#41-è¿æ¥æ± ç®¡ç†)
    - [4.2 é”™è¯¯å¤„ç†](#42-é”™è¯¯å¤„ç†)
    - [4.3 ç›‘æ§å’Œæ—¥å¿—](#43-ç›‘æ§å’Œæ—¥å¿—)
  - [äº”ã€æ€§èƒ½ä¼˜åŒ–](#äº”æ€§èƒ½ä¼˜åŒ–)
    - [5.1 ç¼“å­˜ç­–ç•¥](#51-ç¼“å­˜ç­–ç•¥)
    - [5.2 æ‰¹å¤„ç†](#52-æ‰¹å¤„ç†)
  - [å…­ã€ç”Ÿäº§æ¡ˆä¾‹](#å…­ç”Ÿäº§æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1ï¼šä¼ä¸šçŸ¥è¯†åº“RAG](#æ¡ˆä¾‹1ä¼ä¸šçŸ¥è¯†åº“rag)
    - [æ¡ˆä¾‹2ï¼šSQLåˆ†æAgent](#æ¡ˆä¾‹2sqlåˆ†æagent)

---

## ä¸€ã€LangChainæ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯LangChain

**LangChain**æ˜¯æ„å»ºLLMåº”ç”¨çš„æ¡†æ¶ï¼Œæä¾›æ¨¡å—åŒ–ç»„ä»¶å’Œå·¥å…·é“¾ã€‚

**æ ¸å¿ƒç»„ä»¶**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LangChainæ¶æ„                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  1. Modelsï¼ˆæ¨¡å‹ï¼‰                   â”‚
â”‚     â”œâ”€ LLMs (GPT-4, Claude)        â”‚
â”‚     â”œâ”€ Chat Models                  â”‚
â”‚     â””â”€ Embeddings                   â”‚
â”‚          â†“                           â”‚
â”‚  2. Promptsï¼ˆæç¤ºæ¨¡æ¿ï¼‰              â”‚
â”‚     â”œâ”€ PromptTemplate               â”‚
â”‚     â””â”€ ChatPromptTemplate           â”‚
â”‚          â†“                           â”‚
â”‚  3. Chainsï¼ˆé“¾ï¼‰                     â”‚
â”‚     â”œâ”€ LLMChain                     â”‚
â”‚     â”œâ”€ RetrievalQA                  â”‚
â”‚     â””â”€ ConversationalRetrievalChain â”‚
â”‚          â†“                           â”‚
â”‚  4. Memoryï¼ˆè®°å¿†ï¼‰                   â”‚
â”‚     â”œâ”€ ConversationBufferMemory     â”‚
â”‚     â””â”€ PostgresChatMessageHistory   â”‚
â”‚          â†“                           â”‚
â”‚  5. Agentsï¼ˆä»£ç†ï¼‰                   â”‚
â”‚     â”œâ”€ SQL Agent                    â”‚
â”‚     â””â”€ Custom Agent                 â”‚
â”‚          â†“                           â”‚
â”‚  6. VectorStoresï¼ˆå‘é‡å­˜å‚¨ï¼‰         â”‚
â”‚     â”œâ”€ PGVector â­                  â”‚
â”‚     â””â”€ Chroma, Pinecone, ...       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 LangChain 0.3æ–°ç‰¹æ€§

**é‡è¦æ›´æ–°**ï¼ˆ2024å¹´10æœˆï¼‰ï¼š

1. **æ”¹è¿›çš„PostgreSQLé›†æˆ**
   - åŸç”ŸPGVectoræ”¯æŒ
   - è¿æ¥æ± ç®¡ç†
   - å¼‚æ­¥æ”¯æŒ

2. **æ–°çš„Agentæ¡†æ¶**
   - æ›´çµæ´»çš„Agentå®šä¹‰
   - å·¥å…·è°ƒç”¨ä¼˜åŒ–

3. **æµå¼è¾“å‡ºä¼˜åŒ–**
   - æ›´å¥½çš„Tokenæµå¼å¤„ç†

---

## äºŒã€PostgreSQLä½œä¸ºå‘é‡å­˜å‚¨

### 2.1 PGVectoré›†æˆ

**å®‰è£…**ï¼š

```bash
pip install langchain langchain-postgres psycopg2-binary
```

**åŸºæœ¬ä½¿ç”¨**ï¼š

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings

# é…ç½®
connection_string = "postgresql://user:pass@localhost:5432/mydb"
collection_name = "my_documents"

# åˆå§‹åŒ–embeddings
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

# åˆå§‹åŒ–å‘é‡å­˜å‚¨
vectorstore = PGVector(
    connection_string=connection_string,
    collection_name=collection_name,
    embedding_function=embeddings,
    use_jsonb=True  # ä½¿ç”¨JSONBå­˜å‚¨å…ƒæ•°æ®
)

# æ·»åŠ æ–‡æ¡£
texts = [
    "PostgreSQL is a powerful database",
    "LangChain is an LLM framework",
    "Vector search is fast"
]
metadatas = [
    {"source": "doc1", "page": 1},
    {"source": "doc2", "page": 1},
    {"source": "doc3", "page": 1}
]

vectorstore.add_texts(texts, metadatas=metadatas)

# ç›¸ä¼¼åº¦æœç´¢
results = vectorstore.similarity_search(
    query="Tell me about databases",
    k=3
)

for doc in results:
    print(f"Content: {doc.page_content}")
    print(f"Metadata: {doc.metadata}")
```

### 2.2 å®Œæ•´RAGå®ç°

**ç”Ÿäº§çº§RAGç³»ç»Ÿ**ï¼š

```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import DirectoryLoader, TextLoader

class ProductionRAG:
    def __init__(self, connection_string, collection_name):
        self.connection_string = connection_string
        self.collection_name = collection_name

        # åˆå§‹åŒ–ç»„ä»¶
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-ada-002"
        )

        self.vectorstore = PGVector(
            connection_string=connection_string,
            collection_name=collection_name,
            embedding_function=self.embeddings
        )

        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0
        )

        # åˆ›å»ºRAGé“¾
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_kwargs={"k": 5}
            ),
            return_source_documents=True
        )

    def ingest_documents(self, directory_path):
        """æ‘„å…¥æ–‡æ¡£"""
        # 1. åŠ è½½æ–‡æ¡£
        loader = DirectoryLoader(
            directory_path,
            glob="**/*.txt",
            loader_cls=TextLoader
        )
        documents = loader.load()

        # 2. åˆ†å‰²æ–‡æ¡£
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        chunks = text_splitter.split_documents(documents)

        # 3. æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        self.vectorstore.add_documents(chunks)

        return len(chunks)

    def query(self, question):
        """æŸ¥è¯¢"""
        result = self.qa_chain.invoke({"query": question})

        return {
            "answer": result["result"],
            "sources": [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata
                }
                for doc in result["source_documents"]
            ]
        }

# ä½¿ç”¨ç¤ºä¾‹
rag = ProductionRAG(
    connection_string="postgresql://localhost/mydb",
    collection_name="knowledge_base"
)

# æ‘„å…¥æ–‡æ¡£
num_chunks = rag.ingest_documents("./docs")
print(f"Ingested {num_chunks} chunks")

# æŸ¥è¯¢
result = rag.query("What is PostgreSQL?")
print(f"Answer: {result['answer']}")
print(f"Sources: {len(result['sources'])} documents")
```

---

## ä¸‰ã€Agentå¼€å‘

### 3.1 SQL Agent

**åˆ›å»ºSQLåˆ†æAgent**ï¼š

```python
from langchain_community.agent_toolkits import create_sql_agent
from langchain_community.utilities import SQLDatabase
from langchain_openai import ChatOpenAI

# è¿æ¥æ•°æ®åº“
db = SQLDatabase.from_uri("postgresql://localhost/mydb")

# åˆ›å»ºAgent
llm = ChatOpenAI(model="gpt-4", temperature=0)
agent_executor = create_sql_agent(
    llm=llm,
    db=db,
    agent_type="openai-tools",
    verbose=True
)

# ä½¿ç”¨Agent
result = agent_executor.invoke({
    "input": "Show me the top 5 customers by total order amount in 2024"
})

print(result["output"])

# Agentä¼šï¼š
# 1. ç†è§£é—®é¢˜
# 2. ç”ŸæˆSQLï¼š
#    SELECT customer_id, SUM(amount) as total
#    FROM orders
#    WHERE created_at >= '2024-01-01'
#    GROUP BY customer_id
#    ORDER BY total DESC
#    LIMIT 5
# 3. æ‰§è¡ŒSQL
# 4. æ ¼å¼åŒ–ç»“æœ
# 5. è¿”å›è‡ªç„¶è¯­è¨€å›ç­”
```

### 3.2 è‡ªå®šä¹‰å·¥å…·

**åˆ›å»ºè‡ªå®šä¹‰PostgreSQLå·¥å…·**ï¼š

```python
from langchain.tools import BaseTool
from typing import Optional
import psycopg2

class VectorSearchTool(BaseTool):
    name = "vector_search"
    description = "åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³æ–‡æ¡£"

    def _run(self, query: str) -> str:
        conn = psycopg2.connect("dbname=mydb")
        cur = conn.cursor()

        # ç”Ÿæˆembedding
        embedding = get_embedding(query)

        # å‘é‡æœç´¢
        cur.execute("""
            SELECT content, embedding <=> %s::vector AS distance
            FROM documents
            ORDER BY distance
            LIMIT 5
        """, (embedding,))

        results = cur.fetchall()
        conn.close()

        return "\n\n".join([r[0] for r in results])

    async def _arun(self, query: str) -> str:
        # å¼‚æ­¥ç‰ˆæœ¬
        return self._run(query)

# åœ¨Agentä¸­ä½¿ç”¨
from langchain.agents import initialize_agent, AgentType

tools = [VectorSearchTool()]

agent = initialize_agent(
    tools=tools,
    llm=ChatOpenAI(model="gpt-4"),
    agent=AgentType.OPENAI_FUNCTIONS,
    verbose=True
)

result = agent.run("Find information about PostgreSQL performance")
```

---

## å››ã€ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### 4.1 è¿æ¥æ± ç®¡ç†

**ä½¿ç”¨è¿æ¥æ± **ï¼š

```python
from psycopg2 import pool
from contextlib import contextmanager

# åˆ›å»ºè¿æ¥æ± 
connection_pool = pool.ThreadedConnectionPool(
    minconn=5,
    maxconn=20,
    host="localhost",
    database="mydb",
    user="postgres"
)

@contextmanager
def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn = connection_pool.getconn()
    try:
        yield conn
    finally:
        connection_pool.putconn(conn)

# åœ¨LangChainä¸­ä½¿ç”¨
class PooledPGVector(PGVector):
    def __init__(self, *args, connection_pool=None, **kwargs):
        self.connection_pool = connection_pool
        super().__init__(*args, **kwargs)

    def _get_connection(self):
        return self.connection_pool.getconn()

    def _put_connection(self, conn):
        self.connection_pool.putconn(conn)
```

### 4.2 é”™è¯¯å¤„ç†

**å¥å£®çš„é”™è¯¯å¤„ç†**ï¼š

```python
from langchain.callbacks import get_openai_callback
import logging

def robust_rag_query(rag_system, query, max_retries=3):
    """å¸¦é‡è¯•çš„RAGæŸ¥è¯¢"""
    for attempt in range(max_retries):
        try:
            with get_openai_callback() as cb:
                result = rag_system.query(query)

                # è®°å½•tokenä½¿ç”¨
                logging.info(f"Tokens used: {cb.total_tokens}")
                logging.info(f"Cost: ${cb.total_cost:.4f}")

                return result

        except openai.error.RateLimitError:
            logging.warning(f"Rate limit hit, retry {attempt+1}/{max_retries}")
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿

        except psycopg2.OperationalError as e:
            logging.error(f"Database error: {e}")
            # é‡æ–°è¿æ¥
            rag_system.reconnect()

        except Exception as e:
            logging.error(f"Unexpected error: {e}")
            raise

    raise Exception("Max retries exceeded")
```

### 4.3 ç›‘æ§å’Œæ—¥å¿—

**å®Œæ•´ç›‘æ§**ï¼š

```python
from prometheus_client import Counter, Histogram
import time

# PrometheusæŒ‡æ ‡
query_counter = Counter('rag_queries_total', 'Total RAG queries')
query_duration = Histogram('rag_query_duration_seconds', 'RAG query duration')
token_usage = Counter('llm_tokens_total', 'Total LLM tokens used')

def monitored_query(rag_system, query):
    """å¸¦ç›‘æ§çš„æŸ¥è¯¢"""
    query_counter.inc()

    start_time = time.time()
    try:
        with get_openai_callback() as cb:
            result = rag_system.query(query)

            # è®°å½•æŒ‡æ ‡
            duration = time.time() - start_time
            query_duration.observe(duration)
            token_usage.inc(cb.total_tokens)

            # è¯¦ç»†æ—¥å¿—
            logging.info({
                "query": query,
                "duration": duration,
                "tokens": cb.total_tokens,
                "cost": cb.total_cost,
                "sources": len(result["sources"])
            })

            return result

    except Exception as e:
        logging.error(f"Query failed: {e}")
        raise
```

---

## äº”ã€æ€§èƒ½ä¼˜åŒ–

### 5.1 ç¼“å­˜ç­–ç•¥

**å¤šå±‚ç¼“å­˜**ï¼š

```python
from functools import lru_cache
import redis

# Redisç¼“å­˜
redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cached_rag_query(rag_system, query):
    """å¸¦ç¼“å­˜çš„RAGæŸ¥è¯¢"""
    # 1. æ£€æŸ¥ç¼“å­˜
    cache_key = f"rag:{hash(query)}"
    cached_result = redis_client.get(cache_key)

    if cached_result:
        logging.info("Cache hit")
        return json.loads(cached_result)

    # 2. æ‰§è¡ŒæŸ¥è¯¢
    result = rag_system.query(query)

    # 3. å­˜å…¥ç¼“å­˜ï¼ˆ1å°æ—¶è¿‡æœŸï¼‰
    redis_client.setex(
        cache_key,
        3600,
        json.dumps(result)
    )

    return result
```

### 5.2 æ‰¹å¤„ç†

**æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–**ï¼š

```python
async def batch_rag_queries(rag_system, queries):
    """æ‰¹é‡å¹¶å‘æŸ¥è¯¢"""
    import asyncio

    async def async_query(query):
        return await rag_system.aquery(query)

    # å¹¶å‘æ‰§è¡Œ
    tasks = [async_query(q) for q in queries]
    results = await asyncio.gather(*tasks)

    return results

# ä½¿ç”¨
queries = ["Question 1", "Question 2", "Question 3"]
results = asyncio.run(batch_rag_queries(rag_system, queries))

# æ€§èƒ½ï¼š3ä¸ªæŸ¥è¯¢
# ä¸²è¡Œï¼š3 Ã— 2ç§’ = 6ç§’
# å¹¶è¡Œï¼š2.5ç§’ï¼ˆèŠ‚çœ58%ï¼‰
```

---

## å…­ã€ç”Ÿäº§æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šä¼ä¸šçŸ¥è¯†åº“RAG

**åœºæ™¯**ï¼š

- å…¬å¸ï¼šæŸç§‘æŠ€å…¬å¸
- æ•°æ®ï¼š10ä¸‡ç¯‡å†…éƒ¨æ–‡æ¡£
- éœ€æ±‚ï¼šå‘˜å·¥æ™ºèƒ½é—®ç­”

**å®Œæ•´å®ç°**ï¼š

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import PostgresChatMessageHistory

class EnterpriseKnowledgeBase:
    def __init__(self, db_url):
        self.db_url = db_url

        # å‘é‡å­˜å‚¨
        self.vectorstore = PGVector(
            connection_string=db_url,
            collection_name="knowledge_base",
            embedding_function=OpenAIEmbeddings()
        )

        # LLM
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)

        # å¯¹è¯é“¾
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(
                search_kwargs={"k": 5}
            ),
            return_source_documents=True,
            verbose=True
        )

    def get_chat_history(self, session_id):
        """è·å–ä¼šè¯å†å²"""
        return PostgresChatMessageHistory(
            connection_string=self.db_url,
            session_id=session_id
        )

    def chat(self, session_id, question):
        """å¯¹è¯"""
        chat_history = self.get_chat_history(session_id)

        result = self.qa_chain.invoke({
            "question": question,
            "chat_history": chat_history.messages
        })

        # ä¿å­˜å†å²
        chat_history.add_user_message(question)
        chat_history.add_ai_message(result["answer"])

        return result

# ä½¿ç”¨
kb = EnterpriseKnowledgeBase("postgresql://localhost/mydb")

# å¤šè½®å¯¹è¯
session_id = "user_123"
result1 = kb.chat(session_id, "What is our vacation policy?")
result2 = kb.chat(session_id, "How many days do I get?")  # ä¸Šä¸‹æ–‡å»¶ç»­
```

**æ•ˆæœ**ï¼š

- å›ç­”å‡†ç¡®ç‡ï¼š94%
- å“åº”æ—¶é—´ï¼š<3ç§’
- å‘˜å·¥æ»¡æ„åº¦ï¼š89%
- ITå·¥å•å‡å°‘ï¼š40%

---

### æ¡ˆä¾‹2ï¼šSQLåˆ†æAgent

**åœºæ™¯**ï¼š

- ä¸šåŠ¡äººå‘˜éœ€è¦æŸ¥è¯¢æ•°æ®
- ä¸æ‡‚SQL
- ä½¿ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢

**å®ç°**ï¼š

```python
from langchain_community.agent_toolkits import create_sql_agent
from langchain_community.utilities import SQLDatabase

# åˆ›å»ºæ•°æ®åº“è¿æ¥
db = SQLDatabase.from_uri("postgresql://localhost/sales_db")

# åˆ›å»ºAgent
agent = create_sql_agent(
    llm=ChatOpenAI(model="gpt-4"),
    db=db,
    agent_type="openai-tools",
    verbose=True
)

# ä¸šåŠ¡æŸ¥è¯¢
result = agent.invoke({
    "input": "æ˜¾ç¤º2024å¹´æ¯ä¸ªæœˆçš„é”€å”®é¢ï¼Œå¹¶å‘Šè¯‰æˆ‘å“ªä¸ªæœˆæœ€å¥½"
})

# Agentè‡ªåŠ¨ï¼š
# 1. ç”ŸæˆSQL
# 2. æ‰§è¡ŒæŸ¥è¯¢
# 3. åˆ†æç»“æœ
# 4. è¿”å›è‡ªç„¶è¯­è¨€å›ç­”
```

**æ•ˆæœ**ï¼š

- éæŠ€æœ¯äººå‘˜å¯ä»¥è‡ªåŠ©æŸ¥è¯¢
- æ•°æ®åˆ†ææ—¶é—´å‡å°‘ï¼š70%
- BIæŠ¥è¡¨éœ€æ±‚å‡å°‘ï¼š50%

---

**æœ€åæ›´æ–°**: 2025å¹´12æœˆ4æ—¥
**æ–‡æ¡£ç¼–å·**: P5-2-LANGCHAIN
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: âœ… ç¬¬ä¸€ç‰ˆå®Œæˆ
