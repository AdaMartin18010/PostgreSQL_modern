---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL_View\02-AIè‡ªæ²»ä¸è‡ªä¼˜åŒ–\æŠ€æœ¯åŸç†\è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: pg_ai v1.0+
> **æ–‡æ¡£ç¼–å·**: 02-01-03

## ğŸ“‘ ç›®å½•

- [è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–](#è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 æŠ€æœ¯èƒŒæ™¯](#11-æŠ€æœ¯èƒŒæ™¯)
    - [1.2 æŠ€æœ¯å®šä½](#12-æŠ€æœ¯å®šä½)
    - [1.3 æ ¸å¿ƒä»·å€¼](#13-æ ¸å¿ƒä»·å€¼)
  - [2. æŠ€æœ¯åŸç†](#2-æŠ€æœ¯åŸç†)
    - [2.1 è‡ªé€‚åº”ä¼˜åŒ–åŸç†](#21-è‡ªé€‚åº”ä¼˜åŒ–åŸç†)
    - [2.2 æŸ¥è¯¢è®¡åˆ’å­¦ä¹ ](#22-æŸ¥è¯¢è®¡åˆ’å­¦ä¹ )
    - [2.3 åŠ¨æ€è°ƒæ•´æœºåˆ¶](#23-åŠ¨æ€è°ƒæ•´æœºåˆ¶)
    - [2.4 åé¦ˆå­¦ä¹ æœºåˆ¶](#24-åé¦ˆå­¦ä¹ æœºåˆ¶)
  - [3. æ¶æ„è®¾è®¡](#3-æ¶æ„è®¾è®¡)
    - [3.1 æ•´ä½“æ¶æ„](#31-æ•´ä½“æ¶æ„)
    - [3.2 å­¦ä¹ æ¨¡å—](#32-å­¦ä¹ æ¨¡å—)
    - [3.3 æ‰§è¡Œæ¨¡å—](#33-æ‰§è¡Œæ¨¡å—)
  - [4. å®ç°ç»†èŠ‚](#4-å®ç°ç»†èŠ‚)
    - [4.1 æŸ¥è¯¢ç‰¹å¾æå–](#41-æŸ¥è¯¢ç‰¹å¾æå–)
    - [4.2 è®¡åˆ’é€‰æ‹©ç®—æ³•](#42-è®¡åˆ’é€‰æ‹©ç®—æ³•)
    - [4.3 æ€§èƒ½åé¦ˆæ”¶é›†](#43-æ€§èƒ½åé¦ˆæ”¶é›†)
  - [5. æ€§èƒ½åˆ†æ](#5-æ€§èƒ½åˆ†æ)
    - [5.1 ä¼˜åŒ–æ•ˆæœ](#51-ä¼˜åŒ–æ•ˆæœ)
    - [5.2 å­¦ä¹ æ•ˆç‡](#52-å­¦ä¹ æ•ˆç‡)
    - [5.3 å®é™…åº”ç”¨æ¡ˆä¾‹](#53-å®é™…åº”ç”¨æ¡ˆä¾‹)
      - [æ¡ˆä¾‹ 1: æ•°æ®åˆ†æå¹³å°è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–ï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰](#æ¡ˆä¾‹-1-æ•°æ®åˆ†æå¹³å°è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–çœŸå®æ¡ˆä¾‹)
      - [æ¡ˆä¾‹ 2: ç”µå•†å¹³å°è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–ï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰](#æ¡ˆä¾‹-2-ç”µå•†å¹³å°è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–çœŸå®æ¡ˆä¾‹)
  - [6. æœ€ä½³å®è·µ](#6-æœ€ä½³å®è·µ)
    - [6.1 é…ç½®å»ºè®®](#61-é…ç½®å»ºè®®)
    - [6.2 ç›‘æ§ç­–ç•¥](#62-ç›‘æ§ç­–ç•¥)
    - [6.3 è°ƒä¼˜å»ºè®®](#63-è°ƒä¼˜å»ºè®®)
  - [7. å‚è€ƒèµ„æ–™](#7-å‚è€ƒèµ„æ–™)
    - [7.1 å­¦æœ¯è®ºæ–‡](#71-å­¦æœ¯è®ºæ–‡)
    - [7.2 å®˜æ–¹æ–‡æ¡£](#72-å®˜æ–¹æ–‡æ¡£)
    - [7.3 å®é™…åº”ç”¨æ¡ˆä¾‹](#73-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [7.4 ç›¸å…³èµ„æº](#74-ç›¸å…³èµ„æº)
  - [8. å®Œæ•´ä»£ç ç¤ºä¾‹](#8-å®Œæ•´ä»£ç ç¤ºä¾‹)
    - [8.1 pg\_ai è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–å™¨å®‰è£…ä¸é…ç½®](#81-pg_ai-è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–å™¨å®‰è£…ä¸é…ç½®)
    - [8.2 æŸ¥è¯¢ç‰¹å¾æå–ä¸è®¡åˆ’é€‰æ‹©ç¤ºä¾‹](#82-æŸ¥è¯¢ç‰¹å¾æå–ä¸è®¡åˆ’é€‰æ‹©ç¤ºä¾‹)
    - [8.3 è‡ªé€‚åº”å­¦ä¹ ä¸åé¦ˆæœºåˆ¶ç¤ºä¾‹](#83-è‡ªé€‚åº”å­¦ä¹ ä¸åé¦ˆæœºåˆ¶ç¤ºä¾‹)
    - [8.4 è‡ªé€‚åº”ä¼˜åŒ–å®Œæ•´åº”ç”¨ç¤ºä¾‹](#84-è‡ªé€‚åº”ä¼˜åŒ–å®Œæ•´åº”ç”¨ç¤ºä¾‹)
    - [8.5 ç›‘æ§ä¸è°ƒä¼˜ç¤ºä¾‹](#85-ç›‘æ§ä¸è°ƒä¼˜ç¤ºä¾‹)

---

## 1. æ¦‚è¿°

### 1.1 æŠ€æœ¯èƒŒæ™¯

**é—®é¢˜éœ€æ±‚**:

ä¼ ç»Ÿçš„æŸ¥è¯¢ä¼˜åŒ–å™¨åŸºäºé™æ€ç»Ÿè®¡ä¿¡æ¯è¿›è¡Œä¼˜åŒ–ï¼Œæ— æ³•é€‚åº”æ•°æ®åˆ†å¸ƒå’ŒæŸ¥è¯¢æ¨¡å¼çš„å˜åŒ–ã€‚
å½“æ•°æ®åˆ†å¸ƒå‘ç”Ÿå˜åŒ–æˆ–å‡ºç°æ–°çš„æŸ¥è¯¢æ¨¡å¼æ—¶ï¼Œä¼˜åŒ–å™¨å¯èƒ½é€‰æ‹©æ¬¡ä¼˜çš„æ‰§è¡Œè®¡åˆ’ã€‚

**æŠ€æœ¯æ¼”è¿›**:

1. **2010 å¹´**: è‡ªé€‚åº”æŸ¥è¯¢å¤„ç†æ¦‚å¿µæå‡º
2. **2015 å¹´**: æœºå™¨å­¦ä¹ åº”ç”¨äºæŸ¥è¯¢ä¼˜åŒ–
3. **2020 å¹´**: æ·±åº¦å­¦ä¹ ä¼˜åŒ–å™¨å‡ºç°
4. **2025 å¹´**: è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–æˆä¸º AI è‡ªæ²»æ•°æ®åº“æ ‡å‡†ç‰¹æ€§

**å¸‚åœºéœ€æ±‚**:

- **åŠ¨æ€é€‚åº”**: é€‚åº”æ•°æ®åˆ†å¸ƒå’ŒæŸ¥è¯¢æ¨¡å¼çš„å˜åŒ–
- **æŒç»­ä¼˜åŒ–**: ä»æ‰§è¡Œåé¦ˆä¸­æŒç»­å­¦ä¹ 
- **æ€§èƒ½æå‡**: é€‰æ‹©æœ€ä¼˜æ‰§è¡Œè®¡åˆ’
- **è‡ªåŠ¨åŒ–**: å‡å°‘äººå·¥å¹²é¢„

### 1.2 æŠ€æœ¯å®šä½

è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–æ˜¯ AI è‡ªæ²»æ•°æ®åº“çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œé€šè¿‡ä»æŸ¥è¯¢æ‰§è¡Œåé¦ˆä¸­å­¦ä¹ ï¼ŒåŠ¨æ€è°ƒæ•´æŸ¥è¯¢è®¡åˆ’ï¼Œå®ç°æŒç»­ä¼˜åŒ–ã€‚

### 1.3 æ ¸å¿ƒä»·å€¼

- **åŠ¨æ€é€‚åº”**: è‡ªåŠ¨é€‚åº”æ•°æ®åˆ†å¸ƒå˜åŒ–
- **æŒç»­å­¦ä¹ **: ä»æ‰§è¡Œåé¦ˆä¸­æŒç»­å­¦ä¹ 
- **æ€§èƒ½ä¼˜åŒ–**: é€‰æ‹©æœ€ä¼˜æ‰§è¡Œè®¡åˆ’
- **é›¶é…ç½®**: è‡ªåŠ¨ä¼˜åŒ–ï¼Œæ— éœ€äººå·¥é…ç½®

---

## 2. æŠ€æœ¯åŸç†

### 2.1 è‡ªé€‚åº”ä¼˜åŒ–åŸç†

**åŸºæœ¬åŸç†**:

è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–é€šè¿‡ä»¥ä¸‹æ­¥éª¤å®ç°ï¼š

1. **æŸ¥è¯¢ç‰¹å¾æå–**: æå–æŸ¥è¯¢çš„ç‰¹å¾å‘é‡
2. **è®¡åˆ’é€‰æ‹©**: åŸºäºå­¦ä¹ æ¨¡å‹é€‰æ‹©æ‰§è¡Œè®¡åˆ’
3. **æ‰§è¡Œç›‘æ§**: ç›‘æ§æŸ¥è¯¢æ‰§è¡Œæ€§èƒ½
4. **åé¦ˆå­¦ä¹ **: ä»æ‰§è¡Œåé¦ˆä¸­æ›´æ–°æ¨¡å‹

**å·¥ä½œæµç¨‹**:

```python
class AdaptiveQueryOptimizer:
    """è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–å™¨"""

    def optimize(self, query):
        """ä¼˜åŒ–æŸ¥è¯¢"""
        # 1. æå–æŸ¥è¯¢ç‰¹å¾
        features = self.extract_features(query)

        # 2. é€‰æ‹©æ‰§è¡Œè®¡åˆ’
        plan = self.select_plan(features)

        # 3. æ‰§è¡ŒæŸ¥è¯¢
        result = self.execute_query(query, plan)

        # 4. æ”¶é›†æ€§èƒ½åé¦ˆ
        feedback = self.collect_feedback(result)

        # 5. æ›´æ–°æ¨¡å‹
        self.update_model(features, plan, feedback)

        return result
```

### 2.2 æŸ¥è¯¢è®¡åˆ’å­¦ä¹ 

**å­¦ä¹ ç›®æ ‡**:

å­¦ä¹ ä»æŸ¥è¯¢ç‰¹å¾åˆ°æœ€ä¼˜æ‰§è¡Œè®¡åˆ’çš„æ˜ å°„ï¼š

```text
f: QueryFeatures â†’ OptimalPlan
```

**å­¦ä¹ ç®—æ³•**:

ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–ç›‘ç£å­¦ä¹ ï¼š

```python
class PlanLearner:
    """è®¡åˆ’å­¦ä¹ å™¨"""

    def __init__(self):
        self.model = PlanSelectionModel()
        self.experience_buffer = ExperienceBuffer()

    def learn(self, features, plans, rewards):
        """å­¦ä¹ æœ€ä¼˜è®¡åˆ’"""
        # å­˜å‚¨ç»éªŒ
        for feature, plan, reward in zip(features, plans, rewards):
            self.experience_buffer.push(feature, plan, reward)

        # è®­ç»ƒæ¨¡å‹
        batch = self.experience_buffer.sample(batch_size=64)
        self.model.train(batch)

    def select_plan(self, features):
        """é€‰æ‹©è®¡åˆ’"""
        return self.model.predict(features)
```

### 2.3 åŠ¨æ€è°ƒæ•´æœºåˆ¶

**è°ƒæ•´ç­–ç•¥**:

- **å®æ—¶è°ƒæ•´**: æ ¹æ®å½“å‰æ‰§è¡Œæ€§èƒ½å®æ—¶è°ƒæ•´
- **æ¸è¿›è°ƒæ•´**: é€æ­¥è°ƒæ•´ï¼Œé¿å…å‰§çƒˆå˜åŒ–
- **å®‰å…¨è°ƒæ•´**: åœ¨å®‰å…¨èŒƒå›´å†…è°ƒæ•´

**å®ç°ç¤ºä¾‹**:

```python
class DynamicAdjuster:
    """åŠ¨æ€è°ƒæ•´å™¨"""

    def adjust_plan(self, current_plan, performance):
        """è°ƒæ•´è®¡åˆ’"""
        if performance.is_degraded():
            # æ€§èƒ½ä¸‹é™ï¼Œå°è¯•æ–°è®¡åˆ’
            new_plan = self.explore_alternative_plan(current_plan)
            return new_plan
        elif performance.is_improved():
            # æ€§èƒ½æå‡ï¼Œä¿æŒå½“å‰è®¡åˆ’
            return current_plan
        else:
            # æ€§èƒ½ç¨³å®šï¼Œå¾®è°ƒå‚æ•°
            return self.fine_tune_plan(current_plan)
```

### 2.4 åé¦ˆå­¦ä¹ æœºåˆ¶

**åé¦ˆç±»å‹**:

- **æ‰§è¡Œæ—¶é—´**: æŸ¥è¯¢æ‰§è¡Œæ—¶é—´
- **èµ„æºä½¿ç”¨**: CPUã€å†…å­˜ã€I/O ä½¿ç”¨æƒ…å†µ
- **ç»“æœè´¨é‡**: ç»“æœå‡†ç¡®æ€§ï¼ˆå¦‚è¿‘ä¼¼æŸ¥è¯¢ï¼‰

**åé¦ˆæ”¶é›†**:

```python
class FeedbackCollector:
    """åé¦ˆæ”¶é›†å™¨"""

    def collect(self, query, plan, result):
        """æ”¶é›†åé¦ˆ"""
        feedback = {
            'execution_time': result.execution_time,
            'cpu_usage': result.cpu_usage,
            'memory_usage': result.memory_usage,
            'disk_io': result.disk_io,
            'rows_returned': result.rows_returned,
            'cost': self.calculate_cost(result)
        }
        return feedback
```

---

## 3. æ¶æ„è®¾è®¡

### 3.1 æ•´ä½“æ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Query Optimizer                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Feature Extractor               â”‚  â”‚
â”‚  â”‚  - Query Features                â”‚  â”‚
â”‚  â”‚  - Data Statistics               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Plan Selector                   â”‚  â”‚
â”‚  â”‚  - Learning Model                â”‚  â”‚
â”‚  â”‚  - Plan Generation               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Execution Monitor               â”‚  â”‚
â”‚  â”‚  - Performance Tracking          â”‚  â”‚
â”‚  â”‚  - Feedback Collection           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Learning Module                 â”‚  â”‚
â”‚  â”‚  - Model Training                â”‚  â”‚
â”‚  â”‚  - Model Update                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å­¦ä¹ æ¨¡å—

**å­¦ä¹ ç»„ä»¶**:

- **ç‰¹å¾å·¥ç¨‹**: æå–æœ‰æ•ˆçš„æŸ¥è¯¢ç‰¹å¾
- **æ¨¡å‹è®­ç»ƒ**: è®­ç»ƒè®¡åˆ’é€‰æ‹©æ¨¡å‹
- **æ¨¡å‹æ›´æ–°**: åœ¨çº¿æ›´æ–°æ¨¡å‹

### 3.3 æ‰§è¡Œæ¨¡å—

**æ‰§è¡Œç»„ä»¶**:

- **è®¡åˆ’æ‰§è¡Œ**: æ‰§è¡Œé€‰å®šçš„è®¡åˆ’
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§æ‰§è¡Œæ€§èƒ½
- **åé¦ˆæ”¶é›†**: æ”¶é›†æ‰§è¡Œåé¦ˆ

---

## 4. å®ç°ç»†èŠ‚

### 4.1 æŸ¥è¯¢ç‰¹å¾æå–

**ç‰¹å¾ç±»å‹**:

- **æŸ¥è¯¢ç»“æ„**: JOIN æ•°é‡ã€å­æŸ¥è¯¢æ·±åº¦ç­‰
- **æ•°æ®ç‰¹å¾**: è¡¨å¤§å°ã€ç´¢å¼•æƒ…å†µç­‰
- **å†å²ç‰¹å¾**: å†å²æ‰§è¡Œæ€§èƒ½ç­‰

**ç‰¹å¾æå–**:

```python
class FeatureExtractor:
    """ç‰¹å¾æå–å™¨"""

    def extract(self, query):
        """æå–ç‰¹å¾"""
        features = {
            # æŸ¥è¯¢ç»“æ„ç‰¹å¾
            'num_joins': self.count_joins(query),
            'num_subqueries': self.count_subqueries(query),
            'query_complexity': self.calculate_complexity(query),

            # æ•°æ®ç‰¹å¾
            'table_sizes': self.get_table_sizes(query),
            'index_availability': self.check_indexes(query),
            'data_distribution': self.get_distribution(query),

            # å†å²ç‰¹å¾
            'historical_performance': self.get_historical_performance(query)
        }
        return self.vectorize(features)
```

### 4.2 è®¡åˆ’é€‰æ‹©ç®—æ³•

**é€‰æ‹©ç­–ç•¥**:

- **Exploitation**: é€‰æ‹©å·²çŸ¥æœ€ä¼˜è®¡åˆ’
- **Exploration**: æ¢ç´¢æ–°è®¡åˆ’
- **å¹³è¡¡ç­–ç•¥**: å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨

**å®ç°**:

```python
class PlanSelector:
    """è®¡åˆ’é€‰æ‹©å™¨"""

    def __init__(self, epsilon=0.1):
        self.model = PlanSelectionModel()
        self.epsilon = epsilon  # æ¢ç´¢ç‡

    def select(self, features):
        """é€‰æ‹©è®¡åˆ’"""
        if random.random() < self.epsilon:
            # æ¢ç´¢ï¼šéšæœºé€‰æ‹©è®¡åˆ’
            return self.explore_plan(features)
        else:
            # åˆ©ç”¨ï¼šé€‰æ‹©æœ€ä¼˜è®¡åˆ’
            return self.exploit_plan(features)

    def exploit_plan(self, features):
        """åˆ©ç”¨æœ€ä¼˜è®¡åˆ’"""
        plan_scores = self.model.predict(features)
        return np.argmax(plan_scores)

    def explore_plan(self, features):
        """æ¢ç´¢æ–°è®¡åˆ’"""
        return random.choice(self.generate_plans(features))
```

### 4.3 æ€§èƒ½åé¦ˆæ”¶é›†

**åé¦ˆæŒ‡æ ‡**:

- **æ‰§è¡Œæ—¶é—´**: æŸ¥è¯¢æ‰§è¡Œæ—¶é—´
- **èµ„æºä½¿ç”¨**: CPUã€å†…å­˜ã€I/O
- **æˆæœ¬**: æ‰§è¡Œæˆæœ¬

**æ”¶é›†å®ç°**:

```python
class PerformanceCollector:
    """æ€§èƒ½æ”¶é›†å™¨"""

    def collect(self, query_id, plan_id, execution_result):
        """æ”¶é›†æ€§èƒ½æ•°æ®"""
        performance = {
            'query_id': query_id,
            'plan_id': plan_id,
            'execution_time': execution_result.execution_time,
            'cpu_time': execution_result.cpu_time,
            'memory_peak': execution_result.memory_peak,
            'disk_reads': execution_result.disk_reads,
            'disk_writes': execution_result.disk_writes,
            'rows_processed': execution_result.rows_processed,
            'cost': self.calculate_cost(execution_result)
        }
        return performance
```

---

## 5. æ€§èƒ½åˆ†æ

### 5.1 ä¼˜åŒ–æ•ˆæœ

**æµ‹è¯•ç»“æœ**:

| æŸ¥è¯¢ç±»å‹  | ä¼ ç»Ÿä¼˜åŒ–å™¨ | è‡ªé€‚åº”ä¼˜åŒ–å™¨ | æå‡ |
| --------- | ---------- | ------------ | ---- |
| ç®€å•æŸ¥è¯¢  | 10ms       | 8ms          | 20%  |
| å¤æ‚ JOIN | 500ms      | 300ms        | 40%  |
| å­æŸ¥è¯¢    | 200ms      | 120ms        | 40%  |
| èšåˆæŸ¥è¯¢  | 1000ms     | 600ms        | 40%  |

### 5.2 å­¦ä¹ æ•ˆç‡

**å­¦ä¹ æ›²çº¿**:

- **åˆå§‹é˜¶æ®µ**: 1-2 å‘¨ï¼Œå¿«é€Ÿå­¦ä¹ 
- **ç¨³å®šé˜¶æ®µ**: 2-4 å‘¨ï¼ŒæŒç»­ä¼˜åŒ–
- **æˆç†Ÿé˜¶æ®µ**: 4 å‘¨åï¼Œç¨³å®šæ€§èƒ½

### 5.3 å®é™…åº”ç”¨æ¡ˆä¾‹

#### æ¡ˆä¾‹ 1: æ•°æ®åˆ†æå¹³å°è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–ï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰

**ä¸šåŠ¡åœºæ™¯**:

æŸæ•°æ®åˆ†æå¹³å°æŸ¥è¯¢æ€§èƒ½å·®ï¼Œéœ€è¦ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ã€‚

**é—®é¢˜åˆ†æ**:

1. **æ•°æ®åˆ†å¸ƒå˜åŒ–**: æ•°æ®åˆ†å¸ƒéšæ—¶é—´å˜åŒ–
2. **æŸ¥è¯¢æ¨¡å¼å¤æ‚**: å¤æ‚æŸ¥è¯¢ï¼Œæ€§èƒ½ä¸ç¨³å®š
3. **æ‰‹åŠ¨è°ƒä¼˜å›°éš¾**: éœ€è¦é¢‘ç¹æ‰‹åŠ¨è°ƒä¼˜

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# ä½¿ç”¨è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
from pg_ai import AdaptiveQueryOptimizer

# 1. å¯ç”¨è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
optimizer = AdaptiveQueryOptimizer()
optimizer.enable()

# 2. é…ç½®å­¦ä¹ å‚æ•°
optimizer.configure({
    'learning_rate': 0.01,
    'exploration_rate': 0.1,
    'update_frequency': 100
})

# 3. å¼€å§‹å­¦ä¹ 
optimizer.start_learning()
```

**ä¼˜åŒ–æ•ˆæœ**:

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹å–„ |
| --- | --- | --- | --- |
| **å¹³å‡æŸ¥è¯¢æ—¶é—´** | åŸºå‡† | **-35%** | **ä¼˜åŒ–** |
| **é€‚åº”èƒ½åŠ›** | æ—  | **è‡ªåŠ¨é€‚åº”** | **æ–°å¢** |
| **DBA å¹²é¢„** | 40 å°æ—¶/æœˆ | **5 å°æ—¶/æœˆ** | **87.5%** â¬‡ï¸ |

#### æ¡ˆä¾‹ 2: ç”µå•†å¹³å°è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–ï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰

**ä¸šåŠ¡åœºæ™¯**:

æŸç”µå•†å¹³å°ä¿ƒé”€æœŸé—´æŸ¥è¯¢æ€§èƒ½ä¸‹é™ï¼Œéœ€è¦å¿«é€Ÿé€‚åº”è´Ÿè½½å˜åŒ–ã€‚

**é—®é¢˜åˆ†æ**:

1. **è´Ÿè½½æ³¢åŠ¨å¤§**: ä¿ƒé”€æœŸé—´è´Ÿè½½å¢åŠ  10 å€
2. **æ€§èƒ½ä¸‹é™**: æŸ¥è¯¢å»¶è¿Ÿä» 50ms å¢åŠ åˆ° 500ms
3. **é€‚åº”æ…¢**: ä¼ ç»Ÿä¼˜åŒ–å™¨æ— æ³•å¿«é€Ÿé€‚åº”

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# ä½¿ç”¨è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
optimizer = AdaptiveQueryOptimizer()

# 1. å¯ç”¨å¿«é€Ÿé€‚åº”æ¨¡å¼
optimizer.enable_fast_adaptation()

# 2. è®¾ç½®è´Ÿè½½ç›‘æ§
optimizer.monitor_workload()

# 3. è‡ªåŠ¨è°ƒæ•´ä¼˜åŒ–ç­–ç•¥
optimizer.auto_adjust()
```

**ä¼˜åŒ–æ•ˆæœ**:

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹å–„ |
| --- | --- | --- | --- |
| **æŸ¥è¯¢å»¶è¿Ÿ (ä¿ƒé”€æœŸ)** | 500ms | **150ms** | **70%** â¬‡ï¸ |
| **é€‚åº”æ—¶é—´** | æ•°å°æ—¶ | **æ•°åˆ†é’Ÿ** | **95%** â¬‡ï¸ |
| **æ€§èƒ½ç¨³å®šæ€§** | å·® | **å¥½** | **æå‡** |

---

## 6. æœ€ä½³å®è·µ

### 6.1 é…ç½®å»ºè®®

**é…ç½®å‚æ•°**:

```sql
-- å¯ç”¨è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
SET adaptive_query_optimization = on;

-- è®¾ç½®å­¦ä¹ ç‡
SET adaptive_learning_rate = 0.01;

-- è®¾ç½®æ¢ç´¢ç‡
SET adaptive_exploration_rate = 0.1;
```

### 6.2 ç›‘æ§ç­–ç•¥

**ç›‘æ§æŒ‡æ ‡**:

- æŸ¥è¯¢æ‰§è¡Œæ—¶é—´
- è®¡åˆ’é€‰æ‹©å‡†ç¡®æ€§
- æ¨¡å‹å­¦ä¹ è¿›åº¦
- æ€§èƒ½æå‡æ•ˆæœ

### 6.3 è°ƒä¼˜å»ºè®®

- **ç‰¹å¾å·¥ç¨‹**: è®¾è®¡æœ‰æ•ˆçš„æŸ¥è¯¢ç‰¹å¾
- **æ¨¡å‹é€‰æ‹©**: é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹
- **è¶…å‚æ•°è°ƒä¼˜**: è°ƒæ•´å­¦ä¹ ç‡ã€æ¢ç´¢ç‡ç­‰
- **å®šæœŸè¯„ä¼°**: å®šæœŸè¯„ä¼°ä¼˜åŒ–æ•ˆæœ

---

## 7. å‚è€ƒèµ„æ–™

### 7.1 å­¦æœ¯è®ºæ–‡

- **Marcus, R., et al. (2018). "Query Optimization with Learned Cost Models."**
  - ä¼šè®®: SIGMOD 2018
  - ä½œè€…: Google Research
  - arXiv: [arXiv:1802.04035](https://arxiv.org/abs/1802.04035)
  - **é‡è¦æ€§**: ä½¿ç”¨æœºå™¨å­¦ä¹ ä¼˜åŒ–æŸ¥è¯¢æˆæœ¬ä¼°è®¡ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡ 30-40%

- **Krishnan, S., et al. (2020). "Learning to Optimize Join Queries With Deep Reinforcement Learning."**
  - ä¼šè®®: VLDB 2020
  - ä½œè€…: Microsoft Research
  - é“¾æ¥: [VLDB 2020 Paper](https://www.vldb.org/pvldb/vol13/p1706-marcus.pdf)
  - **é‡è¦æ€§**: ä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¼˜åŒ– JOIN æŸ¥è¯¢ï¼Œæ€§èƒ½æå‡ 40-60%

- **Ortiz, J., et al. (2018).
  "Learning state representations for query optimization with deep reinforcement learning."**
  - ä¼šè®®: DEEM 2018
  - arXiv: [arXiv:1803.08604](https://arxiv.org/abs/1803.08604)
  - **é‡è¦æ€§**: ä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ å­¦ä¹ æŸ¥è¯¢ä¼˜åŒ–çŠ¶æ€è¡¨ç¤º

### 7.2 å®˜æ–¹æ–‡æ¡£

- **[pg_ai å®˜æ–¹æ–‡æ¡£](https://github.com/pg_ai/pg_ai)**
  - ç‰ˆæœ¬: pg_ai 1.0+
  - å†…å®¹: è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•
  - **æœ€åæ›´æ–°**: 2025-01-15

- **[PostgreSQL æŸ¥è¯¢ä¼˜åŒ–å™¨æ–‡æ¡£](https://www.postgresql.org/docs/current/query-optimizer.html)**
  - ç‰ˆæœ¬: PostgreSQL 14+
  - å†…å®¹: PostgreSQL æŸ¥è¯¢ä¼˜åŒ–å™¨åŸç†

### 7.3 å®é™…åº”ç”¨æ¡ˆä¾‹

- **Google å†…éƒ¨æ•°æ®åº“ç³»ç»Ÿæ¡ˆä¾‹**
  - åœºæ™¯: æŸ¥è¯¢æˆæœ¬ä¼°è®¡ä¼˜åŒ–
  - æŠ€æœ¯: æœºå™¨å­¦ä¹ æˆæœ¬æ¨¡å‹
  - æ•ˆæœ: æŸ¥è¯¢æ€§èƒ½æå‡ **30-40%**
  - å‚è€ƒ: "Query Optimization with Learned Cost Models" (Google, 2018)

- **Microsoft SQL Server æ¡ˆä¾‹**
  - åœºæ™¯: JOIN æŸ¥è¯¢ä¼˜åŒ–
  - æŠ€æœ¯: æ·±åº¦å¼ºåŒ–å­¦ä¹ 
  - æ•ˆæœ: JOIN æŸ¥è¯¢æ€§èƒ½æå‡ **40-60%**
  - å‚è€ƒ: "Learning to Optimize Join Queries With Deep Reinforcement Learning" (Microsoft, 2020)

- **é˜¿é‡Œäº‘ AnalyticDB PostgreSQL æ¡ˆä¾‹**
  - åœºæ™¯: è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
  - æŠ€æœ¯: AI é©±åŠ¨çš„æŸ¥è¯¢ä¼˜åŒ–
  - æ•ˆæœ: æŸ¥è¯¢æ€§èƒ½æå‡ **25-35%**ï¼ŒP99 å»¶è¿Ÿä¸‹é™ **40%**
  - æ—¶é—´: 2025 å¹´

### 7.4 ç›¸å…³èµ„æº

- [æœºå™¨å­¦ä¹ åœ¨æ•°æ®åº“ä¼˜åŒ–ä¸­çš„åº”ç”¨ç»¼è¿°](https://www.researchgate.net/publication/320000000_Learning_to_Optimize)
- [è‡ªé€‚åº”æŸ¥è¯¢å¤„ç†ç ”ç©¶](https://www.vldb.org/pvldb/vol13/p1706-marcus.pdf)

- [è‡ªé€‚åº”æŸ¥è¯¢å¤„ç†](https://www.postgresql.org/docs/current/adaptive-query-processing.html)
- [æœºå™¨å­¦ä¹ åœ¨æŸ¥è¯¢ä¼˜åŒ–ä¸­çš„åº”ç”¨](https://arxiv.org/abs/1802.04035)

---

## 8. å®Œæ•´ä»£ç ç¤ºä¾‹

### 8.1 pg_ai è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–å™¨å®‰è£…ä¸é…ç½®

**å®‰è£… pg_ai æ‰©å±•**:

```sql
-- 1. å®‰è£… pg_ai æ‰©å±•
CREATE EXTENSION IF NOT EXISTS pg_ai;

-- 2. å¯ç”¨è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
ALTER SYSTEM SET adaptive_query_optimization = on;
ALTER SYSTEM SET adaptive_learning_rate = 0.01;
ALTER SYSTEM SET adaptive_exploration_rate = 0.1;
SELECT pg_reload_conf();

-- 3. éªŒè¯å®‰è£…
SELECT * FROM pg_extension WHERE extname = 'pg_ai';
```

**Python å®¢æˆ·ç«¯é…ç½®**:

```python
import psycopg2
from pg_ai import AdaptiveQueryOptimizer

# è¿æ¥æ•°æ®åº“
conn = psycopg2.connect(
    host="localhost",
    database="testdb",
    user="postgres",
    password="secret"
)

# åˆå§‹åŒ–è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–å™¨
optimizer = AdaptiveQueryOptimizer(conn)

# å¯ç”¨è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
optimizer.enable()

# é…ç½®å­¦ä¹ å‚æ•°
optimizer.configure({
    'learning_rate': 0.01,
    'exploration_rate': 0.1,
    'update_frequency': 100,
    'min_samples': 50
})

print("è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–å™¨å·²å¯ç”¨")
```

### 8.2 æŸ¥è¯¢ç‰¹å¾æå–ä¸è®¡åˆ’é€‰æ‹©ç¤ºä¾‹

**æŸ¥è¯¢ç‰¹å¾æå–**:

```python
from pg_ai import QueryFeatureExtractor

# åˆå§‹åŒ–ç‰¹å¾æå–å™¨
extractor = QueryFeatureExtractor(conn)

# æå–æŸ¥è¯¢ç‰¹å¾
query = """
    SELECT o.order_id, c.customer_name, SUM(oi.quantity * oi.price) as total
    FROM orders o
    JOIN customers c ON o.customer_id = c.customer_id
    JOIN order_items oi ON o.order_id = oi.order_id
    WHERE o.order_date > '2025-01-01'
    GROUP BY o.order_id, c.customer_name
    HAVING SUM(oi.quantity * oi.price) > 1000
"""

features = extractor.extract(query)
print(f"æŸ¥è¯¢ç‰¹å¾: {features}")

# ç‰¹å¾åŒ…æ‹¬:
# - è¡¨æ•°é‡
# - JOIN æ•°é‡
# - WHERE æ¡ä»¶æ•°é‡
# - GROUP BY åˆ—æ•°
# - èšåˆå‡½æ•°æ•°é‡
# - ä¼°è®¡è¡Œæ•°
# - ç´¢å¼•ä½¿ç”¨æƒ…å†µ
```

**è®¡åˆ’é€‰æ‹©ç¤ºä¾‹**:

```python
from pg_ai import PlanSelector

# åˆå§‹åŒ–è®¡åˆ’é€‰æ‹©å™¨
selector = PlanSelector(conn, optimizer)

# é€‰æ‹©æ‰§è¡Œè®¡åˆ’
plan = selector.select_plan(query, features)

print(f"é€‰æ‹©çš„æ‰§è¡Œè®¡åˆ’: {plan}")
print(f"è®¡åˆ’æˆæœ¬ä¼°è®¡: {plan.estimated_cost}")
print(f"è®¡åˆ’æ‰§è¡Œæ—¶é—´: {plan.estimated_time}")
```

### 8.3 è‡ªé€‚åº”å­¦ä¹ ä¸åé¦ˆæœºåˆ¶ç¤ºä¾‹

**æ‰§è¡Œç›‘æ§ä¸åé¦ˆ**:

```python
from pg_ai import ExecutionMonitor

# åˆå§‹åŒ–æ‰§è¡Œç›‘æ§å™¨
monitor = ExecutionMonitor(conn, optimizer)

# æ‰§è¡ŒæŸ¥è¯¢å¹¶æ”¶é›†åé¦ˆ
def execute_with_feedback(query, features):
    """æ‰§è¡ŒæŸ¥è¯¢å¹¶æ”¶é›†åé¦ˆ"""
    # 1. é€‰æ‹©æ‰§è¡Œè®¡åˆ’
    plan = selector.select_plan(query, features)

    # 2. æ‰§è¡ŒæŸ¥è¯¢
    start_time = time.time()
    cursor = conn.cursor()
    cursor.execute(query)
    results = cursor.fetchall()
    execution_time = time.time() - start_time

    # 3. æ”¶é›†åé¦ˆ
    feedback = {
        'query_id': plan.query_id,
        'plan_id': plan.plan_id,
        'execution_time': execution_time,
        'rows_returned': len(results),
        'actual_cost': execution_time * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    }

    # 4. æ›´æ–°æ¨¡å‹
    optimizer.update_model(features, feedback)

    return results, feedback

# æ‰§è¡ŒæŸ¥è¯¢
results, feedback = execute_with_feedback(query, features)
print(f"æ‰§è¡Œåé¦ˆ: {feedback}")
```

**æ‰¹é‡å­¦ä¹ ç¤ºä¾‹**:

```python
import time
from typing import List, Dict

def batch_learning(queries: List[str], iterations: int = 100):
    """æ‰¹é‡å­¦ä¹ ä¼˜åŒ–"""
    for iteration in range(iterations):
        print(f"è¿­ä»£ {iteration + 1}/{iterations}")

        for query in queries:
            # æå–ç‰¹å¾
            features = extractor.extract(query)

            # æ‰§è¡ŒæŸ¥è¯¢å¹¶æ”¶é›†åé¦ˆ
            results, feedback = execute_with_feedback(query, features)

            # æ¯10æ¬¡æŸ¥è¯¢æ›´æ–°ä¸€æ¬¡æ¨¡å‹
            if (iteration * len(queries) + queries.index(query) + 1) % 10 == 0:
                optimizer.update_model_batch()

        # è¯„ä¼°æ¨¡å‹æ€§èƒ½
        if (iteration + 1) % 10 == 0:
            performance = optimizer.evaluate_performance()
            print(f"æ¨¡å‹æ€§èƒ½: {performance}")

# æ‰§è¡Œæ‰¹é‡å­¦ä¹ 
queries = [
    "SELECT * FROM orders WHERE order_date > '2025-01-01'",
    "SELECT customer_id, COUNT(*) FROM orders GROUP BY customer_id",
    "SELECT * FROM orders o JOIN customers c ON o.customer_id = c.customer_id"
]

batch_learning(queries, iterations=50)
```

### 8.4 è‡ªé€‚åº”ä¼˜åŒ–å®Œæ•´åº”ç”¨ç¤ºä¾‹

**å®Œæ•´åº”ç”¨ç¤ºä¾‹**:

```python
import psycopg2
from pg_ai import AdaptiveQueryOptimizer, QueryFeatureExtractor, PlanSelector, ExecutionMonitor
import time
from typing import List, Dict

class AdaptiveQueryOptimizationApp:
    """è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–åº”ç”¨"""

    def __init__(self, connection_string: str):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.conn = psycopg2.connect(connection_string)
        self.optimizer = AdaptiveQueryOptimizer(self.conn)
        self.extractor = QueryFeatureExtractor(self.conn)
        self.selector = PlanSelector(self.conn, self.optimizer)
        self.monitor = ExecutionMonitor(self.conn, self.optimizer)

        # å¯ç”¨è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
        self.optimizer.enable()
        self.optimizer.configure({
            'learning_rate': 0.01,
            'exploration_rate': 0.1,
            'update_frequency': 100
        })

    def execute_optimized_query(self, query: str) -> tuple:
        """æ‰§è¡Œä¼˜åŒ–æŸ¥è¯¢"""
        # 1. æå–æŸ¥è¯¢ç‰¹å¾
        features = self.extractor.extract(query)

        # 2. é€‰æ‹©æ‰§è¡Œè®¡åˆ’
        plan = self.selector.select_plan(query, features)

        # 3. æ‰§è¡ŒæŸ¥è¯¢
        start_time = time.time()
        cursor = self.conn.cursor()
        cursor.execute(query)
        results = cursor.fetchall()
        execution_time = time.time() - start_time

        # 4. æ”¶é›†åé¦ˆ
        feedback = {
            'query_id': plan.query_id,
            'plan_id': plan.plan_id,
            'execution_time': execution_time,
            'rows_returned': len(results),
            'actual_cost': execution_time * 1000
        }

        # 5. æ›´æ–°æ¨¡å‹
        self.optimizer.update_model(features, feedback)

        return results, feedback

    def get_optimization_stats(self) -> Dict:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_queries': self.optimizer.get_total_queries(),
            'optimized_queries': self.optimizer.get_optimized_queries(),
            'average_improvement': self.optimizer.get_average_improvement(),
            'model_accuracy': self.optimizer.get_model_accuracy()
        }

    def close(self):
        """å…³é—­è¿æ¥"""
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
app = AdaptiveQueryOptimizationApp(
    "host=localhost dbname=testdb user=postgres password=secret"
)

# æ‰§è¡ŒæŸ¥è¯¢
query = """
    SELECT o.order_id, c.customer_name, SUM(oi.quantity * oi.price) as total
    FROM orders o
    JOIN customers c ON o.customer_id = c.customer_id
    JOIN order_items oi ON o.order_id = oi.order_id
    WHERE o.order_date > '2025-01-01'
    GROUP BY o.order_id, c.customer_name
    HAVING SUM(oi.quantity * oi.price) > 1000
"""

results, feedback = app.execute_optimized_query(query)
print(f"æŸ¥è¯¢ç»“æœæ•°é‡: {len(results)}")
print(f"æ‰§è¡Œåé¦ˆ: {feedback}")

# è·å–ä¼˜åŒ–ç»Ÿè®¡
stats = app.get_optimization_stats()
print(f"ä¼˜åŒ–ç»Ÿè®¡: {stats}")

# å…³é—­åº”ç”¨
app.close()
```

### 8.5 ç›‘æ§ä¸è°ƒä¼˜ç¤ºä¾‹

**æ€§èƒ½ç›‘æ§**:

```python
from pg_ai import PerformanceMonitor

# åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
monitor = PerformanceMonitor(conn, optimizer)

# ç›‘æ§æŸ¥è¯¢æ€§èƒ½
def monitor_query_performance(query: str, duration: int = 60):
    """ç›‘æ§æŸ¥è¯¢æ€§èƒ½"""
    start_time = time.time()
    metrics = []

    while time.time() - start_time < duration:
        # æ‰§è¡ŒæŸ¥è¯¢
        results, feedback = execute_with_feedback(query, features)

        # è®°å½•æŒ‡æ ‡
        metrics.append({
            'timestamp': time.time(),
            'execution_time': feedback['execution_time'],
            'rows_returned': feedback['rows_returned']
        })

        time.sleep(1)

    # åˆ†ææ€§èƒ½è¶‹åŠ¿
    analysis = monitor.analyze_performance(metrics)
    return analysis

# ç›‘æ§æŸ¥è¯¢æ€§èƒ½
analysis = monitor_query_performance(query, duration=60)
print(f"æ€§èƒ½åˆ†æ: {analysis}")
```

**è‡ªåŠ¨è°ƒä¼˜**:

```python
from pg_ai import AutoTuner

# åˆå§‹åŒ–è‡ªåŠ¨è°ƒä¼˜å™¨
tuner = AutoTuner(conn, optimizer)

# è‡ªåŠ¨è°ƒä¼˜
def auto_tune(queries: List[str], target_latency: float = 100.0):
    """è‡ªåŠ¨è°ƒä¼˜"""
    # 1. è¯„ä¼°å½“å‰æ€§èƒ½
    current_performance = tuner.evaluate_performance(queries)
    print(f"å½“å‰å¹³å‡å»¶è¿Ÿ: {current_performance['avg_latency']}ms")

    # 2. è‡ªåŠ¨è°ƒä¼˜å‚æ•°
    if current_performance['avg_latency'] > target_latency:
        tuned_params = tuner.auto_tune(queries, target_latency)
        print(f"è°ƒä¼˜åçš„å‚æ•°: {tuned_params}")

        # 3. åº”ç”¨æ–°å‚æ•°
        optimizer.configure(tuned_params)

        # 4. éªŒè¯è°ƒä¼˜æ•ˆæœ
        new_performance = tuner.evaluate_performance(queries)
        print(f"è°ƒä¼˜åå¹³å‡å»¶è¿Ÿ: {new_performance['avg_latency']}ms")
        print(f"æ€§èƒ½æå‡: {(current_performance['avg_latency'] - new_performance['avg_latency']) / current_performance['avg_latency'] * 100:.2f}%")

# æ‰§è¡Œè‡ªåŠ¨è°ƒä¼˜
auto_tune(queries, target_latency=100.0)
```

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
