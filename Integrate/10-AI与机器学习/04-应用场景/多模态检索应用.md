---
> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL_AI\04-åº”ç”¨åœºæ™¯\å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨

> **æ–‡æ¡£ç¼–å·**: AI-04-06
> **æœ€åæ›´æ–°**: 2025å¹´1æœˆ
> **ä¸»é¢˜**: 04-åº”ç”¨åœºæ™¯
> **å­ä¸»é¢˜**: 06-å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨

## ğŸ“‘ ç›®å½•

- [å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨](#å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨)

---

## 1. å¤šæ¨¡æ€æ£€ç´¢æ¦‚è¿°

### 1.1 å¤šæ¨¡æ€æ£€ç´¢æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((å¤šæ¨¡æ€æ£€ç´¢))
    æ•°æ®ç±»å‹
      æ–‡æœ¬
        æ–‡æ¡£
        æè¿°
        æ ‡ç­¾
      å›¾åƒ
        ç…§ç‰‡
        å›¾è¡¨
        æˆªå›¾
      éŸ³é¢‘
        è¯­éŸ³
        éŸ³ä¹
        éŸ³æ•ˆ
      è§†é¢‘
        è§†é¢‘ç‰‡æ®µ
        è§†é¢‘å¸§
    æ£€ç´¢æ–¹å¼
      å•æ¨¡æ€æ£€ç´¢
        æ–‡æœ¬æ£€ç´¢
        å›¾åƒæ£€ç´¢
        éŸ³é¢‘æ£€ç´¢
      è·¨æ¨¡æ€æ£€ç´¢
        ä»¥å›¾æœæ–‡
        ä»¥æ–‡æœå›¾
        å›¾æ–‡æ··åˆ
      å¤šæ¨¡æ€èåˆ
        åŠ æƒèåˆ
        å­¦ä¹ èåˆ
```

### 1.2 åº”ç”¨åœºæ™¯

**å¤šæ¨¡æ€æ£€ç´¢åº”ç”¨åœºæ™¯**ï¼š

- âœ… **ç”µå•†æœç´¢**ï¼šä»¥å›¾æœå•†å“ã€ä»¥æ–‡æœå›¾
- âœ… **å†…å®¹æ¨è**ï¼šå›¾æ–‡æ··åˆæ¨è
- âœ… **çŸ¥è¯†åº“æ£€ç´¢**ï¼šæ–‡æ¡£+å›¾åƒæ£€ç´¢
- âœ… **åª’ä½“åº“ç®¡ç†**ï¼šç»Ÿä¸€æ£€ç´¢æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘

---

## 2. ç³»ç»Ÿæ¶æ„

### 2.1 ç³»ç»Ÿæ¶æ„

**å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿæ¶æ„**ï¼š

```mermaid
graph TB
    subgraph "æ•°æ®å±‚"
        Text[æ–‡æœ¬æ•°æ®]
        Image[å›¾åƒæ•°æ®]
        Audio[éŸ³é¢‘æ•°æ®]
    end

    subgraph "å‘é‡åŒ–å±‚"
        TextVec[æ–‡æœ¬å‘é‡åŒ–<br/>pg_ai]
        ImageVec[å›¾åƒå‘é‡åŒ–<br/>CLIP]
        AudioVec[éŸ³é¢‘å‘é‡åŒ–<br/>AudioCLIP]
    end

    subgraph "PostgreSQLå­˜å‚¨"
        PG[(PostgreSQL)]
        TextTable[æ–‡æœ¬å‘é‡è¡¨]
        ImageTable[å›¾åƒå‘é‡è¡¨]
        AudioTable[éŸ³é¢‘å‘é‡è¡¨]
    end

    subgraph "æ£€ç´¢å±‚"
        Search[ç»Ÿä¸€æ£€ç´¢æ¥å£]
        Fusion[å¤šæ¨¡æ€èåˆ]
    end

    Text --> TextVec
    Image --> ImageVec
    Audio --> AudioVec
    TextVec --> TextTable
    ImageVec --> ImageTable
    AudioVec --> AudioTable
    TextTable --> Search
    ImageTable --> Search
    AudioTable --> Search
    Search --> Fusion

    style PG fill:#4a90e2,color:#fff
    style Fusion fill:#50c878,color:#fff
```

### 2.2 æ•°æ®æµ

**å¤šæ¨¡æ€æ£€ç´¢æ•°æ®æµ**ï¼š

```text
1. å¤šæ¨¡æ€æ•°æ®è¾“å…¥ï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ï¼‰
2. åˆ†åˆ«å‘é‡åŒ–ï¼ˆä½¿ç”¨ä¸åŒæ¨¡å‹ï¼‰
3. å­˜å‚¨åˆ°PostgreSQLï¼ˆä¸åŒå‘é‡è¡¨ï¼‰
4. ç”¨æˆ·æŸ¥è¯¢ï¼ˆæ–‡æœ¬/å›¾åƒ/éŸ³é¢‘ï¼‰
5. æŸ¥è¯¢å‘é‡åŒ–
6. è·¨æ¨¡æ€æ£€ç´¢
7. å¤šæ¨¡æ€èåˆæ’åº
8. è¿”å›ç»“æœ
```

---

## 3. æ•°æ®åº“è®¾è®¡

### 3.1 å¤šæ¨¡æ€æ•°æ®è¡¨

**å¤šæ¨¡æ€æ•°æ®è¡¨ç»“æ„**ï¼š

```sql
-- 1. å¤šæ¨¡æ€å†…å®¹ä¸»è¡¨
CREATE TABLE multimodal_content (
    id SERIAL PRIMARY KEY,
    content_type TEXT NOT NULL,  -- text, image, audio, video
    title TEXT,
    description TEXT,
    file_path TEXT,
    file_url TEXT,
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 2. æ–‡æœ¬å‘é‡è¡¨
CREATE TABLE text_vectors (
    id SERIAL PRIMARY KEY,
    content_id INT REFERENCES multimodal_content(id),
    text_content TEXT NOT NULL,
    text_vec vector(1536),  -- OpenAI text embedding
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 3. å›¾åƒå‘é‡è¡¨
CREATE TABLE image_vectors (
    id SERIAL PRIMARY KEY,
    content_id INT REFERENCES multimodal_content(id),
    image_path TEXT,
    image_url TEXT,
    image_vec vector(512),  -- CLIP image embedding
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 4. éŸ³é¢‘å‘é‡è¡¨
CREATE TABLE audio_vectors (
    id SERIAL PRIMARY KEY,
    content_id INT REFERENCES multimodal_content(id),
    audio_path TEXT,
    audio_url TEXT,
    audio_vec vector(512),  -- AudioCLIP embedding
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 5. åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX ON text_vectors USING hnsw(text_vec vector_cosine_ops);
CREATE INDEX ON image_vectors USING hnsw(image_vec vector_cosine_ops);
CREATE INDEX ON audio_vectors USING hnsw(audio_vec vector_cosine_ops);
```

### 3.2 æ–‡æœ¬å‘é‡è¡¨

**æ–‡æœ¬å‘é‡ç”Ÿæˆ**ï¼š

```sql
-- ä½¿ç”¨pg_aiè‡ªåŠ¨ç”Ÿæˆæ–‡æœ¬å‘é‡
UPDATE text_vectors
SET text_vec = ai.embedding_openai(
    'text-embedding-3-small',
    text_content
)
WHERE text_vec IS NULL;
```

### 3.3 å›¾åƒå‘é‡è¡¨

**å›¾åƒå‘é‡ç”Ÿæˆ**ï¼š

```sql
-- ä½¿ç”¨pg_aiç”Ÿæˆå›¾åƒå‘é‡ï¼ˆCLIPæ¨¡å‹ï¼‰
UPDATE image_vectors
SET image_vec = ai.embedding_image(
    'clip-vit-base-patch32',
    image_data  -- å›¾åƒäºŒè¿›åˆ¶æ•°æ®
)
WHERE image_vec IS NULL;
```

---

## 4. å¤šæ¨¡æ€æ£€ç´¢å®ç°

### 4.1 æ–‡æœ¬+å›¾åƒæ£€ç´¢

**æ–‡æœ¬+å›¾åƒæ··åˆæ£€ç´¢**ï¼š

```sql
-- 1. æ–‡æœ¬æŸ¥è¯¢æ£€ç´¢å›¾åƒ
WITH text_query AS (
    SELECT ai.embedding_openai('text-embedding-3-small', 'sunset beach') AS vec
),
image_results AS (
    SELECT
        iv.content_id,
        mc.title,
        mc.file_url,
        1 - (iv.image_vec <=> tq.vec) AS similarity
    FROM image_vectors iv
    JOIN multimodal_content mc ON mc.id = iv.content_id,
         text_query tq
    WHERE 1 - (iv.image_vec <=> tq.vec) > 0.7
    ORDER BY iv.image_vec <=> tq.vec
    LIMIT 10
)
SELECT * FROM image_results;

-- æ€§èƒ½æµ‹è¯•ï¼šæ–‡æœ¬æŸ¥è¯¢æ£€ç´¢å›¾åƒ
EXPLAIN (ANALYZE, BUFFERS, TIMING)
WITH text_query AS (
    SELECT ai.embedding_openai('text-embedding-3-small', 'sunset beach') AS vec
),
image_results AS (
    SELECT
        iv.content_id,
        mc.title,
        mc.file_url,
        1 - (iv.image_vec <=> tq.vec) AS similarity
    FROM image_vectors iv
    JOIN multimodal_content mc ON mc.id = iv.content_id,
         text_query tq
    WHERE 1 - (iv.image_vec <=> tq.vec) > 0.7
    ORDER BY iv.image_vec <=> tq.vec
    LIMIT 10
)
SELECT * FROM image_results;

-- 2. å›¾åƒæŸ¥è¯¢æ£€ç´¢æ–‡æœ¬
WITH image_query AS (
    SELECT ai.embedding_image('clip-vit-base-patch32', $1) AS vec
),
text_results AS (
    SELECT
        tv.content_id,
        mc.title,
        tv.text_content,
        1 - (tv.text_vec <=> iq.vec) AS similarity
    FROM text_vectors tv
    JOIN multimodal_content mc ON mc.id = tv.content_id,
         image_query iq
    WHERE 1 - (tv.text_vec <=> iq.vec) > 0.7
    ORDER BY tv.text_vec <=> iq.vec
    LIMIT 10
)
SELECT * FROM text_results;

-- æ€§èƒ½æµ‹è¯•ï¼šå›¾åƒæŸ¥è¯¢æ£€ç´¢æ–‡æœ¬
EXPLAIN (ANALYZE, BUFFERS, TIMING)
WITH image_query AS (
    SELECT ai.embedding_image('clip-vit-base-patch32', $1) AS vec
),
text_results AS (
    SELECT
        tv.content_id,
        mc.title,
        tv.text_content,
        1 - (tv.text_vec <=> iq.vec) AS similarity
    FROM text_vectors tv
    JOIN multimodal_content mc ON mc.id = tv.content_id,
         image_query iq
    WHERE 1 - (tv.text_vec <=> iq.vec) > 0.7
    ORDER BY tv.text_vec <=> iq.vec
    LIMIT 10
)
SELECT * FROM text_results;
```

### 4.2 è·¨æ¨¡æ€ç›¸ä¼¼åº¦

**è·¨æ¨¡æ€ç›¸ä¼¼åº¦è®¡ç®—**ï¼š

```sql
-- æ–‡æœ¬å’Œå›¾åƒè·¨æ¨¡æ€ç›¸ä¼¼åº¦
WITH text_query AS (
    SELECT ai.embedding_openai('text-embedding-3-small', 'mountain landscape') AS vec
),
image_results AS (
    SELECT
        iv.content_id,
        mc.title,
        mc.file_url,
        -- è·¨æ¨¡æ€ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨CLIPç»Ÿä¸€ç©ºé—´ï¼‰
        1 - (iv.image_vec <=> tq.vec) AS cross_modal_similarity
    FROM image_vectors iv
    JOIN multimodal_content mc ON mc.id = iv.content_id,
         text_query tq
    WHERE 1 - (iv.image_vec <=> tq.vec) > 0.7
    ORDER BY iv.image_vec <=> tq.vec
    LIMIT 10
)
SELECT * FROM image_results;
```

### 4.3 ç»Ÿä¸€æŸ¥è¯¢æ¥å£

**ç»Ÿä¸€æŸ¥è¯¢æ¥å£**ï¼š

```sql
CREATE OR REPLACE FUNCTION multimodal_search(
    p_query_type TEXT,  -- 'text', 'image', 'audio'
    p_query_content TEXT,  -- æŸ¥è¯¢å†…å®¹æˆ–è·¯å¾„
    p_result_type TEXT DEFAULT 'all'  -- 'text', 'image', 'audio', 'all'
)
RETURNS TABLE(
    content_id INT,
    content_type TEXT,
    title TEXT,
    similarity DECIMAL,
    file_url TEXT
) AS $$
DECLARE
    v_query_vec vector;
BEGIN
    -- 1. æ ¹æ®æŸ¥è¯¢ç±»å‹å‘é‡åŒ–
    IF p_query_type = 'text' THEN
        SELECT ai.embedding_openai('text-embedding-3-small', p_query_content)
        INTO v_query_vec;
    ELSIF p_query_type = 'image' THEN
        SELECT ai.embedding_image('clip-vit-base-patch32', p_query_content)
        INTO v_query_vec;
    END IF;

    -- 2. è·¨æ¨¡æ€æ£€ç´¢
    IF p_result_type = 'all' OR p_result_type = 'text' THEN
        RETURN QUERY
        SELECT
            tv.content_id,
            'text'::TEXT,
            mc.title,
            1 - (tv.text_vec <=> v_query_vec) AS similarity,
            mc.file_url
        FROM text_vectors tv
        JOIN multimodal_content mc ON mc.id = tv.content_id
        WHERE 1 - (tv.text_vec <=> v_query_vec) > 0.7
        ORDER BY tv.text_vec <=> v_query_vec
        LIMIT 10;
    END IF;

    IF p_result_type = 'all' OR p_result_type = 'image' THEN
        RETURN QUERY
        SELECT
            iv.content_id,
            'image'::TEXT,
            mc.title,
            1 - (iv.image_vec <=> v_query_vec) AS similarity,
            mc.file_url
        FROM image_vectors iv
        JOIN multimodal_content mc ON mc.id = iv.content_id
        WHERE 1 - (iv.image_vec <=> v_query_vec) > 0.7
        ORDER BY iv.image_vec <=> v_query_vec
        LIMIT 10;
    END IF;
END;
$$ LANGUAGE plpgsql;
```

### 4.4 å¤šæ¨¡æ€èåˆ

**å¤šæ¨¡æ€èåˆæ£€ç´¢**ï¼š

```sql
-- æ–‡æœ¬+å›¾åƒå¤šæ¨¡æ€èåˆæ£€ç´¢
WITH text_query AS (
    SELECT ai.embedding_openai('text-embedding-3-small', 'sunset beach') AS text_vec
),
image_query AS (
    SELECT ai.embedding_image('clip-vit-base-patch32', image_data) AS image_vec
),
text_results AS (
    SELECT
        tv.content_id,
        mc.title,
        mc.file_url,
        1 - (tv.text_vec <=> tq.text_vec) AS text_score
    FROM text_vectors tv
    JOIN multimodal_content mc ON mc.id = tv.content_id,
         text_query tq
    WHERE 1 - (tv.text_vec <=> tq.text_vec) > 0.7
),
image_results AS (
    SELECT
        iv.content_id,
        mc.title,
        mc.file_url,
        1 - (iv.image_vec <=> iq.image_vec) AS image_score
    FROM image_vectors iv
    JOIN multimodal_content mc ON mc.id = iv.content_id,
         image_query iq
    WHERE 1 - (iv.image_vec <=> iq.image_vec) > 0.7
)
SELECT
    COALESCE(tr.content_id, ir.content_id) AS content_id,
    COALESCE(tr.title, ir.title) AS title,
    COALESCE(tr.file_url, ir.file_url) AS file_url,
    COALESCE(tr.text_score, 0) * 0.5 + COALESCE(ir.image_score, 0) * 0.5 AS fusion_score
FROM text_results tr
FULL OUTER JOIN image_results ir ON tr.content_id = ir.content_id
ORDER BY fusion_score DESC
LIMIT 20;
```

---

## 5. æ€§èƒ½ä¼˜åŒ–

### 5.1 å‘é‡ç´¢å¼•ä¼˜åŒ–

**å¤šæ¨¡æ€å‘é‡ç´¢å¼•ä¼˜åŒ–**ï¼š

```sql
-- 1. æ–‡æœ¬å‘é‡ç´¢å¼•
CREATE INDEX ON text_vectors
USING hnsw(text_vec vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 2. å›¾åƒå‘é‡ç´¢å¼•
CREATE INDEX ON image_vectors
USING hnsw(image_vec vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 3. æŸ¥è¯¢æ—¶ä¼˜åŒ–
SET hnsw.ef_search = 100;  -- æå‡å¬å›ç‡
```

### 5.2 æŸ¥è¯¢ä¼˜åŒ–

**æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥**ï¼š

```sql
-- 1. ä½¿ç”¨LIMITæå‰ç»ˆæ­¢
SELECT ... LIMIT 10;

-- 2. è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
WHERE similarity > 0.7;

-- 3. ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—
CREATE MATERIALIZED VIEW popular_multimodal_content AS
SELECT
    mc.id,
    mc.title,
    mc.content_type,
    tv.text_vec,
    iv.image_vec
FROM multimodal_content mc
LEFT JOIN text_vectors tv ON tv.content_id = mc.id
LEFT JOIN image_vectors iv ON iv.content_id = mc.id
WHERE mc.view_count > 1000;

CREATE INDEX ON popular_multimodal_content
USING hnsw(text_vec vector_cosine_ops);
CREATE INDEX ON popular_multimodal_content
USING hnsw(image_vec vector_cosine_ops);
```

### 5.3 ç¼“å­˜ç­–ç•¥

**å¤šæ¨¡æ€æ£€ç´¢ç¼“å­˜**ï¼š

```sql
-- 1. æŸ¥è¯¢ç»“æœç¼“å­˜
CREATE TABLE multimodal_search_cache (
    query_hash TEXT PRIMARY KEY,
    query_type TEXT,
    results JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    expires_at TIMESTAMPTZ
);

-- 2. å‘é‡ç¼“å­˜ï¼ˆå¸¸ç”¨æŸ¥è¯¢å‘é‡ï¼‰
CREATE TABLE query_vector_cache (
    query_text TEXT PRIMARY KEY,
    query_vec vector(1536),
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

---

**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: AI-04-06
