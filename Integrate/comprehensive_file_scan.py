#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""å…¨é¢æ‰«æIntegrateç›®å½•ä¸‹éœ€è¦è¡¥å……å†…å®¹çš„æ–‡ä»¶"""

import os
import re
from collections import defaultdict

def scan_all_files():
    """æ‰«ææ‰€æœ‰éœ€è¦è¡¥å……çš„æ–‡ä»¶"""
    files_by_category = defaultdict(list)
    all_short_files = []

    # æ’é™¤çš„ç›®å½•
    excluded_dirs = [
        'node_modules', '.git', 'å½’æ¡£', '00-å½’æ¡£',
        '__pycache__', '.pytest_cache', 'venv', 'env'
    ]

    # æ’é™¤çš„æ–‡ä»¶
    excluded_files = [
        'README.md', 'CONTENT_ENHANCEMENT_TASKS.md',
        'PROGRESS_REPORT.md', 'scan_short_files.py',
        'comprehensive_file_scan.py', 'check_file_status.py',
        'comprehensive_scan_all.py', 'scan_empty_content.py',
        'fix_all_nested_toc_comprehensive.py', 'fix_unclosed_code_blocks.py'
    ]

    # å·²å®Œæˆçš„ç›®å½•ï¼ˆå¯ä»¥è·³è¿‡æˆ–é™ä½ä¼˜å…ˆçº§ï¼‰
    completed_dirs = [
        '10-AIä¸æœºå™¨å­¦ä¹ /03-æ ¸å¿ƒèƒ½åŠ›',
        '10-AIä¸æœºå™¨å­¦ä¹ /04-åº”ç”¨åœºæ™¯',
        '10-AIä¸æœºå™¨å­¦ä¹ /05-å®è·µæ¡ˆä¾‹',
        '10-AIä¸æœºå™¨å­¦ä¹ /06-å¯¹æ¯”åˆ†æ',
        '10-AIä¸æœºå™¨å­¦ä¹ /07-å®æ–½è·¯å¾„',
        '10-AIä¸æœºå™¨å­¦ä¹ /08-æœªæ¥è¶‹åŠ¿',
        '20-æ•…éšœè¯Šæ–­æ¡ˆä¾‹',
        '19-å®æˆ˜æ¡ˆä¾‹',
        '16-åº”ç”¨è®¾è®¡ä¸å¼€å‘/æµ‹è¯•ä¸è´¨é‡ä¿è¯',
    ]

    for root, dirs, files in os.walk('.'):
        # è·³è¿‡æ’é™¤çš„ç›®å½•
        if any(excluded in root for excluded in excluded_dirs):
            continue

        # æ£€æŸ¥æ˜¯å¦åœ¨å·²å®Œæˆçš„ç›®å½•ä¸­
        is_completed = any(completed in root for completed in completed_dirs)

        for f in files:
            if not f.endswith('.md'):
                continue

            if f in excluded_files:
                continue

            filepath = os.path.join(root, f)
            rel_path = filepath.replace(os.sep, '/').replace('./', '')

            try:
                with open(filepath, 'r', encoding='utf-8') as file:
                    content = file.read()
                    lines = len(content.split('\n'))
                    h3_count = len(re.findall(r'^###\s+', content, re.MULTILINE))

                    # åˆ¤æ–­æ˜¯å¦éœ€è¦è¡¥å……
                    needs_enhancement = False
                    priority = 'P1'

                    if lines < 200:
                        needs_enhancement = True
                        priority = 'P0' if not is_completed else 'P1'
                    elif lines < 300 and h3_count < 8:
                        needs_enhancement = True
                        priority = 'P1' if not is_completed else 'P2'
                    elif lines < 400 and h3_count < 10:
                        needs_enhancement = True
                        priority = 'P2'

                    if needs_enhancement:
                        # æå–ç›®å½•åˆ†ç±»
                        parts = rel_path.split('/')
                        if len(parts) > 1:
                            category = parts[0]
                        else:
                            category = 'æ ¹ç›®å½•'

                        file_info = {
                            'path': rel_path,
                            'lines': lines,
                            'h3_count': h3_count,
                            'priority': priority,
                            'category': category,
                            'is_completed_dir': is_completed
                        }

                        files_by_category[category].append(file_info)
                        all_short_files.append(file_info)

            except Exception as e:
                pass

    return files_by_category, all_short_files

def generate_task_report(files_by_category, all_short_files):
    """ç”Ÿæˆä»»åŠ¡æŠ¥å‘Š"""
    print("=" * 80)
    print("ğŸ“Š PostgreSQLæ–‡æ¡£è¡¥å……ä»»åŠ¡å…¨é¢æ¢³ç†æŠ¥å‘Š")
    print("=" * 80)
    print()

    print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»æ–‡ä»¶æ•°: {len(all_short_files)}")

    # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
    p0_count = sum(1 for f in all_short_files if f['priority'] == 'P0')
    p1_count = sum(1 for f in all_short_files if f['priority'] == 'P1')
    p2_count = sum(1 for f in all_short_files if f['priority'] == 'P2')

    print(f"  P0ä¼˜å…ˆçº§ï¼ˆ<200è¡Œï¼‰: {p0_count}ä¸ª")
    print(f"  P1ä¼˜å…ˆçº§ï¼ˆ200-300è¡Œä¸”H3<8ï¼‰: {p1_count}ä¸ª")
    print(f"  P2ä¼˜å…ˆçº§ï¼ˆ300-400è¡Œä¸”H3<10ï¼‰: {p2_count}ä¸ª")
    print()

    print("ğŸ“ æŒ‰ç›®å½•åˆ†ç±»ç»Ÿè®¡:")
    for category in sorted(files_by_category.keys()):
        files = files_by_category[category]
        p0 = sum(1 for f in files if f['priority'] == 'P0')
        p1 = sum(1 for f in files if f['priority'] == 'P1')
        p2 = sum(1 for f in files if f['priority'] == 'P2')
        print(f"  {category}: {len(files)}ä¸ªæ–‡ä»¶ (P0:{p0}, P1:{p1}, P2:{p2})")
    print()

    print("=" * 80)
    print("ğŸ“‹ è¯¦ç»†æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰")
    print("=" * 80)
    print()

    # æŒ‰ä¼˜å…ˆçº§å’Œç›®å½•æ’åº
    sorted_files = sorted(all_short_files, key=lambda x: (
        x['priority'],
        x['category'],
        x['lines']
    ))

    current_priority = None
    current_category = None

    for file_info in sorted_files:
        if file_info['priority'] != current_priority:
            current_priority = file_info['priority']
            print(f"\n## {current_priority}ä¼˜å…ˆçº§æ–‡ä»¶")
            print()

        if file_info['category'] != current_category:
            current_category = file_info['category']
            print(f"\n### {current_category}")
            print()

        status = "âœ…" if file_info['is_completed_dir'] else "â³"
        print(f"  {status} {file_info['path']}: {file_info['lines']}è¡Œ, {file_info['h3_count']}ä¸ªH3")

    print()
    print("=" * 80)
    print("âœ… æ‰«æå®Œæˆ")
    print("=" * 80)

    return sorted_files

if __name__ == '__main__':
    files_by_category, all_short_files = scan_all_files()
    sorted_files = generate_task_report(files_by_category, all_short_files)

    # ä¿å­˜åˆ°æ–‡ä»¶
    with open('COMPREHENSIVE_SCAN_RESULT.md', 'w', encoding='utf-8') as f:
        f.write("# PostgreSQLæ–‡æ¡£è¡¥å……ä»»åŠ¡å…¨é¢æ¢³ç†ç»“æœ\n\n")
        f.write(f"æ€»æ–‡ä»¶æ•°: {len(all_short_files)}\n\n")

        f.write("## æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡\n\n")
        p0_count = sum(1 for file_info in all_short_files if file_info['priority'] == 'P0')
        p1_count = sum(1 for file_info in all_short_files if file_info['priority'] == 'P1')
        p2_count = sum(1 for file_info in all_short_files if file_info['priority'] == 'P2')
        f.write(f"- P0ä¼˜å…ˆçº§: {p0_count}ä¸ª\n")
        f.write(f"- P1ä¼˜å…ˆçº§: {p1_count}ä¸ª\n")
        f.write(f"- P2ä¼˜å…ˆçº§: {p2_count}ä¸ª\n\n")

        f.write("## è¯¦ç»†æ–‡ä»¶åˆ—è¡¨\n\n")
        current_priority = None
        for file_info in sorted_files:
            if file_info['priority'] != current_priority:
                current_priority = file_info['priority']
                f.write(f"\n### {current_priority}ä¼˜å…ˆçº§\n\n")
            f.write(f"- `{file_info['path']}`: {file_info['lines']}è¡Œ, {file_info['h3_count']}ä¸ªH3\n")

    print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: COMPREHENSIVE_SCAN_RESULT.md")
