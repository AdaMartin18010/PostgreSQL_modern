---

> **📋 文档来源**: `docs\04-Distributed\02-实时流处理完整指南.md`
> **📅 复制日期**: 2025-12-22
> **⚠️ 注意**: 本文档为复制版本，原文件保持不变

---

# PostgreSQL实时流处理完整指南

> **创建日期**: 2025年12月4日
> **适用场景**: 实时数据管道、事件驱动架构
> **文档状态**: 🚧 深度创建中

---

## 📑 目录

- [PostgreSQL实时流处理完整指南](#postgresql实时流处理完整指南)
  - [📑 目录](#-目录)
  - [一、流处理概述](#一流处理概述)
    - [1.1 什么是流处理](#11-什么是流处理)
    - [1.2 PostgreSQL流处理能力](#12-postgresql流处理能力)
  - [二、逻辑复制流](#二逻辑复制流)
    - [2.1 配置流复制](#21-配置流复制)
  - [三、LISTEN/NOTIFY](#三listennotify)
    - [3.1 基本使用](#31-基本使用)
  - [四、与Kafka集成](#四与kafka集成)
    - [4.1 Debezium CDC](#41-debezium-cdc)
  - [五、生产案例](#五生产案例)
    - [案例1：实时数据同步](#案例1实时数据同步)
    - [案例2：事件驱动架构](#案例2事件驱动架构)

---

## 一、流处理概述

### 1.1 什么是流处理

**实时处理数据变更流**：

```text
传统批处理：
  数据库 → 每小时ETL → 数据仓库 → 分析
  延迟：1小时+

流处理：
  数据库 → 实时流 → 处理 → 目标系统
  延迟：<1秒
```

### 1.2 PostgreSQL流处理能力

**三种方式**：

1. **逻辑复制（Logical Replication）**
   - 最强大，完整的数据变更流

2. **LISTEN/NOTIFY**
   - 轻量级，应用层通知

3. **触发器 + 队列表**
   - 灵活，可自定义

---

## 二、逻辑复制流

### 2.1 配置流复制

**设置Publication**：

```sql
-- 创建Publication
CREATE PUBLICATION events_pub
FOR TABLE orders, users
WITH (publish = 'insert,update,delete');
```

**消费变更流（Python）**：

```python
import psycopg2
from psycopg2.extras import LogicalReplicationConnection

# 连接到复制槽
conn = psycopg2.connect(
    "dbname=mydb",
    connection_factory=LogicalReplicationConnection
)

cur = conn.cursor()

# 创建复制槽
cur.create_replication_slot('my_slot', output_plugin='pgoutput')

# 开始流式接收
cur.start_replication(
    slot_name='my_slot',
    options={
        'proto_version': '1',
        'publication_names': 'events_pub'
    }
)

# 消费消息
def consume_stream(msg):
    print(f"Change: {msg.payload}")
    msg.cursor.send_feedback(flush_lsn=msg.data_start)

cur.consume_stream(consume_stream)
```

---

## 三、LISTEN/NOTIFY

### 3.1 基本使用

**发送通知**：

```sql
-- 触发器：INSERT时通知
CREATE FUNCTION notify_new_order()
RETURNS TRIGGER AS $$
BEGIN
    PERFORM pg_notify(
        'new_orders',
        json_build_object(
            'order_id', NEW.id,
            'user_id', NEW.user_id,
            'amount', NEW.amount
        )::text
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER orders_notify
AFTER INSERT ON orders
FOR EACH ROW EXECUTE FUNCTION notify_new_order();
```

**接收通知（Python）**：

```python
import psycopg2
import select

conn = psycopg2.connect("dbname=mydb")
conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)

cur = conn.cursor()
cur.execute("LISTEN new_orders;")

print("Waiting for notifications...")
while True:
    if select.select([conn], [], [], 5) == ([], [], []):
        print("Timeout, still listening...")
    else:
        conn.poll()
        while conn.notifies:
            notify = conn.notifies.pop(0)
            print(f"Notification: {notify.payload}")
            # 处理通知
            process_new_order(json.loads(notify.payload))
```

---

## 四、与Kafka集成

### 4.1 Debezium CDC

**配置Debezium**：

```json
{
  "name": "pg-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "postgres",
    "database.dbname": "mydb",
    "table.include.list": "public.orders,public.users",
    "plugin.name": "pgoutput",
    "publication.name": "events_pub"
  }
}
```

**效果**：

- PostgreSQL变更 → Kafka → 任意消费者
- 延迟：<100ms
- 可靠性：至少一次交付

---

## 五、生产案例

### 案例1：实时数据同步

**场景**：

- PostgreSQL → Elasticsearch（实时搜索）
- 延迟要求：<1秒

**架构**：

```text
PostgreSQL → Debezium → Kafka → Consumer → Elasticsearch
```

**效果**：

- 同步延迟：<500ms
- 数据一致性：99.99%

---

### 案例2：事件驱动架构

**场景**：

- 订单系统解耦
- 微服务架构

**使用LISTEN/NOTIFY**：

**效果**：

- 服务解耦 ✅
- 实时响应 ✅
- 可靠性高 ✅

---

**最后更新**: 2025年12月4日
**文档编号**: P7-2-STREAM-PROCESSING
**版本**: v1.0
**状态**: ✅ 完成
