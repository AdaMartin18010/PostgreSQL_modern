---

> **📋 文档来源**: `docs\04-Distributed\02-实时流处理完整指南.md`
> **📅 复制日期**: 2025-12-22
> **⚠️ 注意**: 本文档为复制版本，原文件保持不变

---

# PostgreSQL实时流处理完整指南

> **创建日期**: 2025年1月
> **技术版本**: PostgreSQL 17+/18+
> **适用场景**: 实时数据管道、事件驱动架构、CDC、微服务解耦
> **难度等级**: ⭐⭐⭐⭐ 高级

---

## 📑 目录

- [PostgreSQL实时流处理完整指南](#postgresql实时流处理完整指南)
  - [📑 目录](#-目录)
  - [1. 流处理概述](#1-流处理概述)
    - [1.1 什么是流处理](#11-什么是流处理)
    - [1.2 PostgreSQL流处理能力](#12-postgresql流处理能力)
    - [1.3 流处理架构模式](#13-流处理架构模式)
  - [2. 逻辑复制流](#2-逻辑复制流)
    - [2.1 配置流复制](#21-配置流复制)
    - [2.2 创建Publication](#22-创建publication)
    - [2.3 创建Subscription](#23-创建subscription)
    - [2.4 监控与管理](#24-监控与管理)
  - [3. LISTEN/NOTIFY](#3-listennotify)
    - [3.1 基本使用](#31-基本使用)
    - [3.2 高级特性](#32-高级特性)
    - [3.3 性能优化](#33-性能优化)
  - [5. 与Kafka集成](#5-与kafka集成)
    - [5.1 Debezium CDC](#51-debezium-cdc)
    - [5.2 Kafka Connect](#52-kafka-connect)
    - [5.3 生产配置](#53-生产配置)
  - [五、生产案例](#五生产案例)
    - [案例1：实时数据同步](#案例1实时数据同步)
    - [案例2：事件驱动架构](#案例2事件驱动架构)

---

## 1. 流处理概述

### 1.1 什么是流处理

**流处理 vs 批处理**：

```text
传统批处理：
  数据库 → 每小时ETL → 数据仓库 → 分析
  延迟：1小时+
  数据量：大批量
  实时性：低

流处理：
  数据库 → 实时流 → 处理 → 目标系统
  延迟：<1秒
  数据量：小批量连续
  实时性：高
```

**流处理优势**：

- **低延迟**：毫秒级数据同步
- **实时性**：数据变更立即处理
- **解耦**：生产者和消费者解耦
- **可扩展**：支持多个消费者

**应用场景**：

- 实时数据同步（PostgreSQL → Elasticsearch）
- 事件驱动架构（微服务解耦）
- CDC（Change Data Capture）
- 实时分析（流式ETL）

### 1.2 PostgreSQL流处理能力

**三种主要方式**：

| 方式 | 延迟 | 可靠性 | 复杂度 | 适用场景 |
|------|------|--------|--------|---------|
| **逻辑复制** | <100ms | 高 | 中 | 跨数据库同步、CDC |
| **LISTEN/NOTIFY** | <10ms | 中 | 低 | 应用层通知、轻量级事件 |
| **触发器+队列表** | <50ms | 高 | 高 | 自定义流处理逻辑 |

**1. 逻辑复制（Logical Replication）**

- **特点**：最强大，完整的数据变更流
- **支持**：INSERT、UPDATE、DELETE、TRUNCATE
- **延迟**：<100ms
- **可靠性**：事务级别一致性

**2. LISTEN/NOTIFY**

- **特点**：轻量级，应用层通知
- **支持**：自定义消息
- **延迟**：<10ms
- **可靠性**：消息可能丢失

**3. 触发器 + 队列表**

- **特点**：灵活，可自定义
- **支持**：完全自定义逻辑
- **延迟**：<50ms
- **可靠性**：事务保证

### 1.3 流处理架构模式

**模式1：发布-订阅模式**

```text
PostgreSQL (Publisher)
    ↓
Publication
    ↓
多个Subscription (Subscribers)
    ↓
目标系统1, 目标系统2, ...
```

**模式2：消息队列模式**

```text
PostgreSQL → 触发器 → 队列表
                ↓
           消费者进程
                ↓
        目标系统1, 目标系统2, ...
```

**模式3：CDC模式**

```text
PostgreSQL → Debezium → Kafka
                ↓
        多个消费者
                ↓
    Elasticsearch, Redis, ...
```

---

## 2. 逻辑复制流

### 2.1 配置流复制

**前置条件**：

```sql
-- 1. 配置wal_level
ALTER SYSTEM SET wal_level = logical;
SELECT pg_reload_conf();

-- 2. 检查wal_level
SHOW wal_level;  -- 应该返回 'logical'

-- 3. 创建复制用户
CREATE USER replicator WITH REPLICATION PASSWORD 'password';
GRANT CONNECT ON DATABASE mydb TO replicator;
```

**配置pg_hba.conf**：

```ini
# 允许逻辑复制连接
host replication replicator 192.168.1.0/24 md5
```

### 2.2 创建Publication

**基本Publication**：

```sql
-- 创建Publication（包含所有表）
CREATE PUBLICATION all_tables_pub FOR ALL TABLES;

-- 创建Publication（指定表）
CREATE PUBLICATION events_pub
FOR TABLE orders, users, products
WITH (publish = 'insert,update,delete');

-- 创建Publication（指定schema）
CREATE PUBLICATION schema_pub FOR TABLES IN SCHEMA public;
```

**高级配置**：

```sql
-- 只发布INSERT和UPDATE
CREATE PUBLICATION insert_update_pub
FOR TABLE orders
WITH (publish = 'insert,update');

-- 查看Publication
SELECT * FROM pg_publication;

-- 查看Publication包含的表
SELECT
    p.pubname,
    t.schemaname,
    t.tablename
FROM pg_publication p
JOIN pg_publication_tables t ON p.pubname = t.pubname;
```

### 2.3 创建Subscription

**基本Subscription**：

```sql
-- 在目标数据库创建Subscription
CREATE SUBSCRIPTION events_sub
CONNECTION 'host=source_host port=5432 dbname=mydb user=replicator password=password'
PUBLICATION events_pub
WITH (
    copy_data = true,  -- 复制现有数据
    create_slot = true,  -- 自动创建复制槽
    enabled = true  -- 立即启用
);
```

**高级Subscription配置**：

```sql
-- 创建带过滤的Subscription
CREATE SUBSCRIPTION filtered_sub
CONNECTION 'host=source_host port=5432 dbname=mydb user=replicator password=password'
PUBLICATION events_pub
WITH (
    slot_name = 'custom_slot',
    synchronous_commit = 'remote_apply',  -- 同步提交
    connect = true,
    copy_data = false  -- 不复制现有数据
);

-- 查看Subscription状态
SELECT
    subname,
    subenabled,
    subslotname,
    subpublications
FROM pg_subscription;

-- 查看复制延迟
SELECT
    subname,
    pg_wal_lsn_diff(
        pg_current_wal_lsn(),
        subslotname::text::pg_lsn
    ) AS replication_lag_bytes
FROM pg_subscription;
```

**Python消费变更流**：

```python
import psycopg2
from psycopg2.extras import LogicalReplicationConnection
import json
import time

class LogicalReplicationConsumer:
    def __init__(self, dsn, slot_name, publication_name):
        self.dsn = dsn
        self.slot_name = slot_name
        self.publication_name = publication_name
        self.conn = None
        self.cursor = None

    def connect(self):
        """连接到数据库"""
        self.conn = psycopg2.connect(
            self.dsn,
            connection_factory=LogicalReplicationConnection
        )
        self.cursor = self.conn.cursor()

    def create_slot(self):
        """创建复制槽"""
        try:
            self.cursor.create_replication_slot(
                self.slot_name,
                output_plugin='pgoutput'
            )
            print(f"复制槽 {self.slot_name} 创建成功")
        except psycopg2.ProgrammingError as e:
            if 'already exists' in str(e):
                print(f"复制槽 {self.slot_name} 已存在")
            else:
                raise

    def start_replication(self, callback):
        """开始复制"""
        self.cursor.start_replication(
            slot_name=self.slot_name,
            options={
                'proto_version': '1',
                'publication_names': self.publication_name
            }
        )

        print(f"开始复制，监听Publication: {self.publication_name}")

        # 消费消息
        self.cursor.consume_stream(callback)

    def process_message(self, msg):
        """处理消息"""
        # 解析WAL消息
        change = self.parse_wal_message(msg.payload)

        if change:
            print(f"变更: {json.dumps(change, indent=2)}")

            # 发送确认
            msg.cursor.send_feedback(flush_lsn=msg.data_start)

    def parse_wal_message(self, payload):
        """解析WAL消息（简化版）"""
        # 实际实现需要解析pgoutput格式
        # 这里只是示例
        return {
            'type': 'change',
            'payload': payload.decode('utf-8', errors='ignore')
        }

    def close(self):
        """关闭连接"""
        if self.cursor:
            self.cursor.close()
        if self.conn:
            self.conn.close()

# 使用示例
if __name__ == '__main__':
    consumer = LogicalReplicationConsumer(
        dsn="dbname=mydb user=replicator password=password",
        slot_name='my_slot',
        publication_name='events_pub'
    )

    try:
        consumer.connect()
        consumer.create_slot()
        consumer.start_replication(consumer.process_message)
    except KeyboardInterrupt:
        print("停止复制...")
    finally:
        consumer.close()
```

### 2.4 监控与管理

**监控复制状态**：

```sql
-- 查看所有复制槽
SELECT
    slot_name,
    slot_type,
    active,
    restart_lsn,
    confirmed_flush_lsn
FROM pg_replication_slots;

-- 查看复制统计信息
SELECT
    pid,
    usename,
    application_name,
    client_addr,
    state,
    sync_state,
    sync_priority,
    pg_wal_lsn_diff(
        pg_current_wal_lsn(),
        sent_lsn
    ) AS replication_lag_bytes
FROM pg_stat_replication;

-- 查看Subscription统计
SELECT
    subname,
    pid,
    received_lsn,
    latest_end_lsn,
    latest_end_time
FROM pg_stat_subscription;
```

**管理操作**：

```sql
-- 暂停Subscription
ALTER SUBSCRIPTION events_sub DISABLE;

-- 恢复Subscription
ALTER SUBSCRIPTION events_sub ENABLE;

-- 删除Subscription
DROP SUBSCRIPTION events_sub;

-- 删除复制槽（谨慎操作）
SELECT pg_drop_replication_slot('my_slot');
```

---

## 3. LISTEN/NOTIFY

### 3.1 基本使用

**发送通知**：

```sql
-- 基本通知
NOTIFY channel_name, 'message';

-- 带数据的通知
NOTIFY new_orders, '{"order_id": 123, "amount": 99.99}';

-- 在触发器中发送通知
CREATE FUNCTION notify_new_order()
RETURNS TRIGGER AS $$
BEGIN
    PERFORM pg_notify(
        'new_orders',
        json_build_object(
            'order_id', NEW.id,
            'user_id', NEW.user_id,
            'amount', NEW.amount,
            'created_at', NEW.created_at
        )::text
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER orders_notify
AFTER INSERT ON orders
FOR EACH ROW EXECUTE FUNCTION notify_new_order();
```

**接收通知（Python异步版本）**：

```python
import psycopg2
import psycopg2.extensions
import select
import json
import asyncio
from typing import Callable

class NotificationListener:
    def __init__(self, dsn: str):
        self.dsn = dsn
        self.conn = None
        self.callbacks = {}

    def connect(self):
        """建立连接"""
        self.conn = psycopg2.connect(self.dsn)
        self.conn.set_isolation_level(
            psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT
        )

        # 注册通知处理器
        psycopg2.extensions.register_type(
            psycopg2.extensions.PG_NOTIFY_OID,
            self.conn
        )

    def listen(self, channel: str, callback: Callable):
        """监听频道"""
        cur = self.conn.cursor()
        cur.execute(f"LISTEN {channel};")
        self.callbacks[channel] = callback
        print(f"开始监听频道: {channel}")

    def poll(self, timeout: int = 5):
        """轮询通知"""
        if select.select([self.conn], [], [], timeout) == ([], [], []):
            return False

        self.conn.poll()

        while self.conn.notifies:
            notify = self.conn.notifies.pop(0)
            channel = notify.channel
            payload = notify.payload

            if channel in self.callbacks:
                try:
                    data = json.loads(payload)
                    self.callbacks[channel](data)
                except json.JSONDecodeError:
                    self.callbacks[channel](payload)

        return True

    def run_forever(self):
        """持续监听"""
        print("等待通知...")
        while True:
            try:
                self.poll()
            except KeyboardInterrupt:
                print("停止监听...")
                break
            except Exception as e:
                print(f"错误: {e}")
                time.sleep(1)

    def close(self):
        """关闭连接"""
        if self.conn:
            self.conn.close()

# 使用示例
def handle_new_order(data):
    print(f"新订单: {data}")

if __name__ == '__main__':
    listener = NotificationListener("dbname=mydb user=postgres")
    listener.connect()
    listener.listen('new_orders', handle_new_order)
    listener.run_forever()
```

### 3.2 高级特性

**批量通知**：

```sql
-- 批量发送通知
CREATE FUNCTION notify_batch_orders()
RETURNS TRIGGER AS $$
DECLARE
    batch_data jsonb;
BEGIN
    -- 收集批量数据
    SELECT jsonb_agg(
        jsonb_build_object(
            'id', id,
            'user_id', user_id,
            'amount', amount
        )
    ) INTO batch_data
    FROM new_table;

    -- 发送批量通知
    PERFORM pg_notify('batch_orders', batch_data::text);

    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER batch_orders_notify
AFTER INSERT ON orders
REFERENCING NEW TABLE AS new_table
FOR EACH STATEMENT EXECUTE FUNCTION notify_batch_orders();
```

**条件通知**：

```sql
-- 只在满足条件时通知
CREATE FUNCTION notify_high_value_orders()
RETURNS TRIGGER AS $$
BEGIN
    IF NEW.amount > 1000 THEN
        PERFORM pg_notify(
            'high_value_orders',
            json_build_object(
                'order_id', NEW.id,
                'amount', NEW.amount
            )::text
        );
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;
```

### 3.3 性能优化

**优化建议**：

1. **批量处理**：使用FOR EACH STATEMENT触发器
2. **异步处理**：通知后立即返回，异步处理业务逻辑
3. **连接池**：使用PgBouncer管理连接
4. **消息大小**：限制消息大小，避免阻塞

**性能对比**：

| 方式 | 延迟 | 吞吐量 | 可靠性 |
|------|------|--------|--------|
| LISTEN/NOTIFY | <10ms | 1000/s | 中 |
| 逻辑复制 | <100ms | 10000/s | 高 |
| 触发器+队列 | <50ms | 5000/s | 高 |

---

## 5. 与Kafka集成

### 5.1 Debezium CDC

**Debezium简介**：

Debezium是一个开源的CDC平台，可以将PostgreSQL的变更事件流式传输到Kafka。

**优势**：

- **低延迟**：<100ms
- **高可靠性**：事务级别一致性
- **易扩展**：支持多个消费者
- **易监控**：集成Kafka监控

**完整配置**：

```json
{
  "name": "postgres-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "postgres.example.com",
    "database.port": "5432",
    "database.user": "replicator",
    "database.password": "password",
    "database.dbname": "mydb",
    "database.server.name": "postgres-server",
    "table.include.list": "public.orders,public.users,public.products",
    "plugin.name": "pgoutput",
    "publication.name": "events_pub",
    "slot.name": "debezium_slot",
    "publication.autocreate.mode": "filtered",
    "heartbeat.interval.ms": "10000",
    "max.batch.size": "2048",
    "max.queue.size": "8192",
    "snapshot.mode": "initial",
    "snapshot.locking.mode": "minimal",
    "transforms": "unwrap",
    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
    "transforms.unwrap.drop.tombstones": "false",
    "transforms.unwrap.delete.handling.mode": "rewrite"
  }
}
```

**创建Connector**：

```bash
# 使用Kafka Connect REST API
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d @debezium-config.json

# 检查Connector状态
curl http://localhost:8083/connectors/postgres-connector/status
```

**Kafka消息格式**：

```json
{
  "before": {
    "id": 123,
    "user_id": 456,
    "amount": 99.99
  },
  "after": {
    "id": 123,
    "user_id": 456,
    "amount": 149.99
  },
  "source": {
    "version": "2.5.0",
    "connector": "postgresql",
    "name": "postgres-server",
    "ts_ms": 1705123456789,
    "snapshot": "false",
    "db": "mydb",
    "schema": "public",
    "table": "orders",
    "txId": 12345,
    "lsn": 12345678
  },
  "op": "u",
  "ts_ms": 1705123456789
}
```

### 5.2 Kafka Connect

**Kafka Connect配置**：

```properties
# connect-standalone.properties
bootstrap.servers=localhost:9092
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false
offset.storage.file.filename=/tmp/connect.offsets
offset.flush.interval.ms=10000
plugin.path=/usr/share/confluent-hub-components
```

**启动Kafka Connect**：

```bash
# 启动Kafka Connect
connect-standalone connect-standalone.properties debezium-config.json

# 或使用Docker
docker run -it --rm \
  --name connect \
  -p 8083:8083 \
  -e CONNECT_BOOTSTRAP_SERVERS=kafka:9092 \
  -e CONNECT_REST_PORT=8083 \
  -e CONNECT_GROUP_ID=connect-cluster \
  -e CONNECT_CONFIG_STORAGE_TOPIC=connect-configs \
  -e CONNECT_OFFSET_STORAGE_TOPIC=connect-offsets \
  -e CONNECT_STATUS_STORAGE_TOPIC=connect-status \
  -e CONNECT_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter \
  -e CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter \
  debezium/connect:latest
```

### 5.3 生产配置

**高可用配置**：

```json
{
  "config": {
    "tasks.max": "4",
    "database.history.kafka.bootstrap.servers": "kafka1:9092,kafka2:9092,kafka3:9092",
    "database.history.kafka.topic": "dbhistory.postgres",
    "max.batch.size": "4096",
    "max.queue.size": "16384",
    "poll.interval.ms": "500",
    "heartbeat.interval.ms": "5000",
    "errors.tolerance": "all",
    "errors.log.enable": "true",
    "errors.log.include.messages": "true"
  }
}
```

**监控指标**：

```bash
# 查看Connector指标
curl http://localhost:8083/connectors/postgres-connector/metrics

# 查看Kafka Consumer Lag
kafka-consumer-groups --bootstrap-server localhost:9092 \
  --group connect-postgres-connector \
  --describe
```

---

## 五、生产案例

### 案例1：实时数据同步

**场景**：

- PostgreSQL → Elasticsearch（实时搜索）
- 延迟要求：<1秒

**架构**：

```text
PostgreSQL → Debezium → Kafka → Consumer → Elasticsearch
```

**效果**：

- 同步延迟：<500ms
- 数据一致性：99.99%

---

### 案例2：事件驱动架构

**场景**：

- 订单系统解耦
- 微服务架构

**使用LISTEN/NOTIFY**：

**效果**：

- 服务解耦 ✅
- 实时响应 ✅
- 可靠性高 ✅

---

**最后更新**: 2025年12月4日
**文档编号**: P7-2-STREAM-PROCESSING
**版本**: v1.0
**状态**: ✅ 完成
