---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `docs\04-Distributed\09-CDCå˜æ›´æ•°æ®æ•è·å®æˆ˜.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# PostgreSQL 18 CDCå˜æ›´æ•°æ®æ•è·å®æˆ˜

## 1. CDCæ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CDC (Change Data Capture)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  [PostgreSQL]                                  â”‚
â”‚       â”‚                                        â”‚
â”‚   WALæ—¥å¿—                                      â”‚
â”‚       â”‚                                        â”‚
â”‚  [é€»è¾‘è§£ç ]                                     â”‚
â”‚       â”‚                                        â”‚
â”‚  [Replication Slot]                            â”‚
â”‚       â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚        â”‚        â”‚                          â”‚
â”‚ [Kafka] [Kinesis] [è‡ªå®šä¹‰]                      â”‚
â”‚   â”‚        â”‚        â”‚                          â”‚
â”‚ [æ¶ˆè´¹è€…1][æ¶ˆè´¹è€…2][æ¶ˆè´¹è€…3]                     â”‚
â”‚                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. é€»è¾‘è§£ç 

### 2.1 é…ç½®

```sql
-- å¯ç”¨é€»è¾‘å¤åˆ¶
ALTER SYSTEM SET wal_level = logical;
ALTER SYSTEM SET max_replication_slots = 10;
ALTER SYSTEM SET max_wal_senders = 10;

-- é‡å¯PostgreSQL
-- sudo systemctl restart postgresql

-- åˆ›å»ºå¤åˆ¶æ§½
SELECT * FROM pg_create_logical_replication_slot('cdc_slot', 'pgoutput');

-- æŸ¥çœ‹å¤åˆ¶æ§½
SELECT * FROM pg_replication_slots;
```

### 2.2 æ¶ˆè´¹å˜æ›´

```sql
-- è¯»å–å˜æ›´
SELECT * FROM pg_logical_slot_peek_changes('cdc_slot', NULL, NULL);

-- æ¶ˆè´¹å˜æ›´ï¼ˆæ¨è¿›LSNï¼‰
SELECT * FROM pg_logical_slot_get_changes('cdc_slot', NULL, NULL);

-- è¾“å‡ºæ ¼å¼
/*
lsn          | xid  | data
-------------+------+------------------------------------------
0/16B2D50    | 1001 | BEGIN 1001
0/16B2D88    | 1001 | table public.users: INSERT: id[integer]:1 name[text]:'alice'
0/16B2DC0    | 1001 | COMMIT 1001
*/
```

---

## 3. Debeziumé›†æˆ

### 3.1 é…ç½®Debezium

```json
{
  "name": "postgres-cdc-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "postgres",
    "database.password": "password",
    "database.dbname": "mydb",
    "database.server.name": "postgres-server",
    "table.include.list": "public.users,public.orders",
    "plugin.name": "pgoutput",
    "slot.name": "debezium_slot",
    "publication.name": "debezium_pub"
  }
}
```

### 3.2 åˆ›å»ºPublication

```sql
-- åˆ›å»ºå‘å¸ƒ
CREATE PUBLICATION debezium_pub FOR TABLE users, orders;

-- æˆ–å‘å¸ƒæ‰€æœ‰è¡¨
CREATE PUBLICATION debezium_pub FOR ALL TABLES;

-- æŸ¥çœ‹å‘å¸ƒ
\dRp+
```

---

## 4. å®æ—¶æ•°æ®åŒæ­¥

### 4.1 PostgreSQL â†’ Kafka

```python
from kafka import KafkaProducer
import psycopg2
import json

class PostgresCDC:
    """PostgreSQL CDCåˆ°Kafka"""

    def __init__(self, pg_conn_str, kafka_servers):
        self.pg_conn = psycopg2.connect(pg_conn_str)
        self.cursor = self.pg_conn.cursor()
        self.producer = KafkaProducer(
            bootstrap_servers=kafka_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )

    def start_cdc(self, slot_name='cdc_slot'):
        """å¯åŠ¨CDC"""

        # åˆ›å»ºå¤åˆ¶æ§½
        try:
            self.cursor.execute(f"""
                SELECT * FROM pg_create_logical_replication_slot('{slot_name}', 'pgoutput');
            """)
        except:
            pass  # æ§½å·²å­˜åœ¨

        # æŒç»­è¯»å–å˜æ›´
        while True:
            self.cursor.execute(f"""
                SELECT * FROM pg_logical_slot_get_changes('{slot_name}', NULL, NULL,
                    'proto_version', '1',
                    'publication_names', 'debezium_pub');
            """)

            changes = self.cursor.fetchall()

            for lsn, xid, data in changes:
                # è§£æå˜æ›´
                change_event = self.parse_change(data)

                # å‘é€åˆ°Kafka
                if change_event:
                    topic = f"postgres.public.{change_event['table']}"
                    self.producer.send(topic, change_event)

            if not changes:
                time.sleep(0.1)

    def parse_change(self, data: str):
        """è§£æå˜æ›´æ•°æ®"""

        if 'INSERT' in data:
            # è§£æINSERT
            return {'operation': 'INSERT', 'table': '...', 'data': {...}}
        elif 'UPDATE' in data:
            return {'operation': 'UPDATE', 'table': '...', 'data': {...}}
        elif 'DELETE' in data:
            return {'operation': 'DELETE', 'table': '...', 'data': {...}}

        return None

# ä½¿ç”¨
cdc = PostgresCDC(
    pg_conn_str="postgresql://localhost/mydb",
    kafka_servers=['localhost:9092']
)
cdc.start_cdc()
```

---

## 5. æ•°æ®æ¹–åŒæ­¥

### 5.1 PostgreSQL â†’ S3

```python
import boto3
from datetime import datetime

class CDCToS3:
    """CDCåˆ°S3æ•°æ®æ¹–"""

    def __init__(self, pg_conn_str, s3_bucket):
        self.pg_conn = psycopg2.connect(pg_conn_str)
        self.cursor = self.pg_conn.cursor()
        self.s3 = boto3.client('s3')
        self.bucket = s3_bucket
        self.buffer = []
        self.buffer_size = 10000

    def sync_changes(self, slot_name='s3_cdc_slot'):
        """åŒæ­¥å˜æ›´åˆ°S3"""

        while True:
            self.cursor.execute(f"""
                SELECT * FROM pg_logical_slot_get_changes('{slot_name}', NULL, NULL);
            """)

            changes = self.cursor.fetchall()

            for change in changes:
                self.buffer.append(change)

                if len(self.buffer) >= self.buffer_size:
                    self.flush_to_s3()

            if not changes:
                if self.buffer:
                    self.flush_to_s3()
                time.sleep(1)

    def flush_to_s3(self):
        """åˆ·æ–°åˆ°S3"""

        if not self.buffer:
            return

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        key = f"cdc/changes_{timestamp}.json"

        # ä¸Šä¼ 
        data = json.dumps([self.parse_change(c[2]) for c in self.buffer])
        self.s3.put_object(Bucket=self.bucket, Key=key, Body=data)

        print(f"âœ… ä¸Šä¼  {len(self.buffer)} æ¡å˜æ›´åˆ° s3://{self.bucket}/{key}")
        self.buffer = []
```

---

## 6. å®æ—¶ç‰©åŒ–è§†å›¾

### 6.1 åŸºäºCDCçš„ç‰©åŒ–è§†å›¾

```sql
-- æºè¡¨
CREATE TABLE orders (
    order_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT,
    amount NUMERIC,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- ç‰©åŒ–è§†å›¾ï¼ˆæ±‡æ€»ï¼‰
CREATE TABLE user_order_summary (
    user_id BIGINT PRIMARY KEY,
    order_count INT,
    total_amount NUMERIC,
    last_order_at TIMESTAMPTZ
);

-- CDCè§¦å‘å™¨å¢é‡æ›´æ–°
CREATE OR REPLACE FUNCTION update_user_summary()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        INSERT INTO user_order_summary (user_id, order_count, total_amount, last_order_at)
        VALUES (NEW.user_id, 1, NEW.amount, NEW.created_at)
        ON CONFLICT (user_id) DO UPDATE
        SET order_count = user_order_summary.order_count + 1,
            total_amount = user_order_summary.total_amount + NEW.amount,
            last_order_at = GREATEST(user_order_summary.last_order_at, NEW.created_at);

    ELSIF TG_OP = 'UPDATE' THEN
        UPDATE user_order_summary
        SET total_amount = total_amount - OLD.amount + NEW.amount
        WHERE user_id = NEW.user_id;

    ELSIF TG_OP = 'DELETE' THEN
        UPDATE user_order_summary
        SET order_count = order_count - 1,
            total_amount = total_amount - OLD.amount
        WHERE user_id = OLD.user_id;
    END IF;

    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_cdc_summary
    AFTER INSERT OR UPDATE OR DELETE ON orders
    FOR EACH ROW EXECUTE FUNCTION update_user_summary();
```

---

## 7. ç›‘æ§CDC

### 7.1 å¤åˆ¶æ§½ç›‘æ§

```sql
-- æŸ¥çœ‹å¤åˆ¶æ§½çŠ¶æ€
SELECT
    slot_name,
    plugin,
    slot_type,
    active,
    pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) AS lag_size,
    pg_wal_lsn_diff(pg_current_wal_lsn(), confirmed_flush_lsn) AS pending_bytes
FROM pg_replication_slots;

-- å‘Šè­¦: lag_size > 1GB
SELECT slot_name
FROM pg_replication_slots
WHERE pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) > 1073741824;
```

---

## 8. æ•…éšœå¤„ç†

### 8.1 å¤åˆ¶æ§½å µå¡

```bash
# ç°è±¡: WALå †ç§¯ï¼Œç£ç›˜æ»¡
df -h /var/lib/postgresql/18/main/pg_wal

# æ’æŸ¥
psql -c "SELECT * FROM pg_replication_slots WHERE active = false;"

# è§£å†³: åˆ é™¤ä¸æ´»è·ƒçš„æ§½
psql -c "SELECT pg_drop_replication_slot('stuck_slot');"

# æˆ–é‡ç½®æ§½ä½ç½®
psql -c "SELECT pg_replication_slot_advance('cdc_slot', '0/12345678');"
```

---

**å®Œæˆ**: PostgreSQL 18 CDCå˜æ›´æ•°æ®æ•è·å®æˆ˜
**å­—æ•°**: ~10,000å­—
**æ¶µç›–**: é€»è¾‘è§£ç ã€Debeziumã€Kafkaé›†æˆã€æ•°æ®æ¹–åŒæ­¥ã€ç›‘æ§
