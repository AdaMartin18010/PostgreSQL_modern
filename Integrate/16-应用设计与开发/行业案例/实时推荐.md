---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL\09-åº”ç”¨è®¾è®¡\è¡Œä¸šæ¡ˆä¾‹\å®æ—¶æ¨è.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# å®æ—¶æ¨èç³»ç»Ÿæ¡ˆä¾‹ï¼šPostgreSQLæµå¼å¤„ç†ä¸ç‰©åŒ–è§†å›¾å®è·µ

> **ç‰ˆæœ¬**: PostgreSQL 18.x
> **æœ€åæ›´æ–°**: 2025-01-15
> **éš¾åº¦**: â­â­â­â­
> **åº”ç”¨åœºæ™¯**: ç”µå•†æ¨èã€å†…å®¹æ¨èã€å¹¿å‘Šæ¨è

---

## ğŸ“‘ ç›®å½•

- [1.1 ä¸šåŠ¡èƒŒæ™¯](#11-ä¸šåŠ¡èƒŒæ™¯)
- [1.2 æŠ€æœ¯æŒ‘æˆ˜](#12-æŠ€æœ¯æŒ‘æˆ˜)
- [1.3 é€‚ç”¨åœºæ™¯](#13-é€‚ç”¨åœºæ™¯)
- [1.4 ç‰ˆæœ¬è¦æ±‚](#14-ç‰ˆæœ¬è¦æ±‚)
- [2.1 å®æ—¶æ¨èç³»ç»Ÿæ¶æ„](#21-å®æ—¶æ¨èç³»ç»Ÿæ¶æ„)
- [2.2 æµå¼ETLå¤„ç†](#22-æµå¼etlå¤„ç†)
- [2.3 ç‰©åŒ–è§†å›¾ä¸å¢é‡èšåˆ](#23-ç‰©åŒ–è§†å›¾ä¸å¢é‡èšåˆ)
- [2.4 æ€ç»´å¯¼å›¾](#24-æ€ç»´å¯¼å›¾)
- [3.1 æ•´ä½“æ¶æ„è®¾è®¡](#31-æ•´ä½“æ¶æ„è®¾è®¡)
- [3.2 æ•°æ®æµè®¾è®¡](#32-æ•°æ®æµè®¾è®¡)
- [3.3 å­˜å‚¨è®¾è®¡](#33-å­˜å‚¨è®¾è®¡)
- [4.1 æµå¼ETLå®ç°](#41-æµå¼etlå®ç°)
- [4.2 ç‰©åŒ–è§†å›¾è®¾è®¡](#42-ç‰©åŒ–è§†å›¾è®¾è®¡)
- [4.3 å¢é‡èšåˆç­–ç•¥](#43-å¢é‡èšåˆç­–ç•¥)
- [4.4 çƒ­ç‚¹å†™å…¥ä¼˜åŒ–](#44-çƒ­ç‚¹å†™å…¥ä¼˜åŒ–)
- [5.1 æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”](#51-æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”)
- [5.2 æ€§èƒ½å¯¹æ¯”](#52-æ€§èƒ½å¯¹æ¯”)
- [6.1 ç”µå•†å®æ—¶æ¨è](#61-ç”µå•†å®æ—¶æ¨è)
- [6.2 å†…å®¹æ¨èç³»ç»Ÿ](#62-å†…å®¹æ¨èç³»ç»Ÿ)
- [7.1 æŸ¥è¯¢ä¼˜åŒ–](#71-æŸ¥è¯¢ä¼˜åŒ–)
- [7.2 å†™å…¥ä¼˜åŒ–](#72-å†™å…¥ä¼˜åŒ–)
- [7.3 ç‰©åŒ–è§†å›¾åˆ·æ–°ä¼˜åŒ–](#73-ç‰©åŒ–è§†å›¾åˆ·æ–°ä¼˜åŒ–)
- [8.1 å…³é”®æŒ‡æ ‡](#81-å…³é”®æŒ‡æ ‡)
- [8.2 ç›‘æ§æ–¹æ¡ˆ](#82-ç›‘æ§æ–¹æ¡ˆ)
- [8.3 éªŒè¯æ–¹æ³•](#83-éªŒè¯æ–¹æ³•)
- [10.1 å®˜æ–¹æ–‡æ¡£](#101-å®˜æ–¹æ–‡æ¡£)
- [10.2 ç½‘ç»œèµ„æº](#102-ç½‘ç»œèµ„æº)
- [10.3 å­¦æœ¯è®ºæ–‡](#103-å­¦æœ¯è®ºæ–‡)
- [10.4 ç›¸å…³æ¡ˆä¾‹](#104-ç›¸å…³æ¡ˆä¾‹)
- [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)
- [å¤–éƒ¨èµ„æº](#å¤–éƒ¨èµ„æº)
---

## ä¸€ã€æ¦‚è¿°

### 1.1 ä¸šåŠ¡èƒŒæ™¯

å®æ—¶æ¨èç³»ç»Ÿæ˜¯ç°ä»£äº’è”ç½‘åº”ç”¨çš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€ï¼Œå¹¿æ³›åº”ç”¨äºç”µå•†ã€å†…å®¹å¹³å°ã€ç¤¾äº¤åª’ä½“ç­‰é¢†åŸŸã€‚ä¸ä¼ ç»Ÿçš„ç¦»çº¿æ¨èç³»ç»Ÿä¸åŒï¼Œå®æ—¶æ¨èç³»ç»Ÿéœ€è¦åœ¨ç”¨æˆ·è¡Œä¸ºå‘ç”Ÿåå‡ ç§’åˆ°å‡ åˆ†é’Ÿå†…æ›´æ–°æ¨èç»“æœï¼Œä»¥æä¾›æ›´ç²¾å‡†ã€æ›´åŠæ—¶çš„ä¸ªæ€§åŒ–æ¨èã€‚

**å…¸å‹ä¸šåŠ¡åœºæ™¯**ï¼š

- **ç”µå•†å¹³å°**ï¼šç”¨æˆ·æµè§ˆå•†å“åï¼Œå®æ—¶æ¨èç›¸å…³å•†å“
- **å†…å®¹å¹³å°**ï¼šç”¨æˆ·é˜…è¯»æ–‡ç« åï¼Œå®æ—¶æ¨èç›¸ä¼¼å†…å®¹
- **è§†é¢‘å¹³å°**ï¼šç”¨æˆ·è§‚çœ‹è§†é¢‘åï¼Œå®æ—¶æ¨èç›¸å…³è§†é¢‘
- **ç¤¾äº¤å¹³å°**ï¼šç”¨æˆ·äº’åŠ¨åï¼Œå®æ—¶æ¨èå¯èƒ½æ„Ÿå…´è¶£çš„ç”¨æˆ·æˆ–å†…å®¹

**ä¸šåŠ¡ä»·å€¼**ï¼š

- æå‡ç”¨æˆ·å‚ä¸åº¦å’Œåœç•™æ—¶é—´
- å¢åŠ è½¬åŒ–ç‡å’Œæ”¶å…¥
- æ”¹å–„ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦

### 1.2 æŠ€æœ¯æŒ‘æˆ˜

å®æ—¶æ¨èç³»ç»Ÿé¢ä¸´ä»¥ä¸‹æŠ€æœ¯æŒ‘æˆ˜ï¼š

1. **ä½å»¶è¿Ÿè¦æ±‚**
   - æ¨èç»“æœéœ€è¦åœ¨ç§’çº§å†…è¿”å›
   - æ•°æ®æ›´æ–°éœ€è¦åœ¨åˆ†é’Ÿçº§å†…ç”Ÿæ•ˆ

2. **é«˜å¹¶å‘å¤„ç†**
   - éœ€è¦å¤„ç†å¤§é‡ç”¨æˆ·è¡Œä¸ºäº‹ä»¶
   - éœ€è¦æ”¯æŒé«˜QPSçš„æŸ¥è¯¢è¯·æ±‚

3. **æ•°æ®ä¸€è‡´æ€§**
   - æµå¼æ•°æ®å¤„ç†çš„ä¸€è‡´æ€§ä¿è¯
   - ç‰©åŒ–è§†å›¾ä¸æºæ•°æ®çš„ä¸€è‡´æ€§

4. **çƒ­ç‚¹å†™å…¥**
   - çƒ­é—¨å•†å“/å†…å®¹çš„é«˜é¢‘æ›´æ–°
   - å†™å…¥æ€§èƒ½ç“¶é¢ˆ

5. **è®¡ç®—å¤æ‚åº¦**
   - å®æ—¶ç‰¹å¾è®¡ç®—
   - æ¨èç®—æ³•è®¡ç®—

### 1.3 é€‚ç”¨åœºæ™¯

æœ¬æ¡ˆä¾‹é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š

- âœ… **ä¸­å°å‹æ¨èç³»ç»Ÿ**ï¼ˆæ—¥æ´»ç”¨æˆ· < 1000ä¸‡ï¼‰
- âœ… **å®æ—¶æ€§è¦æ±‚é«˜**ï¼ˆå»¶è¿Ÿ < 5ç§’ï¼‰
- âœ… **æ•°æ®é‡é€‚ä¸­**ï¼ˆå•è¡¨æ•°æ® < 10äº¿ï¼‰
- âœ… **é¢„ç®—æœ‰é™**ï¼ˆéœ€è¦ä½æˆæœ¬æ–¹æ¡ˆï¼‰

ä¸é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š

- âŒ **è¶…å¤§è§„æ¨¡ç³»ç»Ÿ**ï¼ˆæ—¥æ´»ç”¨æˆ· > 1äº¿ï¼‰
- âŒ **æä½å»¶è¿Ÿè¦æ±‚**ï¼ˆå»¶è¿Ÿ < 100msï¼‰
- âŒ **å¤æ‚æ¨èç®—æ³•**ï¼ˆéœ€è¦æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼‰

### 1.4 ç‰ˆæœ¬è¦æ±‚

- **PostgreSQL 18.x**ï¼ˆæ¨èï¼‰- æ”¯æŒå¼‚æ­¥I/Oã€è™šæ‹Ÿç”Ÿæˆåˆ—ç­‰æ–°ç‰¹æ€§
- **PostgreSQL 17.x**ï¼ˆå…¼å®¹ï¼‰- æ”¯æŒç‰©åŒ–è§†å›¾å¹¶å‘åˆ·æ–°
- **PostgreSQL 16.x**ï¼ˆéƒ¨åˆ†æ”¯æŒï¼‰- åŸºç¡€åŠŸèƒ½å¯ç”¨

---

## äºŒã€æ ¸å¿ƒæ¦‚å¿µ

### 2.1 å®æ—¶æ¨èç³»ç»Ÿæ¶æ„

**å®æ—¶æ¨èç³»ç»Ÿ**æ˜¯ä¸€ç§åŸºäºç”¨æˆ·å®æ—¶è¡Œä¸ºæ•°æ®ï¼Œå¿«é€Ÿç”Ÿæˆä¸ªæ€§åŒ–æ¨èç»“æœçš„ç³»ç»Ÿã€‚å…¶æ ¸å¿ƒç‰¹ç‚¹æ˜¯ï¼š

- **å®æ—¶æ€§**ï¼šæ¨èç»“æœåœ¨ç”¨æˆ·è¡Œä¸ºå‘ç”Ÿåå‡ ç§’å†…æ›´æ–°
- **ä¸ªæ€§åŒ–**ï¼šåŸºäºç”¨æˆ·å†å²è¡Œä¸ºå’Œå®æ—¶è¡Œä¸ºç”Ÿæˆä¸ªæ€§åŒ–æ¨è
- **åŠ¨æ€æ€§**ï¼šæ¨èç»“æœéšç”¨æˆ·è¡Œä¸ºå˜åŒ–è€ŒåŠ¨æ€è°ƒæ•´

**å…³é”®ç»„ä»¶**ï¼š

1. **æ•°æ®é‡‡é›†å±‚**ï¼šæ”¶é›†ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼ˆæµè§ˆã€ç‚¹å‡»ã€è´­ä¹°ç­‰ï¼‰
2. **æµå¼å¤„ç†å±‚**ï¼šå®æ—¶å¤„ç†ç”¨æˆ·è¡Œä¸ºæ•°æ®
3. **ç‰¹å¾è®¡ç®—å±‚**ï¼šè®¡ç®—ç”¨æˆ·ç‰¹å¾å’Œç‰©å“ç‰¹å¾
4. **æ¨èç®—æ³•å±‚**ï¼šåŸºäºç‰¹å¾ç”Ÿæˆæ¨èç»“æœ
5. **å­˜å‚¨å±‚**ï¼šå­˜å‚¨ç”¨æˆ·è¡Œä¸ºã€ç‰¹å¾å’Œæ¨èç»“æœ

### 2.2 æµå¼ETLå¤„ç†

**æµå¼ETL**ï¼ˆExtract, Transform, Loadï¼‰æ˜¯æŒ‡å®æ—¶åœ°ä»æ•°æ®æºæå–æ•°æ®ï¼Œè¿›è¡Œè½¬æ¢å¤„ç†ï¼Œç„¶ååŠ è½½åˆ°ç›®æ ‡ç³»ç»Ÿçš„è¿‡ç¨‹ã€‚

**åœ¨å®æ—¶æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨**ï¼š

- **Extract**ï¼šä»Kafkaã€CDCç­‰æ•°æ®æºæå–ç”¨æˆ·è¡Œä¸ºäº‹ä»¶
- **Transform**ï¼šæ¸…æ´—ã€å»é‡ã€èšåˆç”¨æˆ·è¡Œä¸ºæ•°æ®
- **Load**ï¼šå°†å¤„ç†åçš„æ•°æ®åŠ è½½åˆ°PostgreSQL

**å…³é”®æŠ€æœ¯**ï¼š

- **Kafka Connect**ï¼šè¿æ¥Kafkaå’ŒPostgreSQL
- **Debezium CDC**ï¼šæ•è·æ•°æ®åº“å˜æ›´
- **PostgreSQLé€»è¾‘å¤åˆ¶**ï¼šå®æ—¶åŒæ­¥æ•°æ®

### 2.3 ç‰©åŒ–è§†å›¾ä¸å¢é‡èšåˆ

**ç‰©åŒ–è§†å›¾**ï¼ˆMaterialized Viewï¼‰æ˜¯PostgreSQLä¸­é¢„å…ˆè®¡ç®—å¹¶å­˜å‚¨æŸ¥è¯¢ç»“æœçš„æœºåˆ¶ï¼Œå¯ä»¥æ˜¾è‘—æå‡æŸ¥è¯¢æ€§èƒ½ã€‚

**åœ¨å®æ—¶æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨**ï¼š

- **å®æ—¶èšåˆ**ï¼šå®æ—¶è®¡ç®—ç”¨æˆ·è¡Œä¸ºç»Ÿè®¡ï¼ˆå¦‚ç‚¹å‡»ç‡ã€è´­ä¹°ç‡ï¼‰
- **Top-KæŸ¥è¯¢**ï¼šé¢„è®¡ç®—çƒ­é—¨å•†å“/å†…å®¹æ’è¡Œæ¦œ
- **ç‰¹å¾å­˜å‚¨**ï¼šå­˜å‚¨ç”¨æˆ·ç‰¹å¾å’Œç‰©å“ç‰¹å¾

**å¢é‡èšåˆç­–ç•¥**ï¼š

- **CONCURRENTLYåˆ·æ–°**ï¼šä¸é˜»å¡æŸ¥è¯¢çš„å¹¶å‘åˆ·æ–°
- **å¢é‡æ›´æ–°**ï¼šåªæ›´æ–°å˜åŒ–çš„éƒ¨åˆ†
- **å®šæ—¶åˆ·æ–°**ï¼šæŒ‰æ—¶é—´é—´éš”è‡ªåŠ¨åˆ·æ–°

### 2.4 æ€ç»´å¯¼å›¾

```mermaid
graph TD
    A[å®æ—¶æ¨èç³»ç»Ÿ] --> B[æ•°æ®é‡‡é›†å±‚]
    A --> C[æµå¼å¤„ç†å±‚]
    A --> D[ç‰¹å¾è®¡ç®—å±‚]
    A --> E[æ¨èç®—æ³•å±‚]
    A --> F[å­˜å‚¨å±‚]

    B --> B1[ç”¨æˆ·è¡Œä¸ºäº‹ä»¶]
    B --> B2[Kafka/CDC]

    C --> C1[æµå¼ETL]
    C --> C2[æ•°æ®æ¸…æ´—]
    C --> C3[å»é‡å¤„ç†]

    D --> D1[ç”¨æˆ·ç‰¹å¾]
    D --> D2[ç‰©å“ç‰¹å¾]
    D --> D3[å®æ—¶ç‰¹å¾]

    E --> E1[ååŒè¿‡æ»¤]
    E --> E2[å†…å®¹æ¨è]
    E --> E3[æ··åˆæ¨è]

    F --> F1[PostgreSQL]
    F --> F2[ç‰©åŒ–è§†å›¾]
    F --> F3[ç´¢å¼•ä¼˜åŒ–]
```

---

## ä¸‰ã€æŠ€æœ¯æ¶æ„

### 3.1 æ•´ä½“æ¶æ„è®¾è®¡

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”¨æˆ·è¡Œä¸º    â”‚
â”‚  (Web/App)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚  â† äº‹ä»¶æµ
â”‚  (æ¶ˆæ¯é˜Ÿåˆ—)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æµå¼ETLå¤„ç†  â”‚  â† å®æ—¶å¤„ç†
â”‚ (Kafka Connect)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚  â† æ•°æ®å­˜å‚¨
â”‚  - äº‹ä»¶è¡¨   â”‚
â”‚  - ç‰©åŒ–è§†å›¾ â”‚
â”‚  - ç‰¹å¾è¡¨   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨èæœåŠ¡     â”‚  â† æ¨èAPI
â”‚ (FastAPI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ•°æ®æµè®¾è®¡

**æ•°æ®æµè·¯å¾„**ï¼š

1. **ç”¨æˆ·è¡Œä¸ºé‡‡é›†**
   - ç”¨æˆ·æµè§ˆã€ç‚¹å‡»ã€è´­ä¹°ç­‰è¡Œä¸º
   - é€šè¿‡åŸ‹ç‚¹SDKå‘é€åˆ°Kafka

2. **æµå¼å¤„ç†**
   - Kafka Connectæ¶ˆè´¹äº‹ä»¶
   - æ•°æ®æ¸…æ´—ã€å»é‡ã€è½¬æ¢
   - å†™å…¥PostgreSQLäº‹ä»¶è¡¨

3. **ç‰¹å¾è®¡ç®—**
   - åŸºäºäº‹ä»¶è¡¨è®¡ç®—ç”¨æˆ·ç‰¹å¾
   - æ›´æ–°ç‰©åŒ–è§†å›¾
   - å­˜å‚¨ç‰¹å¾åˆ°ç‰¹å¾è¡¨

4. **æ¨èç”Ÿæˆ**
   - æŸ¥è¯¢ç‰©åŒ–è§†å›¾è·å–Top-K
   - ç»“åˆç”¨æˆ·ç‰¹å¾ç”Ÿæˆæ¨è
   - è¿”å›æ¨èç»“æœ

### 3.3 å­˜å‚¨è®¾è®¡

**æ ¸å¿ƒè¡¨ç»“æ„**ï¼š

```sql
-- ç”¨æˆ·è¡Œä¸ºäº‹ä»¶è¡¨
CREATE TABLE user_events (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    item_id BIGINT NOT NULL,
    event_type VARCHAR(50) NOT NULL,  -- click, view, purchase
    event_time TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    score NUMERIC,
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_user_events_user_time ON user_events(user_id, event_time DESC);
CREATE INDEX idx_user_events_item_time ON user_events(item_id, event_time DESC);
CREATE INDEX idx_user_events_type_time ON user_events(event_type, event_time DESC);

-- ç‰©åŒ–è§†å›¾ï¼šå®æ—¶Top-Kå•†å“
CREATE MATERIALIZED VIEW mv_top_items AS
SELECT
    item_id,
    COUNT(*) AS click_count,
    COUNT(DISTINCT user_id) AS user_count,
    AVG(score) AS avg_score,
    MAX(event_time) AS last_event_time
FROM user_events
WHERE event_type = 'click'
  AND event_time > NOW() - INTERVAL '1 hour'
GROUP BY item_id
ORDER BY click_count DESC
LIMIT 1000;

-- åˆ›å»ºå”¯ä¸€ç´¢å¼•æ”¯æŒCONCURRENTLYåˆ·æ–°
CREATE UNIQUE INDEX ON mv_top_items(item_id);
```

---

## å››ã€å®ç°æ–¹æ¡ˆ

### 4.1 æµå¼ETLå®ç°

**ä½¿ç”¨Kafka Connectè¿æ¥PostgreSQL**ï¼š

```yaml
# kafka-connect-postgresqlé…ç½®
{
  "name": "postgresql-sink",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
    "connection.url": "jdbc:postgresql://localhost:5432/recommendation",
    "connection.user": "postgres",
    "connection.password": "password",
    "topics": "user-events",
    "table.name.format": "user_events",
    "insert.mode": "insert",
    "batch.size": "1000",
    "auto.create": "false"
  }
}
```

**ä½¿ç”¨Debezium CDCæ•è·å˜æ›´**ï¼š

```sql
-- å¯ç”¨é€»è¾‘å¤åˆ¶
ALTER SYSTEM SET wal_level = logical;
SELECT pg_reload_conf();

-- åˆ›å»ºå‘å¸ƒ
CREATE PUBLICATION user_events_pub FOR TABLE user_events;
```

### 4.2 ç‰©åŒ–è§†å›¾è®¾è®¡

**å®æ—¶èšåˆç‰©åŒ–è§†å›¾**ï¼š

```sql
-- ç”¨æˆ·è¡Œä¸ºç»Ÿè®¡ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW mv_user_stats AS
SELECT
    user_id,
    COUNT(*) AS total_events,
    COUNT(DISTINCT item_id) AS unique_items,
    COUNT(*) FILTER (WHERE event_type = 'click') AS click_count,
    COUNT(*) FILTER (WHERE event_type = 'purchase') AS purchase_count,
    AVG(score) AS avg_score,
    MAX(event_time) AS last_event_time
FROM user_events
WHERE event_time > NOW() - INTERVAL '7 days'
GROUP BY user_id;

-- åˆ›å»ºç´¢å¼•
CREATE UNIQUE INDEX ON mv_user_stats(user_id);
CREATE INDEX ON mv_user_stats(last_event_time DESC);
```

**å¹¶å‘åˆ·æ–°ç­–ç•¥**ï¼š

```sql
-- å®šæ—¶åˆ·æ–°ç‰©åŒ–è§†å›¾ï¼ˆä¸é˜»å¡æŸ¥è¯¢ï¼‰
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_top_items;
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_user_stats;
```

### 4.3 å¢é‡èšåˆç­–ç•¥

**ä½¿ç”¨çª—å£å‡½æ•°å®ç°å¢é‡èšåˆ**ï¼š

```sql
-- æ»‘åŠ¨çª—å£èšåˆ
CREATE MATERIALIZED VIEW mv_hourly_stats AS
SELECT
    item_id,
    date_trunc('hour', event_time) AS hour,
    COUNT(*) AS event_count,
    COUNT(DISTINCT user_id) AS user_count
FROM user_events
WHERE event_time > NOW() - INTERVAL '24 hours'
GROUP BY item_id, date_trunc('hour', event_time);

-- å¢é‡æ›´æ–°ç­–ç•¥
-- 1. åˆ é™¤è¿‡æœŸæ•°æ®
DELETE FROM mv_hourly_stats
WHERE hour < NOW() - INTERVAL '24 hours';

-- 2. æ’å…¥æ–°æ•°æ®
INSERT INTO mv_hourly_stats
SELECT
    item_id,
    date_trunc('hour', event_time) AS hour,
    COUNT(*) AS event_count,
    COUNT(DISTINCT user_id) AS user_count
FROM user_events
WHERE event_time > NOW() - INTERVAL '1 hour'
GROUP BY item_id, date_trunc('hour', event_time)
ON CONFLICT (item_id, hour) DO UPDATE
SET event_count = mv_hourly_stats.event_count + EXCLUDED.event_count,
    user_count = mv_hourly_stats.user_count + EXCLUDED.user_count;
```

### 4.4 çƒ­ç‚¹å†™å…¥ä¼˜åŒ–

**åˆ†åŒºè¡¨è®¾è®¡**ï¼š

```sql
-- æŒ‰æ—¶é—´åˆ†åŒº
CREATE TABLE user_events (
    id BIGSERIAL,
    user_id BIGINT NOT NULL,
    item_id BIGINT NOT NULL,
    event_type VARCHAR(50) NOT NULL,
    event_time TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    score NUMERIC,
    metadata JSONB
) PARTITION BY RANGE (event_time);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE user_events_2025_01 PARTITION OF user_events
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

-- è‡ªåŠ¨åˆ›å»ºåˆ†åŒºå‡½æ•°ï¼ˆå¸¦å®Œæ•´é”™è¯¯å¤„ç†ï¼‰
CREATE OR REPLACE FUNCTION create_monthly_partition()
RETURNS void
LANGUAGE plpgsql
AS $$
DECLARE
    v_next_month DATE;
    v_partition_name TEXT;
    v_start_date DATE;
    v_end_date DATE;
BEGIN
    -- æ£€æŸ¥ä¸»è¡¨æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'user_events') THEN
        RAISE EXCEPTION 'user_eventsä¸»è¡¨ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºåˆ†åŒº';
    END IF;

    -- è®¡ç®—ä¸‹ä¸ªæœˆçš„æ—¶é—´èŒƒå›´
    v_next_month := date_trunc('month', NOW() + INTERVAL '1 month');
    v_partition_name := 'user_events_' || to_char(v_next_month, 'YYYY_MM');
    v_start_date := v_next_month;
    v_end_date := v_next_month + INTERVAL '1 month';

    -- æ£€æŸ¥åˆ†åŒºæ˜¯å¦å·²å­˜åœ¨
    IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = v_partition_name) THEN
        RAISE NOTICE 'åˆ†åŒºå·²å­˜åœ¨: %', v_partition_name;
        RETURN;
    END IF;

    -- åˆ›å»ºåˆ†åŒº
    BEGIN
        EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF user_events
                        FOR VALUES FROM (%L) TO (%L)',
                       v_partition_name,
                       v_start_date,
                       v_end_date);

        RAISE NOTICE 'åˆ†åŒºåˆ›å»ºæˆåŠŸ: % (FROM % TO %)', v_partition_name, v_start_date, v_end_date;
    EXCEPTION
        WHEN duplicate_table THEN
            RAISE NOTICE 'åˆ†åŒºå·²å­˜åœ¨: %', v_partition_name;
        WHEN undefined_table THEN
            RAISE EXCEPTION 'user_eventsä¸»è¡¨ä¸å­˜åœ¨';
        WHEN OTHERS THEN
            RAISE EXCEPTION 'åˆ›å»ºåˆ†åŒºå¤±è´¥: %', SQLERRM;
    END;

EXCEPTION
    WHEN OTHERS THEN
        RAISE EXCEPTION 'create_monthly_partitionæ‰§è¡Œå¤±è´¥: %', SQLERRM;
END;
$$;
```

**æ‰¹é‡å†™å…¥ä¼˜åŒ–**ï¼š

```python
# Pythonæ‰¹é‡å†™å…¥ç¤ºä¾‹
import psycopg2
from psycopg2.extras import execute_batch

def batch_insert_events(events):
    conn = psycopg2.connect("dbname=recommendation user=postgres")
    cur = conn.cursor()

    # ä½¿ç”¨execute_batchæ‰¹é‡æ’å…¥
    execute_batch(
        cur,
        "INSERT INTO user_events (user_id, item_id, event_type, score) VALUES (%s, %s, %s, %s)",
        events,
        page_size=1000
    )

    conn.commit()
    cur.close()
    conn.close()
```

---

## äº”ã€çŸ¥è¯†çŸ©é˜µå¯¹æ¯”

### 5.1 æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”

| ç»´åº¦ | PostgreSQLç‰©åŒ–è§†å›¾ | Redisç¼“å­˜ | ClickHouse | æ–¹æ¡ˆé€‰æ‹©å»ºè®® |
|------|-------------------|-----------|------------|-------------|
| **å»¶è¿Ÿ** | ç§’çº§ï¼ˆ1-5ç§’ï¼‰ | æ¯«ç§’çº§ï¼ˆ<100msï¼‰ | ç§’çº§ï¼ˆ1-3ç§’ï¼‰ | Redisé€‚åˆæä½å»¶è¿Ÿ |
| **æ•°æ®ä¸€è‡´æ€§** | å¼ºä¸€è‡´æ€§ | æœ€ç»ˆä¸€è‡´æ€§ | æœ€ç»ˆä¸€è‡´æ€§ | PostgreSQLé€‚åˆå¼ºä¸€è‡´æ€§ |
| **æŸ¥è¯¢å¤æ‚åº¦** | æ”¯æŒå¤æ‚SQL | ç®€å•é”®å€¼æŸ¥è¯¢ | æ”¯æŒå¤æ‚æŸ¥è¯¢ | PostgreSQL/ClickHouseé€‚åˆå¤æ‚æŸ¥è¯¢ |
| **å­˜å‚¨æˆæœ¬** | ä¸­ç­‰ | é«˜ï¼ˆå†…å­˜ï¼‰ | ä½ï¼ˆå‹ç¼©ï¼‰ | ClickHouseé€‚åˆå¤§æ•°æ®é‡ |
| **è¿ç»´å¤æ‚åº¦** | ä½ | ä¸­ | é«˜ | PostgreSQLè¿ç»´æœ€ç®€å• |
| **æ‰©å±•æ€§** | å‚ç›´æ‰©å±• | æ°´å¹³æ‰©å±• | æ°´å¹³æ‰©å±• | Redis/ClickHouseæ‰©å±•æ€§å¥½ |
| **é€‚ç”¨åœºæ™¯** | ä¸­å°è§„æ¨¡ | é«˜å¹¶å‘è¯» | å¤§æ•°æ®åˆ†æ | æ ¹æ®åœºæ™¯é€‰æ‹© |

### 5.2 æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | PostgreSQLç‰©åŒ–è§†å›¾ | Redisç¼“å­˜ | ClickHouse |
|------|-------------------|-----------|------------|
| **å†™å…¥QPS** | 10,000+ | 100,000+ | 50,000+ |
| **æŸ¥è¯¢QPS** | 5,000+ | 100,000+ | 10,000+ |
| **æŸ¥è¯¢å»¶è¿Ÿ** | 10-50ms | 1-5ms | 50-200ms |
| **æ•°æ®æ›´æ–°å»¶è¿Ÿ** | 1-5ç§’ | <100ms | 1-3ç§’ |
| **å­˜å‚¨ç©ºé—´** | 1x | 2-3x | 0.3-0.5x |

---

## å…­ã€å®è·µæ¡ˆä¾‹

### 6.1 ç”µå•†å®æ—¶æ¨è

**ä¸šåŠ¡åœºæ™¯**ï¼š

- ç”¨æˆ·æµè§ˆå•†å“åï¼Œå®æ—¶æ¨èç›¸å…³å•†å“
- åŸºäºç”¨æˆ·å†å²è´­ä¹°å’Œæµè§ˆè¡Œä¸º

**å®ç°æ–¹æ¡ˆ**ï¼š

```sql
-- å•†å“ç›¸ä¼¼åº¦ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW mv_item_similarity AS
SELECT
    i1.item_id AS item_id,
    i2.item_id AS similar_item_id,
    COUNT(DISTINCT i1.user_id) AS co_occurrence,
    COUNT(DISTINCT i1.user_id)::NUMERIC /
        (SELECT COUNT(DISTINCT user_id) FROM user_events WHERE item_id = i1.item_id) AS similarity
FROM user_events i1
JOIN user_events i2 ON i1.user_id = i2.user_id
WHERE i1.item_id != i2.item_id
  AND i1.event_time > NOW() - INTERVAL '30 days'
  AND i2.event_time > NOW() - INTERVAL '30 days'
GROUP BY i1.item_id, i2.item_id
HAVING COUNT(DISTINCT i1.user_id) >= 5
ORDER BY i1.item_id, similarity DESC;

-- æ¨èæŸ¥è¯¢
SELECT similar_item_id, similarity
FROM mv_item_similarity
WHERE item_id = 12345
ORDER BY similarity DESC
LIMIT 10;
```

### 6.2 å†…å®¹æ¨èç³»ç»Ÿ

**ä¸šåŠ¡åœºæ™¯**ï¼š

- ç”¨æˆ·é˜…è¯»æ–‡ç« åï¼Œå®æ—¶æ¨èç›¸ä¼¼æ–‡ç« 
- åŸºäºå†…å®¹ç›¸ä¼¼åº¦å’Œç”¨æˆ·å…´è¶£

**å®ç°æ–¹æ¡ˆ**ï¼š

```sql
-- ç”¨æˆ·å…´è¶£ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW mv_user_interests AS
SELECT
    user_id,
    category,
    COUNT(*) AS interest_score,
    MAX(event_time) AS last_interaction
FROM user_events
WHERE event_type IN ('view', 'click', 'share')
  AND event_time > NOW() - INTERVAL '7 days'
GROUP BY user_id, category;

-- å†…å®¹æ¨èæŸ¥è¯¢
SELECT
    a.id,
    a.title,
    a.category,
    COALESCE(ui.interest_score, 0) AS user_interest,
    a.publish_time
FROM articles a
LEFT JOIN mv_user_interests ui ON a.category = ui.category AND ui.user_id = 12345
WHERE a.publish_time > NOW() - INTERVAL '30 days'
ORDER BY user_interest DESC, a.publish_time DESC
LIMIT 20;
```

---

## ä¸ƒã€æ€§èƒ½ä¼˜åŒ–

### 7.1 æŸ¥è¯¢ä¼˜åŒ–

**ç´¢å¼•ä¼˜åŒ–**ï¼š

```sql
-- å¤åˆç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_user_events_user_item_time
ON user_events(user_id, item_id, event_time DESC);

-- éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æœ€è¿‘æ•°æ®ï¼‰
CREATE INDEX idx_user_events_recent
ON user_events(user_id, event_time DESC)
WHERE event_time > NOW() - INTERVAL '7 days';

-- è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX idx_user_events_hour
ON user_events(date_trunc('hour', event_time), item_id);
```

**æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§**ï¼š

```sql
-- ä½¿ç”¨LIMITå‡å°‘æ‰«æ
SELECT * FROM user_events
WHERE user_id = 12345
ORDER BY event_time DESC
LIMIT 100;  -- é™åˆ¶è¿”å›æ•°é‡

-- ä½¿ç”¨è¦†ç›–ç´¢å¼•
CREATE INDEX idx_user_events_covering
ON user_events(user_id, event_time DESC)
INCLUDE (item_id, event_type, score);
```

### 7.2 å†™å…¥ä¼˜åŒ–

**æ‰¹é‡å†™å…¥**ï¼š

```python
# ä½¿ç”¨COPYå‘½ä»¤æ‰¹é‡å¯¼å…¥
import psycopg2
from io import StringIO

def bulk_insert_events(events):
    conn = psycopg2.connect("dbname=recommendation user=postgres")
    cur = conn.cursor()

    # å‡†å¤‡æ•°æ®
    data = StringIO()
    for event in events:
        data.write(f"{event['user_id']}\t{event['item_id']}\t{event['event_type']}\t{event['score']}\n")
    data.seek(0)

    # ä½¿ç”¨COPYå‘½ä»¤
    cur.copy_from(data, 'user_events', columns=('user_id', 'item_id', 'event_type', 'score'))

    conn.commit()
    cur.close()
    conn.close()
```

**è¿æ¥æ± ä¼˜åŒ–**ï¼š

```python
# ä½¿ç”¨è¿æ¥æ± 
from psycopg2 import pool

connection_pool = pool.SimpleConnectionPool(
    1, 20,
    database="recommendation",
    user="postgres",
    password="password"
)

def get_connection():
    return connection_pool.getconn()

def return_connection(conn):
    connection_pool.putconn(conn)
```

### 7.3 ç‰©åŒ–è§†å›¾åˆ·æ–°ä¼˜åŒ–

**å¢é‡åˆ·æ–°ç­–ç•¥**ï¼š

```sql
-- åˆ›å»ºåˆ·æ–°å‡½æ•°
CREATE OR REPLACE FUNCTION refresh_mv_top_items()
RETURNS void AS $$
BEGIN
    -- åˆ é™¤è¿‡æœŸæ•°æ®
    DELETE FROM mv_top_items
    WHERE last_event_time < NOW() - INTERVAL '1 hour';

    -- æ’å…¥æ–°æ•°æ®
    INSERT INTO mv_top_items
    SELECT
        item_id,
        COUNT(*) AS click_count,
        COUNT(DISTINCT user_id) AS user_count,
        AVG(score) AS avg_score,
        MAX(event_time) AS last_event_time
    FROM user_events
    WHERE event_type = 'click'
      AND event_time > NOW() - INTERVAL '1 hour'
    GROUP BY item_id
    ON CONFLICT (item_id) DO UPDATE
    SET click_count = mv_top_items.click_count + EXCLUDED.click_count,
        user_count = GREATEST(mv_top_items.user_count, EXCLUDED.user_count),
        avg_score = (mv_top_items.avg_score * mv_top_items.click_count +
                     EXCLUDED.avg_score * EXCLUDED.click_count) /
                    (mv_top_items.click_count + EXCLUDED.click_count),
        last_event_time = GREATEST(mv_top_items.last_event_time, EXCLUDED.last_event_time);
END;
$$ LANGUAGE plpgsql;

-- å®šæ—¶æ‰§è¡Œ
SELECT cron.schedule('refresh-top-items', '*/5 * * * *', 'SELECT refresh_mv_top_items()');
```

---

## å…«ã€ç›‘æ§ä¸éªŒè¯

### 8.1 å…³é”®æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**ï¼š

- **æŸ¥è¯¢å»¶è¿Ÿ**ï¼šP50, P95, P99å»¶è¿Ÿ
- **å†™å…¥QPS**ï¼šæ¯ç§’å†™å…¥äº‹ä»¶æ•°
- **æŸ¥è¯¢QPS**ï¼šæ¯ç§’æŸ¥è¯¢è¯·æ±‚æ•°
- **ç‰©åŒ–è§†å›¾åˆ·æ–°æ—¶é—´**ï¼šåˆ·æ–°è€—æ—¶

**ä¸šåŠ¡æŒ‡æ ‡**ï¼š

- **æ¨èå‡†ç¡®åº¦**ï¼šç‚¹å‡»ç‡ã€è½¬åŒ–ç‡
- **æ¨èè¦†ç›–ç‡**ï¼šæ¨èå•†å“è¦†ç›–ç‡
- **ç”¨æˆ·æ»¡æ„åº¦**ï¼šç”¨æˆ·åé¦ˆè¯„åˆ†

### 8.2 ç›‘æ§æ–¹æ¡ˆ

**ä½¿ç”¨pg_stat_statementsç›‘æ§æŸ¥è¯¢**ï¼š

```sql
-- å¯ç”¨pg_stat_statements
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- æŸ¥çœ‹æ…¢æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 100  -- å¹³å‡æ‰§è¡Œæ—¶é—´è¶…è¿‡100ms
ORDER BY mean_exec_time DESC
LIMIT 10;
```

**ç›‘æ§ç‰©åŒ–è§†å›¾å¤§å°**ï¼š

```sql
-- æŸ¥çœ‹ç‰©åŒ–è§†å›¾å¤§å°
SELECT
    schemaname,
    matviewname,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||matviewname)) AS size
FROM pg_matviews
ORDER BY pg_total_relation_size(schemaname||'.'||matviewname) DESC;
```

### 8.3 éªŒè¯æ–¹æ³•

**åŠŸèƒ½éªŒè¯**ï¼š

```sql
-- éªŒè¯ç‰©åŒ–è§†å›¾æ•°æ®å‡†ç¡®æ€§
SELECT
    COUNT(*) AS mv_count,
    (SELECT COUNT(*) FROM user_events WHERE event_time > NOW() - INTERVAL '1 hour') AS source_count
FROM mv_top_items;
```

**æ€§èƒ½éªŒè¯**ï¼š

```sql
-- æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
EXPLAIN ANALYZE
SELECT * FROM mv_top_items
ORDER BY click_count DESC
LIMIT 10;
```

---

## ä¹ã€æœ€ä½³å®è·µ

1. **ç‰©åŒ–è§†å›¾è®¾è®¡**
   - åªç‰©åŒ–é¢‘ç¹æŸ¥è¯¢çš„æ•°æ®
   - ä½¿ç”¨CONCURRENTLYåˆ·æ–°é¿å…é˜»å¡
   - å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®

2. **ç´¢å¼•ä¼˜åŒ–**
   - ä¸ºç‰©åŒ–è§†å›¾åˆ›å»ºå”¯ä¸€ç´¢å¼•
   - ä½¿ç”¨éƒ¨åˆ†ç´¢å¼•å‡å°‘ç´¢å¼•å¤§å°
   - å®šæœŸåˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ

3. **åˆ·æ–°ç­–ç•¥**
   - æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾ç½®åˆ·æ–°é¢‘ç‡
   - ä½¿ç”¨å¢é‡åˆ·æ–°å‡å°‘è®¡ç®—é‡
   - ç›‘æ§åˆ·æ–°æ€§èƒ½

4. **æ•°æ®åˆ†åŒº**
   - æŒ‰æ—¶é—´åˆ†åŒºä¾¿äºæ•°æ®ç®¡ç†
   - è‡ªåŠ¨åˆ›å»ºåˆ†åŒºé¿å…é—æ¼
   - å®šæœŸå½’æ¡£å†å²æ•°æ®

5. **ç›‘æ§å‘Šè­¦**
   - ç›‘æ§æŸ¥è¯¢å»¶è¿Ÿå’ŒQPS
   - ç›‘æ§ç‰©åŒ–è§†å›¾åˆ·æ–°æ—¶é—´
   - è®¾ç½®å‘Šè­¦é˜ˆå€¼

---

## åã€å‚è€ƒèµ„æº

### 10.1 å®˜æ–¹æ–‡æ¡£

- [PostgreSQLç‰©åŒ–è§†å›¾æ–‡æ¡£](https://www.postgresql.org/docs/current/sql-creatematerializedview.html)
- [PostgreSQLé€»è¾‘å¤åˆ¶æ–‡æ¡£](https://www.postgresql.org/docs/current/logical-replication.html)
- [PostgreSQLå¹¶å‘æ§åˆ¶æ–‡æ¡£](https://www.postgresql.org/docs/current/mvcc.html)

### 10.2 ç½‘ç»œèµ„æº

- [Kafka Connect PostgreSQL Sink](https://docs.confluent.io/kafka-connect-jdbc/current/sink-connector/index.html)
- [Debezium PostgreSQL Connector](https://debezium.io/documentation/reference/connectors/postgresql.html)
- [PostgreSQLç‰©åŒ–è§†å›¾æœ€ä½³å®è·µ](https://www.postgresql.org/docs/current/rules-materializedviews.html)

### 10.3 å­¦æœ¯è®ºæ–‡

- "Real-time Recommendation Systems: A Survey" - ACM Computing Surveys, 2023
- "Materialized Views in PostgreSQL: Performance and Best Practices" - VLDB, 2022

### 10.4 ç›¸å…³æ¡ˆä¾‹

- [Netflixæ¨èç³»ç»Ÿæ¶æ„](https://netflixtechblog.com/)
- [Amazonæ¨èç³»ç»Ÿå®è·µ](https://www.amazon.science/)

---

## åä¸€ã€äº¤å‰å¼•ç”¨

### ç›¸å…³æ–‡æ¡£

- â­â­â­ [å®æ—¶æ¨èç³»ç»Ÿæ¶æ„](../åº”ç”¨æ¶æ„/07.05-å®æ—¶æ¨èç³»ç»Ÿ.md) - æ¨èç³»ç»Ÿæ¶æ„è®¾è®¡
- â­â­â­ [æ•°æ®ç§‘å­¦å®è·µ](../åº”ç”¨æ¶æ„/07.06-æ•°æ®ç§‘å­¦å®è·µ.md) - æ•°æ®ç§‘å­¦å®Œæ•´æŒ‡å—
- â­â­ [ETLæµç¨‹å®Œæ•´æŒ‡å—](../æ•°æ®æ¨¡å‹è®¾è®¡/09.04-ETLæµç¨‹å®Œæ•´æŒ‡å—.md) - æµå¼ETLå¤„ç†
- â­â­ [æ•°æ®åˆ†æå®Œæ•´æŒ‡å—](../æ•°æ®æ¨¡å‹è®¾è®¡/09.01-æ•°æ®åˆ†æå®Œæ•´æŒ‡å—.md) - æ¨èæ•°æ®åˆ†æ
- â­ [å¤šæ¨¡å‹æ•°æ®åº“](../../../07-å¤šæ¨¡å‹æ•°æ®åº“/README.md) - pgvectorè¯¦ç»†è¯´æ˜

### å¤–éƒ¨èµ„æº

- [PostgreSQLç‰©åŒ–è§†å›¾æ–‡æ¡£](https://www.postgresql.org/docs/current/sql-creatematerializedview.html)
- [PostgreSQLé€»è¾‘å¤åˆ¶æ–‡æ¡£](https://www.postgresql.org/docs/current/logical-replication.html)
- [Kafka Connectæ–‡æ¡£](https://docs.confluent.io/kafka-connect-jdbc/current/sink-connector/index.html)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-22
**PostgreSQLç‰ˆæœ¬**: 18.x (æ¨è) â­ | 17.x (æ¨è) | 16.x (å…¼å®¹)
**ç»´æŠ¤è€…**: Data-Science Team
