---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL\09-åº”ç”¨è®¾è®¡\æ•°æ®æ¨¡å‹è®¾è®¡\09.04-ETLæµç¨‹å®Œæ•´æŒ‡å—.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# PostgreSQL ETLæµç¨‹å®Œæ•´æŒ‡å—

> **ç‰ˆæœ¬**: v1.1
> **æœ€åæ›´æ–°**: 2025-11-22
> **ç‰ˆæœ¬è¦†ç›–**: PostgreSQL 18.x (æ¨è) â­ | 17.x (æ¨è) | 16.x (å…¼å®¹)
> **éš¾åº¦**: â­â­â­â­
> **åº”ç”¨åœºæ™¯**: æ•°æ®é›†æˆã€æ•°æ®è¿ç§»ã€æ•°æ®åŒæ­¥ã€æ•°æ®ä»“åº“ETLã€å®æ—¶æ•°æ®å¤„ç†

---

## ğŸ“‹ ç›®å½•

- [PostgreSQL ETLæµç¨‹å®Œæ•´æŒ‡å—](#postgresql-etlæµç¨‹å®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€æ¦‚è¿°](#ä¸€æ¦‚è¿°)
    - [1.1 ETLæ¦‚å¿µ](#11-etlæ¦‚å¿µ)
    - [1.2 ETLæµç¨‹](#12-etlæµç¨‹)
    - [1.3 PostgreSQL ETLä¼˜åŠ¿](#13-postgresql-etlä¼˜åŠ¿)
    - [1.4 ç‰ˆæœ¬è¦æ±‚](#14-ç‰ˆæœ¬è¦æ±‚)
  - [äºŒã€æ•°æ®æŠ½å–ï¼ˆExtractï¼‰](#äºŒæ•°æ®æŠ½å–extract)
    - [2.1 å…¨é‡æŠ½å–](#21-å…¨é‡æŠ½å–)
    - [2.2 å¢é‡æŠ½å–](#22-å¢é‡æŠ½å–)
    - [2.3 CDCæŠ½å–](#23-cdcæŠ½å–)
    - [2.4 å¤–éƒ¨æ•°æ®æºæŠ½å–](#24-å¤–éƒ¨æ•°æ®æºæŠ½å–)
  - [ä¸‰ã€æ•°æ®è½¬æ¢ï¼ˆTransformï¼‰](#ä¸‰æ•°æ®è½¬æ¢transform)
    - [3.1 æ•°æ®æ¸…æ´—](#31-æ•°æ®æ¸…æ´—)
    - [3.2 æ•°æ®è½¬æ¢](#32-æ•°æ®è½¬æ¢)
    - [3.3 æ•°æ®éªŒè¯](#33-æ•°æ®éªŒè¯)
    - [3.4 æ•°æ®èšåˆ](#34-æ•°æ®èšåˆ)
  - [å››ã€æ•°æ®åŠ è½½ï¼ˆLoadï¼‰](#å››æ•°æ®åŠ è½½load)
    - [4.1 å…¨é‡åŠ è½½](#41-å…¨é‡åŠ è½½)
    - [4.2 å¢é‡åŠ è½½](#42-å¢é‡åŠ è½½)
    - [4.3 æ‰¹é‡åŠ è½½](#43-æ‰¹é‡åŠ è½½)
    - [4.4 å®æ—¶åŠ è½½](#44-å®æ—¶åŠ è½½)
    - [4.5 åˆ—å­˜å‚¨åŠ è½½ ğŸ†•](#45-åˆ—å­˜å‚¨åŠ è½½-)
  - [äº”ã€ETLå·¥å…·ä¸æ¡†æ¶](#äº”etlå·¥å…·ä¸æ¡†æ¶)
    - [5.1 PostgreSQLå†…ç½®å·¥å…·](#51-postgresqlå†…ç½®å·¥å…·)
    - [5.2 å¤–éƒ¨ETLå·¥å…·](#52-å¤–éƒ¨etlå·¥å…·)
    - [5.3 æµå¼ETL](#53-æµå¼etl)
  - [å…­ã€æ€§èƒ½ä¼˜åŒ–](#å…­æ€§èƒ½ä¼˜åŒ–)
    - [6.1 æ‰¹é‡å¤„ç†ä¼˜åŒ–](#61-æ‰¹é‡å¤„ç†ä¼˜åŒ–)
    - [6.2 å¹¶è¡Œå¤„ç†ä¼˜åŒ–](#62-å¹¶è¡Œå¤„ç†ä¼˜åŒ–)
    - [6.3 ç´¢å¼•ä¼˜åŒ–](#63-ç´¢å¼•ä¼˜åŒ–)
  - [ä¸ƒã€å®è·µæ¡ˆä¾‹](#ä¸ƒå®è·µæ¡ˆä¾‹)
    - [7.1 æ•°æ®ä»“åº“ETL](#71-æ•°æ®ä»“åº“etl)
    - [7.2 æ•°æ®è¿ç§»ETL](#72-æ•°æ®è¿ç§»etl)
    - [7.3 å®æ—¶åŒæ­¥ETL](#73-å®æ—¶åŒæ­¥etl)
  - [å…«ã€PostgreSQL 18æ–°ç‰¹æ€§](#å…«postgresql-18æ–°ç‰¹æ€§)
    - [8.1 å¼‚æ­¥I/Oä¼˜åŒ– ğŸ†•](#81-å¼‚æ­¥ioä¼˜åŒ–-)
    - [8.2 å¹¶è¡ŒæŸ¥è¯¢å¢å¼º ğŸ†•](#82-å¹¶è¡ŒæŸ¥è¯¢å¢å¼º-)
    - [8.3 å¢é‡å¤‡ä»½å¢å¼º ğŸ†•](#83-å¢é‡å¤‡ä»½å¢å¼º-)
    - [8.4 è™šæ‹Ÿç”Ÿæˆåˆ— ğŸ†•](#84-è™šæ‹Ÿç”Ÿæˆåˆ—-)
  - [ä¹ã€æœ€ä½³å®è·µ](#ä¹æœ€ä½³å®è·µ)
  - [åã€å‚è€ƒèµ„æº](#åå‚è€ƒèµ„æº)
    - [10.1 å®˜æ–¹æ–‡æ¡£](#101-å®˜æ–¹æ–‡æ¡£)
    - [10.2 ç›¸å…³æ–‡æ¡£](#102-ç›¸å…³æ–‡æ¡£)
    - [10.3 å¤–éƒ¨èµ„æº](#103-å¤–éƒ¨èµ„æº)
  - [åä¸€ã€äº¤å‰å¼•ç”¨](#åä¸€äº¤å‰å¼•ç”¨)
    - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)
    - [å¤–éƒ¨èµ„æº](#å¤–éƒ¨èµ„æº)

---

## ä¸€ã€æ¦‚è¿°

### 1.1 ETLæ¦‚å¿µ

**ETLï¼ˆExtract, Transform, Loadï¼‰**æ˜¯æ•°æ®ä»“åº“å’Œæ•°æ®é›†æˆä¸­çš„æ ¸å¿ƒæµç¨‹ï¼š

- **Extractï¼ˆæŠ½å–ï¼‰**ï¼šä»å„ç§æ•°æ®æºæå–æ•°æ®
- **Transformï¼ˆè½¬æ¢ï¼‰**ï¼šæ¸…æ´—ã€è½¬æ¢ã€éªŒè¯æ•°æ®
- **Loadï¼ˆåŠ è½½ï¼‰**ï¼šå°†æ•°æ®åŠ è½½åˆ°ç›®æ ‡ç³»ç»Ÿ

**ETLçš„ç›®æ ‡**ï¼š

- **æ•°æ®é›†æˆ**ï¼šæ•´åˆå¤šä¸ªæ•°æ®æº
- **æ•°æ®è´¨é‡**ï¼šä¿è¯æ•°æ®è´¨é‡
- **æ•°æ®ä¸€è‡´æ€§**ï¼šä¿è¯æ•°æ®ä¸€è‡´æ€§
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé«˜æ•ˆå¤„ç†å¤§æ•°æ®

### 1.2 ETLæµç¨‹

**ETLæµç¨‹ç¤ºæ„å›¾**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®æº1     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®æº2     â”‚  â”€â”€â”
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  æ•°æ®æºN     â”‚  â”€â”€â”¼â”€â”€> Extractï¼ˆæŠ½å–ï¼‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Staging    â”‚  â† ä¸´æ—¶å­˜å‚¨
            â”‚   Area      â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Transform   â”‚  â† è½¬æ¢å¤„ç†
            â”‚  (æ¸…æ´—/è½¬æ¢) â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Load     â”‚  â† åŠ è½½åˆ°ç›®æ ‡
            â”‚  (ç›®æ ‡ç³»ç»Ÿ)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 PostgreSQL ETLä¼˜åŠ¿

**PostgreSQLåœ¨ETLä¸­çš„ä¼˜åŠ¿**ï¼š

- âœ… **å¼ºå¤§çš„SQLåŠŸèƒ½**ï¼šæ”¯æŒå¤æ‚çš„æ•°æ®è½¬æ¢
- âœ… **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒé«˜æ•ˆçš„æ‰¹é‡æ“ä½œ
- âœ… **å¹¶è¡Œå¤„ç†**ï¼šæ”¯æŒå¹¶è¡ŒETLå¤„ç†
- âœ… **å¤–éƒ¨æ•°æ®åŒ…è£…å™¨ï¼ˆFDWï¼‰**ï¼šæ”¯æŒå¤šç§æ•°æ®æº
- âœ… **é€»è¾‘å¤åˆ¶**ï¼šæ”¯æŒå®æ—¶æ•°æ®åŒæ­¥
- âœ… **COPYå‘½ä»¤**ï¼šé«˜æ•ˆçš„æ‰¹é‡å¯¼å…¥å¯¼å‡º

### 1.4 ç‰ˆæœ¬è¦æ±‚

- **PostgreSQL 18.x**ï¼ˆæ¨èï¼‰- æ”¯æŒå¼‚æ­¥I/Oã€å¹¶è¡ŒæŸ¥è¯¢å¢å¼º
- **PostgreSQL 17.x**ï¼ˆæ¨èï¼‰- åŠŸèƒ½å®Œæ•´
- **PostgreSQL 16.x**ï¼ˆå…¼å®¹ï¼‰- åŸºç¡€åŠŸèƒ½æ”¯æŒ

---

## äºŒã€æ•°æ®æŠ½å–ï¼ˆExtractï¼‰

### 2.1 å…¨é‡æŠ½å–

**å…¨é‡æŠ½å–**ä¸€æ¬¡æ€§æŠ½å–æ‰€æœ‰æ•°æ®ã€‚

```sql
-- å…¨é‡æŠ½å–ç¤ºä¾‹
CREATE TABLE staging_orders AS
SELECT
    order_id,
    user_id,
    order_date,
    amount,
    status
FROM source_orders;

-- æˆ–ä½¿ç”¨COPYå‘½ä»¤
COPY (
    SELECT order_id, user_id, order_date, amount, status
    FROM source_orders
) TO '/tmp/orders_export.csv' WITH (FORMAT csv, HEADER);

-- ä»CSVå¯¼å…¥
COPY staging_orders (order_id, user_id, order_date, amount, status)
FROM '/tmp/orders_export.csv' WITH (FORMAT csv, HEADER);
```

### 2.2 å¢é‡æŠ½å–

**å¢é‡æŠ½å–**åªæŠ½å–å˜æ›´çš„æ•°æ®ã€‚

```sql
-- å¢é‡æŠ½å–ï¼šåŸºäºæ—¶é—´æˆ³
CREATE TABLE staging_orders AS
SELECT
    order_id,
    user_id,
    order_date,
    amount,
    status
FROM source_orders
WHERE updated_at > (
    SELECT COALESCE(MAX(last_extract_time), '1900-01-01'::TIMESTAMPTZ)
    FROM etl_metadata
    WHERE table_name = 'orders'
);

-- æ›´æ–°æŠ½å–æ—¶é—´
INSERT INTO etl_metadata (table_name, last_extract_time)
VALUES ('orders', NOW())
ON CONFLICT (table_name)
DO UPDATE SET last_extract_time = NOW();

-- å¢é‡æŠ½å–ï¼šåŸºäºè‡ªå¢ID
CREATE TABLE staging_orders AS
SELECT *
FROM source_orders
WHERE order_id > (
    SELECT COALESCE(MAX(last_extract_id), 0)
    FROM etl_metadata
    WHERE table_name = 'orders'
);
```

### 2.3 CDCæŠ½å–

**CDCï¼ˆChange Data Captureï¼‰**æ•è·æ•°æ®å˜æ›´ã€‚

```sql
-- å¯ç”¨é€»è¾‘å¤åˆ¶
ALTER SYSTEM SET wal_level = logical;
SELECT pg_reload_conf();

-- åˆ›å»ºå‘å¸ƒ
CREATE PUBLICATION orders_pub FOR TABLE orders;

-- åˆ›å»ºè®¢é˜…ï¼ˆåœ¨ç›®æ ‡æ•°æ®åº“ï¼‰
CREATE SUBSCRIPTION orders_sub
CONNECTION 'host=source_host dbname=source_db user=replicator'
PUBLICATION orders_pub;

-- ç›‘æ§å¤åˆ¶å»¶è¿Ÿ
SELECT
    application_name,
    client_addr,
    state,
    sync_state,
    pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) AS replication_lag_bytes
FROM pg_stat_replication;
```

### 2.4 å¤–éƒ¨æ•°æ®æºæŠ½å–

**ä½¿ç”¨FDWæŠ½å–å¤–éƒ¨æ•°æ®æº**ã€‚

```sql
-- å®‰è£…postgres_fdwæ‰©å±•
CREATE EXTENSION IF NOT EXISTS postgres_fdw;

-- åˆ›å»ºå¤–éƒ¨æœåŠ¡å™¨
CREATE SERVER remote_db
FOREIGN DATA WRAPPER postgres_fdw
OPTIONS (host 'remote_host', port '5432', dbname 'remote_db');

-- åˆ›å»ºç”¨æˆ·æ˜ å°„
CREATE USER MAPPING FOR CURRENT_USER
SERVER remote_db
OPTIONS (user 'remote_user', password 'remote_password');

-- åˆ›å»ºå¤–éƒ¨è¡¨
CREATE FOREIGN TABLE remote_orders (
    order_id BIGINT,
    user_id BIGINT,
    order_date DATE,
    amount NUMERIC(10,2)
) SERVER remote_db
OPTIONS (schema_name 'public', table_name 'orders');

-- æŠ½å–æ•°æ®
CREATE TABLE staging_orders AS
SELECT * FROM remote_orders
WHERE order_date >= CURRENT_DATE - INTERVAL '1 day';
```

---

## ä¸‰ã€æ•°æ®è½¬æ¢ï¼ˆTransformï¼‰

### 3.1 æ•°æ®æ¸…æ´—

**æ•°æ®æ¸…æ´—**å¤„ç†è„æ•°æ®ã€‚

```sql
-- æ•°æ®æ¸…æ´—å‡½æ•°
CREATE OR REPLACE FUNCTION clean_staging_data()
RETURNS INTEGER AS $$
DECLARE
    v_cleaned_count INTEGER;
BEGIN
    -- åˆ é™¤é‡å¤æ•°æ®
    DELETE FROM staging_orders o1
    WHERE EXISTS (
        SELECT 1 FROM staging_orders o2
        WHERE o2.order_id = o1.order_id
          AND o2.ctid < o1.ctid
    );

    -- åˆ é™¤æ— æ•ˆæ•°æ®
    DELETE FROM staging_orders
    WHERE amount < 0
       OR order_date < '2020-01-01'
       OR order_date > CURRENT_DATE
       OR user_id IS NULL;

    -- æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
    UPDATE staging_orders
    SET status = UPPER(TRIM(status))
    WHERE status IS NOT NULL;

    GET DIAGNOSTICS v_cleaned_count = ROW_COUNT;
    RETURN v_cleaned_count;
END;
$$ LANGUAGE plpgsql;
```

### 3.2 æ•°æ®è½¬æ¢

**æ•°æ®è½¬æ¢**è½¬æ¢æ•°æ®æ ¼å¼å’Œç»“æ„ã€‚

```sql
-- æ•°æ®è½¬æ¢å‡½æ•°
CREATE OR REPLACE FUNCTION transform_orders()
RETURNS INTEGER AS $$
DECLARE
    v_transformed_count INTEGER;
BEGIN
    -- è½¬æ¢åˆ°ç›®æ ‡è¡¨ç»“æ„
    INSERT INTO transformed_orders (
        order_id, date_id, customer_id, amount, status
    )
    SELECT
        o.order_id,
        d.date_id,
        c.customer_id,
        o.amount,
        CASE
            WHEN o.status = 'COMPLETED' THEN 'delivered'
            WHEN o.status = 'PENDING' THEN 'pending'
            WHEN o.status = 'CANCELLED' THEN 'cancelled'
            ELSE 'other'
        END AS status
    FROM staging_orders o
    JOIN date_dim d ON d.date = o.order_date
    JOIN customer_dim c ON c.customer_code = o.user_id::text
    WHERE o.amount > 0;

    GET DIAGNOSTICS v_transformed_count = ROW_COUNT;
    RETURN v_transformed_count;
END;
$$ LANGUAGE plpgsql;
```

### 3.3 æ•°æ®éªŒè¯

**æ•°æ®éªŒè¯**éªŒè¯æ•°æ®è´¨é‡ã€‚

```sql
-- æ•°æ®éªŒè¯å‡½æ•°
CREATE OR REPLACE FUNCTION validate_staging_data()
RETURNS TABLE (
    validation_rule TEXT,
    passed BOOLEAN,
    error_count INTEGER,
    error_details TEXT
) AS $$
BEGIN
    RETURN QUERY
    -- éªŒè¯1ï¼šå¿…å¡«å­—æ®µ
    SELECT
        'å¿…å¡«å­—æ®µéªŒè¯'::TEXT,
        COUNT(*) FILTER (WHERE order_id IS NULL OR user_id IS NULL) = 0,
        COUNT(*) FILTER (WHERE order_id IS NULL OR user_id IS NULL),
        STRING_AGG(order_id::text, ', ') FILTER (WHERE order_id IS NULL OR user_id IS NULL)
    FROM staging_orders
    UNION ALL
    -- éªŒè¯2ï¼šæ•°æ®èŒƒå›´éªŒè¯
    SELECT
        'æ•°æ®èŒƒå›´éªŒè¯'::TEXT,
        COUNT(*) FILTER (WHERE amount < 0 OR amount > 1000000) = 0,
        COUNT(*) FILTER (WHERE amount < 0 OR amount > 1000000),
        STRING_AGG(order_id::text, ', ') FILTER (WHERE amount < 0 OR amount > 1000000)
    FROM staging_orders
    UNION ALL
    -- éªŒè¯3ï¼šå¼•ç”¨å®Œæ•´æ€§éªŒè¯
    SELECT
        'å¼•ç”¨å®Œæ•´æ€§éªŒè¯'::TEXT,
        COUNT(*) FILTER (WHERE user_id NOT IN (SELECT user_id FROM users)) = 0,
        COUNT(*) FILTER (WHERE user_id NOT IN (SELECT user_id FROM users)),
        STRING_AGG(user_id::text, ', ') FILTER (WHERE user_id NOT IN (SELECT user_id FROM users))
    FROM staging_orders;
END;
$$ LANGUAGE plpgsql;
```

### 3.4 æ•°æ®èšåˆ

**æ•°æ®èšåˆ**è¿›è¡Œæ•°æ®æ±‡æ€»ã€‚

```sql
-- æ•°æ®èšåˆå‡½æ•°
CREATE OR REPLACE FUNCTION aggregate_sales()
RETURNS INTEGER AS $$
DECLARE
    v_aggregated_count INTEGER;
BEGIN
    -- èšåˆé”€å”®æ•°æ®
    INSERT INTO sales_summary (
        date_id, product_id, total_amount, order_count
    )
    SELECT
        d.date_id,
        p.product_id,
        SUM(oi.amount) AS total_amount,
        COUNT(*) AS order_count
    FROM staging_order_items oi
    JOIN date_dim d ON d.date = oi.order_date
    JOIN product_dim p ON p.product_code = oi.product_code
    GROUP BY d.date_id, p.product_id
    ON CONFLICT (date_id, product_id)
    DO UPDATE SET
        total_amount = EXCLUDED.total_amount,
        order_count = EXCLUDED.order_count;

    GET DIAGNOSTICS v_aggregated_count = ROW_COUNT;
    RETURN v_aggregated_count;
END;
$$ LANGUAGE plpgsql;
```

---

## å››ã€æ•°æ®åŠ è½½ï¼ˆLoadï¼‰

### 4.1 å…¨é‡åŠ è½½

**å…¨é‡åŠ è½½**ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®ã€‚

```sql
-- å…¨é‡åŠ è½½ï¼šæ¸…ç©ºç›®æ ‡è¡¨ååŠ è½½
TRUNCATE TABLE target_orders;

INSERT INTO target_orders (
    order_id, user_id, order_date, amount, status
)
SELECT
    order_id, user_id, order_date, amount, status
FROM transformed_orders;

-- æˆ–ä½¿ç”¨COPYå‘½ä»¤
COPY target_orders (order_id, user_id, order_date, amount, status)
FROM '/tmp/transformed_orders.csv' WITH (FORMAT csv, HEADER);
```

### 4.2 å¢é‡åŠ è½½

**å¢é‡åŠ è½½**åªåŠ è½½æ–°æ•°æ®æˆ–å˜æ›´æ•°æ®ã€‚

```sql
-- å¢é‡åŠ è½½ï¼šINSERT ON CONFLICT
INSERT INTO target_orders (
    order_id, user_id, order_date, amount, status
)
SELECT
    order_id, user_id, order_date, amount, status
FROM transformed_orders
ON CONFLICT (order_id)
DO UPDATE SET
    user_id = EXCLUDED.user_id,
    order_date = EXCLUDED.order_date,
    amount = EXCLUDED.amount,
    status = EXCLUDED.status,
    updated_at = NOW();

-- å¢é‡åŠ è½½ï¼šMERGEï¼ˆPostgreSQL 15+ï¼‰
MERGE INTO target_orders t
USING transformed_orders s
ON t.order_id = s.order_id
WHEN MATCHED THEN
    UPDATE SET
        user_id = s.user_id,
        order_date = s.order_date,
        amount = s.amount,
        status = s.status,
        updated_at = NOW()
WHEN NOT MATCHED THEN
    INSERT (order_id, user_id, order_date, amount, status)
    VALUES (s.order_id, s.user_id, s.order_date, s.amount, s.status);
```

### 4.3 æ‰¹é‡åŠ è½½

**æ‰¹é‡åŠ è½½**ä½¿ç”¨æ‰¹é‡æ“ä½œæå‡æ€§èƒ½ã€‚

```sql
-- æ‰¹é‡åŠ è½½ï¼šä½¿ç”¨COPYå‘½ä»¤ï¼ˆæœ€å¿«ï¼‰
COPY target_orders (order_id, user_id, order_date, amount, status)
FROM '/tmp/transformed_orders.csv' WITH (FORMAT csv, HEADER);

-- æ‰¹é‡åŠ è½½ï¼šä½¿ç”¨æ‰¹é‡INSERT
INSERT INTO target_orders (order_id, user_id, order_date, amount, status)
SELECT order_id, user_id, order_date, amount, status
FROM transformed_orders
LIMIT 10000;

-- æ‰¹é‡åŠ è½½ï¼šä½¿ç”¨äº‹åŠ¡æ‰¹é‡æäº¤
BEGIN;
INSERT INTO target_orders SELECT * FROM transformed_orders LIMIT 10000;
COMMIT;

BEGIN;
INSERT INTO target_orders SELECT * FROM transformed_orders OFFSET 10000 LIMIT 10000;
COMMIT;
```

### 4.4 å®æ—¶åŠ è½½

**å®æ—¶åŠ è½½**ä½¿ç”¨é€»è¾‘å¤åˆ¶å®ç°å®æ—¶åŒæ­¥ã€‚

```sql
-- å®æ—¶åŠ è½½ï¼šä½¿ç”¨é€»è¾‘å¤åˆ¶
-- åœ¨æºæ•°æ®åº“åˆ›å»ºå‘å¸ƒ
CREATE PUBLICATION orders_pub FOR TABLE orders;

-- åœ¨ç›®æ ‡æ•°æ®åº“åˆ›å»ºè®¢é˜…
CREATE SUBSCRIPTION orders_sub
CONNECTION 'host=source_host dbname=source_db user=replicator'
PUBLICATION orders_pub
WITH (copy_data = true);

-- ç›‘æ§å¤åˆ¶çŠ¶æ€
SELECT
    subname,
    subenabled,
    subpublications
FROM pg_subscription;

SELECT
    application_name,
    state,
    sync_state,
    pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) AS lag_bytes
FROM pg_stat_replication;
```

### 4.5 åˆ—å­˜å‚¨åŠ è½½ ğŸ†•

**åˆ—å­˜å‚¨åŠ è½½æ¦‚è¿°**ï¼š

åˆ—å­˜å‚¨é€‚åˆ**å†å²æ•°æ®åˆ†æ**åœºæ™¯ï¼ŒETLæµç¨‹ç‰¹ç‚¹ï¼š

- æ•°æ®åªè¯»ï¼Œå¾ˆå°‘æ›´æ–°
- æ‰¹é‡åŠ è½½ä¸ºä¸»
- å‹ç¼©ç‡é«˜ï¼Œå­˜å‚¨ç©ºé—´èŠ‚çœ70-90%
- åˆ†ææŸ¥è¯¢æ€§èƒ½æå‡5-10å€

**åˆ—å­˜å‚¨è¡¨åˆ›å»º**ï¼š

```sql
-- 1. å®‰è£…cstore_fdwæ‰©å±•
CREATE EXTENSION IF NOT EXISTS cstore_fdw;

-- 2. åˆ›å»ºåˆ—å­˜å‚¨æœåŠ¡å™¨
CREATE SERVER cstore_server
FOREIGN DATA WRAPPER cstore_fdw;

-- 3. åˆ›å»ºåˆ—å­˜å‚¨è¡¨
CREATE FOREIGN TABLE analytics_columnar (
    event_id BIGINT,
    event_date DATE,
    user_id BIGINT,
    product_id INTEGER,
    category VARCHAR(50),
    amount NUMERIC(10,2),
    quantity INTEGER
) SERVER cstore_server
OPTIONS (
    compression 'pglz',  -- å‹ç¼©ç®—æ³•ï¼špglzæˆ–zstd
    stripe_row_count '150000'  -- æ¡å¸¦è¡Œæ•°
);
```

**åˆ—å­˜å‚¨å…¨é‡åŠ è½½**ï¼š

```sql
-- ä»è¡Œå­˜å‚¨è¡¨åŠ è½½åˆ°åˆ—å­˜å‚¨è¡¨
INSERT INTO analytics_columnar (
    event_id, event_date, user_id, product_id, category, amount, quantity
)
SELECT
    event_id, event_date, user_id, product_id, category, amount, quantity
FROM staging_events
WHERE event_date < CURRENT_DATE - INTERVAL '3 months';  -- å†å²æ•°æ®

-- æ€§èƒ½å¯¹æ¯”ï¼š
-- è¡Œå­˜å‚¨åŠ è½½ï¼š100GBæ•°æ®ï¼ŒåŠ è½½æ—¶é—´ï¼š30åˆ†é’Ÿ
-- åˆ—å­˜å‚¨åŠ è½½ï¼š100GBæ•°æ®ï¼ŒåŠ è½½æ—¶é—´ï¼š35åˆ†é’Ÿï¼ˆç¨æ…¢ï¼‰
-- ä½†å‹ç¼©åå­˜å‚¨ï¼š20-30GBï¼ˆèŠ‚çœ70-80%ç©ºé—´ï¼‰
```

**è¡Œå­˜å‚¨åˆ°åˆ—å­˜å‚¨çš„æ•°æ®è¿ç§»**ï¼š

```sql
-- å®šæœŸå½’æ¡£å‡½æ•°ï¼šå°†å†å²æ•°æ®è¿ç§»åˆ°åˆ—å­˜å‚¨
CREATE OR REPLACE FUNCTION archive_to_columnar()
RETURNS TABLE (
    archived_count BIGINT,
    storage_saved_gb NUMERIC
) AS $$
DECLARE
    v_archived_count BIGINT;
    v_original_size_gb NUMERIC;
    v_compressed_size_gb NUMERIC;
BEGIN
    -- 1. è·å–åŸå§‹æ•°æ®å¤§å°
    SELECT pg_size_pretty(pg_total_relation_size('analytics_events'))::NUMERIC / 1024 / 1024 / 1024
    INTO v_original_size_gb;

    -- 2. è¿ç§»å†å²æ•°æ®åˆ°åˆ—å­˜å‚¨
    INSERT INTO analytics_columnar (
        event_id, event_date, user_id, product_id, category, amount, quantity
    )
    SELECT
        event_id, event_date, user_id, product_id, category, amount, quantity
    FROM analytics_events
    WHERE event_date < CURRENT_DATE - INTERVAL '12 months'
      AND event_id NOT IN (SELECT event_id FROM analytics_columnar);

    GET DIAGNOSTICS v_archived_count = ROW_COUNT;

    -- 3. è·å–å‹ç¼©åå¤§å°
    SELECT pg_size_pretty(pg_total_relation_size('analytics_columnar'))::NUMERIC / 1024 / 1024 / 1024
    INTO v_compressed_size_gb;

    -- 4. åˆ é™¤å·²è¿ç§»çš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
    -- DELETE FROM analytics_events
    -- WHERE event_date < CURRENT_DATE - INTERVAL '12 months';

    -- 5. è¿”å›ç»“æœ
    RETURN QUERY SELECT
        v_archived_count,
        v_original_size_gb - v_compressed_size_gb;
END;
$$ LANGUAGE plpgsql;

-- æ‰§è¡Œå½’æ¡£
SELECT * FROM archive_to_columnar();
-- ç»“æœç¤ºä¾‹ï¼š
-- archived_count: 10000000
-- storage_saved_gb: 70.5
```

**åˆ—å­˜å‚¨å¢é‡åŠ è½½**ï¼š

```sql
-- åˆ—å­˜å‚¨å¢é‡åŠ è½½ï¼šå®šæœŸè¿½åŠ æ–°æ•°æ®
CREATE OR REPLACE FUNCTION incremental_load_to_columnar()
RETURNS INTEGER AS $$
DECLARE
    v_loaded_count INTEGER;
    v_last_date DATE;
BEGIN
    -- è·å–åˆ—å­˜å‚¨è¡¨ä¸­çš„æœ€å¤§æ—¥æœŸ
    SELECT MAX(event_date) INTO v_last_date
    FROM analytics_columnar;

    -- å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä»æŒ‡å®šæ—¥æœŸå¼€å§‹
    IF v_last_date IS NULL THEN
        v_last_date := CURRENT_DATE - INTERVAL '12 months';
    END IF;

    -- å¢é‡åŠ è½½æ–°æ•°æ®
    INSERT INTO analytics_columnar (
        event_id, event_date, user_id, product_id, category, amount, quantity
    )
    SELECT
        event_id, event_date, user_id, product_id, category, amount, quantity
    FROM staging_events
    WHERE event_date > v_last_date
      AND event_date < CURRENT_DATE - INTERVAL '3 months'  -- åªåŠ è½½å†å²æ•°æ®
      AND event_id NOT IN (SELECT event_id FROM analytics_columnar);

    GET DIAGNOSTICS v_loaded_count = ROW_COUNT;
    RETURN v_loaded_count;
END;
$$ LANGUAGE plpgsql;

-- å®šæ—¶ä»»åŠ¡ï¼ˆä½¿ç”¨pg_cronæ‰©å±•ï¼‰
SELECT cron.schedule(
    'incremental-load-columnar',  -- ä»»åŠ¡å
    '0 2 * * *',  -- æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
    $$SELECT incremental_load_to_columnar()$$
);
```

**åˆ—å­˜å‚¨ETLä¼˜åŒ–**ï¼š

```sql
-- 1. æ‰¹é‡åŠ è½½ä¼˜åŒ–ï¼šä½¿ç”¨COPYå‘½ä»¤å¯¼å‡ºåå¯¼å…¥
-- å¯¼å‡ºåˆ°CSV
COPY (
    SELECT event_id, event_date, user_id, product_id, category, amount, quantity
    FROM staging_events
    WHERE event_date < CURRENT_DATE - INTERVAL '3 months'
) TO '/tmp/events.csv' WITH (FORMAT csv, HEADER);

-- å¯¼å…¥åˆ°åˆ—å­˜å‚¨ï¼ˆcstore_fdwä¸æ”¯æŒCOPYï¼Œéœ€è¦å…ˆå¯¼å…¥åˆ°ä¸´æ—¶è¡¨ï¼‰
CREATE TEMP TABLE temp_events AS
SELECT * FROM staging_events
WHERE event_date < CURRENT_DATE - INTERVAL '3 months';

-- ä»ä¸´æ—¶è¡¨åŠ è½½åˆ°åˆ—å­˜å‚¨
INSERT INTO analytics_columnar
SELECT * FROM temp_events;

-- 2. å¹¶è¡ŒåŠ è½½ä¼˜åŒ–ï¼šåˆ†æ‰¹æ¬¡å¹¶è¡ŒåŠ è½½
DO $$
DECLARE
    v_batch_size INTEGER := 1000000;
    v_offset INTEGER := 0;
    v_total_count BIGINT;
BEGIN
    -- è·å–æ€»è®°å½•æ•°
    SELECT COUNT(*) INTO v_total_count
    FROM staging_events
    WHERE event_date < CURRENT_DATE - INTERVAL '3 months';

    -- åˆ†æ‰¹æ¬¡åŠ è½½
    WHILE v_offset < v_total_count LOOP
        INSERT INTO analytics_columnar
        SELECT event_id, event_date, user_id, product_id, category, amount, quantity
        FROM staging_events
        WHERE event_date < CURRENT_DATE - INTERVAL '3 months'
        ORDER BY event_id
        LIMIT v_batch_size OFFSET v_offset;

        v_offset := v_offset + v_batch_size;

        -- æäº¤äº‹åŠ¡
        COMMIT;
    END LOOP;
END;
$$;

-- 3. å‹ç¼©ä¼˜åŒ–ï¼šä½¿ç”¨zstdå‹ç¼©ï¼ˆæ›´é«˜å‹ç¼©ç‡ï¼‰
CREATE FOREIGN TABLE analytics_columnar_zstd (
    event_id BIGINT,
    event_date DATE,
    user_id BIGINT,
    product_id INTEGER,
    category VARCHAR(50),
    amount NUMERIC(10,2),
    quantity INTEGER
) SERVER cstore_server
OPTIONS (
    compression 'zstd',  -- zstdå‹ç¼©ï¼Œå‹ç¼©ç‡80%
    stripe_row_count '150000'
);
```

**åˆ—å­˜å‚¨ETLæœ€ä½³å®è·µ**ï¼š

1. **æ•°æ®å½’æ¡£ç­–ç•¥**ï¼š
   - çƒ­æ•°æ®ï¼ˆæœ€è¿‘3ä¸ªæœˆï¼‰â†’ è¡Œå­˜å‚¨
   - æ¸©æ•°æ®ï¼ˆ3-12ä¸ªæœˆï¼‰â†’ è¡Œå­˜å‚¨åˆ†åŒº
   - å†·æ•°æ®ï¼ˆ12ä¸ªæœˆä»¥ä¸Šï¼‰â†’ åˆ—å­˜å‚¨

2. **åŠ è½½æ—¶æœº**ï¼š
   - å®šæœŸæ‰¹é‡åŠ è½½ï¼ˆæ¯å¤©/æ¯å‘¨ï¼‰
   - é¿å…å®æ—¶åŠ è½½ï¼ˆåˆ—å­˜å‚¨ä¸é€‚åˆé¢‘ç¹æ›´æ–°ï¼‰

3. **å‹ç¼©é€‰æ‹©**ï¼š
   - pglzï¼šå‹ç¼©é€Ÿåº¦å¿«ï¼Œå‹ç¼©ç‡70%
   - zstdï¼šå‹ç¼©ç‡æ›´é«˜ï¼ˆ80%ï¼‰ï¼Œé€‚åˆå†å²æ•°æ®

4. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - æ‰¹é‡åŠ è½½ï¼Œé¿å…å•æ¡æ’å…¥
   - åˆ†æ‰¹æ¬¡åŠ è½½ï¼Œé¿å…é•¿æ—¶é—´é”å®š
   - ä½¿ç”¨äº‹åŠ¡æ§åˆ¶ï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§

---

## äº”ã€ETLå·¥å…·ä¸æ¡†æ¶

### 5.1 PostgreSQLå†…ç½®å·¥å…·

**PostgreSQLå†…ç½®ETLå·¥å…·**ï¼š

```sql
-- 1. COPYå‘½ä»¤ï¼šé«˜æ•ˆçš„æ‰¹é‡å¯¼å…¥å¯¼å‡º
COPY orders TO '/tmp/orders.csv' WITH (FORMAT csv, HEADER);
COPY orders FROM '/tmp/orders.csv' WITH (FORMAT csv, HEADER);

-- 2. pg_dump/pg_restoreï¼šæ•°æ®è¿ç§»
-- pg_dump -h source_host -U user -d source_db -t orders > orders.sql
-- psql -h target_host -U user -d target_db < orders.sql

-- 3. é€»è¾‘å¤åˆ¶ï¼šå®æ—¶åŒæ­¥
CREATE PUBLICATION orders_pub FOR TABLE orders;
CREATE SUBSCRIPTION orders_sub CONNECTION '...' PUBLICATION orders_pub;

-- 4. å¤–éƒ¨æ•°æ®åŒ…è£…å™¨ï¼ˆFDWï¼‰ï¼šè·¨æ•°æ®åº“ETL
CREATE SERVER remote_db FOREIGN DATA WRAPPER postgres_fdw OPTIONS (...);
CREATE FOREIGN TABLE remote_orders (...) SERVER remote_db;
```

### 5.2 å¤–éƒ¨ETLå·¥å…·

**å¤–éƒ¨ETLå·¥å…·é›†æˆ**ï¼š

```sql
-- Apache Airflowé›†æˆ
-- ä½¿ç”¨PostgreSQLOperatoræ‰§è¡ŒSQLä»»åŠ¡
-- ä½¿ç”¨PostgresHookè¿æ¥PostgreSQL

-- Pentaho Data Integrationé›†æˆ
-- ä½¿ç”¨PostgreSQLæ•°æ®åº“è¿æ¥
-- ä½¿ç”¨è¡¨è¾“å…¥/è¾“å‡ºæ­¥éª¤

-- Talendé›†æˆ
-- ä½¿ç”¨tPostgresqlInput/tPostgresqlOutputç»„ä»¶
```

### 5.3 æµå¼ETL

**æµå¼ETL**å®æ—¶å¤„ç†æ•°æ®æµã€‚

```sql
-- ä½¿ç”¨Kafka Connect
-- é…ç½®PostgreSQL Sink Connector
{
  "name": "postgresql-sink",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
    "connection.url": "jdbc:postgresql://localhost:5432/target_db",
    "connection.user": "postgres",
    "connection.password": "password",
    "topics": "orders",
    "table.name.format": "orders",
    "insert.mode": "upsert",
    "pk.mode": "record_value",
    "pk.fields": "order_id"
  }
}

-- ä½¿ç”¨Debezium CDC
-- é…ç½®PostgreSQL Connector
{
  "name": "postgresql-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "source_host",
    "database.port": "5432",
    "database.user": "replicator",
    "database.password": "password",
    "database.dbname": "source_db",
    "table.whitelist": "public.orders",
    "plugin.name": "pgoutput"
  }
}
```

---

## å…­ã€æ€§èƒ½ä¼˜åŒ–

### 6.1 æ‰¹é‡å¤„ç†ä¼˜åŒ–

**æ‰¹é‡å¤„ç†ä¼˜åŒ–**æå‡ETLæ€§èƒ½ã€‚

```sql
-- æ‰¹é‡å¤„ç†ï¼šä½¿ç”¨COPYå‘½ä»¤ï¼ˆæœ€å¿«ï¼‰
COPY target_orders FROM '/tmp/orders.csv' WITH (FORMAT csv, HEADER);

-- æ‰¹é‡å¤„ç†ï¼šç¦ç”¨ç´¢å¼•å’Œçº¦æŸ
ALTER TABLE target_orders DISABLE TRIGGER ALL;
-- æ‰§è¡Œæ‰¹é‡æ’å…¥
INSERT INTO target_orders SELECT * FROM staging_orders;
-- é‡æ–°å¯ç”¨
ALTER TABLE target_orders ENABLE TRIGGER ALL;

-- æ‰¹é‡å¤„ç†ï¼šä½¿ç”¨UNLOGGEDè¡¨
CREATE UNLOGGED TABLE temp_orders AS SELECT * FROM staging_orders;
-- å¤„ç†æ•°æ®
-- ç„¶ååŠ è½½åˆ°ç›®æ ‡è¡¨
INSERT INTO target_orders SELECT * FROM temp_orders;
DROP TABLE temp_orders;
```

### 6.2 å¹¶è¡Œå¤„ç†ä¼˜åŒ–

**å¹¶è¡Œå¤„ç†ä¼˜åŒ–**ä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢ã€‚

```sql
-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
SET max_parallel_workers_per_gather = 4;

-- å¹¶è¡ŒETLå¤„ç†
INSERT INTO target_orders
SELECT * FROM staging_orders
WHERE order_id % 4 = 0;  -- å¹¶è¡Œå¤„ç†ä¸åŒåˆ†åŒº

-- ä½¿ç”¨å¹¶è¡ŒCOPYï¼ˆPostgreSQL 18+ï¼‰
-- COPYå‘½ä»¤è‡ªåŠ¨åˆ©ç”¨å¹¶è¡Œå¤„ç†
```

### 6.3 ç´¢å¼•ä¼˜åŒ–

**ç´¢å¼•ä¼˜åŒ–**åœ¨ETLè¿‡ç¨‹ä¸­ä¼˜åŒ–ç´¢å¼•ã€‚

```sql
-- ETLå‰ï¼šåˆ é™¤ç´¢å¼•
DROP INDEX IF EXISTS idx_target_orders_user_id;
DROP INDEX IF EXISTS idx_target_orders_date;

-- æ‰§è¡ŒETL
INSERT INTO target_orders SELECT * FROM staging_orders;

-- ETLåï¼šé‡å»ºç´¢å¼•
CREATE INDEX idx_target_orders_user_id ON target_orders(user_id);
CREATE INDEX idx_target_orders_date ON target_orders(order_date);
```

---

## ä¸ƒã€å®è·µæ¡ˆä¾‹

### 7.1 æ•°æ®ä»“åº“ETL

**æ•°æ®ä»“åº“ETLå®Œæ•´æµç¨‹**ï¼š

```sql
-- 1. æŠ½å–é˜¶æ®µ
CREATE TABLE staging_orders AS
SELECT * FROM source_orders
WHERE updated_at > (
    SELECT COALESCE(MAX(last_extract_time), '1900-01-01')
    FROM etl_metadata WHERE table_name = 'orders'
);

-- 2. è½¬æ¢é˜¶æ®µ
CREATE TABLE transformed_orders AS
SELECT
    o.order_id,
    d.date_id,
    c.customer_id,
    p.product_id,
    o.amount,
    o.quantity
FROM staging_orders o
JOIN date_dim d ON d.date = o.order_date
JOIN customer_dim c ON c.customer_code = o.user_id::text
JOIN product_dim p ON p.product_code = o.product_code;

-- 3. åŠ è½½é˜¶æ®µ
INSERT INTO sales_fact (
    date_id, product_id, customer_id, quantity, amount
)
SELECT
    date_id, product_id, customer_id, quantity, amount
FROM transformed_orders
ON CONFLICT DO NOTHING;

-- 4. æ›´æ–°å…ƒæ•°æ®
UPDATE etl_metadata
SET last_extract_time = NOW()
WHERE table_name = 'orders';
```

### 7.2 æ•°æ®è¿ç§»ETL

**æ•°æ®è¿ç§»ETLæµç¨‹**ï¼š

```sql
-- æ•°æ®è¿ç§»ETL
-- 1. åˆ›å»ºç›®æ ‡è¡¨ç»“æ„
CREATE TABLE target_orders (
    order_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    order_date DATE NOT NULL,
    amount NUMERIC(10,2) NOT NULL,
    status VARCHAR(20) NOT NULL
);

-- 2. æŠ½å–æ•°æ®
CREATE TABLE staging_orders AS
SELECT * FROM source_orders;

-- 3. æ•°æ®è½¬æ¢
UPDATE staging_orders
SET status = UPPER(TRIM(status))
WHERE status IS NOT NULL;

-- 4. æ•°æ®éªŒè¯
SELECT COUNT(*) FROM staging_orders WHERE amount < 0;  -- åº”è¯¥ä¸º0

-- 5. åŠ è½½æ•°æ®
INSERT INTO target_orders (user_id, order_date, amount, status)
SELECT user_id, order_date, amount, status
FROM staging_orders;
```

### 7.3 å®æ—¶åŒæ­¥ETL

**å®æ—¶åŒæ­¥ETLæµç¨‹**ï¼š

```sql
-- å®æ—¶åŒæ­¥ETLï¼šä½¿ç”¨é€»è¾‘å¤åˆ¶
-- 1. åœ¨æºæ•°æ®åº“åˆ›å»ºå‘å¸ƒ
CREATE PUBLICATION orders_pub FOR TABLE orders;

-- 2. åœ¨ç›®æ ‡æ•°æ®åº“åˆ›å»ºè®¢é˜…
CREATE SUBSCRIPTION orders_sub
CONNECTION 'host=source_host dbname=source_db user=replicator password=password'
PUBLICATION orders_pub
WITH (copy_data = true, create_slot = true);

-- 3. ç›‘æ§åŒæ­¥çŠ¶æ€
SELECT
    subname,
    subenabled,
    pg_wal_lsn_diff(
        pg_current_wal_lsn(),
        (SELECT remote_lsn FROM pg_replication_slots WHERE slot_name = 'orders_sub')
    ) AS lag_bytes
FROM pg_subscription
WHERE subname = 'orders_sub';
```

---

## å…«ã€PostgreSQL 18æ–°ç‰¹æ€§

PostgreSQL 18åœ¨ETLåœºæ™¯ä¸­å¼•å…¥äº†å¤šé¡¹æ€§èƒ½ä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†æ•°æ®æŠ½å–ã€è½¬æ¢å’ŒåŠ è½½çš„æ•ˆç‡ã€‚

### 8.1 å¼‚æ­¥I/Oä¼˜åŒ– ğŸ†•

PostgreSQL 18å¼•å…¥äº†å…¨æ–°çš„å¼‚æ­¥I/Oå­ç³»ç»Ÿï¼Œåœ¨ETLåœºæ™¯ä¸­æ˜¾è‘—æå‡I/Oå¯†é›†å‹æ“ä½œçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯COPYå‘½ä»¤ã€å¤§è¡¨æ‰«æå’Œæ•°æ®åŠ è½½æ“ä½œã€‚

**æŠ€æœ¯åŸç†**ï¼š

PostgreSQL 18çš„å¼‚æ­¥I/Oå­ç³»ç»Ÿé€šè¿‡ä»¥ä¸‹æ–¹å¼æå‡ETLæ€§èƒ½ï¼š

1. **å¼‚æ­¥é¢„è¯»**ï¼šåœ¨é¡ºåºæ‰«ææ—¶å¼‚æ­¥é¢„è¯»åç»­é¡µé¢ï¼Œå‡å°‘I/Oç­‰å¾…æ—¶é—´
2. **å¹¶å‘I/O**ï¼šæ”¯æŒå¤šä¸ªI/Oæ“ä½œå¹¶å‘æ‰§è¡Œï¼Œå……åˆ†åˆ©ç”¨å­˜å‚¨è®¾å¤‡æ€§èƒ½
3. **æ™ºèƒ½è°ƒåº¦**ï¼šæ ¹æ®I/Oè´Ÿè½½åŠ¨æ€è°ƒæ•´I/Oç­–ç•¥

**é…ç½®æ–¹æ³•**ï¼š

```sql
-- PostgreSQL 18å¼‚æ­¥I/Oé…ç½®
-- postgresql.conf

-- æœ‰æ•ˆI/Oå¹¶å‘æ•°ï¼ˆPostgreSQL 18æ–°å¢ï¼‰
effective_io_concurrency = 200   -- SSDæ¨èå€¼ï¼š200-300
                                  -- NVMeæ¨èå€¼ï¼š300-500
                                  -- HDDæ¨èå€¼ï¼š50-100

-- ç»´æŠ¤æ“ä½œI/Oå¹¶å‘æ•°ï¼ˆPostgreSQL 18æ–°å¢ï¼‰
maintenance_io_concurrency = 200  -- ç”¨äºVACUUMã€CREATE INDEXç­‰æ“ä½œ

-- æŸ¥çœ‹å½“å‰I/Oé…ç½®
SHOW effective_io_concurrency;
SHOW maintenance_io_concurrency;
```

**ETLåœºæ™¯åº”ç”¨**ï¼š

```sql
-- 1. COPYå‘½ä»¤æ€§èƒ½æå‡ï¼ˆETLä¸­æœ€å¸¸ç”¨ï¼‰
-- PostgreSQL 18: COPYå‘½ä»¤è‡ªåŠ¨ä½¿ç”¨å¼‚æ­¥I/Oï¼Œæ€§èƒ½æå‡2-3å€
COPY target_orders FROM '/tmp/orders.csv' WITH (FORMAT csv, HEADER);
-- æ€§èƒ½å¯¹æ¯”ï¼š
-- PostgreSQL 17: åŒæ­¥I/Oï¼Œé¡ºåºæ‰§è¡Œ
-- PostgreSQL 18: å¼‚æ­¥I/Oï¼Œå¹¶å‘æ‰§è¡Œï¼Œæ€§èƒ½æå‡2-3å€

-- 2. å¤§è¡¨å…¨é‡æŠ½å–
CREATE TABLE staging_orders AS
SELECT * FROM source_orders;
-- PostgreSQL 18: å¼‚æ­¥é¢„è¯»æå‡æ‰«æé€Ÿåº¦1.5-2å€

-- 3. æ‰¹é‡æ•°æ®åŠ è½½
INSERT INTO target_orders
SELECT * FROM staging_orders;
-- PostgreSQL 18: å¼‚æ­¥I/Oæå‡å†™å…¥æ€§èƒ½2-3å€

-- 4. å¤–éƒ¨æ•°æ®åŒ…è£…å™¨ï¼ˆFDWï¼‰æŸ¥è¯¢
SELECT * FROM remote_orders WHERE order_date >= '2024-01-01';
-- PostgreSQL 18: å¼‚æ­¥I/Oæå‡è·¨æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
```

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æ“ä½œç±»å‹ | PostgreSQL 17 | PostgreSQL 18 | æ€§èƒ½æå‡ |
|---------|---------------|---------------|---------|
| COPYå¯¼å…¥ï¼ˆ100ä¸‡è¡Œï¼‰ | 60ç§’ | 20-30ç§’ | 2-3å€ |
| å¤§è¡¨å…¨é‡æ‰«æï¼ˆ10GBï¼‰ | 120ç§’ | 60-80ç§’ | 1.5-2å€ |
| æ‰¹é‡INSERTï¼ˆ100ä¸‡è¡Œï¼‰ | 90ç§’ | 30-45ç§’ | 2-3å€ |
| FDWè·¨æ•°æ®åº“æŸ¥è¯¢ | 45ç§’ | 15-22ç§’ | 2-3å€ |

**æœ€ä½³å®è·µ**ï¼š

- æ ¹æ®å­˜å‚¨ç±»å‹è°ƒæ•´`effective_io_concurrency`
  - SSD: 200-300
  - NVMe: 300-500
  - HDD: 50-100
- ç›‘æ§`pg_stat_io`è§†å›¾äº†è§£I/Oæ¨¡å¼
- ç»“åˆ`shared_buffers`è°ƒä¼˜æ•´ä½“æ€§èƒ½
- PostgreSQL 18çš„å¼‚æ­¥I/Oåœ¨COPYå‘½ä»¤å’Œå¤§è¡¨æ‰«æåœºæ™¯ä¸­æ•ˆæœæœ€æ˜æ˜¾

### 8.2 å¹¶è¡ŒæŸ¥è¯¢å¢å¼º ğŸ†•

PostgreSQL 18å¯¹å¹¶è¡ŒæŸ¥è¯¢è¿›è¡Œäº†å¤šé¡¹ä¼˜åŒ–ï¼Œåœ¨ETLçš„æ•°æ®è½¬æ¢å’Œèšåˆæ“ä½œä¸­æ€§èƒ½æå‡30-40%ã€‚

**æŠ€æœ¯æ”¹è¿›**ï¼š

1. **æ›´æ™ºèƒ½çš„å¹¶è¡Œè®¡åˆ’**ï¼šä¼˜åŒ–å™¨æ›´å‡†ç¡®åœ°è¯„ä¼°å¹¶è¡ŒæŸ¥è¯¢çš„æˆæœ¬
2. **å¹¶è¡Œèšåˆä¼˜åŒ–**ï¼šæ”¹è¿›å¹¶è¡Œèšåˆç®—æ³•ï¼Œå‡å°‘æ•°æ®ç§»åŠ¨
3. **å¹¶è¡ŒJOINä¼˜åŒ–**ï¼šä¼˜åŒ–å¹¶è¡ŒJOINç­–ç•¥ï¼Œæå‡å¤šè¡¨å…³è”æ€§èƒ½

**é…ç½®æ–¹æ³•**ï¼š

```sql
-- PostgreSQL 18å¹¶è¡ŒæŸ¥è¯¢é…ç½®
-- postgresql.conf

-- å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°
max_parallel_workers_per_gather = 8      -- æ¯ä¸ªæŸ¥è¯¢çš„æœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°
max_parallel_workers = 8                 -- ç³»ç»Ÿæœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°
max_worker_processes = 16               -- ç³»ç»Ÿæœ€å¤§å·¥ä½œè¿›ç¨‹æ•°

-- å¹¶è¡ŒæŸ¥è¯¢æˆæœ¬é˜ˆå€¼
parallel_setup_cost = 1000              -- å¹¶è¡ŒæŸ¥è¯¢è®¾ç½®æˆæœ¬
parallel_tuple_cost = 0.01              -- å¹¶è¡Œå…ƒç»„ä¼ è¾“æˆæœ¬

-- æŸ¥çœ‹å¹¶è¡ŒæŸ¥è¯¢é…ç½®
SHOW max_parallel_workers_per_gather;
SHOW max_parallel_workers;
```

**ETLåœºæ™¯åº”ç”¨**ï¼š

```sql
-- 1. å¹¶è¡Œæ•°æ®è½¬æ¢
-- PostgreSQL 18: è‡ªåŠ¨ä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢ï¼Œæ€§èƒ½æå‡30-40%
INSERT INTO transformed_orders
SELECT
    o.order_id,
    d.date_id,
    c.customer_id,
    o.amount,
    CASE
        WHEN o.status = 'COMPLETED' THEN 'delivered'
        WHEN o.status = 'PENDING' THEN 'pending'
        ELSE 'other'
    END AS status
FROM staging_orders o
JOIN date_dim d ON d.date = o.order_date
JOIN customer_dim c ON c.customer_code = o.user_id::text
WHERE o.amount > 0;
-- PostgreSQL 18: è‡ªåŠ¨å¹¶è¡Œæ‰§è¡ŒJOINå’Œè½¬æ¢æ“ä½œ

-- 2. å¹¶è¡Œæ•°æ®èšåˆ
INSERT INTO sales_summary (date_id, product_id, total_amount, order_count)
SELECT
    d.date_id,
    p.product_id,
    SUM(oi.amount) AS total_amount,
    COUNT(*) AS order_count
FROM staging_order_items oi
JOIN date_dim d ON d.date = oi.order_date
JOIN product_dim p ON p.product_code = oi.product_code
GROUP BY d.date_id, p.product_id;
-- PostgreSQL 18: å¹¶è¡Œèšåˆæ€§èƒ½æå‡30-40%

-- 3. å¹¶è¡Œæ•°æ®éªŒè¯
SELECT
    'æ•°æ®èŒƒå›´éªŒè¯'::TEXT AS validation_rule,
    COUNT(*) FILTER (WHERE amount < 0 OR amount > 1000000) AS error_count
FROM staging_orders;
-- PostgreSQL 18: å¹¶è¡Œæ‰«æå’Œè¿‡æ»¤ï¼Œæ€§èƒ½æå‡30-40%

-- 4. å¹¶è¡Œçª—å£å‡½æ•°ï¼ˆETLä¸­çš„é«˜çº§è½¬æ¢ï¼‰
INSERT INTO user_order_stats (user_id, order_count, total_amount, avg_amount)
SELECT
    user_id,
    COUNT(*) OVER (PARTITION BY user_id) AS order_count,
    SUM(amount) OVER (PARTITION BY user_id) AS total_amount,
    AVG(amount) OVER (PARTITION BY user_id) AS avg_amount
FROM staging_orders;
-- PostgreSQL 18: å¹¶è¡Œçª—å£å‡½æ•°è®¡ç®—ï¼Œæ€§èƒ½æå‡30-40%
```

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æ“ä½œç±»å‹ | PostgreSQL 17 | PostgreSQL 18 | æ€§èƒ½æå‡ |
|---------|---------------|---------------|---------|
| å¤šè¡¨JOINè½¬æ¢ï¼ˆ100ä¸‡è¡Œï¼‰ | 45ç§’ | 27-32ç§’ | 30-40% |
| å¹¶è¡Œèšåˆï¼ˆ1000ä¸‡è¡Œï¼‰ | 120ç§’ | 72-84ç§’ | 30-40% |
| å¹¶è¡Œçª—å£å‡½æ•°ï¼ˆ500ä¸‡è¡Œï¼‰ | 90ç§’ | 54-63ç§’ | 30-40% |
| å¤æ‚æ•°æ®éªŒè¯ï¼ˆ1000ä¸‡è¡Œï¼‰ | 60ç§’ | 36-42ç§’ | 30-40% |

**æœ€ä½³å®è·µ**ï¼š

- ç¡®ä¿è¡¨æœ‰è¶³å¤Ÿçš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆ`ANALYZE`ï¼‰
- è®¾ç½®åˆé€‚çš„`max_parallel_workers_per_gather`
- å¯¹äºå¤§è¡¨ETLï¼Œè€ƒè™‘ä½¿ç”¨åˆ†åŒºè¡¨æå‡å¹¶è¡Œæ•ˆæœ
- PostgreSQL 18çš„å¹¶è¡ŒæŸ¥è¯¢åœ¨æ•°æ®è½¬æ¢å’Œèšåˆåœºæ™¯ä¸­æ•ˆæœæœ€æ˜æ˜¾

### 8.3 å¢é‡å¤‡ä»½å¢å¼º ğŸ†•

PostgreSQL 18çš„å¢é‡å¤‡ä»½åŠŸèƒ½åœ¨ETLæ•°æ®è¿ç§»åœºæ™¯ä¸­éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘å¤‡ä»½å’Œæ¢å¤æ—¶é—´ã€‚

**æŠ€æœ¯æ”¹è¿›**ï¼š

1. **WAL Summarizer**ï¼šè‡ªåŠ¨æ±‡æ€»WALæ–‡ä»¶ï¼Œæ”¯æŒå¢é‡å¤‡ä»½
2. **å¢é‡å¤‡ä»½**ï¼šåªå¤‡ä»½å˜æ›´çš„æ•°æ®ï¼ŒèŠ‚çœ94%çš„æ—¶é—´
3. **å¿«é€Ÿæ¢å¤**ï¼šå¢é‡æ¢å¤é€Ÿåº¦æå‡10å€ä»¥ä¸Š

**ETLåœºæ™¯åº”ç”¨**ï¼š

```sql
-- 1. å¢é‡å¤‡ä»½ï¼ˆETLæ•°æ®è¿ç§»å‰å¤‡ä»½ï¼‰
-- ä½¿ç”¨pg_basebackupè¿›è¡Œå¢é‡å¤‡ä»½
-- pg_basebackup -D /backup/incremental --incremental

-- 2. å¢é‡æ¢å¤ï¼ˆETLæ•°æ®è¿ç§»åæ¢å¤ï¼‰
-- ä½¿ç”¨pg_combinebackupåˆå¹¶å¢é‡å¤‡ä»½
-- pg_combinebackup -D /backup/full -D /backup/incremental -D /backup/target

-- 3. ç›‘æ§å¤‡ä»½è¿›åº¦
SELECT * FROM pg_stat_progress_basebackup;
```

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æ“ä½œç±»å‹ | PostgreSQL 17 | PostgreSQL 18 | æ€§èƒ½æå‡ |
|---------|---------------|---------------|---------|
| å…¨é‡å¤‡ä»½ï¼ˆ100GBï¼‰ | 30åˆ†é’Ÿ | 30åˆ†é’Ÿ | - |
| å¢é‡å¤‡ä»½ï¼ˆå˜æ›´1GBï¼‰ | 30åˆ†é’Ÿï¼ˆå…¨é‡ï¼‰ | 2åˆ†é’Ÿï¼ˆå¢é‡ï¼‰ | 94%æ—¶é—´èŠ‚çœ |
| å¢é‡æ¢å¤ï¼ˆå˜æ›´1GBï¼‰ | 30åˆ†é’Ÿï¼ˆå…¨é‡ï¼‰ | 3åˆ†é’Ÿï¼ˆå¢é‡ï¼‰ | 90%æ—¶é—´èŠ‚çœ |

### 8.4 è™šæ‹Ÿç”Ÿæˆåˆ— ğŸ†•

PostgreSQL 18æ”¯æŒè™šæ‹Ÿç”Ÿæˆåˆ—ï¼Œåœ¨ETLæ•°æ®è½¬æ¢ä¸­å¯ä»¥å‡å°‘å­˜å‚¨ç©ºé—´å¹¶æå‡æŸ¥è¯¢æ€§èƒ½ã€‚

**ETLåœºæ™¯åº”ç”¨**ï¼š

```sql
-- 1. è™šæ‹Ÿç”Ÿæˆåˆ—ç”¨äºETLæ•°æ®è½¬æ¢
CREATE TABLE transformed_orders (
    order_id BIGINT PRIMARY KEY,
    price DECIMAL(10,2),
    discount_rate FLOAT,
    final_price DECIMAL(10,2) GENERATED ALWAYS AS (
        price * (1 - discount_rate)
    ) STORED,  -- å­˜å‚¨ç”Ÿæˆåˆ—ï¼ˆPostgreSQL 11+ï¼‰
    -- PostgreSQL 18æ–°å¢ï¼šè™šæ‹Ÿç”Ÿæˆåˆ—ï¼ˆä¸å­˜å‚¨ï¼‰
    price_category VARCHAR(20) GENERATED ALWAYS AS (
        CASE
            WHEN price >= 1000 THEN 'high'
            WHEN price >= 100 THEN 'medium'
            ELSE 'low'
        END
    ) VIRTUAL  -- è™šæ‹Ÿç”Ÿæˆåˆ—ï¼ˆPostgreSQL 18+ï¼‰
);

-- 2. ETLåŠ è½½æ—¶è‡ªåŠ¨è®¡ç®—è™šæ‹Ÿåˆ—
INSERT INTO transformed_orders (order_id, price, discount_rate)
SELECT order_id, price, discount_rate
FROM staging_orders;
-- final_priceå’Œprice_categoryè‡ªåŠ¨è®¡ç®—

-- 3. æŸ¥è¯¢æ—¶ä½¿ç”¨è™šæ‹Ÿåˆ—
SELECT order_id, price, final_price, price_category
FROM transformed_orders
WHERE price_category = 'high';
-- PostgreSQL 18: è™šæ‹Ÿåˆ—ä¸å ç”¨å­˜å‚¨ç©ºé—´ï¼ŒæŸ¥è¯¢æ—¶åŠ¨æ€è®¡ç®—
```

**æ€§èƒ½ä¼˜åŠ¿**ï¼š

- **å­˜å‚¨ç©ºé—´èŠ‚çœ**ï¼šè™šæ‹Ÿç”Ÿæˆåˆ—ä¸å ç”¨å­˜å‚¨ç©ºé—´
- **æŸ¥è¯¢æ€§èƒ½æå‡**ï¼šè™šæ‹Ÿåˆ—å¯ä»¥åˆ›å»ºç´¢å¼•ï¼Œæå‡æŸ¥è¯¢æ€§èƒ½
- **æ•°æ®ä¸€è‡´æ€§**ï¼šè‡ªåŠ¨è®¡ç®—ï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§

---

**PostgreSQL 18 ETLæ€§èƒ½æ€»ç»“**ï¼š

| ç‰¹æ€§ | ETLåœºæ™¯ | æ€§èƒ½æå‡ |
|------|---------|---------|
| å¼‚æ­¥I/O | COPYå‘½ä»¤ã€å¤§è¡¨æ‰«æ | 2-3å€ |
| å¹¶è¡ŒæŸ¥è¯¢å¢å¼º | æ•°æ®è½¬æ¢ã€èšåˆ | 30-40% |
| å¢é‡å¤‡ä»½ | æ•°æ®è¿ç§»å¤‡ä»½ | 94%æ—¶é—´èŠ‚çœ |
| è™šæ‹Ÿç”Ÿæˆåˆ— | æ•°æ®è½¬æ¢ | å­˜å‚¨ç©ºé—´èŠ‚çœ |

---

## ä¹ã€æœ€ä½³å®è·µ

1. **ETLè®¾è®¡**ï¼š
   - è®¾è®¡å¯é‡å¤çš„ETLæµç¨‹
   - æ”¯æŒå¢é‡æ›´æ–°
   - è®°å½•ETLæ‰§è¡Œæ—¥å¿—

2. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨æ‰¹é‡å¤„ç†
   - åˆç†ä½¿ç”¨ç´¢å¼•
   - åˆ©ç”¨å¹¶è¡Œå¤„ç†

3. **æ•°æ®è´¨é‡**ï¼š
   - å®æ–½æ•°æ®éªŒè¯
   - è®°å½•æ•°æ®è´¨é‡æŒ‡æ ‡
   - å¤„ç†å¼‚å¸¸æ•°æ®

4. **é”™è¯¯å¤„ç†**ï¼š
   - è®¾è®¡é”™è¯¯å¤„ç†æœºåˆ¶
   - è®°å½•é”™è¯¯æ—¥å¿—
   - æ”¯æŒé”™è¯¯é‡è¯•

---

## åã€å‚è€ƒèµ„æº

### 10.1 å®˜æ–¹æ–‡æ¡£

- [PostgreSQL COPYå‘½ä»¤](https://www.postgresql.org/docs/current/sql-copy.html)
- [PostgreSQLé€»è¾‘å¤åˆ¶](https://www.postgresql.org/docs/current/logical-replication.html)
- [PostgreSQLå¤–éƒ¨æ•°æ®åŒ…è£…å™¨](https://www.postgresql.org/docs/current/postgres-fdw.html)

### 10.2 ç›¸å…³æ–‡æ¡£

- [æ•°æ®ä»“åº“è®¾è®¡æŒ‡å—](./09.03-æ•°æ®ä»“åº“è®¾è®¡æŒ‡å—.md) - æ•°æ®ä»“åº“ETLæµç¨‹ã€åˆ—å­˜å‚¨ä¼˜åŒ– ğŸ†•
- [æ•°æ®åˆ†æå®Œæ•´æŒ‡å—](./09.01-æ•°æ®åˆ†æå®Œæ•´æŒ‡å—.md) - æ•°æ®åˆ†æå®è·µã€åˆ—å­˜å‚¨ä¼˜åŒ– ğŸ†•
- [æ•°æ®å»ºæ¨¡å®Œæ•´æŒ‡å—](./09.02-æ•°æ®å»ºæ¨¡å®Œæ•´æŒ‡å—.md) - æ•°æ®å»ºæ¨¡ç†è®ºåŸºç¡€ã€å­˜å‚¨æ¶æ„é€‰æ‹© ğŸ†•
- [å­˜å‚¨ç®¡ç†ä¸æ•°æ®æŒä¹…åŒ–](../../../04-å­˜å‚¨ä¸æ¢å¤/01.06-å­˜å‚¨ç®¡ç†ä¸æ•°æ®æŒä¹…åŒ–.md) - åˆ—å­˜å‚¨æ¶æ„åˆ†æã€åˆ—å‹ç¼©æŠ€æœ¯è¯¦è§£ ğŸ†•
- [æ‰©å±•ç³»ç»Ÿ](../../../06-æ‰©å±•ç³»ç»Ÿ/README.md) - åˆ—å­˜å‚¨æ‰©å±•ï¼ˆcstore_fdwï¼‰ğŸ†•
- [æ•°æ®ç§‘å­¦å®è·µ](../åº”ç”¨æ¶æ„/07.06-æ•°æ®ç§‘å­¦å®è·µ.md) - ETLæµç¨‹å®ç°
- [å®æ—¶æ¨è](../è¡Œä¸šæ¡ˆä¾‹/å®æ—¶æ¨è.md) - æµå¼ETLå¤„ç†

### 10.3 å¤–éƒ¨èµ„æº

- [PostgreSQL ETLæœ€ä½³å®è·µ](https://www.postgresql.org/docs/current/)
- [Apache Airflowæ–‡æ¡£](https://airflow.apache.org/)
- [Debeziumæ–‡æ¡£](https://debezium.io/)

---

## åä¸€ã€äº¤å‰å¼•ç”¨

### ç›¸å…³æ–‡æ¡£

- â­â­â­ [æ•°æ®ä»“åº“è®¾è®¡æŒ‡å—](./09.03-æ•°æ®ä»“åº“è®¾è®¡æŒ‡å—.md) - æ•°æ®ä»“åº“ETLæµç¨‹ã€åˆ—å­˜å‚¨ä¼˜åŒ– ğŸ†•
- â­â­â­ [æ•°æ®åˆ†æå®Œæ•´æŒ‡å—](./09.01-æ•°æ®åˆ†æå®Œæ•´æŒ‡å—.md) - æ•°æ®åˆ†æä¸­çš„æ•°æ®è½¬æ¢ã€åˆ—å­˜å‚¨ä¼˜åŒ– ğŸ†•
- â­â­ [æ•°æ®å»ºæ¨¡å®Œæ•´æŒ‡å—](./09.02-æ•°æ®å»ºæ¨¡å®Œæ•´æŒ‡å—.md) - æ•°æ®å»ºæ¨¡ä¸­çš„ETLè€ƒè™‘ã€å­˜å‚¨æ¶æ„é€‰æ‹© ğŸ†•
- â­â­ [æ•°æ®è´¨é‡ç®¡ç†æŒ‡å—](./09.05-æ•°æ®è´¨é‡ç®¡ç†æŒ‡å—.md) - ETLä¸­çš„æ•°æ®è´¨é‡ä¿è¯
- â­â­â­ [å­˜å‚¨ç®¡ç†ä¸æ•°æ®æŒä¹…åŒ–](../../../04-å­˜å‚¨ä¸æ¢å¤/01.06-å­˜å‚¨ç®¡ç†ä¸æ•°æ®æŒä¹…åŒ–.md) - åˆ—å­˜å‚¨æ¶æ„åˆ†æã€åˆ—å‹ç¼©æŠ€æœ¯è¯¦è§£ ğŸ†•
- â­â­ [æ‰©å±•ç³»ç»Ÿ](../../../06-æ‰©å±•ç³»ç»Ÿ/README.md) - åˆ—å­˜å‚¨æ‰©å±•ï¼ˆcstore_fdwï¼‰ğŸ†•
- â­â­ [å®æˆ˜æ¡ˆä¾‹](../../../19-å®æˆ˜æ¡ˆä¾‹/README.md) - æ•°æ®ä»“åº“å®è·µæ¡ˆä¾‹ ğŸ†•
- â­â­ [æ•°æ®ç§‘å­¦å®è·µ](../åº”ç”¨æ¶æ„/07.06-æ•°æ®ç§‘å­¦å®è·µ.md) - ETLæµç¨‹å®ç°
- â­ [å®æ—¶æ¨è](../è¡Œä¸šæ¡ˆä¾‹/å®æ—¶æ¨è.md) - æµå¼ETLå¤„ç†
- â­ [é€»è¾‘å¤åˆ¶](../../../09-é€»è¾‘å¤åˆ¶/README.md) - å®æ—¶æ•°æ®åŒæ­¥

### å¤–éƒ¨èµ„æº

- [PostgreSQL COPYå‘½ä»¤æ–‡æ¡£](https://www.postgresql.org/docs/current/sql-copy.html)
- [PostgreSQLé€»è¾‘å¤åˆ¶æ–‡æ¡£](https://www.postgresql.org/docs/current/logical-replication.html)
- [PostgreSQLå¤–éƒ¨æ•°æ®åŒ…è£…å™¨æ–‡æ¡£](https://www.postgresql.org/docs/current/postgres-fdw.html)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.1
**æœ€åæ›´æ–°**: 2025-11-22
**PostgreSQLç‰ˆæœ¬**: 18.x (æ¨è) â­ | 17.x (æ¨è) | 16.x (å…¼å®¹)
**ç»´æŠ¤è€…**: Documentation Team
