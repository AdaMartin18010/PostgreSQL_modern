---

> **📋 文档来源**: `PostgreSQL\09-应用设计\数据模型设计\09.07-列存储最佳实践指南.md`
> **📅 复制日期**: 2025-12-22
> **⚠️ 注意**: 本文档为复制版本，原文件保持不变

---

# PostgreSQL列存储最佳实践指南

> **版本**: v1.0
> **创建日期**: 2025-01-15
> **最后更新**: 2025-01-15
> **版本覆盖**: PostgreSQL 18.x (推荐) ⭐ | 17.x (推荐) | 16.x (兼容)
> **难度**: ⭐⭐⭐⭐
> **应用场景**: 列存储设计、优化、运维最佳实践

---

## 📋 目录

- [PostgreSQL列存储最佳实践指南](#postgresql列存储最佳实践指南)
  - [📋 目录](#-目录)
  - [一、概述](#一概述)
    - [1.1 最佳实践概述](#11-最佳实践概述)
    - [1.2 实践原则](#12-实践原则)
  - [二、设计最佳实践](#二设计最佳实践)
    - [2.1 表设计](#21-表设计)
    - [2.2 列选择](#22-列选择)
    - [2.3 数据类型选择](#23-数据类型选择)
    - [2.4 压缩配置](#24-压缩配置)
  - [三、查询最佳实践](#三查询最佳实践)
    - [3.1 列选择优化](#31-列选择优化)
    - [3.2 聚合查询优化](#32-聚合查询优化)
    - [3.3 过滤条件优化](#33-过滤条件优化)
    - [3.4 连接查询优化](#34-连接查询优化)
  - [四、性能优化最佳实践](#四性能优化最佳实践)
    - [4.1 压缩优化](#41-压缩优化)
    - [4.2 查询性能优化](#42-查询性能优化)
    - [4.3 I/O优化](#43-io优化)
    - [4.4 并行查询优化](#44-并行查询优化)
  - [五、运维最佳实践](#五运维最佳实践)
    - [5.1 数据加载](#51-数据加载)
    - [5.2 数据维护](#52-数据维护)
    - [5.3 监控和诊断](#53-监控和诊断)
    - [5.4 备份和恢复](#54-备份和恢复)
  - [六、混合存储架构最佳实践](#六混合存储架构最佳实践)
    - [6.1 热冷数据分离](#61-热冷数据分离)
    - [6.2 数据迁移策略](#62-数据迁移策略)
    - [6.3 查询路由](#63-查询路由)
  - [七、实际案例](#七实际案例)
    - [7.1 电商数据分析案例](#71-电商数据分析案例)
    - [7.2 金融数据仓库案例](#72-金融数据仓库案例)
    - [7.3 日志分析案例](#73-日志分析案例)
  - [八、常见问题与解决方案](#八常见问题与解决方案)
    - [问题1：列存储查询性能不佳](#问题1列存储查询性能不佳)
    - [问题2：列存储表占用空间过大](#问题2列存储表占用空间过大)
    - [问题3：数据加载速度慢](#问题3数据加载速度慢)
  - [九、参考资源](#九参考资源)
    - [相关文档](#相关文档)
    - [外部资源](#外部资源)

---

## 一、概述

### 1.1 最佳实践概述

**列存储最佳实践**是指在设计、开发、运维列存储系统时应该遵循的最佳方法和经验总结。

### 1.2 实践原则

**核心原则**：

1. **选择合适的场景**：列存储适合OLAP分析查询，不适合OLTP事务处理
2. **优化列选择**：只查询需要的列，减少I/O开销
3. **合理使用压缩**：选择合适的压缩算法和参数
4. **混合存储架构**：热数据行存储 + 冷数据列存储
5. **持续监控优化**：监控性能指标，持续优化

---

## 二、设计最佳实践

### 2.1 表设计

**✅ 推荐做法**：

```sql
-- 1. 列存储表设计：宽表设计，包含所有分析需要的列
CREATE FOREIGN TABLE fact_sales_columnar (
    sale_id BIGINT,
    date_id INTEGER,
    product_id INTEGER,
    customer_id INTEGER,
    store_id INTEGER,
    quantity INTEGER,
    amount DECIMAL(10,2),
    cost DECIMAL(10,2),
    profit DECIMAL(10,2),
    discount DECIMAL(10,2),
    tax DECIMAL(10,2)
) SERVER cstore_server
OPTIONS (
    compression 'pglz',
    stripe_row_count '150000'
);

-- 2. 避免频繁更新的列：列存储不适合频繁更新
-- ❌ 不推荐：包含频繁更新的状态列
-- status VARCHAR(20)  -- 如果频繁更新，不适合列存储

-- ✅ 推荐：只包含分析需要的列，状态信息放在行存储表
```

**设计原则**：

- ✅ 宽表设计：包含所有分析需要的列
- ✅ 避免频繁更新：列存储适合只读或很少更新的数据
- ✅ 合理分区：按时间或其他维度分区
- ❌ 避免窄表：避免过多小表，增加查询复杂度

### 2.2 列选择

**✅ 推荐做法**：

```sql
-- 1. 将高基数列放在前面：提高压缩效率
CREATE FOREIGN TABLE analytics_columnar (
    -- 高基数列（如ID、时间戳）
    event_id BIGINT,
    timestamp TIMESTAMPTZ,
    user_id BIGINT,

    -- 低基数列（如状态、类型）
    event_type VARCHAR(50),
    status VARCHAR(20),

    -- 数值列（适合聚合）
    metric_value DOUBLE PRECISION,
    amount DECIMAL(10,2)
) SERVER cstore_server;

-- 2. 避免稀疏列：列存储对稀疏列压缩效果差
-- ❌ 不推荐：大量NULL值的列
-- optional_field TEXT  -- 如果90%以上是NULL，压缩效果差

-- ✅ 推荐：使用默认值或分离到其他表
```

**列选择原则**：

- ✅ 高基数列在前：提高压缩效率
- ✅ 避免稀疏列：NULL值多的列压缩效果差
- ✅ 数值列优先：数值列压缩和聚合性能好
- ❌ 避免大文本列：大文本列压缩效果差

### 2.3 数据类型选择

**✅ 推荐做法**：

```sql
-- 1. 使用合适的数据类型：减少存储空间
CREATE FOREIGN TABLE analytics_columnar (
    -- ✅ 推荐：使用合适大小的整数类型
    id BIGINT,              -- 需要大范围时使用
    status_code SMALLINT,   -- 小范围使用SMALLINT
    quantity INTEGER,       -- 中等范围使用INTEGER

    -- ✅ 推荐：使用DECIMAL而不是REAL（精度要求）
    amount DECIMAL(10,2),   -- 金额使用DECIMAL
    price DECIMAL(8,2),     -- 价格使用DECIMAL

    -- ✅ 推荐：使用TIMESTAMPTZ而不是TEXT
    event_time TIMESTAMPTZ, -- 时间使用TIMESTAMPTZ

    -- ❌ 不推荐：使用TEXT存储结构化数据
    -- metadata TEXT  -- 如果可能，使用JSONB
    metadata JSONB          -- 结构化数据使用JSONB
) SERVER cstore_server;
```

**数据类型选择原则**：

- ✅ 使用合适大小的类型：减少存储空间
- ✅ 数值类型优先：数值类型压缩和聚合性能好
- ✅ 时间类型使用TIMESTAMPTZ：避免字符串转换
- ❌ 避免大文本类型：大文本压缩效果差

### 2.4 压缩配置

**✅ 推荐做法**：

```sql
-- 1. 根据数据特征选择压缩算法
-- 高压缩率需求：使用zstd
CREATE FOREIGN TABLE analytics_zstd (
    id BIGINT,
    metric_value DOUBLE PRECISION
) SERVER cstore_server
OPTIONS (
    compression 'zstd',  -- 压缩率80%
    stripe_row_count '150000'
);

-- 平衡压缩率和性能：使用pglz
CREATE FOREIGN TABLE analytics_pglz (
    id BIGINT,
    metric_value DOUBLE PRECISION
) SERVER cstore_server
OPTIONS (
    compression 'pglz',  -- 压缩率70%，性能好
    stripe_row_count '150000'
);

-- 2. 调整条带行数：影响压缩率和查询性能
-- 大数据量：使用较大的条带行数
OPTIONS (
    stripe_row_count '300000'  -- 大数据量使用大条带
);

-- 小数据量或频繁查询：使用较小的条带行数
OPTIONS (
    stripe_row_count '50000'   -- 小数据量使用小条带
);
```

**压缩配置原则**：

- ✅ 高压缩率需求：使用zstd
- ✅ 平衡需求：使用pglz
- ✅ 根据数据量调整条带行数
- ❌ 避免过度压缩：压缩率过高会影响查询性能

---

## 三、查询最佳实践

### 3.1 列选择优化

**✅ 推荐做法**：

```sql
-- 1. 只查询需要的列：减少I/O开销
-- ❌ 不推荐：查询所有列
SELECT * FROM fact_sales_columnar WHERE date_id = 20230101;

-- ✅ 推荐：只查询需要的列
SELECT product_id, amount, quantity
FROM fact_sales_columnar
WHERE date_id = 20230101;

-- 2. 将过滤列放在前面：提高过滤效率
-- ✅ 推荐：过滤列在前
SELECT product_id, amount
FROM fact_sales_columnar
WHERE date_id BETWEEN 20230101 AND 20231231
  AND product_id IN (1, 2, 3)
  AND amount > 1000;
```

**列选择优化原则**：

- ✅ 只查询需要的列：减少I/O开销50-90%
- ✅ 过滤列在前：提高过滤效率
- ❌ 避免SELECT *：查询所有列会大幅增加I/O

### 3.2 聚合查询优化

**✅ 推荐做法**：

```sql
-- 1. 利用列存储批量聚合优势
-- ✅ 推荐：列存储聚合查询
SELECT
    product_id,
    SUM(amount) as total_amount,
    SUM(quantity) as total_quantity,
    AVG(amount) as avg_amount,
    COUNT(*) as order_count
FROM fact_sales_columnar
WHERE date_id BETWEEN 20230101 AND 20231231
GROUP BY product_id
ORDER BY total_amount DESC
LIMIT 100;

-- 2. 避免在列存储上进行复杂计算
-- ❌ 不推荐：复杂计算
SELECT
    product_id,
    SUM(amount * (1 - discount) * (1 + tax)) as final_amount
FROM fact_sales_columnar
GROUP BY product_id;

-- ✅ 推荐：预先计算或使用物化视图
-- 在ETL阶段计算final_amount，存储到列存储表
```

**聚合查询优化原则**：

- ✅ 利用列存储批量聚合：性能提升10-100倍
- ✅ 预先计算复杂表达式：在ETL阶段计算
- ❌ 避免复杂计算：列存储不适合复杂计算

### 3.3 过滤条件优化

**✅ 推荐做法**：

```sql
-- 1. 使用范围查询：列存储对范围查询优化好
-- ✅ 推荐：范围查询
SELECT product_id, amount
FROM fact_sales_columnar
WHERE date_id BETWEEN 20230101 AND 20231231
  AND amount BETWEEN 100 AND 1000;

-- 2. 使用IN子句：列存储对IN子句优化好
-- ✅ 推荐：IN子句
SELECT product_id, amount
FROM fact_sales_columnar
WHERE product_id IN (1, 2, 3, 4, 5)
  AND date_id = 20230101;

-- 3. 避免复杂条件：列存储对复杂条件支持有限
-- ❌ 不推荐：复杂条件
SELECT product_id, amount
FROM fact_sales_columnar
WHERE (amount > 100 AND amount < 1000) OR (amount > 5000 AND amount < 6000);

-- ✅ 推荐：简化条件或使用UNION
SELECT product_id, amount
FROM fact_sales_columnar
WHERE amount BETWEEN 100 AND 1000
UNION ALL
SELECT product_id, amount
FROM fact_sales_columnar
WHERE amount BETWEEN 5000 AND 6000;
```

**过滤条件优化原则**：

- ✅ 使用范围查询：列存储优化好
- ✅ 使用IN子句：列存储优化好
- ❌ 避免复杂条件：列存储支持有限

### 3.4 连接查询优化

**✅ 推荐做法**：

```sql
-- 1. 列存储表与行存储维度表连接
-- ✅ 推荐：列存储事实表 + 行存储维度表
SELECT
    d.product_name,
    SUM(f.amount) as total_amount,
    SUM(f.quantity) as total_quantity
FROM fact_sales_columnar f
JOIN product_dim d ON f.product_id = d.product_id
WHERE f.date_id BETWEEN 20230101 AND 20231231
GROUP BY d.product_name;

-- 2. 避免列存储表之间的连接
-- ❌ 不推荐：列存储表之间连接
SELECT f1.product_id, SUM(f1.amount) as amount1, SUM(f2.amount) as amount2
FROM fact_sales_columnar f1
JOIN fact_sales_columnar f2 ON f1.product_id = f2.product_id
GROUP BY f1.product_id;

-- ✅ 推荐：预先聚合或使用UNION
-- 分别查询两个表，在应用层合并
```

**连接查询优化原则**：

- ✅ 列存储事实表 + 行存储维度表：性能好
- ❌ 避免列存储表之间连接：性能差
- ✅ 预先聚合：减少连接复杂度

---

## 四、性能优化最佳实践

### 4.1 压缩优化

**✅ 推荐做法**：

```sql
-- 1. 根据数据特征选择压缩算法
-- 数值数据：使用zstd（高压缩率）
CREATE FOREIGN TABLE numeric_data (
    id BIGINT,
    value DOUBLE PRECISION
) SERVER cstore_server
OPTIONS (
    compression 'zstd',
    stripe_row_count '150000'
);

-- 文本数据：使用pglz（平衡压缩率和性能）
CREATE FOREIGN TABLE text_data (
    id BIGINT,
    text_field TEXT
) SERVER cstore_server
OPTIONS (
    compression 'pglz',
    stripe_row_count '150000'
);

-- 2. 监控压缩率
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### 4.2 查询性能优化

**✅ 推荐做法**：

```sql
-- 1. 使用EXPLAIN (ANALYZE, BUFFERS, TIMING)分析查询性能
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT product_id, SUM(amount)
FROM fact_sales_columnar
WHERE date_id BETWEEN 20230101 AND 20231231
GROUP BY product_id;

-- 2. 监控慢查询
SELECT
    query,
    calls,
    total_time,
    mean_time,
    rows
FROM pg_stat_statements
WHERE mean_time > 1000  -- 平均执行时间超过1秒
ORDER BY mean_time DESC
LIMIT 10;
```

### 4.3 I/O优化

**✅ 推荐做法**：

```sql
-- 1. 只查询需要的列：减少I/O
-- ❌ 不推荐
SELECT * FROM fact_sales_columnar WHERE date_id = 20230101;

-- ✅ 推荐
SELECT product_id, amount FROM fact_sales_columnar WHERE date_id = 20230101;

-- 2. 使用分区：减少扫描数据量
-- 按时间分区，只扫描相关分区
SELECT product_id, SUM(amount)
FROM fact_sales_columnar
WHERE date_id BETWEEN 20230101 AND 20230331  -- 只扫描Q1分区
GROUP BY product_id;
```

### 4.4 并行查询优化

**✅ 推荐做法**：

```sql
-- 1. 启用并行查询
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 100;
SET parallel_tuple_cost = 0.01;

-- 2. 使用并行聚合
EXPLAIN (ANALYZE, BUFFERS)
SELECT product_id, SUM(amount)
FROM fact_sales_columnar
WHERE date_id BETWEEN 20230101 AND 20231231
GROUP BY product_id;
-- 应该看到 Gather 节点，表示使用了并行查询
```

---

## 五、运维最佳实践

### 5.1 数据加载

**✅ 推荐做法**：

```sql
-- 1. 批量加载：列存储适合批量加载
-- ✅ 推荐：批量INSERT
INSERT INTO fact_sales_columnar
SELECT sale_id, date_id, product_id, customer_id, store_id,
       quantity, amount, cost, profit
FROM sales_fact
WHERE date_id < 20240101;

-- 2. 分批加载：大数据量分批加载
DO $$
DECLARE
    batch_size INTEGER := 1000000;
    total_rows BIGINT;
    current_offset INTEGER := 0;
BEGIN
    SELECT COUNT(*) INTO total_rows FROM sales_fact WHERE date_id < 20240101;

    WHILE current_offset < total_rows LOOP
        INSERT INTO fact_sales_columnar
        SELECT sale_id, date_id, product_id, customer_id, store_id,
               quantity, amount, cost, profit
        FROM sales_fact
        WHERE date_id < 20240101
        ORDER BY sale_id
        LIMIT batch_size OFFSET current_offset;

        current_offset := current_offset + batch_size;
        RAISE NOTICE 'Loaded % rows', current_offset;
    END LOOP;
END $$;
```

### 5.2 数据维护

**✅ 推荐做法**：

```sql
-- 1. 定期归档：将历史数据迁移到列存储
CREATE OR REPLACE FUNCTION archive_to_columnar()
RETURNS void AS $$
BEGIN
    -- 将12个月前的数据迁移到列存储
    INSERT INTO fact_sales_columnar
    SELECT sale_id, date_id, product_id, customer_id, store_id,
           quantity, amount, cost, profit
    FROM sales_fact
    WHERE date_id < (SELECT date_id FROM date_dim
                     WHERE date = CURRENT_DATE - INTERVAL '12 months')
      AND sale_id NOT IN (SELECT sale_id FROM fact_sales_columnar);

    -- 可选：删除已归档的数据
    -- DELETE FROM sales_fact WHERE date_id < ...;
END;
$$ LANGUAGE plpgsql;

-- 2. 定期执行归档
-- 使用pg_cron或其他调度工具定期执行
```

### 5.3 监控和诊断

**✅ 推荐做法**：

```sql
-- 1. 监控列存储表大小
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size
FROM pg_tables
WHERE schemaname = 'public'
  AND tablename LIKE '%columnar%'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 2. 监控查询性能
SELECT
    query,
    calls,
    total_time,
    mean_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements
WHERE query LIKE '%columnar%'
ORDER BY mean_time DESC
LIMIT 10;
```

### 5.4 备份和恢复

**✅ 推荐做法**：

```sql
-- 1. 列存储表备份：使用pg_dump
-- 备份列存储表定义和数据
pg_dump -h localhost -U postgres -d warehouse -t fact_sales_columnar > columnar_backup.sql

-- 2. 恢复列存储表
psql -h localhost -U postgres -d warehouse < columnar_backup.sql

-- 3. 注意：列存储表是外部表，备份时需要备份数据文件
-- cstore_fdw的数据文件存储在数据目录中，需要单独备份
```

---

## 六、混合存储架构最佳实践

### 6.1 热冷数据分离

**✅ 推荐做法**：

```sql
-- 1. 热数据：行存储（最近3个月）
CREATE TABLE sales_fact_hot (
    sale_id BIGSERIAL PRIMARY KEY,
    date_id INTEGER NOT NULL,
    product_id INTEGER NOT NULL,
    amount DECIMAL(10,2) NOT NULL
) PARTITION BY RANGE (date_id);

-- 2. 冷数据：列存储（3个月以前）
CREATE FOREIGN TABLE sales_fact_cold (
    sale_id BIGINT,
    date_id INTEGER,
    product_id INTEGER,
    amount DECIMAL(10,2)
) SERVER cstore_server
OPTIONS (
    compression 'pglz',
    stripe_row_count '150000'
);

-- 3. 统一查询视图
CREATE VIEW sales_fact_all AS
SELECT sale_id, date_id, product_id, amount
FROM sales_fact_hot
UNION ALL
SELECT sale_id, date_id, product_id, amount
FROM sales_fact_cold;
```

### 6.2 数据迁移策略

**✅ 推荐做法**：

```sql
-- 1. 定期迁移：将热数据迁移到冷数据
CREATE OR REPLACE FUNCTION migrate_hot_to_cold()
RETURNS void AS $$
BEGIN
    -- 将3个月前的数据迁移到列存储
    INSERT INTO sales_fact_cold
    SELECT sale_id, date_id, product_id, amount
    FROM sales_fact_hot
    WHERE date_id < (SELECT date_id FROM date_dim
                     WHERE date = CURRENT_DATE - INTERVAL '3 months')
      AND sale_id NOT IN (SELECT sale_id FROM sales_fact_cold);

    -- 删除已迁移的数据
    DELETE FROM sales_fact_hot
    WHERE date_id < (SELECT date_id FROM date_dim
                     WHERE date = CURRENT_DATE - INTERVAL '3 months');
END;
$$ LANGUAGE plpgsql;
```

### 6.3 查询路由

**✅ 推荐做法**：

```sql
-- 1. 根据查询条件路由到不同的表
CREATE OR REPLACE FUNCTION query_sales(
    start_date_id INTEGER,
    end_date_id INTEGER
)
RETURNS TABLE (
    product_id INTEGER,
    total_amount DECIMAL(10,2)
) AS $$
BEGIN
    -- 如果查询最近3个月，查询热数据表
    IF end_date_id >= (SELECT date_id FROM date_dim
                       WHERE date = CURRENT_DATE - INTERVAL '3 months') THEN
        RETURN QUERY
        SELECT product_id, SUM(amount) as total_amount
        FROM sales_fact_hot
        WHERE date_id BETWEEN start_date_id AND end_date_id
        GROUP BY product_id;
    ELSE
        -- 否则查询冷数据表
        RETURN QUERY
        SELECT product_id, SUM(amount) as total_amount
        FROM sales_fact_cold
        WHERE date_id BETWEEN start_date_id AND end_date_id
        GROUP BY product_id;
    END IF;
END;
$$ LANGUAGE plpgsql;
```

---

## 七、实际案例

### 7.1 电商数据分析案例

**场景**：电商平台需要分析历史订单数据，生成销售报表。

**解决方案**：

```sql
-- 1. 创建列存储表存储历史订单数据
CREATE FOREIGN TABLE orders_columnar (
    order_id BIGINT,
    user_id BIGINT,
    product_id INTEGER,
    order_date DATE,
    amount DECIMAL(10,2),
    quantity INTEGER,
    status VARCHAR(20)
) SERVER cstore_server
OPTIONS (
    compression 'pglz',
    stripe_row_count '150000'
);

-- 2. 定期将历史数据迁移到列存储
-- 保留最近3个月在行存储表，3个月以前迁移到列存储

-- 3. 分析查询：按产品统计销售
SELECT
    product_id,
    SUM(amount) as total_amount,
    SUM(quantity) as total_quantity,
    COUNT(*) as order_count
FROM orders_columnar
WHERE order_date BETWEEN '2023-01-01' AND '2023-12-31'
GROUP BY product_id
ORDER BY total_amount DESC
LIMIT 100;

-- 性能提升：查询时间从30秒降低到3秒，性能提升10倍
```

### 7.2 金融数据仓库案例

**场景**：金融机构需要分析历史交易数据，生成风险报告。

**解决方案**：

```sql
-- 1. 创建列存储表存储历史交易数据
CREATE FOREIGN TABLE transactions_columnar (
    transaction_id BIGINT,
    account_id BIGINT,
    transaction_date DATE,
    amount DECIMAL(15,2),
    transaction_type VARCHAR(50),
    risk_score DECIMAL(5,2)
) SERVER cstore_server
OPTIONS (
    compression 'zstd',  -- 使用zstd获得更高压缩率
    stripe_row_count '200000'
);

-- 2. 风险分析查询
SELECT
    transaction_type,
    COUNT(*) as transaction_count,
    SUM(amount) as total_amount,
    AVG(risk_score) as avg_risk_score
FROM transactions_columnar
WHERE transaction_date BETWEEN '2023-01-01' AND '2023-12-31'
GROUP BY transaction_type
ORDER BY avg_risk_score DESC;

-- 压缩率：原始数据100GB，压缩后20GB，压缩率80%
-- 查询性能：查询时间从60秒降低到5秒，性能提升12倍
```

### 7.3 日志分析案例

**场景**：应用系统需要分析历史日志数据，生成访问统计。

**解决方案**：

```sql
-- 1. 创建列存储表存储日志数据
CREATE FOREIGN TABLE logs_columnar (
    log_id BIGINT,
    timestamp TIMESTAMPTZ,
    user_id BIGINT,
    action VARCHAR(50),
    resource_id BIGINT,
    response_time INTEGER,
    status_code INTEGER
) SERVER cstore_server
OPTIONS (
    compression 'pglz',
    stripe_row_count '150000'
);

-- 2. 访问统计查询
SELECT
    action,
    COUNT(*) as action_count,
    AVG(response_time) as avg_response_time,
    COUNT(CASE WHEN status_code >= 400 THEN 1 END) as error_count
FROM logs_columnar
WHERE timestamp BETWEEN '2023-01-01' AND '2023-12-31'
GROUP BY action
ORDER BY action_count DESC;

-- 性能提升：查询时间从120秒降低到8秒，性能提升15倍
```

---

## 八、常见问题与解决方案

### 问题1：列存储查询性能不佳

**原因**：

- 查询了所有列（SELECT *）
- 使用了复杂的过滤条件
- 压缩算法选择不当

**解决方案**：

- 只查询需要的列
- 简化过滤条件
- 选择合适的压缩算法

### 问题2：列存储表占用空间过大

**原因**：

- 压缩算法选择不当
- 条带行数设置不合理
- 数据类型选择不当

**解决方案**：

- 使用zstd压缩算法
- 增加条带行数
- 使用合适的数据类型

### 问题3：数据加载速度慢

**原因**：

- 单条INSERT
- 没有批量加载
- 压缩开销大

**解决方案**：

- 使用批量INSERT
- 分批加载大数据量
- 选择合适的压缩算法

---

## 九、参考资源

### 相关文档

- [存储管理与数据持久化](../../../04-存储与恢复/01.06-存储管理与数据持久化.md) - 列存储架构分析
- [数据仓库设计指南](./09.03-数据仓库设计指南.md) - 列存储优化
- [数据建模完整指南](./09.02-数据建模完整指南.md) - 存储架构选择
- [列存储技术栈对比指南](./09.06-列存储技术栈对比指南.md) - 技术栈选型
- [执行计划与性能调优](../../../02-查询与优化/02.03-执行计划/02.04-执行计划与性能调优.md) - 列存储查询优化
- [ETL流程完整指南](./09.04-ETL流程完整指南.md) - 列存储数据加载

### 外部资源

- [cstore_fdw GitHub](https://github.com/citusdata/cstore_fdw)
- [PostgreSQL列存储最佳实践](https://www.postgresql.org/docs/current/)

---
