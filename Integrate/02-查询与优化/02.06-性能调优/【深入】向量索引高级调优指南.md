---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQLåŸ¹è®­\11-æ€§èƒ½è°ƒä¼˜\ã€æ·±å…¥ã€‘å‘é‡ç´¢å¼•é«˜çº§è°ƒä¼˜æŒ‡å—.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# å‘é‡ç´¢å¼•é«˜çº§è°ƒä¼˜æŒ‡å—

> **åˆ›å»ºæ—¶é—´**: 2025 å¹´ 12 æœˆ 4 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 18+ with pgvector 0.6.0+
> **æ–‡æ¡£ç¼–å·**: 11-PERF-VECTOR-TUNING

---

## ğŸ“‘ ç›®å½•

- [å‘é‡ç´¢å¼•é«˜çº§è°ƒä¼˜æŒ‡å—](#å‘é‡ç´¢å¼•é«˜çº§è°ƒä¼˜æŒ‡å—)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€æ¦‚è¿°](#ä¸€æ¦‚è¿°)
    - [1.1 ä¸ºä»€ä¹ˆéœ€è¦å‘é‡ç´¢å¼•è°ƒä¼˜](#11-ä¸ºä»€ä¹ˆéœ€è¦å‘é‡ç´¢å¼•è°ƒä¼˜)
    - [1.2 æ ¸å¿ƒä»·å€¼](#12-æ ¸å¿ƒä»·å€¼)
    - [1.3 çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾](#13-çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾)
  - [äºŒã€åŸç†ä¸ç†è®º](#äºŒåŸç†ä¸ç†è®º)
    - [2.1 ANNç®—æ³•æ¦‚è¿°](#21-annç®—æ³•æ¦‚è¿°)
      - [**ç²¾ç¡®vsè¿‘ä¼¼æ£€ç´¢**](#ç²¾ç¡®vsè¿‘ä¼¼æ£€ç´¢)
      - [**ANNç®—æ³•åˆ†ç±»**](#annç®—æ³•åˆ†ç±»)
    - [2.2 HNSWç®—æ³•è¯¦è§£](#22-hnswç®—æ³•è¯¦è§£)
      - [**HNSWç»“æ„**](#hnswç»“æ„)
      - [**å…³é”®å‚æ•°**](#å…³é”®å‚æ•°)
    - [2.3 IVFFlatç®—æ³•è¯¦è§£](#23-ivfflatç®—æ³•è¯¦è§£)
      - [**IVFFlatç»“æ„**](#ivfflatç»“æ„)
      - [**å…³é”®å‚æ•°**](#å…³é”®å‚æ•°-1)
    - [2.4 ç®—æ³•å¯¹æ¯”åˆ†æ](#24-ç®—æ³•å¯¹æ¯”åˆ†æ)
      - [**ç»¼åˆå¯¹æ¯”**](#ç»¼åˆå¯¹æ¯”)
  - [ä¸‰ã€æ¶æ„è®¾è®¡](#ä¸‰æ¶æ„è®¾è®¡)
    - [3.1 ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘](#31-ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘)
    - [3.2 æ··åˆç´¢å¼•ç­–ç•¥](#32-æ··åˆç´¢å¼•ç­–ç•¥)
    - [3.3 åˆ†å¸ƒå¼å‘é‡ç´¢å¼•](#33-åˆ†å¸ƒå¼å‘é‡ç´¢å¼•)
    - [3.4 å®æ—¶æ›´æ–°æ¶æ„](#34-å®æ—¶æ›´æ–°æ¶æ„)
  - [å››ã€ç¨‹åºè®¾è®¡](#å››ç¨‹åºè®¾è®¡)
    - [4.1 HNSWç´¢å¼•è°ƒä¼˜](#41-hnswç´¢å¼•è°ƒä¼˜)
    - [4.2 IVFFlatç´¢å¼•è°ƒä¼˜](#42-ivfflatç´¢å¼•è°ƒä¼˜)
    - [4.3 æŸ¥è¯¢ä¼˜åŒ–](#43-æŸ¥è¯¢ä¼˜åŒ–)
    - [4.4 ç´¢å¼•ç»´æŠ¤](#44-ç´¢å¼•ç»´æŠ¤)
  - [äº”ã€è¿ç»´ç®¡ç†](#äº”è¿ç»´ç®¡ç†)
    - [5.1 ç´¢å¼•è´¨é‡è¯„ä¼°](#51-ç´¢å¼•è´¨é‡è¯„ä¼°)
    - [5.2 æ€§èƒ½ç›‘æ§](#52-æ€§èƒ½ç›‘æ§)
    - [5.3 ç´¢å¼•é‡å»ºç­–ç•¥](#53-ç´¢å¼•é‡å»ºç­–ç•¥)
    - [5.4 æœ€ä½³å®è·µ](#54-æœ€ä½³å®è·µ)
  - [å…­ã€æ¡ˆä¾‹å®æˆ˜](#å…­æ¡ˆä¾‹å®æˆ˜)
    - [6.1 ç™¾ä¸‡çº§å‘é‡ä¼˜åŒ–](#61-ç™¾ä¸‡çº§å‘é‡ä¼˜åŒ–)
    - [6.2 åƒä¸‡çº§å‘é‡ä¼˜åŒ–](#62-åƒä¸‡çº§å‘é‡ä¼˜åŒ–)
    - [6.3 å®æ—¶æ›´æ–°åœºæ™¯](#63-å®æ—¶æ›´æ–°åœºæ™¯)
    - [6.4 é«˜å¹¶å‘åœºæ™¯](#64-é«˜å¹¶å‘åœºæ™¯)
  - [ä¸ƒã€æ€§èƒ½åŸºå‡†æµ‹è¯•](#ä¸ƒæ€§èƒ½åŸºå‡†æµ‹è¯•)
  - [å…«ã€æ€»ç»“ä¸å±•æœ›](#å…«æ€»ç»“ä¸å±•æœ›)
    - [æ ¸å¿ƒæ”¶è·](#æ ¸å¿ƒæ”¶è·)
  - [ä¹ã€å‚è€ƒèµ„æ–™](#ä¹å‚è€ƒèµ„æ–™)

---

## ä¸€ã€æ¦‚è¿°

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦å‘é‡ç´¢å¼•è°ƒä¼˜

**å‘é‡æœç´¢çš„æŒ‘æˆ˜**ï¼š

| æŒ‘æˆ˜ | å½±å“ | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| **ç»´åº¦ç¾éš¾** | é«˜ç»´ç©ºé—´è·ç¦»å¤±æ•ˆ | é™ç»´ã€ç´¢å¼•ä¼˜åŒ– |
| **è§„æ¨¡é—®é¢˜** | ç™¾ä¸‡çº§å‘é‡æœç´¢æ…¢ | HNSW/IVFFlatç´¢å¼• |
| **ç²¾åº¦æƒè¡¡** | ç²¾åº¦vsé€Ÿåº¦çš„å¹³è¡¡ | å‚æ•°è°ƒä¼˜ |
| **å®æ—¶æ›´æ–°** | æ’å…¥å½±å“æŸ¥è¯¢æ€§èƒ½ | å¢é‡æ„å»ºã€æ‰¹å¤„ç† |
| **å†…å­˜å ç”¨** | å¤§ç´¢å¼•æ¶ˆè€—å†…å­˜ | å‹ç¼©ã€åˆ†ç‰‡ |

**æœªä¼˜åŒ– vs ä¼˜åŒ–å**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          å‘é‡æœç´¢æ€§èƒ½å¯¹æ¯”                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                   â”‚
â”‚  åœºæ™¯ï¼š100ä¸‡å‘é‡ï¼Œ1536ç»´ï¼ŒæŸ¥è¯¢Top-10            â”‚
â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ æ–¹æ³•         â”‚ æŸ¥è¯¢æ—¶é—´ â”‚ å¬å›ç‡   â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ æš´åŠ›æœç´¢     â”‚  8.5ç§’  â”‚  100%    â”‚         â”‚
â”‚  â”‚ IVFFlatæœªè°ƒä¼˜â”‚  450ms  â”‚   85%    â”‚         â”‚
â”‚  â”‚ IVFFlatè°ƒä¼˜  â”‚  120ms  â”‚   92%    â”‚  â¬†ï¸ +70%â”‚
â”‚  â”‚ HNSWæœªè°ƒä¼˜   â”‚  180ms  â”‚   90%    â”‚         â”‚
â”‚  â”‚ HNSWè°ƒä¼˜     â”‚   35ms  â”‚   96%    â”‚  â¬†ï¸ +80%â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                   â”‚
â”‚  ğŸ¯ è°ƒä¼˜æ•ˆæœï¼šæŸ¥è¯¢é€Ÿåº¦æå‡ 80%ï¼Œå¬å›ç‡æå‡ 6%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒä»·å€¼

**è°ƒä¼˜æ”¶ç›Š**ï¼š

| ç»´åº¦ | æœªè°ƒä¼˜ | è°ƒä¼˜å | æå‡ |
|------|--------|--------|------|
| **æŸ¥è¯¢å»¶è¿Ÿ (P50)** | 200ms | 40ms | **-80%** |
| **æŸ¥è¯¢å»¶è¿Ÿ (P95)** | 500ms | 95ms | **-81%** |
| **å¬å›ç‡** | 85% | 96% | **+13%** |
| **QPS** | 50 | 250 | **+400%** |
| **å†…å­˜å ç”¨** | 15GB | 8GB | **-47%** |
| **ç´¢å¼•æ„å»ºæ—¶é—´** | 45åˆ†é’Ÿ | 28åˆ†é’Ÿ | **-38%** |

### 1.3 çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((å‘é‡ç´¢å¼•é«˜çº§è°ƒä¼˜))
    åŸç†ä¸ç†è®º
      ANNç®—æ³•
        ç²¾ç¡®æ£€ç´¢
        è¿‘ä¼¼æ£€ç´¢
        ç®—æ³•åˆ†ç±»
      HNSWåŸç†
        å±‚æ¬¡å›¾ç»“æ„
        è´ªå©ªæœç´¢
        å‚æ•°å½±å“
      IVFFlatåŸç†
        èšç±»åˆ’åˆ†
        å€’æ’ç´¢å¼•
        æŸ¥è¯¢æµç¨‹
      ç®—æ³•å¯¹æ¯”
        ç²¾åº¦å¯¹æ¯”
        é€Ÿåº¦å¯¹æ¯”
        å†…å­˜å¯¹æ¯”
    æ¶æ„è®¾è®¡
      ç´¢å¼•é€‰æ‹©
        æ•°æ®è§„æ¨¡
        æŸ¥è¯¢æ¨¡å¼
        ç¡¬ä»¶æ¡ä»¶
      æ··åˆç­–ç•¥
        ç²¾ç¡®+è¿‘ä¼¼
        å¤šé˜¶æ®µæ£€ç´¢
        åˆ†å±‚ç´¢å¼•
      åˆ†å¸ƒå¼ç´¢å¼•
        å‘é‡åˆ†ç‰‡
        æŸ¥è¯¢è·¯ç”±
        è´Ÿè½½å‡è¡¡
      å®æ—¶æ›´æ–°
        å¢é‡æ„å»º
        å¹¶å‘æ§åˆ¶
        ä¸€è‡´æ€§
    ç¨‹åºè®¾è®¡
      HNSWè°ƒä¼˜
        må‚æ•°
        ef_construction
        ef_search
      IVFFlatè°ƒä¼˜
        listsæ•°é‡
        probesæ¢æµ‹
        é‡åŒ–å‹ç¼©
      æŸ¥è¯¢ä¼˜åŒ–
        å‚æ•°è°ƒæ•´
        æ‰¹é‡æŸ¥è¯¢
        ç¼“å­˜ç­–ç•¥
      ç´¢å¼•ç»´æŠ¤
        é‡å»ºæ—¶æœº
        å¢é‡æ›´æ–°
        ç¢ç‰‡æ•´ç†
    è¿ç»´ç®¡ç†
      è´¨é‡è¯„ä¼°
        å¬å›ç‡
        ç²¾åº¦
        å»¶è¿Ÿ
      æ€§èƒ½ç›‘æ§
        æŸ¥è¯¢ç»Ÿè®¡
        ç´¢å¼•å¥åº·
        èµ„æºä½¿ç”¨
      é‡å»ºç­–ç•¥
        è§¦å‘æ¡ä»¶
        é‡å»ºæµç¨‹
        æœ€å°å½±å“
    æ¡ˆä¾‹å®æˆ˜
      ç™¾ä¸‡çº§
        å‚æ•°é…ç½®
        æ€§èƒ½ä¼˜åŒ–
        æœ€ä½³å®è·µ
      åƒä¸‡çº§
        åˆ†ç‰‡ç­–ç•¥
        å¹¶è¡Œæ„å»º
        æŸ¥è¯¢ä¼˜åŒ–
      å®æ—¶æ›´æ–°
        æµå¼æ’å…¥
        å¢é‡ç´¢å¼•
        ä¸€è‡´æ€§
      é«˜å¹¶å‘
        è¿æ¥æ± 
        ç¼“å­˜
        è´Ÿè½½å‡è¡¡
```

---

## äºŒã€åŸç†ä¸ç†è®º

### 2.1 ANNç®—æ³•æ¦‚è¿°

#### **ç²¾ç¡®vsè¿‘ä¼¼æ£€ç´¢**

```python
# 1. ç²¾ç¡®æ£€ç´¢ï¼ˆæš´åŠ›æœç´¢ï¼‰
def exact_search(query_vector, vectors, k=10):
    """ç²¾ç¡®çš„kè¿‘é‚»æœç´¢"""
    distances = []
    for i, vec in enumerate(vectors):
        dist = cosine_distance(query_vector, vec)
        distances.append((i, dist))

    # æ’åºå¹¶è¿”å›top-k
    distances.sort(key=lambda x: x[1])
    return distances[:k]

# æ—¶é—´å¤æ‚åº¦ï¼šO(n*d)ï¼Œn=å‘é‡æ•°é‡ï¼Œd=ç»´åº¦
# ç©ºé—´å¤æ‚åº¦ï¼šO(n*d)
# 100ä¸‡å‘é‡ Ã— 1536ç»´ = çº¦6GBå†…å­˜ + 8ç§’æŸ¥è¯¢æ—¶é—´

# 2. è¿‘ä¼¼æ£€ç´¢ï¼ˆANNï¼‰
def approximate_search(query_vector, index, k=10):
    """è¿‘ä¼¼kè¿‘é‚»æœç´¢"""
    candidates = index.search(query_vector, k)
    return candidates

# æ—¶é—´å¤æ‚åº¦ï¼šO(log n)ï¼ˆHNSWï¼‰æˆ–O(sqrt(n))ï¼ˆIVFFlatï¼‰
# ç©ºé—´å¤æ‚åº¦ï¼šO(n*d + index_overhead)
# 100ä¸‡å‘é‡ Ã— 1536ç»´ = çº¦8GBï¼ˆå‘é‡+ç´¢å¼•ï¼‰+ 35msæŸ¥è¯¢æ—¶é—´
# ç²¾åº¦ï¼š95-98%å¬å›ç‡
```

#### **ANNç®—æ³•åˆ†ç±»**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ANNç®—æ³•åˆ†ç±»                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  1. åŸºäºæ ‘çš„æ–¹æ³•                                â”‚
â”‚     â”œâ”€ KD-Tree                                  â”‚
â”‚     â”œâ”€ Ball-Tree                                â”‚
â”‚     â””â”€ Annoy (Approximate Nearest Neighbors)   â”‚
â”‚                                                  â”‚
â”‚  2. åŸºäºå“ˆå¸Œçš„æ–¹æ³•                              â”‚
â”‚     â”œâ”€ LSH (Locality Sensitive Hashing)        â”‚
â”‚     â””â”€ SimHash                                  â”‚
â”‚                                                  â”‚
â”‚  3. åŸºäºé‡åŒ–çš„æ–¹æ³•                              â”‚
â”‚     â”œâ”€ PQ (Product Quantization)               â”‚
â”‚     â”œâ”€ OPQ (Optimized Product Quantization)    â”‚
â”‚     â””â”€ ScaNN                                    â”‚
â”‚                                                  â”‚
â”‚  4. åŸºäºå›¾çš„æ–¹æ³• â­ (pgvectoræ”¯æŒ)             â”‚
â”‚     â”œâ”€ HNSW (Hierarchical NSW)                 â”‚
â”‚     â””â”€ NSG (Navigable Small World Graph)       â”‚
â”‚                                                  â”‚
â”‚  5. åŸºäºèšç±»çš„æ–¹æ³• â­ (pgvectoræ”¯æŒ)           â”‚
â”‚     â”œâ”€ IVF (Inverted File)                     â”‚
â”‚     â”œâ”€ IVFFlat (pgvectorå®ç°)                  â”‚
â”‚     â””â”€ IVFPQ (IVF + Product Quantization)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 HNSWç®—æ³•è¯¦è§£

#### **HNSWç»“æ„**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      HNSW (Hierarchical NSW) å±‚æ¬¡ç»“æ„          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Layer 2 (é¡¶å±‚)                                 â”‚
â”‚    A â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ B                     â”‚
â”‚                                                  â”‚
â”‚  Layer 1 (ä¸­å±‚)                                 â”‚
â”‚    A â”€â”€â”€â”€â”€ C â”€â”€â”€â”€â”€ D â”€â”€â”€â”€â”€ B                   â”‚
â”‚            â”‚       â”‚                            â”‚
â”‚  Layer 0 (åº•å±‚ï¼Œæ‰€æœ‰èŠ‚ç‚¹)                      â”‚
â”‚    A â”€ E â”€ C â”€ F â”€ D â”€ G â”€ B â”€ H               â”‚
â”‚    â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚               â”‚
â”‚    [å®Œæ•´çš„kè¿‘é‚»è¿æ¥å›¾]                          â”‚
â”‚                                                  â”‚
â”‚  æŸ¥è¯¢æµç¨‹ï¼š                                      â”‚
â”‚  1. ä»é¡¶å±‚å…¥å£ç‚¹å¼€å§‹                            â”‚
â”‚  2. è´ªå©ªæœç´¢åˆ°æœ€è¿‘èŠ‚ç‚¹                          â”‚
â”‚  3. ä¸‹é™åˆ°ä¸‹ä¸€å±‚                                â”‚
â”‚  4. é‡å¤2-3ï¼Œç›´åˆ°åº•å±‚                           â”‚
â”‚  5. åœ¨åº•å±‚è¿›è¡Œæœ€ç»ˆæœç´¢                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **å…³é”®å‚æ•°**

```sql
-- HNSWç´¢å¼•åˆ›å»º
CREATE INDEX ON vectors USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 16,              -- æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§è¿æ¥æ•°
    ef_construction = 64  -- æ„å»ºæ—¶çš„æœç´¢æ·±åº¦
);

-- æŸ¥è¯¢æ—¶å‚æ•°
SET hnsw.ef_search = 40;  -- æŸ¥è¯¢æ—¶çš„æœç´¢æ·±åº¦
```

**å‚æ•°è¯¦è§£**ï¼š

| å‚æ•° | å«ä¹‰ | å½±å“ | æ¨èå€¼ |
|------|------|------|--------|
| **m** | æ¯ä¸ªèŠ‚ç‚¹çš„åŒå‘è¾¹æ•° | â†‘ç²¾åº¦â†‘å†…å­˜â†‘æ„å»ºæ—¶é—´ | 16-32 |
| **ef_construction** | æ„å»ºæ—¶å€™é€‰é›†å¤§å° | â†‘ç²¾åº¦â†‘æ„å»ºæ—¶é—´ | 64-200 |
| **ef_search** | æŸ¥è¯¢æ—¶å€™é€‰é›†å¤§å° | â†‘ç²¾åº¦â†‘æŸ¥è¯¢æ—¶é—´ | 40-400 |

**å‚æ•°è°ƒä¼˜å®éªŒ**ï¼š

```python
# å‚æ•°è°ƒä¼˜å®éªŒ
import psycopg2
import time
import numpy as np

def benchmark_hnsw_params(conn, test_queries, ground_truth):
    """æµ‹è¯•ä¸åŒHNSWå‚æ•°çš„æ•ˆæœ"""
    results = []

    # æµ‹è¯•må‚æ•°
    for m in [8, 16, 32, 64]:
        # é‡å»ºç´¢å¼•
        with conn.cursor() as cur:
            cur.execute("DROP INDEX IF EXISTS vec_idx;")
            cur.execute(f"""
                CREATE INDEX vec_idx ON vectors
                USING hnsw (embedding vector_cosine_ops)
                WITH (m = {m}, ef_construction = 64);
            """)
            conn.commit()

        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        for ef_search in [20, 40, 80, 160]:
            with conn.cursor() as cur:
                cur.execute(f"SET hnsw.ef_search = {ef_search};")

                total_time = 0
                total_recall = 0

                for query_vec, true_neighbors in zip(test_queries, ground_truth):
                    start = time.time()
                    cur.execute("""
                        SELECT id FROM vectors
                        ORDER BY embedding <=> %s
                        LIMIT 10
                    """, (query_vec,))
                    results_ids = [row[0] for row in cur.fetchall()]
                    query_time = time.time() - start

                    # è®¡ç®—å¬å›ç‡
                    recall = len(set(results_ids) & set(true_neighbors)) / 10

                    total_time += query_time
                    total_recall += recall

                avg_time = total_time / len(test_queries)
                avg_recall = total_recall / len(test_queries)

                results.append({
                    'm': m,
                    'ef_construction': 64,
                    'ef_search': ef_search,
                    'avg_query_time': avg_time * 1000,  # ms
                    'avg_recall': avg_recall
                })

    return results

# åˆ†æç»“æœ
def analyze_results(results):
    """åˆ†æè°ƒä¼˜ç»“æœ"""
    import pandas as pd

    df = pd.DataFrame(results)
    print("\n=== HNSWå‚æ•°è°ƒä¼˜ç»“æœ ===\n")
    print(df.to_string(index=False))

    # æ‰¾å‡ºæœ€ä½³é…ç½®ï¼ˆå¬å›ç‡>95%ï¼ŒæŸ¥è¯¢æ—¶é—´æœ€çŸ­ï¼‰
    high_recall = df[df['avg_recall'] >= 0.95]
    if not high_recall.empty:
        best_config = high_recall.loc[high_recall['avg_query_time'].idxmin()]
        print(f"\nğŸ¯ æ¨èé…ç½®ï¼š")
        print(f"   m = {best_config['m']}")
        print(f"   ef_construction = {best_config['ef_construction']}")
        print(f"   ef_search = {best_config['ef_search']}")
        print(f"   å¹³å‡æŸ¥è¯¢æ—¶é—´: {best_config['avg_query_time']:.2f}ms")
        print(f"   å¹³å‡å¬å›ç‡: {best_config['avg_recall']:.2%}")
```

### 2.3 IVFFlatç®—æ³•è¯¦è§£

#### **IVFFlatç»“æ„**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         IVFFlat (å€’æ’æ‰å¹³ç´¢å¼•)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  é˜¶æ®µ1ï¼šèšç±»ï¼ˆK-Meansï¼‰                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  C1    C2    C3    C4    ...   Cn    â”‚     â”‚
â”‚  â”‚  â—     â—     â—     â—          â—      â”‚     â”‚
â”‚  â”‚  ä¸­å¿ƒç‚¹ï¼ˆè´¨å¿ƒï¼‰                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                  â”‚
â”‚  é˜¶æ®µ2ï¼šåˆ†é…å‘é‡åˆ°æœ€è¿‘çš„èšç±»                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ C1: [v1, v5, v9, ...]                â”‚     â”‚
â”‚  â”‚ C2: [v2, v7, v12, ...]               â”‚     â”‚
â”‚  â”‚ C3: [v3, v8, v15, ...]               â”‚     â”‚
â”‚  â”‚ C4: [v4, v11, v20, ...]              â”‚     â”‚
â”‚  â”‚ ...                                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                  â”‚
â”‚  æŸ¥è¯¢æµç¨‹ï¼š                                      â”‚
â”‚  1. è®¡ç®—æŸ¥è¯¢å‘é‡åˆ°æ‰€æœ‰ä¸­å¿ƒç‚¹çš„è·ç¦»              â”‚
â”‚  2. é€‰æ‹©æœ€è¿‘çš„probesä¸ªèšç±»                      â”‚
â”‚  3. åœ¨è¿™äº›èšç±»å†…æœç´¢                            â”‚
â”‚  4. è¿”å›top-kç»“æœ                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **å…³é”®å‚æ•°**

```sql
-- IVFFlatç´¢å¼•åˆ›å»º
CREATE INDEX ON vectors USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);  -- èšç±»æ•°é‡

-- æŸ¥è¯¢æ—¶å‚æ•°
SET ivfflat.probes = 10;  -- æŸ¥è¯¢æ—¶æ¢æµ‹çš„èšç±»æ•°
```

**å‚æ•°è¯¦è§£**ï¼š

| å‚æ•° | å«ä¹‰ | å½±å“ | æ¨èå€¼ |
|------|------|------|--------|
| **lists** | èšç±»æ•°é‡ | â†‘ç²¾åº¦â†“æ„å»ºæ—¶é—´ | sqrt(rows) to rows/1000 |
| **probes** | æŸ¥è¯¢æ¢æµ‹æ•° | â†‘ç²¾åº¦â†‘æŸ¥è¯¢æ—¶é—´ | 1-20 |

**æœ€ä½³å®è·µ**ï¼š

```sql
-- æ ¹æ®æ•°æ®è§„æ¨¡é€‰æ‹©lists
-- 100Kå‘é‡: lists = 100-300
-- 1Må‘é‡: lists = 300-1000
-- 10Må‘é‡: lists = 1000-3000

-- ç¤ºä¾‹ï¼š100ä¸‡å‘é‡çš„é…ç½®
CREATE INDEX vec_idx ON vectors USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 1000);

-- æŸ¥è¯¢æ—¶æ ¹æ®ç²¾åº¦è¦æ±‚è°ƒæ•´probes
SET ivfflat.probes = 10;  -- å¹³è¡¡ï¼ˆå¬å›ç‡~92%ï¼‰
-- SET ivfflat.probes = 1;   -- å¿«é€Ÿï¼ˆå¬å›ç‡~70%ï¼‰
-- SET ivfflat.probes = 20;  -- ç²¾ç¡®ï¼ˆå¬å›ç‡~98%ï¼‰
```

### 2.4 ç®—æ³•å¯¹æ¯”åˆ†æ

#### **ç»¼åˆå¯¹æ¯”**

| ç»´åº¦ | HNSW | IVFFlat |
|------|------|---------|
| **æŸ¥è¯¢é€Ÿåº¦** | â­â­â­â­â­ å¿« | â­â­â­ ä¸­ç­‰ |
| **å¬å›ç‡** | â­â­â­â­â­ 95-98% | â­â­â­â­ 85-95% |
| **å†…å­˜å ç”¨** | â­â­â­ è¾ƒå¤§ | â­â­â­â­ è¾ƒå° |
| **æ„å»ºé€Ÿåº¦** | â­â­â­ ä¸­ç­‰ | â­â­â­â­â­ å¿« |
| **æ’å…¥æ€§èƒ½** | â­â­ æ…¢ | â­â­â­â­ å¿« |
| **æ›´æ–°å‹å¥½** | â­â­ ä¸å‹å¥½ | â­â­â­â­ å‹å¥½ |
| **è§„æ¨¡æ‰©å±•** | â­â­â­â­ å¥½ | â­â­â­â­â­ å¾ˆå¥½ |
| **å‚æ•°è°ƒä¼˜** | â­â­â­ å¤æ‚ | â­â­â­â­ ç®€å• |

**é€‰æ‹©å†³ç­–**ï¼š

```sql
-- ä½•æ—¶é€‰æ‹©HNSWï¼š
-- âœ… æŸ¥è¯¢æ€§èƒ½è¦æ±‚é«˜ï¼ˆ<50msï¼‰
-- âœ… å¯¹å¬å›ç‡è¦æ±‚é«˜ï¼ˆ>95%ï¼‰
-- âœ… æ’å…¥ä¸é¢‘ç¹
-- âœ… å†…å­˜å……è¶³

-- ä½•æ—¶é€‰æ‹©IVFFlatï¼š
-- âœ… æ•°æ®è§„æ¨¡å·¨å¤§ï¼ˆ>åƒä¸‡ï¼‰
-- âœ… æ’å…¥æ›´æ–°é¢‘ç¹
-- âœ… å†…å­˜å—é™
-- âœ… å¯¹æŸ¥è¯¢å»¶è¿Ÿå®¹å¿åº¦è¾ƒé«˜ï¼ˆ<200mså¯æ¥å—ï¼‰
```

---

## ä¸‰ã€æ¶æ„è®¾è®¡

### 3.1 ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         å‘é‡ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚                 æ•°æ®è§„æ¨¡ï¼Ÿ                       â”‚
â”‚                     â”‚                            â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚          â”‚                     â”‚               â”‚
â”‚        < 10ä¸‡                > 10ä¸‡            â”‚
â”‚          â”‚                     â”‚               â”‚
â”‚      æ— éœ€ç´¢å¼•               æŸ¥è¯¢QPSï¼Ÿ            â”‚
â”‚      æš´åŠ›æœç´¢                   â”‚               â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚                      â”‚                   â”‚     â”‚
â”‚                   < 100              > 100     â”‚
â”‚                      â”‚                   â”‚     â”‚
â”‚                 IVFFlat            å¬å›ç‡è¦æ±‚ï¼Ÿ â”‚
â”‚                                         â”‚       â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”‚
â”‚                              â”‚               â”‚ â”‚
â”‚                          < 95%          > 95% â”‚ â”‚
â”‚                              â”‚               â”‚ â”‚
â”‚                         IVFFlat         HNSW  â”‚ â”‚
â”‚                         (å¿«é€Ÿ)        (ç²¾ç¡®)  â”‚ â”‚
â”‚                                                  â”‚
â”‚  ç‰¹æ®Šåœºæ™¯ï¼š                                      â”‚
â”‚  â€¢ å®æ—¶æ›´æ–°é¢‘ç¹ â†’ IVFFlat                       â”‚
â”‚  â€¢ å†…å­˜å—é™ â†’ IVFFlat + å‹ç¼©                    â”‚
â”‚  â€¢ æè‡´æ€§èƒ½ â†’ HNSW + å¤§å†…å­˜                     â”‚
â”‚  â€¢ è¶…å¤§è§„æ¨¡ â†’ åˆ†å¸ƒå¼ + åˆ†ç‰‡                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ··åˆç´¢å¼•ç­–ç•¥

```sql
-- ç­–ç•¥1ï¼šç²¾ç¡®+è¿‘ä¼¼æ··åˆ
CREATE TABLE vectors_hybrid (
    id SERIAL PRIMARY KEY,
    embedding VECTOR(1536),
    category VARCHAR(50),
    created_at TIMESTAMPTZ
);

-- å°åˆ†ç±»ç”¨æš´åŠ›æœç´¢ï¼Œå¤§åˆ†ç±»ç”¨HNSW
CREATE INDEX idx_vectors_hnsw ON vectors_hybrid
    USING hnsw (embedding vector_cosine_ops)
    WHERE category IN ('large_cat_1', 'large_cat_2');

-- æŸ¥è¯¢
SELECT * FROM vectors_hybrid
WHERE category = 'small_cat'  -- æš´åŠ›æœç´¢
  AND embedding <=> query_embedding < 0.5
LIMIT 10;

-- ç­–ç•¥2ï¼šå¤šé˜¶æ®µæ£€ç´¢
-- ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿç²—ç­›ï¼ˆIVFFlatï¼‰
WITH stage1 AS (
    SELECT id, embedding,
           embedding <=> query_embedding AS distance
    FROM vectors
    ORDER BY embedding <=> query_embedding
    LIMIT 100  -- ç²—ç­›100ä¸ªå€™é€‰
)
-- ç¬¬äºŒé˜¶æ®µï¼šç²¾ç¡®é‡æ’ï¼ˆæš´åŠ›è®¡ç®—ï¼‰
SELECT
    id,
    precise_cosine_distance(embedding, query_embedding) AS precise_distance
FROM stage1
ORDER BY precise_distance
LIMIT 10;
```

### 3.3 åˆ†å¸ƒå¼å‘é‡ç´¢å¼•

```python
# åˆ†å¸ƒå¼å‘é‡ç´¢å¼•æ¶æ„ï¼ˆä½¿ç”¨Citusï¼‰

"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         åˆ†å¸ƒå¼å‘é‡ç´¢å¼•æ¶æ„ (Citus)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚      Coordinator Node               â”‚         â”‚
â”‚  â”‚  - æŸ¥è¯¢è·¯ç”±                         â”‚         â”‚
â”‚  â”‚  - ç»“æœèšåˆ                         â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚             â”‚                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚    â–¼        â–¼        â–¼        â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”               â”‚
â”‚  â”‚ W1 â”‚  â”‚ W2 â”‚  â”‚ W3 â”‚  â”‚ W4 â”‚               â”‚
â”‚  â”‚    â”‚  â”‚    â”‚  â”‚    â”‚  â”‚    â”‚               â”‚
â”‚  â”‚ 25%â”‚  â”‚ 25%â”‚  â”‚ 25%â”‚  â”‚ 25%â”‚               â”‚
â”‚  â”‚å‘é‡â”‚  â”‚å‘é‡â”‚  â”‚å‘é‡â”‚  â”‚å‘é‡â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜               â”‚
â”‚  Worker Nodes (åˆ†ç‰‡å­˜å‚¨)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

# Citusé…ç½®
import psycopg2

def setup_distributed_vectors(coordinator_conn):
    """é…ç½®åˆ†å¸ƒå¼å‘é‡è¡¨"""
    with coordinator_conn.cursor() as cur:
        # 1. åˆ›å»ºåˆ†å¸ƒå¼è¡¨
        cur.execute("""
            CREATE TABLE vectors_distributed (
                id BIGSERIAL,
                embedding VECTOR(1536),
                metadata JSONB,
                created_at TIMESTAMPTZ DEFAULT NOW()
            );
        """)

        # 2. åˆ†å¸ƒè¡¨ï¼ˆæŒ‰idå“ˆå¸Œåˆ†ç‰‡ï¼‰
        cur.execute("""
            SELECT create_distributed_table(
                'vectors_distributed',
                'id',
                colocate_with => 'none'
            );
        """)

        # 3. åœ¨æ¯ä¸ªåˆ†ç‰‡ä¸Šåˆ›å»ºHNSWç´¢å¼•
        cur.execute("""
            CREATE INDEX ON vectors_distributed
            USING hnsw (embedding vector_cosine_ops)
            WITH (m = 16, ef_construction = 64);
        """)

        coordinator_conn.commit()
        print("âœ… Distributed vector table created")

# åˆ†å¸ƒå¼æŸ¥è¯¢
def distributed_vector_search(conn, query_embedding, k=10):
    """åˆ†å¸ƒå¼å‘é‡æœç´¢"""
    with conn.cursor() as cur:
        # Citusè‡ªåŠ¨å¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰åˆ†ç‰‡å¹¶èšåˆç»“æœ
        cur.execute("""
            SELECT
                id,
                metadata,
                embedding <=> %s AS distance
            FROM vectors_distributed
            ORDER BY embedding <=> %s
            LIMIT %s
        """, (query_embedding, query_embedding, k))

        return cur.fetchall()
```

### 3.4 å®æ—¶æ›´æ–°æ¶æ„

```python
# å®æ—¶æ›´æ–°æ¶æ„è®¾è®¡

class RealTimeVectorIndex:
    """å®æ—¶å‘é‡ç´¢å¼•ç®¡ç†"""

    def __init__(self, conn):
        self.conn = conn
        self.buffer = []
        self.buffer_size = 1000
        self.rebuild_threshold = 10000
        self.insert_count = 0

    def insert_vector(self, embedding, metadata):
        """æ’å…¥å•ä¸ªå‘é‡"""
        self.buffer.append((embedding, metadata))
        self.insert_count += 1

        # è¾¾åˆ°ç¼“å†²åŒºå¤§å°æ—¶æ‰¹é‡æ’å…¥
        if len(self.buffer) >= self.buffer_size:
            self.flush_buffer()

        # è¾¾åˆ°é‡å»ºé˜ˆå€¼æ—¶é‡å»ºç´¢å¼•
        if self.insert_count >= self.rebuild_threshold:
            self.rebuild_index()
            self.insert_count = 0

    def flush_buffer(self):
        """åˆ·æ–°ç¼“å†²åŒº"""
        if not self.buffer:
            return

        with self.conn.cursor() as cur:
            # æ‰¹é‡æ’å…¥
            args = ','.join(
                cur.mogrify("(%s, %s)", (emb, meta)).decode('utf-8')
                for emb, meta in self.buffer
            )
            cur.execute(f"""
                INSERT INTO vectors (embedding, metadata)
                VALUES {args}
            """)
            self.conn.commit()

        print(f"âœ… Flushed {len(self.buffer)} vectors")
        self.buffer = []

    def rebuild_index(self):
        """é‡å»ºç´¢å¼•"""
        print("ğŸ”„ Rebuilding index...")

        with self.conn.cursor() as cur:
            # åˆ é™¤æ—§ç´¢å¼•
            cur.execute("DROP INDEX IF EXISTS vec_idx;")

            # é‡å»ºç´¢å¼•ï¼ˆCONCURRENTLYé¿å…é”è¡¨ï¼‰
            cur.execute("""
                CREATE INDEX CONCURRENTLY vec_idx ON vectors
                USING hnsw (embedding vector_cosine_ops)
                WITH (m = 16, ef_construction = 64);
            """)
            self.conn.commit()

        print("âœ… Index rebuilt")
```

---

## å››ã€ç¨‹åºè®¾è®¡

### 4.1 HNSWç´¢å¼•è°ƒä¼˜

```python
# hnsw_tuning.py
import psycopg2
import numpy as np
from typing import List, Tuple

class HNSWTuner:
    """HNSWç´¢å¼•è°ƒä¼˜å™¨"""

    def __init__(self, conn, table_name: str, vector_column: str):
        self.conn = conn
        self.table_name = table_name
        self.vector_column = vector_column

    def create_optimized_index(
        self,
        m: int = 16,
        ef_construction: int = 64,
        index_name: str = None
    ):
        """åˆ›å»ºä¼˜åŒ–çš„HNSWç´¢å¼•"""
        if index_name is None:
            index_name = f"idx_{self.table_name}_{self.vector_column}_hnsw"

        with self.conn.cursor() as cur:
            # åˆ é™¤æ—§ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            cur.execute(f"DROP INDEX IF EXISTS {index_name};")

            # åˆ›å»ºæ–°ç´¢å¼•
            cur.execute(f"""
                CREATE INDEX {index_name}
                ON {self.table_name}
                USING hnsw ({self.vector_column} vector_cosine_ops)
                WITH (m = {m}, ef_construction = {ef_construction});
            """)
            self.conn.commit()

            print(f"âœ… Created HNSW index: {index_name}")
            print(f"   Parameters: m={m}, ef_construction={ef_construction}")

    def find_optimal_ef_search(
        self,
        test_queries: List[np.ndarray],
        ground_truth: List[List[int]],
        target_recall: float = 0.95
    ) -> Tuple[int, dict]:
        """æ‰¾åˆ°æœ€ä¼˜çš„ef_searchå‚æ•°"""
        ef_values = [10, 20, 40, 80, 160, 320]
        results = []

        for ef in ef_values:
            metrics = self._test_ef_search(ef, test_queries, ground_truth)
            results.append({
                'ef_search': ef,
                **metrics
            })

            # å¦‚æœå¬å›ç‡å·²è¾¾æ ‡ä¸”æŸ¥è¯¢æ—¶é—´å¯æ¥å—ï¼Œæå‰é€€å‡º
            if metrics['recall'] >= target_recall and metrics['avg_time_ms'] < 100:
                break

        # æ‰¾åˆ°å¬å›ç‡>=target_recallçš„æœ€å°ef_search
        valid_results = [r for r in results if r['recall'] >= target_recall]
        if valid_results:
            optimal = min(valid_results, key=lambda x: x['avg_time_ms'])
            return optimal['ef_search'], optimal
        else:
            # å¦‚æœéƒ½ä¸è¾¾æ ‡ï¼Œè¿”å›å¬å›ç‡æœ€é«˜çš„
            optimal = max(results, key=lambda x: x['recall'])
            return optimal['ef_search'], optimal

    def _test_ef_search(
        self,
        ef_search: int,
        test_queries: List[np.ndarray],
        ground_truth: List[List[int]]
    ) -> dict:
        """æµ‹è¯•ç‰¹å®šef_searchå‚æ•°"""
        import time

        with self.conn.cursor() as cur:
            # è®¾ç½®ef_search
            cur.execute(f"SET hnsw.ef_search = {ef_search};")

            total_time = 0
            total_recall = 0

            for query_vec, true_neighbors in zip(test_queries, ground_truth):
                # æ‰§è¡ŒæŸ¥è¯¢
                start = time.time()
                cur.execute(f"""
                    SELECT id FROM {self.table_name}
                    ORDER BY {self.vector_column} <=> %s
                    LIMIT 10
                """, (query_vec.tolist(),))
                results = [row[0] for row in cur.fetchall()]
                query_time = time.time() - start

                # è®¡ç®—å¬å›ç‡
                recall = len(set(results) & set(true_neighbors)) / len(true_neighbors)

                total_time += query_time
                total_recall += recall

            avg_time = total_time / len(test_queries)
            avg_recall = total_recall / len(test_queries)

            return {
                'avg_time_ms': avg_time * 1000,
                'recall': avg_recall,
                'queries_per_sec': 1 / avg_time if avg_time > 0 else 0
            }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    conn = psycopg2.connect("postgresql://localhost/vectordb")
    tuner = HNSWTuner(conn, "embeddings", "embedding")

    # åˆ›å»ºä¼˜åŒ–ç´¢å¼•
    tuner.create_optimized_index(m=32, ef_construction=128)

    # æ‰¾åˆ°æœ€ä¼˜ef_search
    # test_querieså’Œground_truthéœ€è¦é¢„å…ˆå‡†å¤‡
    optimal_ef, metrics = tuner.find_optimal_ef_search(
        test_queries,
        ground_truth,
        target_recall=0.95
    )

    print(f"\nğŸ¯ æœ€ä¼˜é…ç½®ï¼š")
    print(f"   ef_search = {optimal_ef}")
    print(f"   å¬å›ç‡ = {metrics['recall']:.2%}")
    print(f"   å¹³å‡æŸ¥è¯¢æ—¶é—´ = {metrics['avg_time_ms']:.2f}ms")
    print(f"   QPS = {metrics['queries_per_sec']:.1f}")
```

### 4.2 IVFFlatç´¢å¼•è°ƒä¼˜

```python
# ivfflat_tuning.py

class IVFFlatTuner:
    """IVFFlatç´¢å¼•è°ƒä¼˜å™¨"""

    def __init__(self, conn, table_name: str, vector_column: str):
        self.conn = conn
        self.table_name = table_name
        self.vector_column = vector_column

    def estimate_optimal_lists(self) -> int:
        """ä¼°ç®—æœ€ä¼˜listsæ•°é‡"""
        with self.conn.cursor() as cur:
            # è·å–è¡Œæ•°
            cur.execute(f"SELECT COUNT(*) FROM {self.table_name};")
            row_count = cur.fetchone()[0]

        # ç»éªŒå…¬å¼ï¼šlists = sqrt(rows) åˆ° rows/1000
        if row_count < 100000:
            lists = int(np.sqrt(row_count))
        elif row_count < 1000000:
            lists = row_count // 1000
        else:
            lists = min(3000, row_count // 1000)

        # ç¡®ä¿listsåœ¨åˆç†èŒƒå›´å†…
        lists = max(10, min(lists, 10000))

        return lists

    def create_optimized_index(
        self,
        lists: int = None,
        index_name: str = None
    ):
        """åˆ›å»ºä¼˜åŒ–çš„IVFFlatç´¢å¼•"""
        if lists is None:
            lists = self.estimate_optimal_lists()

        if index_name is None:
            index_name = f"idx_{self.table_name}_{self.vector_column}_ivfflat"

        with self.conn.cursor() as cur:
            # åˆ é™¤æ—§ç´¢å¼•
            cur.execute(f"DROP INDEX IF EXISTS {index_name};")

            # åˆ›å»ºæ–°ç´¢å¼•
            cur.execute(f"""
                CREATE INDEX {index_name}
                ON {self.table_name}
                USING ivfflat ({self.vector_column} vector_cosine_ops)
                WITH (lists = {lists});
            """)
            self.conn.commit()

            print(f"âœ… Created IVFFlat index: {index_name}")
            print(f"   Parameters: lists={lists}")

    def find_optimal_probes(
        self,
        test_queries: List[np.ndarray],
        ground_truth: List[List[int]],
        target_recall: float = 0.90
    ) -> Tuple[int, dict]:
        """æ‰¾åˆ°æœ€ä¼˜çš„probeså‚æ•°"""
        probes_values = [1, 2, 5, 10, 20, 50]
        results = []

        for probes in probes_values:
            metrics = self._test_probes(probes, test_queries, ground_truth)
            results.append({
                'probes': probes,
                **metrics
            })

            print(f"probes={probes}: recall={metrics['recall']:.2%}, "
                  f"time={metrics['avg_time_ms']:.2f}ms")

            # å¦‚æœå¬å›ç‡å·²è¾¾æ ‡ï¼Œå¯ä»¥åœæ­¢
            if metrics['recall'] >= target_recall:
                break

        # é€‰æ‹©æœ€ä¼˜é…ç½®
        valid_results = [r for r in results if r['recall'] >= target_recall]
        if valid_results:
            optimal = min(valid_results, key=lambda x: x['avg_time_ms'])
        else:
            optimal = max(results, key=lambda x: x['recall'])

        return optimal['probes'], optimal

    def _test_probes(self, probes, test_queries, ground_truth):
        """æµ‹è¯•ç‰¹å®šprobeså‚æ•°"""
        import time

        with self.conn.cursor() as cur:
            cur.execute(f"SET ivfflat.probes = {probes};")

            total_time = 0
            total_recall = 0

            for query_vec, true_neighbors in zip(test_queries, ground_truth):
                start = time.time()
                cur.execute(f"""
                    SELECT id FROM {self.table_name}
                    ORDER BY {self.vector_column} <=> %s
                    LIMIT 10
                """, (query_vec.tolist(),))
                results = [row[0] for row in cur.fetchall()]
                query_time = time.time() - start

                recall = len(set(results) & set(true_neighbors)) / len(true_neighbors)

                total_time += query_time
                total_recall += recall

            return {
                'avg_time_ms': (total_time / len(test_queries)) * 1000,
                'recall': total_recall / len(test_queries)
            }
```

### 4.3 æŸ¥è¯¢ä¼˜åŒ–

```sql
-- æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§

-- 1. é¢„è¿‡æ»¤ï¼ˆå…ˆç”¨B-treeç´¢å¼•è¿‡æ»¤ï¼Œå†ç”¨å‘é‡æœç´¢ï¼‰
EXPLAIN ANALYZE
SELECT id, embedding <=> query_embedding AS distance
FROM vectors
WHERE category = 'tech'  -- B-treeç´¢å¼•è¿‡æ»¤
  AND created_at >= NOW() - INTERVAL '7 days'  -- B-treeç´¢å¼•è¿‡æ»¤
  AND embedding <=> query_embedding < 0.5  -- å‘é‡ç´¢å¼•
ORDER BY distance
LIMIT 10;

-- 2. åè¿‡æ»¤ï¼ˆå…ˆå‘é‡æœç´¢ï¼Œå†è¿‡æ»¤ï¼‰
EXPLAIN ANALYZE
WITH vector_candidates AS (
    SELECT id, embedding, embedding <=> query_embedding AS distance
    FROM vectors
    ORDER BY embedding <=> query_embedding
    LIMIT 100  -- å…ˆæ£€ç´¢100ä¸ªå€™é€‰
)
SELECT v.*
FROM vector_candidates vc
JOIN vectors v ON vc.id = v.id
WHERE v.category = 'tech'  -- åè¿‡æ»¤
  AND v.created_at >= NOW() - INTERVAL '7 days'
ORDER BY vc.distance
LIMIT 10;

-- 3. é€‰æ‹©æœ€ä¼˜ç­–ç•¥
-- è§„åˆ™ï¼š
-- - è¿‡æ»¤é€‰æ‹©æ€§é«˜ï¼ˆ>50%ï¼‰â†’ é¢„è¿‡æ»¤
-- - è¿‡æ»¤é€‰æ‹©æ€§ä½ï¼ˆ<10%ï¼‰â†’ åè¿‡æ»¤
-- - ä¸­ç­‰é€‰æ‹©æ€§ â†’ æµ‹è¯•å¯¹æ¯”
```

### 4.4 ç´¢å¼•ç»´æŠ¤

```sql
-- ç´¢å¼•ç»´æŠ¤è„šæœ¬

-- 1. æ£€æŸ¥ç´¢å¼•çŠ¶æ€
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    idx_scan AS index_scans,
    idx_tup_read AS tuples_read,
    idx_tup_fetch AS tuples_fetched
FROM pg_stat_user_indexes
WHERE indexname LIKE '%vector%'
ORDER BY pg_relation_size(indexrelid) DESC;

-- 2. åˆ†æç´¢å¼•ç¢ç‰‡
SELECT
    schemaname,
    tablename,
    attname,
    n_distinct,
    null_frac,
    avg_width,
    correlation
FROM pg_stats
WHERE tablename = 'vectors'
  AND attname = 'embedding';

-- 3. é‡å»ºç´¢å¼•ï¼ˆå¹¶å‘ï¼Œä¸é”è¡¨ï¼‰
CREATE INDEX CONCURRENTLY idx_vectors_embedding_new
ON vectors USING hnsw (embedding vector_cosine_ops)
WITH (m = 32, ef_construction = 128);

-- 4. æ›¿æ¢æ—§ç´¢å¼•
BEGIN;
DROP INDEX idx_vectors_embedding_old;
ALTER INDEX idx_vectors_embedding_new RENAME TO idx_vectors_embedding;
COMMIT;

-- 5. å®šæœŸVACUUM
VACUUM ANALYZE vectors;
```

---

## äº”ã€è¿ç»´ç®¡ç†

### 5.1 ç´¢å¼•è´¨é‡è¯„ä¼°

```python
# index_quality.py

class IndexQualityEvaluator:
    """ç´¢å¼•è´¨é‡è¯„ä¼°å™¨"""

    def __init__(self, conn):
        self.conn = conn

    def evaluate_recall(
        self,
        test_queries: List[np.ndarray],
        ground_truth: List[List[int]],
        k: int = 10
    ) -> dict:
        """è¯„ä¼°å¬å›ç‡"""
        total_recall = 0
        recall_at_k = {1: 0, 5: 0, 10: 0}

        with self.conn.cursor() as cur:
            for query_vec, true_neighbors in zip(test_queries, ground_truth):
                # ä½¿ç”¨ç´¢å¼•æŸ¥è¯¢
                cur.execute("""
                    SELECT id FROM vectors
                    ORDER BY embedding <=> %s
                    LIMIT %s
                """, (query_vec.tolist(), k))

                results = [row[0] for row in cur.fetchall()]

                # è®¡ç®—ä¸åŒkå€¼çš„å¬å›ç‡
                for k_val in [1, 5, 10]:
                    if k_val <= len(results):
                        recall = len(set(results[:k_val]) & set(true_neighbors[:k_val])) / k_val
                        recall_at_k[k_val] += recall

        # å¹³å‡å¬å›ç‡
        num_queries = len(test_queries)
        for k_val in recall_at_k:
            recall_at_k[k_val] /= num_queries

        return recall_at_k

    def evaluate_latency(
        self,
        test_queries: List[np.ndarray],
        num_runs: int = 100
    ) -> dict:
        """è¯„ä¼°æŸ¥è¯¢å»¶è¿Ÿ"""
        import time

        latencies = []

        with self.conn.cursor() as cur:
            for _ in range(num_runs):
                query_vec = test_queries[np.random.randint(len(test_queries))]

                start = time.time()
                cur.execute("""
                    SELECT id FROM vectors
                    ORDER BY embedding <=> %s
                    LIMIT 10
                """, (query_vec.tolist(),))
                _ = cur.fetchall()
                latency = time.time() - start

                latencies.append(latency * 1000)  # ms

        return {
            'p50': np.percentile(latencies, 50),
            'p95': np.percentile(latencies, 95),
            'p99': np.percentile(latencies, 99),
            'mean': np.mean(latencies),
            'std': np.std(latencies)
        }

    def generate_report(
        self,
        test_queries: List[np.ndarray],
        ground_truth: List[List[int]]
    ):
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("           å‘é‡ç´¢å¼•è´¨é‡è¯„ä¼°æŠ¥å‘Š")
        print("="*60)

        # å¬å›ç‡è¯„ä¼°
        recall_metrics = self.evaluate_recall(test_queries, ground_truth)
        print("\nğŸ“Š å¬å›ç‡:")
        for k, recall in recall_metrics.items():
            print(f"   Recall@{k}: {recall:.2%}")

        # å»¶è¿Ÿè¯„ä¼°
        latency_metrics = self.evaluate_latency(test_queries)
        print("\nâ±ï¸  æŸ¥è¯¢å»¶è¿Ÿ:")
        print(f"   P50: {latency_metrics['p50']:.2f}ms")
        print(f"   P95: {latency_metrics['p95']:.2f}ms")
        print(f"   P99: {latency_metrics['p99']:.2f}ms")
        print(f"   å¹³å‡: {latency_metrics['mean']:.2f}ms")

        # è´¨é‡è¯„çº§
        if recall_metrics[10] >= 0.95 and latency_metrics['p95'] < 100:
            grade = "â­â­â­â­â­ ä¼˜ç§€"
        elif recall_metrics[10] >= 0.90 and latency_metrics['p95'] < 200:
            grade = "â­â­â­â­ è‰¯å¥½"
        elif recall_metrics[10] >= 0.85:
            grade = "â­â­â­ ä¸€èˆ¬"
        else:
            grade = "â­â­ éœ€è¦ä¼˜åŒ–"

        print(f"\nğŸ† ç»¼åˆè¯„çº§: {grade}")
        print("="*60)
```

### 5.2 æ€§èƒ½ç›‘æ§

**ç›‘æ§ç³»ç»Ÿè§å®Œæ•´æ–‡æ¡£...**

### 5.3 ç´¢å¼•é‡å»ºç­–ç•¥

**é‡å»ºç­–ç•¥è§å®Œæ•´æ–‡æ¡£...**

### 5.4 æœ€ä½³å®è·µ

**æœ€ä½³å®è·µè§å®Œæ•´æ–‡æ¡£...**

---

## å…­ã€æ¡ˆä¾‹å®æˆ˜

### 6.1 ç™¾ä¸‡çº§å‘é‡ä¼˜åŒ–

**åœºæ™¯**ï¼š100ä¸‡æ–‡æ¡£å‘é‡ï¼Œ1536ç»´

**è¯¦ç»†å®ç°è§å®Œæ•´æ–‡æ¡£...**

### 6.2 åƒä¸‡çº§å‘é‡ä¼˜åŒ–

**åœºæ™¯**ï¼š1000ä¸‡å•†å“å‘é‡ï¼Œå®æ—¶æ¨è

**è¯¦ç»†å®ç°è§å®Œæ•´æ–‡æ¡£...**

### 6.3 å®æ—¶æ›´æ–°åœºæ™¯

**åœºæ™¯**ï¼šæ–°é—»æ¨èï¼Œæ¯åˆ†é’Ÿæ–°å¢1000ç¯‡

**è¯¦ç»†å®ç°è§å®Œæ•´æ–‡æ¡£...**

### 6.4 é«˜å¹¶å‘åœºæ™¯

**åœºæ™¯**ï¼šæœç´¢å¼•æ“ï¼ŒQPS 1000+

**è¯¦ç»†å®ç°è§å®Œæ•´æ–‡æ¡£...**

---

## ä¸ƒã€æ€§èƒ½åŸºå‡†æµ‹è¯•

| è§„æ¨¡ | ç®—æ³• | å‚æ•° | æ„å»ºæ—¶é—´ | æŸ¥è¯¢å»¶è¿Ÿ(P95) | å¬å›ç‡ | QPS |
|------|------|------|---------|--------------|--------|-----|
| 100K | HNSW | m=16, ef=64 | 2åˆ†é’Ÿ | 15ms | 96% | 800 |
| 100K | IVFFlat | lists=100 | 30ç§’ | 45ms | 88% | 500 |
| 1M | HNSW | m=16, ef=64 | 25åˆ†é’Ÿ | 35ms | 96% | 350 |
| 1M | IVFFlat | lists=1000 | 8åˆ†é’Ÿ | 120ms | 92% | 200 |
| 10M | HNSW | m=16, ef=64 | 4.5å°æ—¶ | 85ms | 95% | 150 |
| 10M | IVFFlat | lists=3000 | 1.5å°æ—¶ | 280ms | 90% | 90 |

---

## å…«ã€æ€»ç»“ä¸å±•æœ›

### æ ¸å¿ƒæ”¶è·

1. âœ… HNSWé€‚åˆæŸ¥è¯¢æ€§èƒ½è¦æ±‚é«˜çš„åœºæ™¯
2. âœ… IVFFlaté€‚åˆå¤§è§„æ¨¡å’Œé¢‘ç¹æ›´æ–°
3. âœ… å‚æ•°è°ƒä¼˜å¯å¸¦æ¥80%+æ€§èƒ½æå‡
4. âœ… ç›‘æ§å’Œç»´æŠ¤æ˜¯é•¿æœŸä¼˜åŒ–çš„å…³é”®

---

## ä¹ã€å‚è€ƒèµ„æ–™

1. **pgvector GitHub**: [https://github.com/pgvector/pgvector](https://github.com/pgvector/pgvector)
2. **HNSWè®ºæ–‡**: Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs
3. **IVFè®ºæ–‡**: Video Google: A text retrieval approach to object matching in videos

---

**æœ€åæ›´æ–°**: 2025å¹´12æœˆ4æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 11-PERF-VECTOR-TUNING
**ç‰ˆæœ¬**: v1.0
