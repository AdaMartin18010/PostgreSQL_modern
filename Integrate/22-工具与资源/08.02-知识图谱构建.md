---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL\08-å·¥å…·èµ„æº\08.02-çŸ¥è¯†å›¾è°±æ„å»º.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

ï»¿# çŸ¥è¯†å›¾è°±æ„å»ºï¼šPostgreSQLçŸ¥è¯†åº“ç»“æ„åŒ–ç»„ç»‡

> **ç‰ˆæœ¬**: v1.0
> **æœ€åæ›´æ–°**: 2025-01-15
> **éš¾åº¦**: â­â­â­â­
> **åº”ç”¨åœºæ™¯**: çŸ¥è¯†ç®¡ç†ã€è¯­ä¹‰æœç´¢ã€æ™ºèƒ½æ¨èã€çŸ¥è¯†å‘ç°

---

## ğŸ“‘ ç›®å½•

- [çŸ¥è¯†å›¾è°±æ„å»ºï¼šPostgreSQLçŸ¥è¯†åº“ç»“æ„åŒ–ç»„ç»‡](#çŸ¥è¯†å›¾è°±æ„å»ºpostgresqlçŸ¥è¯†åº“ç»“æ„åŒ–ç»„ç»‡)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€æ¦‚è¿°](#ä¸€æ¦‚è¿°)
    - [1.1 çŸ¥è¯†å›¾è°±ç›®æ ‡](#11-çŸ¥è¯†å›¾è°±ç›®æ ‡)
    - [1.2 åº”ç”¨åœºæ™¯](#12-åº”ç”¨åœºæ™¯)
    - [1.3 æŠ€æœ¯ä¼˜åŠ¿](#13-æŠ€æœ¯ä¼˜åŠ¿)
  - [äºŒã€æ ¸å¿ƒæ¦‚å¿µ](#äºŒæ ¸å¿ƒæ¦‚å¿µ)
    - [2.1 çŸ¥è¯†å›¾è°±æ¨¡å‹](#21-çŸ¥è¯†å›¾è°±æ¨¡å‹)
    - [2.2 å®ä½“-å…³ç³»æ¨¡å‹](#22-å®ä½“-å…³ç³»æ¨¡å‹)
    - [2.3 å±æ€§å›¾æ¨¡å‹](#23-å±æ€§å›¾æ¨¡å‹)
    - [2.4 æ€ç»´å¯¼å›¾](#24-æ€ç»´å¯¼å›¾)
  - [ä¸‰ã€æŠ€æœ¯æ¶æ„](#ä¸‰æŠ€æœ¯æ¶æ„)
    - [3.1 æ•´ä½“æ¶æ„è®¾è®¡](#31-æ•´ä½“æ¶æ„è®¾è®¡)
    - [3.2 æ•°æ®æ¨¡å‹è®¾è®¡](#32-æ•°æ®æ¨¡å‹è®¾è®¡)
    - [3.3 å­˜å‚¨è®¾è®¡](#33-å­˜å‚¨è®¾è®¡)
  - [å››ã€å®ç°æ–¹æ¡ˆ](#å››å®ç°æ–¹æ¡ˆ)
    - [4.1 å®ä½“æŠ½å–](#41-å®ä½“æŠ½å–)
    - [4.2 å…³ç³»æŠ½å–](#42-å…³ç³»æŠ½å–)
    - [4.3 æ•°æ®å¯¹é½](#43-æ•°æ®å¯¹é½)
    - [4.4 å­˜å‚¨å®ç°](#44-å­˜å‚¨å®ç°)
    - [4.5 æŸ¥è¯¢å®ç°](#45-æŸ¥è¯¢å®ç°)
  - [äº”ã€çŸ¥è¯†çŸ©é˜µå¯¹æ¯”](#äº”çŸ¥è¯†çŸ©é˜µå¯¹æ¯”)
    - [5.1 å­˜å‚¨æ–¹æ¡ˆå¯¹æ¯”](#51-å­˜å‚¨æ–¹æ¡ˆå¯¹æ¯”)
    - [5.2 æŸ¥è¯¢æ–¹æ¡ˆå¯¹æ¯”](#52-æŸ¥è¯¢æ–¹æ¡ˆå¯¹æ¯”)
  - [å…­ã€å®è·µæ¡ˆä¾‹](#å…­å®è·µæ¡ˆä¾‹)
    - [6.1 PostgreSQLæ¦‚å¿µå›¾è°±](#61-postgresqlæ¦‚å¿µå›¾è°±)
    - [6.2 æŠ€æœ¯ä¾èµ–å…³ç³»å›¾è°±](#62-æŠ€æœ¯ä¾èµ–å…³ç³»å›¾è°±)
    - [6.3 åº”ç”¨åœºæ™¯å…³è”å›¾è°±](#63-åº”ç”¨åœºæ™¯å…³è”å›¾è°±)
  - [ä¸ƒã€æ€§èƒ½ä¼˜åŒ–](#ä¸ƒæ€§èƒ½ä¼˜åŒ–)
    - [7.1 ç´¢å¼•ä¼˜åŒ–](#71-ç´¢å¼•ä¼˜åŒ–)
    - [7.2 æŸ¥è¯¢ä¼˜åŒ–](#72-æŸ¥è¯¢ä¼˜åŒ–)
    - [7.3 å­˜å‚¨ä¼˜åŒ–](#73-å­˜å‚¨ä¼˜åŒ–)
  - [å…«ã€ç»´æŠ¤ä¸ç®¡ç†](#å…«ç»´æŠ¤ä¸ç®¡ç†)
    - [8.1 æ•°æ®è´¨é‡ä¿è¯](#81-æ•°æ®è´¨é‡ä¿è¯)
    - [8.2 ç‰ˆæœ¬ç®¡ç†](#82-ç‰ˆæœ¬ç®¡ç†)
    - [8.3 å¯è§†åŒ–å±•ç¤º](#83-å¯è§†åŒ–å±•ç¤º)
  - [ä¹ã€æœ€ä½³å®è·µ](#ä¹æœ€ä½³å®è·µ)
  - [åã€å‚è€ƒèµ„æº](#åå‚è€ƒèµ„æº)
    - [10.1 å®˜æ–¹æ–‡æ¡£](#101-å®˜æ–¹æ–‡æ¡£)
    - [10.2 ç½‘ç»œèµ„æº](#102-ç½‘ç»œèµ„æº)
    - [10.3 ç›¸å…³æ–‡æ¡£](#103-ç›¸å…³æ–‡æ¡£)

---

## ä¸€ã€æ¦‚è¿°

### 1.1 çŸ¥è¯†å›¾è°±ç›®æ ‡

çŸ¥è¯†å›¾è°±æ„å»ºæ—¨åœ¨ä»¥PostgreSQLä¸ºåç«¯å®ç°è½»é‡çº§çŸ¥è¯†å›¾è°±ï¼ˆå®ä½“/å…³ç³»/å±æ€§ï¼‰çš„å­˜å‚¨ã€æŸ¥è¯¢ä¸å¯¹é½ï¼Œå®ç°çŸ¥è¯†çš„ç»“æ„åŒ–ç»„ç»‡å’Œè¯­ä¹‰åŒ–è¡¨ç¤ºã€‚

**æ ¸å¿ƒç›®æ ‡**ï¼š

- **ç»“æ„åŒ–ç»„ç»‡**ï¼šå°†éç»“æ„åŒ–çŸ¥è¯†è½¬åŒ–ä¸ºç»“æ„åŒ–å›¾è°±
- **è¯­ä¹‰åŒ–è¡¨ç¤º**ï¼šæ”¯æŒå®ä½“ã€å…³ç³»ã€å±æ€§çš„è¯­ä¹‰è¡¨ç¤º
- **æ™ºèƒ½æŸ¥è¯¢**ï¼šæ”¯æŒè·¯å¾„æŸ¥è¯¢ã€é‚»åŸŸèšåˆã€å±æ€§è¿‡æ»¤
- **çŸ¥è¯†å¯¹é½**ï¼šä¸å¤–éƒ¨çŸ¥è¯†åº“ï¼ˆå¦‚Wikidataï¼‰å¯¹é½

### 1.2 åº”ç”¨åœºæ™¯

çŸ¥è¯†å›¾è°±åœ¨PostgreSQLçŸ¥è¯†åº“ä¸­çš„åº”ç”¨åœºæ™¯ï¼š

- **æ¦‚å¿µå…³ç³»æ˜ å°„**ï¼šå»ºç«‹PostgreSQLæ ¸å¿ƒæ¦‚å¿µä¹‹é—´çš„å…³ç³»
- **æŠ€æœ¯ä¾èµ–åˆ†æ**ï¼šåˆ†ææŠ€æœ¯ä¹‹é—´çš„ä¾èµ–å…³ç³»
- **åº”ç”¨åœºæ™¯å…³è”**ï¼šå…³è”åº”ç”¨åœºæ™¯ä¸ç›¸å…³æŠ€æœ¯
- **æ™ºèƒ½æ¨è**ï¼šåŸºäºçŸ¥è¯†å›¾è°±è¿›è¡Œæ™ºèƒ½æ¨è
- **çŸ¥è¯†å‘ç°**ï¼šé€šè¿‡å›¾è°±å‘ç°éšè—çš„çŸ¥è¯†å…³è”

### 1.3 æŠ€æœ¯ä¼˜åŠ¿

ä½¿ç”¨PostgreSQLæ„å»ºçŸ¥è¯†å›¾è°±çš„ä¼˜åŠ¿ï¼š

- **æˆç†Ÿç¨³å®š**ï¼šPostgreSQLæ˜¯æˆç†Ÿçš„å…³ç³»æ•°æ®åº“
- **SQLæ”¯æŒ**ï¼šä½¿ç”¨æ ‡å‡†SQLè¿›è¡ŒæŸ¥è¯¢
- **JSONBæ”¯æŒ**ï¼šçµæ´»å­˜å‚¨å±æ€§ä¿¡æ¯
- **æ‰©å±•æ€§å¼º**ï¼šæ”¯æŒè‡ªå®šä¹‰å‡½æ•°å’Œæ‰©å±•
- **æ€§èƒ½ä¼˜ç§€**ï¼šé€šè¿‡ç´¢å¼•å’Œä¼˜åŒ–æå‡æŸ¥è¯¢æ€§èƒ½

---

## äºŒã€æ ¸å¿ƒæ¦‚å¿µ

### 2.1 çŸ¥è¯†å›¾è°±æ¨¡å‹

**çŸ¥è¯†å›¾è°±**ï¼ˆKnowledge Graphï¼‰æ˜¯ä¸€ç§è¯­ä¹‰ç½‘ç»œï¼Œç”¨äºè¡¨ç¤ºå®ä½“ã€æ¦‚å¿µåŠå…¶ä¹‹é—´çš„å…³ç³»ã€‚

**æ ¸å¿ƒè¦ç´ **ï¼š

- **å®ä½“**ï¼ˆEntityï¼‰ï¼šçŸ¥è¯†å›¾è°±ä¸­çš„èŠ‚ç‚¹ï¼Œè¡¨ç¤ºå…·ä½“çš„äº‹ç‰©æˆ–æ¦‚å¿µ
- **å…³ç³»**ï¼ˆRelationï¼‰ï¼šå®ä½“ä¹‹é—´çš„è¿æ¥ï¼Œè¡¨ç¤ºå®ä½“ä¹‹é—´çš„å…³ç³»
- **å±æ€§**ï¼ˆPropertyï¼‰ï¼šå®ä½“çš„ç‰¹å¾æˆ–å±æ€§ä¿¡æ¯

**çŸ¥è¯†å›¾è°±ç‰¹ç‚¹**ï¼š

- **ç»“æ„åŒ–**ï¼šçŸ¥è¯†ä»¥ç»“æ„åŒ–çš„æ–¹å¼ç»„ç»‡
- **è¯­ä¹‰åŒ–**ï¼šæ”¯æŒè¯­ä¹‰è¡¨ç¤ºå’Œæ¨ç†
- **å¯æ‰©å±•**ï¼šæ”¯æŒåŠ¨æ€æ·»åŠ å®ä½“å’Œå…³ç³»
- **å¯æŸ¥è¯¢**ï¼šæ”¯æŒå¤æ‚çš„å›¾æŸ¥è¯¢

### 2.2 å®ä½“-å…³ç³»æ¨¡å‹

**å®ä½“-å…³ç³»æ¨¡å‹**ï¼ˆEntity-Relationship Modelï¼‰æ˜¯çŸ¥è¯†å›¾è°±çš„åŸºç¡€æ¨¡å‹ã€‚

**æ¨¡å‹ç»„æˆ**ï¼š

- **å®ä½“è¡¨**ï¼šå­˜å‚¨å®ä½“ä¿¡æ¯
- **å…³ç³»è¡¨**ï¼šå­˜å‚¨å®ä½“ä¹‹é—´çš„å…³ç³»
- **å±æ€§è¡¨**ï¼šå­˜å‚¨å®ä½“çš„å±æ€§ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œä¹Ÿå¯å­˜å‚¨åœ¨å®ä½“è¡¨ä¸­ï¼‰

**æ¨¡å‹ç‰¹ç‚¹**ï¼š

- **æ¸…æ™°åˆ†ç¦»**ï¼šå®ä½“ã€å…³ç³»ã€å±æ€§åˆ†ç¦»å­˜å‚¨
- **æ˜“äºç†è§£**ï¼šç¬¦åˆç›´è§‚çš„è®¤çŸ¥æ¨¡å‹
- **çµæ´»æ‰©å±•**ï¼šæ”¯æŒåŠ¨æ€æ·»åŠ å®ä½“å’Œå…³ç³»ç±»å‹

### 2.3 å±æ€§å›¾æ¨¡å‹

**å±æ€§å›¾æ¨¡å‹**ï¼ˆProperty Graph Modelï¼‰æ˜¯çŸ¥è¯†å›¾è°±çš„å¦ä¸€ç§è¡¨ç¤ºæ–¹å¼ã€‚

**æ¨¡å‹ç»„æˆ**ï¼š

- **é¡¶ç‚¹**ï¼ˆVertexï¼‰ï¼šå®ä½“ï¼ŒåŒ…å«æ ‡ç­¾å’Œå±æ€§
- **è¾¹**ï¼ˆEdgeï¼‰ï¼šå…³ç³»ï¼Œè¿æ¥ä¸¤ä¸ªé¡¶ç‚¹ï¼ŒåŒ…å«æ ‡ç­¾å’Œå±æ€§

**æ¨¡å‹ç‰¹ç‚¹**ï¼š

- **å±æ€§ä¸°å¯Œ**ï¼šé¡¶ç‚¹å’Œè¾¹éƒ½å¯ä»¥åŒ…å«ä¸°å¯Œçš„å±æ€§
- **æ ‡ç­¾åˆ†ç±»**ï¼šé€šè¿‡æ ‡ç­¾å¯¹é¡¶ç‚¹å’Œè¾¹è¿›è¡Œåˆ†ç±»
- **çµæ´»æŸ¥è¯¢**ï¼šæ”¯æŒåŸºäºæ ‡ç­¾å’Œå±æ€§çš„æŸ¥è¯¢

### 2.4 æ€ç»´å¯¼å›¾

```mermaid
graph TD
    A[çŸ¥è¯†å›¾è°±æ„å»º] --> B[æ•°æ®æŠ½å–]
    A --> C[æ•°æ®å¯¹é½]
    A --> D[æ•°æ®å­˜å‚¨]
    A --> E[æ•°æ®æŸ¥è¯¢]
    A --> F[æ•°æ®ç»´æŠ¤]

    B --> B1[å®ä½“æŠ½å–]
    B --> B2[å…³ç³»æŠ½å–]
    B --> B3[å±æ€§æŠ½å–]

    C --> C1[æ ‡å‡†åŒ–å‘½å]
    C --> C2[å¤–éƒ¨è¯è¡¨å¯¹é½]
    C --> C3[Wikidataå¯¹é½]

    D --> D1[å®ä½“è¡¨]
    D --> D2[å…³ç³»è¡¨]
    D --> D3[å±æ€§å­˜å‚¨]

    E --> E1[è·¯å¾„æŸ¥è¯¢]
    E --> E2[é‚»åŸŸèšåˆ]
    E --> E3[å±æ€§è¿‡æ»¤]

    F --> F1[å»é‡åˆå¹¶]
    F --> F2[ç‰ˆæœ¬ç®¡ç†]
    F --> F3[å®¡è®¡è¿½æº¯]
```

---

## ä¸‰ã€æŠ€æœ¯æ¶æ„

### 3.1 æ•´ä½“æ¶æ„è®¾è®¡

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ•°æ®æº      â”‚
â”‚ - æ–‡æ¡£      â”‚
â”‚ - æ—¥å¿—      â”‚
â”‚ - ç»“æ„åŒ–è¡¨  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å®ä½“æŠ½å–    â”‚  â† NLP/è§„åˆ™æŠ½å–
â”‚ å…³ç³»æŠ½å–    â”‚
â”‚ å±æ€§æŠ½å–    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ•°æ®å¯¹é½    â”‚  â† æ ‡å‡†åŒ–/Wikidataå¯¹é½
â”‚ æ ‡å‡†åŒ–å‘½å  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚  â† çŸ¥è¯†å›¾è°±å­˜å‚¨
â”‚ - å®ä½“è¡¨    â”‚
â”‚ - å…³ç³»è¡¨    â”‚
â”‚ - ç´¢å¼•      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æŸ¥è¯¢æœåŠ¡    â”‚  â† å›¾æŸ¥è¯¢API
â”‚ - è·¯å¾„æŸ¥è¯¢  â”‚
â”‚ - é‚»åŸŸæŸ¥è¯¢  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ•°æ®æ¨¡å‹è®¾è®¡

**å®ä½“-å…³ç³»æ¨¡å‹**ï¼š

```sql
-- å®ä½“è¡¨
CREATE TABLE kg_entity (
    id BIGSERIAL PRIMARY KEY,
    type TEXT NOT NULL,              -- å®ä½“ç±»å‹
    name TEXT NOT NULL,              -- å®ä½“åç§°
    name_en TEXT,                    -- è‹±æ–‡åç§°
    description TEXT,                -- æè¿°
    attrs JSONB NOT NULL DEFAULT '{}', -- å±æ€§ï¼ˆJSONBæ ¼å¼ï¼‰
    wikidata_id TEXT,                -- Wikidata ID
    source TEXT,                     -- æ•°æ®æ¥æº
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    version INTEGER DEFAULT 0        -- ç‰ˆæœ¬å·
);

-- å…³ç³»è¡¨
CREATE TABLE kg_relation (
    id BIGSERIAL PRIMARY KEY,
    src BIGINT NOT NULL REFERENCES kg_entity(id) ON DELETE CASCADE,
    dst BIGINT NOT NULL REFERENCES kg_entity(id) ON DELETE CASCADE,
    type TEXT NOT NULL,              -- å…³ç³»ç±»å‹
    description TEXT,                -- å…³ç³»æè¿°
    attrs JSONB NOT NULL DEFAULT '{}', -- å…³ç³»å±æ€§
    weight NUMERIC(5,2) DEFAULT 1.0, -- å…³ç³»æƒé‡
    source TEXT,                     -- æ•°æ®æ¥æº
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    version INTEGER DEFAULT 0,
    CONSTRAINT check_no_self_loop CHECK (src != dst)
);

-- å®ä½“ç±»å‹å­—å…¸è¡¨
CREATE TABLE kg_entity_type (
    type TEXT PRIMARY KEY,
    description TEXT,
    parent_type TEXT REFERENCES kg_entity_type(type),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- å…³ç³»ç±»å‹å­—å…¸è¡¨
CREATE TABLE kg_relation_type (
    type TEXT PRIMARY KEY,
    description TEXT,
    is_directed BOOLEAN DEFAULT TRUE, -- æ˜¯å¦æœ‰å‘
    inverse_type TEXT,                -- åå‘å…³ç³»ç±»å‹
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

**å±æ€§å›¾æ¨¡å‹**ï¼ˆå¯é€‰ï¼Œä½¿ç”¨JSONBå­˜å‚¨ï¼‰ï¼š

```sql
-- å±æ€§å›¾é¡¶ç‚¹è¡¨
CREATE TABLE kg_vertex (
    id BIGSERIAL PRIMARY KEY,
    label TEXT NOT NULL,             -- é¡¶ç‚¹æ ‡ç­¾ï¼ˆå¯¹åº”å®ä½“ç±»å‹ï¼‰
    properties JSONB NOT NULL DEFAULT '{}', -- å±æ€§
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- å±æ€§å›¾è¾¹è¡¨
CREATE TABLE kg_edge (
    id BIGSERIAL PRIMARY KEY,
    src BIGINT NOT NULL REFERENCES kg_vertex(id) ON DELETE CASCADE,
    dst BIGINT NOT NULL REFERENCES kg_vertex(id) ON DELETE CASCADE,
    label TEXT NOT NULL,             -- è¾¹æ ‡ç­¾ï¼ˆå¯¹åº”å…³ç³»ç±»å‹ï¼‰
    properties JSONB NOT NULL DEFAULT '{}', -- å±æ€§
    created_at TIMESTAMPTZ DEFAULT NOW(),
    CONSTRAINT check_no_self_loop CHECK (src != dst)
);
```

### 3.3 å­˜å‚¨è®¾è®¡

**ç´¢å¼•è®¾è®¡**ï¼š

```sql
-- å®ä½“è¡¨ç´¢å¼•
CREATE INDEX idx_kg_entity_type ON kg_entity(type);
CREATE INDEX idx_kg_entity_name ON kg_entity(name);
CREATE INDEX idx_kg_entity_name_en ON kg_entity(name_en);
CREATE INDEX idx_kg_entity_wikidata ON kg_entity(wikidata_id) WHERE wikidata_id IS NOT NULL;
CREATE INDEX idx_kg_entity_attrs ON kg_entity USING GIN (attrs);

-- å…³ç³»è¡¨ç´¢å¼•
CREATE INDEX idx_kg_relation_src ON kg_relation(src);
CREATE INDEX idx_kg_relation_dst ON kg_relation(dst);
CREATE INDEX idx_kg_relation_type ON kg_relation(type);
CREATE INDEX idx_kg_relation_src_type ON kg_relation(src, type);
CREATE INDEX idx_kg_relation_dst_type ON kg_relation(dst, type);
CREATE INDEX idx_kg_relation_attrs ON kg_relation USING GIN (attrs);

-- å¤åˆç´¢å¼•ï¼ˆä¼˜åŒ–è·¯å¾„æŸ¥è¯¢ï¼‰
CREATE INDEX idx_kg_relation_src_dst_type ON kg_relation(src, dst, type);
```

---

## å››ã€å®ç°æ–¹æ¡ˆ

### 4.1 å®ä½“æŠ½å–

**ä»æ–‡æ¡£æŠ½å–å®ä½“**ï¼š

```python
#!/usr/bin/env python3
"""
å®ä½“æŠ½å–å·¥å…·
ä»Markdownæ–‡æ¡£ä¸­æŠ½å–PostgreSQLç›¸å…³å®ä½“
"""

import re
from pathlib import Path
from typing import List, Dict
import psycopg2

class EntityExtractor:
    def __init__(self, db_conn):
        self.conn = db_conn
        self.cur = db_conn.cursor()

        # å®ä½“ç±»å‹æ¨¡å¼
        self.entity_patterns = {
            'concept': [
                r'#+\s+([A-Z][a-zA-Z\s]+)',  # æ ‡é¢˜ä½œä¸ºæ¦‚å¿µ
                r'\*\*([A-Z][a-zA-Z\s]+)\*\*',  # åŠ ç²—æ–‡æœ¬
            ],
            'function': [
                r'`([a-z_]+)\(\)`',  # å‡½æ•°å
                r'CREATE\s+FUNCTION\s+([a-z_]+)',
            ],
            'table': [
                r'CREATE\s+TABLE\s+([a-z_]+)',
                r'FROM\s+([a-z_]+)',
            ],
            'index': [
                r'CREATE\s+INDEX\s+([a-z_]+)',
            ],
        }

    def extract_from_file(self, file_path: Path) -> List[Dict]:
        """ä»æ–‡ä»¶æŠ½å–å®ä½“"""
        entities = []

        try:
            content = file_path.read_text(encoding='utf-8')
        except Exception as e:
            print(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return entities

        # æå–æ ‡é¢˜ä½œä¸ºæ¦‚å¿µå®ä½“
        heading_pattern = r'^#{1,6}\s+(.+)$'
        headings = re.findall(heading_pattern, content, re.MULTILINE)

        for heading in headings:
            # æ¸…ç†æ ‡é¢˜
            heading = heading.strip()
            if len(heading) > 100:  # è·³è¿‡è¿‡é•¿çš„æ ‡é¢˜
                continue

            entities.append({
                'type': 'concept',
                'name': heading,
                'source': str(file_path),
                'description': self._extract_description(content, heading)
            })

        # æå–ä»£ç ä¸­çš„å®ä½“
        code_pattern = r'```sql\n(.*?)```'
        code_blocks = re.findall(code_pattern, content, re.DOTALL)

        for code_block in code_blocks:
            # æå–å‡½æ•°
            functions = re.findall(r'CREATE\s+FUNCTION\s+([a-z_]+)', code_block, re.IGNORECASE)
            for func in functions:
                entities.append({
                    'type': 'function',
                    'name': func,
                    'source': str(file_path),
                    'description': f'å‡½æ•°å®šä¹‰åœ¨ {file_path.name}'
                })

            # æå–è¡¨
            tables = re.findall(r'CREATE\s+TABLE\s+([a-z_]+)', code_block, re.IGNORECASE)
            for table in tables:
                entities.append({
                    'type': 'table',
                    'name': table,
                    'source': str(file_path),
                    'description': f'è¡¨å®šä¹‰åœ¨ {file_path.name}'
                })

        return entities

    def _extract_description(self, content: str, heading: str) -> str:
        """æå–å®ä½“æè¿°"""
        # æŸ¥æ‰¾æ ‡é¢˜åçš„ç¬¬ä¸€æ®µæ–‡æœ¬ä½œä¸ºæè¿°
        pattern = rf'^#+\s+{re.escape(heading)}\s*\n\n(.+?)(?:\n\n|$)'
        match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
        if match:
            desc = match.group(1).strip()
            # é™åˆ¶æè¿°é•¿åº¦
            if len(desc) > 500:
                desc = desc[:500] + '...'
            return desc
        return ''

    def save_entities(self, entities: List[Dict]):
        """ä¿å­˜å®ä½“åˆ°æ•°æ®åº“"""
        for entity in entities:
            # æ£€æŸ¥å®ä½“æ˜¯å¦å·²å­˜åœ¨
            self.cur.execute("""
                SELECT id FROM kg_entity
                WHERE name = %s AND type = %s
            """, (entity['name'], entity['type']))

            existing = self.cur.fetchone()

            if existing:
                # æ›´æ–°å®ä½“
                self.cur.execute("""
                    UPDATE kg_entity
                    SET description = %s,
                        source = %s,
                        updated_at = NOW(),
                        version = version + 1
                    WHERE id = %s
                """, (entity.get('description', ''),
                      entity.get('source', ''),
                      existing[0]))
            else:
                # æ’å…¥æ–°å®ä½“
                self.cur.execute("""
                    INSERT INTO kg_entity (type, name, description, source, attrs)
                    VALUES (%s, %s, %s, %s, %s)
                """, (entity['type'],
                      entity['name'],
                      entity.get('description', ''),
                      entity.get('source', ''),
                      json.dumps(entity.get('attrs', {}))))

        self.conn.commit()

if __name__ == '__main__':
    import sys

    # è¿æ¥æ•°æ®åº“
    conn = psycopg2.connect(
        dbname='knowledge_graph',
        user='postgres',
        password='password'
    )

    extractor = EntityExtractor(conn)

    # ä»ç›®å½•æŠ½å–å®ä½“
    root_dir = Path(sys.argv[1] if len(sys.argv) > 1 else '.')
    all_entities = []

    for md_file in root_dir.rglob('*.md'):
        entities = extractor.extract_from_file(md_file)
        all_entities.extend(entities)
        print(f"ä» {md_file} æŠ½å–äº† {len(entities)} ä¸ªå®ä½“")

    # ä¿å­˜å®ä½“
    extractor.save_entities(all_entities)
    print(f"å…±ä¿å­˜ {len(all_entities)} ä¸ªå®ä½“")

    conn.close()
```

### 4.2 å…³ç³»æŠ½å–

**ä»æ–‡æ¡£æŠ½å–å…³ç³»**ï¼š

```python
#!/usr/bin/env python3
"""
å…³ç³»æŠ½å–å·¥å…·
ä»æ–‡æ¡£ä¸­æŠ½å–å®ä½“ä¹‹é—´çš„å…³ç³»
"""

import re
from pathlib import Path
from typing import List, Dict
import psycopg2

class RelationExtractor:
    def __init__(self, db_conn):
        self.conn = db_conn
        self.cur = db_conn.cursor()

        # å…³ç³»æ¨¡å¼
        self.relation_patterns = {
            'depends_on': [
                r'([A-Z][a-zA-Z\s]+)\s+ä¾èµ–\s+([A-Z][a-zA-Z\s]+)',
                r'([A-Z][a-zA-Z\s]+)\s+åŸºäº\s+([A-Z][a-zA-Z\s]+)',
            ],
            'implements': [
                r'([A-Z][a-zA-Z\s]+)\s+å®ç°\s+([A-Z][a-zA-Z\s]+)',
                r'([A-Z][a-zA-Z\s]+)\s+æä¾›\s+([A-Z][a-zA-Z\s]+)',
            ],
            'uses': [
                r'([A-Z][a-zA-Z\s]+)\s+ä½¿ç”¨\s+([A-Z][a-zA-Z\s]+)',
                r'([A-Z][a-zA-Z\s]+)\s+è°ƒç”¨\s+([A-Z][a-zA-Z\s]+)',
            ],
            'related_to': [
                r'([A-Z][a-zA-Z\s]+)\s+ä¸\s+([A-Z][a-zA-Z\s]+)\s+ç›¸å…³',
            ],
        }

    def extract_from_file(self, file_path: Path) -> List[Dict]:
        """ä»æ–‡ä»¶æŠ½å–å…³ç³»"""
        relations = []

        try:
            content = file_path.read_text(encoding='utf-8')
        except Exception as e:
            print(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return relations

        # æå–æ ‡é¢˜å±‚çº§å…³ç³»
        headings = self._extract_headings(content)
        for i in range(len(headings) - 1):
            relations.append({
                'src': headings[i]['name'],
                'dst': headings[i+1]['name'],
                'type': 'contains',
                'source': str(file_path)
            })

        # æå–æ–‡æœ¬ä¸­çš„å…³ç³»
        for rel_type, patterns in self.relation_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                for match in matches:
                    src = match.group(1).strip()
                    dst = match.group(2).strip()

                    relations.append({
                        'src': src,
                        'dst': dst,
                        'type': rel_type,
                        'source': str(file_path)
                    })

        return relations

    def _extract_headings(self, content: str) -> List[Dict]:
        """æå–æ ‡é¢˜"""
        headings = []
        pattern = r'^(#{1,6})\s+(.+)$'

        for match in re.finditer(pattern, content, re.MULTILINE):
            level = len(match.group(1))
            name = match.group(2).strip()
            headings.append({
                'name': name,
                'level': level
            })

        return headings

    def save_relations(self, relations: List[Dict]):
        """ä¿å­˜å…³ç³»åˆ°æ•°æ®åº“"""
        for relation in relations:
            # æŸ¥æ‰¾æºå®ä½“å’Œç›®æ ‡å®ä½“
            self.cur.execute("""
                SELECT id FROM kg_entity WHERE name = %s
            """, (relation['src'],))
            src_entity = self.cur.fetchone()

            self.cur.execute("""
                SELECT id FROM kg_entity WHERE name = %s
            """, (relation['dst'],))
            dst_entity = self.cur.fetchone()

            if not src_entity or not dst_entity:
                print(f"è·³è¿‡å…³ç³» {relation['src']} -> {relation['dst']}: å®ä½“ä¸å­˜åœ¨")
                continue

            # æ£€æŸ¥å…³ç³»æ˜¯å¦å·²å­˜åœ¨
            self.cur.execute("""
                SELECT id FROM kg_relation
                WHERE src = %s AND dst = %s AND type = %s
            """, (src_entity[0], dst_entity[0], relation['type']))

            existing = self.cur.fetchone()

            if not existing:
                # æ’å…¥æ–°å…³ç³»
                self.cur.execute("""
                    INSERT INTO kg_relation (src, dst, type, source, attrs)
                    VALUES (%s, %s, %s, %s, %s)
                """, (src_entity[0],
                      dst_entity[0],
                      relation['type'],
                      relation.get('source', ''),
                      json.dumps(relation.get('attrs', {}))))

        self.conn.commit()
```

### 4.3 æ•°æ®å¯¹é½

**Wikidataå¯¹é½**ï¼š

```python
#!/usr/bin/env python3
"""
Wikidataå¯¹é½å·¥å…·
å°†å®ä½“ä¸Wikidataå¯¹é½
"""

import requests
import psycopg2
from typing import Dict, Optional

class WikidataAligner:
    def __init__(self, db_conn):
        self.conn = db_conn
        self.cur = db_conn.cursor()
        self.wikidata_api = 'https://www.wikidata.org/w/api.php'

    def align_entity(self, entity_id: int, entity_name: str) -> Optional[str]:
        """å¯¹é½å®ä½“åˆ°Wikidata"""
        # æœç´¢Wikidata
        params = {
            'action': 'wbsearchentities',
            'search': entity_name,
            'language': 'en',
            'format': 'json'
        }

        response = requests.get(self.wikidata_api, params=params)
        data = response.json()

        if data.get('search'):
            # å–ç¬¬ä¸€ä¸ªç»“æœ
            result = data['search'][0]
            wikidata_id = result['id']

            # æ›´æ–°å®ä½“
            self.cur.execute("""
                UPDATE kg_entity
                SET wikidata_id = %s,
                    name_en = %s,
                    attrs = jsonb_set(
                        attrs,
                        '{wikidata}',
                        %s::jsonb,
                        true
                    )
                WHERE id = %s
            """, (wikidata_id,
                  result.get('label', ''),
                  json.dumps(result),
                  entity_id))

            self.conn.commit()
            return wikidata_id

        return None

    def align_all_entities(self):
        """å¯¹é½æ‰€æœ‰å®ä½“"""
        self.cur.execute("""
            SELECT id, name FROM kg_entity
            WHERE wikidata_id IS NULL
        """)

        entities = self.cur.fetchall()

        for entity_id, entity_name in entities:
            print(f"å¯¹é½å®ä½“: {entity_name}")
            wikidata_id = self.align_entity(entity_id, entity_name)
            if wikidata_id:
                print(f"  å¯¹é½åˆ°: {wikidata_id}")
            else:
                print(f"  æœªæ‰¾åˆ°åŒ¹é…")
```

### 4.4 å­˜å‚¨å®ç°

**æ‰¹é‡å¯¼å…¥å®ä½“å’Œå…³ç³»**ï¼š

```python
#!/usr/bin/env python3
"""
æ‰¹é‡å¯¼å…¥å·¥å…·
æ‰¹é‡å¯¼å…¥å®ä½“å’Œå…³ç³»åˆ°çŸ¥è¯†å›¾è°±
"""

import psycopg2
from psycopg2.extras import execute_batch
import json

class KnowledgeGraphImporter:
    def __init__(self, db_conn):
        self.conn = db_conn
        self.cur = db_conn.cursor()

    def import_entities(self, entities: List[Dict]):
        """æ‰¹é‡å¯¼å…¥å®ä½“"""
        execute_batch(
            self.cur,
            """
            INSERT INTO kg_entity (type, name, name_en, description, attrs, source)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON CONFLICT (name, type) DO UPDATE
            SET description = EXCLUDED.description,
                attrs = EXCLUDED.attrs,
                updated_at = NOW(),
                version = kg_entity.version + 1
            """,
            [(
                e['type'],
                e['name'],
                e.get('name_en'),
                e.get('description', ''),
                json.dumps(e.get('attrs', {})),
                e.get('source', '')
            ) for e in entities],
            page_size=1000
        )
        self.conn.commit()

    def import_relations(self, relations: List[Dict]):
        """æ‰¹é‡å¯¼å…¥å…³ç³»"""
        # å…ˆè·å–å®ä½“IDæ˜ å°„
        entity_map = {}
        self.cur.execute("SELECT id, name, type FROM kg_entity")
        for row in self.cur.fetchall():
            key = (row[1], row[2])
            entity_map[key] = row[0]

        # å‡†å¤‡å…³ç³»æ•°æ®
        relation_data = []
        for rel in relations:
            src_key = (rel['src'], rel.get('src_type', 'concept'))
            dst_key = (rel['dst'], rel.get('dst_type', 'concept'))

            if src_key in entity_map and dst_key in entity_map:
                relation_data.append((
                    entity_map[src_key],
                    entity_map[dst_key],
                    rel['type'],
                    rel.get('description', ''),
                    json.dumps(rel.get('attrs', {})),
                    rel.get('weight', 1.0),
                    rel.get('source', '')
                ))

        # æ‰¹é‡æ’å…¥
        execute_batch(
            self.cur,
            """
            INSERT INTO kg_relation (src, dst, type, description, attrs, weight, source)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT DO NOTHING
            """,
            relation_data,
            page_size=1000
        )
        self.conn.commit()
```

### 4.5 æŸ¥è¯¢å®ç°

**è·¯å¾„æŸ¥è¯¢**ï¼š

```sql
-- é€’å½’æŸ¥è¯¢ï¼šæŸ¥æ‰¾ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„è·¯å¾„
WITH RECURSIVE entity_path AS (
    -- åŸºç¡€æŸ¥è¯¢ï¼šç›´æ¥å…³ç³»
    SELECT
        src,
        dst,
        type,
        ARRAY[src, dst] AS path,
        1 AS depth
    FROM kg_relation
    WHERE src = (SELECT id FROM kg_entity WHERE name = 'PostgreSQL')

    UNION ALL

    -- é€’å½’æŸ¥è¯¢ï¼šæ‰©å±•è·¯å¾„
    SELECT
        ep.src,
        r.dst,
        r.type,
        ep.path || r.dst,
        ep.depth + 1
    FROM entity_path ep
    JOIN kg_relation r ON r.src = ep.dst
    WHERE ep.depth < 5  -- é™åˆ¶æ·±åº¦
      AND NOT r.dst = ANY(ep.path)  -- é¿å…å¾ªç¯
)
SELECT DISTINCT
    e1.name AS source,
    e2.name AS target,
    ep.path,
    ep.depth
FROM entity_path ep
JOIN kg_entity e1 ON e1.id = ep.src
JOIN kg_entity e2 ON e2.id = ep.dst
WHERE e2.name = 'ç´¢å¼•'
ORDER BY ep.depth, ep.path;
```

**é‚»åŸŸæŸ¥è¯¢**ï¼š

```sql
-- æŸ¥è¯¢å®ä½“çš„ç›´æ¥é‚»å±…
SELECT
    e1.name AS source,
    r.type AS relation_type,
    e2.name AS target,
    r.weight,
    r.description
FROM kg_entity e1
JOIN kg_relation r ON r.src = e1.id
JOIN kg_entity e2 ON e2.id = r.dst
WHERE e1.name = 'PostgreSQL'
ORDER BY r.weight DESC;

-- æŸ¥è¯¢å®ä½“çš„ä¸¤è·³é‚»å±…
SELECT DISTINCT
    e1.name AS source,
    e2.name AS intermediate,
    e3.name AS target,
    r1.type AS relation1,
    r2.type AS relation2
FROM kg_entity e1
JOIN kg_relation r1 ON r1.src = e1.id
JOIN kg_entity e2 ON e2.id = r1.dst
JOIN kg_relation r2 ON r2.src = e2.id
JOIN kg_entity e3 ON e3.id = r2.dst
WHERE e1.name = 'PostgreSQL'
ORDER BY r1.weight * r2.weight DESC;
```

**å±æ€§è¿‡æ»¤æŸ¥è¯¢**ï¼š

```sql
-- åŸºäºå±æ€§è¿‡æ»¤å®ä½“
SELECT
    name,
    type,
    description,
    attrs
FROM kg_entity
WHERE attrs @> '{"complexity": "high"}'::jsonb
  AND type = 'concept'
ORDER BY name;

-- åŸºäºå±æ€§è¿‡æ»¤å…³ç³»
SELECT
    e1.name AS source,
    r.type,
    e2.name AS target,
    r.attrs
FROM kg_relation r
JOIN kg_entity e1 ON e1.id = r.src
JOIN kg_entity e2 ON e2.id = r.dst
WHERE r.attrs @> '{"confidence": 0.8}'::jsonb
ORDER BY (r.attrs->>'confidence')::numeric DESC;
```

---

## äº”ã€çŸ¥è¯†çŸ©é˜µå¯¹æ¯”

### 5.1 å­˜å‚¨æ–¹æ¡ˆå¯¹æ¯”

| ç»´åº¦ | å®ä½“-å…³ç³»æ¨¡å‹ | å±æ€§å›¾æ¨¡å‹ | æ··åˆæ¨¡å‹ | æ¨èåœºæ™¯ |
|------|-------------|-----------|---------|---------|
| **å­˜å‚¨æ¸…æ™°åº¦** | â­â­â­â­â­ æ¸…æ™° | â­â­â­â­ è‰¯å¥½ | â­â­â­â­ è‰¯å¥½ | å®ä½“-å…³ç³»æ¨¡å‹æœ€æ¸…æ™° |
| **æŸ¥è¯¢çµæ´»æ€§** | â­â­â­â­ è‰¯å¥½ | â­â­â­â­â­ çµæ´» | â­â­â­â­â­ çµæ´» | å±æ€§å›¾æ¨¡å‹æœ€çµæ´» |
| **æ‰©å±•æ€§** | â­â­â­â­ è‰¯å¥½ | â­â­â­â­â­ ä¼˜ç§€ | â­â­â­â­â­ ä¼˜ç§€ | å±æ€§å›¾æ¨¡å‹æ‰©å±•æœ€å¥½ |
| **æ€§èƒ½** | â­â­â­â­â­ ä¼˜ç§€ | â­â­â­â­ è‰¯å¥½ | â­â­â­â­ è‰¯å¥½ | å®ä½“-å…³ç³»æ¨¡å‹æ€§èƒ½æœ€å¥½ |
| **å¤æ‚åº¦** | â­â­â­â­ ä¸­ç­‰ | â­â­â­ ç®€å• | â­â­â­ ç®€å• | å±æ€§å›¾æ¨¡å‹æœ€ç®€å• |
| **é€‚ç”¨åœºæ™¯** | ç»“æ„åŒ–çŸ¥è¯† | çµæ´»å±æ€§ | æ··åˆéœ€æ±‚ | æ ¹æ®éœ€æ±‚é€‰æ‹© |

### 5.2 æŸ¥è¯¢æ–¹æ¡ˆå¯¹æ¯”

| ç»´åº¦ | SQLé€’å½’CTE | å›¾æŸ¥è¯¢è¯­è¨€ | å­˜å‚¨è¿‡ç¨‹ | æ¨èåœºæ™¯ |
|------|-----------|-----------|---------|---------|
| **æ˜“ç”¨æ€§** | â­â­â­ ä¸­ç­‰ | â­â­â­â­â­ ç®€å• | â­â­ å¤æ‚ | å›¾æŸ¥è¯¢è¯­è¨€æœ€æ˜“ç”¨ |
| **æ€§èƒ½** | â­â­â­â­ è‰¯å¥½ | â­â­â­ ä¸­ç­‰ | â­â­â­â­â­ ä¼˜ç§€ | å­˜å‚¨è¿‡ç¨‹æ€§èƒ½æœ€å¥½ |
| **çµæ´»æ€§** | â­â­â­â­ è‰¯å¥½ | â­â­â­â­â­ çµæ´» | â­â­â­ ä¸­ç­‰ | å›¾æŸ¥è¯¢è¯­è¨€æœ€çµæ´» |
| **æ ‡å‡†åŒ–** | â­â­â­â­â­ æ ‡å‡† | â­â­â­ ä¸­ç­‰ | â­â­ éæ ‡å‡† | SQLæœ€æ ‡å‡† |
| **é€‚ç”¨åœºæ™¯** | ç®€å•è·¯å¾„æŸ¥è¯¢ | å¤æ‚å›¾æŸ¥è¯¢ | é«˜æ€§èƒ½æŸ¥è¯¢ | æ ¹æ®åœºæ™¯é€‰æ‹© |

---

## å…­ã€å®è·µæ¡ˆä¾‹

### 6.1 PostgreSQLæ¦‚å¿µå›¾è°±

**æ„å»ºPostgreSQLæ ¸å¿ƒæ¦‚å¿µå›¾è°±**ï¼š

```sql
-- æ’å…¥æ ¸å¿ƒæ¦‚å¿µå®ä½“
INSERT INTO kg_entity (type, name, name_en, description) VALUES
('concept', 'PostgreSQL', 'PostgreSQL', 'å¼€æºå…³ç³»æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ'),
('concept', 'ACID', 'ACID', 'äº‹åŠ¡çš„å››ä¸ªåŸºæœ¬ç‰¹æ€§'),
('concept', 'MVCC', 'MVCC', 'å¤šç‰ˆæœ¬å¹¶å‘æ§åˆ¶'),
('concept', 'WAL', 'Write-Ahead Logging', 'é¢„å†™å¼æ—¥å¿—'),
('concept', 'ç´¢å¼•', 'Index', 'æ•°æ®åº“ç´¢å¼•ç»“æ„'),
('concept', 'æŸ¥è¯¢ä¼˜åŒ–å™¨', 'Query Optimizer', 'SQLæŸ¥è¯¢ä¼˜åŒ–å™¨');

-- æ’å…¥æ¦‚å¿µå…³ç³»
INSERT INTO kg_relation (src, dst, type, description)
SELECT
    e1.id, e2.id, 'implements', 'PostgreSQLå®ç°ACIDç‰¹æ€§'
FROM kg_entity e1, kg_entity e2
WHERE e1.name = 'PostgreSQL' AND e2.name = 'ACID';

INSERT INTO kg_relation (src, dst, type, description)
SELECT
    e1.id, e2.id, 'uses', 'PostgreSQLä½¿ç”¨MVCCå®ç°å¹¶å‘æ§åˆ¶'
FROM kg_entity e1, kg_entity e2
WHERE e1.name = 'PostgreSQL' AND e2.name = 'MVCC';
```

### 6.2 æŠ€æœ¯ä¾èµ–å…³ç³»å›¾è°±

**æ„å»ºæŠ€æœ¯ä¾èµ–å…³ç³»**ï¼š

```sql
-- æŸ¥è¯¢æŠ€æœ¯ä¾èµ–é“¾
WITH RECURSIVE tech_dependencies AS (
    SELECT
        e1.name AS tech,
        e2.name AS depends_on,
        r.type,
        1 AS depth,
        ARRAY[e1.name] AS path
    FROM kg_relation r
    JOIN kg_entity e1 ON e1.id = r.src
    JOIN kg_entity e2 ON e2.id = r.dst
    WHERE r.type = 'depends_on'
      AND e1.type = 'technology'

    UNION ALL

    SELECT
        td.tech,
        e3.name,
        r2.type,
        td.depth + 1,
        td.path || e3.name
    FROM tech_dependencies td
    JOIN kg_entity e2 ON e2.name = td.depends_on
    JOIN kg_relation r2 ON r2.src = e2.id
    JOIN kg_entity e3 ON e3.id = r2.dst
    WHERE r2.type = 'depends_on'
      AND td.depth < 10
      AND NOT e3.name = ANY(td.path)
)
SELECT * FROM tech_dependencies
WHERE tech = 'PostgreSQL'
ORDER BY depth, depends_on;
```

### 6.3 åº”ç”¨åœºæ™¯å…³è”å›¾è°±

**æ„å»ºåº”ç”¨åœºæ™¯å…³è”**ï¼š

```sql
-- æŸ¥è¯¢æ¦‚å¿µçš„åº”ç”¨åœºæ™¯
SELECT
    c.name AS concept,
    s.name AS scenario,
    m.relevance_score,
    m.usage_pattern
FROM kg_entity c
JOIN concept_scenario_mapping m ON m.concept_id = c.id
JOIN application_scenarios s ON s.scenario_id = m.scenario_id
WHERE c.name = 'ç´¢å¼•'
ORDER BY m.relevance_score DESC;
```

---

## ä¸ƒã€æ€§èƒ½ä¼˜åŒ–

### 7.1 ç´¢å¼•ä¼˜åŒ–

**ç´¢å¼•ç­–ç•¥**ï¼š

```sql
-- 1. ä¸ºå¸¸ç”¨æŸ¥è¯¢åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_kg_relation_src_type_weight
ON kg_relation(src, type, weight DESC);

-- 2. ä¸ºå±æ€§æŸ¥è¯¢åˆ›å»ºGINç´¢å¼•
CREATE INDEX idx_kg_entity_attrs_gin
ON kg_entity USING GIN (attrs);

-- 3. ä¸ºå…¨æ–‡æœç´¢åˆ›å»ºç´¢å¼•
CREATE INDEX idx_kg_entity_name_fts
ON kg_entity USING GIN (to_tsvector('english', name || ' ' || COALESCE(description, '')));

-- 4. éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æ´»è·ƒå®ä½“ï¼‰
CREATE INDEX idx_kg_entity_active
ON kg_entity(name, type)
WHERE updated_at > NOW() - INTERVAL '1 year';
```

### 7.2 æŸ¥è¯¢ä¼˜åŒ–

**æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§**ï¼š

```sql
-- 1. é™åˆ¶é€’å½’æ·±åº¦
WITH RECURSIVE path AS (
    -- ...
) SELECT * FROM path WHERE depth <= 5;

-- 2. ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—å¸¸ç”¨æŸ¥è¯¢
CREATE MATERIALIZED VIEW entity_neighbors AS
SELECT
    e1.id AS entity_id,
    e1.name AS entity_name,
    COUNT(*) AS neighbor_count,
    array_agg(e2.name) AS neighbors
FROM kg_entity e1
JOIN kg_relation r ON r.src = e1.id
JOIN kg_entity e2 ON e2.id = r.dst
GROUP BY e1.id, e1.name;

-- 3. ä½¿ç”¨LIMITå‡å°‘ç»“æœé›†
SELECT * FROM kg_entity
WHERE type = 'concept'
ORDER BY updated_at DESC
LIMIT 100;
```

### 7.3 å­˜å‚¨ä¼˜åŒ–

**åˆ†åŒºç­–ç•¥**ï¼ˆå¤§è§„æ¨¡åœºæ™¯ï¼‰ï¼š

```sql
-- æŒ‰å®ä½“ç±»å‹åˆ†åŒº
CREATE TABLE kg_entity (
    -- ...
) PARTITION BY LIST (type);

CREATE TABLE kg_entity_concept PARTITION OF kg_entity
    FOR VALUES IN ('concept');

CREATE TABLE kg_entity_function PARTITION OF kg_entity
    FOR VALUES IN ('function');
```

---

## å…«ã€ç»´æŠ¤ä¸ç®¡ç†

### 8.1 æ•°æ®è´¨é‡ä¿è¯

**å»é‡å’Œåˆå¹¶**ï¼š

```sql
-- æŸ¥æ‰¾é‡å¤å®ä½“
SELECT
    name,
    type,
    COUNT(*) AS count,
    array_agg(id) AS ids
FROM kg_entity
GROUP BY name, type
HAVING COUNT(*) > 1;

-- åˆå¹¶é‡å¤å®ä½“
CREATE OR REPLACE FUNCTION merge_entities(
    keep_id BIGINT,
    merge_id BIGINT
)
RETURNS void AS $$
BEGIN
    -- æ›´æ–°å…³ç³»ä¸­çš„å¼•ç”¨
    UPDATE kg_relation SET src = keep_id WHERE src = merge_id;
    UPDATE kg_relation SET dst = keep_id WHERE dst = merge_id;

    -- åˆ é™¤é‡å¤å®ä½“
    DELETE FROM kg_entity WHERE id = merge_id;
END;
$$ LANGUAGE plpgsql;
```

### 8.2 ç‰ˆæœ¬ç®¡ç†

**ç‰ˆæœ¬åŒ–å­˜å‚¨**ï¼š

```sql
-- å®ä½“ç‰ˆæœ¬å†å²è¡¨
CREATE TABLE kg_entity_history (
    id BIGSERIAL PRIMARY KEY,
    entity_id BIGINT NOT NULL,
    version INTEGER NOT NULL,
    name TEXT,
    description TEXT,
    attrs JSONB,
    changed_at TIMESTAMPTZ DEFAULT NOW(),
    changed_by TEXT
);

-- ç‰ˆæœ¬åŒ–è§¦å‘å™¨
CREATE OR REPLACE FUNCTION save_entity_version()
RETURNS TRIGGER AS $$
BEGIN
    INSERT INTO kg_entity_history (
        entity_id, version, name, description, attrs, changed_at
    ) VALUES (
        NEW.id, NEW.version, NEW.name, NEW.description, NEW.attrs, NOW()
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_entity_version
AFTER UPDATE ON kg_entity
FOR EACH ROW
WHEN (OLD.version IS DISTINCT FROM NEW.version)
EXECUTE FUNCTION save_entity_version();
```

### 8.3 å¯è§†åŒ–å±•ç¤º

**å¯¼å‡ºä¸ºå¯è§†åŒ–æ ¼å¼**ï¼š

```python
#!/usr/bin/env python3
"""
çŸ¥è¯†å›¾è°±å¯è§†åŒ–å¯¼å‡º
å¯¼å‡ºä¸ºGephiã€Graphistryç­‰å·¥å…·å¯ç”¨çš„æ ¼å¼
"""

import psycopg2
import json
import csv

class GraphExporter:
    def __init__(self, db_conn):
        self.conn = db_conn
        self.cur = db_conn.cursor()

    def export_to_gephi(self, output_file: str):
        """å¯¼å‡ºä¸ºGephiæ ¼å¼ï¼ˆCSVï¼‰"""
        # å¯¼å‡ºèŠ‚ç‚¹
        self.cur.execute("""
            SELECT id, name, type,
                   COALESCE(attrs->>'color', '#999999') AS color,
                   COALESCE((attrs->>'size')::numeric, 10) AS size
            FROM kg_entity
        """)

        with open(f'{output_file}_nodes.csv', 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Id', 'Label', 'Type', 'Color', 'Size'])
            for row in self.cur.fetchall():
                writer.writerow(row)

        # å¯¼å‡ºè¾¹
        self.cur.execute("""
            SELECT r.id, r.src, r.dst, r.type,
                   COALESCE(r.weight, 1.0) AS weight
            FROM kg_relation r
        """)

        with open(f'{output_file}_edges.csv', 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Id', 'Source', 'Target', 'Type', 'Weight'])
            for row in self.cur.fetchall():
                writer.writerow(row)

    def export_to_json(self, output_file: str):
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        # å¯¼å‡ºèŠ‚ç‚¹
        self.cur.execute("""
            SELECT json_agg(
                json_build_object(
                    'id', id,
                    'name', name,
                    'type', type,
                    'description', description,
                    'attrs', attrs
                )
            )
            FROM kg_entity
        """)
        nodes = self.cur.fetchone()[0]

        # å¯¼å‡ºè¾¹
        self.cur.execute("""
            SELECT json_agg(
                json_build_object(
                    'id', id,
                    'src', src,
                    'dst', dst,
                    'type', type,
                    'weight', weight,
                    'attrs', attrs
                )
            )
            FROM kg_relation
        """)
        edges = self.cur.fetchone()[0]

        graph = {
            'nodes': nodes,
            'edges': edges
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(graph, f, indent=2, ensure_ascii=False)
```

---

## ä¹ã€æœ€ä½³å®è·µ

1. **æ ‡å‡†åŒ–è®¾è®¡**
   - ç»Ÿä¸€å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹å­—å…¸
   - å»ºç«‹å‘½åè§„èŒƒ
   - å®šä¹‰å±æ€§schema

2. **æ•°æ®è´¨é‡**
   - å»ºç«‹å»é‡è§„åˆ™
   - è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
   - æä¾›äººå·¥æ ¡éªŒé€šé“

3. **æ€§èƒ½ä¼˜åŒ–**
   - åˆç†è®¾è®¡ç´¢å¼•
   - ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—
   - é™åˆ¶é€’å½’æŸ¥è¯¢æ·±åº¦

4. **ç»´æŠ¤ç®¡ç†**
   - å®šæœŸå»é‡å’Œåˆå¹¶
   - ç‰ˆæœ¬åŒ–ç®¡ç†
   - å®¡è®¡è¿½æº¯

5. **å¯è§†åŒ–å±•ç¤º**
   - å¯¹æ¥å›¾è°±å¯è§†åŒ–å·¥å…·
   - å¯¼å‡ºæ ‡å‡†æ ¼å¼
   - æ”¯æŒäº¤äº’å¼æŸ¥è¯¢

---

## åã€å‚è€ƒèµ„æº

### 10.1 å®˜æ–¹æ–‡æ¡£

- [PostgreSQL JSONBæ–‡æ¡£](https://www.postgresql.org/docs/current/datatype-json.html)
- [PostgreSQLé€’å½’æŸ¥è¯¢æ–‡æ¡£](https://www.postgresql.org/docs/current/queries-with.html)
- [Apache AGEæ–‡æ¡£](https://age.apache.org/)

### 10.2 ç½‘ç»œèµ„æº

- [çŸ¥è¯†å›¾è°±æ„å»ºæŒ‡å—](https://www.w3.org/TR/vocab-dcat/)
- [Wikidata APIæ–‡æ¡£](https://www.wikidata.org/wiki/Wikidata:Data_access)
- [Gephiå¯è§†åŒ–å·¥å…·](https://gephi.org/)

### 10.3 ç›¸å…³æ–‡æ¡£

- `03-é«˜çº§ç‰¹æ€§/03.06-å›¾æ•°æ®åº“åŠŸèƒ½.md`
- `PostgreSQLçŸ¥è¯†å›¾è°±.md`
- `08.01-è´¨é‡æ£€æŸ¥å·¥å…·.md`

---

**ç»´æŠ¤è€…**: Data-Science Team
**æœ€åæ›´æ–°**: 2025-01-15
**ç‰ˆæœ¬**: 1.0
