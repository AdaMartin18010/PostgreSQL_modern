---

> **ğŸ“‹ æ–‡æ¡£æ¥æº**: `PostgreSQL\08-å·¥å…·èµ„æº\08.01-è´¨é‡æ£€æŸ¥å·¥å…·.md`
> **ğŸ“… å¤åˆ¶æ—¥æœŸ**: 2025-12-22
> **âš ï¸ æ³¨æ„**: æœ¬æ–‡æ¡£ä¸ºå¤åˆ¶ç‰ˆæœ¬ï¼ŒåŸæ–‡ä»¶ä¿æŒä¸å˜

---

# è´¨é‡æ£€æŸ¥å·¥å…·ï¼šPostgreSQLçŸ¥è¯†åº“è‡ªåŠ¨åŒ–è´¨é‡ä¿è¯

> **ç‰ˆæœ¬**: v1.0
> **æœ€åæ›´æ–°**: 2025-01-15
> **éš¾åº¦**: â­â­â­
> **åº”ç”¨åœºæ™¯**: æ–‡æ¡£è´¨é‡æ£€æŸ¥ã€CI/CDé›†æˆã€è‡ªåŠ¨åŒ–æµ‹è¯•

---

## ğŸ“‘ ç›®å½•

- [1.1 å·¥å…·ç›®æ ‡](#11-å·¥å…·ç›®æ ‡)
- [1.2 æ£€æŸ¥èŒƒå›´](#12-æ£€æŸ¥èŒƒå›´)
- [1.3 å·¥å…·ç‰¹ç‚¹](#13-å·¥å…·ç‰¹ç‚¹)
- [2.1 é“¾æ¥ä¸é”šç‚¹æ£€æŸ¥](#21-é“¾æ¥ä¸é”šç‚¹æ£€æŸ¥)
- [2.2 Markdownè§„èŒƒæ£€æŸ¥](#22-markdownè§„èŒƒæ£€æŸ¥)
- [2.3 æœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥](#23-æœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥)
- [2.4 äº¤å‰å¼•ç”¨å®Œæ•´æ€§æ£€æŸ¥](#24-äº¤å‰å¼•ç”¨å®Œæ•´æ€§æ£€æŸ¥)
- [2.5 ä»£ç å¯è¿è¡Œæ€§æ£€æŸ¥](#25-ä»£ç å¯è¿è¡Œæ€§æ£€æŸ¥)
- [2.6 æ€ç»´å¯¼å›¾](#26-æ€ç»´å¯¼å›¾)
- [3.1 é“¾æ¥æ£€æŸ¥å·¥å…·](#31-é“¾æ¥æ£€æŸ¥å·¥å…·)
- [3.2 Markdownè§„èŒƒæ£€æŸ¥å·¥å…·](#32-markdownè§„èŒƒæ£€æŸ¥å·¥å…·)
- [3.3 æœ¯è¯­æ£€æŸ¥å·¥å…·](#33-æœ¯è¯­æ£€æŸ¥å·¥å…·)
- [3.4 ç»¼åˆæ£€æŸ¥å·¥å…·](#34-ç»¼åˆæ£€æŸ¥å·¥å…·)
- [4.1 å®‰è£…ä¸é…ç½®](#41-å®‰è£…ä¸é…ç½®)
- [4.2 åŸºæœ¬ä½¿ç”¨](#42-åŸºæœ¬ä½¿ç”¨)
- [4.3 é«˜çº§ç”¨æ³•](#43-é«˜çº§ç”¨æ³•)
- [4.4 CI/CDé›†æˆ](#44-cicdé›†æˆ)
- [5.1 å·¥å…·æ–¹æ¡ˆå¯¹æ¯”](#51-å·¥å…·æ–¹æ¡ˆå¯¹æ¯”)
- [5.2 æ£€æŸ¥ç­–ç•¥å¯¹æ¯”](#52-æ£€æŸ¥ç­–ç•¥å¯¹æ¯”)
- [6.1 æœ¬åœ°å¼€å‘æ£€æŸ¥](#61-æœ¬åœ°å¼€å‘æ£€æŸ¥)
- [6.2 CI/CDæµæ°´çº¿é›†æˆ](#62-cicdæµæ°´çº¿é›†æˆ)
- [6.3 æ‰¹é‡ä¿®å¤å·¥å…·](#63-æ‰¹é‡ä¿®å¤å·¥å…·)
- [8.1 å®˜æ–¹æ–‡æ¡£](#81-å®˜æ–¹æ–‡æ¡£)
- [8.2 ç½‘ç»œèµ„æº](#82-ç½‘ç»œèµ„æº)
- [8.3 ç›¸å…³æ–‡æ¡£](#83-ç›¸å…³æ–‡æ¡£)
---

## ä¸€ã€æ¦‚è¿°

### 1.1 å·¥å…·ç›®æ ‡

è´¨é‡æ£€æŸ¥å·¥å…·æ—¨åœ¨å»ºç«‹è‡ªåŠ¨åŒ–ã€å¯é‡å¤çš„æ–‡æ¡£è´¨é‡æ£€æŸ¥æµç¨‹ï¼Œç¡®ä¿PostgreSQLçŸ¥è¯†åº“çš„æ–‡æ¡£è´¨é‡è¾¾åˆ°å›½é™…ä¸€æµæ ‡å‡†ã€‚

**æ ¸å¿ƒç›®æ ‡**ï¼š

- **ä¸€è‡´æ€§ä¿è¯**ï¼šç¡®ä¿æ–‡æ¡£ä¸æ ·ä¾‹çš„ä¸€è‡´æ€§
- **å¯è¾¾æ€§ä¿è¯**ï¼šç¡®ä¿æ‰€æœ‰é“¾æ¥å’Œå¼•ç”¨å¯è¾¾
- **å›½é™…åŒ–è´¨é‡**ï¼šç¡®ä¿ä¸­è‹±æ–‡å†…å®¹å¯¹é½å’Œæœ¯è¯­ä¸€è‡´
- **è‡ªåŠ¨åŒ–æµç¨‹**ï¼šå½¢æˆå¯é‡å¤çš„è‡ªåŠ¨åŒ–æ£€æŸ¥æµç¨‹

### 1.2 æ£€æŸ¥èŒƒå›´

è´¨é‡æ£€æŸ¥å·¥å…·è¦†ç›–ä»¥ä¸‹æ£€æŸ¥èŒƒå›´ï¼š

1. **é“¾æ¥ä¸é”šç‚¹æ£€æŸ¥**
   - å†…éƒ¨ç›¸å¯¹é“¾æ¥æœ‰æ•ˆæ€§
   - Mermaidå›¾è¡¨é”šç‚¹
   - ä»£ç å—å¼•ç”¨é”šç‚¹
   - å¤–éƒ¨é“¾æ¥å¯è¾¾æ€§

1. **Markdownè§„èŒƒæ£€æŸ¥**
   - æ ‡é¢˜å±‚çº§è§„èŒƒ
   - ç©ºè¡Œè§„åˆ™
   - åˆ—è¡¨æ ¼å¼
   - å›´æ ä»£ç å—è§„åˆ™
   - è¡¨æ ¼æ ¼å¼

1. **æœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥**
   - è‹±ä¸­å¯¹é½
   - å¤§å°å†™è§„èŒƒ
   - ç¼©å†™ä¸€è‡´æ€§
   - æœ¯è¯­è¡¨æ¯”å¯¹

1. **äº¤å‰å¼•ç”¨å®Œæ•´æ€§**
   - INDEX.mdä¸å„ç« èŠ‚äº’é“¾
   - æ–‡æ¡£é—´äº¤å‰å¼•ç”¨
   - å¼•ç”¨å®Œæ•´æ€§éªŒè¯

1. **ä»£ç å¯è¿è¡Œæ€§æ£€æŸ¥**
   - SQLè¯­æ³•æ ¡éªŒ
   - å‘½ä»¤æ ¼å¼æ ¡éªŒ
   - é™æ€åˆ†æ

### 1.3 å·¥å…·ç‰¹ç‚¹

- **è‡ªåŠ¨åŒ–**ï¼šæ”¯æŒCI/CDé›†æˆï¼Œè‡ªåŠ¨åŒ–æ£€æŸ¥
- **å¯é…ç½®**ï¼šæ”¯æŒè‡ªå®šä¹‰æ£€æŸ¥è§„åˆ™å’Œé˜ˆå€¼
- **å¯æ‰©å±•**ï¼šæ”¯æŒæ’ä»¶åŒ–æ‰©å±•æ£€æŸ¥åŠŸèƒ½
- **æŠ¥å‘Šè¯¦ç»†**ï¼šç”Ÿæˆè¯¦ç»†çš„JSON/CSVæŠ¥å‘Š
- **æ¸è¿›ä¿®å¤**ï¼šæ”¯æŒè‡ªåŠ¨ä¿®å¤å’Œæ¸è¿›å¼ä¿®å¤

---

## äºŒã€æ ¸å¿ƒåŠŸèƒ½

### 2.1 é“¾æ¥ä¸é”šç‚¹æ£€æŸ¥

**æ£€æŸ¥å†…å®¹**ï¼š

- **å†…éƒ¨é“¾æ¥**ï¼šæ£€æŸ¥ç›¸å¯¹è·¯å¾„é“¾æ¥æ˜¯å¦å­˜åœ¨
- **é”šç‚¹é“¾æ¥**ï¼šæ£€æŸ¥æ ‡é¢˜é”šç‚¹æ˜¯å¦æ­£ç¡®
- **å¤–éƒ¨é“¾æ¥**ï¼šæ£€æŸ¥å¤–éƒ¨é“¾æ¥å¯è¾¾æ€§ï¼ˆå¯é€‰ï¼‰
- **å›¾ç‰‡é“¾æ¥**ï¼šæ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨

**æ£€æŸ¥è§„åˆ™**ï¼š

```python
# é“¾æ¥æ£€æŸ¥è§„åˆ™
LINK_CHECK_RULES = {
    'internal_links': {
        'required': True,
        'check_existence': True,
        'check_anchors': True
    },
    'external_links': {
        'required': False,
        'check_reachability': False,  # é»˜è®¤ä¸æ£€æŸ¥ï¼Œå¯é…ç½®
        'timeout': 5
    },
    'image_links': {
        'required': True,
        'check_existence': True,
        'allowed_formats': ['.png', '.jpg', '.svg', '.gif']
    }
}
```

### 2.2 Markdownè§„èŒƒæ£€æŸ¥

**æ£€æŸ¥å†…å®¹**ï¼š

- **æ ‡é¢˜å±‚çº§**ï¼šæ£€æŸ¥æ ‡é¢˜å±‚çº§æ˜¯å¦è¿ç»­ï¼ˆå¦‚ä¸èƒ½ä»H1è·³åˆ°H3ï¼‰
- **ç©ºè¡Œè§„åˆ™**ï¼šæ£€æŸ¥æ ‡é¢˜å‰åã€åˆ—è¡¨å‰åçš„ç©ºè¡Œ
- **åˆ—è¡¨æ ¼å¼**ï¼šæ£€æŸ¥åˆ—è¡¨ç¼©è¿›å’Œæ ¼å¼
- **ä»£ç å—**ï¼šæ£€æŸ¥å›´æ ä»£ç å—æ ¼å¼
- **è¡¨æ ¼æ ¼å¼**ï¼šæ£€æŸ¥è¡¨æ ¼å¯¹é½å’Œæ ¼å¼

**Markdownè§„åˆ™**ï¼š

```yaml
markdown_rules:
  MD001:  # æ ‡é¢˜å±‚çº§
    level: error
    description: "æ ‡é¢˜å±‚çº§å¿…é¡»è¿ç»­"

  MD009:  # è¡Œå°¾ç©ºæ ¼
    level: warning
    description: "è¡Œå°¾ä¸åº”æœ‰ç©ºæ ¼"

  MD031:  # å›´æ ä»£ç å—
    level: error
    description: "å›´æ ä»£ç å—å‰ååº”æœ‰ç©ºè¡Œ"

  MD032:  # åˆ—è¡¨å‰åç©ºè¡Œ
    level: error
    description: "åˆ—è¡¨å‰ååº”æœ‰ç©ºè¡Œ"
```

### 2.3 æœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥

**æ£€æŸ¥å†…å®¹**ï¼š

- **æœ¯è¯­è¡¨æ¯”å¯¹**ï¼šä¸æœ¯è¯­è¡¨è¿›è¡Œæ¯”å¯¹
- **è‹±ä¸­å¯¹é½**ï¼šæ£€æŸ¥ä¸­è‹±æ–‡æœ¯è¯­æ˜¯å¦å¯¹é½
- **å¤§å°å†™è§„èŒƒ**ï¼šæ£€æŸ¥æœ¯è¯­å¤§å°å†™æ˜¯å¦ä¸€è‡´
- **ç¼©å†™ä¸€è‡´æ€§**ï¼šæ£€æŸ¥ç¼©å†™æ˜¯å¦ä¸€è‡´

**æœ¯è¯­è¡¨æ ¼å¼**ï¼š

```csv
term_en,term_cn,abbreviation,notes
PostgreSQL,PostgreSQL,PG,æ•°æ®åº“ç³»ç»Ÿ
Materialized View,ç‰©åŒ–è§†å›¾,MV,é¢„è®¡ç®—è§†å›¾
Write-Ahead Logging,é¢„å†™å¼æ—¥å¿—,WAL,äº‹åŠ¡æ—¥å¿—æœºåˆ¶
```

### 2.4 äº¤å‰å¼•ç”¨å®Œæ•´æ€§æ£€æŸ¥

**æ£€æŸ¥å†…å®¹**ï¼š

- **INDEX.mdå¼•ç”¨**ï¼šæ£€æŸ¥INDEX.mdä¸­å¼•ç”¨çš„æ–‡æ¡£æ˜¯å¦å­˜åœ¨
- **æ–‡æ¡£é—´å¼•ç”¨**ï¼šæ£€æŸ¥æ–‡æ¡£é—´çš„äº¤å‰å¼•ç”¨æ˜¯å¦å®Œæ•´
- **å¼•ç”¨æ ¼å¼**ï¼šæ£€æŸ¥å¼•ç”¨æ ¼å¼æ˜¯å¦æ­£ç¡®

**æ£€æŸ¥è§„åˆ™**ï¼š

```python
# äº¤å‰å¼•ç”¨æ£€æŸ¥è§„åˆ™
CROSS_REF_CHECK_RULES = {
    'index_file': 'INDEX.md',
    'check_existence': True,
    'check_format': True,
    'allowed_formats': [
        r'\[.*?\]\(.*?\)',  # Markdowné“¾æ¥
        r'`.*?`',            # ä»£ç å¼•ç”¨
    ]
}
```

### 2.5 ä»£ç å¯è¿è¡Œæ€§æ£€æŸ¥

**æ£€æŸ¥å†…å®¹**ï¼š

- **SQLè¯­æ³•**ï¼šæ£€æŸ¥SQLè¯­æ³•æ˜¯å¦æ­£ç¡®
- **å‘½ä»¤æ ¼å¼**ï¼šæ£€æŸ¥å‘½ä»¤è¡Œæ ¼å¼æ˜¯å¦æ­£ç¡®
- **é™æ€åˆ†æ**ï¼šè¿›è¡Œé™æ€ä»£ç åˆ†æ

**æ£€æŸ¥è§„åˆ™**ï¼š

```python
# ä»£ç æ£€æŸ¥è§„åˆ™
CODE_CHECK_RULES = {
    'sql_syntax': {
        'enabled': True,
        'validator': 'pg_validate_sql'
    },
    'command_format': {
        'enabled': True,
        'validators': ['bash', 'psql']
    },
    'static_analysis': {
        'enabled': False,  # å¯é€‰
        'tools': ['sqlfluff']
    }
}
```

### 2.6 æ€ç»´å¯¼å›¾

```mermaid
graph TD
    A[è´¨é‡æ£€æŸ¥å·¥å…·] --> B[é“¾æ¥æ£€æŸ¥]
    A --> C[Markdownæ£€æŸ¥]
    A --> D[æœ¯è¯­æ£€æŸ¥]
    A --> E[äº¤å‰å¼•ç”¨æ£€æŸ¥]
    A --> F[ä»£ç æ£€æŸ¥]

    B --> B1[å†…éƒ¨é“¾æ¥]
    B --> B2[é”šç‚¹é“¾æ¥]
    B --> B3[å¤–éƒ¨é“¾æ¥]
    B --> B4[å›¾ç‰‡é“¾æ¥]

    C --> C1[æ ‡é¢˜å±‚çº§]
    C --> C2[ç©ºè¡Œè§„åˆ™]
    C --> C3[åˆ—è¡¨æ ¼å¼]
    C --> C4[ä»£ç å—æ ¼å¼]

    D --> D1[æœ¯è¯­è¡¨æ¯”å¯¹]
    D --> D2[è‹±ä¸­å¯¹é½]
    D --> D3[å¤§å°å†™è§„èŒƒ]
    D --> D4[ç¼©å†™ä¸€è‡´æ€§]

    E --> E1[INDEX.mdå¼•ç”¨]
    E --> E2[æ–‡æ¡£é—´å¼•ç”¨]
    E --> E3[å¼•ç”¨æ ¼å¼]

    F --> F1[SQLè¯­æ³•]
    F --> F2[å‘½ä»¤æ ¼å¼]
    F --> F3[é™æ€åˆ†æ]
```

---

## ä¸‰ã€å·¥å…·å®ç°

### 3.1 é“¾æ¥æ£€æŸ¥å·¥å…·

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
#!/usr/bin/env python3
"""
é“¾æ¥æ£€æŸ¥å·¥å…·
æ£€æŸ¥Markdownæ–‡æ¡£ä¸­çš„é“¾æ¥æœ‰æ•ˆæ€§
"""

import re
import os
import json
from pathlib import Path
from typing import List, Dict, Tuple
from urllib.parse import urlparse

class LinkChecker:
    def __init__(self, root_dir: str, report_file: str = None):
        self.root_dir = Path(root_dir)
        self.report_file = report_file
        self.errors = []
        self.warnings = []

    def check_file(self, file_path: Path) -> List[Dict]:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„é“¾æ¥"""
        issues = []

        try:
            content = file_path.read_text(encoding='utf-8')
        except Exception as e:
            issues.append({
                'type': 'error',
                'file': str(file_path),
                'message': f'æ— æ³•è¯»å–æ–‡ä»¶: {e}'
            })
            return issues

        # æå–æ‰€æœ‰é“¾æ¥
        link_pattern = r'\[([^\]]+)\]\(([^\)]+)\)'
        links = re.findall(link_pattern, content)

        for text, url in links:
            issue = self._check_link(file_path, url, text)
            if issue:
                issues.append(issue)

        return issues

    def _check_link(self, file_path: Path, url: str, text: str) -> Dict:
        """æ£€æŸ¥å•ä¸ªé“¾æ¥"""
        parsed = urlparse(url)

        # å¤–éƒ¨é“¾æ¥
        if parsed.scheme in ('http', 'https'):
            # å¯é€‰ï¼šæ£€æŸ¥å¤–éƒ¨é“¾æ¥å¯è¾¾æ€§
            return None

        # å†…éƒ¨é“¾æ¥ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        if url.startswith('#'):
            # é”šç‚¹é“¾æ¥
            return self._check_anchor(file_path, url, text)
        else:
            # æ–‡ä»¶é“¾æ¥
            return self._check_file_link(file_path, url, text)

    def _check_anchor(self, file_path: Path, anchor: str, text: str) -> Dict:
        """æ£€æŸ¥é”šç‚¹é“¾æ¥"""
        anchor_id = anchor[1:].lower().replace(' ', '-')

        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            content = file_path.read_text(encoding='utf-8')
        except:
            return None

        # æå–æ‰€æœ‰æ ‡é¢˜
        heading_pattern = r'^#{1,6}\s+(.+)$'
        headings = re.findall(heading_pattern, content, re.MULTILINE)

        # æ£€æŸ¥é”šç‚¹æ˜¯å¦å­˜åœ¨
        for heading in headings:
            heading_id = heading.lower().replace(' ', '-')
            if heading_id == anchor_id:
                return None

        return {
            'type': 'error',
            'file': str(file_path),
            'link': anchor,
            'text': text,
            'message': f'é”šç‚¹ä¸å­˜åœ¨: {anchor}'
        }

    def _check_file_link(self, file_path: Path, url: str, text: str) -> Dict:
        """æ£€æŸ¥æ–‡ä»¶é“¾æ¥"""
        # è§£æç›¸å¯¹è·¯å¾„
        if url.startswith('/'):
            target_path = self.root_dir / url[1:]
        else:
            target_path = (file_path.parent / url).resolve()

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not target_path.exists():
            return {
                'type': 'error',
                'file': str(file_path),
                'link': url,
                'text': text,
                'message': f'æ–‡ä»¶ä¸å­˜åœ¨: {url}'
            }

        # æ£€æŸ¥æ˜¯å¦æ˜¯Markdownæ–‡ä»¶
        if target_path.suffix == '.md' and not target_path.is_file():
            return {
                'type': 'error',
                'file': str(file_path),
                'link': url,
                'text': text,
                'message': f'ä¸æ˜¯æ–‡ä»¶: {url}'
            }

        return None

    def check_all(self, extensions: List[str] = ['.md']) -> Dict:
        """æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶"""
        all_issues = []

        for ext in extensions:
            for file_path in self.root_dir.rglob(f'*{ext}'):
                issues = self.check_file(file_path)
                all_issues.extend(issues)

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'total_files': len(list(self.root_dir.rglob('*.md'))),
            'total_issues': len(all_issues),
            'errors': [i for i in all_issues if i['type'] == 'error'],
            'warnings': [i for i in all_issues if i['type'] == 'warning']
        }

        if self.report_file:
            with open(self.report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)

        return report

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='é“¾æ¥æ£€æŸ¥å·¥å…·')
    parser.add_argument('--root', required=True, help='æ ¹ç›®å½•')
    parser.add_argument('--ext', default='.md', help='æ–‡ä»¶æ‰©å±•å')
    parser.add_argument('--report', help='æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    checker = LinkChecker(args.root, args.report)
    report = checker.check_all([args.ext])

    print(f"æ£€æŸ¥å®Œæˆ: {report['total_issues']} ä¸ªé—®é¢˜")
    print(f"é”™è¯¯: {len(report['errors'])}")
    print(f"è­¦å‘Š: {len(report['warnings'])}")
```

### 3.2 Markdownè§„èŒƒæ£€æŸ¥å·¥å…·

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
#!/usr/bin/env python3
"""
Markdownè§„èŒƒæ£€æŸ¥å·¥å…·
æ£€æŸ¥Markdownæ–‡æ¡£æ ¼å¼è§„èŒƒ
"""

import re
from pathlib import Path
from typing import List, Dict

class MarkdownLinter:
    def __init__(self, rules: List[str] = None):
        self.rules = rules or ['MD001', 'MD009', 'MD031', 'MD032']
        self.issues = []

    def check_file(self, file_path: Path) -> List[Dict]:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶"""
        issues = []

        try:
            lines = file_path.read_text(encoding='utf-8').split('\n')
        except Exception as e:
            return [{
                'type': 'error',
                'file': str(file_path),
                'message': f'æ— æ³•è¯»å–æ–‡ä»¶: {e}'
            }]

        # MD001: æ ‡é¢˜å±‚çº§æ£€æŸ¥
        if 'MD001' in self.rules:
            issues.extend(self._check_heading_levels(file_path, lines))

        # MD009: è¡Œå°¾ç©ºæ ¼æ£€æŸ¥
        if 'MD009' in self.rules:
            issues.extend(self._check_trailing_spaces(file_path, lines))

        # MD031: å›´æ ä»£ç å—æ£€æŸ¥
        if 'MD031' in self.rules:
            issues.extend(self._check_fenced_code_blocks(file_path, lines))

        # MD032: åˆ—è¡¨å‰åç©ºè¡Œæ£€æŸ¥
        if 'MD032' in self.rules:
            issues.extend(self._check_list_spacing(file_path, lines))

        return issues

    def _check_heading_levels(self, file_path: Path, lines: List[str]) -> List[Dict]:
        """æ£€æŸ¥æ ‡é¢˜å±‚çº§"""
        issues = []
        prev_level = 0

        for i, line in enumerate(lines, 1):
            match = re.match(r'^(#{1,6})\s+', line)
            if match:
                level = len(match.group(1))
                if level > prev_level + 1:
                    issues.append({
                        'type': 'error',
                        'file': str(file_path),
                        'line': i,
                        'rule': 'MD001',
                        'message': f'æ ‡é¢˜å±‚çº§è·³è·ƒ: H{prev_level} -> H{level}'
                    })
                prev_level = level

        return issues

    def _check_trailing_spaces(self, file_path: Path, lines: List[str]) -> List[Dict]:
        """æ£€æŸ¥è¡Œå°¾ç©ºæ ¼"""
        issues = []

        for i, line in enumerate(lines, 1):
            if line.rstrip() != line:
                issues.append({
                    'type': 'warning',
                    'file': str(file_path),
                    'line': i,
                    'rule': 'MD009',
                    'message': 'è¡Œå°¾æœ‰ç©ºæ ¼'
                })

        return issues

    def _check_fenced_code_blocks(self, file_path: Path, lines: List[str]) -> List[Dict]:
        """æ£€æŸ¥å›´æ ä»£ç å—"""
        issues = []
        in_code_block = False

        for i, line in enumerate(lines, 1):
            if line.strip().startswith('```'):
                if not in_code_block:
                    # ä»£ç å—å¼€å§‹ï¼Œæ£€æŸ¥å‰ä¸€è¡Œæ˜¯å¦ä¸ºç©º
                    if i > 1 and lines[i-2].strip():
                        issues.append({
                            'type': 'error',
                            'file': str(file_path),
                            'line': i,
                            'rule': 'MD031',
                            'message': 'ä»£ç å—å‰åº”æœ‰ç©ºè¡Œ'
                        })
                in_code_block = not in_code_block
            elif in_code_block and line.strip().startswith('```'):
                # ä»£ç å—ç»“æŸï¼Œæ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦ä¸ºç©º
                if i < len(lines) and lines[i].strip():
                    issues.append({
                        'type': 'error',
                        'file': str(file_path),
                        'line': i,
                        'rule': 'MD031',
                        'message': 'ä»£ç å—ååº”æœ‰ç©ºè¡Œ'
                    })

        return issues

    def _check_list_spacing(self, file_path: Path, lines: List[str]) -> List[Dict]:
        """æ£€æŸ¥åˆ—è¡¨å‰åç©ºè¡Œ"""
        issues = []
        list_pattern = r'^\s*[-*+]\s+'

        for i, line in enumerate(lines, 1):
            if re.match(list_pattern, line):
                # æ£€æŸ¥å‰ä¸€è¡Œæ˜¯å¦ä¸ºç©ºï¼ˆé™¤éæ˜¯åˆ—è¡¨çš„ç¬¬ä¸€é¡¹ï¼‰
                if i > 1 and not re.match(list_pattern, lines[i-2]) and lines[i-2].strip():
                    issues.append({
                        'type': 'error',
                        'file': str(file_path),
                        'line': i,
                        'rule': 'MD032',
                        'message': 'åˆ—è¡¨å‰åº”æœ‰ç©ºè¡Œ'
                    })

        return issues

    def fix_file(self, file_path: Path) -> bool:
        """è‡ªåŠ¨ä¿®å¤æ–‡ä»¶"""
        # å®ç°è‡ªåŠ¨ä¿®å¤é€»è¾‘
        pass
```

### 3.3 æœ¯è¯­æ£€æŸ¥å·¥å…·

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
#!/usr/bin/env python3
"""
æœ¯è¯­æ£€æŸ¥å·¥å…·
æ£€æŸ¥æ–‡æ¡£ä¸­çš„æœ¯è¯­ä¸€è‡´æ€§
"""

import csv
import re
from pathlib import Path
from typing import List, Dict, Set

class TermChecker:
    def __init__(self, glossary_file: str):
        self.glossary = self._load_glossary(glossary_file)
        self.issues = []

    def _load_glossary(self, glossary_file: str) -> Dict:
        """åŠ è½½æœ¯è¯­è¡¨"""
        glossary = {}

        with open(glossary_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                term_en = row.get('term_en', '').strip()
                term_cn = row.get('term_cn', '').strip()
                abbreviation = row.get('abbreviation', '').strip()

                if term_en:
                    glossary[term_en.lower()] = {
                        'en': term_en,
                        'cn': term_cn,
                        'abbr': abbreviation
                    }

        return glossary

    def check_file(self, file_path: Path) -> List[Dict]:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„æœ¯è¯­"""
        issues = []

        try:
            content = file_path.read_text(encoding='utf-8')
        except Exception as e:
            return [{
                'type': 'error',
                'file': str(file_path),
                'message': f'æ— æ³•è¯»å–æ–‡ä»¶: {e}'
            }]

        # æ£€æŸ¥æœ¯è¯­ä½¿ç”¨
        for term_key, term_info in self.glossary.items():
            # æ£€æŸ¥è‹±æ–‡æœ¯è¯­
            if term_info['en'] in content:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡å¯¹ç…§
                if term_info['cn'] and term_info['cn'] not in content:
                    issues.append({
                        'type': 'warning',
                        'file': str(file_path),
                        'term': term_info['en'],
                        'message': f'æœ¯è¯­ "{term_info["en"]}" ç¼ºå°‘ä¸­æ–‡å¯¹ç…§ "{term_info["cn"]}"'
                    })

            # æ£€æŸ¥ç¼©å†™ä¸€è‡´æ€§
            if term_info['abbr']:
                # æ£€æŸ¥ç¼©å†™ä½¿ç”¨æ˜¯å¦ä¸€è‡´
                abbr_pattern = rf'\b{re.escape(term_info["abbr"])}\b'
                if re.search(abbr_pattern, content, re.IGNORECASE):
                    # æ£€æŸ¥æ˜¯å¦é¦–æ¬¡å‡ºç°æ—¶ç»™å‡ºäº†å…¨ç§°
                    pass  # å®ç°æ£€æŸ¥é€»è¾‘

        return issues
```

### 3.4 ç»¼åˆæ£€æŸ¥å·¥å…·

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
#!/usr/bin/env python3
"""
ç»¼åˆè´¨é‡æ£€æŸ¥å·¥å…·
æ•´åˆæ‰€æœ‰æ£€æŸ¥åŠŸèƒ½
"""

from pathlib import Path
from link_checker import LinkChecker
from markdown_linter import MarkdownLinter
from term_checker import TermChecker
import json

class QualityChecker:
    def __init__(self, root_dir: str, config: dict = None):
        self.root_dir = Path(root_dir)
        self.config = config or {}
        self.report = {
            'link_check': {},
            'markdown_check': {},
            'term_check': {},
            'summary': {}
        }

    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        # é“¾æ¥æ£€æŸ¥
        if self.config.get('enable_link_check', True):
            link_checker = LinkChecker(
                str(self.root_dir),
                self.config.get('link_report_file')
            )
            self.report['link_check'] = link_checker.check_all()

        # Markdownæ£€æŸ¥
        if self.config.get('enable_markdown_check', True):
            linter = MarkdownLinter(
                self.config.get('markdown_rules', ['MD001', 'MD009', 'MD031', 'MD032'])
            )
            all_issues = []
            for file_path in self.root_dir.rglob('*.md'):
                issues = linter.check_file(file_path)
                all_issues.extend(issues)

            self.report['markdown_check'] = {
                'total_issues': len(all_issues),
                'errors': [i for i in all_issues if i['type'] == 'error'],
                'warnings': [i for i in all_issues if i['type'] == 'warning']
            }

        # æœ¯è¯­æ£€æŸ¥
        if self.config.get('enable_term_check', True):
            glossary_file = self.config.get('glossary_file')
            if glossary_file and Path(glossary_file).exists():
                term_checker = TermChecker(glossary_file)
                all_issues = []
                for file_path in self.root_dir.rglob('*.md'):
                    issues = term_checker.check_file(file_path)
                    all_issues.extend(issues)

                self.report['term_check'] = {
                    'total_issues': len(all_issues),
                    'errors': [i for i in all_issues if i['type'] == 'error'],
                    'warnings': [i for i in all_issues if i['type'] == 'warning']
                }

        # ç”Ÿæˆæ‘˜è¦
        self.report['summary'] = self._generate_summary()

    def _generate_summary(self) -> dict:
        """ç”Ÿæˆæ£€æŸ¥æ‘˜è¦"""
        total_errors = (
            len(self.report['link_check'].get('errors', [])) +
            len(self.report['markdown_check'].get('errors', [])) +
            len(self.report['term_check'].get('errors', []))
        )

        total_warnings = (
            len(self.report['link_check'].get('warnings', [])) +
            len(self.report['markdown_check'].get('warnings', [])) +
            len(self.report['term_check'].get('warnings', []))
        )

        return {
            'total_errors': total_errors,
            'total_warnings': total_warnings,
            'passed': total_errors == 0
        }

    def save_report(self, report_file: str):
        """ä¿å­˜æŠ¥å‘Š"""
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False)
```

---

## å››ã€ä½¿ç”¨æŒ‡å—

### 4.1 å®‰è£…ä¸é…ç½®

**å®‰è£…ä¾èµ–**ï¼š

```bash
# å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# requirements.txt
# markdown
# pyyaml
# requests  # ç”¨äºå¤–éƒ¨é“¾æ¥æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰
```

**é…ç½®æ–‡ä»¶**ï¼š

```yaml
# quality_check_config.yaml
quality_check:
  root_dir: "."
  output_dir: "out"

  link_check:
    enabled: true
    check_external: false
    timeout: 5

  markdown_check:
    enabled: true
    rules:
      - MD001
      - MD009
      - MD031
      - MD032
    auto_fix: false

  term_check:
    enabled: true
    glossary_file: "tools/glossary.csv"

  report:
    format: "json"  # json, csv, html
    file: "out/quality_report.json"
```

### 4.2 åŸºæœ¬ä½¿ç”¨

**å‘½ä»¤è¡Œä½¿ç”¨**ï¼š

```bash
# å…¨ç›®å½•é“¾æ¥æ£€æŸ¥
python tools/link_checker.py --root . --ext .md --report out/link_report.json

# Markdownè§„åˆ™æ£€æŸ¥
python tools/md_lint.py --root . --rules MD031,MD032,MD009 --fix

# æœ¯è¯­æ¯”å¯¹
python tools/term_check.py --root . --glossary tools/glossary.csv --report out/term_report.csv

# ç»¼åˆæ£€æŸ¥
python tools/quality_checker.py --root . --config quality_check_config.yaml
```

### 4.3 é«˜çº§ç”¨æ³•

**å¢é‡æ£€æŸ¥**ï¼š

```bash
# åªæ£€æŸ¥æ”¹åŠ¨çš„æ–‡ä»¶
python tools/quality_checker.py \
  --root . \
  --changed-files file1.md file2.md \
  --report out/incremental_report.json
```

**è‡ªå®šä¹‰è§„åˆ™**ï¼š

```python
# è‡ªå®šä¹‰æ£€æŸ¥è§„åˆ™
from quality_checker import QualityChecker

config = {
    'enable_link_check': True,
    'enable_markdown_check': True,
    'markdown_rules': ['MD001', 'MD009'],  # åªæ£€æŸ¥ç‰¹å®šè§„åˆ™
    'glossary_file': 'custom_glossary.csv'
}

checker = QualityChecker('.', config)
checker.run_all_checks()
checker.save_report('out/custom_report.json')
```

### 4.4 CI/CDé›†æˆ

**GitHub Actionsç¤ºä¾‹**ï¼š

```yaml
# .github/workflows/quality-check.yml
name: Quality Check

on:
  pull_request:
    paths:
      - '**.md'
  push:
    branches:
      - main

jobs:
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run quality checks
        run: |
          python tools/quality_checker.py \
            --root . \
            --config quality_check_config.yaml \
            --report out/quality_report.json

      - name: Upload report
        uses: actions/upload-artifact@v3
        with:
          name: quality-report
          path: out/quality_report.json

      - name: Check results
        run: |
          python tools/check_report.py \
            --report out/quality_report.json \
            --fail-on-error
```

---

## äº”ã€çŸ¥è¯†çŸ©é˜µå¯¹æ¯”

### 5.1 å·¥å…·æ–¹æ¡ˆå¯¹æ¯”

| ç»´åº¦ | è‡ªå®šä¹‰å·¥å…· | markdownlint | Vale | æ¨èåœºæ™¯ |
|------|-----------|-------------|------|---------|
| **å®šåˆ¶åŒ–** | â­â­â­â­â­ å®Œå…¨å®šåˆ¶ | â­â­â­ ä¸­ç­‰ | â­â­â­â­ é«˜ | è‡ªå®šä¹‰å·¥å…·æœ€çµæ´» |
| **æ˜“ç”¨æ€§** | â­â­â­ ä¸­ç­‰ | â­â­â­â­â­ ç®€å• | â­â­â­â­ ç®€å• | markdownlintæœ€æ˜“ç”¨ |
| **åŠŸèƒ½å®Œæ•´æ€§** | â­â­â­â­ å®Œæ•´ | â­â­â­â­ å®Œæ•´ | â­â­â­â­â­ æœ€å®Œæ•´ | ValeåŠŸèƒ½æœ€å®Œæ•´ |
| **CI/CDé›†æˆ** | â­â­â­â­ è‰¯å¥½ | â­â­â­â­â­ ä¼˜ç§€ | â­â­â­â­â­ ä¼˜ç§€ | ä¸‰è€…éƒ½æ”¯æŒ |
| **ç»´æŠ¤æˆæœ¬** | â­â­ é«˜ | â­â­â­â­ ä½ | â­â­â­ ä¸­ | markdownlintç»´æŠ¤æˆæœ¬æœ€ä½ |
| **é€‚ç”¨åœºæ™¯** | ç‰¹å®šéœ€æ±‚ | é€šç”¨Markdown | æŠ€æœ¯æ–‡æ¡£ | æ ¹æ®éœ€æ±‚é€‰æ‹© |

### 5.2 æ£€æŸ¥ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | å…¨é‡æ£€æŸ¥ | å¢é‡æ£€æŸ¥ | æŠ½æ ·æ£€æŸ¥ | æ¨èåœºæ™¯ |
|------|---------|---------|---------|---------|
| **æ£€æŸ¥å®Œæ•´æ€§** | â­â­â­â­â­ å®Œæ•´ | â­â­â­â­ è‰¯å¥½ | â­â­â­ ä¸­ç­‰ | å…¨é‡æ£€æŸ¥æœ€å®Œæ•´ |
| **æ£€æŸ¥é€Ÿåº¦** | â­â­ æ…¢ | â­â­â­â­â­ å¿« | â­â­â­â­ è¾ƒå¿« | å¢é‡æ£€æŸ¥æœ€å¿« |
| **èµ„æºæ¶ˆè€—** | â­â­ é«˜ | â­â­â­â­ ä½ | â­â­â­â­â­ æœ€ä½ | æŠ½æ ·æ£€æŸ¥èµ„æºæ¶ˆè€—æœ€ä½ |
| **é€‚ç”¨åœºæ™¯** | å®šæœŸå…¨æ£€ | PRæ£€æŸ¥ | å¿«é€Ÿé¢„è§ˆ | æ ¹æ®åœºæ™¯é€‰æ‹© |

---

## å…­ã€å®è·µæ¡ˆä¾‹

### 6.1 æœ¬åœ°å¼€å‘æ£€æŸ¥

**å¼€å‘å‰æ£€æŸ¥**ï¼š

```bash
#!/bin/bash
# pre-commit-check.sh

echo "è¿è¡Œè´¨é‡æ£€æŸ¥..."

# è¿è¡Œæ‰€æœ‰æ£€æŸ¥
python tools/quality_checker.py \
  --root . \
  --config quality_check_config.yaml \
  --report out/pre_commit_report.json

# æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
python tools/check_report.py \
  --report out/pre_commit_report.json \
  --fail-on-error

if [ $? -ne 0 ]; then
    echo "è´¨é‡æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤é”™è¯¯åé‡è¯•"
    exit 1
fi

echo "è´¨é‡æ£€æŸ¥é€šè¿‡"
```

### 6.2 CI/CDæµæ°´çº¿é›†æˆ

**GitLab CIç¤ºä¾‹**ï¼š

```yaml
# .gitlab-ci.yml
stages:
  - quality-check

quality-check:
  stage: quality-check
  image: python:3.9
  script:
    - pip install -r requirements.txt
    - python tools/quality_checker.py --root . --report out/report.json
    - python tools/check_report.py --report out/report.json --fail-on-error
  artifacts:
    reports:
      junit: out/report.xml
    paths:
      - out/report.json
  only:
    - merge_requests
    - main
```

### 6.3 æ‰¹é‡ä¿®å¤å·¥å…·

**è‡ªåŠ¨ä¿®å¤ç¤ºä¾‹**ï¼š

```python
#!/usr/bin/env python3
"""
æ‰¹é‡ä¿®å¤å·¥å…·
è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜
"""

from pathlib import Path
from markdown_linter import MarkdownLinter

def batch_fix(root_dir: str):
    """æ‰¹é‡ä¿®å¤æ–‡ä»¶"""
    root = Path(root_dir)
    linter = MarkdownLinter()

    fixed_count = 0
    for file_path in root.rglob('*.md'):
        if linter.fix_file(file_path):
            fixed_count += 1
            print(f"å·²ä¿®å¤: {file_path}")

    print(f"å…±ä¿®å¤ {fixed_count} ä¸ªæ–‡ä»¶")

if __name__ == '__main__':
    import sys
    batch_fix(sys.argv[1] if len(sys.argv) > 1 else '.')
```

---

## ä¸ƒã€æœ€ä½³å®è·µ

1. **CIé›†æˆ**
   - PRå¿…é¡»é€šè¿‡"é“¾æ¥/Markdown/æœ¯è¯­"ä¸‰ç±»æ£€æŸ¥
   - å…³é”®é”™è¯¯é˜»æ–­åˆå¹¶
   - è­¦å‘Šå…è®¸ä½†éœ€è¦è®°å½•

1. **æŠ¥å‘Šç•™ç—•**
   - è¾“å‡ºJSON/CSVæŠ¥å‘Š
   - å­˜æ¡£äº`out/`ç›®å½•
   - ä¿ç•™å†å²æŠ¥å‘Šç”¨äºè¶‹åŠ¿åˆ†æ

1. **æ¸è¿›ä¿®å¤**
   - å…è®¸è­¦å‘Šç­‰çº§
   - å…³é”®é”™è¯¯å¿…é¡»ä¿®å¤
   - æ”¯æŒè‡ªåŠ¨ä¿®å¤åŠŸèƒ½

1. **èŒƒå›´åŒ–æ£€æŸ¥**
   - ä»…æ£€æŸ¥æ”¹åŠ¨é›†ä»¥æé€Ÿ
   - æ”¯æŒå¢é‡æ£€æŸ¥
   - å®šæœŸå…¨é‡æ£€æŸ¥

1. **å›½é™…åŒ–è”åŠ¨**
   - ä¸`08.03`è§„èŒƒè”åŠ¨
   - åŒè¯­æ¡ç›®åŒæ­¥æ£€æŸ¥
   - æœ¯è¯­è¡¨ç»Ÿä¸€ç®¡ç†

---

## å…«ã€å‚è€ƒèµ„æº

### 8.1 å®˜æ–¹æ–‡æ¡£

- [Markdownè§„èŒƒ](https://daringfireball.net/projects/markdown/)
- [CommonMarkè§„èŒƒ](https://commonmark.org/)
- [markdownlintè§„åˆ™](https://github.com/DavidAnson/markdownlint)

### 8.2 ç½‘ç»œèµ„æº

- [Valeæ–‡æ¡£](https://docs.errata.ai/vale/about)
- [markdownlint-cli](https://github.com/igorshubovych/markdownlint-cli)
- [é“¾æ¥æ£€æŸ¥å·¥å…·](https://github.com/linkchecker/linkchecker)

### 8.3 ç›¸å…³æ–‡æ¡£

- `INDEX.md`ï¼ˆäº¤å‰å¼•ç”¨æºï¼‰
- `08.03-å›½é™…åŒ–æ ‡å‡†æŒ‡å—.md`ï¼ˆæœ¯è¯­/æ ¼å¼ï¼‰
- `PostgreSQLè´¨é‡ä¿è¯æœºåˆ¶.md`ï¼ˆè´¨é‡ä¿è¯æ¡†æ¶ï¼‰

---

**ç»´æŠ¤è€…**: Data-Science Team
**æœ€åæ›´æ–°**: 2025-01-15
**ç‰ˆæœ¬**: 1.0
