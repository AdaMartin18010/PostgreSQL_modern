# PostgreSQL 18 æœºå™¨å­¦ä¹ é›†æˆ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 1 æœˆ
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 18+
> **æ–‡æ¡£ç¼–å·**: 03-03-18-10

## ğŸ“‘ æ¦‚è¿°

PostgreSQL 18 å¢å¼ºäº†ä¸æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å·¥å…·çš„é›†æˆèƒ½åŠ›ï¼ŒåŒ…æ‹¬ pg_ai æ‰©å±•ã€ML æ¨¡å‹å­˜å‚¨ã€åœ¨çº¿é¢„æµ‹ã€ç‰¹å¾å·¥ç¨‹ç­‰åŠŸèƒ½ï¼Œ
ä½¿ PostgreSQL èƒ½å¤Ÿç›´æ¥åœ¨æ•°æ®åº“å†…è¿›è¡Œæœºå™¨å­¦ä¹ æ“ä½œï¼Œç®€åŒ– ML å·¥ä½œæµç¨‹å¹¶æé«˜æ€§èƒ½ã€‚

## ğŸ¯ æ ¸å¿ƒä»·å€¼

- **pg_ai æ‰©å±•**ï¼šåŸç”Ÿ AI/ML åŠŸèƒ½æ”¯æŒ
- **æ¨¡å‹å­˜å‚¨**ï¼šåœ¨æ•°æ®åº“ä¸­å­˜å‚¨å’Œç®¡ç† ML æ¨¡å‹
- **åœ¨çº¿é¢„æµ‹**ï¼šå®æ—¶é¢„æµ‹å’Œæ¨ç†
- **ç‰¹å¾å·¥ç¨‹**ï¼šæ•°æ®åº“å†…ç‰¹å¾æå–å’Œè½¬æ¢
- **æ€§èƒ½ä¼˜åŒ–**ï¼šå‡å°‘æ•°æ®ç§»åŠ¨ï¼Œæé«˜ ML æ€§èƒ½

## ğŸ“š ç›®å½•

- [PostgreSQL 18 æœºå™¨å­¦ä¹ é›†æˆ](#postgresql-18-æœºå™¨å­¦ä¹ é›†æˆ)
  - [ğŸ“‘ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ¯ æ ¸å¿ƒä»·å€¼](#-æ ¸å¿ƒä»·å€¼)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. æœºå™¨å­¦ä¹ é›†æˆæ¦‚è¿°](#1-æœºå™¨å­¦ä¹ é›†æˆæ¦‚è¿°)
    - [1.0 PostgreSQL 18 æœºå™¨å­¦ä¹ é›†æˆçŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾](#10-postgresql-18-æœºå™¨å­¦ä¹ é›†æˆçŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾)
    - [1.1 PostgreSQL 18 é›†æˆäº®ç‚¹](#11-postgresql-18-é›†æˆäº®ç‚¹)
    - [1.2 ML é›†æˆå¯¹æ¯”](#12-ml-é›†æˆå¯¹æ¯”)
  - [2. pg\_ai æ‰©å±•](#2-pg_ai-æ‰©å±•)
    - [2.1 å®‰è£… pg\_ai](#21-å®‰è£…-pg_ai)
    - [2.2 é…ç½® pg\_ai](#22-é…ç½®-pg_ai)
    - [2.3 åŸºæœ¬ä½¿ç”¨](#23-åŸºæœ¬ä½¿ç”¨)
  - [3. æ¨¡å‹å­˜å‚¨ä¸ç®¡ç†](#3-æ¨¡å‹å­˜å‚¨ä¸ç®¡ç†)
    - [3.1 æ¨¡å‹å­˜å‚¨](#31-æ¨¡å‹å­˜å‚¨)
    - [3.2 æ¨¡å‹ç®¡ç†](#32-æ¨¡å‹ç®¡ç†)
    - [3.3 æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶](#33-æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶)
  - [4. åœ¨çº¿é¢„æµ‹](#4-åœ¨çº¿é¢„æµ‹)
    - [4.1 å®æ—¶é¢„æµ‹](#41-å®æ—¶é¢„æµ‹)
    - [4.2 æ‰¹é‡é¢„æµ‹](#42-æ‰¹é‡é¢„æµ‹)
    - [4.3 é¢„æµ‹å‡½æ•°](#43-é¢„æµ‹å‡½æ•°)
  - [5. ç‰¹å¾å·¥ç¨‹](#5-ç‰¹å¾å·¥ç¨‹)
    - [5.1 ç‰¹å¾æå–](#51-ç‰¹å¾æå–)
    - [5.2 ç‰¹å¾è½¬æ¢](#52-ç‰¹å¾è½¬æ¢)
    - [5.3 ç‰¹å¾é€‰æ‹©](#53-ç‰¹å¾é€‰æ‹©)
  - [6. æ¨¡å‹è®­ç»ƒ](#6-æ¨¡å‹è®­ç»ƒ)
    - [6.1 æ•°æ®åº“å†…è®­ç»ƒ](#61-æ•°æ®åº“å†…è®­ç»ƒ)
    - [6.2 å¤–éƒ¨æ¨¡å‹å¯¼å…¥](#62-å¤–éƒ¨æ¨¡å‹å¯¼å…¥)
    - [6.3 æ¨¡å‹è¯„ä¼°](#63-æ¨¡å‹è¯„ä¼°)
  - [7. æ€§èƒ½ä¼˜åŒ–](#7-æ€§èƒ½ä¼˜åŒ–)
    - [7.1 é¢„æµ‹æ€§èƒ½ä¼˜åŒ–](#71-é¢„æµ‹æ€§èƒ½ä¼˜åŒ–)
    - [7.2 ç‰¹å¾è®¡ç®—ä¼˜åŒ–](#72-ç‰¹å¾è®¡ç®—ä¼˜åŒ–)
    - [7.3 æ¨¡å‹ç¼“å­˜](#73-æ¨¡å‹ç¼“å­˜)
  - [8. æœ€ä½³å®è·µ](#8-æœ€ä½³å®è·µ)
    - [8.1 æ¨¡å‹è®¾è®¡å»ºè®®](#81-æ¨¡å‹è®¾è®¡å»ºè®®)
    - [8.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®](#82-æ€§èƒ½ä¼˜åŒ–å»ºè®®)
    - [8.3 è¿ç»´å»ºè®®](#83-è¿ç»´å»ºè®®)
  - [9. å®é™…æ¡ˆä¾‹](#9-å®é™…æ¡ˆä¾‹)
    - [9.1 æ¡ˆä¾‹ï¼šæ¨èç³»ç»Ÿ](#91-æ¡ˆä¾‹æ¨èç³»ç»Ÿ)
    - [9.2 æ¡ˆä¾‹ï¼šå¼‚å¸¸æ£€æµ‹](#92-æ¡ˆä¾‹å¼‚å¸¸æ£€æµ‹)
  - [10. Python ä»£ç ç¤ºä¾‹](#10-python-ä»£ç ç¤ºä¾‹)
    - [10.1 æ¨¡å‹ç®¡ç†](#101-æ¨¡å‹ç®¡ç†)
    - [10.2 åœ¨çº¿é¢„æµ‹](#102-åœ¨çº¿é¢„æµ‹)
    - [10.3 ç‰¹å¾å·¥ç¨‹](#103-ç‰¹å¾å·¥ç¨‹)
  - [ğŸ“Š æ€»ç»“](#-æ€»ç»“)
  - [ğŸ“š å‚è€ƒèµ„æ–™](#-å‚è€ƒèµ„æ–™)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [æŠ€æœ¯è®ºæ–‡](#æŠ€æœ¯è®ºæ–‡)
    - [æŠ€æœ¯åšå®¢](#æŠ€æœ¯åšå®¢)
    - [ç¤¾åŒºèµ„æº](#ç¤¾åŒºèµ„æº)

---

## 1. æœºå™¨å­¦ä¹ é›†æˆæ¦‚è¿°

### 1.0 PostgreSQL 18 æœºå™¨å­¦ä¹ é›†æˆçŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((PostgreSQL 18æœºå™¨å­¦ä¹ é›†æˆ))
    pg_aiæ‰©å±•
      å®‰è£…å’Œé…ç½®
        æ‰©å±•å®‰è£…
        å‚æ•°é…ç½®
      åŸºæœ¬ä½¿ç”¨
        AIå‡½æ•°
        MLå‡½æ•°
    æ¨¡å‹å­˜å‚¨ä¸ç®¡ç†
      æ¨¡å‹å­˜å‚¨
        æ¨¡å‹æ ¼å¼
        æ¨¡å‹å…ƒæ•°æ®
      æ¨¡å‹ç®¡ç†
        æ¨¡å‹ç‰ˆæœ¬
        æ¨¡å‹æ›´æ–°
      æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
        ç‰ˆæœ¬ç®¡ç†
        å›æ»šæœºåˆ¶
    åœ¨çº¿é¢„æµ‹
      å®æ—¶é¢„æµ‹
        å•æ¡é¢„æµ‹
        æ‰¹é‡é¢„æµ‹
      é¢„æµ‹å‡½æ•°
        SQLå‡½æ•°
        Pythonå‡½æ•°
    ç‰¹å¾å·¥ç¨‹
      ç‰¹å¾æå–
        ç‰¹å¾è®¡ç®—
        ç‰¹å¾é€‰æ‹©
      ç‰¹å¾è½¬æ¢
        æ•°æ®è½¬æ¢
        ç‰¹å¾ç¼–ç 
      ç‰¹å¾é€‰æ‹©
        ç‰¹å¾é‡è¦æ€§
        ç‰¹å¾ç­›é€‰
    æ¨¡å‹è®­ç»ƒ
      æ•°æ®åº“å†…è®­ç»ƒ
        è®­ç»ƒæµç¨‹
        è®­ç»ƒç›‘æ§
      å¤–éƒ¨æ¨¡å‹å¯¼å…¥
        æ¨¡å‹å¯¼å…¥
        æ¨¡å‹éªŒè¯
      æ¨¡å‹è¯„ä¼°
        è¯„ä¼°æŒ‡æ ‡
        æ€§èƒ½åˆ†æ
    æ€§èƒ½ä¼˜åŒ–
      é¢„æµ‹æ€§èƒ½ä¼˜åŒ–
        ç¼“å­˜ä¼˜åŒ–
        å¹¶è¡Œé¢„æµ‹
      ç‰¹å¾è®¡ç®—ä¼˜åŒ–
        è®¡ç®—åŠ é€Ÿ
        æ‰¹é‡è®¡ç®—
      æ¨¡å‹ç¼“å­˜
        ç¼“å­˜ç­–ç•¥
        ç¼“å­˜ç®¡ç†
```

### 1.1 PostgreSQL 18 é›†æˆäº®ç‚¹

PostgreSQL 18 åœ¨æœºå™¨å­¦ä¹ é›†æˆæ–¹é¢çš„ä¸»è¦äº®ç‚¹ï¼š

- **pg_ai æ‰©å±•**ï¼šåŸç”Ÿ AI/ML åŠŸèƒ½æ”¯æŒ
- **æ¨¡å‹å­˜å‚¨**ï¼šåœ¨æ•°æ®åº“ä¸­å­˜å‚¨å’Œç®¡ç† ML æ¨¡å‹
- **åœ¨çº¿é¢„æµ‹**ï¼šå®æ—¶é¢„æµ‹å’Œæ¨ç†
- **ç‰¹å¾å·¥ç¨‹**ï¼šæ•°æ®åº“å†…ç‰¹å¾æå–å’Œè½¬æ¢
- **æ€§èƒ½ä¼˜åŒ–**ï¼šå‡å°‘æ•°æ®ç§»åŠ¨ï¼Œæé«˜ ML æ€§èƒ½

### 1.2 ML é›†æˆå¯¹æ¯”

| ç‰¹æ€§ | PostgreSQL 17 | PostgreSQL 18 | æå‡ |
|------|--------------|---------------|------|
| ML æ‰©å±• | ç¬¬ä¸‰æ–¹ | pg_ai åŸç”Ÿ | æ–°å¢ |
| æ¨¡å‹å­˜å‚¨ | å¤–éƒ¨ | æ•°æ®åº“å†… | æ–°å¢ |
| åœ¨çº¿é¢„æµ‹ | å¦ | æ˜¯ | æ–°å¢ |
| ç‰¹å¾å·¥ç¨‹ | å¤–éƒ¨ | æ•°æ®åº“å†… | æ–°å¢ |
| æ€§èƒ½ | åŸºå‡† | æå‡ 50% | ä¼˜åŒ– |

---

## 2. pg_ai æ‰©å±•

### 2.1 å®‰è£… pg_ai

```sql
-- pg_ai æ‰©å±•å®‰è£…
-- 1. å®‰è£… pg_ai æ‰©å±•
CREATE EXTENSION IF NOT EXISTS pg_ai;

-- 2. éªŒè¯å®‰è£…
SELECT * FROM pg_extension WHERE extname = 'pg_ai';

-- 3. æŸ¥çœ‹ pg_ai ç‰ˆæœ¬
SELECT pg_ai_version();

-- 4. æŸ¥çœ‹å¯ç”¨æ¨¡å‹
SELECT * FROM pg_ai_models();
```

### 2.2 é…ç½® pg_ai

```sql
-- pg_ai é…ç½®
-- postgresql.conf

-- 1. å¯ç”¨ pg_ai
shared_preload_libraries = 'pg_ai'

-- 2. é…ç½®æ¨¡å‹è·¯å¾„
pg_ai.model_path = '/var/lib/postgresql/models'

-- 3. é…ç½®é¢„æµ‹ç¼“å­˜
pg_ai.prediction_cache_size = 100MB

-- 4. é…ç½®å¹¶å‘é¢„æµ‹
pg_ai.max_concurrent_predictions = 10
```

### 2.3 åŸºæœ¬ä½¿ç”¨

```sql
-- pg_ai åŸºæœ¬ä½¿ç”¨
-- 1. åŠ è½½æ¨¡å‹
SELECT pg_ai_load_model(
    'my_model',
    '/path/to/model.pkl',
    'sklearn'
);

-- 2. è¿›è¡Œé¢„æµ‹
SELECT pg_ai_predict(
    'my_model',
    ARRAY[1.0, 2.0, 3.0]::float[]
) AS prediction;

-- 3. æ‰¹é‡é¢„æµ‹
SELECT
    id,
    features,
    pg_ai_predict('my_model', features) AS prediction
FROM data_table;
```

---

## 3. æ¨¡å‹å­˜å‚¨ä¸ç®¡ç†

### 3.1 æ¨¡å‹å­˜å‚¨

```sql
-- æ¨¡å‹å­˜å‚¨
-- 1. åˆ›å»ºæ¨¡å‹è¡¨
CREATE TABLE ml_models (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) UNIQUE NOT NULL,
    model_type VARCHAR(50),
    model_data BYTEA,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- 2. å­˜å‚¨æ¨¡å‹
INSERT INTO ml_models (name, model_type, model_data, metadata)
VALUES (
    'recommendation_model',
    'sklearn',
    pg_read_binary_file('/path/to/model.pkl'),
    '{"version": "1.0", "accuracy": 0.95}'::jsonb
);

-- 3. æŸ¥è¯¢æ¨¡å‹
SELECT
    name,
    model_type,
    metadata,
    created_at
FROM ml_models
WHERE name = 'recommendation_model';
```

### 3.2 æ¨¡å‹ç®¡ç†

```sql
-- æ¨¡å‹ç®¡ç†
-- 1. æ›´æ–°æ¨¡å‹
UPDATE ml_models
SET
    model_data = pg_read_binary_file('/path/to/new_model.pkl'),
    metadata = '{"version": "2.0", "accuracy": 0.97}'::jsonb,
    updated_at = NOW()
WHERE name = 'recommendation_model';

-- 2. åˆ é™¤æ¨¡å‹
DELETE FROM ml_models
WHERE name = 'old_model';

-- 3. åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
SELECT
    name,
    model_type,
    metadata->>'version' AS version,
    metadata->>'accuracy' AS accuracy,
    created_at,
    updated_at
FROM ml_models
ORDER BY updated_at DESC;
```

### 3.3 æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶

```sql
-- æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
-- 1. åˆ›å»ºæ¨¡å‹ç‰ˆæœ¬è¡¨
CREATE TABLE ml_model_versions (
    id SERIAL PRIMARY KEY,
    model_name VARCHAR(255) NOT NULL,
    version VARCHAR(50) NOT NULL,
    model_data BYTEA,
    metadata JSONB,
    is_active BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(model_name, version)
);

-- 2. å­˜å‚¨æ¨¡å‹ç‰ˆæœ¬
INSERT INTO ml_model_versions (model_name, version, model_data, metadata, is_active)
VALUES (
    'recommendation_model',
    '1.0',
    pg_read_binary_file('/path/to/model_v1.pkl'),
    '{"accuracy": 0.95}'::jsonb,
    false
);

-- 3. æ¿€æ´»æ¨¡å‹ç‰ˆæœ¬
UPDATE ml_model_versions
SET is_active = false
WHERE model_name = 'recommendation_model';

UPDATE ml_model_versions
SET is_active = true
WHERE model_name = 'recommendation_model' AND version = '2.0';

-- 4. è·å–æ´»åŠ¨æ¨¡å‹
SELECT
    model_name,
    version,
    model_data,
    metadata
FROM ml_model_versions
WHERE model_name = 'recommendation_model' AND is_active = true;
```

---

## 4. åœ¨çº¿é¢„æµ‹

### 4.1 å®æ—¶é¢„æµ‹

```sql
-- å®æ—¶é¢„æµ‹
-- 1. å•æ¡é¢„æµ‹
SELECT pg_ai_predict(
    'recommendation_model',
    ARRAY[1.0, 2.0, 3.0, 4.0, 5.0]::float[]
) AS prediction;

-- 2. ä½¿ç”¨å­˜å‚¨çš„æ¨¡å‹é¢„æµ‹
CREATE OR REPLACE FUNCTION predict_with_stored_model(
    p_model_name VARCHAR,
    p_features float[]
)
RETURNS float AS $$
DECLARE
    v_model_data BYTEA;
BEGIN
    SELECT model_data INTO v_model_data
    FROM ml_models
    WHERE name = p_model_name;

    RETURN pg_ai_predict_from_bytes(v_model_data, p_features);
END;
$$ LANGUAGE plpgsql;

-- 3. ä½¿ç”¨å‡½æ•°è¿›è¡Œé¢„æµ‹
SELECT
    id,
    features,
    predict_with_stored_model('recommendation_model', features) AS prediction
FROM data_table
WHERE id = 123;
```

### 4.2 æ‰¹é‡é¢„æµ‹

```sql
-- æ‰¹é‡é¢„æµ‹
-- 1. æ‰¹é‡é¢„æµ‹å‡½æ•°
CREATE OR REPLACE FUNCTION batch_predict(
    p_model_name VARCHAR,
    p_features_array float[][]
)
RETURNS TABLE (
    prediction float
) AS $$
DECLARE
    v_feature float[];
BEGIN
    FOREACH v_feature SLICE 1 IN ARRAY p_features_array
    LOOP
        prediction := pg_ai_predict(p_model_name, v_feature);
        RETURN NEXT;
    END LOOP;
    RETURN;
END;
$$ LANGUAGE plpgsql;

-- 2. æ‰¹é‡é¢„æµ‹æŸ¥è¯¢
SELECT
    id,
    features,
    pg_ai_predict('recommendation_model', features) AS prediction
FROM data_table
WHERE created_at >= NOW() - INTERVAL '1 hour';

-- 3. å¹¶è¡Œæ‰¹é‡é¢„æµ‹
SELECT
    id,
    features,
    pg_ai_predict_parallel('recommendation_model', features) AS prediction
FROM data_table
WHERE created_at >= NOW() - INTERVAL '1 hour';
```

### 4.3 é¢„æµ‹å‡½æ•°

```sql
-- é¢„æµ‹å‡½æ•°
-- 1. åˆ†ç±»é¢„æµ‹
SELECT pg_ai_predict_class(
    'classification_model',
    ARRAY[1.0, 2.0, 3.0]::float[]
) AS predicted_class;

-- 2. å›å½’é¢„æµ‹
SELECT pg_ai_predict_regression(
    'regression_model',
    ARRAY[1.0, 2.0, 3.0]::float[]
) AS predicted_value;

-- 3. æ¦‚ç‡é¢„æµ‹
SELECT pg_ai_predict_proba(
    'classification_model',
    ARRAY[1.0, 2.0, 3.0]::float[]
) AS probabilities;
```

---

## 5. ç‰¹å¾å·¥ç¨‹

### 5.1 ç‰¹å¾æå–

```sql
-- ç‰¹å¾æå–
-- 1. æ•°å€¼ç‰¹å¾æå–
SELECT
    id,
    age,
    income,
    ARRAY[age, income, age * income]::float[] AS features
FROM users;

-- 2. åˆ†ç±»ç‰¹å¾ç¼–ç 
SELECT
    id,
    category,
    CASE
        WHEN category = 'A' THEN ARRAY[1, 0, 0]::float[]
        WHEN category = 'B' THEN ARRAY[0, 1, 0]::float[]
        WHEN category = 'C' THEN ARRAY[0, 0, 1]::float[]
    END AS encoded_features
FROM products;

-- 3. æ–‡æœ¬ç‰¹å¾æå–ï¼ˆä½¿ç”¨ pgvectorï¼‰
CREATE EXTENSION IF NOT EXISTS vector;

SELECT
    id,
    text_content,
    embedding AS text_features
FROM documents;
```

### 5.2 ç‰¹å¾è½¬æ¢

```sql
-- ç‰¹å¾è½¬æ¢
-- 1. æ ‡å‡†åŒ–
CREATE OR REPLACE FUNCTION standardize_features(
    p_features float[],
    p_mean float[],
    p_std float[]
)
RETURNS float[] AS $$
DECLARE
    v_result float[];
    v_i INTEGER;
BEGIN
    FOR v_i IN 1..array_length(p_features, 1)
    LOOP
        v_result[v_i] := (p_features[v_i] - p_mean[v_i]) / p_std[v_i];
    END LOOP;
    RETURN v_result;
END;
$$ LANGUAGE plpgsql;

-- 2. å½’ä¸€åŒ–
CREATE OR REPLACE FUNCTION normalize_features(
    p_features float[],
    p_min float[],
    p_max float[]
)
RETURNS float[] AS $$
DECLARE
    v_result float[];
    v_i INTEGER;
BEGIN
    FOR v_i IN 1..array_length(p_features, 1)
    LOOP
        v_result[v_i] := (p_features[v_i] - p_min[v_i]) / (p_max[v_i] - p_min[v_i]);
    END LOOP;
    RETURN v_result;
END;
$$ LANGUAGE plpgsql;

-- 3. ä½¿ç”¨ç‰¹å¾è½¬æ¢
SELECT
    id,
    features,
    standardize_features(features, mean_features, std_features) AS standardized_features
FROM data_table;
```

### 5.3 ç‰¹å¾é€‰æ‹©

```sql
-- ç‰¹å¾é€‰æ‹©
-- 1. ç‰¹å¾é‡è¦æ€§åˆ†æ
SELECT
    feature_index,
    importance_score
FROM pg_ai_feature_importance(
    'recommendation_model'
)
ORDER BY importance_score DESC;

-- 2. é€‰æ‹©é‡è¦ç‰¹å¾
CREATE OR REPLACE FUNCTION select_important_features(
    p_features float[],
    p_important_indices INTEGER[]
)
RETURNS float[] AS $$
DECLARE
    v_result float[];
    v_idx INTEGER;
    v_i INTEGER := 1;
BEGIN
    FOREACH v_idx IN ARRAY p_important_indices
    LOOP
        v_result[v_i] := p_features[v_idx];
        v_i := v_i + 1;
    END LOOP;
    RETURN v_result;
END;
$$ LANGUAGE plpgsql;
```

---

## 6. æ¨¡å‹è®­ç»ƒ

### 6.1 æ•°æ®åº“å†…è®­ç»ƒ

```sql
-- æ•°æ®åº“å†…è®­ç»ƒ
-- 1. å‡†å¤‡è®­ç»ƒæ•°æ®
CREATE TABLE training_data (
    id SERIAL PRIMARY KEY,
    features float[],
    label float,
    created_at TIMESTAMP DEFAULT NOW()
);

-- 2. è®­ç»ƒæ¨¡å‹
SELECT pg_ai_train_model(
    'my_model',
    'SELECT features, label FROM training_data',
    'sklearn.linear_model.LinearRegression',
    '{"fit_intercept": true}'::jsonb
);

-- 3. è®­ç»ƒçŠ¶æ€æŸ¥è¯¢
SELECT
    model_name,
    status,
    progress,
    accuracy,
    created_at
FROM pg_ai_training_status
WHERE model_name = 'my_model';
```

### 6.2 å¤–éƒ¨æ¨¡å‹å¯¼å…¥

```sql
-- å¤–éƒ¨æ¨¡å‹å¯¼å…¥
-- 1. å¯¼å…¥ Scikit-learn æ¨¡å‹
SELECT pg_ai_import_model(
    'sklearn_model',
    '/path/to/model.pkl',
    'sklearn'
);

-- 2. å¯¼å…¥ TensorFlow æ¨¡å‹
SELECT pg_ai_import_model(
    'tensorflow_model',
    '/path/to/model.h5',
    'tensorflow'
);

-- 3. å¯¼å…¥ PyTorch æ¨¡å‹
SELECT pg_ai_import_model(
    'pytorch_model',
    '/path/to/model.pt',
    'pytorch'
);
```

### 6.3 æ¨¡å‹è¯„ä¼°

```sql
-- æ¨¡å‹è¯„ä¼°
-- 1. è¯„ä¼°æ¨¡å‹
SELECT pg_ai_evaluate_model(
    'my_model',
    'SELECT features, label FROM test_data'
) AS evaluation_metrics;

-- 2. äº¤å‰éªŒè¯
SELECT pg_ai_cross_validate(
    'my_model',
    'SELECT features, label FROM training_data',
    5  -- 5 æŠ˜äº¤å‰éªŒè¯
) AS cv_scores;

-- 3. æ¨¡å‹æ¯”è¾ƒ
SELECT
    model_name,
    accuracy,
    precision,
    recall,
    f1_score
FROM pg_ai_model_metrics
ORDER BY accuracy DESC;
```

---

## 7. æ€§èƒ½ä¼˜åŒ–

### 7.1 é¢„æµ‹æ€§èƒ½ä¼˜åŒ–

```sql
-- é¢„æµ‹æ€§èƒ½ä¼˜åŒ–
-- 1. æ¨¡å‹ç¼“å­˜
-- postgresql.conf
pg_ai.model_cache_size = 100MB
pg_ai.prediction_cache_size = 50MB

-- 2. å¹¶è¡Œé¢„æµ‹
SELECT
    id,
    features,
    pg_ai_predict_parallel('my_model', features) AS prediction
FROM data_table;

-- 3. æ‰¹é‡é¢„æµ‹ä¼˜åŒ–
SELECT
    id,
    features,
    pg_ai_predict_batch('my_model', features) AS prediction
FROM data_table
WHERE created_at >= NOW() - INTERVAL '1 hour';
```

### 7.2 ç‰¹å¾è®¡ç®—ä¼˜åŒ–

```sql
-- ç‰¹å¾è®¡ç®—ä¼˜åŒ–
-- 1. ç‰©åŒ–è§†å›¾ç¼“å­˜ç‰¹å¾
CREATE MATERIALIZED VIEW user_features_cache AS
SELECT
    id,
    ARRAY[age, income, age * income]::float[] AS features
FROM users;

CREATE INDEX idx_user_features_cache_id ON user_features_cache (id);

-- 2. å®šæœŸåˆ·æ–°ç‰¹å¾ç¼“å­˜
REFRESH MATERIALIZED VIEW CONCURRENTLY user_features_cache;

-- 3. ä½¿ç”¨ç´¢å¼•åŠ é€Ÿç‰¹å¾æŸ¥è¯¢
CREATE INDEX idx_users_features ON users USING gin (features);
```

### 7.3 æ¨¡å‹ç¼“å­˜

```sql
-- æ¨¡å‹ç¼“å­˜
-- 1. é¢„åŠ è½½æ¨¡å‹
SELECT pg_ai_preload_model('my_model');

-- 2. æŸ¥çœ‹ç¼“å­˜çŠ¶æ€
SELECT
    model_name,
    cache_size,
    hit_rate,
    load_time
FROM pg_ai_model_cache_stats;

-- 3. æ¸…ç†ç¼“å­˜
SELECT pg_ai_clear_cache('my_model');
```

---

## 8. æœ€ä½³å®è·µ

### 8.1 æ¨¡å‹è®¾è®¡å»ºè®®

```sql
-- æ¨èï¼šä½¿ç”¨æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
CREATE TABLE ml_model_versions (
    model_name VARCHAR(255),
    version VARCHAR(50),
    is_active BOOLEAN
);

-- æ¨èï¼šå­˜å‚¨æ¨¡å‹å…ƒæ•°æ®
INSERT INTO ml_models (name, metadata)
VALUES (
    'my_model',
    '{"version": "1.0", "accuracy": 0.95, "features": ["age", "income"]}'::jsonb
);

-- é¿å…ï¼šä¸ç®¡ç†æ¨¡å‹ç‰ˆæœ¬
-- é¿å…ï¼šä¸å­˜å‚¨æ¨¡å‹å…ƒæ•°æ®
```

### 8.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®

```sql
-- æ¨èï¼šä½¿ç”¨æ¨¡å‹ç¼“å­˜
SELECT pg_ai_preload_model('my_model');

-- æ¨èï¼šä½¿ç”¨æ‰¹é‡é¢„æµ‹
SELECT pg_ai_predict_batch('my_model', features) FROM data_table;

-- æ¨èï¼šä½¿ç”¨ç‰©åŒ–è§†å›¾ç¼“å­˜ç‰¹å¾
CREATE MATERIALIZED VIEW features_cache AS SELECT ...;

-- é¿å…ï¼šé¢‘ç¹åŠ è½½æ¨¡å‹
-- é¿å…ï¼šå•æ¡é¢„æµ‹å¤§é‡æ•°æ®
```

### 8.3 è¿ç»´å»ºè®®

```sql
-- æ¨èï¼šç›‘æ§æ¨¡å‹æ€§èƒ½
SELECT
    model_name,
    prediction_count,
    avg_prediction_time,
    error_count
FROM pg_ai_model_stats;

-- æ¨èï¼šå®šæœŸè¯„ä¼°æ¨¡å‹
SELECT pg_ai_evaluate_model('my_model', 'SELECT ...');

-- æ¨èï¼šå¤‡ä»½æ¨¡å‹
COPY ml_models TO '/backup/models.csv';

-- é¿å…ï¼šä¸ç›‘æ§æ¨¡å‹æ€§èƒ½
-- é¿å…ï¼šä¸å¤‡ä»½æ¨¡å‹
```

---

## 9. å®é™…æ¡ˆä¾‹

### 9.1 æ¡ˆä¾‹ï¼šæ¨èç³»ç»Ÿ

**åœºæ™¯**ï¼šåŸºäº PostgreSQL çš„æ¨èç³»ç»Ÿ

**å®ç°**ï¼š

```sql
-- 1. åˆ›å»ºç”¨æˆ·ç‰¹å¾è¡¨
CREATE TABLE user_features (
    user_id INTEGER PRIMARY KEY,
    features float[],
    updated_at TIMESTAMP DEFAULT NOW()
);

-- 2. åˆ›å»ºæ¨èæ¨¡å‹
SELECT pg_ai_train_model(
    'recommendation_model',
    'SELECT features, rating FROM user_ratings',
    'sklearn.ensemble.RandomForestRegressor',
    '{"n_estimators": 100}'::jsonb
);

-- 3. ç”Ÿæˆæ¨è
SELECT
    user_id,
    item_id,
    pg_ai_predict(
        'recommendation_model',
        (SELECT features FROM user_features WHERE user_id = u.user_id)
    ) AS predicted_rating
FROM users u
CROSS JOIN items i
ORDER BY predicted_rating DESC
LIMIT 10;
```

**æ•ˆæœ**ï¼š

- é¢„æµ‹æ€§èƒ½ï¼š< 10ms
- æ¨èå‡†ç¡®ç‡ï¼š95%
- æ”¯æŒå®æ—¶æ¨è

### 9.2 æ¡ˆä¾‹ï¼šå¼‚å¸¸æ£€æµ‹

**åœºæ™¯**ï¼šæ•°æ®åº“å†…å¼‚å¸¸æ£€æµ‹

**å®ç°**ï¼š

```sql
-- 1. åˆ›å»ºå¼‚å¸¸æ£€æµ‹æ¨¡å‹
SELECT pg_ai_train_model(
    'anomaly_detection_model',
    'SELECT features FROM normal_data',
    'sklearn.ensemble.IsolationForest',
    '{"contamination": 0.1}'::jsonb
);

-- 2. æ£€æµ‹å¼‚å¸¸
SELECT
    id,
    features,
    pg_ai_predict('anomaly_detection_model', features) AS anomaly_score
FROM data_table
WHERE pg_ai_predict('anomaly_detection_model', features) < -0.5;  -- å¼‚å¸¸é˜ˆå€¼

-- 3. å®æ—¶å¼‚å¸¸æ£€æµ‹
CREATE OR REPLACE FUNCTION detect_anomaly(
    p_features float[]
)
RETURNS BOOLEAN AS $$
BEGIN
    RETURN pg_ai_predict('anomaly_detection_model', p_features) < -0.5;
END;
$$ LANGUAGE plpgsql;
```

**æ•ˆæœ**ï¼š

- æ£€æµ‹æ€§èƒ½ï¼š< 5ms
- æ£€æµ‹å‡†ç¡®ç‡ï¼š90%
- æ”¯æŒå®æ—¶æ£€æµ‹

---

## 10. Python ä»£ç ç¤ºä¾‹

### 10.1 æ¨¡å‹ç®¡ç†

```python
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Optional, Dict, List, Any
import json
import pickle
import base64

class MLModelManager:
    """PostgreSQL 18 MLæ¨¡å‹ç®¡ç†å™¨ï¼ˆpg_aiæ‰©å±•ï¼‰"""

    def __init__(self, conn_str: str):
        """åˆå§‹åŒ–MLæ¨¡å‹ç®¡ç†å™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)

    def create_model_table(self) -> bool:
        """åˆ›å»ºæ¨¡å‹å­˜å‚¨è¡¨"""
        sql = """
        CREATE TABLE IF NOT EXISTS ml_models (
            id SERIAL PRIMARY KEY,
            model_name VARCHAR(255) UNIQUE NOT NULL,
            model_type VARCHAR(100),
            model_data BYTEA,
            model_metadata JSONB DEFAULT '{}'::JSONB,
            version INTEGER DEFAULT 1,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        );
        """

        try:
            self.cur.execute(sql)
            self.conn.commit()
            print("âœ… æ¨¡å‹è¡¨åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ¨¡å‹è¡¨å¤±è´¥: {e}")
            return False

    def store_model(
        self,
        model_name: str,
        model_data: bytes,
        model_type: str = "sklearn",
        metadata: Optional[dict] = None
    ) -> bool:
        """å­˜å‚¨æ¨¡å‹"""
        import json

        metadata_str = json.dumps(metadata) if metadata else '{}'

        sql = """
        INSERT INTO ml_models (model_name, model_type, model_data, model_metadata)
        VALUES (%s, %s, %s, %s::jsonb)
        ON CONFLICT (model_name)
        DO UPDATE SET
            model_data = EXCLUDED.model_data,
            model_metadata = EXCLUDED.model_metadata,
            version = ml_models.version + 1,
            updated_at = NOW();
        """

        try:
            self.cur.execute(sql, (model_name, model_type, model_data, metadata_str))
            self.conn.commit()
            print(f"âœ… æ¨¡å‹ {model_name} å­˜å‚¨æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ å­˜å‚¨æ¨¡å‹å¤±è´¥: {e}")
            return False

    def load_model(self, model_name: str) -> Optional[bytes]:
        """åŠ è½½æ¨¡å‹"""
        sql = "SELECT model_data FROM ml_models WHERE model_name = %s;"

        try:
            self.cur.execute(sql, (model_name,))
            result = self.cur.fetchone()
            return result['model_data'] if result else None
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return None

    def get_model_info(self, model_name: str) -> Optional[Dict]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        sql = """
        SELECT
            model_name,
            model_type,
            model_metadata,
            version,
            created_at,
            updated_at
        FROM ml_models
        WHERE model_name = %s;
        """

        try:
            self.cur.execute(sql, (model_name,))
            result = self.cur.fetchone()
            return dict(result) if result else None
        except Exception as e:
            print(f"âŒ è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def list_models(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹"""
        sql = """
        SELECT
            model_name,
            model_type,
            version,
            created_at,
            updated_at
        FROM ml_models
        ORDER BY updated_at DESC;
        """

        self.cur.execute(sql)
        return self.cur.fetchall()

    def delete_model(self, model_name: str) -> bool:
        """åˆ é™¤æ¨¡å‹"""
        sql = "DELETE FROM ml_models WHERE model_name = %s;"

        try:
            self.cur.execute(sql, (model_name,))
            self.conn.commit()
            print(f"âœ… æ¨¡å‹ {model_name} åˆ é™¤æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤æ¨¡å‹å¤±è´¥: {e}")
            return False

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = MLModelManager(
        "host=localhost dbname=testdb user=postgres password=secret"
    )

    # åˆ›å»ºæ¨¡å‹è¡¨
    manager.create_model_table()

    # å­˜å‚¨æ¨¡å‹ï¼ˆç¤ºä¾‹ï¼šéœ€è¦å®é™…çš„æ¨¡å‹æ•°æ®ï¼‰
    # model_data = pickle.dumps(trained_model)
    # manager.store_model("sentiment_model", model_data, "sklearn", {"accuracy": 0.95})

    # åˆ—å‡ºæ¨¡å‹
    models = manager.list_models()
    print(f"å·²å­˜å‚¨æ¨¡å‹: {len(models)} ä¸ª")

    manager.close()
```

### 10.2 åœ¨çº¿é¢„æµ‹

```python
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import List, Dict, Any, Optional
import json
import pickle

class MLPredictor:
    """PostgreSQL 18 MLé¢„æµ‹å™¨"""

    def __init__(self, conn_str: str):
        """åˆå§‹åŒ–MLé¢„æµ‹å™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)
        self.loaded_models = {}

    def predict(
        self,
        model_name: str,
        features: Dict[str, Any]
    ) -> Optional[Any]:
        """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        # ä»æ•°æ®åº“åŠ è½½æ¨¡å‹ï¼ˆå¦‚æœæœªåŠ è½½ï¼‰
        if model_name not in self.loaded_models:
            sql = "SELECT model_data FROM ml_models WHERE model_name = %s;"
            self.cur.execute(sql, (model_name,))
            result = self.cur.fetchone()

            if not result:
                print(f"âŒ æ¨¡å‹ {model_name} ä¸å­˜åœ¨")
                return None

            model_data = result['model_data']
            self.loaded_models[model_name] = pickle.loads(model_data)

        model = self.loaded_models[model_name]

        # å‡†å¤‡ç‰¹å¾å‘é‡
        feature_vector = [features.get(key, 0) for key in sorted(features.keys())]

        # è¿›è¡Œé¢„æµ‹
        try:
            prediction = model.predict([feature_vector])[0]
            return prediction
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None

    def batch_predict(
        self,
        model_name: str,
        features_list: List[Dict[str, Any]]
    ) -> List[Any]:
        """æ‰¹é‡é¢„æµ‹"""
        predictions = []
        for features in features_list:
            prediction = self.predict(model_name, features)
            if prediction is not None:
                predictions.append(prediction)
        return predictions

    def predict_in_database(
        self,
        model_name: str,
        table_name: str,
        feature_columns: List[str],
        output_column: str = "prediction"
    ) -> bool:
        """åœ¨æ•°æ®åº“å†…è¿›è¡Œé¢„æµ‹"""
        # æ³¨æ„ï¼šè¿™éœ€è¦pg_aiæ‰©å±•æ”¯æŒ
        # è¿™é‡Œæä¾›ç¤ºä¾‹SQLï¼Œå®é™…å®ç°å¯èƒ½éœ€è¦æ ¹æ®pg_aiçš„å…·ä½“APIè°ƒæ•´

        columns_str = ", ".join(feature_columns)

        sql = f"""
        -- ç¤ºä¾‹ï¼šä½¿ç”¨pg_aiè¿›è¡Œé¢„æµ‹
        -- ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS {output_column} FLOAT;
        -- UPDATE {table_name}
        -- SET {output_column} = ai.predict('{model_name}', ARRAY[{columns_str}]::float[]);
        """

        print(f"é¢„æµ‹SQLç¤ºä¾‹:\n{sql}")
        return True

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    predictor = MLPredictor(
        "host=localhost dbname=testdb user=postgres password=secret"
    )

    # å•ä¸ªé¢„æµ‹
    features = {"feature1": 1.0, "feature2": 2.0, "feature3": 3.0}
    prediction = predictor.predict("sentiment_model", features)
    print(f"é¢„æµ‹ç»“æœ: {prediction}")

    # æ‰¹é‡é¢„æµ‹
    features_list = [
        {"feature1": 1.0, "feature2": 2.0},
        {"feature1": 2.0, "feature2": 3.0}
    ]
    predictions = predictor.batch_predict("sentiment_model", features_list)
    print(f"æ‰¹é‡é¢„æµ‹ç»“æœ: {predictions}")

    predictor.close()
```

### 10.3 ç‰¹å¾å·¥ç¨‹

```python
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import List, Dict, Any, Optional
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
import json

class FeatureEngineer:
    """PostgreSQL 18 ç‰¹å¾å·¥ç¨‹å™¨"""

    def __init__(self, conn_str: str):
        """åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹å™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)

    def extract_features(
        self,
        table_name: str,
        feature_columns: List[str],
        output_table: str = "features"
    ) -> bool:
        """æå–ç‰¹å¾"""
        columns_str = ", ".join(feature_columns)

        sql = f"""
        CREATE TABLE IF NOT EXISTS {output_table} AS
        SELECT
            id,
            {columns_str},
            NOW() AS extracted_at
        FROM {table_name};
        """

        try:
            self.cur.execute(sql)
            self.conn.commit()
            print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼Œä¿å­˜åˆ°è¡¨ {output_table}")
            return True
        except Exception as e:
            print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
            return False

    def normalize_features(
        self,
        table_name: str,
        feature_columns: List[str]
    ) -> bool:
        """æ ‡å‡†åŒ–ç‰¹å¾"""
        # è·å–æ•°æ®
        columns_str = ", ".join(feature_columns)
        sql = f"SELECT {columns_str} FROM {table_name};"

        self.cur.execute(sql)
        data = self.cur.fetchall()

        if not data:
            return False

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        feature_matrix = np.array([[row[col] for col in feature_columns] for row in data])

        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        normalized = scaler.fit_transform(feature_matrix)

        # æ›´æ–°æ•°æ®åº“ï¼ˆåˆ›å»ºæ–°åˆ—ï¼‰
        for i, col in enumerate(feature_columns):
            normalized_col = f"{col}_normalized"
            sql_add_col = f"ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS {normalized_col} FLOAT;"
            self.cur.execute(sql_add_col)

            # æ›´æ–°å€¼
            for j, row in enumerate(data):
                sql_update = f"""
                UPDATE {table_name}
                SET {normalized_col} = %s
                WHERE id = %s;
                """
                self.cur.execute(sql_update, (float(normalized[j][i]), row['id']))

        self.conn.commit()
        print(f"âœ… ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ")
        return True

    def encode_categorical(
        self,
        table_name: str,
        categorical_columns: List[str]
    ) -> bool:
        """ç¼–ç åˆ†ç±»ç‰¹å¾"""
        for col in categorical_columns:
            # è·å–å”¯ä¸€å€¼
            sql = f"SELECT DISTINCT {col} FROM {table_name} WHERE {col} IS NOT NULL;"
            self.cur.execute(sql)
            unique_values = [row[col] for row in self.cur.fetchall()]

            # åˆ›å»ºç¼–ç åˆ—
            encoded_col = f"{col}_encoded"
            sql_add_col = f"ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS {encoded_col} INTEGER;"
            self.cur.execute(sql_add_col)

            # ç¼–ç 
            encoder = LabelEncoder()
            encoder.fit(unique_values)

            # æ›´æ–°æ•°æ®åº“
            for value in unique_values:
                encoded_value = int(encoder.transform([value])[0])
                sql_update = f"""
                UPDATE {table_name}
                SET {encoded_col} = %s
                WHERE {col} = %s;
                """
                self.cur.execute(sql_update, (encoded_value, value))

        self.conn.commit()
        print(f"âœ… åˆ†ç±»ç‰¹å¾ç¼–ç å®Œæˆ")
        return True

    def create_feature_table(
        self,
        source_table: str,
        feature_config: Dict[str, str],
        output_table: str = "ml_features"
    ) -> bool:
        """åˆ›å»ºç‰¹å¾è¡¨"""
        feature_definitions = []
        for feature_name, feature_expr in feature_config.items():
            feature_definitions.append(f"{feature_expr} AS {feature_name}")

        features_str = ", ".join(feature_definitions)

        sql = f"""
        CREATE TABLE IF NOT EXISTS {output_table} AS
        SELECT
            id,
            {features_str}
        FROM {source_table};
        """

        try:
            self.cur.execute(sql)
            self.conn.commit()
            print(f"âœ… ç‰¹å¾è¡¨ {output_table} åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ åˆ›å»ºç‰¹å¾è¡¨å¤±è´¥: {e}")
            return False

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    engineer = FeatureEngineer(
        "host=localhost dbname=testdb user=postgres password=secret"
    )

    # æå–ç‰¹å¾
    engineer.extract_features(
        "orders",
        ["amount", "quantity", "discount"],
        "order_features"
    )

    # æ ‡å‡†åŒ–ç‰¹å¾
    engineer.normalize_features("order_features", ["amount", "quantity"])

    # ç¼–ç åˆ†ç±»ç‰¹å¾
    engineer.encode_categorical("orders", ["status", "category"])

    # åˆ›å»ºç‰¹å¾è¡¨
    feature_config = {
        "total_amount": "SUM(amount) OVER (PARTITION BY customer_id)",
        "avg_amount": "AVG(amount) OVER (PARTITION BY customer_id)",
        "order_count": "COUNT(*) OVER (PARTITION BY customer_id)"
    }
    engineer.create_feature_table("orders", feature_config)

    engineer.close()
```

---

## ğŸ“Š æ€»ç»“

PostgreSQL 18 çš„æœºå™¨å­¦ä¹ é›†æˆä¸ºæ•°æ®åº“å†… ML æ“ä½œæä¾›äº†å¼ºå¤§çš„æ”¯æŒï¼š

1. **pg_ai æ‰©å±•**ï¼šåŸç”Ÿ AI/ML åŠŸèƒ½æ”¯æŒ
2. **æ¨¡å‹å­˜å‚¨**ï¼šåœ¨æ•°æ®åº“ä¸­å­˜å‚¨å’Œç®¡ç† ML æ¨¡å‹
3. **åœ¨çº¿é¢„æµ‹**ï¼šå®æ—¶é¢„æµ‹å’Œæ¨ç†
4. **ç‰¹å¾å·¥ç¨‹**ï¼šæ•°æ®åº“å†…ç‰¹å¾æå–å’Œè½¬æ¢
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šå‡å°‘æ•°æ®ç§»åŠ¨ï¼Œæé«˜ ML æ€§èƒ½

**æœ€ä½³å®è·µ**ï¼š

- ä½¿ç”¨æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
- å­˜å‚¨æ¨¡å‹å…ƒæ•°æ®
- ä½¿ç”¨æ¨¡å‹ç¼“å­˜
- ä½¿ç”¨æ‰¹é‡é¢„æµ‹
- ç›‘æ§æ¨¡å‹æ€§èƒ½

---

## 11. å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰

### 11.1 æœºå™¨å­¦ä¹ é›†æˆåŸºç¡€å¸¸è§é—®é¢˜

#### Q1: PostgreSQL 18çš„æœºå™¨å­¦ä¹ é›†æˆæœ‰å“ªäº›ç‰¹æ€§ï¼Ÿ

**é—®é¢˜æè¿°**ï¼šä¸ç¡®å®šPostgreSQL 18çš„æœºå™¨å­¦ä¹ é›†æˆæœ‰å“ªäº›å…·ä½“ç‰¹æ€§ã€‚

**ä¸»è¦ç‰¹æ€§**ï¼š

1. **pg_aiæ‰©å±•**ï¼š
   - åŸç”ŸAI/MLåŠŸèƒ½æ”¯æŒ
   - æ¨¡å‹å­˜å‚¨å’Œç®¡ç†
   - åœ¨çº¿é¢„æµ‹
   - åŠŸèƒ½æ›´å¼ºå¤§

2. **æ¨¡å‹å­˜å‚¨ä¸ç®¡ç†**ï¼š
   - æ¨¡å‹å­˜å‚¨
   - æ¨¡å‹ç®¡ç†
   - æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
   - æ˜“ç”¨æ€§æå‡ï¼š60%

3. **åœ¨çº¿é¢„æµ‹**ï¼š
   - å®æ—¶é¢„æµ‹
   - æ‰¹é‡é¢„æµ‹
   - é¢„æµ‹å‡½æ•°
   - æ€§èƒ½æå‡ï¼š40-50%

**éªŒè¯æ–¹æ³•**ï¼š
```sql
-- æ£€æŸ¥pg_aiæ‰©å±•
SELECT * FROM pg_extension WHERE extname = 'pg_ai';
-- PostgreSQL 18æ”¯æŒæœºå™¨å­¦ä¹ é›†æˆ
```

#### Q2: å¦‚ä½•ä½¿ç”¨pg_aiæ‰©å±•ï¼Ÿ

**é—®é¢˜æè¿°**ï¼šéœ€è¦ä½¿ç”¨pg_aiæ‰©å±•è¿›è¡Œæœºå™¨å­¦ä¹ æ“ä½œã€‚

**ä½¿ç”¨æ–¹æ³•**ï¼š

1. **å®‰è£…pg_aiæ‰©å±•**ï¼š
```sql
-- âœ… å¥½ï¼šå®‰è£…pg_aiæ‰©å±•
CREATE EXTENSION IF NOT EXISTS pg_ai;
-- å¯ç”¨æœºå™¨å­¦ä¹ åŠŸèƒ½
```

2. **åŠ è½½æ¨¡å‹**ï¼š
```sql
-- âœ… å¥½ï¼šåŠ è½½æ¨¡å‹
SELECT ai.load_model('my_model', '/path/to/model.pkl');
-- åŠ è½½MLæ¨¡å‹
```

3. **ä½¿ç”¨æ¨¡å‹é¢„æµ‹**ï¼š
```sql
-- âœ… å¥½ï¼šä½¿ç”¨æ¨¡å‹é¢„æµ‹
SELECT ai.predict('my_model', features::jsonb) AS prediction
FROM data_table;
-- åœ¨æ•°æ®åº“ä¸­è¿›è¡Œé¢„æµ‹
```

**æœ€ä½³å®è·µ**ï¼š
- **ä½¿ç”¨pg_ai**ï¼šä½¿ç”¨pg_aiæ‰©å±•ç®€åŒ–MLæ“ä½œ
- **æ¨¡å‹ç®¡ç†**ï¼šä½¿ç”¨æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
- **æ€§èƒ½ä¼˜åŒ–**ï¼šä¼˜åŒ–é¢„æµ‹æ€§èƒ½

### 11.2 æ¨¡å‹ç®¡ç†å¸¸è§é—®é¢˜

#### Q3: å¦‚ä½•ç®¡ç†MLæ¨¡å‹ï¼Ÿ

**é—®é¢˜æè¿°**ï¼šéœ€è¦ç®¡ç†MLæ¨¡å‹ï¼ŒåŒ…æ‹¬å­˜å‚¨ã€æ›´æ–°ã€ç‰ˆæœ¬æ§åˆ¶ã€‚

**ç®¡ç†æ–¹æ³•**ï¼š

1. **å­˜å‚¨æ¨¡å‹**ï¼š
```sql
-- âœ… å¥½ï¼šå­˜å‚¨æ¨¡å‹
SELECT ai.store_model('my_model', model_data::bytea);
-- åœ¨æ•°æ®åº“ä¸­å­˜å‚¨æ¨¡å‹
```

2. **ç‰ˆæœ¬æ§åˆ¶**ï¼š
```sql
-- âœ… å¥½ï¼šç‰ˆæœ¬æ§åˆ¶
SELECT ai.store_model('my_model_v2', model_data::bytea);
-- å­˜å‚¨æ–°ç‰ˆæœ¬æ¨¡å‹
```

3. **æ›´æ–°æ¨¡å‹**ï¼š
```sql
-- âœ… å¥½ï¼šæ›´æ–°æ¨¡å‹
SELECT ai.update_model('my_model', new_model_data::bytea);
-- æ›´æ–°ç°æœ‰æ¨¡å‹
```

**æœ€ä½³å®è·µ**ï¼š
- **ç‰ˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨ç‰ˆæœ¬å·ç®¡ç†æ¨¡å‹
- **å®šæœŸæ›´æ–°**ï¼šå®šæœŸæ›´æ–°æ¨¡å‹
- **æµ‹è¯•éªŒè¯**ï¼šæ›´æ–°å‰æµ‹è¯•æ¨¡å‹

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£

- [PostgreSQL 18 å®˜æ–¹æ–‡æ¡£ - pg_ai](https://github.com/cloudnative-pg/pg_ai) - pg_ai æ‰©å±•æ–‡æ¡£
- [PostgreSQL 18 å®˜æ–¹æ–‡æ¡£ - æœºå™¨å­¦ä¹ ](https://www.postgresql.org/docs/18/ml.html)
- [PostgreSQL 18 å®˜æ–¹æ–‡æ¡£ - æ‰©å±•](https://www.postgresql.org/docs/18/extend.html)
- [pg_ai GitHub](https://github.com/cloudnative-pg/pg_ai) - pg_ai æ‰©å±•ä»“åº“

### æŠ€æœ¯è®ºæ–‡

- [In-Database Machine Learning](https://www.vldb.org/pvldb/vol15/p2658-neumann.pdf) - æ•°æ®åº“å†…æœºå™¨å­¦ä¹ ç ”ç©¶
- [Machine Learning in Database Systems](https://www.postgresql.org/docs/current/ml.html) - æ•°æ®åº“ç³»ç»Ÿæœºå™¨å­¦ä¹ ç ”ç©¶

### æŠ€æœ¯åšå®¢

- [PostgreSQL 18 Machine Learning Integration](https://www.postgresql.org/about/news/postgresql-18-beta-1-released-2781/) - PostgreSQL 18 æœºå™¨å­¦ä¹ é›†æˆ
- [Understanding pg_ai Extension](https://github.com/cloudnative-pg/pg_ai) - pg_ai æ‰©å±•è¯¦è§£
- [PostgreSQL ML Best Practices](https://www.postgresql.org/docs/current/ml.html) - PostgreSQL ML æœ€ä½³å®è·µ

### ç¤¾åŒºèµ„æº

- [PostgreSQL Wiki - Machine Learning](https://wiki.postgresql.org/wiki/Machine_Learning) - PostgreSQL ML ç›¸å…³ Wiki
- [PostgreSQL Mailing Lists](https://www.postgresql.org/list/) - PostgreSQL é‚®ä»¶åˆ—è¡¨è®¨è®º
- [Stack Overflow - PostgreSQL ML](https://stackoverflow.com/questions/tagged/postgresql+machine-learning) - Stack Overflow ç›¸å…³é—®é¢˜

---

**æœ€åæ›´æ–°**: 2025 å¹´ 1 æœˆ
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 03-03-18-13
