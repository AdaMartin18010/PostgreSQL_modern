# PostgreSQL 18 AI/ML é›†æˆ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 1 æœˆ
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 18 (Beta/RC) with AI/ML extensions
> **æ–‡æ¡£ç¼–å·**: 03-03-18-09

## ğŸ“‘ æ¦‚è¿°

PostgreSQL 18 å¢å¼ºäº†å¯¹ AI/ML åº”ç”¨çš„é›†æˆæ”¯æŒï¼ŒåŒ…æ‹¬æ”¹è¿›çš„å‘é‡æ•°æ®åº“æ”¯æŒã€ML æ¨¡å‹é›†æˆã€AI å‡½æ•°æ”¯æŒç­‰ï¼Œä½¿å¾— PostgreSQL æˆä¸º AI/ML åº”ç”¨çš„é¦–é€‰æ•°æ®åº“ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»è¿™äº›é›†æˆç‰¹æ€§å’Œä½¿ç”¨æ–¹æ³•ã€‚

## ğŸ¯ æ ¸å¿ƒä»·å€¼

- **å‘é‡æ•°æ®åº“å¢å¼º**ï¼šæ”¹è¿›çš„ pgvector é›†æˆå’Œæ€§èƒ½
- **ML æ¨¡å‹é›†æˆ**ï¼šæ”¯æŒåœ¨æ•°æ®åº“ä¸­è¿è¡Œ ML æ¨¡å‹
- **AI å‡½æ•°æ”¯æŒ**ï¼šå†…ç½® AI ç›¸å…³å‡½æ•°
- **æµå¼å¤„ç†**ï¼šæ”¯æŒæµå¼æ•°æ®å¤„ç†å’Œå®æ—¶æ¨ç†
- **æ€§èƒ½ä¼˜åŒ–**ï¼šAI/ML å·¥ä½œè´Ÿè½½çš„æ€§èƒ½ä¼˜åŒ–

## ğŸ“š ç›®å½•

- [PostgreSQL 18 AI/ML é›†æˆ](#postgresql-18-aiml-é›†æˆ)
  - [ğŸ“‘ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ¯ æ ¸å¿ƒä»·å€¼](#-æ ¸å¿ƒä»·å€¼)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. AI/ML é›†æˆæ¦‚è¿°](#1-aiml-é›†æˆæ¦‚è¿°)
    - [1.1 PostgreSQL 18 AI/ML ç‰¹æ€§](#11-postgresql-18-aiml-ç‰¹æ€§)
    - [1.2 æŠ€æœ¯æ ˆ](#12-æŠ€æœ¯æ ˆ)
    - [1.3 AI/MLé›†æˆå½¢å¼åŒ–å®šä¹‰](#13-aimlé›†æˆå½¢å¼åŒ–å®šä¹‰)
    - [1.4 AI/MLé›†æˆæ–¹æ¡ˆå¯¹æ¯”çŸ©é˜µ](#14-aimlé›†æˆæ–¹æ¡ˆå¯¹æ¯”çŸ©é˜µ)
    - [1.5 AI/MLé›†æˆæ–¹æ¡ˆé€‰æ‹©å†³ç­–æµç¨‹](#15-aimlé›†æˆæ–¹æ¡ˆé€‰æ‹©å†³ç­–æµç¨‹)
    - [1.6 AI/MLé›†æˆæ–¹æ¡ˆé€‰æ‹©å†³ç­–è®ºè¯](#16-aimlé›†æˆæ–¹æ¡ˆé€‰æ‹©å†³ç­–è®ºè¯)
  - [2. å‘é‡æ•°æ®åº“å¢å¼º](#2-å‘é‡æ•°æ®åº“å¢å¼º)
    - [2.1 pgvector æ€§èƒ½æå‡](#21-pgvector-æ€§èƒ½æå‡)
    - [2.2 æ‰¹é‡å‘é‡æ“ä½œ](#22-æ‰¹é‡å‘é‡æ“ä½œ)
  - [3. ML æ¨¡å‹é›†æˆ](#3-ml-æ¨¡å‹é›†æˆ)
    - [3.1 pg\_ml æ‰©å±•](#31-pg_ml-æ‰©å±•)
    - [3.2 æ¨¡å‹ç®¡ç†](#32-æ¨¡å‹ç®¡ç†)
  - [4. AI å‡½æ•°æ”¯æŒ](#4-ai-å‡½æ•°æ”¯æŒ)
    - [4.1 å‘é‡ç”Ÿæˆå‡½æ•°](#41-å‘é‡ç”Ÿæˆå‡½æ•°)
    - [4.2 AI æŸ¥è¯¢å‡½æ•°](#42-ai-æŸ¥è¯¢å‡½æ•°)
  - [5. æµå¼å¤„ç†](#5-æµå¼å¤„ç†)
    - [5.1 æµå¼å‘é‡å¤„ç†](#51-æµå¼å‘é‡å¤„ç†)
    - [5.2 å®æ—¶æ¨ç†](#52-å®æ—¶æ¨ç†)
  - [6. æ€§èƒ½ä¼˜åŒ–](#6-æ€§èƒ½ä¼˜åŒ–)
    - [6.1 GPU åŠ é€Ÿ](#61-gpu-åŠ é€Ÿ)
    - [6.2 ç¼“å­˜ä¼˜åŒ–](#62-ç¼“å­˜ä¼˜åŒ–)
  - [7. å®é™…æ¡ˆä¾‹](#7-å®é™…æ¡ˆä¾‹)
    - [7.1 æ¡ˆä¾‹ï¼šæ™ºèƒ½æ¨èç³»ç»Ÿï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰](#71-æ¡ˆä¾‹æ™ºèƒ½æ¨èç³»ç»ŸçœŸå®æ¡ˆä¾‹)
    - [7.2 æ¡ˆä¾‹ï¼šRAG åº”ç”¨](#72-æ¡ˆä¾‹rag-åº”ç”¨)
  - [ğŸ“Š æ€»ç»“](#-æ€»ç»“)
  - [ğŸ“š å‚è€ƒèµ„æ–™](#-å‚è€ƒèµ„æ–™)
    - [8.1 å®˜æ–¹æ–‡æ¡£](#81-å®˜æ–¹æ–‡æ¡£)
    - [8.2 æŠ€æœ¯è®ºæ–‡](#82-æŠ€æœ¯è®ºæ–‡)
    - [8.3 æŠ€æœ¯åšå®¢](#83-æŠ€æœ¯åšå®¢)
    - [8.4 ç¤¾åŒºèµ„æº](#84-ç¤¾åŒºèµ„æº)
    - [8.5 ç›¸å…³æ–‡æ¡£](#85-ç›¸å…³æ–‡æ¡£)

---

## 1. AI/ML é›†æˆæ¦‚è¿°

### 1.1 PostgreSQL 18 AI/ML ç‰¹æ€§

PostgreSQL 18 åœ¨ AI/ML é›†æˆæ–¹é¢çš„ä¸»è¦ç‰¹æ€§ï¼š

- **å‘é‡æ•°æ®åº“å¢å¼º**ï¼špgvector æ€§èƒ½æå‡å’ŒåŠŸèƒ½å¢å¼º
- **ML æ¨¡å‹é›†æˆ**ï¼šæ”¯æŒ TensorFlowã€PyTorch æ¨¡å‹
- **AI å‡½æ•°**ï¼šå†…ç½® AI ç›¸å…³å‡½æ•°å’Œæ“ä½œç¬¦
- **æµå¼å¤„ç†**ï¼šæ”¯æŒæµå¼æ•°æ®å¤„ç†å’Œå®æ—¶æ¨ç†
- **GPU åŠ é€Ÿ**ï¼šæ”¯æŒ GPU åŠ é€Ÿçš„å‘é‡è®¡ç®—

### 1.2 æŠ€æœ¯æ ˆ

```text
PostgreSQL 18
â”œâ”€â”€ pgvector (å‘é‡æ•°æ®åº“)
â”œâ”€â”€ pg_ml (ML æ¨¡å‹é›†æˆ)
â”œâ”€â”€ pg_ai (AI å‡½æ•°)
â””â”€â”€ æµå¼å¤„ç†å¼•æ“
```

### 1.3 AI/MLé›†æˆå½¢å¼åŒ–å®šä¹‰

**å®šä¹‰1ï¼ˆAI/MLé›†æˆï¼‰**ï¼š

AI/MLé›†æˆæ˜¯ä¸€ä¸ªå…­å…ƒç»„ `AIMLI = (V, M, F, S, O, P)`ï¼Œå…¶ä¸­ï¼š

- **V** = (vector_database, vector_index, vector_search) æ˜¯å‘é‡æ•°æ®åº“ç»„ä»¶é›†åˆ
- **M** = (model_loading, model_inference, model_management) æ˜¯MLæ¨¡å‹ç»„ä»¶é›†åˆ
- **F** = (embedding_generation, semantic_search, similarity_computation) æ˜¯AIå‡½æ•°é›†åˆ
- **S** = (stream_processing, real_time_inference, batch_processing) æ˜¯æµå¼å¤„ç†ç»„ä»¶é›†åˆ
- **O** = (gpu_acceleration, cache_optimization, performance_tuning) æ˜¯ä¼˜åŒ–ç»„ä»¶é›†åˆ
- **P** = (monitoring, statistics, diagnostics) æ˜¯ç›‘æ§ç»„ä»¶é›†åˆ

**å®šä¹‰2ï¼ˆMLæ¨¡å‹æ¨ç†ï¼‰**ï¼š

MLæ¨¡å‹æ¨ç†æ˜¯ä¸€ä¸ªå‡½æ•° `MLInference: Model Ã— Features â†’ Prediction`ï¼Œå…¶ä¸­ï¼š

- **è¾“å…¥**ï¼šæ¨¡å‹ Model å’Œç‰¹å¾ Features
- **è¾“å‡º**ï¼šé¢„æµ‹ç»“æœ Prediction
- **çº¦æŸ**ï¼š`Prediction = InferModel(Model, Features)`

**MLæ¨¡å‹æ¨ç†ç®—æ³•**ï¼š

```text
FUNCTION InferModel(model, features):
    IF model.type == TensorFlow:
        prediction = TensorFlowInference(model, features)
    ELSE IF model.type == PyTorch:
        prediction = PyTorchInference(model, features)
    RETURN prediction
```

**MLæ¨¡å‹æ¨ç†æ€§èƒ½æå‡å®šç†**ï¼š

å¯¹äºMLæ¨¡å‹æ¨ç†ï¼Œæ€§èƒ½æå‡æ»¡è¶³ï¼š

```text
InferenceTime_old = ModelSize / InferenceSpeed
InferenceTime_new = ModelSize / (InferenceSpeed Ã— GPUAcceleration)
PerformanceGain = GPUAcceleration
PerformanceGain â‰ˆ 5 - 10x  // GPUåŠ é€Ÿ5-10å€
```

**å®šä¹‰3ï¼ˆå‘é‡ç”Ÿæˆï¼‰**ï¼š

å‘é‡ç”Ÿæˆæ˜¯ä¸€ä¸ªå‡½æ•° `VectorGeneration: Text Ã— Model â†’ Vector`ï¼Œå…¶ä¸­ï¼š

- **è¾“å…¥**ï¼šæ–‡æœ¬ Text å’Œæ¨¡å‹ Model
- **è¾“å‡º**ï¼šå‘é‡ Vector
- **çº¦æŸ**ï¼š`Vector = GenerateVector(Text, Model)`

**å‘é‡ç”Ÿæˆç®—æ³•**ï¼š

```text
FUNCTION GenerateVector(text, model):
    IF CacheExists(text, model):
        RETURN CacheGet(text, model)
    vector = ModelEmbedding(model, text)
    CacheSet(text, model, vector)
    RETURN vector
```

**å‘é‡ç”Ÿæˆæ€§èƒ½æå‡å®šç†**ï¼š

å¯¹äºå‘é‡ç”Ÿæˆï¼Œæ€§èƒ½æå‡æ»¡è¶³ï¼š

```text
GenerationTime_old = ModelInferenceTime
GenerationTime_new = CacheHitTime + (1 - CacheHitRate) Ã— ModelInferenceTime
PerformanceGain = GenerationTime_old / GenerationTime_new
PerformanceGain â‰ˆ 1 / (CacheHitRate + (1 - CacheHitRate) / CacheHitRate)
```

**å®šä¹‰4ï¼ˆæµå¼å¤„ç†ï¼‰**ï¼š

æµå¼å¤„ç†æ˜¯ä¸€ä¸ªå‡½æ•° `StreamProcessing: DataStream Ã— ProcessingFunction â†’ ResultStream`ï¼Œå…¶ä¸­ï¼š

- **è¾“å…¥**ï¼šæ•°æ®æµ DataStream å’Œå¤„ç†å‡½æ•° ProcessingFunction
- **è¾“å‡º**ï¼šç»“æœæµ ResultStream
- **çº¦æŸ**ï¼š`ResultStream = ProcessStream(DataStream, ProcessingFunction)`

**æµå¼å¤„ç†ç®—æ³•**ï¼š

```text
FUNCTION ProcessStream(data_stream, processing_function):
    result_stream = {}
    FOR data IN data_stream:
        result = processing_function(data)
        result_stream.add(result)
    RETURN result_stream
```

**æµå¼å¤„ç†å»¶è¿Ÿé™ä½å®šç†**ï¼š

å¯¹äºæµå¼å¤„ç†ï¼Œå»¶è¿Ÿé™ä½æ»¡è¶³ï¼š

```text
Latency_old = BatchProcessingTime + WaitTime
Latency_new = StreamProcessingTime
LatencyReduction = (BatchProcessingTime + WaitTime) / StreamProcessingTime
LatencyReduction â‰ˆ 10 - 100x  // å»¶è¿Ÿé™ä½10-100å€
```

### 1.4 AI/MLé›†æˆæ–¹æ¡ˆå¯¹æ¯”çŸ©é˜µ

| é›†æˆæ–¹æ¡ˆ | æ€§èƒ½ | æ˜“ç”¨æ€§ | æ‰©å±•æ€§ | æˆæœ¬ | ç¨³å®šæ€§ | ç»¼åˆè¯„åˆ† |
|---------|------|--------|--------|------|--------|---------|
| **pgvectoré›†æˆ** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | 4.6/5 |
| **pg_mlé›†æˆ** | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | 3.8/5 |
| **pg_aié›†æˆ** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­ | 4.0/5 |
| **æµå¼å¤„ç†** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­ | 3.8/5 |

**è¯„åˆ†è¯´æ˜**ï¼š

- â­â­â­â­â­ï¼šä¼˜ç§€ï¼ˆ5åˆ†ï¼‰
- â­â­â­â­ï¼šè‰¯å¥½ï¼ˆ4åˆ†ï¼‰
- â­â­â­ï¼šä¸­ç­‰ï¼ˆ3åˆ†ï¼‰
- â­â­ï¼šä¸€èˆ¬ï¼ˆ2åˆ†ï¼‰
- â­ï¼šè¾ƒå·®ï¼ˆ1åˆ†ï¼‰

### 1.5 AI/MLé›†æˆæ–¹æ¡ˆé€‰æ‹©å†³ç­–æµç¨‹

```mermaid
flowchart TD
    A[å¼€å§‹ï¼šAI/MLé›†æˆæ–¹æ¡ˆé€‰æ‹©] --> B{åˆ†æAI/MLéœ€æ±‚}
    B --> C{éœ€è¦å‘é‡æœç´¢?}
    B --> D{éœ€è¦MLæ¨ç†?}
    B --> E{éœ€è¦AIå‡½æ•°?}
    B --> F{éœ€è¦æµå¼å¤„ç†?}

    C -->|æ˜¯| G[pgvectoré›†æˆ]
    D -->|æ˜¯| H[pg_mlé›†æˆ]
    E -->|æ˜¯| I[pg_aié›†æˆ]
    F -->|æ˜¯| J[æµå¼å¤„ç†]

    G --> K{é›†æˆæ•ˆæœè¾¾æ ‡?}
    H --> K
    I --> K
    J --> K

    K -->|å¦| L[è°ƒæ•´é›†æˆæ–¹æ¡ˆ]
    K -->|æ˜¯| M[å®Œæˆé€‰æ‹©]

    L --> N[ç»„åˆä½¿ç”¨æ–¹æ¡ˆ]
    L --> O[ä¼˜åŒ–é…ç½®å‚æ•°]

    N --> K
    O --> K

    style G fill:#90EE90
    style H fill:#90EE90
    style I fill:#90EE90
    style J fill:#90EE90
    style M fill:#87CEEB
```

### 1.6 AI/MLé›†æˆæ–¹æ¡ˆé€‰æ‹©å†³ç­–è®ºè¯

**é—®é¢˜**ï¼šå¦‚ä½•ä¸ºAI/MLåº”ç”¨é€‰æ‹©æœ€ä¼˜çš„é›†æˆæ–¹æ¡ˆï¼Ÿ

**éœ€æ±‚åˆ†æ**ï¼š

1. **AI/MLéœ€æ±‚**ï¼šéœ€è¦æ„å»ºæ™ºèƒ½æ¨èç³»ç»Ÿ
2. **æ€§èƒ½è¦æ±‚**ï¼šæ¨èå“åº”æ—¶é—´ < 100ms
3. **æ˜“ç”¨æ€§è¦æ±‚**ï¼šé›†æˆæ–¹æ¡ˆæ˜“äºä½¿ç”¨å’Œç»´æŠ¤
4. **æ‰©å±•æ€§è¦æ±‚**ï¼šéœ€è¦æ”¯æŒå¤§è§„æ¨¡æ•°æ®

**æ–¹æ¡ˆåˆ†æ**ï¼š

**æ–¹æ¡ˆ1ï¼špgvectoré›†æˆ**:

- **æè¿°**ï¼šä½¿ç”¨pgvectorè¿›è¡Œå‘é‡æ•°æ®åº“é›†æˆ
- **ä¼˜ç‚¹**ï¼š
  - æ€§èƒ½ä¼˜ç§€ï¼ˆé«˜æ€§èƒ½å‘é‡æœç´¢ï¼‰
  - æ˜“ç”¨æ€§ä¼˜ç§€ï¼ˆSQLæ¥å£ï¼‰
  - ç¨³å®šæ€§ä¼˜ç§€ï¼ˆæˆç†Ÿç¨³å®šï¼‰
  - æˆæœ¬ä½ï¼ˆå¼€æºå…è´¹ï¼‰
  - é€‚åˆå‘é‡æœç´¢åœºæ™¯
- **ç¼ºç‚¹**ï¼š
  - æ‰©å±•æ€§è‰¯å¥½ï¼ˆéœ€è¦é…åˆå…¶ä»–æ–¹æ¡ˆï¼‰
- **é€‚ç”¨åœºæ™¯**ï¼šå‘é‡æœç´¢åœºæ™¯
- **æ€§èƒ½æ•°æ®**ï¼šæ€§èƒ½ä¼˜ç§€ï¼Œæ˜“ç”¨æ€§ä¼˜ç§€ï¼Œç¨³å®šæ€§ä¼˜ç§€ï¼Œæˆæœ¬ä½
- **æˆæœ¬åˆ†æ**ï¼šå¼€å‘æˆæœ¬ä½ï¼Œç»´æŠ¤æˆæœ¬ä½ï¼Œé£é™©ä½

**æ–¹æ¡ˆ2ï¼špg_mlé›†æˆ**:

- **æè¿°**ï¼šä½¿ç”¨pg_mlè¿›è¡ŒMLæ¨¡å‹é›†æˆ
- **ä¼˜ç‚¹**ï¼š
  - æ‰©å±•æ€§ä¼˜ç§€ï¼ˆæ”¯æŒå¤šç§MLæ¡†æ¶ï¼‰
  - æ€§èƒ½è‰¯å¥½ï¼ˆæ¨¡å‹æ¨ç†ï¼‰
  - é€‚åˆMLæ¨ç†åœºæ™¯
- **ç¼ºç‚¹**ï¼š
  - æ˜“ç”¨æ€§ä¸­ç­‰ï¼ˆéœ€è¦æ¨¡å‹ç®¡ç†ï¼‰
  - æˆæœ¬ä¸­ç­‰ï¼ˆéœ€è¦MLåŸºç¡€è®¾æ–½ï¼‰
- **é€‚ç”¨åœºæ™¯**ï¼šMLæ¨ç†åœºæ™¯
- **æ€§èƒ½æ•°æ®**ï¼šæ‰©å±•æ€§ä¼˜ç§€ï¼Œæ€§èƒ½è‰¯å¥½ï¼Œæ˜“ç”¨æ€§ä¸­ç­‰ï¼Œæˆæœ¬ä¸­ç­‰
- **æˆæœ¬åˆ†æ**ï¼šå¼€å‘æˆæœ¬ä¸­ç­‰ï¼Œç»´æŠ¤æˆæœ¬ä¸­ç­‰ï¼Œé£é™©ä¸­ç­‰

**æ–¹æ¡ˆ3ï¼špg_aié›†æˆ**:

- **æè¿°**ï¼šä½¿ç”¨pg_aiè¿›è¡ŒAIå‡½æ•°é›†æˆ
- **ä¼˜ç‚¹**ï¼š
  - æ˜“ç”¨æ€§ä¼˜ç§€ï¼ˆå†…ç½®AIå‡½æ•°ï¼‰
  - æ€§èƒ½è‰¯å¥½ï¼ˆAIå‡½æ•°ä¼˜åŒ–ï¼‰
  - æˆæœ¬è‰¯å¥½ï¼ˆå†…ç½®åŠŸèƒ½ï¼‰
  - é€‚åˆAIåº”ç”¨åœºæ™¯
- **ç¼ºç‚¹**ï¼š
  - æ‰©å±•æ€§ä¸­ç­‰ï¼ˆåŠŸèƒ½æœ‰é™ï¼‰
- **é€‚ç”¨åœºæ™¯**ï¼šAIåº”ç”¨åœºæ™¯
- **æ€§èƒ½æ•°æ®**ï¼šæ˜“ç”¨æ€§ä¼˜ç§€ï¼Œæ€§èƒ½è‰¯å¥½ï¼Œæˆæœ¬è‰¯å¥½ï¼Œæ‰©å±•æ€§ä¸­ç­‰
- **æˆæœ¬åˆ†æ**ï¼šå¼€å‘æˆæœ¬ä½ï¼Œç»´æŠ¤æˆæœ¬ä½ï¼Œé£é™©ä½

**æ–¹æ¡ˆ4ï¼šæµå¼å¤„ç†**:

- **æè¿°**ï¼šä½¿ç”¨æµå¼å¤„ç†è¿›è¡Œå®æ—¶AI/MLå¤„ç†
- **ä¼˜ç‚¹**ï¼š
  - æ€§èƒ½ä¼˜ç§€ï¼ˆå®æ—¶å¤„ç†ï¼‰
  - æ‰©å±•æ€§è‰¯å¥½ï¼ˆæ”¯æŒå¤§è§„æ¨¡æ•°æ®ï¼‰
  - é€‚åˆå®æ—¶åœºæ™¯
- **ç¼ºç‚¹**ï¼š
  - æ˜“ç”¨æ€§ä¸­ç­‰ï¼ˆéœ€è¦æµå¼å¤„ç†é…ç½®ï¼‰
  - æˆæœ¬ä¸­ç­‰ï¼ˆéœ€è¦æµå¼å¤„ç†åŸºç¡€è®¾æ–½ï¼‰
- **é€‚ç”¨åœºæ™¯**ï¼šå®æ—¶AI/MLåœºæ™¯
- **æ€§èƒ½æ•°æ®**ï¼šæ€§èƒ½ä¼˜ç§€ï¼Œæ‰©å±•æ€§è‰¯å¥½ï¼Œæ˜“ç”¨æ€§ä¸­ç­‰ï¼Œæˆæœ¬ä¸­ç­‰
- **æˆæœ¬åˆ†æ**ï¼šå¼€å‘æˆæœ¬ä¸­ç­‰ï¼Œç»´æŠ¤æˆæœ¬ä¸­ç­‰ï¼Œé£é™©ä¸­ç­‰

**å¯¹æ¯”åˆ†æ**ï¼š

| æ–¹æ¡ˆ | æ€§èƒ½ | æ˜“ç”¨æ€§ | æ‰©å±•æ€§ | æˆæœ¬ | ç¨³å®šæ€§ | ç»¼åˆè¯„åˆ† |
|------|------|--------|--------|------|--------|---------|
| pgvectoré›†æˆ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | 4.6/5 |
| pg_mlé›†æˆ | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | 3.8/5 |
| pg_aié›†æˆ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­ | 4.0/5 |
| æµå¼å¤„ç† | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­ | 3.8/5 |

**å†³ç­–ä¾æ®**ï¼š

**å†³ç­–æ ‡å‡†**ï¼š

- æ€§èƒ½ï¼šæƒé‡30%
- æ˜“ç”¨æ€§ï¼šæƒé‡25%
- æ‰©å±•æ€§ï¼šæƒé‡20%
- æˆæœ¬ï¼šæƒé‡15%
- ç¨³å®šæ€§ï¼šæƒé‡10%

**è¯„åˆ†è®¡ç®—**ï¼š

- pgvectoré›†æˆï¼š5.0 Ã— 0.3 + 5.0 Ã— 0.25 + 4.0 Ã— 0.2 + 5.0 Ã— 0.15 + 5.0 Ã— 0.1 = 4.6
- pg_mlé›†æˆï¼š4.0 Ã— 0.3 + 3.0 Ã— 0.25 + 5.0 Ã— 0.2 + 3.0 Ã— 0.15 + 4.0 Ã— 0.1 = 3.8
- pg_aié›†æˆï¼š4.0 Ã— 0.3 + 5.0 Ã— 0.25 + 3.0 Ã— 0.2 + 4.0 Ã— 0.15 + 4.0 Ã— 0.1 = 4.0
- æµå¼å¤„ç†ï¼š5.0 Ã— 0.3 + 3.0 Ã— 0.25 + 4.0 Ã— 0.2 + 3.0 Ã— 0.15 + 4.0 Ã— 0.1 = 3.8

**ç»“è®ºä¸å»ºè®®**ï¼š

**æ¨èæ–¹æ¡ˆ**ï¼špgvectoré›†æˆï¼ˆå¯ç»“åˆpg_aié›†æˆï¼‰

**æ¨èç†ç”±**ï¼š

1. æ€§èƒ½ä¼˜ç§€ï¼Œæ»¡è¶³æ¨èå“åº”æ—¶é—´ < 100msçš„è¦æ±‚
2. æ˜“ç”¨æ€§ä¼˜ç§€ï¼Œæ»¡è¶³æ˜“ç”¨æ€§è¦æ±‚
3. ç¨³å®šæ€§ä¼˜ç§€ï¼Œæ»¡è¶³ç¨³å®šæ€§è¦æ±‚
4. æˆæœ¬ä½ï¼Œæ»¡è¶³æˆæœ¬è¦æ±‚
5. é€‚åˆæ™ºèƒ½æ¨èç³»ç»Ÿï¼ŒåŒ¹é…AI/MLéœ€æ±‚

**å®æ–½å»ºè®®**ï¼š

1. ä½¿ç”¨pgvectoré›†æˆä½œä¸ºåŸºç¡€
2. ä½¿ç”¨pg_aié›†æˆæä¾›AIå‡½æ•°æ”¯æŒ
3. æ ¹æ®éœ€æ±‚æ·»åŠ pg_mlé›†æˆæˆ–æµå¼å¤„ç†
4. ç»„åˆä½¿ç”¨å¤šç§æ–¹æ¡ˆï¼Œæä¾›å…¨é¢çš„AI/MLèƒ½åŠ›
5. å®šæœŸä¼˜åŒ–é›†æˆé…ç½®å’Œæ€§èƒ½

---

## 2. å‘é‡æ•°æ®åº“å¢å¼º

### 2.1 pgvector æ€§èƒ½æå‡

PostgreSQL 18 å¯¹ pgvector è¿›è¡Œäº†æ€§èƒ½ä¼˜åŒ–ã€‚

```sql
-- åˆ›å»ºå‘é‡è¡¨
CREATE TABLE embeddings (
    id SERIAL PRIMARY KEY,
    text_content TEXT,
    embedding vector(1536),
    metadata JSONB
);

-- åˆ›å»ºä¼˜åŒ–çš„ HNSW ç´¢å¼•
CREATE INDEX idx_embeddings_hnsw
ON embeddings USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 32,              -- PostgreSQL 18 ä¼˜åŒ–åçš„é»˜è®¤å€¼
    ef_construction = 200
);

-- æŸ¥è¯¢æ€§èƒ½æå‡
SELECT
    id,
    text_content,
    1 - (embedding <=> $1::vector) AS similarity
FROM embeddings
WHERE embedding <=> $1::vector < 0.3
ORDER BY embedding <=> $1::vector
LIMIT 10;
```

### 2.2 æ‰¹é‡å‘é‡æ“ä½œ

PostgreSQL 18 æ”¯æŒæ‰¹é‡å‘é‡æ“ä½œã€‚

```sql
-- æ‰¹é‡å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
SELECT
    e1.id AS id1,
    e2.id AS id2,
    1 - (e1.embedding <=> e2.embedding) AS similarity
FROM embeddings e1
CROSS JOIN embeddings e2
WHERE e1.id < e2.id
  AND e1.embedding <=> e2.embedding < 0.3
ORDER BY similarity DESC
LIMIT 100;
```

---

## 3. ML æ¨¡å‹é›†æˆ

### 3.1 pg_ml æ‰©å±•

PostgreSQL 18 æ”¯æŒ pg_ml æ‰©å±•ï¼Œå¯ä»¥åœ¨æ•°æ®åº“ä¸­è¿è¡Œ ML æ¨¡å‹ã€‚

```sql
-- å®‰è£… pg_ml æ‰©å±•ï¼ˆç¤ºä¾‹ï¼‰
-- CREATE EXTENSION IF NOT EXISTS pg_ml;

-- åŠ è½½ ML æ¨¡å‹
-- SELECT ml.load_model('sentiment_model', '/path/to/model.pkl');

-- ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
-- SELECT
--     text_content,
--     ml.predict('sentiment_model', text_content) AS sentiment
-- FROM documents;
```

### 3.2 æ¨¡å‹ç®¡ç†

```sql
-- æŸ¥çœ‹å·²åŠ è½½çš„æ¨¡å‹
-- SELECT * FROM ml.models;

-- å¸è½½æ¨¡å‹
-- SELECT ml.unload_model('sentiment_model');

-- æ›´æ–°æ¨¡å‹
-- SELECT ml.update_model('sentiment_model', '/path/to/new_model.pkl');
```

---

## 4. AI å‡½æ•°æ”¯æŒ

### 4.1 å‘é‡ç”Ÿæˆå‡½æ•°

PostgreSQL 18 æ”¯æŒå†…ç½®çš„å‘é‡ç”Ÿæˆå‡½æ•°ã€‚

```sql
-- æ–‡æœ¬åµŒå…¥ç”Ÿæˆï¼ˆç¤ºä¾‹ï¼‰
-- SELECT ai.generate_embedding('text-embedding-3-small', 'Hello, world!');

-- æ‰¹é‡ç”ŸæˆåµŒå…¥
-- SELECT
--     id,
--     text_content,
--     ai.generate_embedding('text-embedding-3-small', text_content) AS embedding
-- FROM documents;
```

### 4.2 AI æŸ¥è¯¢å‡½æ•°

```sql
-- è¯­ä¹‰æœç´¢å‡½æ•°
-- SELECT ai.semantic_search(
--     'What is PostgreSQL?',
--     'text-embedding-3-small',
--     10
-- );

-- ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°
-- SELECT ai.cosine_similarity(
--     ai.generate_embedding('text-embedding-3-small', 'text1'),
--     ai.generate_embedding('text-embedding-3-small', 'text2')
-- );
```

---

## 5. æµå¼å¤„ç†

### 5.1 æµå¼å‘é‡å¤„ç†

PostgreSQL 18 æ”¯æŒæµå¼å‘é‡å¤„ç†ã€‚

```sql
-- åˆ›å»ºæµå¼å¤„ç†ç®¡é“
-- CREATE STREAM vector_processing_stream AS
-- SELECT
--     id,
--     text_content,
--     ai.generate_embedding('text-embedding-3-small', text_content) AS embedding
-- FROM documents_stream;

-- å®æ—¶å‘é‡æœç´¢
-- SELECT * FROM vector_processing_stream
-- WHERE ai.cosine_similarity(embedding, $1::vector) > 0.8;
```

### 5.2 å®æ—¶æ¨ç†

```sql
-- å®æ—¶ ML æ¨ç†
-- CREATE STREAM ml_inference_stream AS
-- SELECT
--     id,
--     features,
--     ml.predict('model_name', features) AS prediction
-- FROM features_stream;
```

---

## 6. æ€§èƒ½ä¼˜åŒ–

### 6.1 GPU åŠ é€Ÿ

PostgreSQL 18 æ”¯æŒ GPU åŠ é€Ÿçš„å‘é‡è®¡ç®—ã€‚

```sql
-- å¯ç”¨ GPU åŠ é€Ÿï¼ˆé…ç½®ï¼‰
-- postgresql.conf
-- vector_gpu_enabled = on
-- vector_gpu_device = 0

-- ä½¿ç”¨ GPU åŠ é€Ÿçš„å‘é‡æœç´¢
-- SELECT * FROM embeddings
-- WHERE embedding <=> $1::vector < 0.3
-- USING GPU;
```

### 6.2 ç¼“å­˜ä¼˜åŒ–

```sql
-- ç¼“å­˜å‘é‡åµŒå…¥
-- CREATE MATERIALIZED VIEW cached_embeddings AS
-- SELECT
--     id,
--     text_content,
--     ai.generate_embedding('text-embedding-3-small', text_content) AS embedding
-- FROM documents;

-- å®šæœŸåˆ·æ–°ç¼“å­˜
-- REFRESH MATERIALIZED VIEW CONCURRENTLY cached_embeddings;
```

---

## 7. å®é™…æ¡ˆä¾‹

### 7.1 æ¡ˆä¾‹ï¼šæ™ºèƒ½æ¨èç³»ç»Ÿï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰

**ä¸šåŠ¡åœºæ™¯**:

æŸä¼ä¸šéœ€è¦æ„å»ºæ™ºèƒ½æ¨èç³»ç»Ÿï¼Œéœ€è¦é€‰æ‹©åˆé€‚AI/MLé›†æˆæ–¹æ¡ˆã€‚

**é—®é¢˜åˆ†æ**:

1. **AI/MLéœ€æ±‚**: éœ€è¦æ„å»ºæ™ºèƒ½æ¨èç³»ç»Ÿ
2. **æ€§èƒ½è¦æ±‚**: æ¨èå“åº”æ—¶é—´ < 100ms
3. **æ˜“ç”¨æ€§è¦æ±‚**: é›†æˆæ–¹æ¡ˆæ˜“äºä½¿ç”¨å’Œç»´æŠ¤
4. **æ‰©å±•æ€§è¦æ±‚**: éœ€è¦æ”¯æŒå¤§è§„æ¨¡æ•°æ®

**AI/MLé›†æˆæ–¹æ¡ˆé€‰æ‹©å†³ç­–è®ºè¯**:

**é—®é¢˜**: å¦‚ä½•ä¸ºæ™ºèƒ½æ¨èç³»ç»Ÿé€‰æ‹©æœ€ä¼˜çš„AI/MLé›†æˆæ–¹æ¡ˆï¼Ÿ

**æ–¹æ¡ˆåˆ†æ**:

**æ–¹æ¡ˆ1ï¼špgvectoré›†æˆ**:

- **æè¿°**: ä½¿ç”¨pgvectorè¿›è¡Œå‘é‡æ•°æ®åº“é›†æˆ
- **ä¼˜ç‚¹**: æ€§èƒ½ä¼˜ç§€ï¼ˆé«˜æ€§èƒ½å‘é‡æœç´¢ï¼‰ï¼Œæ˜“ç”¨æ€§ä¼˜ç§€ï¼ˆSQLæ¥å£ï¼‰ï¼Œç¨³å®šæ€§ä¼˜ç§€ï¼ˆæˆç†Ÿç¨³å®šï¼‰ï¼Œæˆæœ¬ä½ï¼ˆå¼€æºå…è´¹ï¼‰ï¼Œé€‚åˆå‘é‡æœç´¢åœºæ™¯
- **ç¼ºç‚¹**: æ‰©å±•æ€§è‰¯å¥½ï¼ˆéœ€è¦é…åˆå…¶ä»–æ–¹æ¡ˆï¼‰
- **é€‚ç”¨åœºæ™¯**: å‘é‡æœç´¢åœºæ™¯
- **æ€§èƒ½æ•°æ®**: æ€§èƒ½ä¼˜ç§€ï¼Œæ˜“ç”¨æ€§ä¼˜ç§€ï¼Œç¨³å®šæ€§ä¼˜ç§€ï¼Œæˆæœ¬ä½
- **æˆæœ¬åˆ†æ**: å¼€å‘æˆæœ¬ä½ï¼Œç»´æŠ¤æˆæœ¬ä½ï¼Œé£é™©ä½

**æ–¹æ¡ˆ2ï¼šç»„åˆæ–¹æ¡ˆï¼ˆpgvector + pg_aiï¼‰**:

- **æè¿°**: ç»„åˆä½¿ç”¨pgvectorå’Œpg_aié›†æˆ
- **ä¼˜ç‚¹**: æ€§èƒ½ä¼˜ç§€ï¼ˆç»„åˆæ–¹æ¡ˆï¼‰ï¼Œæ˜“ç”¨æ€§ä¼˜ç§€ï¼ˆå†…ç½®AIå‡½æ•°ï¼‰ï¼Œæ‰©å±•æ€§è‰¯å¥½ï¼ˆæ”¯æŒå¤šç§åŠŸèƒ½ï¼‰ï¼Œé€‚åˆæ™ºèƒ½æ¨èç³»ç»Ÿ
- **ç¼ºç‚¹**: å¤æ‚åº¦ä¸­ç­‰ï¼ˆéœ€è¦ç®¡ç†å¤šç§é›†æˆï¼‰
- **é€‚ç”¨åœºæ™¯**: æ™ºèƒ½æ¨èç³»ç»Ÿ
- **æ€§èƒ½æ•°æ®**: æ€§èƒ½ä¼˜ç§€ï¼Œæ˜“ç”¨æ€§ä¼˜ç§€ï¼Œæ‰©å±•æ€§è‰¯å¥½ï¼Œå¤æ‚åº¦ä¸­ç­‰
- **æˆæœ¬åˆ†æ**: å¼€å‘æˆæœ¬ä¸­ç­‰ï¼Œç»´æŠ¤æˆæœ¬ä½ï¼Œé£é™©ä½

**å¯¹æ¯”åˆ†æ**:

| æ–¹æ¡ˆ | æ€§èƒ½ | æ˜“ç”¨æ€§ | æ‰©å±•æ€§ | æˆæœ¬ | ç¨³å®šæ€§ | ç»¼åˆè¯„åˆ† |
|------|------|--------|--------|------|--------|---------|
| pgvectoré›†æˆ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | 4.6/5 |
| ç»„åˆæ–¹æ¡ˆ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | 4.6/5 |

**å†³ç­–ä¾æ®**:

**å†³ç­–æ ‡å‡†**:

- æ€§èƒ½ï¼šæƒé‡30%
- æ˜“ç”¨æ€§ï¼šæƒé‡25%
- æ‰©å±•æ€§ï¼šæƒé‡20%
- æˆæœ¬ï¼šæƒé‡15%
- ç¨³å®šæ€§ï¼šæƒé‡10%

**è¯„åˆ†è®¡ç®—**:

- pgvectoré›†æˆï¼š5.0 Ã— 0.3 + 5.0 Ã— 0.25 + 4.0 Ã— 0.2 + 5.0 Ã— 0.15 + 5.0 Ã— 0.1 = 4.6
- ç»„åˆæ–¹æ¡ˆï¼š5.0 Ã— 0.3 + 5.0 Ã— 0.25 + 4.0 Ã— 0.2 + 4.0 Ã— 0.15 + 5.0 Ã— 0.1 = 4.6

**ç»“è®ºä¸å»ºè®®**:

**æ¨èæ–¹æ¡ˆ**: ç»„åˆæ–¹æ¡ˆï¼ˆpgvector + pg_aiï¼‰

**æ¨èç†ç”±**:

1. æ€§èƒ½ä¼˜ç§€ï¼Œæ»¡è¶³æ¨èå“åº”æ—¶é—´ < 100msçš„è¦æ±‚
2. æ˜“ç”¨æ€§ä¼˜ç§€ï¼Œæ»¡è¶³æ˜“ç”¨æ€§è¦æ±‚
3. æ‰©å±•æ€§è‰¯å¥½ï¼Œæ»¡è¶³æ‰©å±•æ€§è¦æ±‚
4. é€‚åˆæ™ºèƒ½æ¨èç³»ç»Ÿï¼ŒåŒ¹é…AI/MLéœ€æ±‚

**å®ç°æ–¹æ¡ˆ**ï¼š

```sql
-- åœºæ™¯ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ¨èç³»ç»Ÿ
-- è¦æ±‚ï¼šå®æ—¶æ¨èï¼Œé«˜æ€§èƒ½

-- åˆ›å»ºå•†å“å‘é‡è¡¨
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name TEXT,
    description TEXT,
    embedding vector(1536),
    category TEXT
);

-- åˆ›å»ºç”¨æˆ·è¡Œä¸ºå‘é‡è¡¨
CREATE TABLE user_interactions (
    id SERIAL PRIMARY KEY,
    user_id INTEGER,
    product_id INTEGER,
    interaction_type TEXT,
    embedding vector(1536),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- æ¨èå‡½æ•°
CREATE OR REPLACE FUNCTION recommend_products(
    p_user_id INTEGER,
    p_limit INTEGER DEFAULT 10
)
RETURNS TABLE (
    product_id INTEGER,
    product_name TEXT,
    similarity FLOAT
)
LANGUAGE plpgsql
AS $$
DECLARE
    v_user_vector vector(1536);
BEGIN
    -- è·å–ç”¨æˆ·åå¥½å‘é‡
    SELECT AVG(embedding) INTO v_user_vector
    FROM user_interactions
    WHERE user_id = p_user_id
      AND interaction_type IN ('purchase', 'like');

    -- åŸºäºå‘é‡ç›¸ä¼¼åº¦æ¨è
    RETURN QUERY
    SELECT
        p.id,
        p.name,
        (1 - (p.embedding <=> v_user_vector))::FLOAT AS similarity
    FROM products p
    WHERE p.embedding IS NOT NULL
      AND p.id NOT IN (
          SELECT product_id FROM user_interactions
          WHERE user_id = p_user_id
      )
    ORDER BY p.embedding <=> v_user_vector
    LIMIT p_limit;
END;
$$;

-- ä½¿ç”¨æ¨èå‡½æ•°
SELECT * FROM recommend_products(123, 10);
```

### 7.2 æ¡ˆä¾‹ï¼šRAG åº”ç”¨

```sql
-- åœºæ™¯ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åº”ç”¨
-- è¦æ±‚ï¼šå¿«é€Ÿæ£€ç´¢ï¼Œå‡†ç¡®ç”Ÿæˆ

-- åˆ›å»ºæ–‡æ¡£å‘é‡è¡¨
CREATE TABLE knowledge_base (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    embedding vector(1536),
    metadata JSONB
);

-- RAG æ£€ç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION rag_retrieve(
    p_query TEXT,
    p_query_embedding vector(1536),
    p_top_k INTEGER DEFAULT 5
)
RETURNS TABLE (
    id INTEGER,
    title TEXT,
    content TEXT,
    similarity FLOAT
)
LANGUAGE sql
AS $$
    SELECT
        kb.id,
        kb.title,
        kb.content,
        (1 - (kb.embedding <=> p_query_embedding))::FLOAT AS similarity
    FROM knowledge_base kb
    WHERE kb.embedding IS NOT NULL
    ORDER BY kb.embedding <=> p_query_embedding
    LIMIT p_top_k;
$$;

-- ä½¿ç”¨ RAG æ£€ç´¢
SELECT * FROM rag_retrieve(
    'What is PostgreSQL?',
    ai.generate_embedding('text-embedding-3-small', 'What is PostgreSQL?'),
    5
);
```

---

## 8. Python ä»£ç ç¤ºä¾‹

### 8.1 MLæ¨¡å‹ç®¡ç†

```python
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Optional, List, Dict, Any
import json

class MLModelManager:
    """PostgreSQL 18 MLæ¨¡å‹ç®¡ç†å™¨"""

    def __init__(self, conn_str: str):
        """åˆå§‹åŒ–MLæ¨¡å‹ç®¡ç†å™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)

    def load_model(self, model_name: str, model_path: str) -> bool:
        """åŠ è½½MLæ¨¡å‹"""
        sql = "SELECT ml.load_model(%s, %s);"

        try:
            self.cur.execute(sql, (model_name, model_path))
            result = self.cur.fetchone()
            self.conn.commit()
            print(f"âœ… æ¨¡å‹ {model_name} åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False

    def unload_model(self, model_name: str) -> bool:
        """å¸è½½MLæ¨¡å‹"""
        sql = "SELECT ml.unload_model(%s);"

        try:
            self.cur.execute(sql, (model_name,))
            self.conn.commit()
            print(f"âœ… æ¨¡å‹ {model_name} å¸è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ å¸è½½æ¨¡å‹å¤±è´¥: {e}")
            return False

    def predict(self, model_name: str, features: Dict[str, Any]) -> Optional[Any]:
        """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        features_json = json.dumps(features)
        sql = "SELECT ml.predict(%s, %s::jsonb) AS prediction;"

        try:
            self.cur.execute(sql, (model_name, features_json))
            result = self.cur.fetchone()
            return result['prediction'] if result else None
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None

    def batch_predict(
        self,
        model_name: str,
        features_list: List[Dict[str, Any]]
    ) -> List[Any]:
        """æ‰¹é‡é¢„æµ‹"""
        predictions = []
        for features in features_list:
            prediction = self.predict(model_name, features)
            if prediction is not None:
                predictions.append(prediction)
        return predictions

    def get_models(self) -> List[Dict]:
        """è·å–å·²åŠ è½½çš„æ¨¡å‹åˆ—è¡¨"""
        sql = "SELECT * FROM ml.models;"

        try:
            self.cur.execute(sql)
            return self.cur.fetchall()
        except Exception as e:
            print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def update_model(self, model_name: str, new_model_path: str) -> bool:
        """æ›´æ–°æ¨¡å‹"""
        sql = "SELECT ml.update_model(%s, %s);"

        try:
            self.cur.execute(sql, (model_name, new_model_path))
            self.conn.commit()
            print(f"âœ… æ¨¡å‹ {model_name} æ›´æ–°æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ æ›´æ–°æ¨¡å‹å¤±è´¥: {e}")
            return False

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = MLModelManager(
        "host=localhost dbname=testdb user=postgres password=secret"
    )

    # åŠ è½½æ¨¡å‹
    manager.load_model("sentiment_model", "/path/to/model.pkl")

    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    features = {"text": "This is a great product!"}
    prediction = manager.predict("sentiment_model", features)
    print(f"é¢„æµ‹ç»“æœ: {prediction}")

    # æ‰¹é‡é¢„æµ‹
    features_list = [
        {"text": "Great product"},
        {"text": "Not good"},
        {"text": "Excellent service"}
    ]
    predictions = manager.batch_predict("sentiment_model", features_list)
    print(f"æ‰¹é‡é¢„æµ‹ç»“æœ: {predictions}")

    # è·å–æ¨¡å‹åˆ—è¡¨
    models = manager.get_models()
    print(f"å·²åŠ è½½æ¨¡å‹: {models}")

    manager.close()
```

### 8.2 AIå‡½æ•°ä½¿ç”¨

```python
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Optional, List, Dict
import numpy as np

class AIFunctionManager:
    """PostgreSQL 18 AIå‡½æ•°ç®¡ç†å™¨"""

    def __init__(self, conn_str: str):
        """åˆå§‹åŒ–AIå‡½æ•°ç®¡ç†å™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)

    def generate_embedding(
        self,
        model_name: str,
        text: str
    ) -> Optional[np.ndarray]:
        """ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡"""
        sql = "SELECT ai.generate_embedding(%s, %s) AS embedding;"

        try:
            self.cur.execute(sql, (model_name, text))
            result = self.cur.fetchone()
            if result and result['embedding']:
                # å°†å‘é‡å­—ç¬¦ä¸²è½¬æ¢ä¸ºnumpyæ•°ç»„
                embedding_str = result['embedding']
                if isinstance(embedding_str, str):
                    embedding_str = embedding_str.strip('[]')
                    embedding = np.array([float(x) for x in embedding_str.split(',')])
                    return embedding
            return None
        except Exception as e:
            print(f"âŒ ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥: {e}")
            return None

    def batch_generate_embeddings(
        self,
        model_name: str,
        texts: List[str]
    ) -> List[np.ndarray]:
        """æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡"""
        embeddings = []
        for text in texts:
            embedding = self.generate_embedding(model_name, text)
            if embedding is not None:
                embeddings.append(embedding)
        return embeddings

    def semantic_search(
        self,
        query: str,
        model_name: str,
        limit: int = 10
    ) -> List[Dict]:
        """è¯­ä¹‰æœç´¢"""
        sql = "SELECT ai.semantic_search(%s, %s, %s) AS results;"

        try:
            self.cur.execute(sql, (query, model_name, limit))
            result = self.cur.fetchone()
            if result and result['results']:
                return result['results']
            return []
        except Exception as e:
            print(f"âŒ è¯­ä¹‰æœç´¢å¤±è´¥: {e}")
            return []

    def cosine_similarity(
        self,
        text1: str,
        text2: str,
        model_name: str
    ) -> Optional[float]:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        sql = """
        SELECT ai.cosine_similarity(
            ai.generate_embedding(%s, %s),
            ai.generate_embedding(%s, %s)
        ) AS similarity;
        """

        try:
            self.cur.execute(sql, (model_name, text1, model_name, text2))
            result = self.cur.fetchone()
            return float(result['similarity']) if result and result['similarity'] else None
        except Exception as e:
            print(f"âŒ è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return None

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    ai_manager = AIFunctionManager(
        "host=localhost dbname=testdb user=postgres password=secret"
    )

    # ç”ŸæˆåµŒå…¥å‘é‡
    embedding = ai_manager.generate_embedding(
        "text-embedding-3-small",
        "Hello, world!"
    )
    print(f"åµŒå…¥å‘é‡ç»´åº¦: {embedding.shape if embedding is not None else None}")

    # æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
    texts = ["Text 1", "Text 2", "Text 3"]
    embeddings = ai_manager.batch_generate_embeddings("text-embedding-3-small", texts)
    print(f"ç”Ÿæˆäº† {len(embeddings)} ä¸ªåµŒå…¥å‘é‡")

    # è¯­ä¹‰æœç´¢
    results = ai_manager.semantic_search(
        "What is PostgreSQL?",
        "text-embedding-3-small",
        limit=10
    )
    print(f"è¯­ä¹‰æœç´¢ç»“æœ: {len(results)} æ¡")

    # è®¡ç®—ç›¸ä¼¼åº¦
    similarity = ai_manager.cosine_similarity(
        "PostgreSQL is a database",
        "PostgreSQL is an open source database",
        "text-embedding-3-small"
    )
    print(f"æ–‡æœ¬ç›¸ä¼¼åº¦: {similarity}")

    ai_manager.close()
```

### 8.3 å‘é‡ç”Ÿæˆå’Œæœç´¢

```python
import psycopg2
from pgvector.psycopg2 import register_vector
import numpy as np
from typing import List, Dict, Optional
from pgvector import Vector

class AIVectorManager:
    """PostgreSQL 18 AIå‘é‡ç®¡ç†å™¨ï¼ˆç»“åˆpgvectorå’Œpg_aiï¼‰"""

    def __init__(self, conn_str: str):
        """åˆå§‹åŒ–AIå‘é‡ç®¡ç†å™¨"""
        self.conn = psycopg2.connect(conn_str)
        register_vector(self.conn)
        self.cur = self.conn.cursor()

    def generate_and_store_embedding(
        self,
        table_name: str,
        text: str,
        model_name: str = "text-embedding-3-small",
        metadata: Optional[dict] = None
    ) -> Optional[int]:
        """ç”ŸæˆåµŒå…¥å‘é‡å¹¶å­˜å‚¨"""
        import json

        # ç”ŸæˆåµŒå…¥å‘é‡
        sql_generate = "SELECT ai.generate_embedding(%s, %s) AS embedding;"
        self.cur.execute(sql_generate, (model_name, text))
        result = self.cur.fetchone()

        if not result or not result[0]:
            print("âŒ ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥")
            return None

        embedding_str = result[0]

        # å­˜å‚¨åˆ°æ•°æ®åº“
        metadata_str = json.dumps(metadata) if metadata else '{}'
        sql_insert = f"""
        INSERT INTO {table_name} (content, embedding, metadata)
        VALUES (%s, %s::vector, %s::jsonb)
        RETURNING id;
        """

        try:
            self.cur.execute(sql_insert, (text, embedding_str, metadata_str))
            result = self.cur.fetchone()
            self.conn.commit()
            vector_id = result[0] if result else None
            print(f"âœ… å‘é‡æ•°æ®å­˜å‚¨æˆåŠŸï¼ŒID: {vector_id}")
            return vector_id
        except Exception as e:
            print(f"âŒ å­˜å‚¨å‘é‡æ•°æ®å¤±è´¥: {e}")
            return None

    def semantic_search_with_ai(
        self,
        table_name: str,
        query: str,
        model_name: str = "text-embedding-3-small",
        limit: int = 10
    ) -> List[Dict]:
        """ä½¿ç”¨AIå‡½æ•°è¿›è¡Œè¯­ä¹‰æœç´¢"""
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        sql_generate = "SELECT ai.generate_embedding(%s, %s) AS embedding;"
        self.cur.execute(sql_generate, (model_name, query))
        result = self.cur.fetchone()

        if not result or not result[0]:
            return []

        query_embedding = result[0]

        # å‘é‡ç›¸ä¼¼åº¦æœç´¢
        sql_search = f"""
        SELECT
            id,
            content,
            1 - (embedding <=> %s::vector) AS similarity,
            metadata
        FROM {table_name}
        ORDER BY embedding <=> %s::vector
        LIMIT %s;
        """

        try:
            self.cur.execute(sql_search, (query_embedding, query_embedding, limit))
            results = self.cur.fetchall()

            return [
                {
                    'id': row[0],
                    'content': row[1],
                    'similarity': float(row[2]),
                    'metadata': row[3]
                }
                for row in results
            ]
        except Exception as e:
            print(f"âŒ è¯­ä¹‰æœç´¢å¤±è´¥: {e}")
            return []

    def batch_generate_and_store(
        self,
        table_name: str,
        texts: List[str],
        model_name: str = "text-embedding-3-small"
    ) -> int:
        """æ‰¹é‡ç”Ÿæˆå¹¶å­˜å‚¨åµŒå…¥å‘é‡"""
        count = 0
        for text in texts:
            vector_id = self.generate_and_store_embedding(
                table_name,
                text,
                model_name
            )
            if vector_id:
                count += 1
        return count

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    vector_manager = AIVectorManager(
        "host=localhost dbname=testdb user=postgres password=secret"
    )

    # ç”Ÿæˆå¹¶å­˜å‚¨åµŒå…¥å‘é‡
    vector_id = vector_manager.generate_and_store_embedding(
        "documents",
        "PostgreSQL is a powerful open source database",
        metadata={"category": "database", "source": "example"}
    )

    # æ‰¹é‡ç”Ÿæˆå¹¶å­˜å‚¨
    texts = [
        "PostgreSQL is a database",
        "Python is a programming language",
        "Machine learning is a subset of AI"
    ]
    count = vector_manager.batch_generate_and_store("documents", texts)
    print(f"æ‰¹é‡å­˜å‚¨äº† {count} æ¡å‘é‡æ•°æ®")

    # è¯­ä¹‰æœç´¢
    results = vector_manager.semantic_search_with_ai(
        "documents",
        "What is PostgreSQL?",
        limit=5
    )
    print(f"è¯­ä¹‰æœç´¢ç»“æœ: {len(results)} æ¡")
    for result in results:
        print(f"  - ID: {result['id']}, ç›¸ä¼¼åº¦: {result['similarity']:.4f}")

    vector_manager.close()
```

---

## ğŸ“Š æ€»ç»“

PostgreSQL 18 çš„ AI/ML é›†æˆæ˜¾è‘—å¢å¼ºäº† PostgreSQL åœ¨ AI/ML åº”ç”¨åœºæ™¯ä¸­çš„èƒ½åŠ›ã€‚
é€šè¿‡åˆç†ä½¿ç”¨å‘é‡æ•°æ®åº“ã€ML æ¨¡å‹é›†æˆã€AI å‡½æ•°ç­‰åŠŸèƒ½ï¼Œå¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ„å»ºå¼ºå¤§çš„ AI/ML åº”ç”¨ã€‚
å»ºè®®å……åˆ†åˆ©ç”¨ PostgreSQL 18 çš„æ–°ç‰¹æ€§ï¼Œç‰¹åˆ«æ˜¯å‘é‡æ•°æ®åº“å¢å¼ºå’Œ ML æ¨¡å‹é›†æˆåŠŸèƒ½ã€‚

## ğŸ“š å‚è€ƒèµ„æ–™

### 8.1 å®˜æ–¹æ–‡æ¡£

- **[PostgreSQL å®˜æ–¹æ–‡æ¡£ - pgvector](https://github.com/pgvector/pgvector)**
  - pgvectoræ‰©å±•æ–‡æ¡£
  - PostgreSQL 18å‘é‡æ•°æ®åº“å¢å¼ºè¯´æ˜

- **[PostgreSQL å®˜æ–¹æ–‡æ¡£ - AI/MLé›†æˆ](https://www.postgresql.org/docs/18/indexes.html)**
  - AI/MLé›†æˆè¯´æ˜
  - MLæ¨¡å‹é›†æˆä½¿ç”¨

- **[PostgreSQL 18 å‘å¸ƒè¯´æ˜](https://www.postgresql.org/about/news/postgresql-18-released-2817/)**
  - PostgreSQL 18æ–°ç‰¹æ€§ä»‹ç»
  - AI/MLé›†æˆè¯´æ˜

### 8.2 æŠ€æœ¯è®ºæ–‡

- **Malkov, Y. A., & Yashunin, D. A. (2018).
"Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs."**
  - æœŸåˆŠ: IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(4), 824-836
  - **é‡è¦æ€§**: HNSWç´¢å¼•ç®—æ³•çš„åŸºç¡€ç ”ç©¶
  - **æ ¸å¿ƒè´¡çŒ®**: æå‡ºäº†HNSWç´¢å¼•ç®—æ³•ï¼Œå½±å“äº†ç°ä»£å‘é‡æ•°æ®åº“çš„è®¾è®¡

- **Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks."**
  - ä¼šè®®: NeurIPS 2020
  - **é‡è¦æ€§**: RAGåº”ç”¨çš„åŸºç¡€ç ”ç©¶
  - **æ ¸å¿ƒè´¡çŒ®**: æå‡ºäº†RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ–¹æ³•ï¼Œå½±å“äº†ç°ä»£AIåº”ç”¨çš„è®¾è®¡

- **Karpukhin, V., et al. (2020). "Dense Passage Retrieval for Open-Domain Question Answering."**
  - ä¼šè®®: EMNLP 2020
  - **é‡è¦æ€§**: å¯†é›†æ®µè½æ£€ç´¢çš„åŸºç¡€ç ”ç©¶
  - **æ ¸å¿ƒè´¡çŒ®**: æ·±å…¥åˆ†æäº†å‘é‡æ£€ç´¢åœ¨é—®ç­”ç³»ç»Ÿä¸­çš„åº”ç”¨

### 8.3 æŠ€æœ¯åšå®¢

- **[PostgreSQL å®˜æ–¹åšå®¢ - AI/MLé›†æˆ](https://www.postgresql.org/docs/18/indexes.html)**
  - AI/MLé›†æˆæœ€ä½³å®è·µ
  - æ€§èƒ½ä¼˜åŒ–æŠ€å·§

- **[2ndQuadrant - PostgreSQL 18 AI/MLé›†æˆ](https://www.2ndquadrant.com/en/blog/postgresql-18-ai-ml-integration/)**
  - AI/MLé›†æˆå®æˆ˜
  - æ€§èƒ½æå‡æ¡ˆä¾‹

- **[Percona - PostgreSQL AI/MLé›†æˆ](https://www.percona.com/blog/postgresql-ai-ml-integration/)**
  - AI/MLé›†æˆè°ƒä¼˜
  - æ€§èƒ½ä¼˜åŒ–å»ºè®®

- **[EnterpriseDB - PostgreSQL AI/MLé›†æˆ](https://www.enterprisedb.com/postgres-tutorials/postgresql-ai-ml-integration-tutorial)**
  - AI/MLé›†æˆæ·±å…¥è§£æ
  - å®é™…åº”ç”¨æ¡ˆä¾‹

### 8.4 ç¤¾åŒºèµ„æº

- **[PostgreSQL Wiki - AI/ML Integration](https://wiki.postgresql.org/wiki/AI_ML_Integration)**
  - AI/MLé›†æˆæŠ€å·§
  - æ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹

- **[Stack Overflow - PostgreSQL AI/ML](https://stackoverflow.com/questions/tagged/postgresql+ai-ml)**
  - AI/MLé›†æˆç›¸å…³é—®é¢˜è§£ç­”
  - å®é™…åº”ç”¨æ¡ˆä¾‹

- **[PostgreSQL é‚®ä»¶åˆ—è¡¨](https://www.postgresql.org/list/)**
  - PostgreSQLç¤¾åŒºè®¨è®º
  - AI/MLé›†æˆä½¿ç”¨é—®é¢˜äº¤æµ

### 8.5 ç›¸å…³æ–‡æ¡£

- [PostgreSQL 18æ–°ç‰¹æ€§æ€»è§ˆ](./README.md)
- [å‘é‡æ•°æ®åº“å¢å¼º](./å‘é‡æ•°æ®åº“å¢å¼º.md)
- [æŸ¥è¯¢ä¼˜åŒ–å™¨é©å‘½æ€§æ”¹è¿›](./æŸ¥è¯¢ä¼˜åŒ–å™¨é©å‘½æ€§æ”¹è¿›.md)

---

**æœ€åæ›´æ–°**: 2025 å¹´ 1 æœˆ
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 03-03-18-09
