# æµå¼æ•°æ®å¤„ç†ï¼šPostgreSQL å®æ—¶æ•°æ®æµæ–¹æ¡ˆ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 1 æœˆ
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 17+/18+ with extensions
> **æ–‡æ¡£ç¼–å·**: 03-03-TREND-19

## ğŸ“‘ æ¦‚è¿°

æµå¼æ•°æ®å¤„ç†æ˜¯ç°ä»£æ•°æ®æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ï¼ŒPostgreSQL é€šè¿‡é€»è¾‘å¤åˆ¶ã€CDCã€æµå¼å¤„ç†æ¡†æ¶ç­‰æŠ€æœ¯æ”¯æŒå®æ—¶æ•°æ®æµå¤„ç†ï¼Œæ»¡è¶³å®æ—¶åˆ†æã€äº‹ä»¶é©±åŠ¨æ¶æ„ç­‰åœºæ™¯éœ€æ±‚ã€‚

## ğŸ¯ æ ¸å¿ƒä»·å€¼

- **å®æ—¶æ•°æ®æµ**ï¼šæ”¯æŒå®æ—¶æ•°æ®æµå¤„ç†å’Œä¼ è¾“
- **ä½å»¶è¿Ÿå¤„ç†**ï¼šæ¯«ç§’çº§æ•°æ®å¤„ç†å»¶è¿Ÿ
- **é«˜ååé‡**ï¼šæ”¯æŒå¤§è§„æ¨¡æ•°æ®æµå¤„ç†
- **äº‹ä»¶é©±åŠ¨**ï¼šåŸºäºäº‹ä»¶çš„æ•°æ®å¤„ç†æ¶æ„
- **å®¹é”™æ€§**ï¼šè‡ªåŠ¨æ•…éšœæ¢å¤å’Œæ•°æ®ä¸€è‡´æ€§ä¿è¯

## ğŸ“š ç›®å½•

- [æµå¼æ•°æ®å¤„ç†ï¼šPostgreSQL å®æ—¶æ•°æ®æµæ–¹æ¡ˆ](#æµå¼æ•°æ®å¤„ç†postgresql-å®æ—¶æ•°æ®æµæ–¹æ¡ˆ)
  - [ğŸ“‘ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ¯ æ ¸å¿ƒä»·å€¼](#-æ ¸å¿ƒä»·å€¼)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. æµå¼æ•°æ®å¤„ç†æ¦‚è¿°](#1-æµå¼æ•°æ®å¤„ç†æ¦‚è¿°)
    - [1.1 æµå¼æ•°æ®å¤„ç†æ¶æ„](#11-æµå¼æ•°æ®å¤„ç†æ¶æ„)
    - [1.2 æŠ€æœ¯æ ˆ](#12-æŠ€æœ¯æ ˆ)
  - [2. é€»è¾‘å¤åˆ¶æµå¼å¤„ç†](#2-é€»è¾‘å¤åˆ¶æµå¼å¤„ç†)
    - [2.1 é…ç½®é€»è¾‘å¤åˆ¶](#21-é…ç½®é€»è¾‘å¤åˆ¶)
    - [2.2 æµå¼è®¢é˜…](#22-æµå¼è®¢é˜…)
  - [3. CDC æµå¼å¤„ç†](#3-cdc-æµå¼å¤„ç†)
    - [3.1 Debezium é…ç½®](#31-debezium-é…ç½®)
    - [3.2 Kafka Connect é›†æˆ](#32-kafka-connect-é›†æˆ)
  - [4. æµå¼å¤„ç†æ¡†æ¶](#4-æµå¼å¤„ç†æ¡†æ¶)
    - [4.1 Apache Flink é›†æˆ](#41-apache-flink-é›†æˆ)
    - [4.2 æµå¼å¤„ç†ä½œä¸š](#42-æµå¼å¤„ç†ä½œä¸š)
  - [5. å®æ—¶åˆ†æ](#5-å®æ—¶åˆ†æ)
    - [5.1 å®æ—¶èšåˆ](#51-å®æ—¶èšåˆ)
    - [5.2 æµå¼çª—å£æŸ¥è¯¢](#52-æµå¼çª—å£æŸ¥è¯¢)
  - [6. æ€§èƒ½ä¼˜åŒ–](#6-æ€§èƒ½ä¼˜åŒ–)
    - [6.1 å¤åˆ¶æ€§èƒ½ä¼˜åŒ–](#61-å¤åˆ¶æ€§èƒ½ä¼˜åŒ–)
    - [6.2 æµå¼å¤„ç†ä¼˜åŒ–](#62-æµå¼å¤„ç†ä¼˜åŒ–)
  - [7. å®é™…æ¡ˆä¾‹](#7-å®é™…æ¡ˆä¾‹)
    - [7.1 æ¡ˆä¾‹ï¼šå®æ—¶æ¨èç³»ç»Ÿ](#71-æ¡ˆä¾‹å®æ—¶æ¨èç³»ç»Ÿ)
  - [ğŸ“Š æ€»ç»“](#-æ€»ç»“)

---

## 1. æµå¼æ•°æ®å¤„ç†æ¦‚è¿°

### 1.1 æµå¼æ•°æ®å¤„ç†æ¶æ„

```text
æ•°æ®æº
â”œâ”€â”€ PostgreSQL ä¸»åº“
â”‚   â”œâ”€â”€ é€»è¾‘å¤åˆ¶
â”‚   â”œâ”€â”€ WAL æµ
â”‚   â””â”€â”€ CDC
â”œâ”€â”€ æµå¼å¤„ç†å±‚
â”‚   â”œâ”€â”€ Kafka
â”‚   â”œâ”€â”€ Pulsar
â”‚   â””â”€â”€ Flink
â””â”€â”€ ç›®æ ‡ç³»ç»Ÿ
    â”œâ”€â”€ æ•°æ®ä»“åº“
    â”œâ”€â”€ å®æ—¶åˆ†æ
    â””â”€â”€ äº‹ä»¶å¤„ç†
```

### 1.2 æŠ€æœ¯æ ˆ

- **PostgreSQL é€»è¾‘å¤åˆ¶**ï¼šåŸç”Ÿæµå¼å¤åˆ¶
- **Debezium**ï¼šCDC æµå¼å¤„ç†
- **Apache Kafka**ï¼šæ¶ˆæ¯é˜Ÿåˆ—å’Œæµå¤„ç†
- **Apache Flink**ï¼šæµå¼è®¡ç®—å¼•æ“
- **TimescaleDB**ï¼šæ—¶åºæ•°æ®æµå¤„ç†

---

## 2. é€»è¾‘å¤åˆ¶æµå¼å¤„ç†

### 2.1 é…ç½®é€»è¾‘å¤åˆ¶

```sql
-- é…ç½®å‘å¸ƒ
CREATE PUBLICATION stream_pub FOR ALL TABLES;

-- åˆ›å»ºå¤åˆ¶æ§½
SELECT pg_create_logical_replication_slot(
    'stream_slot',
    'pgoutput'
);

-- æŸ¥çœ‹å¤åˆ¶æ§½
SELECT * FROM pg_replication_slots;
```

### 2.2 æµå¼è®¢é˜…

```sql
-- åœ¨è®¢é˜…ç«¯åˆ›å»ºè®¢é˜…
CREATE SUBSCRIPTION stream_sub
CONNECTION 'host=source_host dbname=mydb'
PUBLICATION stream_pub
WITH (
    copy_data = false,
    create_slot = false,
    slot_name = 'stream_slot'
);
```

---

## 3. CDC æµå¼å¤„ç†

### 3.1 Debezium é…ç½®

```json
{
  "name": "postgres-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "postgres",
    "database.password": "password",
    "database.dbname": "mydb",
    "database.server.name": "postgres",
    "table.whitelist": "public.users,public.orders",
    "plugin.name": "pgoutput",
    "slot.name": "debezium_slot"
  }
}
```

### 3.2 Kafka Connect é›†æˆ

```bash
# å¯åŠ¨ Kafka Connect
bin/connect-standalone.sh \
    config/connect-standalone.properties \
    config/postgres-connector.properties
```

---

## 4. æµå¼å¤„ç†æ¡†æ¶

### 4.1 Apache Flink é›†æˆ

```java
// Flink è¯»å– PostgreSQL CDC
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

FlinkCDC.Builder<PostgreSQLSource> builder = FlinkCDC.source()
    .hostname("localhost")
    .port(5432)
    .database("mydb")
    .username("postgres")
    .password("password")
    .tableList("public.users")
    .deserializer(new JsonDebeziumDeserializationSchema());

DataStream<String> stream = env.addSource(builder.build());
```

### 4.2 æµå¼å¤„ç†ä½œä¸š

```java
// å®æ—¶èšåˆ
stream
    .keyBy(event -> event.getUserId())
    .window(TumblingEventTimeWindows.of(Time.minutes(5)))
    .aggregate(new CountAggregateFunction())
    .print();
```

---

## 5. å®æ—¶åˆ†æ

### 5.1 å®æ—¶èšåˆ

```sql
-- ä½¿ç”¨ç‰©åŒ–è§†å›¾å®æ—¶æ›´æ–°
CREATE MATERIALIZED VIEW realtime_stats AS
SELECT
    user_id,
    COUNT(*) as event_count,
    SUM(amount) as total_amount,
    MAX(created_at) as last_event
FROM events
GROUP BY user_id;

-- è‡ªåŠ¨åˆ·æ–°
CREATE UNIQUE INDEX ON realtime_stats (user_id);

-- å¢é‡æ›´æ–°
REFRESH MATERIALIZED VIEW CONCURRENTLY realtime_stats;
```

### 5.2 æµå¼çª—å£æŸ¥è¯¢

```sql
-- ä½¿ç”¨ TimescaleDB è¿ç»­èšåˆ
CREATE MATERIALIZED VIEW hourly_stats
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', created_at) AS hour,
    user_id,
    COUNT(*) as event_count,
    AVG(amount) as avg_amount
FROM events
GROUP BY hour, user_id;
```

---

## 6. æ€§èƒ½ä¼˜åŒ–

### 6.1 å¤åˆ¶æ€§èƒ½ä¼˜åŒ–

```sql
-- é…ç½®å¤åˆ¶å‚æ•°
ALTER SYSTEM SET max_replication_slots = 10;
ALTER SYSTEM SET max_wal_senders = 10;
ALTER SYSTEM SET wal_level = 'logical';
ALTER SYSTEM SET max_slot_wal_keep_size = '10GB';
```

### 6.2 æµå¼å¤„ç†ä¼˜åŒ–

```sql
-- æ‰¹é‡å¤„ç†
ALTER SYSTEM SET logical_decoding_work_mem = '64MB';

-- å¹¶è¡Œå¤„ç†
ALTER SYSTEM SET max_parallel_workers = 8;
ALTER SYSTEM SET max_parallel_workers_per_gather = 4;
```

---

## 7. å®é™…æ¡ˆä¾‹

### 7.1 æ¡ˆä¾‹ï¼šå®æ—¶æ¨èç³»ç»Ÿ

**åœºæ™¯**ï¼šåŸºäºç”¨æˆ·è¡Œä¸ºçš„å®æ—¶æ¨è

**æ¶æ„**ï¼š

```text
PostgreSQL (ç”¨æˆ·è¡Œä¸º)
    â†“ (é€»è¾‘å¤åˆ¶)
Kafka (äº‹ä»¶æµ)
    â†“ (Flink å¤„ç†)
å®æ—¶ç‰¹å¾è®¡ç®—
    â†“
æ¨èå¼•æ“
    â†“
PostgreSQL (æ¨èç»“æœ)
```

**å®ç°**ï¼š

```sql
-- 1. ç”¨æˆ·è¡Œä¸ºè¡¨
CREATE TABLE user_events (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT,
    event_type VARCHAR(50),
    item_id BIGINT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- 2. å‘å¸ƒå˜æ›´
CREATE PUBLICATION events_pub FOR TABLE user_events;

-- 3. å®æ—¶ç‰¹å¾è¡¨
CREATE TABLE user_features (
    user_id BIGINT PRIMARY KEY,
    event_count INT,
    last_event_time TIMESTAMP,
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**Flink å¤„ç†**ï¼š

```java
// å®æ—¶è®¡ç®—ç”¨æˆ·ç‰¹å¾
stream
    .keyBy(event -> event.getUserId())
    .window(SlidingEventTimeWindows.of(Time.hours(1), Time.minutes(5)))
    .aggregate(new UserFeatureAggregate())
    .addSink(new PostgreSQLSink());
```

**æ•ˆæœ**ï¼š

- æ¨èå»¶è¿Ÿï¼šä» 5 åˆ†é’Ÿé™è‡³ 10 ç§’
- æ¨èå‡†ç¡®ç‡æå‡ 25%
- ç³»ç»Ÿååé‡ï¼š10,000 äº‹ä»¶/ç§’

---

## ğŸ“Š æ€»ç»“

PostgreSQL æµå¼æ•°æ®å¤„ç†æä¾›äº†å¼ºå¤§çš„å®æ—¶æ•°æ®æµå¤„ç†èƒ½åŠ›ï¼š

1. **é€»è¾‘å¤åˆ¶æµå¼å¤„ç†**ï¼šåŸç”Ÿæµå¼å¤åˆ¶æ”¯æŒ
2. **CDC æµå¼å¤„ç†**ï¼šåŸºäºå˜æ›´æ•°æ®æ•è·çš„æµå¤„ç†
3. **æµå¼å¤„ç†æ¡†æ¶**ï¼šä¸ Kafkaã€Flink ç­‰æ¡†æ¶é›†æˆ
4. **å®æ—¶åˆ†æ**ï¼šæ”¯æŒå®æ—¶èšåˆå’Œåˆ†æ
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šé«˜æ€§èƒ½æµå¼å¤„ç†é…ç½®

**æœ€ä½³å®è·µ**ï¼š

- ä½¿ç”¨é€»è¾‘å¤åˆ¶è¿›è¡Œæµå¼ä¼ è¾“
- é›†æˆ Kafka ä½œä¸ºæ¶ˆæ¯ä¸­é—´ä»¶
- ä½¿ç”¨ Flink è¿›è¡Œæµå¼è®¡ç®—
- é…ç½®åˆé€‚çš„æ‰¹å¤„ç†å¤§å°
- ç›‘æ§æµå¤„ç†å»¶è¿Ÿ
- å®æ–½æ•…éšœæ¢å¤æœºåˆ¶

---

**æœ€åæ›´æ–°**: 2025 å¹´ 1 æœˆ
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
