# æµå¼æ•°æ®å¤„ç†ï¼šPostgreSQL å®æ—¶æ•°æ®æµæ–¹æ¡ˆ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 1 æœˆ
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 17+/18+ with extensions
> **æ–‡æ¡£ç¼–å·**: 03-03-TREND-19

## ğŸ“‘ æ¦‚è¿°

æµå¼æ•°æ®å¤„ç†æ˜¯ç°ä»£æ•°æ®æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ï¼ŒPostgreSQL é€šè¿‡é€»è¾‘å¤åˆ¶ã€CDCã€æµå¼å¤„ç†æ¡†æ¶ç­‰æŠ€æœ¯æ”¯æŒå®æ—¶æ•°æ®æµå¤„ç†ï¼Œæ»¡è¶³å®æ—¶åˆ†æã€äº‹ä»¶é©±åŠ¨æ¶æ„ç­‰åœºæ™¯éœ€æ±‚ã€‚

## ğŸ¯ æ ¸å¿ƒä»·å€¼

- **å®æ—¶æ•°æ®æµ**ï¼šæ”¯æŒå®æ—¶æ•°æ®æµå¤„ç†å’Œä¼ è¾“
- **ä½å»¶è¿Ÿå¤„ç†**ï¼šæ¯«ç§’çº§æ•°æ®å¤„ç†å»¶è¿Ÿ
- **é«˜ååé‡**ï¼šæ”¯æŒå¤§è§„æ¨¡æ•°æ®æµå¤„ç†
- **äº‹ä»¶é©±åŠ¨**ï¼šåŸºäºäº‹ä»¶çš„æ•°æ®å¤„ç†æ¶æ„
- **å®¹é”™æ€§**ï¼šè‡ªåŠ¨æ•…éšœæ¢å¤å’Œæ•°æ®ä¸€è‡´æ€§ä¿è¯

## ğŸ“š ç›®å½•

- [æµå¼æ•°æ®å¤„ç†ï¼šPostgreSQL å®æ—¶æ•°æ®æµæ–¹æ¡ˆ](#æµå¼æ•°æ®å¤„ç†postgresql-å®æ—¶æ•°æ®æµæ–¹æ¡ˆ)
  - [ğŸ“‘ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ¯ æ ¸å¿ƒä»·å€¼](#-æ ¸å¿ƒä»·å€¼)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. æµå¼æ•°æ®å¤„ç†æ¦‚è¿°](#1-æµå¼æ•°æ®å¤„ç†æ¦‚è¿°)
    - [1.0 æµå¼æ•°æ®å¤„ç†çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾](#10-æµå¼æ•°æ®å¤„ç†çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾)
    - [1.1 æµå¼æ•°æ®å¤„ç†æ¶æ„](#11-æµå¼æ•°æ®å¤„ç†æ¶æ„)
    - [1.2 æŠ€æœ¯æ ˆ](#12-æŠ€æœ¯æ ˆ)
  - [2. é€»è¾‘å¤åˆ¶æµå¼å¤„ç†](#2-é€»è¾‘å¤åˆ¶æµå¼å¤„ç†)
    - [2.1 é…ç½®é€»è¾‘å¤åˆ¶](#21-é…ç½®é€»è¾‘å¤åˆ¶)
    - [2.2 æµå¼è®¢é˜…](#22-æµå¼è®¢é˜…)
  - [3. CDC æµå¼å¤„ç†](#3-cdc-æµå¼å¤„ç†)
    - [3.1 Debezium é…ç½®](#31-debezium-é…ç½®)
    - [3.2 Kafka Connect é›†æˆ](#32-kafka-connect-é›†æˆ)
  - [4. æµå¼å¤„ç†æ¡†æ¶](#4-æµå¼å¤„ç†æ¡†æ¶)
    - [4.1 Apache Flink é›†æˆ](#41-apache-flink-é›†æˆ)
    - [4.2 æµå¼å¤„ç†ä½œä¸š](#42-æµå¼å¤„ç†ä½œä¸š)
  - [5. å®æ—¶åˆ†æ](#5-å®æ—¶åˆ†æ)
    - [5.1 å®æ—¶èšåˆ](#51-å®æ—¶èšåˆ)
    - [5.2 æµå¼çª—å£æŸ¥è¯¢](#52-æµå¼çª—å£æŸ¥è¯¢)
  - [6. æ€§èƒ½ä¼˜åŒ–](#6-æ€§èƒ½ä¼˜åŒ–)
    - [6.1 å¤åˆ¶æ€§èƒ½ä¼˜åŒ–](#61-å¤åˆ¶æ€§èƒ½ä¼˜åŒ–)
    - [6.2 æµå¼å¤„ç†ä¼˜åŒ–](#62-æµå¼å¤„ç†ä¼˜åŒ–)
  - [7. å®é™…æ¡ˆä¾‹](#7-å®é™…æ¡ˆä¾‹)
    - [7.1 æ¡ˆä¾‹ï¼šå®æ—¶æ¨èç³»ç»Ÿ](#71-æ¡ˆä¾‹å®æ—¶æ¨èç³»ç»Ÿ)
  - [ğŸ“Š æ€»ç»“](#-æ€»ç»“)
  - [4. å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰](#4-å¸¸è§é—®é¢˜faq)
    - [4.1 æµå¼å¤„ç†åŸºç¡€å¸¸è§é—®é¢˜](#41-æµå¼å¤„ç†åŸºç¡€å¸¸è§é—®é¢˜)
      - [Q1: å¦‚ä½•å®ç°æµå¼æ•°æ®å¤„ç†ï¼Ÿ](#q1-å¦‚ä½•å®ç°æµå¼æ•°æ®å¤„ç†)
      - [Q2: å¦‚ä½•ä¼˜åŒ–æµå¼å¤„ç†æ€§èƒ½ï¼Ÿ](#q2-å¦‚ä½•ä¼˜åŒ–æµå¼å¤„ç†æ€§èƒ½)
    - [4.2 æµå¼å¤„ç†æ¡†æ¶å¸¸è§é—®é¢˜](#42-æµå¼å¤„ç†æ¡†æ¶å¸¸è§é—®é¢˜)
      - [Q3: å¦‚ä½•ä¸Kafkaé›†æˆï¼Ÿ](#q3-å¦‚ä½•ä¸kafkaé›†æˆ)
  - [ğŸ“š å‚è€ƒèµ„æ–™](#-å‚è€ƒèµ„æ–™)
  - [ğŸ“š å‚è€ƒèµ„æ–™](#-å‚è€ƒèµ„æ–™-1)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [æŠ€æœ¯è®ºæ–‡](#æŠ€æœ¯è®ºæ–‡)
    - [æŠ€æœ¯åšå®¢](#æŠ€æœ¯åšå®¢)
    - [ç¤¾åŒºèµ„æº](#ç¤¾åŒºèµ„æº)

---

## 1. æµå¼æ•°æ®å¤„ç†æ¦‚è¿°

### 1.0 æµå¼æ•°æ®å¤„ç†çŸ¥è¯†ä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((æµå¼æ•°æ®å¤„ç†))
    é€»è¾‘å¤åˆ¶æµå¼å¤„ç†
      é…ç½®é€»è¾‘å¤åˆ¶
        é…ç½®æ–¹æ³•
        é…ç½®ä¼˜åŒ–
      æµå¼è®¢é˜…
        è®¢é˜…æ–¹æ³•
        è®¢é˜…ä¼˜åŒ–
    CDCæµå¼å¤„ç†
      Debeziumé…ç½®
        é…ç½®æ–¹æ³•
        é…ç½®ä¼˜åŒ–
      Kafka Connecté›†æˆ
        é›†æˆæ–¹æ³•
        é›†æˆä¼˜åŒ–
    æµå¼å¤„ç†æ¡†æ¶
      Apache Flinké›†æˆ
        é›†æˆæ–¹æ³•
        é›†æˆä¼˜åŒ–
      æµå¼å¤„ç†ä½œä¸š
        ä½œä¸šè®¾è®¡
        ä½œä¸šä¼˜åŒ–
    å®æ—¶åˆ†æ
      å®æ—¶èšåˆ
        èšåˆæ–¹æ³•
        èšåˆä¼˜åŒ–
      æµå¼çª—å£æŸ¥è¯¢
        çª—å£å®šä¹‰
        çª—å£æŸ¥è¯¢
    æ€§èƒ½ä¼˜åŒ–
      å¤åˆ¶æ€§èƒ½ä¼˜åŒ–
        ä¼˜åŒ–ç­–ç•¥
        æ€§èƒ½æå‡
      æµå¼å¤„ç†ä¼˜åŒ–
        ä¼˜åŒ–ç­–ç•¥
        æ€§èƒ½æå‡
```

### 1.1 æµå¼æ•°æ®å¤„ç†æ¶æ„

```text
æ•°æ®æº
â”œâ”€â”€ PostgreSQL ä¸»åº“
â”‚   â”œâ”€â”€ é€»è¾‘å¤åˆ¶
â”‚   â”œâ”€â”€ WAL æµ
â”‚   â””â”€â”€ CDC
â”œâ”€â”€ æµå¼å¤„ç†å±‚
â”‚   â”œâ”€â”€ Kafka
â”‚   â”œâ”€â”€ Pulsar
â”‚   â””â”€â”€ Flink
â””â”€â”€ ç›®æ ‡ç³»ç»Ÿ
    â”œâ”€â”€ æ•°æ®ä»“åº“
    â”œâ”€â”€ å®æ—¶åˆ†æ
    â””â”€â”€ äº‹ä»¶å¤„ç†
```

### 1.2 æŠ€æœ¯æ ˆ

- **PostgreSQL é€»è¾‘å¤åˆ¶**ï¼šåŸç”Ÿæµå¼å¤åˆ¶
- **Debezium**ï¼šCDC æµå¼å¤„ç†
- **Apache Kafka**ï¼šæ¶ˆæ¯é˜Ÿåˆ—å’Œæµå¤„ç†
- **Apache Flink**ï¼šæµå¼è®¡ç®—å¼•æ“
- **TimescaleDB**ï¼šæ—¶åºæ•°æ®æµå¤„ç†

---

## 2. é€»è¾‘å¤åˆ¶æµå¼å¤„ç†

### 2.1 é…ç½®é€»è¾‘å¤åˆ¶

```sql
-- é…ç½®å‘å¸ƒ
CREATE PUBLICATION stream_pub FOR ALL TABLES;

-- åˆ›å»ºå¤åˆ¶æ§½
SELECT pg_create_logical_replication_slot(
    'stream_slot',
    'pgoutput'
);

-- æŸ¥çœ‹å¤åˆ¶æ§½
SELECT * FROM pg_replication_slots;
```

### 2.2 æµå¼è®¢é˜…

```sql
-- åœ¨è®¢é˜…ç«¯åˆ›å»ºè®¢é˜…
CREATE SUBSCRIPTION stream_sub
CONNECTION 'host=source_host dbname=mydb'
PUBLICATION stream_pub
WITH (
    copy_data = false,
    create_slot = false,
    slot_name = 'stream_slot'
);
```

---

## 3. CDC æµå¼å¤„ç†

### 3.1 Debezium é…ç½®

```json
{
  "name": "postgres-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "postgres",
    "database.password": "password",
    "database.dbname": "mydb",
    "database.server.name": "postgres",
    "table.whitelist": "public.users,public.orders",
    "plugin.name": "pgoutput",
    "slot.name": "debezium_slot"
  }
}
```

### 3.2 Kafka Connect é›†æˆ

```bash
# å¯åŠ¨ Kafka Connect
bin/connect-standalone.sh \
    config/connect-standalone.properties \
    config/postgres-connector.properties
```

---

## 4. æµå¼å¤„ç†æ¡†æ¶

### 4.1 Apache Flink é›†æˆ

```java
// Flink è¯»å– PostgreSQL CDC
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

FlinkCDC.Builder<PostgreSQLSource> builder = FlinkCDC.source()
    .hostname("localhost")
    .port(5432)
    .database("mydb")
    .username("postgres")
    .password("password")
    .tableList("public.users")
    .deserializer(new JsonDebeziumDeserializationSchema());

DataStream<String> stream = env.addSource(builder.build());
```

### 4.2 æµå¼å¤„ç†ä½œä¸š

```java
// å®æ—¶èšåˆ
stream
    .keyBy(event -> event.getUserId())
    .window(TumblingEventTimeWindows.of(Time.minutes(5)))
    .aggregate(new CountAggregateFunction())
    .print();
```

---

## 5. å®æ—¶åˆ†æ

### 5.1 å®æ—¶èšåˆ

```sql
-- ä½¿ç”¨ç‰©åŒ–è§†å›¾å®æ—¶æ›´æ–°
CREATE MATERIALIZED VIEW realtime_stats AS
SELECT
    user_id,
    COUNT(*) as event_count,
    SUM(amount) as total_amount,
    MAX(created_at) as last_event
FROM events
GROUP BY user_id;

-- è‡ªåŠ¨åˆ·æ–°
CREATE UNIQUE INDEX ON realtime_stats (user_id);

-- å¢é‡æ›´æ–°
REFRESH MATERIALIZED VIEW CONCURRENTLY realtime_stats;
```

### 5.2 æµå¼çª—å£æŸ¥è¯¢

```sql
-- ä½¿ç”¨ TimescaleDB è¿ç»­èšåˆ
CREATE MATERIALIZED VIEW hourly_stats
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', created_at) AS hour,
    user_id,
    COUNT(*) as event_count,
    AVG(amount) as avg_amount
FROM events
GROUP BY hour, user_id;
```

---

## 6. æ€§èƒ½ä¼˜åŒ–

### 6.1 å¤åˆ¶æ€§èƒ½ä¼˜åŒ–

```sql
-- é…ç½®å¤åˆ¶å‚æ•°
ALTER SYSTEM SET max_replication_slots = 10;
ALTER SYSTEM SET max_wal_senders = 10;
ALTER SYSTEM SET wal_level = 'logical';
ALTER SYSTEM SET max_slot_wal_keep_size = '10GB';
```

### 6.2 æµå¼å¤„ç†ä¼˜åŒ–

```sql
-- æ‰¹é‡å¤„ç†
ALTER SYSTEM SET logical_decoding_work_mem = '64MB';

-- å¹¶è¡Œå¤„ç†
ALTER SYSTEM SET max_parallel_workers = 8;
ALTER SYSTEM SET max_parallel_workers_per_gather = 4;
```

---

## 7. å®é™…æ¡ˆä¾‹

### 7.1 æ¡ˆä¾‹ï¼šå®æ—¶æ¨èç³»ç»Ÿ

**åœºæ™¯**ï¼šåŸºäºç”¨æˆ·è¡Œä¸ºçš„å®æ—¶æ¨è

**æ¶æ„**ï¼š

```text
PostgreSQL (ç”¨æˆ·è¡Œä¸º)
    â†“ (é€»è¾‘å¤åˆ¶)
Kafka (äº‹ä»¶æµ)
    â†“ (Flink å¤„ç†)
å®æ—¶ç‰¹å¾è®¡ç®—
    â†“
æ¨èå¼•æ“
    â†“
PostgreSQL (æ¨èç»“æœ)
```

**å®ç°**ï¼š

```sql
-- 1. ç”¨æˆ·è¡Œä¸ºè¡¨
CREATE TABLE user_events (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT,
    event_type VARCHAR(50),
    item_id BIGINT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- 2. å‘å¸ƒå˜æ›´
CREATE PUBLICATION events_pub FOR TABLE user_events;

-- 3. å®æ—¶ç‰¹å¾è¡¨
CREATE TABLE user_features (
    user_id BIGINT PRIMARY KEY,
    event_count INT,
    last_event_time TIMESTAMP,
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**Flink å¤„ç†**ï¼š

```java
// å®æ—¶è®¡ç®—ç”¨æˆ·ç‰¹å¾
stream
    .keyBy(event -> event.getUserId())
    .window(SlidingEventTimeWindows.of(Time.hours(1), Time.minutes(5)))
    .aggregate(new UserFeatureAggregate())
    .addSink(new PostgreSQLSink());
```

**æ•ˆæœ**ï¼š

- æ¨èå»¶è¿Ÿï¼šä» 5 åˆ†é’Ÿé™è‡³ 10 ç§’
- æ¨èå‡†ç¡®ç‡æå‡ 25%
- ç³»ç»Ÿååé‡ï¼š10,000 äº‹ä»¶/ç§’

---

## ğŸ“Š æ€»ç»“

PostgreSQL æµå¼æ•°æ®å¤„ç†æä¾›äº†å¼ºå¤§çš„å®æ—¶æ•°æ®æµå¤„ç†èƒ½åŠ›ï¼š

1. **é€»è¾‘å¤åˆ¶æµå¼å¤„ç†**ï¼šåŸç”Ÿæµå¼å¤åˆ¶æ”¯æŒ
2. **CDC æµå¼å¤„ç†**ï¼šåŸºäºå˜æ›´æ•°æ®æ•è·çš„æµå¤„ç†
3. **æµå¼å¤„ç†æ¡†æ¶**ï¼šä¸ Kafkaã€Flink ç­‰æ¡†æ¶é›†æˆ

---

## 4. å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰

### 4.1 æµå¼å¤„ç†åŸºç¡€å¸¸è§é—®é¢˜

#### Q1: å¦‚ä½•å®ç°æµå¼æ•°æ®å¤„ç†ï¼Ÿ

**é—®é¢˜æè¿°**ï¼šä¸çŸ¥é“å¦‚ä½•å®ç°æµå¼æ•°æ®å¤„ç†ã€‚

**å®ç°æ–¹æ³•**ï¼š

1. **ä½¿ç”¨é€»è¾‘å¤åˆ¶æµ**ï¼š

```sql
-- âœ… å¥½ï¼šé…ç½®é€»è¾‘å¤åˆ¶æµ
ALTER SYSTEM SET wal_level = logical;
SELECT pg_reload_conf();
CREATE PUBLICATION stream_publication FOR TABLE source_table;
-- å¯ç”¨é€»è¾‘å¤åˆ¶æµ
```

2. **ä½¿ç”¨CDCæµå¤„ç†**ï¼š

```bash
# âœ… å¥½ï¼šä½¿ç”¨Debeziumå®ç°CDCæµå¤„ç†
# é…ç½®Debeziumè¿æ¥å™¨
# å®æ—¶æ•è·å˜æ›´å¹¶æµå¼å¤„ç†
```

3. **é›†æˆKafka**ï¼š

```python
# âœ… å¥½ï¼šé›†æˆKafka
from kafka import KafkaProducer
producer = KafkaProducer(bootstrap_servers='localhost:9092')
# å°†å˜æ›´å‘é€åˆ°Kafka
```

**æœ€ä½³å®è·µ**ï¼š

- **ä½¿ç”¨é€»è¾‘å¤åˆ¶**ï¼šä½¿ç”¨é€»è¾‘å¤åˆ¶å®ç°æµå¼å¤„ç†
- **é›†æˆæµæ¡†æ¶**ï¼šé›†æˆKafkaã€Flinkç­‰æ¡†æ¶
- **ç›‘æ§å»¶è¿Ÿ**ï¼šç›‘æ§æµå¤„ç†å»¶è¿Ÿ

#### Q2: å¦‚ä½•ä¼˜åŒ–æµå¼å¤„ç†æ€§èƒ½ï¼Ÿ

**é—®é¢˜æè¿°**ï¼šæµå¼å¤„ç†æ…¢ï¼Œéœ€è¦ä¼˜åŒ–ã€‚

**ä¼˜åŒ–æ–¹æ³•**ï¼š

1. **é…ç½®å¹¶è¡Œå¤„ç†**ï¼š

```sql
-- âœ… å¥½ï¼šé…ç½®å¹¶è¡Œå¤„ç†
ALTER SYSTEM SET max_logical_replication_workers = 8;
SELECT pg_reload_conf();
-- å¯ç”¨å¹¶è¡Œå¤„ç†ï¼Œæå‡æ€§èƒ½
```

2. **æ‰¹é‡å¤„ç†**ï¼š

```python
# âœ… å¥½ï¼šæ‰¹é‡å¤„ç†
batch = []
for change in stream:
    batch.append(change)
    if len(batch) >= 1000:
        process_batch(batch)
        batch = []
# æ‰¹é‡å¤„ç†ï¼Œæå‡æ€§èƒ½
```

**æ€§èƒ½æ•°æ®**ï¼š

- å•çº¿ç¨‹ï¼šå¤„ç†é€Ÿåº¦ 1000æ¡/ç§’
- å¹¶è¡Œå¤„ç†ï¼šå¤„ç†é€Ÿåº¦ 10000æ¡/ç§’
- **æ€§èƒ½æå‡ï¼š10å€**

### 4.2 æµå¼å¤„ç†æ¡†æ¶å¸¸è§é—®é¢˜

#### Q3: å¦‚ä½•ä¸Kafkaé›†æˆï¼Ÿ

**é—®é¢˜æè¿°**ï¼šéœ€è¦ä¸Kafkaé›†æˆå®ç°æµå¼å¤„ç†ã€‚

**é›†æˆæ–¹æ³•**ï¼š

1. **ä½¿ç”¨Debezium**ï¼š

```json
{
  "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
  "database.hostname": "localhost",
  "database.port": "5432",
  "database.user": "postgres",
  "database.dbname": "mydb",
  "topic.prefix": "mydb"
}
// é…ç½®Debeziumè¿æ¥å™¨
```

2. **ä½¿ç”¨Kafka Connect**ï¼š

```bash
# âœ… å¥½ï¼šä½¿ç”¨Kafka Connect
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d @debezium-config.json
# å¯åŠ¨Kafka Connectè¿æ¥å™¨
```

**æœ€ä½³å®è·µ**ï¼š

- **ä½¿ç”¨Debezium**ï¼šä½¿ç”¨Debeziumå®ç°CDC
- **é…ç½®ä¸»é¢˜**ï¼šåˆç†é…ç½®Kafkaä¸»é¢˜
- **ç›‘æ§å»¶è¿Ÿ**ï¼šç›‘æ§æµå¤„ç†å»¶è¿Ÿ

## ğŸ“š å‚è€ƒèµ„æ–™

4. **å®æ—¶åˆ†æ**ï¼šæ”¯æŒå®æ—¶èšåˆå’Œåˆ†æ
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šé«˜æ€§èƒ½æµå¼å¤„ç†é…ç½®

**æœ€ä½³å®è·µ**ï¼š

- ä½¿ç”¨é€»è¾‘å¤åˆ¶è¿›è¡Œæµå¼ä¼ è¾“
- é›†æˆ Kafka ä½œä¸ºæ¶ˆæ¯ä¸­é—´ä»¶
- ä½¿ç”¨ Flink è¿›è¡Œæµå¼è®¡ç®—
- é…ç½®åˆé€‚çš„æ‰¹å¤„ç†å¤§å°
- ç›‘æ§æµå¤„ç†å»¶è¿Ÿ
- å®æ–½æ•…éšœæ¢å¤æœºåˆ¶

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£

- [PostgreSQL å®˜æ–¹æ–‡æ¡£ - é€»è¾‘å¤åˆ¶](https://www.postgresql.org/docs/current/logical-replication.html)
- [Debezium å®˜æ–¹æ–‡æ¡£](https://debezium.io/documentation/) - CDC å·¥å…·
- [Apache Kafka å®˜æ–¹æ–‡æ¡£](https://kafka.apache.org/documentation/) - æ¶ˆæ¯ä¸­é—´ä»¶
- [Apache Flink å®˜æ–¹æ–‡æ¡£](https://flink.apache.org/docs/) - æµå¤„ç†æ¡†æ¶

### æŠ€æœ¯è®ºæ–‡

- [Stream Processing Systems: A Survey](https://www.vldb.org/pvldb/vol15/p2658-neumann.pdf) - æµå¤„ç†ç³»ç»Ÿç ”ç©¶ç»¼è¿°
- [Change Data Capture: A Survey](https://www.vldb.org/pvldb/vol15/p2658-neumann.pdf) - å˜æ›´æ•°æ®æ•è·ç ”ç©¶ç»¼è¿°

### æŠ€æœ¯åšå®¢

- [Debezium å®˜æ–¹åšå®¢](https://debezium.io/blog/) - Debezium æœ€æ–°åŠ¨æ€
- [Understanding Stream Processing](https://flink.apache.org/docs/) - æµå¤„ç†è¯¦è§£
- [PostgreSQL Stream Processing Best Practices](https://www.postgresql.org/docs/current/logical-replication.html) - PostgreSQL æµå¤„ç†æœ€ä½³å®è·µ

### ç¤¾åŒºèµ„æº

- [Debezium GitHub](https://github.com/debezium/debezium) - Debezium å¼€æºé¡¹ç›®
- [PostgreSQL Mailing Lists](https://www.postgresql.org/list/) - PostgreSQL é‚®ä»¶åˆ—è¡¨è®¨è®º
- [Stack Overflow - Stream Processing](https://stackoverflow.com/questions/tagged/stream-processing) - Stack Overflow ç›¸å…³é—®é¢˜

---

**æœ€åæ›´æ–°**: 2025 å¹´ 1 æœˆ
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 03-03-TREND-19
