# AI åº”ç”¨å®æˆ˜ï¼šåŸºäº PostgreSQL çš„ AI åº”ç”¨å¼€å‘

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 1 æœˆ
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 17+ with pgvector + AI æ¡†æ¶
> **æ–‡æ¡£ç¼–å·**: 03-03-TREND-04

## ğŸ“‘ æ¦‚è¿°

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åŸºäº PostgreSQL å’Œ pgvector æ„å»ºå®é™…çš„ AI åº”ç”¨ï¼ŒåŒ…æ‹¬æ¨èç³»ç»Ÿã€è¯­ä¹‰æœç´¢ã€RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ã€å›¾åƒæœç´¢ç­‰åœºæ™¯çš„å®Œæ•´å®ç°æ–¹æ¡ˆã€‚

## ğŸ¯ æ ¸å¿ƒä»·å€¼

- **æ¨èç³»ç»Ÿ**ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦çš„å•†å“/å†…å®¹æ¨è
- **è¯­ä¹‰æœç´¢**ï¼šç†è§£æŸ¥è¯¢æ„å›¾çš„æ™ºèƒ½æœç´¢
- **RAG åº”ç”¨**ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œç»“åˆå‘é‡æ•°æ®åº“å’Œ LLM
- **å›¾åƒæœç´¢**ï¼šåŸºäºå›¾åƒç‰¹å¾çš„ç›¸ä¼¼å›¾åƒæœç´¢
- **å®Œæ•´æ–¹æ¡ˆ**ï¼šä»æ•°æ®å‡†å¤‡åˆ°éƒ¨ç½²çš„å®Œæ•´å®ç°

## ğŸ“š ç›®å½•

- [AI åº”ç”¨å®æˆ˜ï¼šåŸºäº PostgreSQL çš„ AI åº”ç”¨å¼€å‘](#ai-åº”ç”¨å®æˆ˜åŸºäº-postgresql-çš„-ai-åº”ç”¨å¼€å‘)
  - [ğŸ“‘ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ¯ æ ¸å¿ƒä»·å€¼](#-æ ¸å¿ƒä»·å€¼)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. AI åº”ç”¨æ¶æ„](#1-ai-åº”ç”¨æ¶æ„)
    - [1.1 æŠ€æœ¯æ ˆ](#11-æŠ€æœ¯æ ˆ)
    - [1.2 æ ¸å¿ƒç»„ä»¶](#12-æ ¸å¿ƒç»„ä»¶)
  - [2. æ¨èç³»ç»Ÿå®ç°](#2-æ¨èç³»ç»Ÿå®ç°)
    - [2.1 å•†å“æ¨èç³»ç»Ÿ](#21-å•†å“æ¨èç³»ç»Ÿ)
    - [2.2 æ¨èç®—æ³•å®ç°](#22-æ¨èç®—æ³•å®ç°)
    - [2.3 æ··åˆæ¨èç­–ç•¥](#23-æ··åˆæ¨èç­–ç•¥)
  - [3. è¯­ä¹‰æœç´¢å®ç°](#3-è¯­ä¹‰æœç´¢å®ç°)
    - [3.1 æ–‡æ¡£è¯­ä¹‰æœç´¢](#31-æ–‡æ¡£è¯­ä¹‰æœç´¢)
    - [3.2 è¯­ä¹‰æœç´¢ API](#32-è¯­ä¹‰æœç´¢-api)
  - [4. RAG åº”ç”¨å®ç°](#4-rag-åº”ç”¨å®ç°)
    - [4.1 RAG æ¶æ„](#41-rag-æ¶æ„)
    - [4.2 RAG å®ç°](#42-rag-å®ç°)
  - [5. å›¾åƒæœç´¢å®ç°](#5-å›¾åƒæœç´¢å®ç°)
    - [5.1 å›¾åƒç‰¹å¾æå–](#51-å›¾åƒç‰¹å¾æå–)
  - [6. æ€§èƒ½ä¼˜åŒ–](#6-æ€§èƒ½ä¼˜åŒ–)
    - [6.1 å‘é‡ç´¢å¼•ä¼˜åŒ–](#61-å‘é‡ç´¢å¼•ä¼˜åŒ–)
    - [6.2 ç¼“å­˜ç­–ç•¥](#62-ç¼“å­˜ç­–ç•¥)
  - [7. éƒ¨ç½²æ–¹æ¡ˆ](#7-éƒ¨ç½²æ–¹æ¡ˆ)
    - [7.1 Docker éƒ¨ç½²](#71-docker-éƒ¨ç½²)
    - [7.2 ç”Ÿäº§ç¯å¢ƒé…ç½®](#72-ç”Ÿäº§ç¯å¢ƒé…ç½®)
  - [ğŸ“Š æ€»ç»“](#-æ€»ç»“)

---

## 1. AI åº”ç”¨æ¶æ„

### 1.1 æŠ€æœ¯æ ˆ

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   åº”ç”¨å±‚        â”‚
â”‚  (Python/Node)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI æ¨¡å‹å±‚     â”‚
â”‚  (OpenAI/æœ¬åœ°)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL     â”‚
â”‚  + pgvector     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒç»„ä»¶

- **PostgreSQL + pgvector**ï¼šå‘é‡å­˜å‚¨å’Œæœç´¢
- **AI æ¨¡å‹**ï¼šæ–‡æœ¬åµŒå…¥ã€å›¾åƒç‰¹å¾æå–
- **åº”ç”¨å±‚**ï¼šä¸šåŠ¡é€»è¾‘å’Œ API æœåŠ¡
- **ç¼“å­˜å±‚**ï¼šRedisï¼ˆå¯é€‰ï¼‰

---

## 2. æ¨èç³»ç»Ÿå®ç°

### 2.1 å•†å“æ¨èç³»ç»Ÿ

```sql
-- åˆ›å»ºå•†å“è¡¨
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    category TEXT,
    embedding vector(1536),  -- å•†å“æè¿°å‘é‡
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç”¨æˆ·è¡Œä¸ºè¡¨
CREATE TABLE user_interactions (
    id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL,
    product_id INTEGER REFERENCES products(id),
    interaction_type TEXT,  -- 'view', 'purchase', 'like'
    embedding vector(1536),  -- ç”¨æˆ·åå¥½å‘é‡
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_products_embedding_hnsw
ON products USING hnsw (embedding vector_cosine_ops);

CREATE INDEX idx_user_interactions_user_product
ON user_interactions (user_id, product_id);
```

### 2.2 æ¨èç®—æ³•å®ç°

```python
# Python å®ç°ï¼šåŸºäºååŒè¿‡æ»¤çš„æ¨è
import psycopg2
from pgvector.psycopg2 import register_vector
import openai

def get_user_preference_vector(user_id, conn):
    """è·å–ç”¨æˆ·åå¥½å‘é‡"""
    cur = conn.cursor()
    cur.execute("""
        SELECT AVG(embedding) AS user_vector
        FROM user_interactions
        WHERE user_id = %s
          AND interaction_type IN ('purchase', 'like')
    """, (user_id,))
    result = cur.fetchone()
    return result[0] if result and result[0] else None

def recommend_products(user_id, limit=10, conn=None):
    """æ¨èå•†å“"""
    # è·å–ç”¨æˆ·åå¥½å‘é‡
    user_vector = get_user_preference_vector(user_id, conn)
    if not user_vector:
        return []

    # åŸºäºå‘é‡ç›¸ä¼¼åº¦æ¨è
    cur = conn.cursor()
    cur.execute("""
        SELECT
            p.id,
            p.name,
            p.description,
            1 - (p.embedding <=> %s::vector) AS similarity
        FROM products p
        WHERE p.embedding IS NOT NULL
          AND p.id NOT IN (
              SELECT product_id
              FROM user_interactions
              WHERE user_id = %s
          )
        ORDER BY p.embedding <=> %s::vector
        LIMIT %s
    """, (user_vector, user_id, user_vector, limit))

    return cur.fetchall()

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("...")
register_vector(conn)
recommendations = recommend_products(user_id=123, limit=10, conn=conn)
```

### 2.3 æ··åˆæ¨èç­–ç•¥

```sql
-- SQL å®ç°ï¼šæ··åˆæ¨èï¼ˆååŒè¿‡æ»¤ + å†…å®¹æ¨èï¼‰
CREATE OR REPLACE FUNCTION hybrid_recommend(
    p_user_id INTEGER,
    p_limit INTEGER DEFAULT 10
)
RETURNS TABLE (
    product_id INTEGER,
    product_name TEXT,
    recommendation_score FLOAT,
    recommendation_type TEXT
)
LANGUAGE plpgsql
AS $$
DECLARE
    v_user_vector vector(1536);
BEGIN
    -- è·å–ç”¨æˆ·åå¥½å‘é‡
    SELECT AVG(embedding) INTO v_user_vector
    FROM user_interactions
    WHERE user_id = p_user_id
      AND interaction_type IN ('purchase', 'like');

    -- æ··åˆæ¨èï¼šååŒè¿‡æ»¤ + å†…å®¹æ¨è
    RETURN QUERY
    WITH collaborative_filtering AS (
        -- ååŒè¿‡æ»¤ï¼šåŸºäºç›¸ä¼¼ç”¨æˆ·
        SELECT DISTINCT
            ui2.product_id,
            0.6 AS score,
            'collaborative' AS rec_type
        FROM user_interactions ui1
        JOIN user_interactions ui2
            ON ui1.product_id = ui2.product_id
            AND ui1.user_id != ui2.user_id
        WHERE ui1.user_id = p_user_id
          AND ui1.interaction_type IN ('purchase', 'like')
          AND ui2.user_id NOT IN (
              SELECT user_id FROM user_interactions
              WHERE user_id = p_user_id
          )
    ),
    content_based AS (
        -- å†…å®¹æ¨èï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦
        SELECT
            p.id AS product_id,
            (1 - (p.embedding <=> v_user_vector))::FLOAT * 0.4 AS score,
            'content' AS rec_type
        FROM products p
        WHERE p.embedding IS NOT NULL
          AND p.id NOT IN (
              SELECT product_id FROM user_interactions
              WHERE user_id = p_user_id
          )
        ORDER BY p.embedding <=> v_user_vector
        LIMIT p_limit * 2
    )
    SELECT
        COALESCE(cf.product_id, cb.product_id) AS product_id,
        p.name AS product_name,
        COALESCE(cf.score, 0) + COALESCE(cb.score, 0) AS recommendation_score,
        COALESCE(cf.rec_type, cb.rec_type) AS recommendation_type
    FROM collaborative_filtering cf
    FULL OUTER JOIN content_based cb ON cf.product_id = cb.product_id
    JOIN products p ON p.id = COALESCE(cf.product_id, cb.product_id)
    ORDER BY recommendation_score DESC
    LIMIT p_limit;
END;
$$;
```

---

## 3. è¯­ä¹‰æœç´¢å®ç°

### 3.1 æ–‡æ¡£è¯­ä¹‰æœç´¢

```sql
-- åˆ›å»ºæ–‡æ¡£è¡¨
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    embedding vector(1536),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_documents_embedding_hnsw
ON documents USING hnsw (embedding vector_cosine_ops);
```

### 3.2 è¯­ä¹‰æœç´¢ API

```python
# Python å®ç°ï¼šè¯­ä¹‰æœç´¢ API
from flask import Flask, request, jsonify
import psycopg2
from pgvector.psycopg2 import register_vector
import openai

app = Flask(__name__)

def get_embedding(text):
    """è·å–æ–‡æœ¬åµŒå…¥å‘é‡"""
    response = openai.Embedding.create(
        model="text-embedding-3-small",
        input=text
    )
    return response['data'][0]['embedding']

@app.route('/search', methods=['POST'])
def semantic_search():
    """è¯­ä¹‰æœç´¢æ¥å£"""
    data = request.json
    query_text = data.get('query')
    limit = data.get('limit', 10)

    # è·å–æŸ¥è¯¢å‘é‡
    query_embedding = get_embedding(query_text)

    # æœç´¢ç›¸ä¼¼æ–‡æ¡£
    conn = psycopg2.connect("...")
    register_vector(conn)
    cur = conn.cursor()

    cur.execute("""
        SELECT
            id,
            title,
            content,
            1 - (embedding <=> %s::vector) AS similarity
        FROM documents
        WHERE embedding IS NOT NULL
        ORDER BY embedding <=> %s::vector
        LIMIT %s
    """, (query_embedding, query_embedding, limit))

    results = cur.fetchall()
    conn.close()

    return jsonify({
        'results': [
            {
                'id': r[0],
                'title': r[1],
                'content': r[2],
                'similarity': float(r[3])
            }
            for r in results
        ]
    })

if __name__ == '__main__':
    app.run(debug=True)
```

---

## 4. RAG åº”ç”¨å®ç°

### 4.1 RAG æ¶æ„

```text
ç”¨æˆ·æŸ¥è¯¢
    â†“
ç”ŸæˆæŸ¥è¯¢å‘é‡
    â†“
å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
    â†“
æ„å»ºä¸Šä¸‹æ–‡
    â†“
LLM ç”Ÿæˆå›ç­”
```

### 4.2 RAG å®ç°

```python
# Python å®ç°ï¼šRAG åº”ç”¨
import psycopg2
from pgvector.psycopg2 import register_vector
import openai

class RAGSystem:
    def __init__(self, db_conn, openai_client):
        self.conn = db_conn
        self.client = openai_client
        register_vector(self.conn)

    def retrieve_context(self, query_embedding, top_k=5):
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        cur = self.conn.cursor()
        cur.execute("""
            SELECT
                content,
                1 - (embedding <=> %s::vector) AS similarity
            FROM documents
            WHERE embedding IS NOT NULL
            ORDER BY embedding <=> %s::vector
            LIMIT %s
        """, (query_embedding, query_embedding, top_k))

        results = cur.fetchall()
        return [r[0] for r in results]

    def generate_answer(self, query, context_docs):
        """ç”Ÿæˆå›ç­”"""
        context = "\n\n".join(context_docs)

        prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{query}

å›ç­”ï¼š"""

        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )

        return response.choices[0].message.content

    def query(self, user_query):
        """RAG æŸ¥è¯¢"""
        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        embedding_response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=user_query
        )
        query_embedding = embedding_response.data[0].embedding

        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        context_docs = self.retrieve_context(query_embedding)

        # 3. ç”Ÿæˆå›ç­”
        answer = self.generate_answer(user_query, context_docs)

        return {
            'answer': answer,
            'sources': context_docs
        }

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("...")
rag = RAGSystem(conn, openai_client)
result = rag.query("ä»€ä¹ˆæ˜¯ PostgreSQLï¼Ÿ")
print(result['answer'])
```

---

## 5. å›¾åƒæœç´¢å®ç°

### 5.1 å›¾åƒç‰¹å¾æå–

```python
# Python å®ç°ï¼šå›¾åƒç‰¹å¾æå–å’Œæœç´¢
import psycopg2
from pgvector.psycopg2 import register_vector
from PIL import Image
import torch
import torchvision.transforms as transforms
from torchvision.models import resnet50

class ImageSearchSystem:
    def __init__(self, db_conn):
        self.conn = db_conn
        register_vector(self.conn)

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.model = resnet50(pretrained=True)
        self.model.eval()

        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    def extract_features(self, image_path):
        """æå–å›¾åƒç‰¹å¾"""
        image = Image.open(image_path).convert('RGB')
        image_tensor = self.transform(image).unsqueeze(0)

        with torch.no_grad():
            features = self.model(image_tensor)
            features = features.squeeze().numpy()

        return features.tolist()

    def search_similar_images(self, query_image_path, limit=10):
        """æœç´¢ç›¸ä¼¼å›¾åƒ"""
        # æå–æŸ¥è¯¢å›¾åƒç‰¹å¾
        query_features = self.extract_features(query_image_path)

        # æœç´¢ç›¸ä¼¼å›¾åƒ
        cur = self.conn.cursor()
        cur.execute("""
            SELECT
                id,
                image_path,
                1 - (embedding <=> %s::vector) AS similarity
            FROM images
            WHERE embedding IS NOT NULL
            ORDER BY embedding <=> %s::vector
            LIMIT %s
        """, (query_features, query_features, limit))

        return cur.fetchall()

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("...")
image_search = ImageSearchSystem(conn)
results = image_search.search_similar_images('query_image.jpg', limit=10)
```

---

## 6. æ€§èƒ½ä¼˜åŒ–

### 6.1 å‘é‡ç´¢å¼•ä¼˜åŒ–

```sql
-- ä¼˜åŒ– HNSW ç´¢å¼•å‚æ•°
CREATE INDEX idx_products_embedding_hnsw
ON products USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 32,              -- å¢åŠ è¿æ¥æ•°
    ef_construction = 200  -- å¢åŠ æ„å»ºç²¾åº¦
);

-- æŸ¥è¯¢æ—¶è°ƒæ•´ ef_search
SET hnsw.ef_search = 100;  -- å¢åŠ æœç´¢ç²¾åº¦
```

### 6.2 ç¼“å­˜ç­–ç•¥

```python
# Python å®ç°ï¼šå‘é‡ç¼“å­˜
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def get_cached_embedding(text):
    """ç¼“å­˜æ–‡æœ¬åµŒå…¥å‘é‡"""
    return get_embedding(text)

def get_embedding_with_cache(text):
    """å¸¦ç¼“å­˜çš„åµŒå…¥å‘é‡è·å–"""
    cache_key = hashlib.md5(text.encode()).hexdigest()
    return get_cached_embedding(text)
```

---

## 7. éƒ¨ç½²æ–¹æ¡ˆ

### 7.1 Docker éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# å¯åŠ¨åº”ç”¨
CMD ["python", "app.py"]
```

### 7.2 ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
# config.py
import os

DATABASE_URL = os.getenv('DATABASE_URL')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# è¿æ¥æ± é…ç½®
DB_POOL_SIZE = 20
DB_MAX_OVERFLOW = 10

# å‘é‡æœç´¢é…ç½®
VECTOR_SEARCH_LIMIT = 10
VECTOR_SIMILARITY_THRESHOLD = 0.7
```

---

## ğŸ“Š æ€»ç»“

åŸºäº PostgreSQL å’Œ pgvector å¯ä»¥æ„å»ºå¼ºå¤§çš„ AI åº”ç”¨ï¼ŒåŒ…æ‹¬æ¨èç³»ç»Ÿã€è¯­ä¹‰æœç´¢ã€RAG åº”ç”¨ã€å›¾åƒæœç´¢ç­‰ã€‚
é€šè¿‡åˆç†è®¾è®¡æ•°æ®æ¨¡å‹ã€ä¼˜åŒ–å‘é‡ç´¢å¼•ã€å®ç°é«˜æ•ˆçš„æ£€ç´¢ç®—æ³•ï¼Œå¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å®ç°é«˜æ€§èƒ½çš„ AI åº”ç”¨ã€‚

---

**æœ€åæ›´æ–°**: 2025 å¹´ 1 æœˆ
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 03-03-TREND-04
