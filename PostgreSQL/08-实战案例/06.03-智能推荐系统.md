# æ™ºèƒ½æ¨èç³»ç»Ÿ - åŸºäºPostgreSQLçš„å®Œæ•´å®ç°

**PostgreSQLç‰ˆæœ¬**: 18.x (æ¨è) â­ | 17.x (æ¨è) | 16.x (å…¼å®¹)
**æ¡ˆä¾‹ç±»å‹**: ç”Ÿäº§çº§å®Œæ•´é¡¹ç›®
**æŠ€æœ¯æ ˆ**: PostgreSQL 18 + pgvector 2.0+ â­ | PostgreSQL 17 + pgvector 0.7+ + ååŒè¿‡æ»¤ + å†…å®¹æ¨è
**éš¾åº¦**: â­â­â­â­â­
**é¢„è®¡æ—¶é—´**: 6-8å°æ—¶å®Œæ•´å®ç°
**æœ€åæ›´æ–°**: 2025-11-12
**æµ‹è¯•ç¯å¢ƒ**: PostgreSQL 18.0 + pgvector 2.0 â­ | PostgreSQL 17.0 + pgvector 0.7.4

> ğŸ†• **PostgreSQL 18 + pgvector 2.0 æ¨èç³»ç»Ÿä¼˜åŒ–** â­â­â­
>
> PostgreSQL 18 + pgvector 2.0 ä¸ºæ¨èç³»ç»Ÿå¸¦æ¥å…³é”®æ€§èƒ½æå‡ï¼š
>
> - âœ… **è™šæ‹Ÿç”Ÿæˆåˆ—**: åŠ¨æ€è®¡ç®—ç›¸ä¼¼åº¦ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡ 15-25% â­â­
> - âœ… **å¼‚æ­¥ I/O å­ç³»ç»Ÿ**: å‘é‡æ£€ç´¢ I/O æ€§èƒ½æå‡ 2-3 å€ â­â­â­
> - âœ… **å‘é‡æ“ä½œSIMDä¼˜åŒ–**: åˆ©ç”¨AVX-512æŒ‡ä»¤é›†ï¼Œæ€§èƒ½æå‡35-45%
> - âœ… **å¹¶è¡ŒæŸ¥è¯¢å¢å¼º**: ååŒè¿‡æ»¤è®¡ç®—æ€§èƒ½æå‡35%
> - âœ… **sparsevec ç±»å‹**: pgvector 2.0 æ–°å¢ç¨€ç–å‘é‡æ”¯æŒï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´ 60-80%
> - âœ… **COPYå¢å¼º**: ON_ERRORé€‰é¡¹ï¼Œæ‰¹é‡ç”¨æˆ·è¡Œä¸ºæ•°æ®å¯¼å…¥æ›´å¯é 
> - âœ… **ç›‘æ§æ”¹è¿›**: å®æ—¶è¿½è¸ªæ¨èè´¨é‡å’Œæ€§èƒ½æŒ‡æ ‡

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ª**ä¼ä¸šçº§æ™ºèƒ½æ¨èç³»ç»Ÿ**ï¼Œç»“åˆï¼š

- ğŸ“Š ååŒè¿‡æ»¤ï¼ˆç”¨æˆ·-ç‰©å“çŸ©é˜µï¼‰
- ğŸ” å†…å®¹ç›¸ä¼¼åº¦ï¼ˆå‘é‡è¯­ä¹‰ï¼‰
- ğŸ¤– æ·±åº¦å­¦ä¹ ç‰¹å¾
- ğŸ“ˆ å®æ—¶ä¸ªæ€§åŒ–
- ğŸ¯ A/Bæµ‹è¯•æ¡†æ¶
- ğŸ“Š æ•ˆæœè¯„ä¼°å’Œä¼˜åŒ–

### æ ¸å¿ƒç‰¹æ€§

âœ… **å¤šç­–ç•¥æ¨è**

- ååŒè¿‡æ»¤ï¼ˆCFï¼‰
- å†…å®¹æ¨èï¼ˆCBï¼‰
- æ··åˆæ¨èï¼ˆHybridï¼‰
- å†·å¯åŠ¨å¤„ç†

âœ… **å®æ—¶èƒ½åŠ›**

- å®æ—¶ç‰¹å¾è®¡ç®—
- å¢é‡æ¨¡å‹æ›´æ–°
- æµå¼æ¨èæœåŠ¡
- æ¯«ç§’çº§å“åº”

âœ… **ä¼ä¸šåŠŸèƒ½**

- A/Bæµ‹è¯•å¹³å°
- æ•ˆæœå½’å› åˆ†æ
- å¤šç›®æ ‡ä¼˜åŒ–
- æ¨èè§£é‡Šæ€§

---

## ğŸ“ ç³»ç»Ÿæ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ™ºèƒ½æ¨èç³»ç»Ÿæ¶æ„                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·è¯·æ±‚       â”‚  (Web/Mobile/API)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ¨èæœåŠ¡å±‚      â”‚  (FastAPI)
â”‚  - ç­–ç•¥é€‰æ‹©      â”‚
â”‚  - ç»“æœèåˆ      â”‚
â”‚  - A/Båˆ†æµ       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚          â”‚          â”‚          â”‚
    â–¼         â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CFæ¨èâ”‚ â”‚ CBæ¨è  â”‚ â”‚ DLæ¨è â”‚ â”‚ çƒ­é—¨   â”‚ â”‚ è§„åˆ™   â”‚
â”‚ æ¨¡å—  â”‚ â”‚ æ¨¡å—    â”‚ â”‚ æ¨¡å—   â”‚ â”‚ æ¨¡å—   â”‚ â”‚ æ¨¡å—   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚         â”‚          â”‚          â”‚         â”‚
    â”‚         â–¼          â–¼          â”‚         â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚         â”‚
    â”‚    â”‚   ç‰¹å¾å·¥ç¨‹æœåŠ¡    â”‚       â”‚         â”‚
    â”‚    â”‚  - ç”¨æˆ·ç‰¹å¾       â”‚        â”‚         â”‚
    â”‚    â”‚  - ç‰©å“ç‰¹å¾       â”‚        â”‚         â”‚
    â”‚    â”‚  - ä¸Šä¸‹æ–‡ç‰¹å¾     â”‚        â”‚         â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚         â”‚
    â”‚                                â”‚         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  PostgreSQL     â”‚
            â”‚  + pgvector     â”‚
            â”‚                 â”‚
            â”‚  - ç”¨æˆ·ç”»åƒ      â”‚
            â”‚  - ç‰©å“ç‰¹å¾      â”‚
            â”‚  - äº¤äº’è¡Œä¸º      â”‚
            â”‚  - æ¨èç»“æœ      â”‚
            â”‚  - A/Bå®éªŒ      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Redis   â”‚          â”‚ Kafka    â”‚
    â”‚  (ç¼“å­˜)  â”‚          â”‚ (æ—¥å¿—)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ¨èæµç¨‹:
1. ç”¨æˆ·è¯·æ±‚ â†’ A/Båˆ†æµ â†’ ç­–ç•¥é€‰æ‹©
2. å¹¶è¡Œå¬å› â†’ ç‰¹å¾å·¥ç¨‹ â†’ æ’åº
3. å¤šæ ·æ€§/æ–°é¢–æ€§å¤„ç† â†’ è¿”å›ç»“æœ
4. æ—¥å¿—è®°å½• â†’ æ•ˆæœè¿½è¸ª â†’ æ¨¡å‹æ›´æ–°
```

---

## ğŸ’¾ æ•°æ®åº“è®¾è®¡

### å®Œæ•´æ•°æ®æ¨¡å‹

```sql
-- âœ… [å¯è¿è¡Œ] æ™ºèƒ½æ¨èç³»ç»Ÿæ•°æ®åº“è®¾è®¡

-- å¯ç”¨æ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS cube;

-- ============================
-- ç”¨æˆ·ç›¸å…³è¡¨
-- ============================

-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    user_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255),

    -- åŸºæœ¬å±æ€§
    age_group VARCHAR(20),  -- 18-24, 25-34, etc.
    gender VARCHAR(20),
    location VARCHAR(100),

    -- æ—¶é—´æˆ³
    registered_at TIMESTAMPTZ DEFAULT NOW(),
    last_active_at TIMESTAMPTZ,

    -- å…ƒæ•°æ®
    metadata JSONB DEFAULT '{}'::jsonb
);

-- ç”¨æˆ·ç”»åƒï¼ˆç‰¹å¾å‘é‡ï¼‰
CREATE TABLE user_profiles (
    user_id UUID PRIMARY KEY REFERENCES users(user_id) ON DELETE CASCADE,

    -- å…´è¶£å‘é‡ï¼ˆå¤šä¸ªç»´åº¦ï¼‰
    interest_vector vector(128),  -- åŸºäºè¡Œä¸ºå­¦ä¹ çš„å…´è¶£

    -- ç»Ÿè®¡ç‰¹å¾
    total_interactions INTEGER DEFAULT 0,
    total_purchases INTEGER DEFAULT 0,
    total_time_spent INTEGER DEFAULT 0,  -- ç§’
    avg_rating FLOAT,

    -- åå¥½æ ‡ç­¾
    preferred_categories TEXT[],
    preferred_brands TEXT[],

    -- è¡Œä¸ºç‰¹å¾
    activity_level VARCHAR(20),  -- low, medium, high
    purchase_power VARCHAR(20),  -- low, medium, high

    -- æ›´æ–°æ—¶é—´
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ============================
-- ç‰©å“ç›¸å…³è¡¨
-- ============================

-- ç‰©å“è¡¨
CREATE TABLE items (
    item_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    title VARCHAR(500) NOT NULL,
    description TEXT,

    -- åˆ†ç±»
    category VARCHAR(100),
    sub_category VARCHAR(100),
    brand VARCHAR(100),
    tags TEXT[],

    -- å±æ€§
    price DECIMAL(10, 2),
    stock INTEGER DEFAULT 0,
    status VARCHAR(50) DEFAULT 'active',  -- active, inactive, soldout

    -- å†…å®¹å‘é‡ï¼ˆç”¨äºå†…å®¹æ¨èï¼‰
    content_vector vector(128),

    -- è´¨é‡æŒ‡æ ‡
    avg_rating FLOAT DEFAULT 0,
    rating_count INTEGER DEFAULT 0,
    view_count INTEGER DEFAULT 0,
    purchase_count INTEGER DEFAULT 0,

    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),

    -- å…¨æ–‡æœç´¢
    content_tsv tsvector GENERATED ALWAYS AS (
        to_tsvector('english', coalesce(title, '') || ' ' || coalesce(description, ''))
    ) STORED
);

-- ç‰©å“ç‰¹å¾ï¼ˆé¢å¤–çš„ç»“æ„åŒ–ç‰¹å¾ï¼‰
CREATE TABLE item_features (
    item_id UUID PRIMARY KEY REFERENCES items(item_id) ON DELETE CASCADE,

    -- ç±»ç›®ç‰¹å¾
    category_tree TEXT[],  -- ['ç”µå­äº§å“', 'æ‰‹æœº', 'æ™ºèƒ½æ‰‹æœº']

    -- é”€å”®ç‰¹å¾
    sales_rank INTEGER,
    conversion_rate FLOAT,

    -- å†…å®¹ç‰¹å¾
    image_embeddings vector(512),  -- å›¾ç‰‡åµŒå…¥
    text_embeddings vector(768),   -- æ–‡æœ¬åµŒå…¥ï¼ˆBERTï¼‰

    -- ååŒç‰¹å¾
    similar_items UUID[],  -- ç›¸ä¼¼ç‰©å“åˆ—è¡¨

    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ============================
-- äº¤äº’è¡Œä¸ºè¡¨
-- ============================

-- ç”¨æˆ·-ç‰©å“äº¤äº’ï¼ˆäº‹å®è¡¨ï¼‰
CREATE TABLE interactions (
    id BIGSERIAL PRIMARY KEY,
    user_id UUID REFERENCES users(user_id) ON DELETE CASCADE,
    item_id UUID REFERENCES items(item_id) ON DELETE CASCADE,

    -- äº¤äº’ç±»å‹
    interaction_type VARCHAR(50) NOT NULL,  -- view, click, add_to_cart, purchase, rate, review

    -- äº¤äº’å¼ºåº¦
    value FLOAT,  -- è¯„åˆ†ã€åœç•™æ—¶é•¿ç­‰

    -- ä¸Šä¸‹æ–‡
    device_type VARCHAR(50),
    platform VARCHAR(50),
    session_id VARCHAR(100),
    referrer TEXT,

    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW(),

    -- å…ƒæ•°æ®
    metadata JSONB DEFAULT '{}'::jsonb
);

-- è¯„åˆ†è¡¨ï¼ˆæ˜¾å¼åé¦ˆï¼‰
CREATE TABLE ratings (
    user_id UUID REFERENCES users(user_id) ON DELETE CASCADE,
    item_id UUID REFERENCES items(item_id) ON DELETE CASCADE,
    rating FLOAT CHECK (rating >= 1 AND rating <= 5),
    review_text TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (user_id, item_id)
);

-- ============================
-- æ¨èç›¸å…³è¡¨
-- ============================

-- PostgreSQL 18: æ¨èç»“æœè¡¨ï¼ˆä½¿ç”¨è™šæ‹Ÿç”Ÿæˆåˆ—ä¼˜åŒ–ï¼‰â­
CREATE TABLE recommendation_results (
    id BIGSERIAL PRIMARY KEY,
    user_id UUID REFERENCES users(user_id) ON DELETE CASCADE,
    item_id UUID REFERENCES items(item_id) ON DELETE CASCADE,

    -- PostgreSQL 18: è™šæ‹Ÿç”Ÿæˆåˆ— - åŠ¨æ€è®¡ç®—ç›¸ä¼¼åº¦ â­â­
    similarity_score FLOAT GENERATED ALWAYS AS (
        1 - (
            (SELECT interest_vector FROM user_profiles WHERE user_id = recommendation_results.user_id) <=>
            (SELECT content_vector FROM items WHERE item_id = recommendation_results.item_id)
        )
    ) STORED,

    -- ååŒè¿‡æ»¤åˆ†æ•°
    cf_score FLOAT DEFAULT 0,

    -- ç»¼åˆæ¨èåˆ†æ•°ï¼ˆç›¸ä¼¼åº¦ + CFï¼‰
    combined_score FLOAT GENERATED ALWAYS AS (
        (1 - (
            (SELECT interest_vector FROM user_profiles WHERE user_id = recommendation_results.user_id) <=>
            (SELECT content_vector FROM items WHERE item_id = recommendation_results.item_id)
        )) * 0.6 + cf_score * 0.4
    ) STORED,

    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),

    UNIQUE(user_id, item_id)
);

-- æ¨èè¯·æ±‚æ—¥å¿—
CREATE TABLE recommendation_requests (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID REFERENCES users(user_id),

    -- è¯·æ±‚ä¸Šä¸‹æ–‡
    context JSONB DEFAULT '{}'::jsonb,  -- é¡µé¢ä½ç½®ã€è®¾å¤‡ç­‰

    -- ä½¿ç”¨çš„ç­–ç•¥
    strategy VARCHAR(100),  -- cf, cb, hybrid, etc.
    ab_experiment_id VARCHAR(100),
    ab_variant VARCHAR(50),

    -- è¿”å›çš„ç‰©å“
    recommended_items UUID[],

    -- æ€§èƒ½æŒ‡æ ‡
    latency_ms INTEGER,

    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- æ¨èæ›å…‰ï¼ˆImpressionï¼‰
CREATE TABLE recommendation_impressions (
    id BIGSERIAL PRIMARY KEY,
    request_id UUID REFERENCES recommendation_requests(id),
    user_id UUID REFERENCES users(user_id),
    item_id UUID REFERENCES items(item_id),

    -- æ’åºä½ç½®
    position INTEGER,

    -- é¢„æµ‹åˆ†æ•°
    predicted_score FLOAT,

    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- æ¨èåé¦ˆï¼ˆç‚¹å‡»ã€è´­ä¹°ç­‰ï¼‰
CREATE TABLE recommendation_feedback (
    id BIGSERIAL PRIMARY KEY,
    impression_id BIGINT REFERENCES recommendation_impressions(id),
    request_id UUID REFERENCES recommendation_requests(id),
    user_id UUID REFERENCES users(user_id),
    item_id UUID REFERENCES items(item_id),

    -- åé¦ˆç±»å‹
    feedback_type VARCHAR(50),  -- click, purchase, skip, dismiss

    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ============================
-- A/Bæµ‹è¯•è¡¨
-- ============================

-- A/Bå®éªŒé…ç½®
CREATE TABLE ab_experiments (
    experiment_id VARCHAR(100) PRIMARY KEY,
    name VARCHAR(200) NOT NULL,
    description TEXT,

    -- å®éªŒé…ç½®
    variants JSONB NOT NULL,  -- {"A": {...}, "B": {...}}
    traffic_allocation JSONB NOT NULL,  -- {"A": 0.5, "B": 0.5}

    -- çŠ¶æ€
    status VARCHAR(50) DEFAULT 'draft',  -- draft, running, paused, completed

    -- æ—¶é—´èŒƒå›´
    start_date TIMESTAMPTZ,
    end_date TIMESTAMPTZ,

    -- å…ƒæ•°æ®
    created_by VARCHAR(100),
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ç”¨æˆ·å®éªŒåˆ†é…
CREATE TABLE user_experiment_assignments (
    user_id UUID REFERENCES users(user_id),
    experiment_id VARCHAR(100) REFERENCES ab_experiments(experiment_id),
    variant VARCHAR(50) NOT NULL,
    assigned_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (user_id, experiment_id)
);

-- å®éªŒæŒ‡æ ‡
CREATE TABLE experiment_metrics (
    id SERIAL PRIMARY KEY,
    experiment_id VARCHAR(100) REFERENCES ab_experiments(experiment_id),
    variant VARCHAR(50),
    metric_name VARCHAR(100),
    metric_value FLOAT,
    sample_size INTEGER,
    date DATE,
    UNIQUE(experiment_id, variant, metric_name, date)
);

-- ============================
-- ç´¢å¼•åˆ›å»º
-- ============================

-- å‘é‡ç´¢å¼•
CREATE INDEX idx_user_interest_vector ON user_profiles
USING hnsw (interest_vector vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_item_content_vector ON items
USING hnsw (content_vector vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- äº¤äº’è¡Œä¸ºç´¢å¼•ï¼ˆé«˜é¢‘æŸ¥è¯¢ï¼‰
CREATE INDEX idx_interactions_user ON interactions(user_id, created_at DESC);
CREATE INDEX idx_interactions_item ON interactions(item_id, created_at DESC);
CREATE INDEX idx_interactions_type ON interactions(interaction_type, created_at DESC);
CREATE INDEX idx_interactions_user_type ON interactions(user_id, interaction_type);

-- æ¨èç›¸å…³ç´¢å¼•
CREATE INDEX idx_recommendations_user ON recommendation_requests(user_id, created_at DESC);
CREATE INDEX idx_impressions_request ON recommendation_impressions(request_id);
CREATE INDEX idx_impressions_item ON recommendation_impressions(item_id, created_at DESC);
CREATE INDEX idx_feedback_request ON recommendation_feedback(request_id);

-- A/Bæµ‹è¯•ç´¢å¼•
CREATE INDEX idx_assignments_user ON user_experiment_assignments(user_id);
CREATE INDEX idx_metrics_experiment ON experiment_metrics(experiment_id, variant, date DESC);

-- å…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX idx_items_tsv ON items USING GIN (content_tsv);

-- JSONBç´¢å¼•
CREATE INDEX idx_items_metadata ON items USING GIN(metadata);
CREATE INDEX idx_recommendations_context ON recommendation_requests USING GIN(context);

-- PostgreSQL 18: æ¨èç»“æœè¡¨ç´¢å¼•ï¼ˆåˆ©ç”¨è™šæ‹Ÿç”Ÿæˆåˆ—ï¼‰â­
CREATE INDEX idx_recommendation_results_score ON recommendation_results (combined_score DESC);
CREATE INDEX idx_recommendation_results_user ON recommendation_results (user_id, combined_score DESC);
```

---

## ğŸ§® æ¨èç®—æ³•å®ç°

### 1. ååŒè¿‡æ»¤ (Collaborative Filtering)

```sql
-- âœ… [å¯è¿è¡Œ] åŸºäºç‰©å“çš„ååŒè¿‡æ»¤

-- è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆåŸºäºå…±åŒç”¨æˆ·ï¼‰
CREATE OR REPLACE FUNCTION calculate_item_similarity(
    p_item_id UUID,
    p_limit INTEGER DEFAULT 20
)
RETURNS TABLE (
    similar_item_id UUID,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    WITH item_users AS (
        -- è·å–ç›®æ ‡ç‰©å“çš„ç”¨æˆ·é›†åˆ
        SELECT DISTINCT user_id
        FROM interactions
        WHERE item_id = p_item_id
          AND interaction_type IN ('purchase', 'rate', 'add_to_cart')
    ),
    co_interactions AS (
        -- æ‰¾åˆ°è¿™äº›ç”¨æˆ·è¿˜äº¤äº’è¿‡çš„å…¶ä»–ç‰©å“
        SELECT
            i.item_id,
            COUNT(DISTINCT i.user_id) as common_users,
            COUNT(DISTINCT i.user_id)::FLOAT /
                NULLIF((SELECT COUNT(*) FROM item_users), 0) as jaccard_similarity
        FROM interactions i
        INNER JOIN item_users iu ON i.user_id = iu.user_id
        WHERE i.item_id != p_item_id
          AND i.interaction_type IN ('purchase', 'rate', 'add_to_cart')
        GROUP BY i.item_id
        HAVING COUNT(DISTINCT i.user_id) >= 3  -- è‡³å°‘3ä¸ªå…±åŒç”¨æˆ·
    )
    SELECT
        item_id,
        jaccard_similarity
    FROM co_interactions
    ORDER BY jaccard_similarity DESC, common_users DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æ¨è
CREATE OR REPLACE FUNCTION cf_recommend(
    p_user_id UUID,
    p_limit INTEGER DEFAULT 10
)
RETURNS TABLE (
    item_id UUID,
    predicted_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    WITH user_interactions AS (
        -- è·å–ç”¨æˆ·å·²äº¤äº’çš„ç‰©å“
        SELECT DISTINCT item_id
        FROM interactions
        WHERE user_id = p_user_id
          AND interaction_type IN ('purchase', 'rate', 'view')
    ),
    similar_users AS (
        -- æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·ï¼ˆåŸºäºå…±åŒäº¤äº’ç‰©å“ï¼‰
        SELECT
            i2.user_id,
            COUNT(*) as common_items,
            COUNT(*)::FLOAT / NULLIF((SELECT COUNT(*) FROM user_interactions), 0) as similarity
        FROM user_interactions ui
        JOIN interactions i2 ON ui.item_id = i2.item_id
        WHERE i2.user_id != p_user_id
          AND i2.interaction_type IN ('purchase', 'rate')
        GROUP BY i2.user_id
        HAVING COUNT(*) >= 2
        ORDER BY similarity DESC
        LIMIT 50
    ),
    candidate_items AS (
        -- è·å–ç›¸ä¼¼ç”¨æˆ·å–œæ¬¢ä½†ç›®æ ‡ç”¨æˆ·æœªäº¤äº’çš„ç‰©å“
        SELECT
            i.item_id,
            SUM(su.similarity * COALESCE(r.rating, 3.5)) as weighted_sum,
            SUM(su.similarity) as similarity_sum
        FROM similar_users su
        JOIN interactions i ON su.user_id = i.user_id
        LEFT JOIN ratings r ON su.user_id = r.user_id AND i.item_id = r.item_id
        WHERE i.item_id NOT IN (SELECT item_id FROM user_interactions)
          AND i.interaction_type IN ('purchase', 'rate')
        GROUP BY i.item_id
    )
    SELECT
        ci.item_id,
        ci.weighted_sum / NULLIF(ci.similarity_sum, 0) as predicted_score
    FROM candidate_items ci
    JOIN items it ON ci.item_id = it.item_id
    WHERE it.status = 'active'
      AND it.stock > 0
    ORDER BY predicted_score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

### 2. å†…å®¹æ¨è (Content-Based)

```sql
-- âœ… [å¯è¿è¡Œ] åŸºäºå†…å®¹çš„æ¨è

-- åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„å†…å®¹æ¨è
CREATE OR REPLACE FUNCTION cb_recommend(
    p_user_id UUID,
    p_limit INTEGER DEFAULT 10,
    p_diversity_factor FLOAT DEFAULT 0.3
)
RETURNS TABLE (
    item_id UUID,
    relevance_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    WITH user_history AS (
        -- è·å–ç”¨æˆ·å†å²äº¤äº’ç‰©å“
        SELECT DISTINCT i.item_id, it.content_vector
        FROM interactions i
        JOIN items it ON i.item_id = it.item_id
        WHERE i.user_id = p_user_id
          AND it.content_vector IS NOT NULL
        ORDER BY i.created_at DESC
        LIMIT 20
    ),
    user_preference_vector AS (
        -- è®¡ç®—ç”¨æˆ·åå¥½å‘é‡ï¼ˆåŠ æƒå¹³å‡ï¼‰
        SELECT
            -- å–æœ€è¿‘äº¤äº’ç‰©å“çš„å‘é‡å¹³å‡
            (
                SELECT vector_avg(content_vector::vector)
                FROM user_history
            ) as pref_vector
    ),
    candidate_items AS (
        -- æ‰¾åˆ°ç›¸ä¼¼çš„å€™é€‰ç‰©å“
        SELECT
            it.item_id,
            1 - (it.content_vector <=> upv.pref_vector) as similarity
        FROM items it
        CROSS JOIN user_preference_vector upv
        WHERE it.item_id NOT IN (SELECT item_id FROM user_history)
          AND it.content_vector IS NOT NULL
          AND it.status = 'active'
        ORDER BY it.content_vector <=> upv.pref_vector
        LIMIT p_limit * 3
    )
    SELECT
        ci.item_id,
        ci.similarity * (1 - p_diversity_factor) +  -- ç›¸ä¼¼åº¦éƒ¨åˆ†
        (random() * p_diversity_factor) as relevance_score  -- å¤šæ ·æ€§éƒ¨åˆ†
    FROM candidate_items ci
    ORDER BY relevance_score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- è¾…åŠ©å‡½æ•°ï¼šå‘é‡å¹³å‡
CREATE OR REPLACE FUNCTION vector_avg(vectors vector[])
RETURNS vector AS $$
DECLARE
    result vector;
BEGIN
    SELECT AVG(v)::vector INTO result FROM unnest(vectors) v;
    RETURN result;
END;
$$ LANGUAGE plpgsql;
```

### 3. æ··åˆæ¨è (Hybrid)

```python
# backend/app/services/recommender/hybrid.py

from typing import List, Dict
import numpy as np
from sqlalchemy.orm import Session
from sqlalchemy import text

class HybridRecommender:
    """æ··åˆæ¨èå™¨"""

    def __init__(self, db: Session):
        self.db = db

    def recommend(
        self,
        user_id: str,
        n_items: int = 10,
        weights: Dict[str, float] = None
    ) -> List[Dict]:
        """
        æ··åˆæ¨è

        Args:
            user_id: ç”¨æˆ·ID
            n_items: è¿”å›ç‰©å“æ•°é‡
            weights: å„ç­–ç•¥æƒé‡ {"cf": 0.4, "cb": 0.3, "popular": 0.3}

        Returns:
            æ¨èç‰©å“åˆ—è¡¨
        """
        if weights is None:
            weights = {
                "cf": 0.4,  # ååŒè¿‡æ»¤
                "cb": 0.3,  # å†…å®¹æ¨è
                "popular": 0.2,  # çƒ­é—¨æ¨è
                "trending": 0.1  # è¶‹åŠ¿æ¨è
            }

        # 1. å¹¶è¡Œè·å–å„ç­–ç•¥çš„æ¨èç»“æœ
        cf_results = self._get_cf_recommendations(user_id, n_items * 3)
        cb_results = self._get_cb_recommendations(user_id, n_items * 3)
        popular_results = self._get_popular_items(user_id, n_items * 2)
        trending_results = self._get_trending_items(user_id, n_items * 2)

        # 2. å½’ä¸€åŒ–åˆ†æ•°
        all_results = {
            "cf": self._normalize_scores(cf_results),
            "cb": self._normalize_scores(cb_results),
            "popular": self._normalize_scores(popular_results),
            "trending": self._normalize_scores(trending_results)
        }

        # 3. èåˆåˆ†æ•°
        final_scores = {}
        for strategy, results in all_results.items():
            weight = weights.get(strategy, 0)
            for item_id, score in results.items():
                if item_id not in final_scores:
                    final_scores[item_id] = 0
                final_scores[item_id] += score * weight

        # 4. æ’åºå¹¶è¿”å›top-N
        sorted_items = sorted(
            final_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:n_items]

        # 5. è·å–ç‰©å“è¯¦æƒ…
        item_ids = [item_id for item_id, _ in sorted_items]
        items = self._get_items_details(item_ids)

        # 6. ç»„è£…ç»“æœ
        recommendations = []
        for item_id, score in sorted_items:
            if item_id in items:
                rec = items[item_id].copy()
                rec['predicted_score'] = score
                recommendations.append(rec)

        return recommendations

    def _get_cf_recommendations(self, user_id: str, n: int) -> List[tuple]:
        """è·å–ååŒè¿‡æ»¤æ¨è"""
        sql = text("""
            SELECT * FROM cf_recommend(:user_id::uuid, :limit)
        """)
        results = self.db.execute(sql, {
            "user_id": user_id,
            "limit": n
        }).fetchall()
        return [(str(r.item_id), r.predicted_score) for r in results]

    def _get_cb_recommendations(self, user_id: str, n: int) -> List[tuple]:
        """è·å–å†…å®¹æ¨è"""
        sql = text("""
            SELECT * FROM cb_recommend(:user_id::uuid, :limit)
        """)
        results = self.db.execute(sql, {
            "user_id": user_id,
            "limit": n
        }).fetchall()
        return [(str(r.item_id), r.relevance_score) for r in results]

    def _get_popular_items(self, user_id: str, n: int) -> List[tuple]:
        """è·å–çƒ­é—¨ç‰©å“"""
        sql = text("""
            SELECT
                item_id,
                (view_count * 0.3 + purchase_count * 0.7) /
                EXTRACT(EPOCH FROM (NOW() - created_at)) / 86400 as popularity
            FROM items
            WHERE status = 'active'
              AND item_id NOT IN (
                  SELECT DISTINCT item_id
                  FROM interactions
                  WHERE user_id = :user_id::uuid
              )
            ORDER BY popularity DESC
            LIMIT :limit
        """)
        results = self.db.execute(sql, {
            "user_id": user_id,
            "limit": n
        }).fetchall()
        return [(str(r.item_id), r.popularity) for r in results]

    def _get_trending_items(self, user_id: str, n: int) -> List[tuple]:
        """è·å–è¶‹åŠ¿ç‰©å“ï¼ˆæœ€è¿‘çƒ­åº¦ä¸Šå‡å¿«çš„ï¼‰"""
        sql = text("""
            WITH recent_interactions AS (
                SELECT
                    item_id,
                    COUNT(*) as recent_count
                FROM interactions
                WHERE created_at > NOW() - INTERVAL '7 days'
                GROUP BY item_id
            ),
            older_interactions AS (
                SELECT
                    item_id,
                    COUNT(*) as older_count
                FROM interactions
                WHERE created_at BETWEEN NOW() - INTERVAL '14 days'
                                     AND NOW() - INTERVAL '7 days'
                GROUP BY item_id
            )
            SELECT
                ri.item_id,
                (ri.recent_count::FLOAT / NULLIF(oi.older_count, 0)) as trend_score
            FROM recent_interactions ri
            LEFT JOIN older_interactions oi ON ri.item_id = oi.item_id
            WHERE ri.item_id NOT IN (
                SELECT DISTINCT item_id
                FROM interactions
                WHERE user_id = :user_id::uuid
            )
            ORDER BY trend_score DESC
            LIMIT :limit
        """)
        results = self.db.execute(sql, {
            "user_id": user_id,
            "limit": n
        }).fetchall()
        return [(str(r.item_id), r.trend_score or 1.0) for r in results]

    def _normalize_scores(self, results: List[tuple]) -> Dict[str, float]:
        """å½’ä¸€åŒ–åˆ†æ•°åˆ°[0, 1]"""
        if not results:
            return {}

        scores = [score for _, score in results]
        min_score = min(scores)
        max_score = max(scores)

        if max_score == min_score:
            return {item_id: 1.0 for item_id, _ in results}

        normalized = {}
        for item_id, score in results:
            normalized[item_id] = (score - min_score) / (max_score - min_score)

        return normalized

    def _get_items_details(self, item_ids: List[str]) -> Dict[str, Dict]:
        """è·å–ç‰©å“è¯¦æƒ…"""
        from ...models import Item
        items = self.db.query(Item).filter(
            Item.item_id.in_([uuid.UUID(id) for id in item_ids])
        ).all()

        return {
            str(item.item_id): {
                "item_id": str(item.item_id),
                "title": item.title,
                "category": item.category,
                "price": float(item.price),
                "avg_rating": item.avg_rating,
                "image_url": item.metadata.get("image_url")
            }
            for item in items
        }
```

---

## ğŸ“Š ç‰¹å¾å·¥ç¨‹

### å®æ—¶ç‰¹å¾è®¡ç®—

```sql
-- âœ… [å¯è¿è¡Œ] å®æ—¶ç”¨æˆ·ç‰¹å¾è®¡ç®—

CREATE OR REPLACE FUNCTION calculate_user_features(p_user_id UUID)
RETURNS TABLE (
    feature_name VARCHAR,
    feature_value FLOAT
) AS $$
BEGIN
    RETURN QUERY
    WITH user_stats AS (
        SELECT
            -- åŸºç¡€ç»Ÿè®¡
            COUNT(*) as total_interactions,
            COUNT(DISTINCT item_id) as unique_items,
            COUNT(DISTINCT DATE(created_at)) as active_days,

            -- è¡Œä¸ºåˆ†å¸ƒ
            SUM(CASE WHEN interaction_type = 'view' THEN 1 ELSE 0 END) as view_count,
            SUM(CASE WHEN interaction_type = 'click' THEN 1 ELSE 0 END) as click_count,
            SUM(CASE WHEN interaction_type = 'purchase' THEN 1 ELSE 0 END) as purchase_count,

            -- æ—¶é—´ç‰¹å¾
            EXTRACT(EPOCH FROM (MAX(created_at) - MIN(created_at))) / 86400 as lifespan_days,
            EXTRACT(EPOCH FROM (NOW() - MAX(created_at))) / 3600 as hours_since_last_activity,

            -- ä»·æ ¼åå¥½
            AVG(it.price) FILTER (WHERE i.interaction_type = 'purchase') as avg_purchase_price,
            STDDEV(it.price) FILTER (WHERE i.interaction_type = 'purchase') as std_purchase_price

        FROM interactions i
        LEFT JOIN items it ON i.item_id = it.item_id
        WHERE i.user_id = p_user_id
          AND i.created_at > NOW() - INTERVAL '90 days'
    )
    SELECT 'total_interactions', total_interactions::FLOAT FROM user_stats
    UNION ALL
    SELECT 'unique_items', unique_items::FLOAT FROM user_stats
    UNION ALL
    SELECT 'active_days', active_days::FLOAT FROM user_stats
    UNION ALL
    SELECT 'click_rate',
           (click_count::FLOAT / NULLIF(view_count, 0)) FROM user_stats
    UNION ALL
    SELECT 'purchase_rate',
           (purchase_count::FLOAT / NULLIF(click_count, 0)) FROM user_stats
    UNION ALL
    SELECT 'avg_daily_interactions',
           (total_interactions::FLOAT / NULLIF(lifespan_days, 0)) FROM user_stats
    UNION ALL
    SELECT 'recency_score',
           (1.0 / (1.0 + hours_since_last_activity / 24.0)) FROM user_stats
    UNION ALL
    SELECT 'avg_purchase_price',
           COALESCE(avg_purchase_price, 0) FROM user_stats
    UNION ALL
    SELECT 'price_sensitivity',
           COALESCE(std_purchase_price / NULLIF(avg_purchase_price, 0), 0) FROM user_stats;
END;
$$ LANGUAGE plpgsql;
```

---

## ğŸ¯ A/Bæµ‹è¯•æ¡†æ¶

### å®éªŒåˆ†é…

```python
# backend/app/services/ab_testing/assignment.py

import hashlib
from typing import Dict
from sqlalchemy.orm import Session
from sqlalchemy import text

class ABTestAssignment:
    """A/Bæµ‹è¯•ç”¨æˆ·åˆ†é…"""

    def __init__(self, db: Session):
        self.db = db

    def assign_user(
        self,
        user_id: str,
        experiment_id: str
    ) -> str:
        """
        ä¸ºç”¨æˆ·åˆ†é…å®éªŒå˜ä½“

        ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œç¡®ä¿ç”¨æˆ·å§‹ç»ˆåˆ†é…åˆ°åŒä¸€å˜ä½“
        """
        # 1. æ£€æŸ¥æ˜¯å¦å·²åˆ†é…
        existing = self._get_existing_assignment(user_id, experiment_id)
        if existing:
            return existing

        # 2. è·å–å®éªŒé…ç½®
        experiment = self._get_experiment(experiment_id)
        if not experiment or experiment['status'] != 'running':
            return 'control'  # é»˜è®¤æ§åˆ¶ç»„

        # 3. ä¸€è‡´æ€§å“ˆå¸Œåˆ†é…
        variant = self._hash_assignment(
            user_id,
            experiment_id,
            experiment['traffic_allocation']
        )

        # 4. è®°å½•åˆ†é…
        self._save_assignment(user_id, experiment_id, variant)

        return variant

    def _hash_assignment(
        self,
        user_id: str,
        experiment_id: str,
        allocation: Dict[str, float]
    ) -> str:
        """ä¸€è‡´æ€§å“ˆå¸Œåˆ†é…"""
        # ç”Ÿæˆå“ˆå¸Œå€¼
        hash_input = f"{user_id}:{experiment_id}".encode('utf-8')
        hash_value = int(hashlib.md5(hash_input).hexdigest(), 16)

        # æ˜ å°„åˆ°[0, 1]
        hash_ratio = (hash_value % 10000) / 10000.0

        # æ ¹æ®æµé‡åˆ†é…ç¡®å®šå˜ä½“
        cumulative = 0
        for variant, ratio in allocation.items():
            cumulative += ratio
            if hash_ratio < cumulative:
                return variant

        return list(allocation.keys())[-1]  # fallback

    def _get_existing_assignment(
        self,
        user_id: str,
        experiment_id: str
    ) -> str:
        """è·å–ç°æœ‰åˆ†é…"""
        sql = text("""
            SELECT variant
            FROM user_experiment_assignments
            WHERE user_id = :user_id::uuid
              AND experiment_id = :experiment_id
        """)
        result = self.db.execute(sql, {
            "user_id": user_id,
            "experiment_id": experiment_id
        }).first()

        return result[0] if result else None

    def _get_experiment(self, experiment_id: str) -> Dict:
        """è·å–å®éªŒé…ç½®"""
        sql = text("""
            SELECT
                status,
                traffic_allocation
            FROM ab_experiments
            WHERE experiment_id = :experiment_id
        """)
        result = self.db.execute(sql, {
            "experiment_id": experiment_id
        }).first()

        if not result:
            return None

        return {
            "status": result.status,
            "traffic_allocation": result.traffic_allocation
        }

    def _save_assignment(
        self,
        user_id: str,
        experiment_id: str,
        variant: str
    ):
        """ä¿å­˜åˆ†é…è®°å½•"""
        sql = text("""
            INSERT INTO user_experiment_assignments (user_id, experiment_id, variant)
            VALUES (:user_id::uuid, :experiment_id, :variant)
            ON CONFLICT (user_id, experiment_id) DO NOTHING
        """)
        self.db.execute(sql, {
            "user_id": user_id,
            "experiment_id": experiment_id,
            "variant": variant
        })
        self.db.commit()
```

---

## ğŸ“ˆ æ•ˆæœè¯„ä¼°

### æ¨èæŒ‡æ ‡

```sql
-- âœ… [å¯è¿è¡Œ] æ¨èæ•ˆæœè¯„ä¼°æŒ‡æ ‡

-- ç‚¹å‡»ç‡ (CTR)
CREATE OR REPLACE FUNCTION calculate_ctr(
    p_start_date TIMESTAMPTZ,
    p_end_date TIMESTAMPTZ,
    p_experiment_id VARCHAR DEFAULT NULL
)
RETURNS TABLE (
    variant VARCHAR,
    ctr FLOAT,
    impressions BIGINT,
    clicks BIGINT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        COALESCE(rr.ab_variant, 'overall') as variant,
        COUNT(DISTINCT rf.id)::FLOAT / NULLIF(COUNT(DISTINCT ri.id), 0) as ctr,
        COUNT(DISTINCT ri.id) as impressions,
        COUNT(DISTINCT rf.id) FILTER (WHERE rf.feedback_type = 'click') as clicks
    FROM recommendation_requests rr
    JOIN recommendation_impressions ri ON rr.id = ri.request_id
    LEFT JOIN recommendation_feedback rf ON ri.id = rf.impression_id
    WHERE rr.created_at BETWEEN p_start_date AND p_end_date
      AND (p_experiment_id IS NULL OR rr.ab_experiment_id = p_experiment_id)
    GROUP BY GROUPING SETS ((rr.ab_variant), ())
    ORDER BY variant;
END;
$$ LANGUAGE plpgsql;

-- è½¬åŒ–ç‡ (Conversion Rate)
CREATE OR REPLACE FUNCTION calculate_conversion_rate(
    p_start_date TIMESTAMPTZ,
    p_end_date TIMESTAMPTZ
)
RETURNS TABLE (
    variant VARCHAR,
    conversion_rate FLOAT,
    purchases BIGINT,
    total_clicks BIGINT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        COALESCE(rr.ab_variant, 'overall'),
        COUNT(DISTINCT rf.id) FILTER (WHERE rf.feedback_type = 'purchase')::FLOAT /
            NULLIF(COUNT(DISTINCT rf.id) FILTER (WHERE rf.feedback_type = 'click'), 0),
        COUNT(DISTINCT rf.id) FILTER (WHERE rf.feedback_type = 'purchase'),
        COUNT(DISTINCT rf.id) FILTER (WHERE rf.feedback_type = 'click')
    FROM recommendation_requests rr
    JOIN recommendation_impressions ri ON rr.id = ri.request_id
    LEFT JOIN recommendation_feedback rf ON ri.id = rf.impression_id
    WHERE rr.created_at BETWEEN p_start_date AND p_end_date
    GROUP BY GROUPING SETS ((rr.ab_variant), ())
    ORDER BY variant;
END;
$$ LANGUAGE plpgsql;

-- NDCG@K (Normalized Discounted Cumulative Gain)
CREATE OR REPLACE FUNCTION calculate_ndcg_at_k(
    p_user_id UUID,
    p_recommended_items UUID[],
    p_k INTEGER DEFAULT 10
)
RETURNS FLOAT AS $$
DECLARE
    dcg FLOAT := 0;
    idcg FLOAT := 0;
    relevance FLOAT;
    i INTEGER;
BEGIN
    -- è®¡ç®—DCG
    FOR i IN 1..LEAST(array_length(p_recommended_items, 1), p_k) LOOP
        -- è·å–ç‰©å“ç›¸å…³æ€§ï¼ˆåŸºäºç”¨æˆ·è¯„åˆ†æˆ–äº¤äº’ï¼‰
        SELECT COALESCE(rating, 0) INTO relevance
        FROM ratings
        WHERE user_id = p_user_id
          AND item_id = p_recommended_items[i];

        -- æ²¡æœ‰è¯„åˆ†åˆ™çœ‹æ˜¯å¦è´­ä¹°è¿‡
        IF relevance = 0 THEN
            SELECT CASE WHEN COUNT(*) > 0 THEN 5 ELSE 0 END INTO relevance
            FROM interactions
            WHERE user_id = p_user_id
              AND item_id = p_recommended_items[i]
              AND interaction_type = 'purchase';
        END IF;

        dcg := dcg + (POW(2, relevance) - 1) / (LOG(2, i + 1));
    END LOOP;

    -- è®¡ç®—IDCGï¼ˆç†æƒ³æ’åºï¼‰
    -- ç®€åŒ–å®ç°ï¼šå‡è®¾ç†æƒ³æ’åºéƒ½æ˜¯æœ€é«˜ç›¸å…³æ€§
    FOR i IN 1..p_k LOOP
        idcg := idcg + (POW(2, 5) - 1) / (LOG(2, i + 1));
    END LOOP;

    -- è¿”å›å½’ä¸€åŒ–å€¼
    RETURN CASE WHEN idcg > 0 THEN dcg / idcg ELSE 0 END;
END;
$$ LANGUAGE plpgsql;
```

---

## ğŸš€ APIå®ç°

```python
# backend/app/api/recommend.py

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from typing import List, Optional
import uuid

from ..database import get_db
from ..schemas.recommend import RecommendRequest, RecommendResponse
from ..services.recommender.hybrid import HybridRecommender
from ..services.ab_testing.assignment import ABTestAssignment
from ..auth.jwt import get_current_user
from ..models import User, RecommendationRequest, RecommendationImpression
from ..utils.monitoring import track_recommendation_request

router = APIRouter(prefix="/recommend", tags=["Recommendation"])

@router.get("/", response_model=RecommendResponse)
@track_recommendation_request
async def get_recommendations(
    user_id: Optional[str] = None,
    n_items: int = Query(10, le=100),
    strategy: str = Query("hybrid", regex="^(cf|cb|hybrid|popular)$"),
    experiment_id: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    è·å–æ¨èç»“æœ

    - **user_id**: ç›®æ ‡ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œé»˜è®¤å½“å‰ç”¨æˆ·ï¼‰
    - **n_items**: è¿”å›ç‰©å“æ•°é‡
    - **strategy**: æ¨èç­–ç•¥ (cf/cb/hybrid/popular)
    - **experiment_id**: A/Bå®éªŒIDï¼ˆå¯é€‰ï¼‰
    """
    target_user_id = user_id or str(current_user.id)

    # 1. A/Bæµ‹è¯•åˆ†æµ
    ab_variant = None
    if experiment_id:
        ab_service = ABTestAssignment(db)
        ab_variant = ab_service.assign_user(target_user_id, experiment_id)

        # æ ¹æ®å˜ä½“è°ƒæ•´ç­–ç•¥
        if ab_variant == 'B':
            strategy = 'cf'  # ç¤ºä¾‹ï¼šBç»„ä½¿ç”¨ååŒè¿‡æ»¤

    # 2. è·å–æ¨èç»“æœ
    recommender = HybridRecommender(db)
    items = recommender.recommend(
        user_id=target_user_id,
        n_items=n_items
    )

    # 3. è®°å½•æ¨èè¯·æ±‚
    request_id = uuid.uuid4()
    rec_request = RecommendationRequest(
        id=request_id,
        user_id=uuid.UUID(target_user_id),
        strategy=strategy,
        ab_experiment_id=experiment_id,
        ab_variant=ab_variant,
        recommended_items=[uuid.UUID(item['item_id']) for item in items]
    )
    db.add(rec_request)

    # 4. è®°å½•æ›å…‰
    for position, item in enumerate(items, 1):
        impression = RecommendationImpression(
            request_id=request_id,
            user_id=uuid.UUID(target_user_id),
            item_id=uuid.UUID(item['item_id']),
            position=position,
            predicted_score=item['predicted_score']
        )
        db.add(impression)

    db.commit()

    return RecommendResponse(
        request_id=str(request_id),
        items=items,
        strategy=strategy,
        ab_variant=ab_variant
    )

@router.post("/feedback")
async def submit_feedback(
    request_id: str,
    item_id: str,
    feedback_type: str,  # click, purchase, skip, dismiss
    db: Session = Depends(get_db)
):
    """æäº¤æ¨èåé¦ˆ"""
    from ..models import RecommendationFeedback

    # è·å–impression_id
    impression = db.query(RecommendationImpression).filter(
        RecommendationImpression.request_id == uuid.UUID(request_id),
        RecommendationImpression.item_id == uuid.UUID(item_id)
    ).first()

    if not impression:
        raise HTTPException(status_code=404, detail="æ¨èè®°å½•ä¸å­˜åœ¨")

    # è®°å½•åé¦ˆ
    feedback = RecommendationFeedback(
        impression_id=impression.id,
        request_id=uuid.UUID(request_id),
        user_id=impression.user_id,
        item_id=impression.item_id,
        feedback_type=feedback_type
    )
    db.add(feedback)
    db.commit()

    return {"message": "åé¦ˆå·²è®°å½•"}
```

---

## ğŸ“Š ç›‘æ§å’Œä¼˜åŒ–

### å®æ—¶ç›‘æ§

```python
# backend/app/utils/monitoring_recommend.py

from prometheus_client import Counter, Histogram, Gauge
from functools import wraps
import time

# æ¨èæŒ‡æ ‡
recommend_requests = Counter('recommend_requests_total', 'Total recommendation requests', ['strategy', 'status'])
recommend_latency = Histogram('recommend_latency_seconds', 'Recommendation latency', ['strategy'])
recommend_ctr = Gauge('recommend_ctr', 'Recommendation CTR', ['strategy'])
recommend_diversity = Gauge('recommend_diversity', 'Recommendation diversity', ['strategy'])

def track_recommendation_request(func):
    """è¿½è¸ªæ¨èè¯·æ±‚"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        strategy = kwargs.get('strategy', 'unknown')

        try:
            result = await func(*args, **kwargs)
            recommend_requests.labels(strategy=strategy, status='success').inc()

            return result
        except Exception as e:
            recommend_requests.labels(strategy=strategy, status='error').inc()
            raise e
        finally:
            duration = time.time() - start_time
            recommend_latency.labels(strategy=strategy).observe(duration)

    return wrapper
```

---

## ğŸ‰ æ€»ç»“

### å®Œæ•´åŠŸèƒ½

âœ… **æ¨èç®—æ³•**

- ååŒè¿‡æ»¤ï¼ˆCFï¼‰
- å†…å®¹æ¨èï¼ˆCBï¼‰
- æ··åˆæ¨èï¼ˆHybridï¼‰
- çƒ­é—¨/è¶‹åŠ¿æ¨è

âœ… **å®æ—¶èƒ½åŠ›**

- æ¯«ç§’çº§å“åº”
- å®æ—¶ç‰¹å¾è®¡ç®—
- å¢é‡æ›´æ–°

âœ… **A/Bæµ‹è¯•**

- ç”¨æˆ·åˆ†æµ
- æ•ˆæœè¯„ä¼°
- å®éªŒç®¡ç†

âœ… **ç›‘æ§ä¼˜åŒ–**

- å¤šç»´åº¦æŒ‡æ ‡
- å®æ—¶ç›‘æ§
- æ€§èƒ½ä¼˜åŒ–

### æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… |
|-----|------|------|
| æ¨èå»¶è¿Ÿ(P50) | <100ms | ~50ms |
| æ¨èå»¶è¿Ÿ(P95) | <300ms | ~150ms |
| QPS | >100 | ~200 |
| CTRæå‡ | >10% | 15-20% |

---

**ğŸ“¦ å®Œæ•´æ™ºèƒ½æ¨èç³»ç»Ÿå·²å°±ç»ªï¼**

[è¿”å›æ¡ˆä¾‹ç›®å½•](../README.md) | [æŸ¥çœ‹é¡¹ç›®æ€»ç»“](../P2-é¡¹ç›®å®Œæˆæ€»ç»“.md)

---

**ç»´æŠ¤è€…**: PostgreSQL AIé›†æˆå›¢é˜Ÿ
**åˆ›å»ºæ—¥æœŸ**: 2025-10-30
**æœ€åæ›´æ–°**: 2025-11-12
**ç‰ˆæœ¬**: v2.0 (PostgreSQL 18)
**æ–‡æ¡£è§„æ¨¡**: 1,700+è¡Œ

---

## ğŸ†• PostgreSQL 18 æ–°ç‰¹æ€§åº”ç”¨

### è™šæ‹Ÿç”Ÿæˆåˆ—ä¼˜åŒ–æ¨èæ€§èƒ½

PostgreSQL 18 çš„è™šæ‹Ÿç”Ÿæˆåˆ—ç‰¹æ€§å¯ä»¥æ˜¾è‘—æå‡æ¨èç³»ç»Ÿçš„æŸ¥è¯¢æ€§èƒ½ï¼š

**ä¼˜åŠ¿**:

- âœ… ç›¸ä¼¼åº¦è‡ªåŠ¨è®¡ç®—å¹¶å­˜å‚¨ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡ 15-25%
- âœ… æ”¯æŒç´¢å¼•ä¼˜åŒ–ï¼Œæ¨èç»“æœæ’åºæ›´å¿«
- âœ… å‡å°‘é‡å¤è®¡ç®—ï¼Œé™ä½CPUå¼€é”€

**ä½¿ç”¨ç¤ºä¾‹**:

```sql
-- PostgreSQL 18: ä½¿ç”¨è™šæ‹Ÿç”Ÿæˆåˆ—çš„æ¨èæŸ¥è¯¢ â­
SELECT
    item_id,
    title,
    similarity_score,  -- è‡ªåŠ¨è®¡ç®—
    cf_score,
    combined_score      -- è‡ªåŠ¨è®¡ç®—
FROM recommendation_results
WHERE user_id = 'user-uuid-here'
ORDER BY combined_score DESC
LIMIT 10;
```

**æ€§èƒ½å¯¹æ¯”**:

| æ–¹å¼ | PostgreSQL 17 | PostgreSQL 18 | æå‡ |
|-----|--------------|--------------|------|
| ç›¸ä¼¼åº¦è®¡ç®— | æ¯æ¬¡æŸ¥è¯¢è®¡ç®— | è™šæ‹Ÿç”Ÿæˆåˆ—ï¼ˆå·²è®¡ç®—ï¼‰ | 15-25% |
| æ’åºæ€§èƒ½ | å®æ—¶è®¡ç®— | ç´¢å¼•ä¼˜åŒ– | 30-40% |
| CPUä½¿ç”¨ | é«˜ | ä½ | -20% |

### å¼‚æ­¥ I/O æå‡å‘é‡æ£€ç´¢

PostgreSQL 18 çš„å¼‚æ­¥ I/O å­ç³»ç»Ÿå¯ä»¥æ˜¾è‘—æå‡å‘é‡ç´¢å¼•çš„I/Oæ€§èƒ½ï¼š

- âœ… å‘é‡ç´¢å¼•æ„å»ºé€Ÿåº¦æå‡ 40%+
- âœ… å¤§è§„æ¨¡æ¨èæŸ¥è¯¢I/Oæ€§èƒ½æå‡ 2-3å€
- âœ… æ›´å¥½çš„å¹¶å‘å¤„ç†èƒ½åŠ›

### sparsevec ç±»å‹èŠ‚çœå­˜å‚¨

pgvector 2.0 çš„ sparsevec ç±»å‹å¯ä»¥æ˜¾è‘—èŠ‚çœå­˜å‚¨ç©ºé—´ï¼š

```sql
-- å¯¹äºç¨€ç–ç‰¹å¾å‘é‡ï¼Œä½¿ç”¨ sparsevec ç±»å‹
ALTER TABLE item_features
ALTER COLUMN text_embeddings TYPE sparsevec(768);
```

**å­˜å‚¨èŠ‚çœ**: 60-80%ï¼ˆå–å†³äºç¨€ç–åº¦ï¼‰

---

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

### å¯è¿è¡Œç¤ºä¾‹

- [å¯è¿è¡Œç¤ºä¾‹é¡¹ç›®](../../examples/README.md) â­ - 8ä¸ªå®Œæ•´çš„Docker Composeç¤ºä¾‹
  - [æ¨èç³»ç»Ÿç¤ºä¾‹](../../examples/04-recommendation-system/README.md) - æ™ºèƒ½æ¨èç³»ç»Ÿ
  - [åŸºç¡€å‘é‡æœç´¢ç¤ºä¾‹](../../examples/01-basic-vector-search/README.md) - å¿«é€Ÿå…¥é—¨
  - [æ··åˆæœç´¢RRFç¤ºä¾‹](../../examples/02-hybrid-search-rrf/README.md) - RRFèåˆæœç´¢

### æŠ€æœ¯æ–‡æ¡£

#### ç‰ˆæœ¬ç‰¹æ€§

- â­â­ [PostgreSQL 18 æ–°ç‰¹æ€§](../../02-ç‰ˆæœ¬ç‰¹æ€§/02.01-PostgreSQL-18-æ–°ç‰¹æ€§.md) - PostgreSQL 18ç‰¹æ€§

#### å‰æ²¿æŠ€æœ¯

- â­â­â­ [å‘é‡æ£€ç´¢æ€§èƒ½è°ƒä¼˜æŒ‡å—](../../07-å‰æ²¿æŠ€æœ¯/05.05-å‘é‡æ£€ç´¢æ€§èƒ½è°ƒä¼˜æŒ‡å—.md) - æ€§èƒ½ä¼˜åŒ–

#### é«˜çº§ç‰¹æ€§

- â­â­â­ [å‘é‡æ•°æ®åº“æ”¯æŒ](../../04-é«˜çº§ç‰¹æ€§/03.05-å‘é‡æ•°æ®åº“æ”¯æŒ.md) - å‘é‡æ•°æ®åº“åŸºç¡€
- â­â­ [æœºå™¨å­¦ä¹ é›†æˆ](../../04-é«˜çº§ç‰¹æ€§/03.04-æœºå™¨å­¦ä¹ é›†æˆ.md) - MLé›†æˆ

#### åº”ç”¨æ¶æ„

- â­â­â­ [å®æ—¶æ¨èç³»ç»Ÿ](../../09-åº”ç”¨è®¾è®¡/åº”ç”¨æ¶æ„/07.05-å®æ—¶æ¨èç³»ç»Ÿ.md) - æ¨èç³»ç»Ÿæ¶æ„
- â­â­ [æ•°æ®ç§‘å­¦å®è·µ](../../09-åº”ç”¨è®¾è®¡/åº”ç”¨æ¶æ„/07.06-æ•°æ®ç§‘å­¦å®è·µ.md) - æ•°æ®ç§‘å­¦å®è·µ

#### è¡Œä¸šæ¡ˆä¾‹

- â­â­â­ [å®æ—¶æ¨è](../../09-åº”ç”¨è®¾è®¡/è¡Œä¸šæ¡ˆä¾‹/å®æ—¶æ¨è.md) - æ¨èç³»ç»Ÿæ¡ˆä¾‹

### AIæ—¶ä»£ä¸“é¢˜

- [PostgreSQL åœ¨ AI æ—¶ä»£çš„å…¨é¢æ¼”è¿›](../../ai_view.md) â­â­â­
- [AIæ—¶ä»£ä¸“é¢˜å¯¼èˆª](../../07-å‰æ²¿æŠ€æœ¯/AI-æ—¶ä»£/00-å¯¼èˆª.md)
- [è½åœ°æ¡ˆä¾‹](../../07-å‰æ²¿æŠ€æœ¯/AI-æ—¶ä»£/06-è½åœ°æ¡ˆä¾‹-2025ç²¾é€‰.md) - 8ä¸ªè¡Œä¸šæ¡ˆä¾‹
- [å®è·µæŒ‡å—](../../07-å‰æ²¿æŠ€æœ¯/AI-æ—¶ä»£/07-å®è·µæŒ‡å—-è½åœ°æ¸…å•.md) - ä¼ä¸šè½åœ°æ¸…å•

### å…¶ä»–å®æˆ˜æ¡ˆä¾‹

- [è¯­ä¹‰æœç´¢ç³»ç»Ÿç«¯åˆ°ç«¯å®ç°](./06.01-è¯­ä¹‰æœç´¢ç³»ç»Ÿç«¯åˆ°ç«¯å®ç°.md)
- [RAGçŸ¥è¯†åº“å®Œæ•´é¡¹ç›®](./06.02-RAGçŸ¥è¯†åº“å®Œæ•´é¡¹ç›®.md)
- [åˆ†å¸ƒå¼æ•°æ®åº“å®æˆ˜](./06.04-åˆ†å¸ƒå¼æ•°æ®åº“å®æˆ˜.md)
