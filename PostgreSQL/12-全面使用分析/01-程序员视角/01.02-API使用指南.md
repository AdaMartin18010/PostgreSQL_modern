# PostgreSQL 18 API使用指南

> **版本**: v1.0
> **最后更新**: 2025-01-15
> **版本覆盖**: PostgreSQL 18.x (推荐) ⭐ | 17.x (推荐) | 16.x (兼容)
> **文档状态**: ✅ 已完成

---

## 📑 目录

- [PostgreSQL 18 API使用指南](#postgresql-18-api使用指南)
  - [📑 目录](#-目录)
  - [📊 思维导图](#-思维导图)
  - [一、概述](#一概述)
  - [二、知识矩阵对比](#二知识矩阵对比)
    - [2.1 连接管理方案对比](#21-连接管理方案对比)
    - [2.2 事务管理方案对比](#22-事务管理方案对比)
  - [三、连接管理](#三连接管理)
    - [3.1 连接参数](#31-连接参数)
      - [3.1.1 连接参数的作用与选择](#311-连接参数的作用与选择)
      - [理论基础：连接参数的设计原理](#理论基础连接参数的设计原理)
    - [为什么需要连接参数](#为什么需要连接参数)
      - [3.1.2 基本连接参数详解](#312-基本连接参数详解)
    - [参数分类与作用机制](#参数分类与作用机制)
    - [3.2 连接池](#32-连接池)
    - [连接池的理论基础](#连接池的理论基础)
    - [3.3 连接健康检查](#33-连接健康检查)
  - [四、事务管理](#四事务管理)
    - [4.1 事务基础](#41-事务基础)
    - [4.2 事务隔离级别](#42-事务隔离级别)
    - [4.3 保存点](#43-保存点)
    - [4.4 嵌套事务](#44-嵌套事务)
  - [五、查询执行](#五查询执行)
    - [5.1 简单查询](#51-简单查询)
    - [5.2 预处理语句](#52-预处理语句)
    - [5.3 批量操作](#53-批量操作)
    - [5.4 游标操作](#54-游标操作)
  - [六、异步操作](#六异步操作)
    - [6.1 异步I/O](#61-异步io)
    - [6.2 并行查询](#62-并行查询)
    - [6.3 异步连接](#63-异步连接)
  - [七、数据类型处理](#七数据类型处理)
    - [7.1 基本类型](#71-基本类型)
    - [7.2 复合类型](#72-复合类型)
    - [7.3 JSON/JSONB](#73-jsonjsonb)
    - [7.4 数组类型](#74-数组类型)
  - [八、错误处理](#八错误处理)
    - [8.1 错误码](#81-错误码)
    - [8.2 异常处理](#82-异常处理)
    - [8.3 重试机制](#83-重试机制)
  - [九、性能优化](#九性能优化)
    - [9.1 连接优化](#91-连接优化)
    - [9.2 查询优化](#92-查询优化)
    - [9.3 批量优化](#93-批量优化)
  - [十、相关文档](#十相关文档)

---

## 📊 思维导图

```mermaid
mindmap
  root((API使用指南))
    连接管理
      连接参数
      连接池
      健康检查
    事务管理
      事务基础
      隔离级别
      保存点
      嵌套事务
    查询执行
      简单查询
      预处理语句
      批量操作
      游标
    异步操作
      异步I/O
      并行查询
      异步连接
    数据类型
      基本类型
      复合类型
      JSON/JSONB
      数组
    错误处理
      错误码
      异常处理
      重试机制
    性能优化
      连接优化
        连接池配置
        连接复用
      查询优化
        查询计划
        索引使用
      批量优化
        批量操作
        事务优化
```

**思维导图说明**：

本思维导图展示了PostgreSQL API使用的完整知识体系，从基础的连接管理到高级的性能优化，每个模块都包含理论基础、实践方法和最佳实践。通过这个思维导图，可以快速了解API使用的全貌，并根据具体需求深入相关章节。

**使用建议**：

- **初学者**：从连接管理和事务管理开始，理解基础概念
- **进阶者**：关注查询执行和性能优化，提升应用性能
- **高级用户**：深入研究异步操作和错误处理，构建高可用系统

---

## 一、概述

PostgreSQL提供了丰富的API接口，支持多种编程语言和连接方式。本文档从程序员视角详细介绍PostgreSQL API的使用方法、最佳实践和性能优化技巧。

**文档设计理念**：

本文档不仅提供代码示例，更重要的是解释**为什么**这样做，**如何**选择最佳方案，以及**何时**使用特定技术。每个概念都包含：

1. **理论基础**：解释概念的本质和设计原理
2. **实践方法**：提供可运行的代码示例
3. **分析论证**：说明不同方案的优劣和适用场景
4. **最佳实践**：总结实际项目中的经验教训

**核心特点**：

- **多语言支持**：支持多种编程语言（Python、Java、Node.js、Go等）
  - **设计原理**：PostgreSQL使用标准协议（PostgreSQL Protocol），任何支持该协议的客户端都可以连接
  - **实践意义**：可以选择最适合项目技术栈的客户端库
  - **性能考虑**：不同客户端库的性能差异，通常原生C库（如psycopg2）性能最好

- **标准协议**：使用标准PostgreSQL协议
  - **理论依据**：标准协议确保跨平台和跨语言的兼容性
  - **实践价值**：可以使用任何支持PostgreSQL协议的客户端工具

- **高性能**：支持连接池、预处理语句、批量操作
  - **优化原理**：减少网络往返、减少数据库负载、利用并行处理
  - **性能提升**：批量操作可以提升性能10-1000倍，连接池可以提升10-100倍

- **异步支持**：PostgreSQL 18增强异步I/O支持
  - **理论基础**：异步I/O可以充分利用I/O等待时间
  - **性能提升**：I/O操作性能提升2-3倍

**PostgreSQL 18 新特性支持**：

- ✅ **异步I/O增强**：更高效的异步操作支持
- ✅ **连接性能优化**：改进的连接管理性能
- ✅ **并行查询增强**：更好的并行查询支持
- ✅ **JSONB性能提升**：更快的JSONB操作

---

## 二、知识矩阵对比

### 2.1 连接管理方案对比

| 方案 | 特点 | 适用场景 | 性能 | 复杂度 | 推荐度 |
|-----|------|---------|------|--------|--------|
| **直接连接** | 简单直接 | 单次操作、脚本 | ⭐⭐ | ⭐ | ⭐⭐ |
| **连接池** | 复用连接 | Web应用、高并发 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **持久连接** | 长连接 | 后台服务、批处理 | ⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| **异步连接** | 非阻塞 | 高并发、实时应用 | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |

### 2.2 事务管理方案对比

| 方案 | 特点 | 适用场景 | 性能 | 一致性 | 推荐度 |
|-----|------|---------|------|--------|--------|
| **自动提交** | 每条语句一个事务 | 简单查询 | ⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐ |
| **显式事务** | 手动控制事务边界 | 复杂操作 | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **保存点** | 部分回滚 | 复杂业务逻辑 | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **嵌套事务** | 事务嵌套 | 复杂场景 | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |

---

## 三、连接管理

### 3.1 连接参数

#### 3.1.1 连接参数的作用与选择

#### 理论基础：连接参数的设计原理

连接参数是应用程序与PostgreSQL数据库建立通信的桥梁。从系统架构角度看，连接参数需要解决以下核心问题：

1. **服务发现**：如何定位数据库服务器（网络层）
2. **身份认证**：如何验证应用的身份（安全层）
3. **会话配置**：如何设置会话级别的参数（应用层）
4. **资源管理**：如何管理连接资源（资源层）

### 为什么需要连接参数

连接参数决定了应用程序如何连接到PostgreSQL数据库，包括：

- **网络配置**：如何找到数据库服务器
- **认证信息**：如何验证身份
- **连接行为**：连接的超时、字符集等设置
- **性能配置**：连接池大小、缓存设置等

**连接参数的重要性分析**：

1. **安全性**：正确的认证参数保护数据安全
   - **理论依据**：最小权限原则（Principle of Least Privilege）
   - **实践意义**：使用专用数据库用户，避免使用超级用户
   - **风险分析**：错误的认证配置可能导致数据泄露或未授权访问

2. **性能**：合理的超时和连接池配置提升性能
   - **理论依据**：连接建立是昂贵的操作（TCP三次握手、SSL握手、认证）
   - **实践意义**：连接池复用连接，减少建立连接的开销
   - **性能数据**：建立新连接通常需要10-50ms，而复用连接仅需<1ms

3. **可靠性**：重试和故障转移参数保证连接稳定
   - **理论依据**：网络是不可靠的（网络分区、临时故障）
   - **实践意义**：合理的超时和重试机制提高系统可用性
   - **可用性影响**：正确的重试策略可以将连接成功率从95%提升到99.9%

4. **兼容性**：字符集和时区设置保证数据正确性
   - **理论依据**：字符编码和时区是数据完整性的基础
   - **实践意义**：错误的字符集会导致数据损坏，错误的时区会导致时间数据错误
   - **数据完整性**：UTF-8编码支持所有Unicode字符，UTC时区避免时区转换问题

#### 3.1.2 基本连接参数详解

### 参数分类与作用机制

连接参数可以按照功能分为以下几类：

| 参数类别 | 核心参数 | 作用机制 | 影响范围 |
|---------|---------|---------|---------|
| **网络参数** | host, port | TCP/IP连接建立 | 连接建立阶段 |
| **认证参数** | user, password, sslmode | 身份验证和加密 | 安全性和性能 |
| **会话参数** | timezone, client_encoding | 会话级别配置 | 数据正确性 |
| **性能参数** | connect_timeout, application_name | 连接行为和监控 | 性能和可观测性 |

**Python (psycopg2) 连接示例**：

以下示例展示了如何正确配置连接参数，每个参数都有其特定的作用和最佳实践：

```python
import psycopg2
from psycopg2 import pool

# 基本连接参数
# 说明：这个示例展示了生产环境推荐的最小连接参数配置
conn = psycopg2.connect(
    # 网络参数：指定数据库服务器位置
    host="localhost",        # 数据库主机地址
    port=5432,               # 数据库端口（默认5432）

    # 认证参数：验证身份
    database="mydb",         # 数据库名称
    user="myuser",           # 用户名
    password="mypassword",   # 密码（生产环境应使用环境变量或密钥管理）

    # 连接行为参数：控制连接特性
    connect_timeout=10,      # 连接超时（秒），防止长时间等待
    application_name="myapp", # 应用名称，用于监控和日志

    # 字符集和时区
    client_encoding="UTF8",  # 客户端字符集
    timezone="UTC",          # 时区设置

    # 连接选项：额外的连接参数
    options="-c statement_timeout=30000"  # 设置语句超时为30秒
)

# 参数说明：
# - host: 可以是IP地址或域名，支持IPv4和IPv6
# - port: PostgreSQL默认端口5432，可以自定义
# - database: 连接的目标数据库，连接后可以切换
# - user: 数据库用户名，必须有相应权限
# - password: 密码，建议使用环境变量或配置文件
# - connect_timeout: 连接超时，避免网络问题时长时间等待
# - application_name: 用于pg_stat_activity识别应用，便于监控
```

**连接参数的最佳实践**：

| 参数 | 推荐值 | 原因 | 注意事项 |
|-----|--------|------|---------|
| **connect_timeout** | 5-10秒 | 平衡响应速度和网络延迟 | 太短可能误判，太长影响用户体验 |
| **application_name** | 应用名称 | 便于监控和问题定位 | 使用有意义的名称 |
| **client_encoding** | UTF8 | 支持多语言字符 | 确保与应用字符集一致 |
| **timezone** | UTC | 避免时区问题 | 应用层处理时区转换 |

**安全连接配置**：

```python
# 场景：生产环境的安全连接配置
# 需求：使用SSL加密，密码从环境变量读取

import os
import psycopg2

# 从环境变量读取敏感信息
db_config = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 5432)),
    'database': os.getenv('DB_NAME'),
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASSWORD'),  # 从环境变量读取，不在代码中硬编码

    # SSL配置：生产环境应使用SSL
    'sslmode': 'require',  # 要求SSL连接
    # 'sslcert': '/path/to/client.crt',  # 客户端证书（可选）
    # 'sslkey': '/path/to/client.key',   # 客户端密钥（可选）
    # 'sslrootcert': '/path/to/ca.crt',  # CA证书（可选）

    # 连接池配置
    'connect_timeout': 10,
    'application_name': 'production_app'
}

conn = psycopg2.connect(**db_config)

# 安全最佳实践说明：
# 1. 密码使用环境变量或密钥管理服务（如AWS Secrets Manager、HashiCorp Vault）
#    理论依据：避免敏感信息泄露，支持密钥轮换
#    实践价值：提高安全性，符合安全合规要求
# 2. 生产环境必须使用SSL（sslmode=require或verify-full）
#    理论依据：防止中间人攻击，保护数据传输安全
#    性能影响：SSL握手增加10-50ms延迟，但安全性提升显著
# 3. 使用最小权限原则，为应用创建专用数据库用户
#    理论依据：最小权限原则（Principle of Least Privilege）
#    实践价值：降低安全风险，即使应用被攻击，影响范围也有限
# 4. 定期轮换密码和证书
#    理论依据：减少密钥泄露的风险窗口
#    实践建议：密码每90天轮换，证书每年轮换
```

**连接字符串方式**：

连接字符串（URI格式）是另一种配置连接的方式，具有简洁、易于管理的优势。

```python
# 使用连接字符串（URI格式）
# 优点：简洁、易于配置管理、适合环境变量
# 缺点：参数验证较少，错误提示不够明确
conn_string = "postgresql://user:password@localhost:5432/mydb?connect_timeout=10&application_name=my_app"
conn = psycopg2.connect(conn_string)

# 连接字符串格式说明：
# postgresql://[user[:password]@][host][:port][/database][?参数1=值1&参数2=值2]
#
# 参数对比分析：
# - 字典方式：类型安全、IDE支持、易于验证、推荐用于复杂配置
# - URI方式：简洁、易于配置、适合环境变量、推荐用于简单配置
```

**PostgreSQL 18 新特性应用**：

PostgreSQL 18引入了多项连接相关的改进，这些改进基于对现代应用需求的深入分析。

```python
# PostgreSQL 18: 支持更多连接参数和认证方式
conn = psycopg2.connect(
    host="localhost",
    database="mydb",
    user="myuser",
    password="mypassword",

    # 异步I/O支持（PostgreSQL 18新特性）
    # 说明：异步I/O可以显著提升I/O密集型操作的性能
    # 理论基础：异步I/O允许在等待I/O完成时处理其他请求
    # 性能提升：I/O操作性能提升2-3倍
    # 适用场景：大量小文件I/O、网络I/O、日志写入
    # 注意：需要驱动支持，psycopg3原生支持，psycopg2需要额外配置
    async_=True,  # 如果驱动支持

    # OAuth 2.0认证（PostgreSQL 18新特性）
    # 说明：支持现代认证方式，提高安全性
    # 理论基础：OAuth 2.0是业界标准的授权协议
    # 优势：无需在连接字符串中传递密码，支持令牌刷新
    # 适用场景：云原生应用、微服务架构、多租户系统
    # oauth_token="..."  # 从OAuth服务获取的访问令牌
)

# PostgreSQL 18连接性能对比分析：
# - 传统连接：建立连接10-50ms，查询延迟1-5ms
# - 异步I/O连接：建立连接5-20ms（提升50%），查询延迟0.5-2ms（提升60%）
# - OAuth认证：首次连接稍慢（需要获取令牌），后续连接更快（令牌缓存）
#
# 性能提升的理论依据：
# 1. 异步I/O减少等待时间，提高CPU利用率
# 2. 连接复用减少建立连接的开销
# 3. 令牌缓存减少认证开销
```

### 3.2 连接池

### 连接池的理论基础

连接池是数据库连接管理的重要模式，其核心思想是**资源复用**和**生命周期管理**。

**为什么需要连接池**：

1. **连接建立的成本分析**：
   - TCP三次握手：~1-3ms
   - SSL/TLS握手：~10-50ms（如果使用SSL）
   - PostgreSQL认证：~1-5ms
   - **总成本**：12-58ms，在高并发场景下会成为瓶颈

2. **资源限制问题**：
   - PostgreSQL默认最大连接数：100（可配置）
   - 每个连接消耗内存：~10MB
   - 100个连接 = 1GB内存
   - **问题**：如果每个请求都创建新连接，很快就会耗尽连接数

3. **连接池的优势**：
   - **性能提升**：复用连接，避免重复建立连接的开销
   - **资源控制**：限制最大连接数，防止资源耗尽
   - **连接管理**：自动处理连接的健康检查和故障恢复

**连接池的工作原理**：

```text
应用请求 → 连接池 → 检查可用连接
                ↓
         有可用连接？ → 是 → 返回连接
                ↓
              否
                ↓
         连接数<最大值？ → 是 → 创建新连接
                ↓
              否
                ↓
         等待或拒绝请求
```

**连接池参数选择的理论依据**：

| 参数 | 作用 | 选择原则 | 推荐值 |
|-----|------|---------|--------|
| **minconn** | 最小连接数 | 保证基本可用性 | 1-5 |
| **maxconn** | 最大连接数 | 平衡性能和资源 | 20-100 |
| **连接超时** | 获取连接的最大等待时间 | 避免长时间阻塞 | 5-10秒 |

**使用连接池库**：

```python
# Python: 使用psycopg2.pool
from psycopg2 import pool

# 创建连接池
# 说明：连接池应该在应用启动时创建，整个应用生命周期内复用
connection_pool = pool.SimpleConnectionPool(
    minconn=1,  # 最小连接数
    # 理论依据：保持至少1个连接，减少首次请求的延迟
    # 权衡：更多连接占用更多资源，但响应更快

    maxconn=20,  # 最大连接数
    # 理论依据：根据并发请求数和数据库服务器能力设置
    # 计算公式：maxconn = 预期并发请求数 × 平均请求处理时间 / 请求间隔
    # 示例：100 QPS，每个请求50ms → maxconn = 100 × 0.05 = 5（建议设置10-20作为缓冲）

    host="localhost",
    database="mydb",
    user="myuser",
    password="mypassword"
)

# 从连接池获取连接
# 说明：获取连接是阻塞操作，如果连接池已满，会等待直到有连接可用
conn = connection_pool.getconn()
# 注意：使用完连接后必须归还，否则会导致连接泄漏

try:
    # 使用连接
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM users")
    results = cursor.fetchall()
finally:
    # 归还连接到池
    connection_pool.putconn(conn)
```

**使用SQLAlchemy连接池**：

```python
# Python: 使用SQLAlchemy
from sqlalchemy import create_engine

engine = create_engine(
    "postgresql://user:password@localhost/mydb",
    pool_size=20,
    max_overflow=10,
    pool_timeout=30,
    pool_recycle=3600  # 1小时后回收连接
)

# 使用连接
with engine.connect() as conn:
    result = conn.execute("SELECT * FROM users")
```

### 3.3 连接健康检查

**健康检查实现**：

```python
import psycopg2
from psycopg2 import pool

def check_connection(conn):
    """检查连接是否健康"""
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        cursor.fetchone()
        return True
    except:
        return False

# 连接池健康检查
class HealthyConnectionPool:
    def __init__(self, *args, **kwargs):
        self.pool = pool.SimpleConnectionPool(*args, **kwargs)

    def getconn(self):
        conn = self.pool.getconn()
        if not check_connection(conn):
            # 连接不健康，关闭并获取新连接
            try:
                conn.close()
            except:
                pass
            conn = self.pool.getconn()
        return conn
```

---

## 四、事务管理

### 4.1 事务基础

**显式事务**：

```python
# Python: 显式事务
conn = psycopg2.connect(...)
try:
    # 开始事务（自动）
    cursor = conn.cursor()

    cursor.execute("INSERT INTO users (name) VALUES (%s)", ("Alice",))
    cursor.execute("INSERT INTO orders (user_id, amount) VALUES (%s, %s)", (1, 100))

    # 提交事务
    conn.commit()
except Exception as e:
    # 回滚事务
    conn.rollback()
    raise
finally:
    cursor.close()
    conn.close()
```

**上下文管理器**：

```python
# Python: 使用上下文管理器
with conn:
    with conn.cursor() as cursor:
        cursor.execute("INSERT INTO users (name) VALUES (%s)", ("Alice",))
        cursor.execute("INSERT INTO orders (user_id, amount) VALUES (%s, %s)", (1, 100))
        # 自动提交或回滚
```

### 4.2 事务隔离级别

**设置隔离级别**：

```python
# 设置隔离级别
conn = psycopg2.connect(...)
conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_READ_COMMITTED)

# 或在连接字符串中设置
conn = psycopg2.connect(
    "...",
    options="-c default_transaction_isolation='read committed'"
)
```

**隔离级别说明**：

| 隔离级别 | 脏读 | 不可重复读 | 幻读 | 性能 | 推荐度 |
|---------|------|-----------|------|------|--------|
| **READ UNCOMMITTED** | ❌ | ❌ | ❌ | ⭐⭐⭐⭐⭐ | ⭐ |
| **READ COMMITTED** | ✅ | ❌ | ❌ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **REPEATABLE READ** | ✅ | ✅ | ❌ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
| **SERIALIZABLE** | ✅ | ✅ | ✅ | ⭐⭐ | ⭐⭐⭐ |

### 4.3 保存点

**保存点使用**：

```python
# 使用保存点实现部分回滚
conn = psycopg2.connect(...)
cursor = conn.cursor()

try:
    cursor.execute("INSERT INTO users (name) VALUES (%s)", ("Alice",))

    # 创建保存点
    cursor.execute("SAVEPOINT sp1")

    try:
        cursor.execute("INSERT INTO orders (user_id, amount) VALUES (%s, %s)", (1, 100))
        # 如果这里出错，只回滚到保存点
    except:
        # 回滚到保存点
        cursor.execute("ROLLBACK TO SAVEPOINT sp1")
        raise

    # 释放保存点
    cursor.execute("RELEASE SAVEPOINT sp1")
    conn.commit()
except:
    conn.rollback()
```

### 4.4 嵌套事务

**嵌套事务模式**：

```python
# 使用保存点模拟嵌套事务
class NestedTransaction:
    def __init__(self, conn):
        self.conn = conn
        self.savepoint_counter = 0

    def __enter__(self):
        self.savepoint_counter += 1
        savepoint_name = f"sp_{self.savepoint_counter}"
        self.conn.cursor().execute(f"SAVEPOINT {savepoint_name}")
        self.savepoint_name = savepoint_name
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.conn.cursor().execute(f"ROLLBACK TO SAVEPOINT {self.savepoint_name}")
        else:
            self.conn.cursor().execute(f"RELEASE SAVEPOINT {self.savepoint_name}")

# 使用
with NestedTransaction(conn):
    cursor.execute("INSERT INTO users (name) VALUES (%s)", ("Alice",))
    with NestedTransaction(conn):
        cursor.execute("INSERT INTO orders (user_id, amount) VALUES (%s, %s)", (1, 100))
```

---

## 五、查询执行

### 5.1 简单查询

**基本查询**：

```python
# 简单查询
cursor = conn.cursor()
cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))
row = cursor.fetchone()

# 获取多行
cursor.execute("SELECT * FROM users WHERE age > %s", (18,))
rows = cursor.fetchall()

# 获取指定数量
rows = cursor.fetchmany(10)
```

### 5.2 预处理语句

**预处理语句**：

```python
# 使用预处理语句（推荐）
cursor = conn.cursor()

# 准备语句
cursor.execute("""
    PREPARE get_user AS
    SELECT * FROM users WHERE id = $1
""")

# 执行预处理语句
cursor.execute("EXECUTE get_user (%s)", (user_id,))
row = cursor.fetchone()

# 或使用参数化查询（自动预处理）
cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))
```

**PostgreSQL 18 优化**：

```python
# PostgreSQL 18: 改进的预处理语句性能
# 使用命名参数（如果驱动支持）
cursor.execute(
    "SELECT * FROM users WHERE id = :id AND name = :name",
    {"id": user_id, "name": user_name}
)
```

### 5.3 批量操作

**批量插入**：

```python
# 方法1: executemany
data = [("Alice", 25), ("Bob", 30), ("Charlie", 35)]
cursor.executemany(
    "INSERT INTO users (name, age) VALUES (%s, %s)",
    data
)
conn.commit()

# 方法2: execute_values (psycopg2扩展，更高效)
from psycopg2.extras import execute_values
execute_values(
    cursor,
    "INSERT INTO users (name, age) VALUES %s",
    data
)
conn.commit()

# 方法3: COPY (最快)
from io import StringIO
f = StringIO()
for name, age in data:
    f.write(f"{name}\t{age}\n")
f.seek(0)
cursor.copy_from(f, "users", columns=("name", "age"))
conn.commit()
```

**批量更新**：

```python
# 批量更新
from psycopg2.extras import execute_batch

updates = [(1, "Alice"), (2, "Bob"), (3, "Charlie")]
execute_batch(
    cursor,
    "UPDATE users SET name = %s WHERE id = %s",
    [(name, id) for id, name in updates],
    page_size=100
)
conn.commit()
```

### 5.4 游标操作

**服务器端游标**：

```python
# 服务器端游标（处理大量数据）
cursor = conn.cursor("large_query")
cursor.execute("SELECT * FROM large_table")

# 逐批获取
while True:
    rows = cursor.fetchmany(1000)
    if not rows:
        break
    # 处理数据
    process_rows(rows)

cursor.close()
```

---

## 六、异步操作

### 6.1 异步I/O

**PostgreSQL 18 异步I/O**：

```python
# Python: 使用asyncpg (异步驱动)
import asyncio
import asyncpg

async def async_query():
    conn = await asyncpg.connect(
        host="localhost",
        database="mydb",
        user="myuser",
        password="mypassword"
    )

    # 异步查询
    rows = await conn.fetch("SELECT * FROM users WHERE age > $1", 18)

    # 异步执行
    await conn.execute("INSERT INTO users (name) VALUES ($1)", "Alice")

    await conn.close()

# 运行
asyncio.run(async_query())
```

### 6.2 并行查询

**并行查询配置**：

```sql
-- 启用并行查询
SET max_parallel_workers_per_gather = 4;
SET parallel_tuple_cost = 0.1;
SET parallel_setup_cost = 1000.0;

-- 执行并行查询
EXPLAIN ANALYZE
SELECT * FROM large_table WHERE condition;
```

### 6.3 异步连接

**异步连接池**：

```python
# 异步连接池
import asyncpg

async def create_pool():
    return await asyncpg.create_pool(
        host="localhost",
        database="mydb",
        user="myuser",
        password="mypassword",
        min_size=10,
        max_size=20
    )

async def use_pool():
    pool = await create_pool()

    async with pool.acquire() as conn:
        rows = await conn.fetch("SELECT * FROM users")

    await pool.close()
```

---

## 七、数据类型处理

### 7.1 基本类型

**基本类型映射**：

```python
# Python类型到PostgreSQL类型
cursor.execute("""
    INSERT INTO users (name, age, salary, active, created_at)
    VALUES (%s, %s, %s, %s, %s)
""", (
    "Alice",      # VARCHAR
    25,           # INTEGER
    50000.50,     # DECIMAL
    True,         # BOOLEAN
    datetime.now() # TIMESTAMP
))
```

### 7.2 复合类型

**复合类型处理**：

```python
# 定义复合类型
cursor.execute("""
    CREATE TYPE address AS (
        street VARCHAR(100),
        city VARCHAR(50),
        zip_code VARCHAR(10)
    )
""")

# 使用复合类型
from psycopg2.extras import RealDictCursor
cursor = conn.cursor(cursor_factory=RealDictCursor)

cursor.execute("""
    INSERT INTO customers (name, addr)
    VALUES (%s, ROW(%s, %s, %s)::address)
""", ("Alice", "123 Main St", "New York", "10001"))
```

### 7.3 JSON/JSONB

**JSON/JSONB处理**：

```python
import json

# 插入JSON
data = {"name": "Alice", "age": 25, "city": "New York"}
cursor.execute(
    "INSERT INTO users (id, profile) VALUES (%s, %s)",
    (1, json.dumps(data))
)

# 查询JSON
cursor.execute("SELECT profile->>'name' FROM users WHERE id = %s", (1,))
name = cursor.fetchone()[0]

# JSONB查询（PostgreSQL 18性能提升）
cursor.execute("""
    SELECT * FROM users
    WHERE profile @> '{"city": "New York"}'::jsonb
""")
```

### 7.4 数组类型

**数组类型处理**：

```python
# 插入数组
tags = ["python", "postgresql", "database"]
cursor.execute(
    "INSERT INTO posts (title, tags) VALUES (%s, %s)",
    ("My Post", tags)
)

# 查询数组
cursor.execute("SELECT * FROM posts WHERE 'python' = ANY(tags)")
```

---

## 八、错误处理

### 8.1 错误码

**错误码处理**：

```python
import psycopg2
from psycopg2 import errorcodes

try:
    cursor.execute("INSERT INTO users (id, name) VALUES (%s, %s)", (1, "Alice"))
    conn.commit()
except psycopg2.IntegrityError as e:
    if e.pgcode == errorcodes.UNIQUE_VIOLATION:
        print("用户已存在")
    elif e.pgcode == errorcodes.NOT_NULL_VIOLATION:
        print("必填字段为空")
    else:
        print(f"完整性错误: {e}")
except psycopg2.OperationalError as e:
    print(f"操作错误: {e}")
except psycopg2.Error as e:
    print(f"数据库错误: {e}")
```

### 8.2 异常处理

**异常处理最佳实践**：

```python
def safe_execute(conn, query, params=None):
    """安全执行查询"""
    try:
        cursor = conn.cursor()
        cursor.execute(query, params)
        result = cursor.fetchall()
        conn.commit()
        return result
    except psycopg2.Error as e:
        conn.rollback()
        logger.error(f"数据库错误: {e}")
        raise
    finally:
        cursor.close()
```

### 8.3 重试机制

**重试机制实现**：

```python
import time
from functools import wraps

def retry_on_deadlock(max_retries=3, delay=1):
    """死锁重试装饰器"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except psycopg2.OperationalError as e:
                    if e.pgcode == errorcodes.DEADLOCK_DETECTED:
                        if attempt < max_retries - 1:
                            time.sleep(delay * (attempt + 1))
                            continue
                    raise
            return None
        return wrapper
    return decorator

@retry_on_deadlock(max_retries=3)
def update_user(user_id, name):
    cursor.execute("UPDATE users SET name = %s WHERE id = %s", (name, user_id))
    conn.commit()
```

---

## 九、性能优化

### 9.1 连接优化

**连接优化建议**：

- 使用连接池，避免频繁创建连接
- 设置合适的连接池大小
- 使用连接健康检查
- 及时关闭不用的连接

### 9.2 查询优化

**查询优化建议**：

- 使用预处理语句
- 使用批量操作
- 使用COPY进行大量数据导入
- 使用服务器端游标处理大量数据

### 9.3 批量优化

**批量操作优化**：

```python
# 使用事务批量提交
def batch_insert(conn, data, batch_size=1000):
    cursor = conn.cursor()
    try:
        for i in range(0, len(data), batch_size):
            batch = data[i:i+batch_size]
            cursor.executemany(
                "INSERT INTO users (name, age) VALUES (%s, %s)",
                batch
            )
            conn.commit()  # 每批提交一次
    except:
        conn.rollback()
        raise
    finally:
        cursor.close()
```

---

## 十、相关文档

- [编程范式与模式](./01.01-编程范式与模式.md)
- [代码模式与最佳实践](./01.03-代码模式与最佳实践.md)
- [性能编程技巧](./01.05-性能编程技巧.md)
- [错误处理与异常](./01.06-错误处理与异常.md)
- [PostgreSQL 18新特性](../../02-版本特性/02.01-PostgreSQL-18-新特性.md)

---

**最后更新**: 2025-01-15
**维护者**: PostgreSQL Documentation Team
