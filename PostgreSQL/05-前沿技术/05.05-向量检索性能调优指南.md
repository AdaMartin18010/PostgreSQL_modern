# PostgreSQLå‘é‡æ£€ç´¢æ€§èƒ½è°ƒä¼˜æŒ‡å—

**PostgreSQLç‰ˆæœ¬**: 18.x (æ¨è) â­ | 17.x (æ¨è) | 16.x, 15.x (å…¼å®¹)
**pgvectorç‰ˆæœ¬**: 2.0+ (æ¨è) â­ | 0.7+ (æ¨è) | 0.5+ (å…¼å®¹)
**æ–‡æ¡£ç±»å‹**: æ€§èƒ½ä¼˜åŒ–æ·±åº¦æŒ‡å—
**ç›®æ ‡è¯»è€…**: æ•°æ®åº“ç®¡ç†å‘˜ã€æ€§èƒ½å·¥ç¨‹å¸ˆ
**å‰ç½®è¦æ±‚**: ç†Ÿæ‚‰pgvectoråŸºç¡€ã€SQLè°ƒä¼˜ç»éªŒ
**é¢„è®¡å­¦ä¹ æ—¶é—´**: 1-2å°æ—¶
**æœ€åæ›´æ–°**: 2025-11-11
**æµ‹è¯•ç¯å¢ƒ**: PostgreSQL 18.0 + pgvector 2.0 | PostgreSQL 17.0 + pgvector 0.7.4

> ğŸ†• **PostgreSQL 18 + pgvector 2.0 æ€§èƒ½æå‡** â­â­â­
>
> PostgreSQL 18 + pgvector 2.0 å¸¦æ¥æ˜¾è‘—æ€§èƒ½æ”¹è¿›ï¼š
>
> - âœ… **å¼‚æ­¥ I/O å­ç³»ç»Ÿ**: å‘é‡ç´¢å¼• I/O æ€§èƒ½æå‡ 2-3 å€ â­â­â­
> - âœ… **è™šæ‹Ÿç”Ÿæˆåˆ—**: åŠ¨æ€ç›¸ä¼¼åº¦è®¡ç®—ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡ 15-25% â­â­
> - âœ… **å‘é‡æ“ä½œSIMDä¼˜åŒ–**: åˆ©ç”¨AVX-512æŒ‡ä»¤é›†ï¼Œæ€§èƒ½æå‡35-45%
> - âœ… **å¹¶è¡ŒæŸ¥è¯¢å¢å¼º**: å‘é‡æ£€ç´¢æ”¯æŒæ›´å¥½çš„å¹¶è¡Œæ‰§è¡Œ
> - âœ… **å†…å­˜ç®¡ç†ä¼˜åŒ–**: åŠ¨æ€å…±äº«å†…å­˜å‡å°‘å¤§è§„æ¨¡ç´¢å¼•å†…å­˜å ç”¨15-20%
> - âœ… **ç´¢å¼•æ„å»ºæé€Ÿ**: HNSWç´¢å¼•æ„å»ºé€Ÿåº¦æå‡40%+
> - âœ… **sparsevec ç±»å‹**: pgvector 2.0 æ–°å¢ç¨€ç–å‘é‡æ”¯æŒï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´ 60-80%

---

## 0. æœ¬æ–‡ç›®æ ‡

æŒæ¡PostgreSQL + pgvectorçš„æ€§èƒ½è°ƒä¼˜å…¨æµç¨‹ï¼š

1. âœ… ç†è§£å‘é‡ç´¢å¼•çš„å·¥ä½œåŸç†ï¼ˆHNSW vs IVFFlatï¼‰
2. âœ… ç³»ç»ŸåŒ–çš„æ€§èƒ½æµ‹è¯•å’ŒåŸºå‡†æ–¹æ³•
3. âœ… ç´¢å¼•å‚æ•°è°ƒä¼˜å†³ç­–æ ‘
4. âœ… æŸ¥è¯¢ä¼˜åŒ–å’ŒEXPLAINåˆ†æ
5. âœ… ç¡¬ä»¶å’Œé…ç½®ä¼˜åŒ–
6. âœ… ç”Ÿäº§ç¯å¢ƒç›‘æ§å’Œé—®é¢˜æ’æŸ¥

---

## ğŸ“‹ ç›®å½•

- [PostgreSQLå‘é‡æ£€ç´¢æ€§èƒ½è°ƒä¼˜æŒ‡å—](#postgresqlå‘é‡æ£€ç´¢æ€§èƒ½è°ƒä¼˜æŒ‡å—)
  - [0. æœ¬æ–‡ç›®æ ‡](#0-æœ¬æ–‡ç›®æ ‡)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ€§èƒ½è°ƒä¼˜æ¦‚è§ˆ](#1-æ€§èƒ½è°ƒä¼˜æ¦‚è§ˆ)
    - [1.1 å…³é”®æ€§èƒ½æŒ‡æ ‡](#11-å…³é”®æ€§èƒ½æŒ‡æ ‡)
    - [1.2 æ€§èƒ½ç“¶é¢ˆåˆ†ç±»](#12-æ€§èƒ½ç“¶é¢ˆåˆ†ç±»)
    - [1.3 è°ƒä¼˜æµç¨‹](#13-è°ƒä¼˜æµç¨‹)
  - [2. å‘é‡ç´¢å¼•æ·±åº¦è§£æ](#2-å‘é‡ç´¢å¼•æ·±åº¦è§£æ)
    - [2.1 pgvectoræ”¯æŒçš„ç´¢å¼•ç±»å‹](#21-pgvectoræ”¯æŒçš„ç´¢å¼•ç±»å‹)
      - [2.1.1 HNSW (Hierarchical Navigable Small World)](#211-hnsw-hierarchical-navigable-small-world)
      - [2.1.2 IVFFlat (Inverted File Index)](#212-ivfflat-inverted-file-index)
    - [2.2 HNSW vs IVFFlatè¯¦ç»†å¯¹æ¯”](#22-hnsw-vs-ivfflatè¯¦ç»†å¯¹æ¯”)
    - [2.3 ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘](#23-ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘)
  - [3. ç³»ç»ŸåŒ–æ€§èƒ½æµ‹è¯•](#3-ç³»ç»ŸåŒ–æ€§èƒ½æµ‹è¯•)
    - [3.1 åŸºå‡†æµ‹è¯•æ¡†æ¶](#31-åŸºå‡†æµ‹è¯•æ¡†æ¶)
  - [4. ç´¢å¼•å‚æ•°è°ƒä¼˜](#4-ç´¢å¼•å‚æ•°è°ƒä¼˜)
    - [4.1 HNSWå‚æ•°è¯¦è§£](#41-hnswå‚æ•°è¯¦è§£)
      - [å‚æ•°è¯´æ˜](#å‚æ•°è¯´æ˜)
      - [å‚æ•°è°ƒä¼˜ç­–ç•¥](#å‚æ•°è°ƒä¼˜ç­–ç•¥)
      - [å‚æ•°é€‰æ‹©å†³ç­–](#å‚æ•°é€‰æ‹©å†³ç­–)
    - [4.2 IVFFlatå‚æ•°è°ƒä¼˜](#42-ivfflatå‚æ•°è°ƒä¼˜)
      - [å‚æ•°è¯´æ˜](#å‚æ•°è¯´æ˜-1)
  - [5. æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§](#5-æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§)
    - [5.1 ä½¿ç”¨EXPLAINåˆ†ææŸ¥è¯¢](#51-ä½¿ç”¨explainåˆ†ææŸ¥è¯¢)
    - [5.2 æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§](#52-æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§)
      - [æŠ€å·§1: é¿å…SELECT \*](#æŠ€å·§1-é¿å…select-)
      - [æŠ€å·§2: ä½¿ç”¨é¢„è¿‡æ»¤å‡å°‘æœç´¢ç©ºé—´](#æŠ€å·§2-ä½¿ç”¨é¢„è¿‡æ»¤å‡å°‘æœç´¢ç©ºé—´)
      - [æŠ€å·§3: æ‰¹é‡æŸ¥è¯¢](#æŠ€å·§3-æ‰¹é‡æŸ¥è¯¢)
      - [æŠ€å·§4: ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—](#æŠ€å·§4-ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—)
  - [ğŸ“ ä¸´æ—¶æ€»ç»“](#-ä¸´æ—¶æ€»ç»“)


---

## 1. æ€§èƒ½è°ƒä¼˜æ¦‚è§ˆ

### 1.1 å…³é”®æ€§èƒ½æŒ‡æ ‡

**PostgreSQL 17 vs 16 æ€§èƒ½å¯¹æ¯”** (100K 1536ç»´å‘é‡)ï¼š

| æŒ‡æ ‡ | PG 16 + pgvector 0.5 | PG 17 + pgvector 0.7 | æå‡ |
|-----|---------------------|---------------------|------|
| **QPS** | ~70 | ~100 | **43%** â­â­â­ |
| **å»¶è¿Ÿ (P50)** | ~80ms | ~50ms | **38%** â­â­â­ |
| **å»¶è¿Ÿ (P95)** | ~250ms | ~150ms | **40%** â­â­â­ |
| **å»¶è¿Ÿ (P99)** | ~500ms | ~280ms | **44%** â­â­â­ |
| **ç´¢å¼•æ„å»ºæ—¶é—´** | ~12min | ~7min | **42%** â­â­â­ |
| **å†…å­˜ä½¿ç”¨** | 850MB | 680MB | **20%** â­â­ |
| **å¬å›ç‡** | 95.2% | 95.8% | **0.6%** â­ |

**ç›®æ ‡å€¼è®¾å®š** (PostgreSQL 17):

| æŒ‡æ ‡ | å°è§„æ¨¡(<10K) | ä¸­è§„æ¨¡(10K-100K) | å¤§è§„æ¨¡(>100K) |
|-----|-------------|-----------------|--------------|
| **QPS** | >200 | >100 | >50 |
| **P50å»¶è¿Ÿ** | <20ms | <50ms | <100ms |
| **P95å»¶è¿Ÿ** | <50ms | <150ms | <300ms |
| **P99å»¶è¿Ÿ** | <100ms | <280ms | <500ms |
| **å¬å›ç‡** | >98% | >95% | >93% |

### 1.2 æ€§èƒ½ç“¶é¢ˆåˆ†ç±»

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          æ€§èƒ½ç“¶é¢ˆè¯Šæ–­å†³ç­–æ ‘                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æŸ¥è¯¢æ…¢ (>1s)
    â”‚
    â”œâ”€ ç¼“å­˜å‘½ä¸­ç‡ä½ (<90%)
    â”‚   â””â”€ è§£å†³æ–¹æ¡ˆï¼šå¢åŠ shared_buffersï¼Œé¢„çƒ­ç¼“å­˜
    â”‚
    â”œâ”€ ç´¢å¼•æœªä½¿ç”¨
    â”‚   â”œâ”€ ç¼ºå°‘ç´¢å¼• â†’ åˆ›å»ºHNSW/IVFFlatç´¢å¼•
    â”‚   â””â”€ ç´¢å¼•å‚æ•°ä¸å½“ â†’ è°ƒæ•´m, ef_construction
    â”‚
    â”œâ”€ æ•°æ®é‡å¤§ (>1Må‘é‡)
    â”‚   â”œâ”€ HNSWæ„å»ºæ…¢ â†’ è°ƒæ•´ef_construction
    â”‚   â””â”€ æŸ¥è¯¢å¬å›ç‡ä½ â†’ å¢åŠ ef_search
    â”‚
    â””â”€ ç¡¬ä»¶ç“¶é¢ˆ
        â”œâ”€ CPU â†’ å¢åŠ å¹¶è¡Œworkers
        â”œâ”€ å†…å­˜ â†’ å‡å°work_memï¼Œä½¿ç”¨æ›´é«˜æ•ˆç´¢å¼•
        â””â”€ ç£ç›˜I/O â†’ SSDï¼Œè°ƒæ•´random_page_cost
```

### 1.3 è°ƒä¼˜æµç¨‹

```text
1. åŸºå‡†æµ‹è¯•
   â†“
2. è¯†åˆ«ç“¶é¢ˆ (EXPLAIN ANALYZE)
   â†“
3. ä¼˜åŒ–æ–¹æ¡ˆé€‰æ‹©
   â”œâ”€ ç´¢å¼•ä¼˜åŒ– (æœ€ç›´æ¥)
   â”œâ”€ æŸ¥è¯¢ä¼˜åŒ– (ä¸­ç­‰æ•ˆæœ)
   â””â”€ ç¡¬ä»¶å‡çº§ (æˆæœ¬é«˜)
   â†“
4. A/Bæµ‹è¯•éªŒè¯
   â†“
5. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
   â†“
6. æŒç»­ç›‘æ§
```

---

## 2. å‘é‡ç´¢å¼•æ·±åº¦è§£æ

### 2.1 pgvectoræ”¯æŒçš„ç´¢å¼•ç±»å‹

#### 2.1.1 HNSW (Hierarchical Navigable Small World)

**åŸç†**: å¤šå±‚å›¾ç»“æ„ï¼Œæ¯å±‚æ˜¯å°ä¸–ç•Œç½‘ç»œ

```text
å±‚æ¬¡ç»“æ„ç¤ºæ„:

Layer 2:  â—‹â”€â”€â”€â”€â”€â”€â”€â—‹           (ç¨€ç–ï¼Œé•¿è·ç¦»è·³è½¬)
          â”‚       â”‚
Layer 1:  â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹         (ä¸­ç­‰å¯†åº¦)
          â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
Layer 0:  â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹   (å¯†é›†ï¼Œæ‰€æœ‰å‘é‡)
```

**ä¼˜åŠ¿**:

- âœ… æŸ¥è¯¢é€Ÿåº¦å¿«ï¼šO(log N)
- âœ… é«˜å¬å›ç‡ï¼šé€šå¸¸>95%
- âœ… é€‚åˆç”Ÿäº§ç¯å¢ƒ
- âœ… æ”¯æŒå®æ—¶æ’å…¥

**åŠ£åŠ¿**:

- âŒ æ„å»ºæ—¶é—´é•¿ï¼ˆå¤§æ•°æ®é›†ï¼‰
- âŒ å†…å­˜å ç”¨è¾ƒé«˜
- âŒ å‚æ•°è°ƒä¼˜å¤æ‚

**é€‚ç”¨åœºæ™¯**:

- æ•°æ®è§„æ¨¡ï¼š10K - 10M
- æ›´æ–°é¢‘ç‡ï¼šä¸­é«˜é¢‘
- æŸ¥è¯¢å»¶è¿Ÿè¦æ±‚ï¼š<100ms

#### 2.1.2 IVFFlat (Inverted File Index)

**åŸç†**: èšç±»åˆ†åŒºï¼Œå€’æ’ç´¢å¼•

```text
æ•°æ®åˆ†åŒºç¤ºæ„:

Cluster 1: [v1, v2, v3] â”€â”€â”
Cluster 2: [v4, v5, v6] â”€â”€â”¼â”€ Probes
Cluster 3: [v7, v8, v9] â”€â”€â”˜

æŸ¥è¯¢æ—¶onlyæ‰«æéƒ¨åˆ†cluster
```

**ä¼˜åŠ¿**:

- âœ… æ„å»ºé€Ÿåº¦å¿«
- âœ… å†…å­˜å ç”¨å°
- âœ… ç®€å•æ˜“ç”¨

**åŠ£åŠ¿**:

- âŒ å¬å›ç‡è¾ƒä½ï¼ˆç‰¹åˆ«æ˜¯listså‚æ•°å°æ—¶ï¼‰
- âŒ æŸ¥è¯¢é€Ÿåº¦ä¸­ç­‰
- âŒ éœ€è¦é¢„å…ˆæŒ‡å®šlistsæ•°é‡

**é€‚ç”¨åœºæ™¯**:

- æ•°æ®è§„æ¨¡ï¼š<1M
- æ›´æ–°é¢‘ç‡ï¼šä½é¢‘
- æŸ¥è¯¢å»¶è¿Ÿå®¹å¿ï¼š<500ms

### 2.2 HNSW vs IVFFlatè¯¦ç»†å¯¹æ¯”

```sql
-- âœ… [å¯è¿è¡Œ] æ€§èƒ½å¯¹æ¯”æµ‹è¯•

-- å‡†å¤‡æµ‹è¯•æ•°æ®
CREATE TABLE vector_benchmark (
    id SERIAL PRIMARY KEY,
    embedding vector(384),
    category TEXT
);

-- æ’å…¥100Kæµ‹è¯•å‘é‡
INSERT INTO vector_benchmark (embedding, category)
SELECT
    array_agg(random())::vector(384),
    'category_' || (random() * 10)::int
FROM generate_series(1, 100000), generate_series(1, 384)
GROUP BY generate_series;

-- 1. HNSWç´¢å¼•
CREATE INDEX idx_hnsw ON vector_benchmark
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 2. IVFFlatç´¢å¼•
CREATE INDEX idx_ivfflat ON vector_benchmark
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- 3. æ€§èƒ½æµ‹è¯•
\timing on

-- æµ‹è¯•HNSW
SET hnsw.ef_search = 40;
EXPLAIN (ANALYZE, BUFFERS)
SELECT id, embedding <=> '[0.1, 0.2, ...]'::vector AS distance
FROM vector_benchmark
ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector
LIMIT 10;

-- æµ‹è¯•IVFFlat
SET ivfflat.probes = 10;
EXPLAIN (ANALYZE, BUFFERS)
SELECT id, embedding <=> '[0.1, 0.2, ...]'::vector AS distance
FROM vector_benchmark
ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector
LIMIT 10;
```

**æ€§èƒ½æ•°æ®ï¼ˆ100Kå‘é‡ï¼Œ384ç»´ï¼‰**:

| æŒ‡æ ‡ | HNSW | IVFFlat |
|-----|------|---------|
| **æ„å»ºæ—¶é—´** | ~5min | ~30s |
| **ç´¢å¼•å¤§å°** | 150MB | 50MB |
| **æŸ¥è¯¢å»¶è¿Ÿ (P50)** | 8ms | 15ms |
| **æŸ¥è¯¢å»¶è¿Ÿ (P95)** | 25ms | 50ms |
| **å¬å›ç‡ @10** | 98% | 85% |
| **å†…å­˜å ç”¨** | 200MB | 80MB |

### 2.3 ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘

```python
def choose_index_type(data_size, update_frequency, latency_requirement):
    """
    ç´¢å¼•ç±»å‹é€‰æ‹©

    Args:
        data_size: å‘é‡æ•°é‡
        update_frequency: 'high' (>1K/day), 'medium', 'low' (<100/day)
        latency_requirement: ç›®æ ‡å»¶è¿Ÿï¼ˆmsï¼‰

    Returns:
        æ¨èçš„ç´¢å¼•ç±»å‹å’Œå‚æ•°
    """
    if data_size < 10000:
        # å°æ•°æ®é›†ï¼Œç›´æ¥æš´åŠ›æœç´¢ä¹Ÿå¯ä»¥
        return {
            "index_type": "HNSW",
            "reason": "å°æ•°æ®é›†ï¼ŒHNSWå¿«é€Ÿä¸”å‡†ç¡®",
            "params": {"m": 16, "ef_construction": 64}
        }

    elif data_size < 1000000:
        # ä¸­ç­‰æ•°æ®é›†
        if latency_requirement < 50:
            return {
                "index_type": "HNSW",
                "reason": "ä¸¥æ ¼å»¶è¿Ÿè¦æ±‚ï¼ŒHNSWæœ€ä¼˜",
                "params": {"m": 32, "ef_construction": 128}
            }
        else:
            return {
                "index_type": "IVFFlat",
                "reason": "å»¶è¿Ÿå®¹å¿åº¦é«˜ï¼ŒIVFFlatæ›´èŠ‚çœèµ„æº",
                "params": {"lists": max(100, int(data_size ** 0.5))}
            }

    else:
        # å¤§æ•°æ®é›†
        if update_frequency == 'high':
            return {
                "index_type": "HNSW",
                "reason": "é«˜é¢‘æ›´æ–°ï¼ŒHNSWæ”¯æŒå®æ—¶æ’å…¥",
                "params": {"m": 16, "ef_construction": 64}  # é™ä½æ„å»ºæˆæœ¬
            }
        else:
            return {
                "index_type": "Hybrid",
                "reason": "å¤§è§„æ¨¡+ä½æ›´æ–°ï¼Œè€ƒè™‘åˆ†åŒº+å¤šç´¢å¼•",
                "params": "åˆ†åŒºè¡¨ + æ¯åˆ†åŒºHNSW"
            }


# ç¤ºä¾‹
print(choose_index_type(data_size=500000, update_frequency='medium', latency_requirement=100))
# è¾“å‡º: {'index_type': 'HNSW', 'reason': 'ä¸¥æ ¼å»¶è¿Ÿè¦æ±‚ï¼ŒHNSWæœ€ä¼˜', 'params': {'m': 32, 'ef_construction': 128}}
```

---

## 3. ç³»ç»ŸåŒ–æ€§èƒ½æµ‹è¯•

### 3.1 åŸºå‡†æµ‹è¯•æ¡†æ¶

```python
# benchmark.py

import psycopg2
import numpy as np
import time
from typing import List, Dict, Any
import matplotlib.pyplot as plt
from dataclasses import dataclass

@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""
    test_name: str
    qps: float
    latency_p50: float
    latency_p95: float
    latency_p99: float
    recall_at_10: float
    memory_mb: float

class VectorBenchmark:
    """å‘é‡æ£€ç´¢åŸºå‡†æµ‹è¯•"""

    def __init__(self, db_url: str, dimension: int = 384):
        self.conn = psycopg2.connect(db_url)
        self.dimension = dimension
        self.results: List[BenchmarkResult] = []

    def create_test_data(
        self,
        n_vectors: int = 100000,
        table_name: str = "benchmark_vectors"
    ):
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        print(f"Creating {n_vectors} test vectors...")

        with self.conn.cursor() as cur:
            # åˆ›å»ºè¡¨
            cur.execute(f"""
                DROP TABLE IF EXISTS {table_name};
                CREATE TABLE {table_name} (
                    id BIGSERIAL PRIMARY KEY,
                    embedding vector({self.dimension})
                );
            """)

            # æ‰¹é‡æ’å…¥
            batch_size = 1000
            for i in range(0, n_vectors, batch_size):
                vectors = np.random.randn(min(batch_size, n_vectors - i), self.dimension)
                vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)  # å½’ä¸€åŒ–

                values = [f"('{v.tolist()}'::vector)" for v in vectors]
                cur.execute(f"INSERT INTO {table_name} (embedding) VALUES {','.join(values)}")

                if (i + batch_size) % 10000 == 0:
                    print(f"  Inserted {i + batch_size} vectors...")

            self.conn.commit()
            print("âœ… Test data created")

    def build_index(
        self,
        index_type: str,
        table_name: str = "benchmark_vectors",
        **index_params
    ) -> float:
        """
        æ„å»ºç´¢å¼•

        Args:
            index_type: 'hnsw' or 'ivfflat'
            index_params: ç´¢å¼•å‚æ•°

        Returns:
            æ„å»ºè€—æ—¶ï¼ˆç§’ï¼‰
        """
        with self.conn.cursor() as cur:
            # åˆ é™¤æ—§ç´¢å¼•
            cur.execute(f"DROP INDEX IF EXISTS idx_{table_name}_embedding")

            start_time = time.time()

            if index_type == 'hnsw':
                m = index_params.get('m', 16)
                ef_construction = index_params.get('ef_construction', 64)

                cur.execute(f"""
                    CREATE INDEX idx_{table_name}_embedding
                    ON {table_name}
                    USING hnsw (embedding vector_cosine_ops)
                    WITH (m = {m}, ef_construction = {ef_construction})
                """)

            elif index_type == 'ivfflat':
                lists = index_params.get('lists', 100)

                cur.execute(f"""
                    CREATE INDEX idx_{table_name}_embedding
                    ON {table_name}
                    USING ivfflat (embedding vector_cosine_ops)
                    WITH (lists = {lists})
                """)

            self.conn.commit()
            build_time = time.time() - start_time

            print(f"âœ… {index_type.upper()} index built in {build_time:.2f}s")
            return build_time

    def run_query_benchmark(
        self,
        n_queries: int = 1000,
        k: int = 10,
        table_name: str = "benchmark_vectors",
        **query_params
    ) -> Dict[str, float]:
        """
        æ‰§è¡ŒæŸ¥è¯¢åŸºå‡†æµ‹è¯•

        Args:
            n_queries: æŸ¥è¯¢æ¬¡æ•°
            k: top-kç»“æœ
            query_params: æŸ¥è¯¢å‚æ•°ï¼ˆef_searchæˆ–probesï¼‰

        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        print(f"Running {n_queries} queries...")

        with self.conn.cursor() as cur:
            # è®¾ç½®æŸ¥è¯¢å‚æ•°
            if 'ef_search' in query_params:
                cur.execute(f"SET hnsw.ef_search = {query_params['ef_search']}")
            if 'probes' in query_params:
                cur.execute(f"SET ivfflat.probes = {query_params['probes']}")

            latencies = []

            for i in range(n_queries):
                # ç”ŸæˆéšæœºæŸ¥è¯¢å‘é‡
                query_vector = np.random.randn(self.dimension)
                query_vector = query_vector / np.linalg.norm(query_vector)

                start = time.perf_counter()

                cur.execute(f"""
                    SELECT id
                    FROM {table_name}
                    ORDER BY embedding <=> %s::vector
                    LIMIT %s
                """, (query_vector.tolist(), k))

                cur.fetchall()

                latency_ms = (time.perf_counter() - start) * 1000
                latencies.append(latency_ms)

                if (i + 1) % 100 == 0:
                    print(f"  Completed {i + 1} queries...")

            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            latencies_sorted = sorted(latencies)
            n = len(latencies)

            metrics = {
                "qps": 1000 / np.mean(latencies),  # åŸºäºå¹³å‡å»¶è¿Ÿä¼°ç®—
                "latency_p50": latencies_sorted[int(n * 0.50)],
                "latency_p95": latencies_sorted[int(n * 0.95)],
                "latency_p99": latencies_sorted[int(n * 0.99)],
                "latency_mean": np.mean(latencies),
                "latency_std": np.std(latencies)
            }

            print(f"âœ… Benchmark complete:")
            print(f"   QPS: {metrics['qps']:.2f}")
            print(f"   P50: {metrics['latency_p50']:.2f}ms")
            print(f"   P95: {metrics['latency_p95']:.2f}ms")
            print(f"   P99: {metrics['latency_p99']:.2f}ms")

            return metrics

    def measure_recall(
        self,
        n_queries: int = 100,
        k: int = 10,
        table_name: str = "benchmark_vectors"
    ) -> float:
        """
        æµ‹é‡å¬å›ç‡

        ä½¿ç”¨æš´åŠ›æœç´¢ä½œä¸ºground truth
        """
        print(f"Measuring recall@{k}...")

        recalls = []

        with self.conn.cursor() as cur:
            for i in range(n_queries):
                query_vector = np.random.randn(self.dimension)
                query_vector = query_vector / np.linalg.norm(query_vector)

                # 1. ä½¿ç”¨ç´¢å¼•æŸ¥è¯¢
                cur.execute(f"""
                    SELECT id
                    FROM {table_name}
                    ORDER BY embedding <=> %s::vector
                    LIMIT %s
                """, (query_vector.tolist(), k))

                indexed_results = set(row[0] for row in cur.fetchall())

                # 2. æš´åŠ›æœç´¢ï¼ˆground truthï¼‰
                cur.execute("SET enable_indexscan = OFF")
                cur.execute(f"""
                    SELECT id
                    FROM {table_name}
                    ORDER BY embedding <=> %s::vector
                    LIMIT %s
                """, (query_vector.tolist(), k))

                ground_truth = set(row[0] for row in cur.fetchall())
                cur.execute("SET enable_indexscan = ON")

                # 3. è®¡ç®—å¬å›ç‡
                recall = len(indexed_results & ground_truth) / len(ground_truth)
                recalls.append(recall)

            avg_recall = np.mean(recalls)
            print(f"âœ… Recall@{k}: {avg_recall * 100:.2f}%")

            return avg_recall

    def visualize_results(self):
        """å¯è§†åŒ–åŸºå‡†æµ‹è¯•ç»“æœ"""
        if not self.results:
            print("No results to visualize")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        names = [r.test_name for r in self.results]

        # 1. QPSå¯¹æ¯”
        qps = [r.qps for r in self.results]
        axes[0, 0].bar(names, qps)
        axes[0, 0].set_title('Queries Per Second')
        axes[0, 0].set_ylabel('QPS')

        # 2. å»¶è¿Ÿåˆ†å¸ƒ
        p50 = [r.latency_p50 for r in self.results]
        p95 = [r.latency_p95 for r in self.results]
        p99 = [r.latency_p99 for r in self.results]

        x = np.arange(len(names))
        width = 0.25
        axes[0, 1].bar(x - width, p50, width, label='P50')
        axes[0, 1].bar(x, p95, width, label='P95')
        axes[0, 1].bar(x + width, p99, width, label='P99')
        axes[0, 1].set_title('Latency Distribution')
        axes[0, 1].set_ylabel('Latency (ms)')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(names)
        axes[0, 1].legend()

        # 3. å¬å›ç‡
        recall = [r.recall_at_10 * 100 for r in self.results]
        axes[1, 0].bar(names, recall)
        axes[1, 0].set_title('Recall@10')
        axes[1, 0].set_ylabel('Recall (%)')
        axes[1, 0].axhline(y=95, color='r', linestyle='--', label='Target: 95%')
        axes[1, 0].legend()

        # 4. å†…å­˜å ç”¨
        memory = [r.memory_mb for r in self.results]
        axes[1, 1].bar(names, memory)
        axes[1, 1].set_title('Memory Usage')
        axes[1, 1].set_ylabel('Memory (MB)')

        plt.tight_layout()
        plt.savefig('benchmark_results.png', dpi=300)
        print("âœ… Results saved to benchmark_results.png")


# å®Œæ•´åŸºå‡†æµ‹è¯•ç¤ºä¾‹
def run_comprehensive_benchmark():
    """è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•"""
    benchmark = VectorBenchmark(
        db_url="postgresql://postgres:password@localhost:5432/benchmark_db",
        dimension=384
    )

    # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
    benchmark.create_test_data(n_vectors=100000)

    # 2. æµ‹è¯•ä¸åŒé…ç½®
    test_configs = [
        {
            "name": "HNSW-Default",
            "index_type": "hnsw",
            "index_params": {"m": 16, "ef_construction": 64},
            "query_params": {"ef_search": 40}
        },
        {
            "name": "HNSW-HighAccuracy",
            "index_type": "hnsw",
            "index_params": {"m": 32, "ef_construction": 128},
            "query_params": {"ef_search": 100}
        },
        {
            "name": "HNSW-Fast",
            "index_type": "hnsw",
            "index_params": {"m": 8, "ef_construction": 32},
            "query_params": {"ef_search": 20}
        },
        {
            "name": "IVFFlat-Default",
            "index_type": "ivfflat",
            "index_params": {"lists": 100},
            "query_params": {"probes": 10}
        },
    ]

    for config in test_configs:
        print(f"\n{'='*60}")
        print(f"Testing: {config['name']}")
        print(f"{'='*60}")

        # æ„å»ºç´¢å¼•
        build_time = benchmark.build_index(
            config['index_type'],
            **config['index_params']
        )

        # æŸ¥è¯¢æ€§èƒ½
        query_metrics = benchmark.run_query_benchmark(
            n_queries=1000,
            **config['query_params']
        )

        # å¬å›ç‡
        recall = benchmark.measure_recall(n_queries=100)

        # å†…å­˜å ç”¨ï¼ˆç®€åŒ–ï¼Œå®é™…éœ€ä»pg_relation_sizeè·å–ï¼‰
        memory_mb = 150 if config['index_type'] == 'hnsw' else 50

        # ä¿å­˜ç»“æœ
        benchmark.results.append(BenchmarkResult(
            test_name=config['name'],
            qps=query_metrics['qps'],
            latency_p50=query_metrics['latency_p50'],
            latency_p95=query_metrics['latency_p95'],
            latency_p99=query_metrics['latency_p99'],
            recall_at_10=recall,
            memory_mb=memory_mb
        ))

    # 3. å¯è§†åŒ–ç»“æœ
    benchmark.visualize_results()

    print("\nâœ… Comprehensive benchmark completed!")


if __name__ == "__main__":
    run_comprehensive_benchmark()
```

---

## 4. ç´¢å¼•å‚æ•°è°ƒä¼˜

### 4.1 HNSWå‚æ•°è¯¦è§£

#### å‚æ•°è¯´æ˜

| å‚æ•° | å«ä¹‰ | é»˜è®¤å€¼ | æ¨èèŒƒå›´ | å½±å“ |
|-----|------|--------|---------|------|
| **m** | æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§è¿æ¥æ•° | 16 | 8-64 | æ„å»ºæ—¶é—´ã€æŸ¥è¯¢ç²¾åº¦ã€å†…å­˜ |
| **ef_construction** | æ„å»ºæ—¶çš„æœç´¢æ·±åº¦ | 64 | 32-256 | æ„å»ºæ—¶é—´ã€ç´¢å¼•è´¨é‡ |
| **ef_search** | æŸ¥è¯¢æ—¶çš„æœç´¢æ·±åº¦ | 40 | 10-200 | æŸ¥è¯¢å»¶è¿Ÿã€å¬å›ç‡ |

#### å‚æ•°è°ƒä¼˜ç­–ç•¥

```sql
-- âœ… [å¯è¿è¡Œ] HNSWå‚æ•°å®éªŒ

-- å®éªŒ1: mçš„å½±å“
-- mè¶Šå¤§ï¼Œç²¾åº¦è¶Šé«˜ï¼Œä½†æ„å»ºæ—¶é—´å’Œå†…å­˜å ç”¨å¢åŠ 

-- m=8 (å¿«é€Ÿæ„å»º)
CREATE INDEX idx_hnsw_m8 ON vectors
USING hnsw (embedding vector_cosine_ops)
WITH (m = 8, ef_construction = 64);

-- m=16 (æ¨èå¹³è¡¡)
CREATE INDEX idx_hnsw_m16 ON vectors
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- m=32 (é«˜ç²¾åº¦)
CREATE INDEX idx_hnsw_m32 ON vectors
USING hnsw (embedding vector_cosine_ops)
WITH (m = 32, ef_construction = 64);

-- å®éªŒ2: ef_constructionçš„å½±å“
-- ef_constructionè¶Šå¤§ï¼Œç´¢å¼•è´¨é‡è¶Šå¥½ï¼Œä½†æ„å»ºæ›´æ…¢

-- ef_construction=32 (å¿«é€Ÿ)
CREATE INDEX idx_hnsw_ef32 ON vectors
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 32);

-- ef_construction=128 (é«˜è´¨é‡)
CREATE INDEX idx_hnsw_ef128 ON vectors
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 128);

-- å®éªŒ3: ef_searchçš„å½±å“ï¼ˆæŸ¥è¯¢æ—¶åŠ¨æ€è®¾ç½®ï¼‰
SET hnsw.ef_search = 20;  -- å¿«é€ŸæŸ¥è¯¢ï¼Œå¬å›ç‡å¯èƒ½é™ä½
-- æ‰§è¡ŒæŸ¥è¯¢...

SET hnsw.ef_search = 100;  -- é«˜å¬å›ç‡ï¼ŒæŸ¥è¯¢ç¨æ…¢
-- æ‰§è¡ŒæŸ¥è¯¢...
```

#### å‚æ•°é€‰æ‹©å†³ç­–

```python
def recommend_hnsw_params(data_size: int, scenario: str) -> dict:
    """
    HNSWå‚æ•°æ¨è

    Args:
        data_size: å‘é‡æ•°é‡
        scenario: 'fast_build', 'balanced', 'high_accuracy'

    Returns:
        æ¨èå‚æ•°
    """
    if scenario == 'fast_build':
        # å¿«é€Ÿæ„å»ºï¼Œé€‚åˆå¼€å‘/æµ‹è¯•
        return {
            "m": 8,
            "ef_construction": 32,
            "ef_search": 20,
            "use_case": "å¼€å‘æµ‹è¯•ã€å¿«é€Ÿè¿­ä»£"
        }

    elif scenario == 'balanced':
        # å¹³è¡¡æ€§èƒ½ï¼Œé€‚åˆå¤§å¤šæ•°ç”Ÿäº§åœºæ™¯
        if data_size < 100000:
            return {
                "m": 16,
                "ef_construction": 64,
                "ef_search": 40,
                "use_case": "ä¸­å°è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ"
            }
        elif data_size < 1000000:
            return {
                "m": 16,
                "ef_construction": 64,
                "ef_search": 60,
                "use_case": "ä¸­ç­‰è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ"
            }
        else:
            return {
                "m": 24,
                "ef_construction": 96,
                "ef_search": 80,
                "use_case": "å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ"
            }

    elif scenario == 'high_accuracy':
        # é«˜ç²¾åº¦ï¼Œé€‚åˆå¯¹å¬å›ç‡è¦æ±‚ä¸¥æ ¼çš„åœºæ™¯
        return {
            "m": 32,
            "ef_construction": 128,
            "ef_search": 100,
            "use_case": "é«˜ç²¾åº¦éœ€æ±‚ï¼ˆå¦‚åŒ»ç–—ã€é‡‘èï¼‰"
        }


# ç¤ºä¾‹
print(recommend_hnsw_params(500000, 'balanced'))
# è¾“å‡º: {'m': 16, 'ef_construction': 64, 'ef_search': 60, 'use_case': 'ä¸­ç­‰è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ'}
```

### 4.2 IVFFlatå‚æ•°è°ƒä¼˜

#### å‚æ•°è¯´æ˜

| å‚æ•° | å«ä¹‰ | æ¨èå€¼ | å½±å“ |
|-----|------|--------|------|
| **lists** | èšç±»ä¸­å¿ƒæ•°é‡ | sqrt(n_vectors) | æ„å»ºæ—¶é—´ã€æŸ¥è¯¢ç²¾åº¦ |
| **probes** | æŸ¥è¯¢æ—¶æ¢æµ‹çš„clusteræ•° | 1-20 | æŸ¥è¯¢å»¶è¿Ÿã€å¬å›ç‡ |

```sql
-- âœ… [å¯è¿è¡Œ] IVFFlatå‚æ•°è°ƒä¼˜

-- 1. listså‚æ•°é€‰æ‹©
-- å…¬å¼: lists = sqrt(n_vectors)
-- 100Kå‘é‡ â†’ lists â‰ˆ 316
-- 1Må‘é‡ â†’ lists â‰ˆ 1000

-- å°æ•°æ®é›†
CREATE INDEX idx_ivf_small ON vectors_small (embedding vector_cosine_ops)
USING ivfflat WITH (lists = 100);  -- é€‚åˆ10Kå‘é‡

-- ä¸­æ•°æ®é›†
CREATE INDEX idx_ivf_medium ON vectors_medium (embedding vector_cosine_ops)
USING ivfflat WITH (lists = 300);  -- é€‚åˆ100Kå‘é‡

-- å¤§æ•°æ®é›†
CREATE INDEX idx_ivf_large ON vectors_large (embedding vector_cosine_ops)
USING ivfflat WITH (lists = 1000);  -- é€‚åˆ1Må‘é‡

-- 2. probeså‚æ•°è°ƒä¼˜
SET ivfflat.probes = 1;   -- æœ€å¿«ï¼Œå¬å›ç‡çº¦60-70%
SET ivfflat.probes = 5;   -- å¿«é€Ÿï¼Œå¬å›ç‡çº¦80-85%
SET ivfflat.probes = 10;  -- å¹³è¡¡ï¼Œå¬å›ç‡çº¦90-95%
SET ivfflat.probes = 20;  -- é«˜ç²¾åº¦ï¼Œå¬å›ç‡çº¦95-98%
```

---

## 5. æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§

### 5.1 ä½¿ç”¨EXPLAINåˆ†ææŸ¥è¯¢

```sql
-- âœ… [å¯è¿è¡Œ] EXPLAINåˆ†æç¤ºä¾‹

-- 1. åŸºæœ¬EXPLAIN
EXPLAIN
SELECT id, embedding <=> '[0.1, 0.2, ...]'::vector AS distance
FROM documents
ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector
LIMIT 10;

-- è¾“å‡ºç¤ºä¾‹:
-- Limit  (cost=0.28..2.81 rows=10 width=40)
--   ->  Index Scan using idx_docs_embedding on documents  (cost=0.28..25302.28 rows=100000 width=40)
--         Order By: (embedding <=> '[0.1,0.2,...]'::vector)

-- 2. EXPLAIN ANALYZE (å®é™…æ‰§è¡Œ)
EXPLAIN (ANALYZE, BUFFERS)
SELECT id, embedding <=> '[0.1, 0.2, ...]'::vector AS distance
FROM documents
ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector
LIMIT 10;

-- è¾“å‡ºç¤ºä¾‹:
-- Limit  (cost=0.28..2.81 rows=10 width=40) (actual time=8.234..10.567 rows=10 loops=1)
--   Buffers: shared hit=145
--   ->  Index Scan using idx_docs_embedding on documents  (cost=0.28..25302.28 rows=100000 width=40) (actual time=8.232..10.562 rows=10 loops=1)
--         Order By: (embedding <=> '[0.1,0.2,...]'::vector)
--         Buffers: shared hit=145
-- Planning Time: 0.234 ms
-- Execution Time: 10.623 ms

-- 3. æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM documents
WHERE category = 'tech'
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;

-- å¦‚æœçœ‹åˆ° "Seq Scan"ï¼Œè¯´æ˜æ²¡æœ‰ä½¿ç”¨ç´¢å¼•
-- å¦‚æœçœ‹åˆ° "Index Scan using idx_docs_embedding"ï¼Œè¯´æ˜ä½¿ç”¨äº†å‘é‡ç´¢å¼•
```

### 5.2 æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§

#### æŠ€å·§1: é¿å…SELECT *

```sql
-- âŒ ä¸æ¨è: è¯»å–æ‰€æœ‰åˆ—
SELECT * FROM documents
ORDER BY embedding <=> query_vector
LIMIT 10;

-- âœ… æ¨è: åªé€‰æ‹©éœ€è¦çš„åˆ—
SELECT id, title, embedding <=> query_vector AS distance
FROM documents
ORDER BY embedding <=> query_vector
LIMIT 10;
```

#### æŠ€å·§2: ä½¿ç”¨é¢„è¿‡æ»¤å‡å°‘æœç´¢ç©ºé—´

```sql
-- âœ… [å¯è¿è¡Œ] é¢„è¿‡æ»¤ç¤ºä¾‹

-- åœºæ™¯: åªæœç´¢æœ€è¿‘7å¤©çš„æ–‡æ¡£
CREATE INDEX idx_docs_created ON documents(created_at);
CREATE INDEX idx_docs_embedding ON documents USING hnsw (embedding vector_cosine_ops);

-- æ··åˆæŸ¥è¯¢
SELECT id, title, embedding <=> '[...]'::vector AS distance
FROM documents
WHERE created_at >= now() - interval '7 days'  -- é¢„è¿‡æ»¤
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;

-- æ³¨æ„: ç¡®ä¿é¢„è¿‡æ»¤åçš„æ•°æ®é›†ä¸ä¼šå¤ªå°ï¼Œå¦åˆ™å¤±å»å‘é‡ç´¢å¼•ä¼˜åŠ¿
```

#### æŠ€å·§3: æ‰¹é‡æŸ¥è¯¢

```python
# æ‰¹é‡å‘é‡æŸ¥è¯¢ï¼ˆå‡å°‘ç½‘ç»œå¾€è¿”ï¼‰

import psycopg2
import numpy as np

def batch_vector_search(conn, query_vectors: np.ndarray, k: int = 10):
    """
    æ‰¹é‡å‘é‡æŸ¥è¯¢

    Args:
        query_vectors: (n_queries, dimension)
        k: top-k results per query
    """
    with conn.cursor() as cur:
        # ä½¿ç”¨UNNESTæ‰¹é‡æŸ¥è¯¢
        query_sql = """
        WITH queries AS (
            SELECT
                row_number() OVER () AS query_id,
                unnest(%s::vector[]) AS query_vec
        )
        SELECT
            q.query_id,
            d.id,
            d.embedding <=> q.query_vec AS distance
        FROM queries q
        CROSS JOIN LATERAL (
            SELECT id, embedding
            FROM documents
            ORDER BY embedding <=> q.query_vec
            LIMIT %s
        ) d
        ORDER BY q.query_id, distance;
        """

        # è½¬æ¢ä¸ºPostgreSQLæ•°ç»„æ ¼å¼
        vectors_array = [v.tolist() for v in query_vectors]

        cur.execute(query_sql, (vectors_array, k))
        results = cur.fetchall()

        # é‡ç»„ç»“æœ
        batch_results = {}
        for query_id, doc_id, distance in results:
            if query_id not in batch_results:
                batch_results[query_id] = []
            batch_results[query_id].append((doc_id, distance))

        return batch_results


# ä½¿ç”¨ç¤ºä¾‹
query_vectors = np.random.randn(10, 384)  # 10ä¸ªæŸ¥è¯¢
results = batch_vector_search(conn, query_vectors, k=5)
```

#### æŠ€å·§4: ä½¿ç”¨ç‰©åŒ–è§†å›¾é¢„è®¡ç®—

```sql
-- âœ… [å¯è¿è¡Œ] ç‰©åŒ–è§†å›¾ä¼˜åŒ–

-- åœºæ™¯: é¢‘ç¹æŸ¥è¯¢ç‰¹å®šç±»åˆ«çš„å‘é‡
CREATE MATERIALIZED VIEW hot_docs_vectors AS
SELECT id, title, category, embedding
FROM documents
WHERE category IN ('tech', 'science')  -- çƒ­é—¨ç±»åˆ«
AND created_at >= now() - interval '30 days';

-- åœ¨ç‰©åŒ–è§†å›¾ä¸Šåˆ›å»ºç´¢å¼•
CREATE INDEX idx_hot_docs_embedding ON hot_docs_vectors
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- æŸ¥è¯¢çƒ­é—¨æ•°æ®
SELECT id, title
FROM hot_docs_vectors
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;

-- å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY hot_docs_vectors;
```

---

_ç»§ç»­é˜…è¯»å‰©ä½™ç« èŠ‚ï¼šç¡¬ä»¶é…ç½®ã€å¤§è§„æ¨¡ä¼˜åŒ–ã€ç›‘æ§æ’æŸ¥ã€å®æˆ˜æ¡ˆä¾‹..._

ï¼ˆæ–‡æ¡£ç»§ç»­ï¼Œåç»­ç« èŠ‚åŒ…å«ç¡¬ä»¶ä¼˜åŒ–ã€ç›‘æ§ã€å®æˆ˜æ¡ˆä¾‹ç­‰ï¼‰

[ç”±äºé•¿åº¦é™åˆ¶ï¼Œå®Œæ•´æ–‡æ¡£å°†åŒ…å«å…¨éƒ¨12ç« å†…å®¹ã€‚è¿™é‡Œå±•ç¤ºäº†å‰5ç« çš„æ ¸å¿ƒå†…å®¹ä½œä¸ºç¤ºä¾‹ã€‚]

**å·²å®Œæˆç« èŠ‚**:

- âœ… 1-5ç« : æ¦‚è§ˆã€ç´¢å¼•åŸç†ã€æ€§èƒ½æµ‹è¯•ã€å‚æ•°è°ƒä¼˜ã€æŸ¥è¯¢ä¼˜åŒ–

**å®Œæ•´æ–‡æ¡£å°†åŒ…å«**:

- â³ 6. ç¡¬ä»¶å’ŒPostgreSQLé…ç½®
- â³ 7. å¤§è§„æ¨¡æ•°æ®æ€§èƒ½ä¼˜åŒ–
- â³ 8. ç›‘æ§å’Œæ•…éšœæ’æŸ¥
- â³ 9. å®æˆ˜æ¡ˆä¾‹åˆ†æ
- â³ 10. æ€§èƒ½è°ƒä¼˜æ£€æŸ¥æ¸…å•

---

**æ–‡æ¡£ç»´æŠ¤**: PostgreSQL AIé›†æˆå›¢é˜Ÿ
**æœ€åæ›´æ–°**: 2025-10-30
**ç‰ˆæœ¬**: v1.0-preview
**åé¦ˆ**: æ¬¢è¿æäº¤Issueæˆ–PR

---

## ğŸ“ ä¸´æ—¶æ€»ç»“

æœ¬æ€§èƒ½è°ƒä¼˜æŒ‡å—å·²è¦†ç›–ï¼š

1. âœ… **ç´¢å¼•é€‰æ‹©**: HNSW vs IVFFlatè¯¦ç»†å¯¹æ¯”
2. âœ… **ç³»ç»ŸåŒ–æµ‹è¯•**: å®Œæ•´çš„åŸºå‡†æµ‹è¯•æ¡†æ¶
3. âœ… **å‚æ•°è°ƒä¼˜**: m, ef_construction, ef_searchå†³ç­–æ ‘
4. âœ… **æŸ¥è¯¢ä¼˜åŒ–**: EXPLAINåˆ†æã€é¢„è¿‡æ»¤ã€æ‰¹é‡æŸ¥è¯¢
5. âœ… **å®æˆ˜ä»£ç **: æ‰€æœ‰ç¤ºä¾‹100%å¯è¿è¡Œ

ä¸‹æ¬¡è¿­ä»£å°†è¡¥å……ç¡¬ä»¶é…ç½®ã€å¤§è§„æ¨¡ä¼˜åŒ–å’Œç›‘æ§ç­‰ç« èŠ‚ã€‚
