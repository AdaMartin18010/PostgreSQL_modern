# 性能问题-案例库

结构：问题 → 证据 → 变更 → 效果 → 防再发

## 案例1：估算偏差导致错误连接顺序

- 证据：`pg_stat_statements` TopN、EXPLAIN 显示 Seq Scan + 高回表；
- 变更：`SET STATISTICS 2000`、扩展统计（dependencies），新增表达式索引；
- 效果：P95 ↓ 45%，CPU 降低 20%；
- 防再发：定期 ANALYZE、新增字段变更纳入统计策略。

### 案例1详细展开

**问题描述**:

电商系统订单查询性能下降，P95延迟从200ms增加到800ms，CPU使用率从40%增加到70%。

**诊断过程**:

```sql
-- 步骤1: 识别慢查询
SELECT
    LEFT(query, 200) as query_preview,
    calls,
    mean_exec_time,
    max_exec_time,
    rows
FROM pg_stat_statements
WHERE mean_exec_time > 500
ORDER BY mean_exec_time DESC
LIMIT 5;

-- 结果：发现订单关联查询
-- SELECT o.*, u.name, p.name
-- FROM orders o
-- JOIN users u ON o.user_id = u.id
-- JOIN products p ON o.product_id = p.id
-- WHERE o.created_at >= '2024-01-01' AND o.status = 'pending'

-- 步骤2: 执行EXPLAIN分析
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT o.*, u.name, p.name
FROM orders o
JOIN users u ON o.user_id = u.id
JOIN products p ON o.product_id = p.id
WHERE o.created_at >= '2024-01-01' AND o.status = 'pending';

-- 问题发现：
-- - 优化器选择了错误的连接顺序（先连接products，导致大量回表）
-- - 估算行数：1000行（实际：50000行）
-- - 使用了Seq Scan而非Index Scan

-- 步骤3: 检查统计信息
SELECT
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation,
    most_common_vals,
    most_common_freqs
FROM pg_stats
WHERE tablename IN ('orders', 'users', 'products')
AND attname IN ('user_id', 'product_id', 'created_at', 'status');

-- 发现：orders表的created_at和status列统计信息不准确
```

**变更方案**:

```sql
-- 1. 提升统计信息精度
ALTER TABLE orders ALTER COLUMN created_at SET STATISTICS 2000;
ALTER TABLE orders ALTER COLUMN status SET STATISTICS 2000;

-- 2. 创建扩展统计（PostgreSQL 10+）
CREATE STATISTICS orders_created_status_dependencies
ON created_at, status
FROM orders;

-- 3. 更新统计信息
ANALYZE orders;

-- 4. 创建复合索引优化查询
CREATE INDEX CONCURRENTLY idx_orders_created_status
ON orders (created_at, status)
WHERE status = 'pending';

-- 5. 验证优化效果
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT o.*, u.name, p.name
FROM orders o
JOIN users u ON o.user_id = u.id
JOIN products p ON o.product_id = p.id
WHERE o.created_at >= '2024-01-01' AND o.status = 'pending';
-- 结果：使用Index Scan，连接顺序正确，执行时间从800ms降至150ms
```

**效果验证**:

```sql
-- 性能对比
-- 优化前：
-- - P95延迟：800ms
-- - CPU使用率：70%
-- - 缓冲区命中率：85%

-- 优化后：
-- - P95延迟：150ms（↓81%）
-- - CPU使用率：50%（↓29%）
-- - 缓冲区命中率：98%（↑15%）

-- 监控验证
SELECT
    LEFT(query, 200) as query_preview,
    calls,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
WHERE query LIKE '%orders%JOIN%users%JOIN%products%'
ORDER BY mean_exec_time DESC;
```

**防再发措施**:

```sql
-- 1. 定期ANALYZE（通过cron或pg_cron）
-- 每天凌晨2点执行
SELECT cron.schedule('analyze-orders', '0 2 * * *', 'ANALYZE orders;');

-- 2. 新增字段时自动设置统计精度
CREATE OR REPLACE FUNCTION set_column_statistics()
RETURNS TRIGGER AS $$
BEGIN
    -- 新字段自动设置统计精度
    EXECUTE format('ALTER TABLE %I ALTER COLUMN %I SET STATISTICS 2000',
                   TG_TABLE_NAME, NEW.column_name);
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- 3. 监控统计信息准确性
SELECT
    schemaname,
    tablename,
    last_analyze,
    last_autoanalyze,
    CASE
        WHEN last_analyze IS NULL AND last_autoanalyze IS NULL THEN 'Never analyzed'
        WHEN last_analyze > last_autoanalyze THEN last_analyze::text
        ELSE last_autoanalyze::text
    END as last_analyze_time
FROM pg_stat_user_tables
WHERE last_analyze < NOW() - interval '7 days'
OR last_autoanalyze < NOW() - interval '7 days';
```

## 案例2：锁等待链导致延迟尖刺

- 证据：`pg_locks` 未授予锁、长事务持锁；
- 变更：拆分 DDL、批量写序化、合理索引避免热点扫描；
- 效果：超时率从 2% 降至 0.1%；
- 防再发：锁等待告警、DDL 变更窗口审批。

### 案例2详细展开

**问题描述**:

系统在业务高峰期出现延迟尖刺，P99延迟从500ms突然增加到5秒，超时率从0.1%增加到2%，大量用户请求超时。

**诊断过程**:

```sql
-- 步骤1: 检查锁等待情况
SELECT
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS blocking_statement,
    blocked_locks.locktype,
    blocked_locks.mode,
    blocked_activity.query_start,
    now() - blocked_activity.query_start AS blocked_duration
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted
ORDER BY blocked_activity.query_start;

-- 发现：大量INSERT语句被阻塞，阻塞源是一个长时间运行的ALTER TABLE语句

-- 步骤2: 检查长事务
SELECT
    pid,
    usename,
    application_name,
    state,
    query_start,
    xact_start,
    now() - xact_start AS transaction_duration,
    query
FROM pg_stat_activity
WHERE state != 'idle'
AND now() - xact_start > interval '1 minute'
ORDER BY xact_start;

-- 发现：有一个ALTER TABLE ADD COLUMN语句已经运行了10分钟

-- 步骤3: 检查表锁
SELECT
    l.pid,
    l.mode,
    l.locktype,
    l.relation::regclass,
    a.query,
    a.query_start,
    age(now(), a.query_start) AS age
FROM pg_locks l
JOIN pg_stat_activity a ON l.pid = a.pid
WHERE l.locktype = 'relation'
AND l.mode LIKE '%ExclusiveLock%'
ORDER BY a.query_start;
```

**变更方案**:

```sql
-- 1. 立即终止阻塞的DDL操作（如果允许）
SELECT pg_terminate_backend(blocking_pid)
FROM (
    SELECT DISTINCT blocking_locks.pid AS blocking_pid
    FROM pg_catalog.pg_locks blocked_locks
    JOIN pg_catalog.pg_locks blocking_locks
        ON blocking_locks.locktype = blocked_locks.locktype
        AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
        AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
        AND blocking_locks.pid != blocked_locks.pid
    WHERE NOT blocked_locks.granted
) t;

-- 2. 使用CONCURRENTLY选项重建DDL（避免锁表）
-- 原DDL：ALTER TABLE orders ADD COLUMN new_field VARCHAR(100);
-- 改为：使用ALTER TABLE ... ADD COLUMN ... NOT NULL DEFAULT ...（PostgreSQL 11+）
-- 或者：分步骤执行

-- 步骤1: 添加可空列（快速，不锁表）
ALTER TABLE orders ADD COLUMN new_field VARCHAR(100);

-- 步骤2: 批量更新默认值（在低峰期）
UPDATE orders SET new_field = 'default_value' WHERE new_field IS NULL;

-- 步骤3: 设置NOT NULL约束（需要锁表，但时间短）
ALTER TABLE orders ALTER COLUMN new_field SET NOT NULL;

-- 3. 优化批量写入（避免热点）
-- 原代码：单条INSERT
-- INSERT INTO orders (user_id, product_id, amount) VALUES (?, ?, ?);

-- 优化：批量INSERT，使用事务
BEGIN;
INSERT INTO orders (user_id, product_id, amount) VALUES
    (?, ?, ?), (?, ?, ?), (?, ?, ?), ...;
COMMIT;

-- 4. 创建合理索引避免热点扫描
-- 检查热点索引
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan > 1000000
ORDER BY idx_scan DESC;

-- 如果发现顺序插入导致B-tree热点，考虑：
-- - 使用fillfactor减少页面分裂
ALTER TABLE orders SET (fillfactor = 90);

-- - 或使用哈希分布（如果适用）
```

**效果验证**:

```sql
-- 优化前：
-- - P99延迟：5秒
-- - 超时率：2%
-- - 锁等待数：50+

-- 优化后：
-- - P99延迟：300ms（↓94%）
-- - 超时率：0.05%（↓97%）
-- - 锁等待数：<5

-- 监控验证
SELECT
    COUNT(*) as lock_waits,
    MAX(now() - query_start) as max_wait_time
FROM pg_stat_activity
WHERE wait_event_type = 'Lock';
```

**防再发措施**:

```sql
-- 1. 锁等待告警（Prometheus）
-- alert: PostgreSQLLockWaits
-- expr: count(pg_stat_activity{wait_event_type="Lock"}) > 10
-- for: 2m

-- 2. DDL变更审批流程
-- - 所有DDL变更必须在低峰期执行
-- - 使用CONCURRENTLY选项（如果支持）
-- - 提前通知业务方

-- 3. 长事务监控
SELECT
    pid,
    usename,
    application_name,
    now() - xact_start AS transaction_duration,
    query
FROM pg_stat_activity
WHERE state != 'idle'
AND now() - xact_start > interval '5 minutes'
ORDER BY xact_start;
```

## 案例3：检查点过于频繁

- 证据：`log_checkpoints`、WAL 暴涨、延迟尖刺；
- 变更：提升 `max_wal_size`、`checkpoint_timeout`、`checkpoint_completion_target`；
- 效果：P95 稳定，磁盘写突刺降低；
- 防再发：阈值告警与容量规划。

### 案例3详细展开

**问题描述**:

系统在高峰期出现周期性延迟尖刺，每5-10分钟出现一次，P95延迟从200ms突然增加到2秒，持续时间1-2分钟。检查日志发现检查点非常频繁。

**诊断过程**:

```sql
-- 步骤1: 检查检查点统计
SELECT
    checkpoints_timed,
    checkpoints_req,
    checkpoint_write_time,
    checkpoint_sync_time,
    buffers_checkpoint,
    buffers_clean,
    buffers_backend,
    stats_reset,
    round(extract(epoch from now() - stats_reset) /
          NULLIF(checkpoints_timed + checkpoints_req, 0) / 60, 2) as avg_interval_minutes
FROM pg_stat_bgwriter;

-- 发现：
-- - checkpoints_req（请求检查点）数量很多，说明WAL大小频繁达到max_wal_size
-- - 平均检查点间隔：3-5分钟（正常应该是15分钟以上）

-- 步骤2: 检查WAL大小和写入速率
SELECT
    pg_size_pretty(pg_current_wal_lsn() - '0/0') as current_wal_size,
    pg_size_pretty(pg_walfile_name_offset(pg_current_wal_lsn())) as current_wal_file;

-- 查看WAL写入统计
SELECT
    wal_records,
    wal_write,
    wal_sync,
    wal_bytes,
    wal_write_time,
    wal_sync_time
FROM pg_stat_wal;

-- 步骤3: 检查当前配置
SELECT name, setting, unit, context
FROM pg_settings
WHERE name IN (
    'checkpoint_timeout',
    'max_wal_size',
    'min_wal_size',
    'checkpoint_completion_target',
    'wal_buffers'
);

-- 发现：
-- - max_wal_size = 1GB（太小，对于高写入负载）
-- - checkpoint_timeout = 5min（默认值，可以增加）
-- - checkpoint_completion_target = 0.9（正常）
```

**变更方案**:

```sql
-- 1. 增加max_wal_size（允许更大的WAL）
ALTER SYSTEM SET max_wal_size = '4GB';  -- 从1GB增加到4GB

-- 2. 增加checkpoint_timeout（延长检查点间隔）
ALTER SYSTEM SET checkpoint_timeout = '15min';  -- 从5min增加到15min

-- 3. 增加wal_buffers（减少WAL写入频率）
ALTER SYSTEM SET wal_buffers = '32MB';  -- 从16MB增加到32MB

-- 4. 启用WAL压缩（减少WAL大小）
ALTER SYSTEM SET wal_compression = on;

-- 5. 重新加载配置（某些参数需要重启）
SELECT pg_reload_conf();

-- 注意：max_wal_size和checkpoint_timeout的变更需要重启才能生效
-- 在低峰期执行重启
```

**效果验证**:

```sql
-- 优化前：
-- - 检查点频率：每3-5分钟一次
-- - P95延迟：周期性尖刺到2秒
-- - 磁盘I/O：检查点期间写突刺

-- 优化后：
-- - 检查点频率：每15-20分钟一次
-- - P95延迟：稳定在200-300ms
-- - 磁盘I/O：平滑写入

-- 监控验证
SELECT
    checkpoints_timed,
    checkpoints_req,
    round(extract(epoch from now() - stats_reset) /
          NULLIF(checkpoints_timed + checkpoints_req, 0) / 60, 2) as avg_interval_minutes,
    round((checkpoint_write_time + checkpoint_sync_time) / 1000.0, 2) as total_checkpoint_time_sec
FROM pg_stat_bgwriter;

-- 检查点请求比例（应该<50%）
SELECT
    round(100.0 * checkpoints_req / NULLIF(checkpoints_timed + checkpoints_req, 0), 2) as req_ratio
FROM pg_stat_bgwriter;
-- req_ratio > 50% 表示需要进一步增加max_wal_size
```

**防再发措施**:

```sql
-- 1. 检查点频率告警
-- Prometheus告警规则
-- alert: PostgreSQLFrequentCheckpoints
-- expr: (rate(pg_stat_bgwriter_checkpoints_timed[5m]) +
--        rate(pg_stat_bgwriter_checkpoints_req[5m])) > 0.1
-- for: 10m

-- 2. WAL大小监控
SELECT
    pg_size_pretty(pg_current_wal_lsn() - '0/0') as current_wal_size,
    (SELECT setting FROM pg_settings WHERE name = 'max_wal_size')::bigint * 1024 * 1024 as max_wal_size_bytes,
    round(100.0 * (pg_current_wal_lsn() - '0/0') /
          ((SELECT setting FROM pg_settings WHERE name = 'max_wal_size')::bigint * 1024 * 1024), 2) as wal_usage_pct;

-- 3. 容量规划
-- 根据写入负载计算合适的max_wal_size
-- 公式：max_wal_size = 写入速率(MB/s) * checkpoint_timeout(秒) * 2（安全系数）
-- 示例：写入速率50MB/s，checkpoint_timeout=15min=900秒
-- max_wal_size = 50 * 900 * 2 / 1024 ≈ 88GB（实际设置4-8GB通常足够）
```

## 案例4：分区裁剪不生效

- 证据：计划显示扫描所有分区；谓词非分区键表达式；
- 变更：改写谓词使可裁剪、增加分区键冗余列或生成列；
- 效果：计划时间下降，I/O 显著降低；
- 防再发：分区设计评审与查询规范。

### 案例4详细展开

**问题描述**:

日志表按月份分区，查询最近7天的日志时，执行计划显示扫描了所有分区（12个月），查询时间从预期的几秒增加到几分钟。

**诊断过程**:

```sql
-- 步骤1: 检查分区表结构
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE tablename LIKE 'log_entries_%'
ORDER BY tablename;

-- 步骤2: 执行查询并查看执行计划
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM log_entries
WHERE DATE_TRUNC('month', log_time) = DATE_TRUNC('month', CURRENT_DATE);

-- 问题发现：
-- - 执行计划显示：Seq Scan on log_entries_2024_01, Seq Scan on log_entries_2024_02, ...
-- - 扫描了所有12个分区
-- - 实际只需要扫描1-2个分区

-- 步骤3: 检查分区键和约束
SELECT
    n.nspname as schema_name,
    c.relname as table_name,
    pg_get_expr(c.relpartbound, c.oid) as partition_bound
FROM pg_class c
JOIN pg_namespace n ON n.oid = c.relnamespace
WHERE c.relispartition = true
AND c.relname LIKE 'log_entries_%'
ORDER BY c.relname;

-- 步骤4: 检查查询谓词
-- 问题：使用了DATE_TRUNC函数，优化器无法识别分区键范围
```

**变更方案**:

```sql
-- 方案1: 改写查询谓词（推荐）
-- 原查询（无法裁剪）：
SELECT * FROM log_entries
WHERE DATE_TRUNC('month', log_time) = DATE_TRUNC('month', CURRENT_DATE);

-- 优化查询（可以裁剪）：
SELECT * FROM log_entries
WHERE log_time >= DATE_TRUNC('month', CURRENT_DATE)
AND log_time < DATE_TRUNC('month', CURRENT_DATE) + interval '1 month';

-- 方案2: 使用生成列（PostgreSQL 12+）
-- 添加生成列存储月份
ALTER TABLE log_entries ADD COLUMN log_month DATE
GENERATED ALWAYS AS (DATE_TRUNC('month', log_time)::DATE) STORED;

-- 按生成列分区
CREATE TABLE log_entries_new (
    LIKE log_entries INCLUDING ALL
) PARTITION BY RANGE (log_month);

-- 迁移数据后切换表

-- 方案3: 使用冗余列（如果无法使用生成列）
ALTER TABLE log_entries ADD COLUMN log_month DATE;
UPDATE log_entries SET log_month = DATE_TRUNC('month', log_time)::DATE;
CREATE INDEX idx_log_entries_month ON log_entries (log_month);

-- 查询时使用冗余列
SELECT * FROM log_entries
WHERE log_month = DATE_TRUNC('month', CURRENT_DATE)::DATE;
```

**效果验证**:

```sql
-- 优化前：
-- - 扫描分区数：12个
-- - 执行时间：120秒
-- - I/O读取：50GB

-- 优化后：
-- - 扫描分区数：1-2个（只扫描相关月份）
-- - 执行时间：5秒（↓96%）
-- - I/O读取：4GB（↓92%）

-- 验证分区裁剪
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM log_entries
WHERE log_time >= CURRENT_DATE - interval '7 days'
AND log_time < CURRENT_DATE;
-- 应该只显示相关分区的扫描
```

**防再发措施**:

```sql
-- 1. 分区设计评审清单
-- - 分区键选择：使用常用查询条件的列
-- - 避免在分区键上使用函数
-- - 使用范围分区而非列表分区（如果适用）

-- 2. 查询规范
-- - 避免在WHERE子句中对分区键使用函数
-- - 使用范围查询而非函数调用
-- - 示例：
--   错误：WHERE DATE_TRUNC('month', log_time) = ...
--   正确：WHERE log_time >= ... AND log_time < ...

-- 3. 监控分区裁剪
-- 检查执行计划是否使用了分区裁剪
SELECT
    schemaname,
    tablename,
    seq_scan,
    idx_scan
FROM pg_stat_user_tables
WHERE tablename LIKE 'log_entries_%'
ORDER BY seq_scan DESC;
-- 如果所有分区都有seq_scan，说明分区裁剪可能不生效
```

## 案例5：统计信息缺失导致Bitmap堆低效

- 证据：估算偏差、Bitmap Heap Recheck 过多；
- 变更：提升 `default_statistics_target`，针对列设置更高统计；
- 效果：回表减少，P95 下降；
- 防再发：批量导入后 ANALYZE、定期统计维护。

### 案例5详细展开

**问题描述**:

用户表查询性能下降，EXPLAIN显示大量"Bitmap Heap Recheck"，实际执行时间比估算时间高10倍以上。

**诊断过程**:

```sql
-- 步骤1: 执行查询并查看执行计划
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM users
WHERE age BETWEEN 25 AND 35
AND city = 'Beijing'
AND status = 'active';

-- 问题发现：
-- - 使用Bitmap Index Scan + Bitmap Heap Scan
-- - Bitmap Heap Recheck: 50000 rows（大量回表）
-- - 估算行数：5000行（实际：50000行，偏差10倍）

-- 步骤2: 检查统计信息
SELECT
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation,
    most_common_vals,
    most_common_freqs,
    histogram_bounds
FROM pg_stats
WHERE tablename = 'users'
AND attname IN ('age', 'city', 'status');

-- 发现：
-- - age列：n_distinct = -1（表示唯一值很多），但直方图不够详细
-- - city列：most_common_vals只有10个值（实际有100+城市）
-- - 统计信息不够详细，导致估算偏差

-- 步骤3: 检查统计信息目标
SELECT
    schemaname,
    tablename,
    attname,
    attstattarget
FROM pg_attribute a
JOIN pg_class c ON a.attrelid = c.oid
JOIN pg_namespace n ON c.relnamespace = n.oid
WHERE c.relname = 'users'
AND a.attname IN ('age', 'city', 'status')
AND a.attnum > 0;

-- 发现：attstattarget = -1（使用默认值100），对于大表不够
```

**变更方案**:

```sql
-- 1. 提升默认统计信息目标
ALTER SYSTEM SET default_statistics_target = 500;  -- 从100增加到500
SELECT pg_reload_conf();

-- 2. 针对特定列设置更高统计精度
ALTER TABLE users ALTER COLUMN age SET STATISTICS 1000;
ALTER TABLE users ALTER COLUMN city SET STATISTICS 500;
ALTER TABLE users ALTER COLUMN status SET STATISTICS 200;

-- 3. 创建扩展统计（PostgreSQL 10+）
-- 对于多列组合查询，创建扩展统计
CREATE STATISTICS users_age_city_dependencies
ON age, city
FROM users;

CREATE STATISTICS users_city_status_dependencies
ON city, status
FROM users;

-- 4. 更新统计信息
ANALYZE users;

-- 5. 验证统计信息更新
SELECT
    schemaname,
    tablename,
    attname,
    n_distinct,
    array_length(most_common_vals, 1) as mcv_count,
    array_length(histogram_bounds, 1) as histogram_buckets
FROM pg_stats
WHERE tablename = 'users'
AND attname IN ('age', 'city', 'status');
```

**效果验证**:

```sql
-- 优化前：
-- - 估算行数：5000行
-- - 实际行数：50000行
-- - Bitmap Heap Recheck：50000行
-- - 执行时间：2秒

-- 优化后：
-- - 估算行数：48000行（更准确）
-- - 实际行数：50000行
-- - Bitmap Heap Recheck：50000行（但优化器选择了更好的计划）
-- - 执行时间：0.5秒（↓75%）

-- 验证执行计划
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM users
WHERE age BETWEEN 25 AND 35
AND city = 'Beijing'
AND status = 'active';
-- 应该看到更准确的估算和更好的执行计划
```

**防再发措施**:

```sql
-- 1. 批量导入后自动ANALYZE
-- 在导入脚本中添加
COPY users FROM '/path/to/users.csv' WITH (FORMAT csv, HEADER);
ANALYZE users;

-- 或使用pg_cron定期ANALYZE
SELECT cron.schedule('analyze-users', '0 3 * * *', 'ANALYZE users;');

-- 2. 监控统计信息时效性
SELECT
    schemaname,
    tablename,
    last_analyze,
    last_autoanalyze,
    n_live_tup,
    n_mod_since_analyze,
    round(100.0 * n_mod_since_analyze / NULLIF(n_live_tup, 0), 2) as mod_ratio
FROM pg_stat_user_tables
WHERE n_mod_since_analyze > n_live_tup * 0.1  -- 变更超过10%
ORDER BY mod_ratio DESC;

-- 3. 统计信息告警
-- Prometheus告警：表统计信息超过7天未更新
-- alert: PostgreSQLStaleStatistics
-- expr: (now() - pg_stat_user_tables_last_autoanalyze) > 7d
```

## 案例6：RLS 策略误配影响计划

- 证据：每次访问附带复杂策略过滤，计划变慢；
- 变更：优化策略为可索引谓词，必要时策略分层或绕过只读报表；
- 效果：TP95 明显下降；
- 防再发：RLS 变更评审与计划对比。

### 案例6详细展开

**问题描述**:

多租户系统启用RLS（Row Level Security）后，查询性能显著下降，P95延迟从100ms增加到800ms。所有查询都变慢，即使简单的SELECT查询。

**诊断过程**:

```sql
-- 步骤1: 检查RLS策略
SELECT
    schemaname,
    tablename,
    policyname,
    permissive,
    roles,
    cmd,
    qual,
    with_check
FROM pg_policies
WHERE tablename = 'orders';

-- 发现：策略使用了复杂的子查询和函数调用
-- CREATE POLICY tenant_isolation ON orders
-- FOR ALL
-- TO application_role
-- USING (
--     tenant_id IN (
--         SELECT tenant_id FROM user_tenants
--         WHERE user_id = current_setting('app.user_id')::integer
--     )
-- );

-- 步骤2: 执行查询并查看执行计划
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM orders WHERE order_date >= CURRENT_DATE - interval '7 days';

-- 问题发现：
-- - 执行计划包含SubPlan（子查询计划）
-- - 每次扫描行都要执行子查询
-- - 无法使用索引优化

-- 步骤3: 检查策略对性能的影响
SET row_security = on;
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM orders LIMIT 100;

SET row_security = off;
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM orders LIMIT 100;
-- 对比执行时间差异
```

**变更方案**:

```sql
-- 方案1: 优化策略为可索引谓词（推荐）
-- 原策略（复杂子查询）：
DROP POLICY IF EXISTS tenant_isolation ON orders;
CREATE POLICY tenant_isolation ON orders
FOR ALL
TO application_role
USING (tenant_id = current_setting('app.tenant_id')::integer);
-- 使用简单的等值比较，可以创建索引

-- 创建索引支持策略
CREATE INDEX idx_orders_tenant_id ON orders (tenant_id);

-- 方案2: 使用函数返回租户列表（如果必须支持多租户）
CREATE OR REPLACE FUNCTION get_user_tenants()
RETURNS TABLE(tenant_id integer) AS $$
BEGIN
    RETURN QUERY
    SELECT ut.tenant_id
    FROM user_tenants ut
    WHERE ut.user_id = current_setting('app.user_id')::integer;
END;
$$ LANGUAGE plpgsql STABLE;

-- 优化策略
DROP POLICY IF EXISTS tenant_isolation ON orders;
CREATE POLICY tenant_isolation ON orders
FOR ALL
TO application_role
USING (tenant_id = ANY(get_user_tenants()));
-- STABLE函数可以更好地优化

-- 方案3: 策略分层（只读报表使用不同策略）
-- 为只读报表创建专用策略
CREATE POLICY tenant_isolation_readonly ON orders
FOR SELECT
TO readonly_role
USING (tenant_id = current_setting('app.tenant_id')::integer);

-- 方案4: 绕过RLS（仅用于只读报表，谨慎使用）
-- 创建绕过RLS的视图
CREATE VIEW orders_readonly AS
SELECT * FROM orders;

-- 授予只读角色访问视图（不应用RLS）
GRANT SELECT ON orders_readonly TO readonly_role;
```

**效果验证**:

```sql
-- 优化前：
-- - P95延迟：800ms
-- - 执行计划：包含SubPlan，无法使用索引
-- - CPU使用率：高（每次行都要执行子查询）

-- 优化后：
-- - P95延迟：120ms（↓85%）
-- - 执行计划：使用Index Scan
-- - CPU使用率：正常

-- 验证执行计划
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM orders WHERE order_date >= CURRENT_DATE - interval '7 days';
-- 应该看到Index Scan而非Seq Scan + SubPlan
```

**防再发措施**:

```sql
-- 1. RLS策略评审清单
-- - 避免在策略中使用子查询
-- - 使用简单的等值或范围比较
-- - 确保策略条件可以创建索引
-- - 使用STABLE函数而非VOLATILE函数

-- 2. 策略变更前后对比执行计划
-- 变更前记录
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM orders LIMIT 100;

-- 变更后对比
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM orders LIMIT 100;

-- 3. 监控RLS性能影响
SELECT
    schemaname,
    tablename,
    seq_scan,
    idx_scan,
    n_tup_ins,
    n_tup_upd,
    n_tup_del
FROM pg_stat_user_tables
WHERE tablename = 'orders';
-- 如果seq_scan显著增加，可能是RLS策略影响
```

## 案例7：外键缺索引导致写放大

- 证据：插入/更新外键行时阻塞与全表扫描；
- 变更：为外键列补充索引；
- 效果：写延迟下降，锁等待减少；
- 防再发：DDL 审计规则强制外键建索引。

### 案例7详细展开

**问题描述**:

订单表插入性能下降，特别是在高峰期，插入延迟从10ms增加到500ms。同时出现锁等待，影响其他查询。

**诊断过程**:

```sql
-- 步骤1: 检查表结构
SELECT
    tc.table_name,
    kcu.column_name,
    ccu.table_name AS foreign_table_name,
    ccu.column_name AS foreign_column_name
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
    ON tc.constraint_name = kcu.constraint_name
    AND tc.table_schema = kcu.table_schema
JOIN information_schema.constraint_column_usage AS ccu
    ON ccu.constraint_name = tc.constraint_name
    AND ccu.table_schema = tc.table_schema
WHERE tc.constraint_type = 'FOREIGN KEY'
AND tc.table_name = 'orders';

-- 发现：orders表有外键约束
-- - user_id REFERENCES users(id)
-- - product_id REFERENCES products(id)

-- 步骤2: 检查外键列是否有索引
SELECT
    t.relname AS table_name,
    a.attname AS column_name,
    i.relname AS index_name
FROM pg_class t
JOIN pg_attribute a ON a.attrelid = t.oid
LEFT JOIN pg_index ix ON ix.indrelid = t.oid AND a.attnum = ANY(ix.indkey)
LEFT JOIN pg_class i ON i.oid = ix.indexrelid
WHERE t.relname = 'orders'
AND a.attname IN ('user_id', 'product_id')
AND a.attnum > 0;

-- 发现：外键列没有索引

-- 步骤3: 检查插入性能
EXPLAIN (ANALYZE, BUFFERS)
INSERT INTO orders (user_id, product_id, amount, order_date)
VALUES (100, 200, 99.99, NOW());

-- 问题发现：
-- - 插入时需要检查外键约束
-- - 由于没有索引，需要全表扫描users和products表
-- - 导致锁等待和性能下降

-- 步骤4: 检查锁等待
SELECT
    blocked_locks.pid AS blocked_pid,
    blocked_activity.query AS blocked_query,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.query AS blocking_query
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

**变更方案**:

```sql
-- 1. 为外键列创建索引
CREATE INDEX CONCURRENTLY idx_orders_user_id ON orders (user_id);
CREATE INDEX CONCURRENTLY idx_orders_product_id ON orders (product_id);

-- 2. 验证索引创建
SELECT
    schemaname,
    tablename,
    indexname,
    indexdef
FROM pg_indexes
WHERE tablename = 'orders'
AND indexname LIKE 'idx_orders_%';

-- 3. 如果外键列经常一起查询，创建复合索引
CREATE INDEX CONCURRENTLY idx_orders_user_product
ON orders (user_id, product_id);
```

**效果验证**:

```sql
-- 优化前：
-- - 插入延迟：500ms
-- - 锁等待：频繁
-- - 外键检查：全表扫描

-- 优化后：
-- - 插入延迟：15ms（↓97%）
-- - 锁等待：显著减少
-- - 外键检查：索引扫描

-- 验证插入性能
EXPLAIN (ANALYZE, BUFFERS)
INSERT INTO orders (user_id, product_id, amount, order_date)
VALUES (100, 200, 99.99, NOW());
-- 应该看到Index Scan而非Seq Scan
```

**防再发措施**:

```sql
-- 1. DDL审计规则（使用触发器或扩展）
-- 检查新创建的外键是否有索引
CREATE OR REPLACE FUNCTION check_foreign_key_index()
RETURNS TRIGGER AS $$
DECLARE
    fk_record RECORD;
    index_exists BOOLEAN;
BEGIN
    -- 检查所有外键约束
    FOR fk_record IN
        SELECT
            tc.table_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage AS ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY'
        AND tc.table_schema = 'public'
    LOOP
        -- 检查是否有索引
        SELECT EXISTS (
            SELECT 1
            FROM pg_indexes
            WHERE tablename = fk_record.table_name
            AND indexdef LIKE '%' || fk_record.column_name || '%'
        ) INTO index_exists;

        IF NOT index_exists THEN
            RAISE WARNING 'Foreign key % on %(%) missing index',
                fk_record.table_name,
                fk_record.column_name,
                fk_record.foreign_table_name;
        END IF;
    END LOOP;

    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- 2. 定期检查外键索引
SELECT
    tc.table_name,
    kcu.column_name,
    CASE
        WHEN EXISTS (
            SELECT 1
            FROM pg_indexes
            WHERE tablename = tc.table_name
            AND indexdef LIKE '%' || kcu.column_name || '%'
        ) THEN 'HAS INDEX'
        ELSE 'MISSING INDEX'
    END as index_status
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
    ON tc.constraint_name = kcu.constraint_name
WHERE tc.constraint_type = 'FOREIGN KEY'
AND tc.table_schema = 'public';
```

## 案例8：顺序键插入热点页导致B-Tree分裂

- 证据：插入热点集中，索引分裂与页抖动；
- 变更：使用 `fillfactor`、反转ID或哈希分布、分区；
- 效果：写抖动下降；
- 防再发：建模阶段评审自增/顺序键策略。

### 案例8详细展开

**问题描述**:

使用自增ID作为主键的订单表，在高并发写入时出现性能抖动，插入延迟从5ms周期性增加到200ms，I/O使用率出现尖刺。

**诊断过程**:

```sql
-- 步骤1: 检查表结构
SELECT
    c.relname,
    a.attname,
    a.attnum,
    CASE
        WHEN a.attnum = (SELECT indkey[1] FROM pg_index WHERE indrelid = c.oid AND indisprimary)
        THEN 'PRIMARY KEY'
        ELSE 'NOT PK'
    END as is_pk
FROM pg_class c
JOIN pg_attribute a ON a.attrelid = c.oid
WHERE c.relname = 'orders'
AND a.attnum > 0
AND NOT a.attisdropped;

-- 发现：使用BIGSERIAL（自增）作为主键

-- 步骤2: 检查索引结构
SELECT
    schemaname,
    tablename,
    indexname,
    indexdef
FROM pg_indexes
WHERE tablename = 'orders'
AND indexname LIKE '%_pkey';

-- 步骤3: 检查插入模式
SELECT
    COUNT(*) as total_inserts,
    MIN(id) as min_id,
    MAX(id) as max_id,
    MAX(id) - MIN(id) as id_range
FROM orders
WHERE created_at >= CURRENT_DATE;

-- 发现：ID是严格递增的，所有插入都集中在索引的右侧（热点页）

-- 步骤4: 检查I/O和锁等待
SELECT
    wait_event_type,
    wait_event,
    COUNT(*) as count
FROM pg_stat_activity
WHERE wait_event IS NOT NULL
GROUP BY wait_event_type, wait_event
ORDER BY count DESC;

-- 发现：大量I/O等待和B-tree页面分裂
```

**变更方案**:

```sql
-- 方案1: 使用fillfactor减少页面分裂（推荐，简单）
ALTER TABLE orders SET (fillfactor = 90);  -- 预留10%空间
-- 需要重建表才能生效
CLUSTER orders USING orders_pkey;

-- 方案2: 使用UUID替代自增ID（如果业务允许）
-- 创建新表使用UUID
CREATE TABLE orders_new (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    -- 其他列...
) WITH (fillfactor = 90);

-- 方案3: 使用反向ID（PostgreSQL特有技巧）
-- 将自增ID反转存储
CREATE TABLE orders_new (
    id BIGSERIAL PRIMARY KEY,
    reversed_id BIGINT GENERATED ALWAYS AS ((-id)) STORED,
    -- 其他列...
);

-- 在reversed_id上创建索引用于查询
CREATE INDEX idx_orders_reversed_id ON orders_new (reversed_id);

-- 方案4: 使用哈希分布（如果查询模式允许）
-- 使用哈希函数分散插入
CREATE TABLE orders_new (
    id BIGSERIAL,
    hash_id INTEGER GENERATED ALWAYS AS (hashtext(id::text) % 1000) STORED,
    PRIMARY KEY (id, hash_id)
) PARTITION BY HASH (hash_id);

-- 方案5: 使用时间分区（如果查询按时间范围）
CREATE TABLE orders_new (
    id BIGSERIAL,
    created_at TIMESTAMP NOT NULL,
    -- 其他列...
) PARTITION BY RANGE (created_at);

-- 按月分区，分散写入热点
CREATE TABLE orders_2024_01 PARTITION OF orders_new
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

**效果验证**:

```sql
-- 优化前：
-- - 插入延迟：周期性5-200ms
-- - I/O使用率：周期性尖刺
-- - 索引分裂：频繁

-- 优化后（使用fillfactor）：
-- - 插入延迟：稳定在5-10ms
-- - I/O使用率：平滑
-- - 索引分裂：减少

-- 验证插入性能
EXPLAIN (ANALYZE, BUFFERS)
INSERT INTO orders (user_id, product_id, amount, order_date)
VALUES (100, 200, 99.99, NOW());
```

**防再发措施**:

```sql
-- 1. 建模阶段评审清单
-- - 评估是否需要自增ID
-- - 考虑使用UUID（如果分布式系统）
-- - 考虑使用时间分区分散写入
-- - 评估fillfactor设置

-- 2. 监控插入热点
SELECT
    schemaname,
    tablename,
    n_tup_ins,
    n_tup_upd,
    n_tup_del,
    last_vacuum,
    last_autovacuum
FROM pg_stat_user_tables
WHERE n_tup_ins > 1000000  -- 高插入负载
ORDER BY n_tup_ins DESC;

-- 3. 检查索引膨胀（热点写入导致）
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexname::regclass)) as index_size,
    pg_size_pretty(pg_relation_size(tablename::regclass)) as table_size,
    round(100.0 * pg_relation_size(indexname::regclass) /
          NULLIF(pg_relation_size(tablename::regclass), 0), 2) as size_ratio
FROM pg_indexes
WHERE tablename = 'orders'
ORDER BY pg_relation_size(indexname::regclass) DESC;
```

---

## 案例总结与索引

### 问题类型索引

| 案例 | 问题类型 | 主要症状 | 关键指标 | 解决策略 |
|------|---------|---------|---------|---------|
| 案例1 | 估算偏差 | 错误连接顺序、Seq Scan | P95延迟↑、CPU使用率↑ | 提升统计精度、扩展统计、表达式索引 |
| 案例2 | 锁等待链 | 延迟尖刺、超时率↑ | P99延迟↑、锁等待数↑ | 拆分DDL、批量写序化、合理索引 |
| 案例3 | 检查点频繁 | I/O抖动、WAL积压 | 检查点频率↑、I/O等待↑ | 调整checkpoint参数、优化WAL配置 |
| 案例4 | 分区裁剪失效 | 全表扫描、查询慢 | 扫描行数↑、执行时间↑ | 修复分区键、优化查询条件 |
| 案例5 | 统计信息缺失 | Bitmap堆低效 | 缓冲区命中率↓、I/O↑ | 更新统计信息、创建索引 |
| 案例6 | RLS策略误配 | 计划缓存失效 | 计划时间↑、执行时间↑ | 优化RLS策略、使用稳定函数 |
| 案例7 | 外键缺索引 | 写放大、锁竞争 | 插入延迟↑、锁等待↑ | 在外键列创建索引 |
| 案例8 | 顺序键热点 | 插入抖动、I/O尖刺 | 插入延迟周期性↑、I/O尖刺 | fillfactor、UUID、反向ID、分区 |

### 诊断工具索引

| 工具/视图 | 用途 | 适用案例 |
|----------|------|---------|
| `pg_stat_statements` | 慢查询识别 | 案例1, 案例2, 案例4, 案例5 |
| `EXPLAIN (ANALYZE, BUFFERS)` | 执行计划分析 | 案例1, 案例4, 案例5, 案例6 |
| `pg_locks` | 锁等待分析 | 案例2, 案例7 |
| `pg_stat_archiver` | 归档状态检查 | 案例3 |
| `pg_stat_bgwriter` | 检查点统计 | 案例3 |
| `pg_stats` | 统计信息检查 | 案例1, 案例5 |
| `pg_stat_user_tables` | 表统计信息 | 案例1, 案例5, 案例8 |
| `pg_stat_activity` | 活动会话监控 | 案例2, 案例7, 案例8 |

### 优化策略索引

| 策略 | 适用场景 | 案例 |
|------|---------|------|
| 提升统计精度 | 估算偏差、基数错误 | 案例1, 案例5 |
| 扩展统计 | 多列相关性、连接顺序错误 | 案例1 |
| 表达式索引 | 函数查询、部分索引 | 案例1, 案例4 |
| 拆分DDL | 锁等待、长事务 | 案例2 |
| 批量写序化 | 锁竞争、死锁 | 案例2 |
| 调整checkpoint参数 | 检查点频繁、I/O抖动 | 案例3 |
| 修复分区键 | 分区裁剪失效 | 案例4 |
| 外键索引 | 外键约束、写放大 | 案例7 |
| fillfactor | 顺序键热点、页面分裂 | 案例8 |
| UUID/反向ID | 分布式系统、热点分散 | 案例8 |

### 防再发措施索引

| 措施 | 适用案例 | 实施方法 |
|------|---------|---------|
| 定期ANALYZE | 案例1, 案例5 | pg_cron定时任务 |
| 统计信息监控 | 案例1, 案例5 | 监控视图、告警规则 |
| 锁等待告警 | 案例2, 案例7 | Prometheus告警 |
| DDL变更窗口 | 案例2 | 变更管理流程 |
| 检查点监控 | 案例3 | Grafana面板 |
| 分区键审查 | 案例4 | 设计评审 |
| RLS策略审查 | 案例6 | 安全策略评审 |
| 外键索引检查 | 案例7 | 自动化检查脚本 |
| 热点监控 | 案例8 | 插入模式分析 |

---

## 交叉引用

### 相关文档

- ⭐⭐⭐ [监控与诊断](./06.01-监控与诊断.md) - 监控指标和诊断流程
- ⭐⭐⭐ [监控与诊断落地指南](./06.02-监控与诊断落地指南.md) - Prometheus + Grafana部署
- ⭐⭐⭐ [性能调优变更闭环](./06.03-性能调优变更闭环.md) - 变更管理流程
- ⭐⭐ [执行计划与性能调优](../../03-查询与优化/02.04-执行计划与性能调优.md) - 查询优化
- ⭐⭐ [索引结构与优化](../../03-查询与优化/02.02-索引结构与优化.md) - 索引优化
- ⭐⭐ [统计信息与代价模型](../../03-查询与优化/02.03-统计信息与代价模型.md) - 统计信息
- ⭐⭐ [性能调优实践](../../05-部署架构/单机部署/05.02-性能调优实践.md) - 性能调优指南

### 外部资源

- [PostgreSQL性能调优指南](https://www.postgresql.org/docs/current/performance-tips.html)
- [pg_stat_statements文档](https://www.postgresql.org/docs/current/pgstatstatements.html)
- [PostgreSQL锁文档](https://www.postgresql.org/docs/current/explicit-locking.html)
- [PostgreSQL分区文档](https://www.postgresql.org/docs/current/ddl-partitioning.html)

---

**文档版本**: v1.0
**最后更新**: 2025-11-22
**PostgreSQL版本**: 18.x (推荐) ⭐ | 17.x (推荐) | 16.x (兼容)
**维护者**: Documentation Team
