# 03 | 快速参考手册

> **工具定位**: 本文档提供常用决策、公式、配置、SQL的完整快速查阅手册。
> **📖 概念词典引用**：本文档中涉及的所有核心概念定义与 [核心概念词典](./01-核心概念词典.md) 保持一致。如发现不一致，请以核心概念词典为准。

---

## 📑 目录

- [03 | 快速参考手册](#03--快速参考手册)
  - [📑 目录](#-目录)
  - [一、隔离级别决策表](#一隔离级别决策表)
    - [1.1 完整决策矩阵](#11-完整决策矩阵)
    - [1.2 隔离级别对比](#12-隔离级别对比)
    - [1.3 快速选择算法](#13-快速选择算法)
  - [二、核心公式速查](#二核心公式速查)
    - [2.1 性能公式](#21-性能公式)
    - [2.2 存储公式](#22-存储公式)
    - [2.3 分布式系统公式](#23-分布式系统公式)
    - [2.4 容量规划公式](#24-容量规划公式)
  - [三、配置参数速查](#三配置参数速查)
    - [3.1 按场景配置模板](#31-按场景配置模板)
      - [OLTP高并发](#oltp高并发)
      - [OLAP分析](#olap分析)
      - [混合HTAP](#混合htap)
    - [3.2 关键参数速查表](#32-关键参数速查表)
    - [3.3 危险配置检查](#33-危险配置检查)
  - [四、监控SQL工具箱](#四监控sql工具箱)
    - [4.1 性能监控](#41-性能监控)
      - [当前活动连接](#当前活动连接)
      - [慢查询TOP10](#慢查询top10)
      - [表扫描分析](#表扫描分析)
    - [4.2 存储监控](#42-存储监控)
      - [表膨胀检查](#表膨胀检查)
      - [索引效率分析](#索引效率分析)
    - [4.3 锁监控](#43-锁监控)
      - [锁等待链](#锁等待链)
      - [死锁历史](#死锁历史)
    - [4.4 复制监控](#44-复制监控)
      - [主从延迟](#主从延迟)
  - [五、故障诊断检查单](#五故障诊断检查单)
    - [5.1 性能下降诊断](#51-性能下降诊断)
    - [5.2 OOM诊断](#52-oom诊断)
    - [5.3 数据损坏诊断](#53-数据损坏诊断)
  - [六、性能优化检查单](#六性能优化检查单)
    - [6.1 配置优化](#61-配置优化)
    - [6.2 索引优化](#62-索引优化)
    - [6.3 查询优化](#63-查询优化)
    - [6.4 表设计优化](#64-表设计优化)

---

## 一、隔离级别决策表

### 1.1 完整决策矩阵

| 场景 | 数据特征 | 并发需求 | 一致性需求 | 推荐级别 | 性能 | 理由 |
|-----|---------|---------|-----------|---------|------|------|
| **Web应用** | 读多写少 | 1K TPS | 最终一致 | Read Committed | ⭐⭐⭐⭐⭐ | 无幻读问题,性能最优 |
| **报表分析** | 只读 | 100 QPS | 快照一致 | Repeatable Read | ⭐⭐⭐⭐ | 稳定快照,避免不一致 |
| **金融交易** | 写密集 | 500 TPS | 强一致 | Serializable | ⭐⭐⭐ | 零异常,合规要求 |
| **秒杀活动** | 写密集 | 10K TPS | 库存准确 | Read Committed + 乐观锁 | ⭐⭐⭐⭐ | 高吞吐,应用层保证 |
| **数据同步** | 批量写 | 低 | 快照一致 | Repeatable Read | ⭐⭐⭐⭐ | 批量操作稳定 |

### 1.2 隔离级别对比

| 特性 | RC | RR | Serializable |
|-----|----|----|-------------|
| **脏读** | ✗ | ✗ | ✗ |
| **不可重复读** | ✓ | ✗ | ✗ |
| **幻读** | ✓ | ✓ (PostgreSQL✗) | ✗ |
| **写偏斜** | ✓ | ✓ | ✗ |
| **快照一致** | 语句级 | 事务级 | 串行化 |
| **TPS (相对)** | 100% | 95% | 60-80% |
| **中止率** | <1% | 2-5% | 5-15% |

### 1.3 快速选择算法

```text
Step 1: 数据一致性要求
├─ 强一致性 (金融/库存) → Serializable
├─ 快照一致性 (报表/分析) → Repeatable Read
└─ 最终一致性 (一般应用) → Read Committed

Step 2: 性能要求
├─ 极高TPS (>10K) → Read Committed + 应用层控制
├─ 中等TPS (1-10K) → Repeatable Read
└─ 低TPS (<1K) → Serializable

Step 3: 数据特征
├─ 热点行冲突 → Read Committed + 乐观锁
├─ 范围查询多 → Repeatable Read (避免幻读)
└─ 复杂依赖 → Serializable
```

---

## 二、核心公式速查

### 2.1 性能公式

**吞吐量 (TPS)**:

\[
TPS = \frac{Concurrency}{Latency_{avg}} \times (1 - AbortRate)
\]

**示例**: 100并发, 10ms延迟, 5%中止率
→ TPS = 100 / 0.01 × 0.95 = 9500

**延迟 (P99)**:

\[
Latency_{P99} = Latency_{exec} + Latency_{lock} + Latency_{IO}
\]

**锁等待延迟**:

\[
Latency_{lock} = \frac{\lambda \times W^2}{2(1 - \rho)}
\]

其中 \(\rho = \lambda \times W\) (利用率)

### 2.2 存储公式

**MVCC存储**:

\[
Storage = BaseSize \times (1 + AvgChainLength - 1)
\]

\[
AvgChainLength = 1 + \frac{UpdateRate \times VacuumInterval}{RowCount}
\]

**索引膨胀**:

\[
IndexBloat = AvgChainLength \times (1 - HOTRate)
\]

**示例**: 更新1000/s, VACUUM 60s, 100万行, HOT 80%

- ChainLength = 1 + (1000 × 60) / 1000000 = 1.06
- IndexBloat = 1.06 × (1 - 0.8) = 0.212 (+21.2%)

### 2.3 分布式系统公式

**2PC延迟**:

\[
Latency_{2PC} = 2 \times RTT + 2 \times T_{fsync}
\]

**示例**: RTT=1ms, fsync=5ms
→ Latency = 2×1 + 2×5 = 12ms

**Raft共识延迟**:

\[
Latency_{Raft} = RTT + T_{fsync} + T_{apply}
\]

**CAP可用性**:

\[
Availability = \frac{MTBF}{MTBF + MTTR}
\]

**示例**: 故障间隔30天, 恢复10分钟
→ A = 30×24×60 / (30×24×60 + 10) = 99.977%

### 2.4 容量规划公式

**连接数需求 (Little's Law)**:

\[
Connections = TPS \times Latency_{avg}
\]

**内存需求**:

\[
Memory = shared\_buffers + (work\_mem \times max\_connections \times 5)
\]

**IOPS需求**:

\[
IOPS = TPS \times (Reads\_per\_tx + Writes\_per\_tx + WAL\_writes)
\]

---

## 三、配置参数速查

### 3.1 按场景配置模板

#### OLTP高并发

```ini
# 内存配置 (64GB RAM)
shared_buffers = 16GB              # 25% RAM
work_mem = 64MB                    # 保守值
maintenance_work_mem = 2GB
effective_cache_size = 48GB        # 75% RAM

# 连接
max_connections = 200
max_worker_processes = 16

# WAL
wal_buffers = 16MB
checkpoint_timeout = 15min
checkpoint_completion_target = 0.9
max_wal_size = 4GB

# VACUUM
autovacuum_max_workers = 4
autovacuum_vacuum_scale_factor = 0.05  # 5%触发

# 查询优化
random_page_cost = 1.1             # SSD
effective_io_concurrency = 200
```

#### OLAP分析

```ini
# 内存配置 (128GB RAM)
shared_buffers = 32GB
work_mem = 512MB                   # 大聚合查询
maintenance_work_mem = 4GB
effective_cache_size = 96GB

# 连接 (分析并发低)
max_connections = 50

# 并行查询
max_parallel_workers_per_gather = 4
max_parallel_workers = 16
max_worker_processes = 32

# 大查询优化
temp_buffers = 256MB
hash_mem_multiplier = 2.0
```

#### 混合HTAP

```ini
# 使用角色分离配置
ALTER ROLE oltp_user SET work_mem = '64MB';
ALTER ROLE oltp_user SET max_parallel_workers_per_gather = 0;

ALTER ROLE olap_user SET work_mem = '512MB';
ALTER ROLE olap_user SET max_parallel_workers_per_gather = 4;

# 连接池 (PgBouncer)
max_connections = 100  # 数据库
pgbouncer_max_client_conn = 1000  # 应用
```

### 3.2 关键参数速查表

| 参数 | 推荐值 | 公式 | 说明 |
|-----|-------|------|------|
| shared_buffers | 8-32GB | RAM × 0.25 | 超过32GB收益递减 |
| work_mem | 64-512MB | (RAM - SB) / (max_conn × 5) | 避免OOM |
| maintenance_work_mem | 1-4GB | RAM × 0.05 | VACUUM/CREATE INDEX |
| effective_cache_size | 48-96GB | RAM × 0.75 | 优化器参考 |
| max_connections | 100-200 | CPU × 4 | 用连接池 |
| checkpoint_timeout | 15-30min | - | 平衡IO |
| random_page_cost | 1.1 | - | SSD必须降低 |
| autovacuum_scale_factor | 0.05-0.2 | - | 热表降低 |

### 3.3 危险配置检查

| 配置 | 危险值 | 后果 | 修复 |
|-----|-------|------|------|
| fsync | off | 💀 数据丢失 | 立即改on |
| synchronous_commit | off | ⚠️ 事务丢失 | 谨慎使用 |
| max_connections | >1000 | 🔴 性能崩溃 | 用连接池 |
| work_mem × max_conn | >50% RAM | 💀 OOM | 降低work_mem |
| autovacuum | off | 🔴 表膨胀 | 必须开启 |
| full_page_writes | off | 💀 数据损坏 | 保持on |

---

## 四、监控SQL工具箱

### 4.1 性能监控

#### 当前活动连接

```sql
SELECT pid,
       usename,
       application_name,
       client_addr,
       state,
       wait_event_type,
       wait_event,
       EXTRACT(EPOCH FROM (NOW() - query_start)) AS query_seconds,
       LEFT(query, 100) AS query_snippet
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY query_start;
```

#### 慢查询TOP10

```sql
SELECT query,
       calls,
       ROUND(total_exec_time::numeric / 1000, 2) AS total_sec,
       ROUND(mean_exec_time::numeric, 2) AS mean_ms,
       ROUND(max_exec_time::numeric, 2) AS max_ms,
       ROUND(stddev_exec_time::numeric, 2) AS stddev_ms
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 10;
```

#### 表扫描分析

```sql
SELECT schemaname, tablename,
       seq_scan AS seq_scans,
       seq_tup_read,
       idx_scan AS index_scans,
       idx_tup_fetch,
       CASE
           WHEN seq_scan > 0 THEN seq_tup_read / seq_scan
           ELSE 0
       END AS avg_seq_tup_read,
       CASE
           WHEN seq_scan > idx_scan THEN '⚠️ 需要索引'
           ELSE '✓'
       END AS status
FROM pg_stat_user_tables
WHERE seq_scan > 100
ORDER BY seq_tup_read DESC
LIMIT 20;
```

### 4.2 存储监控

#### 表膨胀检查

```sql
SELECT schemaname||'.'||tablename AS table_name,
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
       n_live_tup,
       n_dead_tup,
       ROUND(100.0 * n_dead_tup / NULLIF(n_live_tup, 0), 2) AS dead_pct,
       ROUND(100.0 * n_tup_hot_upd / NULLIF(n_tup_upd, 0), 2) AS hot_pct,
       last_autovacuum,
       CASE
           WHEN n_dead_tup::FLOAT / NULLIF(n_live_tup, 0) > 0.3 THEN '🔴 Critical'
           WHEN n_dead_tup::FLOAT / NULLIF(n_live_tup, 0) > 0.1 THEN '🟡 Warning'
           ELSE '🟢 OK'
       END AS health
FROM pg_stat_user_tables
WHERE n_live_tup > 1000
ORDER BY n_dead_tup DESC
LIMIT 20;
```

#### 索引效率分析

```sql
SELECT schemaname||'.'||tablename AS table_name,
       indexrelname AS index_name,
       idx_scan AS scans,
       idx_tup_read,
       idx_tup_fetch,
       pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
       CASE
           WHEN idx_scan = 0 THEN '🔴 未使用'
           WHEN idx_scan < 50 THEN '🟡 低频'
           ELSE '🟢 正常'
       END AS usage_status
FROM pg_stat_user_indexes
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY idx_scan;
```

### 4.3 锁监控

#### 锁等待链

```sql
SELECT DISTINCT
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_query,
    blocking_activity.query AS blocking_query,
    blocked_activity.wait_event AS wait_event
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity
    ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity
    ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

#### 死锁历史

```sql
-- 需要安装pg_stat_statements扩展
SELECT query,
       calls,
       total_exec_time / calls AS avg_time_ms
FROM pg_stat_statements
WHERE query LIKE '%deadlock%'
ORDER BY calls DESC;
```

### 4.4 复制监控

#### 主从延迟

```sql
-- 在主库执行
SELECT client_addr,
       application_name,
       state,
       sync_state,
       pg_wal_lsn_diff(pg_current_wal_lsn(), sent_lsn) AS send_lag_bytes,
       pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) AS replay_lag_bytes,
       write_lag,
       flush_lag,
       replay_lag
FROM pg_stat_replication;
```

---

## 五、故障诊断检查单

### 5.1 性能下降诊断

```text
□ 1. 检查CPU使用率
    - top/htop查看CPU
    - pg_stat_activity查看活动查询

□ 2. 检查IO等待
    - iostat -x 1
    - wait_event_type = 'IO'的会话数

□ 3. 检查锁等待
    - 查询锁等待链SQL
    - 检查长事务: state='idle in transaction'

□ 4. 检查表膨胀
    - 运行表膨胀检查SQL
    - n_dead_tup > 30%? → VACUUM

□ 5. 检查慢查询
    - pg_stat_statements TOP10
    - EXPLAIN ANALYZE慢查询

□ 6. 检查连接数
    - 接近max_connections? → 连接池
    - 连接泄漏? → 应用bug
```

### 5.2 OOM诊断

```text
□ 1. 检查work_mem配置
    - work_mem × max_connections × 5 < 物理内存?

□ 2. 检查大查询
    - EXPLAIN查看Hash/Sort节点
    - 检查temp文件使用

□ 3. 检查连接数
    - 过多连接导致内存耗尽

□ 4. 检查共享内存
    - ipcs -m查看共享内存

□ 5. 检查系统日志
    - dmesg | grep -i "out of memory"
```

### 5.3 数据损坏诊断

```text
□ 1. 检查PostgreSQL日志
    - ERROR/PANIC级别
    - "invalid page header"?

□ 2. 检查文件系统
    - df -h: 磁盘满?
    - fsck: 文件系统错误?

□ 3. 检查硬件
    - smartctl -a /dev/sda: 磁盘坏道?
    - memtest: 内存错误?

□ 4. 检查配置
    - fsync=on?
    - full_page_writes=on?
```

---

## 六、性能优化检查单

### 6.1 配置优化

```text
□ shared_buffers = 25% RAM (8-32GB)
□ work_mem = 计算公式
□ effective_cache_size = 75% RAM
□ random_page_cost = 1.1 (SSD)
□ max_connections = CPU × 4
□ checkpoint_timeout = 15-30min
□ autovacuum开启
□ 连接池 (PgBouncer/pgpool)
```

### 6.2 索引优化

```text
□ 找出未使用索引 (idx_scan=0) → DROP
□ 找出重复索引 → 合并
□ 找出顺序扫描频繁的表 → CREATE INDEX
□ 复合索引列顺序优化 (高选择性在前)
□ 部分索引 (WHERE子句过滤)
□ 覆盖索引 (INCLUDE列)
```

### 6.3 查询优化

```text
□ EXPLAIN ANALYZE慢查询
□ 避免SELECT * (只选需要的列)
□ 避免NOT IN (用NOT EXISTS或LEFT JOIN)
□ 避免OR (用UNION)
□ 分页用索引 (id > last_id而非OFFSET)
□ 批量操作 (COPY而非多次INSERT)
□ 使用PREPARE (预编译)
```

### 6.4 表设计优化

```text
□ 合理分区 (时间/范围分区)
□ 降低fillfactor (频繁更新的表)
□ 拆分热点字段 (status等)
□ 合理数据类型 (避免TEXT存短字符串)
□ 主键选择 (BIGSERIAL vs UUID)
□ 外键索引 (JOIN性能)
```

---

**文档版本**: 2.0.0（大幅充实）
**最后更新**: 2025-12-05
**新增内容**: 完整决策表、监控SQL工具箱、故障诊断检查单

**打印版本**: 适合打印为A4双面快速手册

**关联文档**:

- 所有其他文档的精华浓缩
- 决策树详见 `02-设计权衡分析/`
- 公式详见 `06-性能分析/`
- 配置详见 `11-工具与自动化/10-配置验证器.md`
