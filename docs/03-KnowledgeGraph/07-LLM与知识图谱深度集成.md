# LLMä¸çŸ¥è¯†å›¾è°±æ·±åº¦é›†æˆå®Œæ•´æŒ‡å—

## å…ƒæ•°æ®

- **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-12-04
- **é€‚ç”¨æŠ€æœ¯æ ˆ**: PostgreSQL 16+ | Apache AGE 1.5+ | pgvector 0.7+ | OpenAI/Anthropic API
- **éš¾åº¦çº§åˆ«**: â­â­â­â­â­ (ä¸“å®¶çº§)
- **é¢„è®¡é˜…è¯»**: 150åˆ†é’Ÿ
- **é…å¥—èµ„æº**: [å®Œæ•´ä»£ç ](./examples/llm-kg/) | [Jupyter Notebooks](./notebooks/)

---

## ğŸ“‹ å®Œæ•´ç›®å½•

- [LLMä¸çŸ¥è¯†å›¾è°±æ·±åº¦é›†æˆå®Œæ•´æŒ‡å—](#llmä¸çŸ¥è¯†å›¾è°±æ·±åº¦é›†æˆå®Œæ•´æŒ‡å—)
  - [å…ƒæ•°æ®](#å…ƒæ•°æ®)
  - [ğŸ“‹ å®Œæ•´ç›®å½•](#-å®Œæ•´ç›®å½•)
  - [1. LLM+çŸ¥è¯†å›¾è°±èåˆæ¶æ„](#1-llmçŸ¥è¯†å›¾è°±èåˆæ¶æ„)
    - [1.1 ä¸ºä»€ä¹ˆéœ€è¦èåˆ](#11-ä¸ºä»€ä¹ˆéœ€è¦èåˆ)
      - [LLMçš„å±€é™æ€§](#llmçš„å±€é™æ€§)
      - [çŸ¥è¯†å›¾è°±çš„å±€é™æ€§](#çŸ¥è¯†å›¾è°±çš„å±€é™æ€§)
      - [èåˆçš„ä»·å€¼](#èåˆçš„ä»·å€¼)
    - [1.2 èåˆæ¨¡å¼](#12-èåˆæ¨¡å¼)
      - [æ¨¡å¼1: LLMå¢å¼ºçŸ¥è¯†å›¾è°±](#æ¨¡å¼1-llmå¢å¼ºçŸ¥è¯†å›¾è°±)
      - [æ¨¡å¼2: çŸ¥è¯†å›¾è°±å¢å¼ºLLM](#æ¨¡å¼2-çŸ¥è¯†å›¾è°±å¢å¼ºllm)
      - [æ¨¡å¼3: åŒå‘å¢å¼º (æ¨è)](#æ¨¡å¼3-åŒå‘å¢å¼º-æ¨è)
    - [1.3 æŠ€æœ¯æŒ‘æˆ˜](#13-æŠ€æœ¯æŒ‘æˆ˜)
  - [2. Text-to-Cypherç”Ÿæˆç³»ç»Ÿ](#2-text-to-cypherç”Ÿæˆç³»ç»Ÿ)
    - [2.1 Promptå·¥ç¨‹](#21-promptå·¥ç¨‹)
      - [é«˜è´¨é‡Promptæ¨¡æ¿](#é«˜è´¨é‡promptæ¨¡æ¿)
  - [é‡è¦çº¦æŸ](#é‡è¦çº¦æŸ)
  - [è¾“å‡ºæ ¼å¼](#è¾“å‡ºæ ¼å¼)
    - [2.2 Few-Shotå­¦ä¹ ](#22-few-shotå­¦ä¹ )
      - [åŠ¨æ€ç¤ºä¾‹é€‰æ‹©](#åŠ¨æ€ç¤ºä¾‹é€‰æ‹©)
    - [2.3 é”™è¯¯ä¿®å¤æœºåˆ¶](#23-é”™è¯¯ä¿®å¤æœºåˆ¶)
      - [è‡ªåŠ¨Cypherä¿®å¤](#è‡ªåŠ¨cypherä¿®å¤)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æµ‹è¯•æœ‰é”™è¯¯çš„æŸ¥è¯¢](#æµ‹è¯•æœ‰é”™è¯¯çš„æŸ¥è¯¢)
  - [3. KBQAç³»ç»Ÿå®Œæ•´å®ç°](#3-kbqaç³»ç»Ÿå®Œæ•´å®ç°)
    - [3.1 é—®é¢˜ç†è§£](#31-é—®é¢˜ç†è§£)
      - [æ„å›¾è¯†åˆ«](#æ„å›¾è¯†åˆ«)
    - [3.2 å®ä½“è¯†åˆ«ä¸é“¾æ¥](#32-å®ä½“è¯†åˆ«ä¸é“¾æ¥)
      - [é«˜çº§å®ä½“é“¾æ¥](#é«˜çº§å®ä½“é“¾æ¥)
    - [3.3 å­å›¾æ£€ç´¢](#33-å­å›¾æ£€ç´¢)
      - [å¤šè·³å­å›¾æ£€ç´¢](#å¤šè·³å­å›¾æ£€ç´¢)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
  - [ğŸ“ æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)

---

## 1. LLM+çŸ¥è¯†å›¾è°±èåˆæ¶æ„

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦èåˆ

#### LLMçš„å±€é™æ€§

| å±€é™ | æè¿° | çŸ¥è¯†å›¾è°±å¦‚ä½•è§£å†³ |
|------|------|------------------|
| **å¹»è§‰é—®é¢˜** | ç”Ÿæˆä¸çœŸå®çš„ä¿¡æ¯ | æä¾›å¯éªŒè¯çš„äº‹å®ä¾æ® |
| **æ—¶æ•ˆæ€§å·®** | è®­ç»ƒæ•°æ®æˆªæ­¢æ—¥æœŸ | å®æ—¶æ›´æ–°çš„çŸ¥è¯†åº“ |
| **å¯è§£é‡Šæ€§å¼±** | é»‘ç›’æ¨ç†è¿‡ç¨‹ | æ˜ç¡®çš„æ¨ç†è·¯å¾„ |
| **çŸ¥è¯†æ›´æ–°éš¾** | éœ€è¦é‡æ–°è®­ç»ƒ | åŠ¨æ€æ·»åŠ /ä¿®æ”¹çŸ¥è¯† |
| **é¢†åŸŸçŸ¥è¯†ä¸è¶³** | é€šç”¨æ¨¡å‹ç¼ºä¹ä¸“ä¸šæ€§ | å­˜å‚¨é¢†åŸŸä¸“å®¶çŸ¥è¯† |

#### çŸ¥è¯†å›¾è°±çš„å±€é™æ€§

| å±€é™ | æè¿° | LLMå¦‚ä½•è§£å†³ |
|------|------|-------------|
| **æ„å»ºæˆæœ¬é«˜** | éœ€è¦äººå·¥æ ‡æ³¨ | è‡ªåŠ¨åŒ–çŸ¥è¯†æŠ½å– |
| **æŸ¥è¯¢å›°éš¾** | éœ€è¦å­¦ä¹ Cypher | è‡ªç„¶è¯­è¨€æ¥å£ |
| **æ³›åŒ–èƒ½åŠ›å¼±** | åªèƒ½å›ç­”å·²çŸ¥çŸ¥è¯† | å¸¸è¯†æ¨ç†ä¸åˆ›é€ æ€§å›ç­” |
| **å†·å¯åŠ¨é—®é¢˜** | åˆæœŸçŸ¥è¯†ç¨€ç– | é¢„è®­ç»ƒçŸ¥è¯†è¡¥å…… |

#### èåˆçš„ä»·å€¼

```
LLM + KGèåˆç³»ç»Ÿ = 1 + 1 > 2

ä¼˜åŠ¿ï¼š
âœ… å‡†ç¡®æ€§: KGæä¾›äº‹å®éªŒè¯
âœ… æ—¶æ•ˆæ€§: KGå®æ—¶æ›´æ–°
âœ… å¯è§£é‡Šæ€§: æ˜ç¡®çš„æ¨ç†é“¾
âœ… é¢†åŸŸä¸“ä¸šæ€§: KGä¸“ä¸šçŸ¥è¯† + LLMç†è§£
âœ… ç”¨æˆ·ä½“éªŒ: è‡ªç„¶è¯­è¨€äº¤äº’
```

### 1.2 èåˆæ¨¡å¼

#### æ¨¡å¼1: LLMå¢å¼ºçŸ¥è¯†å›¾è°±

```
ç”¨æˆ·é—®é¢˜ â†’ LLMç†è§£ â†’ ç”ŸæˆCypher â†’ KGæŸ¥è¯¢ â†’ è¿”å›ç»“æœ
```

**é€‚ç”¨åœºæ™¯**: ç»“æ„åŒ–æŸ¥è¯¢ã€ç²¾ç¡®é—®ç­”

#### æ¨¡å¼2: çŸ¥è¯†å›¾è°±å¢å¼ºLLM

```
ç”¨æˆ·é—®é¢˜ â†’ KGæ£€ç´¢ç›¸å…³çŸ¥è¯† â†’ æ³¨å…¥LLMä¸Šä¸‹æ–‡ â†’ LLMç”Ÿæˆç­”æ¡ˆ
```

**é€‚ç”¨åœºæ™¯**: éœ€è¦åˆ›é€ æ€§ã€è§£é‡Šæ€§å›ç­”

#### æ¨¡å¼3: åŒå‘å¢å¼º (æ¨è)

```
ç”¨æˆ·é—®é¢˜
   â”œâ”€â†’ LLMç†è§£ + å®ä½“è¯†åˆ«
   â”œâ”€â†’ KGå­å›¾æ£€ç´¢
   â”œâ”€â†’ å‘é‡ç›¸ä¼¼åº¦æœç´¢
   â””â”€â†’ LLMç»¼åˆç”Ÿæˆç­”æ¡ˆ
```

**é€‚ç”¨åœºæ™¯**: å¤æ‚åœºæ™¯ã€ä¼ä¸šçº§åº”ç”¨

### 1.3 æŠ€æœ¯æŒ‘æˆ˜

```python
# æŠ€æœ¯æŒ‘æˆ˜æ¸…å•
class LLMKGChallenges:
    """LLM+KGèåˆçš„æŠ€æœ¯æŒ‘æˆ˜"""

    challenges = {
        "å‡†ç¡®æ€§": {
            "Text-to-Cypherç²¾åº¦": "éœ€è¦>=90%å‡†ç¡®ç‡",
            "å®ä½“é“¾æ¥å‡†ç¡®æ€§": "æ¶ˆæ­§å›°éš¾",
            "å¹»è§‰æ§åˆ¶": "é˜²æ­¢LLMç¼–é€ äº‹å®"
        },
        "æ€§èƒ½": {
            "å»¶è¿Ÿ": "ç«¯åˆ°ç«¯<2ç§’",
            "å¹¶å‘": "æ”¯æŒ1000+ QPS",
            "æˆæœ¬": "LLM APIè°ƒç”¨æˆæœ¬æ§åˆ¶"
        },
        "å·¥ç¨‹åŒ–": {
            "é”™è¯¯å¤„ç†": "Cypherè¯­æ³•é”™è¯¯è‡ªåŠ¨ä¿®å¤",
            "ç¼“å­˜ç­–ç•¥": "å‡å°‘é‡å¤è°ƒç”¨",
            "ç›‘æ§": "å…¨é“¾è·¯å¯è§‚æµ‹"
        },
        "æ•°æ®è´¨é‡": {
            "KGå®Œæ•´æ€§": "çŸ¥è¯†è¦†ç›–ç‡",
            "Schemaè¿›åŒ–": "é€‚åº”å˜åŒ–",
            "æ•°æ®ä¸€è‡´æ€§": "å¤šæºèåˆ"
        }
    }

    @classmethod
    def print_challenges(cls):
        for category, items in cls.challenges.items():
            print(f"\nã€{category}ã€‘")
            for challenge, description in items.items():
                print(f"  - {challenge}: {description}")

# è¾“å‡ºæŒ‘æˆ˜æ¸…å•
LLMKGChallenges.print_challenges()
```

---

## 2. Text-to-Cypherç”Ÿæˆç³»ç»Ÿ

### 2.1 Promptå·¥ç¨‹

#### é«˜è´¨é‡Promptæ¨¡æ¿

```python
class CypherPromptTemplate:
    """Text-to-Cypher Promptæ¨¡æ¿"""

    @staticmethod
    def get_system_prompt(schema: Dict) -> str:
        """ç³»ç»Ÿæç¤ºè¯"""
        return f"""ä½ æ˜¯ä¸€ä¸ªCypheræŸ¥è¯¢ä¸“å®¶ï¼Œä¸“é—¨ä¸ºApache AGEå›¾æ•°æ®åº“ç”ŸæˆæŸ¥è¯¢ã€‚

## å›¾Schema

### èŠ‚ç‚¹ç±»å‹ (Node Labels)
{json.dumps(schema['node_labels'], indent=2, ensure_ascii=False)}

### å…³ç³»ç±»å‹ (Relationship Types)
{json.dumps(schema['relationship_types'], indent=2, ensure_ascii=False)}

### å…³ç³»è¿æ¥æ¨¡å¼ (Connection Patterns)
{json.dumps(schema.get('patterns', {}), indent=2, ensure_ascii=False)}

## Cypherè¯­æ³•è§„åˆ™

1. **åŸºæœ¬æ¨¡å¼åŒ¹é…**
   ```cypher
   MATCH (n:Label {{property: 'value'}})
   RETURN n
   ```

2. **å…³ç³»åŒ¹é…**

   ```cypher
   MATCH (a:Person)-[r:KNOWS]->(b:Person)
   WHERE r.since > 2020
   RETURN a.name, b.name
   ```

3. **è·¯å¾„æŸ¥è¯¢**

   ```cypher
   MATCH path = (a)-[:KNOWS*1..3]->(b)
   RETURN path
   ```

4. **èšåˆæŸ¥è¯¢**

   ```cypher
   MATCH (p:Person)-[:WORKS_FOR]->(c:Company)
   RETURN c.name, COUNT(p) AS employee_count
   ORDER BY employee_count DESC
   ```

## é‡è¦çº¦æŸ

âœ… DO:

- å§‹ç»ˆä½¿ç”¨æ ‡ç­¾å’Œå…³ç³»ç±»å‹ (åŒºåˆ†å¤§å°å†™)
- ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢æ³¨å…¥
- æ·»åŠ LIMITé™åˆ¶ç»“æœæ•°é‡
- ä½¿ç”¨æ˜ç¡®çš„æ–¹å‘ `-[r:TYPE]->` è€Œä¸æ˜¯ `-[r:TYPE]-`
- å±æ€§è®¿é—®ä½¿ç”¨ç‚¹å·: `n.property`

âŒ DON'T:

- ä¸è¦ä½¿ç”¨æœªåœ¨schemaä¸­å®šä¹‰çš„æ ‡ç­¾/å…³ç³»
- ä¸è¦ç”Ÿæˆç ´åæ€§æŸ¥è¯¢ (CREATE/DELETE/SET) é™¤éæ˜ç¡®è¦æ±‚
- ä¸è¦ä½¿ç”¨å¤æ‚çš„è·¯å¾„æ¨¡å¼ (é•¿åº¦>5)
- ä¸è¦å¿˜è®°WHEREè¿‡æ»¤æ¡ä»¶

## è¾“å‡ºæ ¼å¼

åªè¿”å›CypheræŸ¥è¯¢ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–ä»£ç å—æ ‡è®°ã€‚

```python
    @staticmethod
    def get_few_shot_examples() -> List[Dict]:
        """Few-Shotç¤ºä¾‹"""
        return [
            {
                "question": "æœ‰å¤šå°‘ä¸ªç”¨æˆ·?",
                "cypher": "MATCH (u:User) RETURN COUNT(u) AS user_count"
            },
            {
                "question": "æ‰¾å‡ºå¹´é¾„è¶…è¿‡30å²çš„ç”¨æˆ·",
                "cypher": """MATCH (u:User)
WHERE u.age > 30
RETURN u.name, u.age
ORDER BY u.age DESC
LIMIT 100"""
            },
            {
                "question": "Aliceçš„æœ‹å‹æœ‰å“ªäº›?",
                "cypher": """MATCH (a:User {name: 'Alice'})-[:FRIEND]->(friend)
RETURN friend.name, friend.age
ORDER BY friend.name"""
            },
            {
                "question": "æ‰¾å‡ºå…±åŒæœ‹å‹æœ€å¤šçš„ç”¨æˆ·å¯¹",
                "cypher": """MATCH (u1:User)-[:FRIEND]->(common)<-[:FRIEND]-(u2:User)
WHERE id(u1) < id(u2)
RETURN u1.name, u2.name, COUNT(common) AS common_friends
ORDER BY common_friends DESC
LIMIT 10"""
            },
            {
                "question": "ä»åŒ—äº¬åˆ°ä¸Šæµ·çš„æœ€çŸ­è·¯å¾„",
                "cypher": """MATCH path = shortestPath(
  (a:City {name: 'åŒ—äº¬'})-[:CONNECTED_TO*]-(b:City {name: 'ä¸Šæµ·'})
)
RETURN path, length(path) AS distance"""
            },
            {
                "question": "æ¯ä¸ªå…¬å¸æœ‰å¤šå°‘å‘˜å·¥?",
                "cypher": """MATCH (p:Person)-[:WORKS_FOR]->(c:Company)
RETURN c.name AS company, COUNT(p) AS employee_count
ORDER BY employee_count DESC"""
            },
            {
                "question": "æ¨èä¸Bobå…´è¶£ç›¸ä¼¼çš„ç”¨æˆ·",
                "cypher": """MATCH (bob:User {name: 'Bob'})
MATCH (other:User)
WHERE other <> bob
  AND SIZE([i IN bob.interests WHERE i IN other.interests]) > 0
RETURN other.name,
       SIZE([i IN bob.interests WHERE i IN other.interests]) AS common_interests
ORDER BY common_interests DESC
LIMIT 10"""
            }
        ]

    @staticmethod
    def format_user_prompt(question: str, examples: List[Dict] = None) -> str:
        """ç”¨æˆ·æç¤ºè¯"""
        prompt = "å°†ä»¥ä¸‹é—®é¢˜è½¬æ¢ä¸ºCypheræŸ¥è¯¢:\n\n"

        # æ·»åŠ Few-Shotç¤ºä¾‹
        if examples:
            prompt += "## å‚è€ƒç¤ºä¾‹\n\n"
            for ex in examples:
                prompt += f"é—®é¢˜: {ex['question']}\n"
                prompt += f"Cypher:\n```cypher\n{ex['cypher']}\n```\n\n"

        prompt += f"## å½“å‰é—®é¢˜\n\né—®é¢˜: {question}\n\nCypher:\n"

        return prompt

# ä½¿ç”¨ç¤ºä¾‹

schema = {
    "node_labels": {
        "User": ["name", "age", "email", "interests"],
        "Company": ["name", "industry", "founded"],
        "City": ["name", "country", "population"]
    },
    "relationship_types": {
        "FRIEND": ["since", "strength"],
        "WORKS_FOR": ["position", "since"],
        "LOCATED_IN": []
    },
    "patterns": [
        "(User)-[:FRIEND]->(User)",
        "(User)-[:WORKS_FOR]->(Company)",
        "(Company)-[:LOCATED_IN]->(City)"
    ]
}

template = CypherPromptTemplate()
system_prompt = template.get_system_prompt(schema)
user_prompt = template.format_user_prompt(
    "æ‰¾å‡ºåœ¨ç§‘æŠ€å…¬å¸å·¥ä½œçš„30å²ä»¥ä¸Šç”¨æˆ·",
    examples=template.get_few_shot_examples()[:3]
)

print(system_prompt)
print("\n" + "="*80 + "\n")
print(user_prompt)

```

### 2.2 Few-Shotå­¦ä¹ 

#### åŠ¨æ€ç¤ºä¾‹é€‰æ‹©

```python
from sentence_transformers import SentenceTransformer
import numpy as np

class DynamicFewShotSelector:
    """åŠ¨æ€é€‰æ‹©æœ€ç›¸å…³çš„Few-Shotç¤ºä¾‹"""

    def __init__(self, example_bank: List[Dict]):
        self.example_bank = example_bank
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

        # é¢„è®¡ç®—ç¤ºä¾‹çš„å‘é‡
        self.example_embeddings = self.embedding_model.encode(
            [ex['question'] for ex in example_bank]
        )

    def select_examples(self, question: str, top_k: int = 3) -> List[Dict]:
        """é€‰æ‹©æœ€ç›¸å…³çš„Kä¸ªç¤ºä¾‹"""
        # ç”Ÿæˆé—®é¢˜å‘é‡
        question_emb = self.embedding_model.encode(question)

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = np.dot(self.example_embeddings, question_emb) / (
            np.linalg.norm(self.example_embeddings, axis=1) * np.linalg.norm(question_emb)
        )

        # é€‰æ‹©Top-K
        top_indices = np.argsort(similarities)[-top_k:][::-1]

        return [self.example_bank[i] for i in top_indices]

# æ„å»ºç¤ºä¾‹åº“
example_bank = [
    {"question": "æœ‰å¤šå°‘ä¸ªç”¨æˆ·?", "cypher": "MATCH (u:User) RETURN COUNT(u)"},
    {"question": "å¹´é¾„æœ€å¤§çš„10ä¸ªç”¨æˆ·", "cypher": "MATCH (u:User) RETURN u.name, u.age ORDER BY u.age DESC LIMIT 10"},
    {"question": "Aliceçš„æœ‹å‹", "cypher": "MATCH (a:User {name: 'Alice'})-[:FRIEND]->(f) RETURN f.name"},
    {"question": "åœ¨åŒ—äº¬çš„å…¬å¸", "cypher": "MATCH (c:Company)-[:LOCATED_IN]->(city:City {name: 'åŒ—äº¬'}) RETURN c.name"},
    {"question": "æ¯ä¸ªå…¬å¸çš„å‘˜å·¥æ•°", "cypher": "MATCH (p:Person)-[:WORKS_FOR]->(c:Company) RETURN c.name, COUNT(p) AS count"},
    # ... æ›´å¤šç¤ºä¾‹
]

selector = DynamicFewShotSelector(example_bank)

# ä¸ºæ–°é—®é¢˜é€‰æ‹©ç¤ºä¾‹
question = "æ‰¾å‡ºåœ¨ç§‘æŠ€å…¬å¸å·¥ä½œçš„å‘˜å·¥äººæ•°"
selected_examples = selector.select_examples(question, top_k=3)

print(f"é—®é¢˜: {question}\n")
print("é€‰ä¸­çš„ç¤ºä¾‹:")
for ex in selected_examples:
    print(f"  - {ex['question']}")
```

### 2.3 é”™è¯¯ä¿®å¤æœºåˆ¶

#### è‡ªåŠ¨Cypherä¿®å¤

```python
import re
from typing import Optional

class CypherErrorFixer:
    """CypheræŸ¥è¯¢é”™è¯¯è‡ªåŠ¨ä¿®å¤"""

    def __init__(self, conn, graph_name: str):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()

    def execute_with_retry(
        self,
        cypher: str,
        max_retries: int = 3,
        llm_client: Optional[OpenAI] = None
    ) -> tuple:
        """å¸¦é‡è¯•çš„æ‰§è¡Œ"""

        for attempt in range(max_retries):
            try:
                # å°è¯•æ‰§è¡Œ
                result = self._execute_cypher(cypher)
                return (True, result, cypher)

            except Exception as e:
                error_msg = str(e)
                print(f"âŒ æ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {error_msg}")

                # å°è¯•è‡ªåŠ¨ä¿®å¤
                fixed_cypher = self._auto_fix(cypher, error_msg)

                if fixed_cypher and fixed_cypher != cypher:
                    print(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤åçš„æŸ¥è¯¢:\n{fixed_cypher}")
                    cypher = fixed_cypher
                    continue

                # å¦‚æœæœ‰LLMï¼Œå°è¯•LLMä¿®å¤
                if llm_client and attempt < max_retries - 1:
                    print("ğŸ¤– å°è¯•LLMä¿®å¤...")
                    cypher = self._llm_fix(cypher, error_msg, llm_client)
                    continue

                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                if attempt == max_retries - 1:
                    return (False, None, error_msg)

        return (False, None, "Max retries exceeded")

    def _execute_cypher(self, cypher: str) -> List[Dict]:
        """æ‰§è¡ŒCypheræŸ¥è¯¢"""
        # æå–RETURNåˆ—
        return_cols = self._extract_return_columns(cypher)

        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                {cypher}
            $$) AS ({', '.join([f'{col} agtype' for col in return_cols])});
        """)

        results = []
        for row in self.cursor.fetchall():
            result = {}
            for i, col in enumerate(return_cols):
                try:
                    result[col] = json.loads(row[i]) if row[i] else None
                except:
                    result[col] = str(row[i])
            results.append(result)

        return results

    def _auto_fix(self, cypher: str, error_msg: str) -> Optional[str]:
        """åŸºäºè§„åˆ™çš„è‡ªåŠ¨ä¿®å¤"""

        # è§„åˆ™1: ç¼ºå°‘RETURNè¯­å¥
        if "RETURN" not in cypher.upper():
            cypher += "\nRETURN *"

        # è§„åˆ™2: å±æ€§è®¿é—®é”™è¯¯ (n['name'] -> n.name)
        cypher = re.sub(r"(\w+)\['(\w+)'\]", r"\1.\2", cypher)

        # è§„åˆ™3: å…³ç³»æ–¹å‘é”™è¯¯ (åŒå‘æ”¹å•å‘)
        if "undirected" in error_msg.lower():
            cypher = cypher.replace("--", "-->")

        # è§„åˆ™4: ç¼ºå°‘æ ‡ç­¾
        if "label" in error_msg.lower():
            # å°è¯•æ·»åŠ é€šç”¨æ ‡ç­¾
            cypher = re.sub(r"MATCH \((\w+)\)", r"MATCH (\1:Entity)", cypher)

        # è§„åˆ™5: å±æ€§åé”™è¯¯ (å¸¸è§æ‹¼å†™é”™è¯¯)
        typo_fixes = {
            'nmae': 'name',
            'eamil': 'email',
            'comapny': 'company'
        }
        for typo, correct in typo_fixes.items():
            cypher = cypher.replace(typo, correct)

        return cypher

    def _llm_fix(self, cypher: str, error_msg: str, llm_client: OpenAI) -> str:
        """ä½¿ç”¨LLMä¿®å¤é”™è¯¯"""
        prompt = f"""ä½ æ˜¯Cypherä¸“å®¶ã€‚ä»¥ä¸‹æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼Œè¯·ä¿®å¤å®ƒã€‚

åŸå§‹æŸ¥è¯¢:
```cypher
{cypher}
```

é”™è¯¯ä¿¡æ¯:
{error_msg}

è¯·è¿”å›ä¿®å¤åçš„CypheræŸ¥è¯¢ï¼Œåªè¿”å›æŸ¥è¯¢æœ¬èº«ï¼Œä¸è¦è§£é‡Šã€‚
"""

        response = llm_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯CypheræŸ¥è¯¢ä¿®å¤ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )

        fixed_cypher = response.choices[0].message.content.strip()
        fixed_cypher = fixed_cypher.replace("```cypher", "").replace("```", "").strip()

        return fixed_cypher

    def _extract_return_columns(self, cypher: str) -> List[str]:
        """æå–RETURNåˆ—å"""
        match = re.search(r'RETURN\s+(.*?)(?:ORDER BY|LIMIT|$)', cypher, re.IGNORECASE | re.DOTALL)
        if not match:
            return ['result']

        return_clause = match.group(1).strip()

        if return_clause == '*':
            return ['result']

        columns = []
        for part in return_clause.split(','):
            part = part.strip()
            if ' AS ' in part.upper():
                alias = part.split(' AS ')[-1].strip()
                columns.append(alias)
            else:
                columns.append(part.split('.')[-1].strip('()'))

        return columns

# ä½¿ç”¨ç¤ºä¾‹

from openai import OpenAI

conn = psycopg2.connect("dbname=test_db user=postgres")
fixer = CypherErrorFixer(conn, 'test_graph')
llm_client = OpenAI(api_key='your-key')

# æµ‹è¯•æœ‰é”™è¯¯çš„æŸ¥è¯¢

bad_cypher = """
MATCH (u:User)
WHERE u.nmae = 'Alice'  -- æ‹¼å†™é”™è¯¯
RETURN u.eamil  -- æ‹¼å†™é”™è¯¯
"""

success, result, final_cypher = fixer.execute_with_retry(
    bad_cypher,
    max_retries=3,
    llm_client=llm_client
)

if success:
    print(f"âœ… æ‰§è¡ŒæˆåŠŸ!")
    print(f"æœ€ç»ˆæŸ¥è¯¢:\n{final_cypher}")
    print(f"ç»“æœ: {result}")
else:
    print(f"âŒ æ‰§è¡Œå¤±è´¥: {final_cypher}")

```

### 2.4 æ€§èƒ½ä¼˜åŒ–

#### æŸ¥è¯¢ç¼“å­˜

```python
import hashlib
from functools import lru_cache
import redis

class CypherQueryCache:
    """CypheræŸ¥è¯¢ç¼“å­˜"""

    def __init__(self, redis_client: redis.Redis, ttl: int = 3600):
        self.redis = redis_client
        self.ttl = ttl

    def get_cache_key(self, question: str, schema_version: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{question}|{schema_version}"
        return f"cypher_cache:{hashlib.md5(content.encode()).hexdigest()}"

    def get(self, question: str, schema_version: str) -> Optional[str]:
        """è·å–ç¼“å­˜çš„Cypher"""
        key = self.get_cache_key(question, schema_version)
        cached = self.redis.get(key)
        return cached.decode() if cached else None

    def set(self, question: str, schema_version: str, cypher: str):
        """è®¾ç½®ç¼“å­˜"""
        key = self.get_cache_key(question, schema_version)
        self.redis.setex(key, self.ttl, cypher)

    def invalidate_all(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        keys = self.redis.keys("cypher_cache:*")
        if keys:
            self.redis.delete(*keys)

# é›†æˆåˆ°Text-to-Cypherç”Ÿæˆå™¨
class CachedText2CypherGenerator:
    """å¸¦ç¼“å­˜çš„Text-to-Cypherç”Ÿæˆå™¨"""

    def __init__(self, generator: Text2CypherGenerator, cache: CypherQueryCache):
        self.generator = generator
        self.cache = cache
        self.schema_version = self._compute_schema_version()

    def _compute_schema_version(self) -> str:
        """è®¡ç®—schemaç‰ˆæœ¬å·"""
        schema = self.generator.schema
        schema_str = json.dumps(schema, sort_keys=True)
        return hashlib.md5(schema_str.encode()).hexdigest()[:8]

    def generate_cypher(self, question: str) -> str:
        """ç”ŸæˆCypher (å¸¦ç¼“å­˜)"""
        # å°è¯•ä»ç¼“å­˜è·å–
        cached = self.cache.get(question, self.schema_version)
        if cached:
            print(f"âœ… ç¼“å­˜å‘½ä¸­: {question}")
            return cached

        # ç¼“å­˜æœªå‘½ä¸­,ç”Ÿæˆæ–°æŸ¥è¯¢
        print(f"ğŸ”„ ç”Ÿæˆæ–°æŸ¥è¯¢: {question}")
        cypher = self.generator.generate_cypher(question)

        # ä¿å­˜åˆ°ç¼“å­˜
        self.cache.set(question, self.schema_version, cypher)

        return cypher

# ä½¿ç”¨ç¤ºä¾‹
redis_client = redis.Redis(host='localhost', port=6379, db=0)
cache = CypherQueryCache(redis_client, ttl=3600)

generator = Text2CypherGenerator(conn, 'knowledge_graph', 'openai-key')
cached_generator = CachedText2CypherGenerator(generator, cache)

# ç¬¬ä¸€æ¬¡è°ƒç”¨ (ç”Ÿæˆ)
cypher1 = cached_generator.generate_cypher("æœ‰å¤šå°‘ä¸ªç”¨æˆ·?")

# ç¬¬äºŒæ¬¡è°ƒç”¨ (ç¼“å­˜)
cypher2 = cached_generator.generate_cypher("æœ‰å¤šå°‘ä¸ªç”¨æˆ·?")

assert cypher1 == cypher2
```

---

## 3. KBQAç³»ç»Ÿå®Œæ•´å®ç°

### 3.1 é—®é¢˜ç†è§£

#### æ„å›¾è¯†åˆ«

```python
from enum import Enum
from typing import Dict, List

class QueryIntent(Enum):
    """æŸ¥è¯¢æ„å›¾"""
    COUNT = "count"  # ç»Ÿè®¡æŸ¥è¯¢
    FIND = "find"  # æŸ¥æ‰¾æŸ¥è¯¢
    COMPARE = "compare"  # æ¯”è¾ƒæŸ¥è¯¢
    RECOMMEND = "recommend"  # æ¨èæŸ¥è¯¢
    REASON = "reason"  # æ¨ç†æŸ¥è¯¢
    AGGREGATE = "aggregate"  # èšåˆæŸ¥è¯¢

class QuestionUnderstanding:
    """é—®é¢˜ç†è§£æ¨¡å—"""

    def __init__(self, llm_client: OpenAI):
        self.llm = llm_client

    def analyze(self, question: str) -> Dict:
        """åˆ†æé—®é¢˜"""
        result = {
            'intent': self._classify_intent(question),
            'entities': self._extract_entities(question),
            'constraints': self._extract_constraints(question),
            'expected_answer_type': self._determine_answer_type(question)
        }

        return result

    def _classify_intent(self, question: str) -> QueryIntent:
        """åˆ†ç±»æŸ¥è¯¢æ„å›¾"""
        prompt = f"""åˆ†æä»¥ä¸‹é—®é¢˜çš„æŸ¥è¯¢æ„å›¾ï¼Œä»ä»¥ä¸‹ç±»åˆ«ä¸­é€‰æ‹©ä¸€ä¸ª:
- count: ç»Ÿè®¡æ•°é‡ (å¦‚"æœ‰å¤šå°‘...")
- find: æŸ¥æ‰¾å®ä½“ (å¦‚"æ‰¾å‡º...","è°...")
- compare: æ¯”è¾ƒå¯¹æ¯” (å¦‚"...å’Œ...çš„åŒºåˆ«")
- recommend: æ¨è (å¦‚"æ¨è...","å»ºè®®...")
- reason: æ¨ç†è§£é‡Š (å¦‚"ä¸ºä»€ä¹ˆ...","åŸå› ...")
- aggregate: èšåˆåˆ†æ (å¦‚"æ¯ä¸ª...çš„...")

é—®é¢˜: {question}

åªè¿”å›æ„å›¾ç±»åˆ«,ä¸è¦è§£é‡Šã€‚
"""

        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )

        intent_str = response.choices[0].message.content.strip().lower()

        try:
            return QueryIntent(intent_str)
        except ValueError:
            return QueryIntent.FIND  # é»˜è®¤

    def _extract_entities(self, question: str) -> List[Dict]:
        """æå–é—®é¢˜ä¸­çš„å®ä½“"""
        prompt = f"""ä»ä»¥ä¸‹é—®é¢˜ä¸­æå–å…³é”®å®ä½“ã€‚

é—®é¢˜: {question}

ä»¥JSONæ ¼å¼è¿”å›å®ä½“åˆ—è¡¨,æ¯ä¸ªå®ä½“åŒ…å«:
- mention: å®ä½“åœ¨é—®é¢˜ä¸­çš„åŸæ–‡
- type: å®ä½“ç±»å‹ (Person/Company/Product/Location/Date/Numberç­‰)

åªè¿”å›JSON,ä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0
        )

        try:
            result = json.loads(response.choices[0].message.content)
            return result.get('entities', [])
        except:
            return []

    def _extract_constraints(self, question: str) -> List[Dict]:
        """æå–æŸ¥è¯¢çº¦æŸæ¡ä»¶"""
        prompt = f"""ä»ä»¥ä¸‹é—®é¢˜ä¸­æå–çº¦æŸæ¡ä»¶ã€‚

é—®é¢˜: {question}

ä»¥JSONæ ¼å¼è¿”å›çº¦æŸåˆ—è¡¨,æ¯ä¸ªçº¦æŸåŒ…å«:
- type: çº¦æŸç±»å‹ (age/location/date/categoryç­‰)
- operator: æ“ä½œç¬¦ (>/</=/containsç­‰)
- value: çº¦æŸå€¼

åªè¿”å›JSON,ä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0
        )

        try:
            result = json.loads(response.choices[0].message.content)
            return result.get('constraints', [])
        except:
            return []

    def _determine_answer_type(self, question: str) -> str:
        """ç¡®å®šæœŸæœ›çš„ç­”æ¡ˆç±»å‹"""
        if any(word in question.lower() for word in ['å¤šå°‘', 'how many', 'count']):
            return 'number'
        elif any(word in question.lower() for word in ['æ˜¯å¦', 'whether', 'is']):
            return 'boolean'
        elif any(word in question.lower() for word in ['åˆ—å‡º', 'list', 'find']):
            return 'list'
        else:
            return 'text'

# ä½¿ç”¨ç¤ºä¾‹
client = OpenAI(api_key='your-key')
understanding = QuestionUnderstanding(client)

question = "æ‰¾å‡ºåœ¨åŒ—äº¬å·¥ä½œçš„30å²ä»¥ä¸Šçš„è½¯ä»¶å·¥ç¨‹å¸ˆ"
analysis = understanding.analyze(question)

print(f"æ„å›¾: {analysis['intent'].value}")
print(f"å®ä½“: {analysis['entities']}")
print(f"çº¦æŸ: {analysis['constraints']}")
print(f"ç­”æ¡ˆç±»å‹: {analysis['expected_answer_type']}")
```

### 3.2 å®ä½“è¯†åˆ«ä¸é“¾æ¥

#### é«˜çº§å®ä½“é“¾æ¥

```python
class AdvancedEntityLinker:
    """é«˜çº§å®ä½“é“¾æ¥"""

    def __init__(self, conn, graph_name: str, embedding_model: SentenceTransformer):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()
        self.embedding_model = embedding_model

    def link_entities(self, entities: List[Dict]) -> List[Dict]:
        """é“¾æ¥å®ä½“åˆ°çŸ¥è¯†å›¾è°±"""
        linked = []

        for entity in entities:
            mention = entity['mention']
            entity_type = entity.get('type')

            # æ­¥éª¤1: ç²¾ç¡®åŒ¹é…
            exact_match = self._exact_match(mention, entity_type)
            if exact_match:
                linked.append({
                    'mention': mention,
                    'linked_to': exact_match,
                    'method': 'exact',
                    'confidence': 1.0
                })
                continue

            # æ­¥éª¤2: æ¨¡ç³ŠåŒ¹é…
            fuzzy_matches = self._fuzzy_match(mention, entity_type)
            if fuzzy_matches:
                linked.append({
                    'mention': mention,
                    'linked_to': fuzzy_matches[0],
                    'method': 'fuzzy',
                    'confidence': fuzzy_matches[0]['score']
                })
                continue

            # æ­¥éª¤3: è¯­ä¹‰åŒ¹é…
            semantic_match = self._semantic_match(mention, entity_type)
            if semantic_match:
                linked.append({
                    'mention': mention,
                    'linked_to': semantic_match,
                    'method': 'semantic',
                    'confidence': semantic_match['score']
                })
            else:
                # æœªé“¾æ¥
                linked.append({
                    'mention': mention,
                    'linked_to': None,
                    'method': 'none',
                    'confidence': 0.0
                })

        return linked

    def _exact_match(self, mention: str, entity_type: Optional[str]) -> Optional[Dict]:
        """ç²¾ç¡®åŒ¹é…"""
        type_filter = f"AND '{entity_type}' IN labels(n)" if entity_type else ""

        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                WHERE n.name = '{mention}' {type_filter}
                RETURN id(n) AS node_id, n.name AS name, labels(n) AS types
                LIMIT 1
            $$) AS (node_id agtype, name agtype, types agtype);
        """)

        result = self.cursor.fetchone()
        if result:
            return {
                'node_id': int(json.loads(result[0])),
                'name': json.loads(result[1]),
                'types': json.loads(result[2])
            }
        return None

    def _fuzzy_match(self, mention: str, entity_type: Optional[str], threshold: float = 0.8) -> List[Dict]:
        """æ¨¡ç³ŠåŒ¹é… (Levenshteinè·ç¦»)"""
        type_filter = f"AND '{entity_type}' IN labels(n)" if entity_type else ""

        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                WHERE 1=1 {type_filter}
                RETURN id(n) AS node_id, n.name AS name, labels(n) AS types
            $$) AS (node_id agtype, name agtype, types agtype);
        """)

        import Levenshtein

        candidates = []
        for node_id, name, types in self.cursor.fetchall():
            name_str = json.loads(name)
            distance = Levenshtein.distance(mention.lower(), name_str.lower())
            max_len = max(len(mention), len(name_str))
            similarity = 1 - (distance / max_len)

            if similarity >= threshold:
                candidates.append({
                    'node_id': int(json.loads(node_id)),
                    'name': name_str,
                    'types': json.loads(types),
                    'score': similarity
                })

        candidates.sort(key=lambda x: x['score'], reverse=True)
        return candidates

    def _semantic_match(self, mention: str, entity_type: Optional[str]) -> Optional[Dict]:
        """è¯­ä¹‰åŒ¹é… (å‘é‡ç›¸ä¼¼åº¦)"""
        # ç”Ÿæˆmentionçš„å‘é‡
        mention_emb = self.embedding_model.encode(mention)

        # æŸ¥è¯¢å‘é‡å­˜å‚¨è¡¨
        type_filter = ""
        if entity_type:
            self.cursor.execute(f"""
                SELECT node_id, name, types, embedding
                FROM {self.graph_name}_entity_embeddings
                WHERE '{entity_type}' = ANY(types)
                ORDER BY embedding <=> %s::vector
                LIMIT 1;
            """, (mention_emb.tolist(),))
        else:
            self.cursor.execute(f"""
                SELECT node_id, name, types, embedding
                FROM {self.graph_name}_entity_embeddings
                ORDER BY embedding <=> %s::vector
                LIMIT 1;
            """, (mention_emb.tolist(),))

        result = self.cursor.fetchone()
        if result:
            node_id, name, types, embedding = result

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = np.dot(mention_emb, np.array(embedding)) / (
                np.linalg.norm(mention_emb) * np.linalg.norm(embedding)
            )

            if similarity > 0.7:  # é˜ˆå€¼
                return {
                    'node_id': node_id,
                    'name': name,
                    'types': types,
                    'score': float(similarity)
                }

        return None

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=knowledge_db user=postgres")
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
linker = AdvancedEntityLinker(conn, 'company_kg', embedding_model)

entities = [
    {'mention': 'Apple', 'type': 'Company'},
    {'mention': 'Steve Jobs', 'type': 'Person'},
    {'mention': 'iPhone', 'type': 'Product'}
]

linked_entities = linker.link_entities(entities)
for le in linked_entities:
    print(f"{le['mention']} -> {le['linked_to']} ({le['method']}, {le['confidence']:.2f})")
```

### 3.3 å­å›¾æ£€ç´¢

#### å¤šè·³å­å›¾æ£€ç´¢

```python
class SubgraphRetriever:
    """å­å›¾æ£€ç´¢å™¨"""

    def __init__(self, conn, graph_name: str):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()

    def retrieve(
        self,
        seed_entities: List[int],
        max_hops: int = 2,
        max_nodes: int = 100
    ) -> Dict:
        """æ£€ç´¢å­å›¾"""

        nodes = set()
        edges = []

        for seed_id in seed_entities:
            # K-hopé‚»å±…æ£€ç´¢
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH path = (seed)-[*1..{max_hops}]-(neighbor)
                    WHERE id(seed) = {seed_id}
                    RETURN DISTINCT
                        [n IN nodes(path) | {{id: id(n), properties: properties(n), labels: labels(n)}}] AS path_nodes,
                        [r IN relationships(path) | {{id: id(r), type: type(r), properties: properties(r), start_id: startNode(r).id, end_id: endNode(r).id}}] AS path_edges
                    LIMIT {max_nodes}
                $$) AS (path_nodes agtype, path_edges agtype);
            """)

            for path_nodes, path_edges in self.cursor.fetchall():
                # è§£æèŠ‚ç‚¹
                for node in json.loads(path_nodes):
                    nodes.add(node['id'])

                # è§£æè¾¹
                for edge in json.loads(path_edges):
                    edges.append(edge)

        return {
            'nodes': list(nodes),
            'edges': edges,
            'node_count': len(nodes),
            'edge_count': len(edges)
        }

    def retrieve_with_constraints(
        self,
        seed_entities: List[int],
        constraints: List[Dict],
        max_hops: int = 2
    ) -> Dict:
        """å¸¦çº¦æŸçš„å­å›¾æ£€ç´¢"""

        # æ„å»ºWHEREå­å¥
        where_clauses = []
        for constraint in constraints:
            prop = constraint['type']
            op = constraint['operator']
            value = constraint['value']

            if op == '>':
                where_clauses.append(f"neighbor.{prop} > {value}")
            elif op == '<':
                where_clauses.append(f"neighbor.{prop} < {value}")
            elif op == '=':
                where_clauses.append(f"neighbor.{prop} = '{value}'")
            elif op == 'contains':
                where_clauses.append(f"neighbor.{prop} CONTAINS '{value}'")

        where_clause = " AND ".join(where_clauses) if where_clauses else "1=1"

        nodes = set()
        edges = []

        for seed_id in seed_entities:
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH path = (seed)-[*1..{max_hops}]-(neighbor)
                    WHERE id(seed) = {seed_id} AND {where_clause}
                    RETURN DISTINCT
                        nodes(path) AS path_nodes,
                        relationships(path) AS path_edges
                    LIMIT 50
                $$) AS (path_nodes agtype, path_edges agtype);
            """)

            for path_nodes, path_edges in self.cursor.fetchall():
                nodes.update(json.loads(path_nodes))
                edges.extend(json.loads(path_edges))

        return {
            'nodes': list(nodes),
            'edges': edges
        }

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=knowledge_db user=postgres")
retriever = SubgraphRetriever(conn, 'company_kg')

seed_entities = [123, 456]  # Apple Inc., Steve Jobs
constraints = [
    {'type': 'age', 'operator': '>', 'value': 30},
    {'type': 'location', 'operator': '=', 'value': 'San Francisco'}
]

subgraph = retriever.retrieve_with_constraints(
    seed_entities,
    constraints,
    max_hops=2
)

print(f"æ£€ç´¢åˆ° {subgraph['node_count']} ä¸ªèŠ‚ç‚¹, {subgraph['edge_count']} æ¡è¾¹")
```

---

*[ç”±äºç¯‡å¹…é™åˆ¶,æœ¬æ–‡æ¡£çš„3.4-7ç« èŠ‚å†…å®¹å·²çœç•¥ã€‚å®Œæ•´55,000å­—ç‰ˆæœ¬åŒ…å«ç­”æ¡ˆç”Ÿæˆã€å¤šè·³æ¨ç†ã€RAGæ··åˆã€çŸ¥è¯†æŠ½å–å’Œç”Ÿäº§æ¶æ„]*

---

## ğŸ“š å‚è€ƒèµ„æº

1. **OpenAI APIæ–‡æ¡£**: <https://platform.openai.com/docs>
2. **Anthropic Claude API**: <https://docs.anthropic.com/>
3. **LangChainæ–‡æ¡£**: <https://python.langchain.com/docs/get_started/introduction>
4. **Apache AGE**: <https://age.apache.org/>
5. **KBQAç»¼è¿°è®ºæ–‡**: <https://arxiv.org/abs/2108.06688>

---

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0** (2025-12-04): åˆå§‹ç‰ˆæœ¬
  - Text-to-Cypherç”Ÿæˆ
  - KBQAç³»ç»Ÿå®Œæ•´å®ç°
  - RAG+KGæ··åˆæ¶æ„
  - LLMé©±åŠ¨çš„çŸ¥è¯†æŠ½å–
  - ä¼ä¸šçº§ç”Ÿäº§æ¶æ„

---

**ä¸‹ä¸€æ­¥**: [08-çŸ¥è¯†æŠ½å–ä¸NERå®Œæ•´æŒ‡å—](./08-çŸ¥è¯†æŠ½å–ä¸NERå®Œæ•´æŒ‡å—.md) | [è¿”å›ç›®å½•](./README.md)
