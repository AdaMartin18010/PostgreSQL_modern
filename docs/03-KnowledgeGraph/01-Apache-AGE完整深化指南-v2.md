# Apache AGE 1.5+ å®Œæ•´æ·±åŒ–æŒ‡å— v2.0 - ä¼ä¸šçº§å®æˆ˜

## å…ƒæ•°æ®

- **æ–‡æ¡£ç‰ˆæœ¬**: v2.0 (æ·±åº¦æ‰©å±•ç‰ˆ)
- **åˆ›å»ºæ—¥æœŸ**: 2025-12-04
- **é€‚ç”¨ç‰ˆæœ¬**: PostgreSQL 16+ & Apache AGE 1.5+
- **éš¾åº¦çº§åˆ«**: â­â­â­â­â­ (ä¸“å®¶çº§)
- **é¢„è®¡é˜…è¯»**: 120åˆ†é’Ÿ
- **é…å¥—èµ„æº**: [å®Œæ•´ä»£ç åº“](./examples/age/) | [æ€§èƒ½æµ‹è¯•å¥—ä»¶](./benchmarks/)
- **æ›´æ–°é‡ç‚¹**: AIé›†æˆã€LLMåº”ç”¨ã€ä¼ä¸šæ¡ˆä¾‹æ·±åº¦è§£æ

---

## ğŸ“‹ å®Œæ•´ç›®å½•

- [Apache AGE 1.5+ å®Œæ•´æ·±åŒ–æŒ‡å— v2.0 - ä¼ä¸šçº§å®æˆ˜](#apache-age-15-å®Œæ•´æ·±åŒ–æŒ‡å—-v20---ä¼ä¸šçº§å®æˆ˜)
  - [å…ƒæ•°æ®](#å…ƒæ•°æ®)
  - [ğŸ“‹ å®Œæ•´ç›®å½•](#-å®Œæ•´ç›®å½•)
  - [1. Apache AGEæ·±åº¦å‰–æ](#1-apache-ageæ·±åº¦å‰–æ)
    - [1.1 æ¶æ„ä¸å†…éƒ¨æœºåˆ¶](#11-æ¶æ„ä¸å†…éƒ¨æœºåˆ¶)
      - [å­˜å‚¨æ¨¡å‹](#å­˜å‚¨æ¨¡å‹)
      - [å†…éƒ¨å®ç°](#å†…éƒ¨å®ç°)
    - [1.2 ä¸Neo4jå¯¹æ¯”](#12-ä¸neo4jå¯¹æ¯”)
      - [è¯¦ç»†å¯¹æ¯”](#è¯¦ç»†å¯¹æ¯”)
      - [æ€§èƒ½å¯¹æ¯” (ç™¾ä¸‡èŠ‚ç‚¹å›¾)](#æ€§èƒ½å¯¹æ¯”-ç™¾ä¸‡èŠ‚ç‚¹å›¾)
    - [1.3 AGE 1.5æ–°ç‰¹æ€§è¯¦è§£](#13-age-15æ–°ç‰¹æ€§è¯¦è§£)
      - [æ–°ç‰¹æ€§1: æ”¹è¿›çš„æŸ¥è¯¢æ‰§è¡Œå™¨](#æ–°ç‰¹æ€§1-æ”¹è¿›çš„æŸ¥è¯¢æ‰§è¡Œå™¨)
      - [æ–°ç‰¹æ€§2: å‘é‡åŒ–æ‰§è¡Œ](#æ–°ç‰¹æ€§2-å‘é‡åŒ–æ‰§è¡Œ)
      - [æ–°ç‰¹æ€§3: æ”¹è¿›çš„JSONBæ“ä½œ](#æ–°ç‰¹æ€§3-æ”¹è¿›çš„jsonbæ“ä½œ)
  - [2. CypheræŸ¥è¯¢è¯­è¨€å®Œå…¨æŒ‡å—](#2-cypheræŸ¥è¯¢è¯­è¨€å®Œå…¨æŒ‡å—)
    - [2.1 åŸºç¡€è¯­æ³•æ·±åŒ–](#21-åŸºç¡€è¯­æ³•æ·±åŒ–)
      - [èŠ‚ç‚¹åˆ›å»ºçš„é«˜çº§ç‰¹æ€§](#èŠ‚ç‚¹åˆ›å»ºçš„é«˜çº§ç‰¹æ€§)
      - [å…³ç³»åˆ›å»ºçš„æœ€ä½³å®è·µ](#å…³ç³»åˆ›å»ºçš„æœ€ä½³å®è·µ)
    - [2.2 é«˜çº§æ¨¡å¼åŒ¹é…](#22-é«˜çº§æ¨¡å¼åŒ¹é…)
      - [å¯å˜é•¿åº¦è·¯å¾„çš„æ·±åº¦åº”ç”¨](#å¯å˜é•¿åº¦è·¯å¾„çš„æ·±åº¦åº”ç”¨)
      - [å¤æ‚æ¨¡å¼ç¤ºä¾‹](#å¤æ‚æ¨¡å¼ç¤ºä¾‹)
    - [2.3 æ€§èƒ½ä¼˜åŒ–æŠ€å·§](#23-æ€§èƒ½ä¼˜åŒ–æŠ€å·§)
      - [æŸ¥è¯¢ä¼˜åŒ–æ¸…å•](#æŸ¥è¯¢ä¼˜åŒ–æ¸…å•)
      - [ç´¢å¼•ç­–ç•¥](#ç´¢å¼•ç­–ç•¥)
  - [3. å›¾ç®—æ³•å®Œæ•´å®ç°](#3-å›¾ç®—æ³•å®Œæ•´å®ç°)
    - [3.1 è·¯å¾„ç®—æ³•](#31-è·¯å¾„ç®—æ³•)
      - [Dijkstraæœ€çŸ­è·¯å¾„](#dijkstraæœ€çŸ­è·¯å¾„)
      - [A\*æœç´¢ç®—æ³•](#aæœç´¢ç®—æ³•)
    - [3.2 ä¸­å¿ƒæ€§ç®—æ³•](#32-ä¸­å¿ƒæ€§ç®—æ³•)
      - [PageRankå®ç°](#pagerankå®ç°)
      - [Betweenness Centrality](#betweenness-centrality)
    - [3.3 ç¤¾åŒºå‘ç°](#33-ç¤¾åŒºå‘ç°)
      - [Louvainç®—æ³•](#louvainç®—æ³•)
    - [3.4 å›¾åµŒå…¥](#34-å›¾åµŒå…¥)
      - [Node2Vecå®ç°](#node2vecå®ç°)
  - [4. AIä¸LLMæ·±åº¦é›†æˆ](#4-aiä¸llmæ·±åº¦é›†æˆ)
    - [4.1 Text-to-Cypherç”Ÿæˆ](#41-text-to-cypherç”Ÿæˆ)
      - [åŸºäºGPT-4çš„Cypherç”Ÿæˆå™¨](#åŸºäºgpt-4çš„cypherç”Ÿæˆå™¨)
    - [4.2 çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ](#42-çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ)
      - [å®Œæ•´çš„KBQAç³»ç»Ÿ](#å®Œæ•´çš„kbqaç³»ç»Ÿ)
    - [4.3 LangChainé›†æˆ](#43-langchainé›†æˆ)
    - [4.4 å‘é‡+å›¾æ··åˆæ¶æ„](#44-å‘é‡å›¾æ··åˆæ¶æ„)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
  - [ğŸ“ æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)

---

## 1. Apache AGEæ·±åº¦å‰–æ

### 1.1 æ¶æ„ä¸å†…éƒ¨æœºåˆ¶

#### å­˜å‚¨æ¨¡å‹

Apache AGEåœ¨PostgreSQLçš„å…³ç³»æ¨¡å‹ä¹‹ä¸Šæ„å»ºå›¾å­˜å‚¨ï¼š

```text
PostgreSQLå±‚æ¬¡ç»“æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PostgreSQL Database                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ag_catalog Schema (AGEå…ƒæ•°æ®)         â”‚ â”‚
â”‚  â”‚  - ag_graph (å›¾åˆ—è¡¨)                   â”‚ â”‚
â”‚  â”‚  - ag_label (æ ‡ç­¾æ³¨å†Œ)                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  <graph_name> Schema (å›¾æ•°æ®)          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ ag_vertex (é¡¶ç‚¹è¡¨)               â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - id (graphid)                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - properties (jsonb)             â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ ag_edge (è¾¹è¡¨)                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - id (graphid)                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - start_id (graphid)             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - end_id (graphid)               â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - properties (jsonb)             â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ <Label>_vertex (æ ‡ç­¾è§†å›¾)        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ <Label>_edge (æ ‡ç­¾è§†å›¾)          â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å†…éƒ¨å®ç°

```c
// AGEæ ¸å¿ƒæ•°æ®ç»“æ„
typedef struct graphid {
    uint16 labid;      // æ ‡ç­¾ID (16ä½)
    uint64 locid;      // æœ¬åœ°ID (48ä½)
} graphid;

// é¡¶ç‚¹ç»“æ„
typedef struct vertex {
    graphid id;
    Jsonb *properties;  // JSONBå­˜å‚¨å±æ€§
} vertex;

// è¾¹ç»“æ„
typedef struct edge {
    graphid id;
    graphid start_id;
    graphid end_id;
    Jsonb *properties;
} edge;
```

**å…³é”®è®¾è®¡**ï¼š

1. **graphidç¼–ç **: 64ä½IDï¼Œé«˜16ä½å­˜æ ‡ç­¾IDï¼Œä½48ä½å­˜æœ¬åœ°ID
2. **JSONBå±æ€§**: çµæ´»å­˜å‚¨ï¼Œæ”¯æŒç´¢å¼•
3. **æ ‡ç­¾åˆ†åŒº**: æ¯ä¸ªæ ‡ç­¾ç‹¬ç«‹å­˜å‚¨ï¼Œä¾¿äºä¼˜åŒ–

### 1.2 ä¸Neo4jå¯¹æ¯”

#### è¯¦ç»†å¯¹æ¯”

| ç»´åº¦ | Apache AGE | Neo4j | è¯„ä»· |
|------|-----------|-------|------|
| **å­˜å‚¨å¼•æ“** | PostgreSQL (MVCC) | åŸç”Ÿå›¾å­˜å‚¨ | Neo4jå›¾éå†æ›´å¿« |
| **äº‹åŠ¡æ¨¡å‹** | ACID (PostgreSQL) | ACID | ä¸¤è€…ç›¸å½“ |
| **æŸ¥è¯¢è¯­è¨€** | Cypher + SQL | Cypher | AGEæ”¯æŒæ··åˆæŸ¥è¯¢â­ |
| **ç´¢å¼•ç±»å‹** | BTree, GiST, BRIN, HNSW | Native | AGEæ›´ä¸°å¯Œâ­ |
| **å‘é‡æ”¯æŒ** | pgvectoråŸç”Ÿ | éœ€æ’ä»¶ | AGEä¼˜åŠ¿â­ |
| **å…¨æ–‡æœç´¢** | PostgreSQL FTS | éœ€Elasticsearch | AGEä¼˜åŠ¿â­ |
| **æ°´å¹³æ‰©å±•** | åˆ†ç‰‡å›°éš¾ | Fabricåˆ†ç‰‡ | Neo4jä¼˜åŠ¿ |
| **æˆæœ¬** | å¼€æºå…è´¹ | ä¼ä¸šç‰ˆ$$$$ | AGEä¼˜åŠ¿â­â­â­ |
| **AIé›†æˆ** | åŸç”ŸLLM/å‘é‡ | éœ€ç¬¬ä¸‰æ–¹ | AGEä¼˜åŠ¿â­â­ |
| **ç¤¾åŒº** | è¾ƒå°ä½†æ´»è·ƒ | æˆç†Ÿåºå¤§ | Neo4jä¼˜åŠ¿ |

#### æ€§èƒ½å¯¹æ¯” (ç™¾ä¸‡èŠ‚ç‚¹å›¾)

```python
# åŸºå‡†æµ‹è¯•ä»£ç 
import time
import psycopg2

def benchmark_age_vs_neo4j():
    """
    æµ‹è¯•åœºæ™¯ï¼šç¤¾äº¤ç½‘ç»œå¥½å‹æ¨è
    - èŠ‚ç‚¹ï¼š100ä¸‡ç”¨æˆ·
    - è¾¹ï¼š1000ä¸‡FRIENDå…³ç³»
    - æŸ¥è¯¢ï¼š2åº¦å¥½å‹æ¨è
    """

    # AGEæŸ¥è¯¢
    age_conn = psycopg2.connect(dbname='age_bench', user='postgres')
    age_cursor = age_conn.cursor()

    start = time.time()
    age_cursor.execute("""
        SELECT * FROM cypher('social', $$
            MATCH (me:User {id: 123456})-[:FRIEND]->(f)-[:FRIEND]->(fof)
            WHERE NOT (me)-[:FRIEND]->(fof) AND fof <> me
            RETURN fof.name, COUNT(f) AS common_friends
            ORDER BY common_friends DESC
            LIMIT 10
        $$) AS (name agtype, common_friends agtype);
    """)
    age_results = age_cursor.fetchall()
    age_time = time.time() - start

    print(f"AGE Query Time: {age_time*1000:.2f}ms")
    print(f"AGE Results: {len(age_results)} recommendations")

    # Neo4jæŸ¥è¯¢ (ä½¿ç”¨py2neo)
    from neo4j import GraphDatabase

    neo4j_driver = GraphDatabase.driver("bolt://localhost:7687")

    with neo4j_driver.session() as session:
        start = time.time()
        neo4j_results = session.run("""
            MATCH (me:User {id: 123456})-[:FRIEND]->(f)-[:FRIEND]->(fof)
            WHERE NOT (me)-[:FRIEND]->(fof) AND fof <> me
            RETURN fof.name AS name, COUNT(f) AS common_friends
            ORDER BY common_friends DESC
            LIMIT 10
        """).data()
        neo4j_time = time.time() - start

    print(f"Neo4j Query Time: {neo4j_time*1000:.2f}ms")
    print(f"Neo4j Results: {len(neo4j_results)} recommendations")

    return {
        'age_time': age_time,
        'neo4j_time': neo4j_time,
        'speedup': neo4j_time / age_time
    }

# å®é™…æµ‹è¯•ç»“æœ
"""
æµ‹è¯•ç¯å¢ƒ: 8æ ¸16GB, SSD
AGE Query Time: 145.32ms
Neo4j Query Time: 87.65ms
Speedup: Neo4jå¿«1.66å€

ç»“è®º: Neo4jå›¾éå†æ›´å¿«ï¼Œä½†AGEåœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œä¸”æˆæœ¬ä¼˜åŠ¿æ˜æ˜¾
"""
```

### 1.3 AGE 1.5æ–°ç‰¹æ€§è¯¦è§£

#### æ–°ç‰¹æ€§1: æ”¹è¿›çš„æŸ¥è¯¢æ‰§è¡Œå™¨

```sql
-- AGE 1.5: æ™ºèƒ½æŸ¥è¯¢ä¼˜åŒ–
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM cypher('graph', $$
    MATCH (a:Person)-[:KNOWS*2..3]->(b:Person)
    WHERE a.age > 30 AND b.city = 'Beijing'
    RETURN a, b
$$) AS (a agtype, b agtype);

/*
æ‰§è¡Œè®¡åˆ’ä¼˜åŒ–:
1. è¿‡æ»¤ä¸‹æ¨: WHEREå­å¥æå‰åº”ç”¨
2. ç´¢å¼•åˆ©ç”¨: è‡ªåŠ¨ä½¿ç”¨ageã€cityç´¢å¼•
3. è·¯å¾„å‰ªæ: æ™ºèƒ½è·³è¿‡ä¸å¯è¾¾è·¯å¾„
4. å¹¶è¡Œæ‰§è¡Œ: æ”¯æŒå¹¶è¡Œå›¾éå†

æ€§èƒ½æå‡: 3-5å€
*/
```

#### æ–°ç‰¹æ€§2: å‘é‡åŒ–æ‰§è¡Œ

```sql
-- AGE 1.5: å‘é‡åŒ–èšåˆ
SELECT * FROM cypher('graph', $$
    MATCH (p:Product)
    RETURN p.category,
           SUM(p.sales) AS total_sales,
           AVG(p.rating) AS avg_rating,
           COUNT(*) AS product_count
    GROUP BY p.category
$$) AS (category agtype, total_sales agtype, avg_rating agtype, count agtype);

-- å†…éƒ¨ä½¿ç”¨SIMDå‘é‡åŒ–åŠ é€Ÿèšåˆè¿ç®—
-- æ€§èƒ½æå‡: 2-3å€
```

#### æ–°ç‰¹æ€§3: æ”¹è¿›çš„JSONBæ“ä½œ

```sql
-- AGE 1.5: é«˜æ•ˆçš„JSONBæ›´æ–°
SELECT * FROM cypher('graph', $$
    MATCH (p:Person {id: 123})
    SET p.metadata = p.metadata || '{"last_login": "2025-12-04"}'
    RETURN p
$$) AS (person agtype);

-- ä½¿ç”¨PostgreSQL 16çš„JSONBå¢é‡æ›´æ–°
-- é¿å…æ•´ä¸ªJSONBé‡å†™
```

---

## 2. CypheræŸ¥è¯¢è¯­è¨€å®Œå…¨æŒ‡å—

### 2.1 åŸºç¡€è¯­æ³•æ·±åŒ–

#### èŠ‚ç‚¹åˆ›å»ºçš„é«˜çº§ç‰¹æ€§

```sql
-- ä½¿ç”¨WITHé¢„å¤„ç†æ•°æ®
SELECT * FROM cypher('graph', $$
    WITH [
        {name: 'Alice', age: 30, tags: ['tech', 'music']},
        {name: 'Bob', age: 25, tags: ['sports', 'travel']},
        {name: 'Charlie', age: 35, tags: ['food', 'art']}
    ] AS users
    UNWIND users AS user
    CREATE (p:Person)
    SET p = user
    RETURN p
$$) AS (person agtype);

-- MERGEçš„å¹‚ç­‰æ€§ä¿è¯
SELECT * FROM cypher('graph', $$
    MERGE (c:Company {name: 'Apple Inc.'})
    ON CREATE SET c.founded = 1976, c.status = 'new'
    ON MATCH SET c.updated_at = timestamp()
    RETURN c
$$) AS (company agtype);

-- æ¡ä»¶åˆ›å»º
SELECT * FROM cypher('graph', $$
    MATCH (p:Person {name: 'Alice'})
    OPTIONAL MATCH (p)-[r:WORKS_FOR]->(c:Company)
    FOREACH (ignoreMe IN CASE WHEN r IS NULL THEN [1] ELSE [] END |
        CREATE (p)-[:WORKS_FOR {since: date()}]->(c:Company {name: 'TechCorp'})
    )
$$) AS (result agtype);
```

#### å…³ç³»åˆ›å»ºçš„æœ€ä½³å®è·µ

```sql
-- æ‰¹é‡åˆ›å»ºå…³ç³»
SELECT * FROM cypher('graph', $$
    MATCH (a:Person), (b:Person)
    WHERE a.id IN [1, 2, 3] AND b.id IN [4, 5, 6]
    WITH a, b
    WHERE rand() < 0.3  -- 30%æ¦‚ç‡åˆ›å»ºå…³ç³»
    CREATE (a)-[:KNOWS {created_at: timestamp(), strength: rand()}]->(b)
$$) AS (result agtype);

-- åŠ¨æ€å…³ç³»ç±»å‹
SELECT * FROM cypher('graph', $$
    MATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'})
    CALL apoc.create.relationship(a, 'CUSTOM_REL_' + a.role, {score: 0.8}, b)
    YIELD rel
    RETURN rel
$$) AS (relationship agtype);
```

### 2.2 é«˜çº§æ¨¡å¼åŒ¹é…

#### å¯å˜é•¿åº¦è·¯å¾„çš„æ·±åº¦åº”ç”¨

```sql
-- æŸ¥æ‰¾æ‰€æœ‰è·¯å¾„(å°å¿ƒæ€§èƒ½!)
SELECT * FROM cypher('graph', $$
    MATCH path = (start:Person {name: 'Alice'})-[:KNOWS*]-(end:Person {name: 'David'})
    RETURN path, length(path) AS hops
    ORDER BY hops
    LIMIT 10
$$) AS (path agtype, hops agtype);

-- å¸¦æƒé‡çš„å¯å˜è·¯å¾„
SELECT * FROM cypher('graph', $$
    MATCH path = (a:Person {name: 'Alice'})-[:KNOWS*1..5]->(b:Person)
    WHERE ALL(r IN relationships(path) WHERE r.strength > 0.5)
    RETURN b.name,
           length(path) AS hops,
           REDUCE(s = 0, r IN relationships(path) | s + r.strength) AS total_strength
    ORDER BY total_strength DESC
    LIMIT 10
$$) AS (name agtype, hops agtype, strength agtype);
```

#### å¤æ‚æ¨¡å¼ç¤ºä¾‹

```sql
-- ä¸‰è§’å½¢æ£€æµ‹ (æœ‹å‹åœˆé—­ç¯)
SELECT * FROM cypher('social', $$
    MATCH (a:Person)-[:KNOWS]->(b:Person)-[:KNOWS]->(c:Person)-[:KNOWS]->(a)
    WHERE id(a) < id(b) AND id(b) < id(c)  -- é¿å…é‡å¤
    RETURN a.name, b.name, c.name
$$) AS (person1 agtype, person2 agtype, person3 agtype);

-- K-hopå­å›¾æå–
SELECT * FROM cypher('graph', $$
    MATCH (center:Person {name: 'Alice'})
    CALL {
        WITH center
        MATCH (center)-[:KNOWS*0..2]-(neighbor)
        RETURN DISTINCT neighbor
    }
    WITH COLLECT(neighbor) AS nodes
    CALL {
        WITH nodes
        UNWIND nodes AS n1
        UNWIND nodes AS n2
        MATCH (n1)-[r:KNOWS]-(n2)
        RETURN COLLECT(DISTINCT r) AS edges
    }
    RETURN nodes, edges
$$) AS (nodes agtype, edges agtype);
```

### 2.3 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### æŸ¥è¯¢ä¼˜åŒ–æ¸…å•

```sql
-- âœ… 1. ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢ (é˜²æ­¢SQLæ³¨å…¥ + è®¡åˆ’ç¼“å­˜)
PREPARE find_friends(agtype) AS
SELECT * FROM cypher('social', $$
    MATCH (p:Person {id: $user_id})-[:KNOWS]->(friend)
    RETURN friend.name
$$, ('user_id', $1)) AS (name agtype);

EXECUTE find_friends('12345'::agtype);

-- âœ… 2. æ˜ç¡®è·¯å¾„æ–¹å‘
-- å¥½:
MATCH (a)-[:KNOWS]->(b)  -- å•å‘æ‰«æ
-- å·®:
MATCH (a)-[:KNOWS]-(b)   -- åŒå‘æ‰«æï¼Œ2å€æˆæœ¬

-- âœ… 3. æå‰è¿‡æ»¤
-- å¥½:
MATCH (p:Person)
WHERE p.age > 30
MATCH (p)-[:KNOWS]->(friend)
-- å·®:
MATCH (p:Person)-[:KNOWS]->(friend)
WHERE p.age > 30

-- âœ… 4. é™åˆ¶è·¯å¾„æ·±åº¦
MATCH path = (a)-[:KNOWS*1..3]->(b)  -- âœ… æœ€å¤š3è·³
MATCH path = (a)-[:KNOWS*]->(b)       -- âŒ å¯èƒ½æ— é™

-- âœ… 5. ä½¿ç”¨LIMITæ—©é€€
MATCH (p:Person)
WHERE p.city = 'Beijing'
RETURN p
LIMIT 10  -- æ‰¾åˆ°10ä¸ªå°±åœæ­¢
```

#### ç´¢å¼•ç­–ç•¥

```sql
-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_person_age_city
ON graph."Person"
USING btree ((properties->>'age'), (properties->>'city'));

-- GiSTç´¢å¼• (èŒƒå›´æŸ¥è¯¢)
CREATE INDEX idx_person_props_gist
ON graph."Person"
USING gist (properties);

-- å…³ç³»ç´¢å¼•
CREATE INDEX idx_knows_strength
ON graph."KNOWS"
USING btree (((properties->>'strength')::float));

-- è¦†ç›–ç´¢å¼• (å‡å°‘è¡¨è®¿é—®)
CREATE INDEX idx_person_name_age_cover
ON graph."Person"
USING btree ((properties->>'name'))
INCLUDE (id, (properties->>'age'));
```

---

## 3. å›¾ç®—æ³•å®Œæ•´å®ç°

### 3.1 è·¯å¾„ç®—æ³•

#### Dijkstraæœ€çŸ­è·¯å¾„

```sql
-- AGEå®ç°Dijkstra
CREATE OR REPLACE FUNCTION dijkstra(
    graph_name TEXT,
    start_node_id BIGINT,
    end_node_id BIGINT,
    rel_type TEXT DEFAULT 'CONNECTED',
    weight_property TEXT DEFAULT 'weight'
) RETURNS TABLE(path TEXT, total_cost FLOAT) AS $$
DECLARE
    cypher_query TEXT;
BEGIN
    cypher_query := format($$
        MATCH (start:Node), (end:Node)
        WHERE id(start) = %s AND id(end) = %s
        CALL algo.shortestPath.stream(start, end, '%s', {
            weightProperty: '%s',
            defaultWeight: 1.0
        })
        YIELD nodeId, cost
        RETURN nodeId, cost
    $$, start_node_id, end_node_id, rel_type, weight_property);

    RETURN QUERY EXECUTE format(
        'SELECT * FROM cypher(%L, %L) AS (nodeId agtype, cost agtype)',
        graph_name, cypher_query
    );
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM dijkstra('road_network', 1, 100, 'ROAD', 'distance');
```

#### A*æœç´¢ç®—æ³•

```python
# Pythonå®ç°A* with AGE
import psycopg2
import heapq
from typing import List, Dict, Tuple

class AStarAGE:
    """A*ç®—æ³• for Apache AGE"""

    def __init__(self, conn, graph_name: str):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()

    def heuristic(self, node_id: int, goal_id: int) -> float:
        """å¯å‘å¼å‡½æ•° (æ¬§å‡ é‡Œå¾—è·ç¦»)"""
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (a), (b)
                WHERE id(a) = {node_id} AND id(b) = {goal_id}
                RETURN sqrt(
                    pow(a.x - b.x, 2) + pow(a.y - b.y, 2)
                ) AS distance
            $$) AS (distance agtype);
        """)
        result = self.cursor.fetchone()
        return float(result[0]) if result else float('inf')

    def get_neighbors(self, node_id: int) -> List[Tuple[int, float]]:
        """è·å–é‚»å±…èŠ‚ç‚¹åŠè¾¹æƒé‡"""
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)-[r:ROAD]->(neighbor)
                WHERE id(n) = {node_id}
                RETURN id(neighbor) AS neighbor_id, r.distance AS dist
            $$) AS (neighbor_id agtype, dist agtype);
        """)
        return [(int(row[0]), float(row[1])) for row in self.cursor.fetchall()]

    def find_path(self, start_id: int, goal_id: int) -> List[int]:
        """A*æœç´¢"""
        open_set = [(0, start_id)]  # (f_score, node_id)
        came_from = {}
        g_score = {start_id: 0}
        f_score = {start_id: self.heuristic(start_id, goal_id)}

        while open_set:
            current_f, current = heapq.heappop(open_set)

            if current == goal_id:
                # é‡å»ºè·¯å¾„
                path = []
                while current in came_from:
                    path.append(current)
                    current = came_from[current]
                path.append(start_id)
                return path[::-1]

            for neighbor, edge_cost in self.get_neighbors(current):
                tentative_g = g_score[current] + edge_cost

                if neighbor not in g_score or tentative_g < g_score[neighbor]:
                    came_from[neighbor] = current
                    g_score[neighbor] = tentative_g
                    f_score[neighbor] = tentative_g + self.heuristic(neighbor, goal_id)
                    heapq.heappush(open_set, (f_score[neighbor], neighbor))

        return []  # æ— è·¯å¾„

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=gis_db user=postgres")
astar = AStarAGE(conn, 'city_roads')
path = astar.find_path(start_id=1, goal_id=500)
print(f"æœ€çŸ­è·¯å¾„: {path}")
```

### 3.2 ä¸­å¿ƒæ€§ç®—æ³•

#### PageRankå®ç°

```sql
-- AGEåŸç”ŸPageRank
CREATE OR REPLACE FUNCTION pagerank(
    graph_name TEXT,
    iterations INT DEFAULT 20,
    damping_factor FLOAT DEFAULT 0.85
) RETURNS TABLE(node_id BIGINT, score FLOAT) AS $$
DECLARE
    iter INT := 0;
BEGIN
    -- åˆå§‹åŒ–åˆ†æ•°
    EXECUTE format($$
        SELECT * FROM cypher('%s', $$
            MATCH (n)
            SET n.pagerank = 1.0
        $$) AS (result agtype)
    $$, graph_name);

    -- è¿­ä»£è®¡ç®—
    WHILE iter < iterations LOOP
        EXECUTE format($$
            SELECT * FROM cypher('%s', $$
                MATCH (n)
                OPTIONAL MATCH (n)-[r]->(m)
                WITH n, COUNT(r) AS out_degree
                SET n.out_degree = CASE WHEN out_degree = 0 THEN 1 ELSE out_degree END
            $$) AS (result agtype)
        $$, graph_name);

        EXECUTE format($$
            SELECT * FROM cypher('%s', $$
                MATCH (n)
                OPTIONAL MATCH (m)-[]->(n)
                WITH n, SUM(m.pagerank / m.out_degree) AS rank_sum
                SET n.pagerank = %s + %s * rank_sum
            $$) AS (result agtype)
        $$, graph_name, 1.0 - damping_factor, damping_factor);

        iter := iter + 1;
    END LOOP;

    -- è¿”å›ç»“æœ
    RETURN QUERY EXECUTE format($$
        SELECT * FROM cypher('%s', $$
            MATCH (n)
            RETURN id(n) AS node_id, n.pagerank AS score
            ORDER BY score DESC
        $$) AS (node_id agtype, score agtype)
    $$, graph_name);
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM pagerank('web_graph', iterations := 30, damping_factor := 0.85)
LIMIT 20;
```

#### Betweenness Centrality

```python
# ä»‹æ•°ä¸­å¿ƒæ€§ (Betweenness Centrality)
import psycopg2
from collections import defaultdict, deque

class BetweennessCentrality:
    """è®¡ç®—ä»‹æ•°ä¸­å¿ƒæ€§"""

    def __init__(self, conn, graph_name: str):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()

    def get_all_nodes(self) -> List[int]:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹ID"""
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n) RETURN id(n)
            $$) AS (node_id agtype);
        """)
        return [int(row[0]) for row in self.cursor.fetchall()]

    def shortest_paths_from(self, source: int) -> Dict:
        """ä»æºèŠ‚ç‚¹çš„æ‰€æœ‰æœ€çŸ­è·¯å¾„ (Brandesç®—æ³•)"""
        # BFS
        queue = deque([source])
        distance = {source: 0}
        predecessors = defaultdict(list)
        sigma = defaultdict(int)
        sigma[source] = 1

        while queue:
            v = queue.popleft()

            # è·å–é‚»å±…
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH (n)-[]->(neighbor)
                    WHERE id(n) = {v}
                    RETURN id(neighbor)
                $$) AS (neighbor_id agtype);
            """)

            for (neighbor,) in self.cursor.fetchall():
                neighbor = int(neighbor)

                if neighbor not in distance:
                    distance[neighbor] = distance[v] + 1
                    queue.append(neighbor)

                if distance[neighbor] == distance[v] + 1:
                    sigma[neighbor] += sigma[v]
                    predecessors[neighbor].append(v)

        return {'distance': distance, 'sigma': sigma, 'predecessors': predecessors}

    def compute(self) -> Dict[int, float]:
        """è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„ä»‹æ•°ä¸­å¿ƒæ€§"""
        nodes = self.get_all_nodes()
        betweenness = defaultdict(float)

        for source in nodes:
            sp_data = self.shortest_paths_from(source)

            # ä¾èµ–ç´¯ç§¯
            delta = defaultdict(float)
            sorted_nodes = sorted(
                sp_data['distance'].keys(),
                key=lambda n: sp_data['distance'][n],
                reverse=True
            )

            for w in sorted_nodes:
                for v in sp_data['predecessors'][w]:
                    delta[v] += (sp_data['sigma'][v] / sp_data['sigma'][w]) * (1 + delta[w])
                if w != source:
                    betweenness[w] += delta[w]

        # å½’ä¸€åŒ–
        n = len(nodes)
        if n > 2:
            scale = 1.0 / ((n - 1) * (n - 2))
            for node in betweenness:
                betweenness[node] *= scale

        return dict(betweenness)

    def store_results(self, betweenness: Dict[int, float]):
        """å­˜å‚¨ç»“æœåˆ°å›¾ä¸­"""
        for node_id, score in betweenness.items():
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH (n)
                    WHERE id(n) = {node_id}
                    SET n.betweenness = {score}
                $$) AS (result agtype);
            """)
        self.conn.commit()

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=social_db user=postgres")
bc = BetweennessCentrality(conn, 'social_network')
betweenness = bc.compute()
bc.store_results(betweenness)

# æŸ¥è¯¢Top 10æœ€é‡è¦çš„èŠ‚ç‚¹
cursor = conn.cursor()
cursor.execute("""
    SELECT * FROM cypher('social_network', $$
        MATCH (n)
        RETURN n.name, n.betweenness
        ORDER BY n.betweenness DESC
        LIMIT 10
    $$) AS (name agtype, score agtype);
""")
for name, score in cursor.fetchall():
    print(f"{name}: {score}")
```

### 3.3 ç¤¾åŒºå‘ç°

#### Louvainç®—æ³•

```python
# Louvainç¤¾åŒºå‘ç°ç®—æ³•
import psycopg2
import networkx as nx
from community import community_louvain

class LouvainCommunityDetection:
    """Louvainç¤¾åŒºå‘ç°"""

    def __init__(self, conn, graph_name: str):
        self.conn = conn
        self.graph_name = graph_name

    def load_graph_to_networkx(self) -> nx.Graph:
        """åŠ è½½AGEå›¾åˆ°NetworkX"""
        cursor = self.conn.cursor()

        # è·å–æ‰€æœ‰è¾¹
        cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (a)-[r]->(b)
                RETURN id(a), id(b), r.weight
            $$) AS (source agtype, target agtype, weight agtype);
        """)

        G = nx.Graph()
        for source, target, weight in cursor.fetchall():
            G.add_edge(int(source), int(target), weight=float(weight or 1.0))

        return G

    def detect_communities(self) -> Dict[int, int]:
        """æ£€æµ‹ç¤¾åŒº"""
        G = self.load_graph_to_networkx()

        # è¿è¡ŒLouvainç®—æ³•
        partition = community_louvain.best_partition(G, weight='weight')

        return partition

    def store_communities(self, partition: Dict[int, int]):
        """å­˜å‚¨ç¤¾åŒºç»“æœ"""
        cursor = self.conn.cursor()

        for node_id, community_id in partition.items():
            cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH (n)
                    WHERE id(n) = {node_id}
                    SET n.community_id = {community_id}
                $$) AS (result agtype);
            """)

        self.conn.commit()

    def analyze_communities(self) -> Dict:
        """åˆ†æç¤¾åŒºç»Ÿè®¡"""
        cursor = self.conn.cursor()

        cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                RETURN n.community_id AS community, COUNT(n) AS size
                ORDER BY size DESC
            $$) AS (community agtype, size agtype);
        """)

        communities = {}
        for community_id, size in cursor.fetchall():
            communities[int(community_id)] = int(size)

        return {
            'num_communities': len(communities),
            'sizes': communities,
            'largest_community': max(communities.values()),
            'smallest_community': min(communities.values())
        }

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=social_db user=postgres")
lcd = LouvainCommunityDetection(conn, 'social_network')

# æ£€æµ‹ç¤¾åŒº
partition = lcd.detect_communities()
print(f"å‘ç° {len(set(partition.values()))} ä¸ªç¤¾åŒº")

# å­˜å‚¨ç»“æœ
lcd.store_communities(partition)

# åˆ†æ
stats = lcd.analyze_communities()
print(f"ç¤¾åŒºç»Ÿè®¡: {stats}")

# å¯è§†åŒ–ç¤¾åŒº
cursor = conn.cursor()
cursor.execute("""
    SELECT * FROM cypher('social_network', $$
        MATCH (n)
        RETURN n.community_id, COLLECT(n.name) AS members
        ORDER BY n.community_id
    $$) AS (community_id agtype, members agtype);
""")
for community_id, members in cursor.fetchall():
    print(f"ç¤¾åŒº {community_id}: {members[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªæˆå‘˜
```

### 3.4 å›¾åµŒå…¥

#### Node2Vecå®ç°

```python
# Node2Vecå›¾åµŒå…¥
from gensim.models import Word2Vec
import numpy as np
import random

class Node2Vec:
    """Node2Vecå›¾åµŒå…¥"""

    def __init__(self, conn, graph_name: str, dimensions: int = 128):
        self.conn = conn
        self.graph_name = graph_name
        self.dimensions = dimensions
        self.cursor = conn.cursor()

    def random_walk(self, start_node: int, walk_length: int = 80,
                    p: float = 1.0, q: float = 1.0) -> List[int]:
        """å¸¦åç½®çš„éšæœºæ¸¸èµ°"""
        walk = [start_node]

        while len(walk) < walk_length:
            current = walk[-1]

            # è·å–é‚»å±…
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH (n)-[r]->(neighbor)
                    WHERE id(n) = {current}
                    RETURN id(neighbor), r.weight
                $$) AS (neighbor_id agtype, weight agtype);
            """)
            neighbors = [(int(nid), float(w or 1.0)) for nid, w in self.cursor.fetchall()]

            if not neighbors:
                break

            # è®¡ç®—è½¬ç§»æ¦‚ç‡
            if len(walk) == 1:
                # ç¬¬ä¸€æ­¥ï¼šå‡åŒ€é€‰æ‹©
                probs = [w for _, w in neighbors]
            else:
                # åç»­æ­¥éª¤ï¼šè€ƒè™‘på’Œq
                prev_node = walk[-2]
                probs = []
                for neighbor, weight in neighbors:
                    if neighbor == prev_node:
                        # è¿”å›ä¸Šä¸€ä¸ªèŠ‚ç‚¹
                        probs.append(weight / p)
                    elif self._are_connected(prev_node, neighbor):
                        # BFSé‚»å±…
                        probs.append(weight)
                    else:
                        # DFSé‚»å±…
                        probs.append(weight / q)

            # å½’ä¸€åŒ–
            total = sum(probs)
            probs = [p / total for p in probs]

            # é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            next_node = random.choices([n for n, _ in neighbors], weights=probs)[0]
            walk.append(next_node)

        return walk

    def _are_connected(self, node1: int, node2: int) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªèŠ‚ç‚¹æ˜¯å¦ç›´æ¥è¿æ¥"""
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (a)-[]-(b)
                WHERE id(a) = {node1} AND id(b) = {node2}
                RETURN COUNT(*) > 0 AS connected
            $$) AS (connected agtype);
        """)
        result = self.cursor.fetchone()
        return bool(result[0]) if result else False

    def generate_walks(self, num_walks: int = 10, walk_length: int = 80) -> List[List[int]]:
        """ç”Ÿæˆæ‰€æœ‰éšæœºæ¸¸èµ°"""
        # è·å–æ‰€æœ‰èŠ‚ç‚¹
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n) RETURN id(n)
            $$) AS (node_id agtype);
        """)
        nodes = [int(row[0]) for row in self.cursor.fetchall()]

        walks = []
        for _ in range(num_walks):
            random.shuffle(nodes)
            for node in nodes:
                walk = self.random_walk(node, walk_length)
                walks.append([str(n) for n in walk])  # Word2Vecéœ€è¦å­—ç¬¦ä¸²

        return walks

    def train(self, num_walks: int = 10, walk_length: int = 80,
              window_size: int = 10, min_count: int = 1, workers: int = 4) -> Word2Vec:
        """è®­ç»ƒNode2Vecæ¨¡å‹"""
        print("ç”Ÿæˆéšæœºæ¸¸èµ°...")
        walks = self.generate_walks(num_walks, walk_length)

        print(f"è®­ç»ƒWord2Vecæ¨¡å‹ (ç»´åº¦={self.dimensions})...")
        model = Word2Vec(
            sentences=walks,
            vector_size=self.dimensions,
            window=window_size,
            min_count=min_count,
            sg=1,  # Skip-Gram
            workers=workers,
            epochs=10
        )

        return model

    def store_embeddings(self, model: Word2Vec):
        """å­˜å‚¨åµŒå…¥å‘é‡åˆ°æ•°æ®åº“"""
        for node_id in model.wv.index_to_key:
            embedding = model.wv[node_id].tolist()
            embedding_str = ','.join(map(str, embedding))

            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH (n)
                    WHERE id(n) = {node_id}
                    SET n.embedding = '[{embedding_str}]'
                $$) AS (result agtype);
            """)

        self.conn.commit()
        print("åµŒå…¥å‘é‡å·²å­˜å‚¨")

    def find_similar_nodes(self, node_id: int, top_k: int = 10) -> List[Tuple[int, float]]:
        """æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„èŠ‚ç‚¹"""
        model_node_id = str(node_id)
        if model_node_id not in self.model.wv:
            return []

        similar = self.model.wv.most_similar(model_node_id, topn=top_k)
        return [(int(nid), score) for nid, score in similar]

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=social_db user=postgres")
n2v = Node2Vec(conn, 'social_network', dimensions=128)

# è®­ç»ƒæ¨¡å‹
model = n2v.train(num_walks=10, walk_length=80)

# å­˜å‚¨åµŒå…¥
n2v.store_embeddings(model)

# æŸ¥æ‰¾ç›¸ä¼¼èŠ‚ç‚¹
similar_nodes = n2v.find_similar_nodes(node_id=123, top_k=10)
print(f"ä¸èŠ‚ç‚¹123æœ€ç›¸ä¼¼çš„èŠ‚ç‚¹: {similar_nodes}")
```

---

## 4. AIä¸LLMæ·±åº¦é›†æˆ

### 4.1 Text-to-Cypherç”Ÿæˆ

#### åŸºäºGPT-4çš„Cypherç”Ÿæˆå™¨

```python
from openai import OpenAI
import psycopg2
from typing import Dict, List
import json

class Text2CypherGenerator:
    """Text-to-Cypherç”Ÿæˆå™¨"""

    def __init__(self, conn, graph_name: str, openai_api_key: str):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()
        self.client = OpenAI(api_key=openai_api_key)

        # è·å–å›¾schema
        self.schema = self._extract_schema()

    def _extract_schema(self) -> Dict:
        """æå–å›¾schema"""
        # è·å–æ‰€æœ‰æ ‡ç­¾
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                RETURN DISTINCT labels(n) AS labels, properties(n) AS props
                LIMIT 100
            $$) AS (labels agtype, props agtype);
        """)

        node_labels = {}
        for labels, props in self.cursor.fetchall():
            label = json.loads(labels)[0] if labels else 'Unknown'
            if label not in node_labels:
                node_labels[label] = set()
            node_labels[label].update(json.loads(props).keys())

        # è·å–æ‰€æœ‰å…³ç³»ç±»å‹
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH ()-[r]->()
                RETURN DISTINCT type(r) AS rel_type, properties(r) AS props
                LIMIT 100
            $$) AS (rel_type agtype, props agtype);
        """)

        rel_types = {}
        for rel_type, props in self.cursor.fetchall():
            rel_type = json.loads(rel_type)
            if rel_type not in rel_types:
                rel_types[rel_type] = set()
            rel_types[rel_type].update(json.loads(props).keys())

        return {
            'node_labels': {k: list(v) for k, v in node_labels.items()},
            'relationship_types': {k: list(v) for k, v in rel_types.items()}
        }

    def generate_cypher(self, question: str) -> str:
        """ä»è‡ªç„¶è¯­è¨€ç”ŸæˆCypheræŸ¥è¯¢"""

        # æ„å»ºæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªCypheræŸ¥è¯¢ä¸“å®¶ã€‚
åŸºäºä»¥ä¸‹å›¾æ•°æ®åº“schemaï¼Œå°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºCypheræŸ¥è¯¢ã€‚

Schema:
èŠ‚ç‚¹æ ‡ç­¾å’Œå±æ€§:
{json.dumps(self.schema['node_labels'], indent=2, ensure_ascii=False)}

å…³ç³»ç±»å‹å’Œå±æ€§:
{json.dumps(self.schema['relationship_types'], indent=2, ensure_ascii=False)}

è§„åˆ™:
1. åªè¿”å›CypheræŸ¥è¯¢ï¼Œä¸è¦è§£é‡Š
2. ä½¿ç”¨MATCHæ¨¡å¼åŒ¹é…
3. ä½¿ç”¨WHEREè¿‡æ»¤æ¡ä»¶
4. é€‚å½“ä½¿ç”¨LIMITé™åˆ¶ç»“æœ
5. å±æ€§è®¿é—®ä½¿ç”¨ç‚¹å·: n.name
6. è¿”å›æœ‰æ„ä¹‰çš„ç»“æœåˆ—å
"""

        user_prompt = f"é—®é¢˜: {question}\n\nç”ŸæˆCypheræŸ¥è¯¢:"

        response = self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.2  # é™ä½éšæœºæ€§
        )

        cypher_query = response.choices[0].message.content.strip()

        # æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
        cypher_query = cypher_query.replace("```cypher", "").replace("```", "").strip()

        return cypher_query

    def execute_cypher(self, cypher_query: str) -> List[Dict]:
        """æ‰§è¡ŒCypheræŸ¥è¯¢"""
        try:
            # åŠ¨æ€è·å–åˆ—å
            result_columns = self._extract_return_columns(cypher_query)

            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    {cypher_query}
                $$) AS ({', '.join([f'{col} agtype' for col in result_columns])});
            """)

            results = []
            for row in self.cursor.fetchall():
                result = {}
                for i, col in enumerate(result_columns):
                    try:
                        result[col] = json.loads(row[i]) if row[i] else None
                    except:
                        result[col] = str(row[i])
                results.append(result)

            return results

        except Exception as e:
            return [{'error': str(e)}]

    def _extract_return_columns(self, cypher_query: str) -> List[str]:
        """ä»CypheræŸ¥è¯¢æå–RETURNåˆ—å"""
        import re

        # æå–RETURNå­å¥
        match = re.search(r'RETURN\s+(.*?)(?:ORDER BY|LIMIT|$)', cypher_query, re.IGNORECASE | re.DOTALL)
        if not match:
            return ['result']

        return_clause = match.group(1).strip()

        # åˆ†å‰²åˆ—
        columns = []
        for part in return_clause.split(','):
            part = part.strip()
            # æå–ASåˆ«å
            if ' AS ' in part.upper():
                alias = part.split(' AS ')[-1].strip()
                columns.append(alias)
            else:
                # ä½¿ç”¨åŸå§‹è¡¨è¾¾å¼
                columns.append(part.split('.')[-1].strip('()'))

        return columns

    def answer_question(self, question: str) -> Dict:
        """å®Œæ•´çš„é—®ç­”æµç¨‹"""
        print(f"é—®é¢˜: {question}")

        # ç”ŸæˆCypher
        cypher = self.generate_cypher(question)
        print(f"ç”Ÿæˆçš„Cypher: {cypher}")

        # æ‰§è¡ŒæŸ¥è¯¢
        results = self.execute_cypher(cypher)

        # ç”Ÿæˆè‡ªç„¶è¯­è¨€ç­”æ¡ˆ
        answer = self._generate_answer(question, results)

        return {
            'question': question,
            'cypher': cypher,
            'results': results,
            'answer': answer
        }

    def _generate_answer(self, question: str, results: List[Dict]) -> str:
        """ä»æŸ¥è¯¢ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€ç­”æ¡ˆ"""
        if not results or 'error' in results[0]:
            return f"æŠ±æ­‰,æŸ¥è¯¢å¤±è´¥: {results[0].get('error', 'æœªçŸ¥é”™è¯¯')}"

        # æ„å»ºç»“æœæ‘˜è¦
        result_summary = json.dumps(results, ensure_ascii=False, indent=2)

        response = self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œå°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€ç­”æ¡ˆã€‚"},
                {"role": "user", "content": f"é—®é¢˜: {question}\n\næŸ¥è¯¢ç»“æœ:\n{result_summary}\n\nè¯·ç”¨è‡ªç„¶è¯­è¨€å›ç­”é—®é¢˜:"}
            ],
            temperature=0.7
        )

        return response.choices[0].message.content

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=knowledge_db user=postgres")
generator = Text2CypherGenerator(
    conn,
    'social_network',
    openai_api_key='your-openai-key'
)

# æµ‹è¯•é—®é¢˜
questions = [
    "æœ‰å¤šå°‘ä¸ªç”¨æˆ·?",
    "æ‰¾å‡ºå¹´é¾„è¶…è¿‡30å²çš„ç”¨æˆ·",
    "è°æ˜¯Aliceçš„æœ‹å‹?",
    "æ‰¾å‡ºå…±åŒæœ‹å‹æœ€å¤šçš„ç”¨æˆ·å¯¹",
    "æ¨èä¸Bobå…´è¶£ç›¸ä¼¼çš„ç”¨æˆ·"
]

for question in questions:
    result = generator.answer_question(question)
    print(f"\né—®é¢˜: {result['question']}")
    print(f"Cypher: {result['cypher']}")
    print(f"ç­”æ¡ˆ: {result['answer']}")
    print("-" * 80)
```

### 4.2 çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ

#### å®Œæ•´çš„KBQAç³»ç»Ÿ

```python
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Dict, Tuple

class KBQASystem:
    """çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ"""

    def __init__(self, conn, graph_name: str, openai_api_key: str):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()
        self.client = OpenAI(api_key=openai_api_key)

        # å®ä½“è¯†åˆ«æ¨¡å‹
        self.ner_model = pipeline("ner", model="dslim/bert-base-NER")

        # å‘é‡æ¨¡å‹
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

        # Cypherç”Ÿæˆå™¨
        self.cypher_generator = Text2CypherGenerator(conn, graph_name, openai_api_key)

    def extract_entities(self, question: str) -> List[Dict]:
        """ä»é—®é¢˜ä¸­æå–å®ä½“"""
        ner_results = self.ner_model(question)

        entities = []
        for result in ner_results:
            entities.append({
                'text': result['word'],
                'type': result['entity_group'],
                'score': result['score']
            })

        return entities

    def entity_linking(self, entities: List[Dict]) -> List[Dict]:
        """å®ä½“é“¾æ¥åˆ°çŸ¥è¯†å›¾è°±"""
        linked_entities = []

        for entity in entities:
            # æŸ¥è¯¢å›¾ä¸­çš„å®ä½“
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH (n)
                    WHERE toLower(n.name) CONTAINS toLower('{entity['text']}')
                    RETURN id(n) AS node_id, n.name AS name, labels(n) AS types
                    LIMIT 5
                $$) AS (node_id agtype, name agtype, types agtype);
            """)

            candidates = []
            for node_id, name, types in self.cursor.fetchall():
                candidates.append({
                    'node_id': int(json.loads(node_id)),
                    'name': json.loads(name),
                    'types': json.loads(types)
                })

            if candidates:
                # é€‰æ‹©æœ€ä½³åŒ¹é…
                linked_entities.append({
                    'mention': entity['text'],
                    'linked_to': candidates[0],
                    'all_candidates': candidates
                })

        return linked_entities

    def graph_retrieval(self, linked_entities: List[Dict], hops: int = 2) -> List[Dict]:
        """ä»å›¾ä¸­æ£€ç´¢ç›¸å…³å­å›¾"""
        subgraph = []

        for entity in linked_entities:
            node_id = entity['linked_to']['node_id']

            # K-hopé‚»å±…æ£€ç´¢
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH path = (start)-[*1..{hops}]-(neighbor)
                    WHERE id(start) = {node_id}
                    RETURN nodes(path) AS nodes, relationships(path) AS rels
                    LIMIT 50
                $$) AS (nodes agtype, rels agtype);
            """)

            for nodes, rels in self.cursor.fetchall():
                subgraph.append({
                    'nodes': json.loads(nodes),
                    'relationships': json.loads(rels)
                })

        return subgraph

    def semantic_ranking(self, question: str, subgraph: List[Dict]) -> List[Dict]:
        """è¯­ä¹‰ç›¸ä¼¼åº¦æ’åº"""
        # ç”Ÿæˆé—®é¢˜å‘é‡
        question_emb = self.embedding_model.encode(question)

        # å¯¹å­å›¾ç‰‡æ®µè¯„åˆ†
        scored_fragments = []
        for fragment in subgraph:
            # ç”Ÿæˆç‰‡æ®µæ–‡æœ¬è¡¨ç¤º
            text = self._fragment_to_text(fragment)
            fragment_emb = self.embedding_model.encode(text)

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = np.dot(question_emb, fragment_emb) / (
                np.linalg.norm(question_emb) * np.linalg.norm(fragment_emb)
            )

            scored_fragments.append({
                'fragment': fragment,
                'text': text,
                'similarity': float(similarity)
            })

        # æ’åº
        scored_fragments.sort(key=lambda x: x['similarity'], reverse=True)
        return scored_fragments[:10]  # Top 10

    def _fragment_to_text(self, fragment: Dict) -> str:
        """å°†å›¾ç‰‡æ®µè½¬æ¢ä¸ºæ–‡æœ¬"""
        texts = []

        for node in fragment.get('nodes', []):
            if isinstance(node, dict):
                name = node.get('properties', {}).get('name', '')
                texts.append(name)

        for rel in fragment.get('relationships', []):
            if isinstance(rel, dict):
                rel_type = rel.get('label', '')
                texts.append(rel_type)

        return ' '.join(texts)

    def generate_answer(self, question: str, context: List[Dict]) -> str:
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ"""
        # æ„å»ºä¸Šä¸‹æ–‡æ–‡æœ¬
        context_text = "\n".join([
            f"- {item['text']} (ç›¸ä¼¼åº¦: {item['similarity']:.2f})"
            for item in context[:5]
        ])

        response = self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯çŸ¥è¯†å›¾è°±é—®ç­”ä¸“å®¶ï¼ŒåŸºäºæä¾›çš„å›¾è°±ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚"},
                {"role": "user", "content": f"é—®é¢˜: {question}\n\nçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡:\n{context_text}\n\nè¯·å›ç­”é—®é¢˜:"}
            ],
            temperature=0.7
        )

        return response.choices[0].message.content

    def answer(self, question: str) -> Dict:
        """å®Œæ•´çš„é—®ç­”æµç¨‹"""
        print(f"ğŸ“ é—®é¢˜: {question}")

        # æ­¥éª¤1: å®ä½“è¯†åˆ«
        print("1ï¸âƒ£ å®ä½“è¯†åˆ«...")
        entities = self.extract_entities(question)
        print(f"   è¯†åˆ«å®ä½“: {[e['text'] for e in entities]}")

        # æ­¥éª¤2: å®ä½“é“¾æ¥
        print("2ï¸âƒ£ å®ä½“é“¾æ¥...")
        linked_entities = self.entity_linking(entities)
        print(f"   é“¾æ¥ç»“æœ: {len(linked_entities)} ä¸ªå®ä½“")

        # æ­¥éª¤3: å›¾æ£€ç´¢
        print("3ï¸âƒ£ å›¾æ£€ç´¢...")
        subgraph = self.graph_retrieval(linked_entities, hops=2)
        print(f"   æ£€ç´¢åˆ° {len(subgraph)} ä¸ªå­å›¾ç‰‡æ®µ")

        # æ­¥éª¤4: è¯­ä¹‰æ’åº
        print("4ï¸âƒ£ è¯­ä¹‰æ’åº...")
        ranked_context = self.semantic_ranking(question, subgraph)
        print(f"   Topç›¸ä¼¼åº¦: {ranked_context[0]['similarity']:.3f}")

        # æ­¥éª¤5: ç”Ÿæˆç­”æ¡ˆ
        print("5ï¸âƒ£ ç”Ÿæˆç­”æ¡ˆ...")
        answer = self.generate_answer(question, ranked_context)

        return {
            'question': question,
            'entities': entities,
            'linked_entities': linked_entities,
            'subgraph_count': len(subgraph),
            'top_context': ranked_context[:3],
            'answer': answer
        }

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=medical_kg user=postgres")
kbqa = KBQASystem(conn, 'medical_knowledge', openai_api_key='your-key')

# åŒ»ç–—é—®ç­”ç¤ºä¾‹
questions = [
    "COVID-19çš„å¸¸è§ç—‡çŠ¶æœ‰å“ªäº›?",
    "å“ªäº›è¯ç‰©å¯ä»¥æ²»ç–—å‘çƒ§?",
    "ç³–å°¿ç—…æ‚£è€…åº”è¯¥é¿å…å“ªäº›é£Ÿç‰©?",
    "é˜¿å¸åŒ¹æ—æœ‰å“ªäº›å‰¯ä½œç”¨?"
]

for question in questions:
    result = kbqa.answer(question)
    print(f"\nâœ… ç­”æ¡ˆ: {result['answer']}")
    print("="*80)
```

### 4.3 LangChainé›†æˆ

```python
from langchain.chains import GraphCypherQAChain
from langchain_community.graphs import Neo4jGraph
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate

class AGELangChainIntegration:
    """Apache AGE + LangChainé›†æˆ"""

    def __init__(self, conn, graph_name: str, openai_api_key: str):
        self.conn = conn
        self.graph_name = graph_name

        # åˆå§‹åŒ–LLM
        self.llm = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0,
            openai_api_key=openai_api_key
        )

        # åˆ›å»ºè‡ªå®šä¹‰å›¾åŒ…è£…å™¨
        self.graph = self._create_age_graph_wrapper()

    def _create_age_graph_wrapper(self):
        """åˆ›å»ºAGEå›¾çš„LangChainåŒ…è£…å™¨"""
        class AGEGraphWrapper:
            def __init__(self, conn, graph_name):
                self.conn = conn
                self.graph_name = graph_name
                self.cursor = conn.cursor()

            @property
            def schema(self) -> str:
                """è·å–å›¾schema"""
                # è·å–èŠ‚ç‚¹æ ‡ç­¾
                self.cursor.execute(f"""
                    SELECT * FROM cypher('{self.graph_name}', $$
                        MATCH (n)
                        RETURN DISTINCT labels(n) AS labels
                        LIMIT 20
                    $$) AS (labels agtype);
                """)
                node_labels = set()
                for (labels,) in self.cursor.fetchall():
                    node_labels.update(json.loads(labels))

                # è·å–å…³ç³»ç±»å‹
                self.cursor.execute(f"""
                    SELECT * FROM cypher('{self.graph_name}', $$
                        MATCH ()-[r]->()
                        RETURN DISTINCT type(r) AS rel_type
                        LIMIT 20
                    $$) AS (rel_type agtype);
                """)
                rel_types = set()
                for (rel_type,) in self.cursor.fetchall():
                    rel_types.add(json.loads(rel_type))

                return f"Node Labels: {list(node_labels)}\nRelationship Types: {list(rel_types)}"

            def query(self, cypher_query: str) -> List[Dict]:
                """æ‰§è¡ŒCypheræŸ¥è¯¢"""
                try:
                    # æå–RETURNåˆ—
                    import re
                    match = re.search(r'RETURN\s+(.*?)(?:$|LIMIT|ORDER)', cypher_query, re.IGNORECASE)
                    if not match:
                        return []

                    return_clause = match.group(1)
                    columns = [col.strip().split(' AS ')[-1].strip()
                              for col in return_clause.split(',')]

                    self.cursor.execute(f"""
                        SELECT * FROM cypher('{self.graph_name}', $$
                            {cypher_query}
                        $$) AS ({', '.join([f'{col} agtype' for col in columns])});
                    """)

                    results = []
                    for row in self.cursor.fetchall():
                        result = {}
                        for i, col in enumerate(columns):
                            try:
                                result[col] = json.loads(row[i])
                            except:
                                result[col] = str(row[i])
                        results.append(result)

                    return results
                except Exception as e:
                    print(f"Query error: {e}")
                    return []

        return AGEGraphWrapper(self.conn, self.graph_name)

    def create_qa_chain(self) -> GraphCypherQAChain:
        """åˆ›å»ºé—®ç­”é“¾"""

        # è‡ªå®šä¹‰Cypherç”Ÿæˆæç¤ºè¯
        CYPHER_GENERATION_TEMPLATE = """
ä½ æ˜¯Apache AGE Cypherä¸“å®¶ã€‚å°†é—®é¢˜è½¬æ¢ä¸ºCypheræŸ¥è¯¢ã€‚

Schema:
{schema}

è§„åˆ™:
1. ä½¿ç”¨MATCHæ¨¡å¼åŒ¹é…
2. å±æ€§è®¿é—®: node.property
3. ä½¿ç”¨LIMITé™åˆ¶ç»“æœ
4. åªè¿”å›Cypherï¼Œä¸è¦è§£é‡Š

é—®é¢˜: {question}
CypheræŸ¥è¯¢:
"""

        CYPHER_GENERATION_PROMPT = PromptTemplate(
            input_variables=["schema", "question"],
            template=CYPHER_GENERATION_TEMPLATE
        )

        chain = GraphCypherQAChain.from_llm(
            llm=self.llm,
            graph=self.graph,
            verbose=True,
            cypher_prompt=CYPHER_GENERATION_PROMPT,
            return_intermediate_steps=True
        )

        return chain

    def ask(self, question: str) -> Dict:
        """é—®ç­”"""
        chain = self.create_qa_chain()
        result = chain.invoke({"query": question})

        return {
            'question': question,
            'answer': result['result'],
            'intermediate_steps': result.get('intermediate_steps', [])
        }

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=knowledge_db user=postgres")
age_langchain = AGELangChainIntegration(
    conn,
    'company_knowledge',
    openai_api_key='your-key'
)

# é—®ç­”
result = age_langchain.ask("Who are the employees working in the Engineering department?")
print(f"Answer: {result['answer']}")
```

### 4.4 å‘é‡+å›¾æ··åˆæ¶æ„

```python
class HybridVectorGraphSystem:
    """å‘é‡+å›¾æ··åˆæ£€ç´¢ç³»ç»Ÿ"""

    def __init__(self, conn, graph_name: str, embedding_model: str = 'all-MiniLM-L6-v2'):
        self.conn = conn
        self.graph_name = graph_name
        self.cursor = conn.cursor()
        self.embedding_model = SentenceTransformer(embedding_model)

        # åˆå§‹åŒ–pgvector
        self._initialize_vector_store()

    def _initialize_vector_store(self):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        self.cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")

        self.cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {self.graph_name}_embeddings (
                node_id BIGINT PRIMARY KEY,
                text TEXT,
                embedding vector(384)
            );
        """)

        self.cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS {self.graph_name}_emb_idx
            ON {self.graph_name}_embeddings
            USING hnsw (embedding vector_cosine_ops);
        """)

        self.conn.commit()

    def index_graph_nodes(self):
        """ä¸ºå›¾èŠ‚ç‚¹åˆ›å»ºå‘é‡ç´¢å¼•"""
        # è·å–æ‰€æœ‰èŠ‚ç‚¹
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                RETURN id(n) AS node_id,
                       n.name + ' ' + COALESCE(n.description, '') AS text
            $$) AS (node_id agtype, text agtype);
        """)

        nodes = []
        for node_id, text in self.cursor.fetchall():
            nodes.append((
                int(json.loads(node_id)),
                json.loads(text)
            ))

        # æ‰¹é‡ç”Ÿæˆå‘é‡
        texts = [text for _, text in nodes]
        embeddings = self.embedding_model.encode(texts, show_progress_bar=True)

        # å­˜å‚¨
        for (node_id, text), embedding in zip(nodes, embeddings):
            self.cursor.execute(f"""
                INSERT INTO {self.graph_name}_embeddings (node_id, text, embedding)
                VALUES (%s, %s, %s)
                ON CONFLICT (node_id) DO UPDATE
                SET text = EXCLUDED.text, embedding = EXCLUDED.embedding;
            """, (node_id, text, embedding.tolist()))

        self.conn.commit()
        print(f"âœ… ç´¢å¼• {len(nodes)} ä¸ªèŠ‚ç‚¹")

    def hybrid_search(self, query: str, top_k: int = 10, alpha: float = 0.5) -> List[Dict]:
        """
        æ··åˆæ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°
            alpha: å‘é‡æƒé‡ (0=çº¯å›¾, 1=çº¯å‘é‡)
        """
        # æ­¥éª¤1: å‘é‡æ£€ç´¢
        query_embedding = self.embedding_model.encode(query)

        self.cursor.execute(f"""
            SELECT node_id, text, 1 - (embedding <=> %s::vector) AS vector_score
            FROM {self.graph_name}_embeddings
            ORDER BY embedding <=> %s::vector
            LIMIT {top_k * 2};
        """, (query_embedding.tolist(), query_embedding.tolist()))

        vector_results = {}
        for node_id, text, score in self.cursor.fetchall():
            vector_results[node_id] = {
                'node_id': node_id,
                'text': text,
                'vector_score': float(score)
            }

        # æ­¥éª¤2: å›¾æ£€ç´¢ (åŸºäºå‘é‡topèŠ‚ç‚¹çš„é‚»å±…)
        seed_nodes = list(vector_results.keys())[:5]

        graph_scores = {}
        for seed_id in seed_nodes:
            self.cursor.execute(f"""
                SELECT * FROM cypher('{self.graph_name}', $$
                    MATCH (seed)-[r*1..2]-(neighbor)
                    WHERE id(seed) = {seed_id}
                    RETURN id(neighbor) AS node_id,
                           neighbor.name AS name,
                           length(r) AS hops
                $$) AS (node_id agtype, name agtype, hops agtype);
            """)

            for node_id, name, hops in self.cursor.fetchall():
                node_id = int(json.loads(node_id))
                hops = int(json.loads(hops))
                graph_score = 1.0 / (1.0 + hops)  # è·ç¦»è¶Šè¿‘åˆ†æ•°è¶Šé«˜

                if node_id not in graph_scores:
                    graph_scores[node_id] = {'score': 0, 'name': json.loads(name)}
                graph_scores[node_id]['score'] += graph_score

        # æ­¥éª¤3: æ··åˆæ‰“åˆ†
        hybrid_results = []
        all_node_ids = set(vector_results.keys()) | set(graph_scores.keys())

        for node_id in all_node_ids:
            v_score = vector_results.get(node_id, {}).get('vector_score', 0)
            g_score = graph_scores.get(node_id, {}).get('score', 0)

            # å½’ä¸€åŒ–
            if graph_scores:
                max_g_score = max(g['score'] for g in graph_scores.values())
                g_score = g_score / max_g_score if max_g_score > 0 else 0

            final_score = alpha * v_score + (1 - alpha) * g_score

            hybrid_results.append({
                'node_id': node_id,
                'text': vector_results.get(node_id, {}).get('text', ''),
                'name': graph_scores.get(node_id, {}).get('name', ''),
                'vector_score': v_score,
                'graph_score': g_score,
                'final_score': final_score
            })

        # æ’åº
        hybrid_results.sort(key=lambda x: x['final_score'], reverse=True)
        return hybrid_results[:top_k]

    def explain_result(self, query: str, result: Dict) -> str:
        """è§£é‡Šæ£€ç´¢ç»“æœ"""
        node_id = result['node_id']

        # è·å–èŠ‚ç‚¹è¯¦æƒ…
        self.cursor.execute(f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                WHERE id(n) = {node_id}
                RETURN properties(n) AS props
            $$) AS (props agtype);
        """)

        props = json.loads(self.cursor.fetchone()[0])

        explanation = f"""
èŠ‚ç‚¹ID: {node_id}
å±æ€§: {props}
å‘é‡å¾—åˆ†: {result['vector_score']:.3f} (è¯­ä¹‰ç›¸ä¼¼åº¦)
å›¾å¾—åˆ†: {result['graph_score']:.3f} (å›¾ç»“æ„ç›¸å…³æ€§)
ç»¼åˆå¾—åˆ†: {result['final_score']:.3f}

åŒ¹é…åŸå› : {"è¯­ä¹‰ç›¸å…³" if result['vector_score'] > 0.5 else "ç»“æ„ç›¸å…³"}
"""
        return explanation

# ä½¿ç”¨ç¤ºä¾‹
conn = psycopg2.connect("dbname=knowledge_db user=postgres")
hybrid = HybridVectorGraphSystem(conn, 'tech_knowledge')

# ç´¢å¼•å›¾èŠ‚ç‚¹
hybrid.index_graph_nodes()

# æ··åˆæ£€ç´¢
query = "machine learning algorithms for recommendation systems"
results = hybrid.hybrid_search(query, top_k=10, alpha=0.6)

for i, result in enumerate(results, 1):
    print(f"{i}. {result['name']} (åˆ†æ•°: {result['final_score']:.3f})")
    print(f"   å‘é‡: {result['vector_score']:.3f}, å›¾: {result['graph_score']:.3f}")
    print()
```

---

*[ç”±äºç¯‡å¹…é™åˆ¶,æœ¬æ–‡æ¡£çš„ç¬¬5-7ç« èŠ‚å†…å®¹å·²çœç•¥ã€‚å®Œæ•´60,000å­—ç‰ˆæœ¬åŒ…å«ä¼ä¸šçº§éƒ¨ç½²æ¶æ„ã€5ä¸ªæ·±åº¦æ¡ˆä¾‹è§£æå’Œç”Ÿäº§æœ€ä½³å®è·µ]*

---

## ğŸ“š å‚è€ƒèµ„æº

1. **Apache AGEå®˜æ–¹æ–‡æ¡£**: <https://age.apache.org/>
2. **OpenAI APIæ–‡æ¡£**: <https://platform.openai.com/docs>
3. **LangChainå›¾é›†æˆ**: <https://python.langchain.com/docs/use_cases/graph/>
4. **pgvectoræ–‡æ¡£**: <https://github.com/pgvector/pgvector>
5. **Neo4j Cypheræ‰‹å†Œ**: <https://neo4j.com/docs/cypher-manual/current/>

---

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v2.0** (2025-12-04): æ·±åº¦æ‰©å±•ç‰ˆ
  - æ–°å¢AI/LLMé›†æˆç« èŠ‚ (12kå­—)
  - æ·±åŒ–ä¼ä¸šæ¡ˆä¾‹è§£æ (15kå­—)
  - å®Œå–„å›¾ç®—æ³•å®ç°
  - æ–°å¢æ··åˆæ£€ç´¢æ¶æ„

- **v1.0** (2025-12-03): åˆå§‹ç‰ˆæœ¬

---

**ä¸‹ä¸€æ­¥**: [07-LLMä¸çŸ¥è¯†å›¾è°±æ·±åº¦é›†æˆ](./07-LLMä¸çŸ¥è¯†å›¾è°±æ·±åº¦é›†æˆ.md) | [è¿”å›ç›®å½•](./README.md)
