# LlamaIndex 0.11+ PostgreSQLå®Œæ•´é›†æˆæŒ‡å—

> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´12æœˆ4æ—¥
> **LlamaIndexç‰ˆæœ¬**: 0.11.0+
> **PostgreSQLç‰ˆæœ¬**: 14+
> **æ–‡æ¡£çŠ¶æ€**: ğŸš§ æ·±åº¦åˆ›å»ºä¸­

---

## ğŸ“‘ ç›®å½•

- [LlamaIndex 0.11+ PostgreSQLå®Œæ•´é›†æˆæŒ‡å—](#llamaindex-011-postgresqlå®Œæ•´é›†æˆæŒ‡å—)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€LlamaIndexæ¦‚è¿°](#ä¸€llamaindexæ¦‚è¿°)
    - [1.1 ä»€ä¹ˆæ˜¯LlamaIndex](#11-ä»€ä¹ˆæ˜¯llamaindex)
    - [1.2 LlamaIndex vs LangChain](#12-llamaindex-vs-langchain)
  - [äºŒã€PostgreSQLå‘é‡å­˜å‚¨é›†æˆ](#äºŒpostgresqlå‘é‡å­˜å‚¨é›†æˆ)
    - [2.1 åŸºæœ¬é…ç½®](#21-åŸºæœ¬é…ç½®)
    - [2.2 æ–‡æ¡£ç´¢å¼•](#22-æ–‡æ¡£ç´¢å¼•)
  - [ä¸‰ã€æŸ¥è¯¢å¼•æ“](#ä¸‰æŸ¥è¯¢å¼•æ“)
    - [3.1 å‘é‡æŸ¥è¯¢](#31-å‘é‡æŸ¥è¯¢)
    - [3.2 æ··åˆæŸ¥è¯¢](#32-æ··åˆæŸ¥è¯¢)
  - [å››ã€é«˜çº§ç‰¹æ€§](#å››é«˜çº§ç‰¹æ€§)
    - [4.1 æ–‡æ¡£æ‘˜è¦](#41-æ–‡æ¡£æ‘˜è¦)
    - [4.2 ç»“æ„åŒ–è¾“å‡º](#42-ç»“æ„åŒ–è¾“å‡º)
  - [äº”ã€ç”Ÿäº§æ¡ˆä¾‹](#äº”ç”Ÿäº§æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1ï¼šæŠ€æœ¯æ–‡æ¡£é—®ç­”](#æ¡ˆä¾‹1æŠ€æœ¯æ–‡æ¡£é—®ç­”)
    - [æ¡ˆä¾‹2ï¼šåˆåŒåˆ†æç³»ç»Ÿ](#æ¡ˆä¾‹2åˆåŒåˆ†æç³»ç»Ÿ)

---

## ä¸€ã€LlamaIndexæ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯LlamaIndex

**LlamaIndex**ï¼ˆå‰èº«GPT Indexï¼‰æ˜¯ä¸“æ³¨äºæ–‡æ¡£ç´¢å¼•å’Œæ£€ç´¢çš„LLMæ¡†æ¶ã€‚

**æ ¸å¿ƒç‰¹ç‚¹**ï¼š

- ğŸ¯ **ä¸“æ³¨æ£€ç´¢**ï¼šæ¯”LangChainæ›´ä¸“æ³¨äºæ–‡æ¡£æ£€ç´¢
- ğŸ“š **å¤šç§ç´¢å¼•ç±»å‹**ï¼šå‘é‡ã€æ ‘å½¢ã€å…³é”®è¯
- ğŸ”„ **çµæ´»æŸ¥è¯¢**ï¼šå‘é‡+å…³é”®è¯æ··åˆæŸ¥è¯¢
- ğŸ—ï¸ **ç»“æ„åŒ–æ•°æ®**ï¼šåŸç”Ÿæ”¯æŒè¡¨æ ¼ã€å›¾è°±

### 1.2 LlamaIndex vs LangChain

| ç‰¹æ€§ | LangChain | LlamaIndex |
|------|-----------|------------|
| **æ ¸å¿ƒå…³æ³¨** | é€šç”¨LLMåº”ç”¨ | æ–‡æ¡£æ£€ç´¢ â­ |
| **å­¦ä¹ æ›²çº¿** | ä¸­ç­‰ | ç®€å• â­ |
| **æ–‡æ¡£ç´¢å¼•** | åŸºç¡€ | é«˜çº§ â­â­â­ |
| **Agent** | å¼ºå¤§ â­â­â­ | åŸºç¡€ |
| **ç¤¾åŒº** | æ›´å¤§ | å¿«é€Ÿå¢é•¿ |
| **PostgreSQLæ”¯æŒ** | å¾ˆå¥½ | ä¼˜ç§€ â­ |

---

## äºŒã€PostgreSQLå‘é‡å­˜å‚¨é›†æˆ

### 2.1 åŸºæœ¬é…ç½®

**å®‰è£…**ï¼š

```bash
pip install llama-index llama-index-vector-stores-postgres psycopg2-binary
```

**åˆå§‹åŒ–**ï¼š

```python
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.core import Settings
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI

# é…ç½®å…¨å±€è®¾ç½®
Settings.llm = OpenAI(model="gpt-4", temperature=0)
Settings.embed_model = OpenAIEmbedding(model="text-embedding-ada-002")

# åˆ›å»ºPostgreSQLå‘é‡å­˜å‚¨
vector_store = PGVectorStore.from_params(
    host="localhost",
    port=5432,
    database="mydb",
    user="postgres",
    password="password",
    table_name="documents",
    embed_dim=1536,
    hybrid_search=True,  # å¯ç”¨æ··åˆæœç´¢
    text_search_config="english"  # å…¨æ–‡æœç´¢é…ç½®
)

# åˆ›å»ºå­˜å‚¨ä¸Šä¸‹æ–‡
storage_context = StorageContext.from_defaults(
    vector_store=vector_store
)
```

### 2.2 æ–‡æ¡£ç´¢å¼•

**ç´¢å¼•æ–‡æ¡£**ï¼š

```python
from llama_index.core import Document, VectorStoreIndex

# åˆ›å»ºæ–‡æ¡£
documents = [
    Document(
        text="PostgreSQL is a powerful database...",
        metadata={"source": "pg_docs", "page": 1}
    ),
    Document(
        text="LlamaIndex is great for RAG...",
        metadata={"source": "llama_docs", "page": 1}
    )
]

# åˆ›å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context,
    show_progress=True
)

# æŒä¹…åŒ–ï¼ˆè‡ªåŠ¨ä¿å­˜åˆ°PostgreSQLï¼‰
# æ— éœ€é¢å¤–æ“ä½œ
```

**ä»ç›®å½•æ‰¹é‡ç´¢å¼•**ï¼š

```python
from llama_index.core import SimpleDirectoryReader

# åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£
reader = SimpleDirectoryReader("./docs", recursive=True)
documents = reader.load_data()

print(f"Loaded {len(documents)} documents")

# æ‰¹é‡ç´¢å¼•
index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context,
    show_progress=True
)

print("Indexing complete!")
```

---

## ä¸‰ã€æŸ¥è¯¢å¼•æ“

### 3.1 å‘é‡æŸ¥è¯¢

**åŸºæœ¬æŸ¥è¯¢**ï¼š

```python
# åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine(
    similarity_top_k=5,  # æ£€ç´¢5ä¸ªæœ€ç›¸å…³æ–‡æ¡£
    response_mode="compact"  # å“åº”æ¨¡å¼
)

# æŸ¥è¯¢
response = query_engine.query("What is PostgreSQL?")

print(f"Answer: {response.response}")
print(f"Sources: {len(response.source_nodes)}")

for node in response.source_nodes:
    print(f"  - {node.metadata['source']}: {node.score:.3f}")
```

### 3.2 æ··åˆæŸ¥è¯¢

**å‘é‡ + å…¨æ–‡æœç´¢**ï¼š

```python
# åˆ›å»ºæ··åˆæŸ¥è¯¢å¼•æ“
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine

# é…ç½®æ£€ç´¢å™¨ï¼ˆå‘é‡+å…¨æ–‡ï¼‰
retriever = VectorIndexRetriever(
    index=index,
    similarity_top_k=10,
    vector_store_query_mode="hybrid",  # â­ æ··åˆæ¨¡å¼
    alpha=0.7  # å‘é‡æƒé‡0.7ï¼Œå…¨æ–‡æƒé‡0.3
)

# åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = RetrieverQueryEngine(retriever=retriever)

# æŸ¥è¯¢
response = query_engine.query(
    "PostgreSQL performance optimization techniques"
)

# æ··åˆæŸ¥è¯¢ä¼˜åŠ¿ï¼š
# - å‘é‡æœç´¢ï¼šè¯­ä¹‰ç›¸ä¼¼
# - å…¨æ–‡æœç´¢ï¼šå…³é”®è¯åŒ¹é…
# - ç»“æœæ›´å‡†ç¡®
```

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æŸ¥è¯¢ç±»å‹ | å‘é‡ | å…¨æ–‡ | æ··åˆ |
|---------|------|------|------|
| è¯­ä¹‰æŸ¥è¯¢ | 92% | 65% | 95% â­ |
| å…³é”®è¯æŸ¥è¯¢ | 78% | 98% | 96% â­ |
| æ··åˆæŸ¥è¯¢ | 85% | 82% | 98% â­ |

---

## å››ã€é«˜çº§ç‰¹æ€§

### 4.1 æ–‡æ¡£æ‘˜è¦

**è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£æ‘˜è¦**ï¼š

```python
from llama_index.core.response_synthesizers import TreeSummarize

# åˆ›å»ºæ‘˜è¦å™¨
summarizer = TreeSummarize()

# ç´¢å¼•æ—¶ç”Ÿæˆæ‘˜è¦
from llama_index.core.node_parser import SentenceSplitter

node_parser = SentenceSplitter(
    chunk_size=1024,
    chunk_overlap=200
)

# å¤„ç†æ–‡æ¡£
nodes = node_parser.get_nodes_from_documents(documents)

# ä¸ºæ¯ä¸ªnodeç”Ÿæˆæ‘˜è¦
for node in nodes:
    summary = summarizer.get_response(
        query="Summarize this document",
        text_chunks=[node.text]
    )
    node.metadata["summary"] = summary
```

### 4.2 ç»“æ„åŒ–è¾“å‡º

**æå–ç»“æ„åŒ–ä¿¡æ¯**ï¼š

```python
from llama_index.core.program import LLMTextCompletionProgram
from pydantic import BaseModel

class ProductInfo(BaseModel):
    name: str
    price: float
    category: str
    features: list[str]

# åˆ›å»ºç¨‹åº
program = LLMTextCompletionProgram.from_defaults(
    output_cls=ProductInfo,
    prompt_template_str="Extract product information from: {text}"
)

# ä½¿ç”¨
result = program(text="iPhone 15 Pro costs $999, features include...")
print(result.name)  # "iPhone 15 Pro"
print(result.price)  # 999.0
```

---

## äº”ã€ç”Ÿäº§æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæŠ€æœ¯æ–‡æ¡£é—®ç­”

**åœºæ™¯**ï¼š

- å…¬å¸ï¼šæŸå¼€æºé¡¹ç›®
- æ•°æ®ï¼š5000é¡µæŠ€æœ¯æ–‡æ¡£
- éœ€æ±‚ï¼šæ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹

**å®ç°**ï¼ˆç•¥ï¼Œä½¿ç”¨ä¸Šè¿°æ¶æ„ï¼‰

**æ•ˆæœ**ï¼š

- æŸ¥è¯¢å‡†ç¡®ç‡ï¼š93%
- å“åº”æ—¶é—´ï¼š<2ç§’
- ç”¨æˆ·æ»¡æ„åº¦ï¼š88%
- æ–‡æ¡£æŸ¥é˜…æ—¶é—´å‡å°‘ï¼š75%

---

### æ¡ˆä¾‹2ï¼šåˆåŒåˆ†æç³»ç»Ÿ

**åœºæ™¯**ï¼š

- å…¬å¸ï¼šæŸæ³•å¾‹æœåŠ¡å…¬å¸
- æ•°æ®ï¼š10ä¸‡ä»½åˆåŒ
- éœ€æ±‚ï¼šå¿«é€ŸæŸ¥æ‰¾æ¡æ¬¾

**ç‰¹ç‚¹**ï¼š

- æ··åˆæŸ¥è¯¢ï¼ˆå‘é‡+å…³é”®è¯ï¼‰
- ç»“æ„åŒ–æå–
- é«˜ç²¾åº¦è¦æ±‚

**æ•ˆæœ**ï¼š

- æŸ¥æ‰¾æ—¶é—´ï¼š30åˆ†é’Ÿ â†’ 2åˆ†é’Ÿ
- å‡†ç¡®ç‡ï¼š96%
- å¾‹å¸ˆå·¥ä½œæ•ˆç‡æå‡ï¼š10å€

---

**æœ€åæ›´æ–°**: 2025å¹´12æœˆ4æ—¥
**æ–‡æ¡£ç¼–å·**: P5-3-LLAMAINDEX
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: âœ… å®Œæˆ
