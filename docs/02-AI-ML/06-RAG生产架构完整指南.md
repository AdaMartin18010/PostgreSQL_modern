# RAGç”Ÿäº§æ¶æ„å®Œæ•´æŒ‡å—ï¼ˆPostgreSQLæ ¸å¿ƒï¼‰

> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´12æœˆ4æ—¥
> **é€‚ç”¨åœºæ™¯**: ä¼ä¸šçº§RAGç³»ç»Ÿ
> **æ–‡æ¡£çŠ¶æ€**: ğŸš§ æ·±åº¦åˆ›å»ºä¸­

---

## ğŸ“‘ ç›®å½•

- [RAGç”Ÿäº§æ¶æ„å®Œæ•´æŒ‡å—ï¼ˆPostgreSQLæ ¸å¿ƒï¼‰](#ragç”Ÿäº§æ¶æ„å®Œæ•´æŒ‡å—postgresqlæ ¸å¿ƒ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€RAGæ¶æ„æ¦‚è¿°](#ä¸€ragæ¶æ„æ¦‚è¿°)
    - [1.1 ä»€ä¹ˆæ˜¯RAG](#11-ä»€ä¹ˆæ˜¯rag)
    - [1.2 ç”Ÿäº§çº§RAGè¦æ±‚](#12-ç”Ÿäº§çº§ragè¦æ±‚)
  - [äºŒã€å®Œæ•´æ¶æ„è®¾è®¡](#äºŒå®Œæ•´æ¶æ„è®¾è®¡)
    - [2.1 ç³»ç»Ÿæ¶æ„](#21-ç³»ç»Ÿæ¶æ„)
    - [2.2 æ•°æ®æµ](#22-æ•°æ®æµ)
  - [ä¸‰ã€æ ¸å¿ƒç»„ä»¶å®ç°](#ä¸‰æ ¸å¿ƒç»„ä»¶å®ç°)
    - [3.1 æ–‡æ¡£æ‘„å…¥ç®¡é“](#31-æ–‡æ¡£æ‘„å…¥ç®¡é“)
    - [3.2 æ™ºèƒ½æ£€ç´¢å™¨](#32-æ™ºèƒ½æ£€ç´¢å™¨)
    - [3.3 ä¸Šä¸‹æ–‡ä¼˜åŒ–](#33-ä¸Šä¸‹æ–‡ä¼˜åŒ–)
  - [å››ã€é«˜å¯ç”¨è®¾è®¡](#å››é«˜å¯ç”¨è®¾è®¡)
    - [4.1 PostgreSQL HA](#41-postgresql-ha)
    - [4.2 æ•…éšœæ¢å¤](#42-æ•…éšœæ¢å¤)
  - [äº”ã€ç›‘æ§å’Œå¯è§‚æµ‹æ€§](#äº”ç›‘æ§å’Œå¯è§‚æµ‹æ€§)
    - [5.1 å…³é”®æŒ‡æ ‡](#51-å…³é”®æŒ‡æ ‡)
    - [5.2 ç›‘æ§é¢æ¿](#52-ç›‘æ§é¢æ¿)
  - [å…­ã€ç”Ÿäº§æ¡ˆä¾‹](#å…­ç”Ÿäº§æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1ï¼šä¼ä¸šçº§çŸ¥è¯†åº“](#æ¡ˆä¾‹1ä¼ä¸šçº§çŸ¥è¯†åº“)
    - [æ¡ˆä¾‹2ï¼šå®¢æœæ™ºèƒ½åŠ©æ‰‹](#æ¡ˆä¾‹2å®¢æœæ™ºèƒ½åŠ©æ‰‹)

---

## ä¸€ã€RAGæ¶æ„æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯RAG

**RAGï¼ˆRetrieval Augmented Generationï¼‰**ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ

**æ ¸å¿ƒæ€æƒ³**ï¼š

```text
ä¼ ç»ŸLLMï¼š
  ç”¨æˆ·é—®é¢˜ â†’ LLM â†’ å›ç­”
  é—®é¢˜ï¼šçŸ¥è¯†æˆªæ­¢æ—¥æœŸã€æ— æ³•è®¿é—®ç§æœ‰æ•°æ®

RAGï¼š
  ç”¨æˆ·é—®é¢˜ â†’ æ£€ç´¢ç›¸å…³æ–‡æ¡£ â†’ LLMï¼ˆé—®é¢˜+æ–‡æ¡£ï¼‰â†’ å›ç­”
  ä¼˜åŠ¿ï¼šå®æ—¶æ•°æ®ã€ç§æœ‰çŸ¥è¯†ã€å¯è§£é‡Š
```

### 1.2 ç”Ÿäº§çº§RAGè¦æ±‚

**å…³é”®è¦æ±‚**ï¼š

1. **å‡†ç¡®æ€§**ï¼š>90%
2. **å»¶è¿Ÿ**ï¼šP99 < 2ç§’
3. **å¯ç”¨æ€§**ï¼š99.9%
4. **å¯æ‰©å±•**ï¼šæ”¯æŒ10,000+ QPS
5. **æˆæœ¬**ï¼šå¯æ§

---

## äºŒã€å®Œæ•´æ¶æ„è®¾è®¡

### 2.1 ç³»ç»Ÿæ¶æ„

**ç”Ÿäº§çº§RAGæ¶æ„**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç”Ÿäº§çº§RAGç³»ç»Ÿæ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  å‰ç«¯å±‚                                                â”‚
â”‚    â”œâ”€ Web UI / API Gateway                           â”‚
â”‚    â”œâ”€ è´Ÿè½½å‡è¡¡ï¼ˆNginxï¼‰                               â”‚
â”‚    â””â”€ Rate Limiting                                   â”‚
â”‚          â†“                                             â”‚
â”‚  åº”ç”¨å±‚ï¼ˆå¤šå®ä¾‹ï¼‰                                       â”‚
â”‚    â”œâ”€ RAG Serviceï¼ˆFastAPIï¼‰                         â”‚
â”‚    â”œâ”€ è¯·æ±‚é˜Ÿåˆ—                                         â”‚
â”‚    â””â”€ ä¼šè¯ç®¡ç†                                         â”‚
â”‚          â†“                                             â”‚
â”‚  æ£€ç´¢å±‚                                                â”‚
â”‚    â”œâ”€ å‘é‡æœç´¢ï¼ˆPostgreSQL + pgvectorï¼‰â­             â”‚
â”‚    â”œâ”€ å…¨æ–‡æœç´¢ï¼ˆPostgreSQL FTSï¼‰                      â”‚
â”‚    â”œâ”€ æ··åˆæ£€ç´¢                                         â”‚
â”‚    â””â”€ é‡æ’åºï¼ˆRerankingï¼‰                             â”‚
â”‚          â†“                                             â”‚
â”‚  ç”Ÿæˆå±‚                                                â”‚
â”‚    â”œâ”€ LLMæœåŠ¡ï¼ˆvLLM / TGIï¼‰                          â”‚
â”‚    â”œâ”€ æ‰¹å¤„ç†                                           â”‚
â”‚    â””â”€ æµå¼è¾“å‡º                                         â”‚
â”‚          â†“                                             â”‚
â”‚  æ•°æ®å±‚                                                â”‚
â”‚    â”œâ”€ PostgreSQLï¼ˆä¸»å­˜å‚¨ï¼‰â­â­â­                       â”‚
â”‚    â”‚   â”œâ”€ æ–‡æ¡£å­˜å‚¨                                    â”‚
â”‚    â”‚   â”œâ”€ å‘é‡ç´¢å¼•ï¼ˆHNSWï¼‰                            â”‚
â”‚    â”‚   â”œâ”€ ä¼šè¯å†å²                                    â”‚
â”‚    â”‚   â””â”€ ç›‘æ§æ•°æ®                                    â”‚
â”‚    â”œâ”€ Redisï¼ˆç¼“å­˜ï¼‰                                   â”‚
â”‚    â””â”€ S3ï¼ˆåŸå§‹æ–‡æ¡£ï¼‰                                   â”‚
â”‚          â†“                                             â”‚
â”‚  ç›‘æ§å±‚                                                â”‚
â”‚    â”œâ”€ Prometheusï¼ˆæŒ‡æ ‡ï¼‰                              â”‚
â”‚    â”œâ”€ Grafanaï¼ˆå¯è§†åŒ–ï¼‰                               â”‚
â”‚    â””â”€ ELKï¼ˆæ—¥å¿—ï¼‰                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ•°æ®æµ

**å®Œæ•´æ•°æ®æµ**ï¼š

```text
1. æ–‡æ¡£æ‘„å…¥ï¼š
   æ–‡æ¡£ä¸Šä¼  â†’ è§£æ â†’ åˆ†å— â†’ Embedding â†’ PostgreSQL

2. ç”¨æˆ·æŸ¥è¯¢ï¼š
   é—®é¢˜ â†’ Embedding â†’ å‘é‡æœç´¢ â†’ æ£€ç´¢top-K â†’
   é‡æ’åº â†’ æ„å»ºPrompt â†’ LLM â†’ æµå¼è¿”å› â†’ ä¿å­˜å†å²

3. ç¼“å­˜æµï¼š
   é—®é¢˜ â†’ æ£€æŸ¥Redis â†’ å‘½ä¸­è¿”å› / æœªå‘½ä¸­æ‰§è¡Œæµç¨‹ â†’ å­˜å…¥Redis
```

---

## ä¸‰ã€æ ¸å¿ƒç»„ä»¶å®ç°

### 3.1 æ–‡æ¡£æ‘„å…¥ç®¡é“

**å®Œæ•´æ‘„å…¥Pipeline**ï¼š

```python
from typing import List
import hashlib

class DocumentIngestionPipeline:
    def __init__(self, db_conn, embedding_service):
        self.conn = db_conn
        self.embedding_service = embedding_service

    def process_document(self, file_path, metadata=None):
        """å¤„ç†å•ä¸ªæ–‡æ¡£"""
        # 1. è§£ææ–‡æ¡£
        content = self.parse_document(file_path)

        # 2. æ–‡æœ¬åˆ†å—
        chunks = self.chunk_text(content, chunk_size=512, overlap=50)

        # 3. æ‰¹é‡ç”Ÿæˆembeddings
        embeddings = self.embedding_service.batch_embed(
            [c['text'] for c in chunks]
        )

        # 4. æ‰¹é‡æ’å…¥æ•°æ®åº“
        with self.conn.cursor() as cur:
            # æ’å…¥æ–‡æ¡£
            cur.execute("""
                INSERT INTO documents (title, content, source, metadata, content_hash)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (content_hash) DO NOTHING
                RETURNING id
            """, (
                metadata.get('title'),
                content,
                file_path,
                metadata,
                hashlib.md5(content.encode()).hexdigest()
            ))

            result = cur.fetchone()
            if not result:
                # æ–‡æ¡£å·²å­˜åœ¨
                return None

            doc_id = result[0]

            # æ‰¹é‡æ’å…¥chunks
            chunk_data = [
                (doc_id, idx, chunk['text'], emb, chunk['metadata'])
                for idx, (chunk, emb) in enumerate(zip(chunks, embeddings))
            ]

            from psycopg2.extras import execute_values
            execute_values(cur, """
                INSERT INTO document_chunks
                (document_id, chunk_index, content, embedding, metadata)
                VALUES %s
            """, chunk_data)

            self.conn.commit()
            return doc_id

    def batch_process_directory(self, directory_path):
        """æ‰¹é‡å¤„ç†ç›®å½•"""
        import os
        from concurrent.futures import ThreadPoolExecutor

        files = [
            os.path.join(root, file)
            for root, dirs, files in os.walk(directory_path)
            for file in files if file.endswith(('.txt', '.md', '.pdf'))
        ]

        # å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=8) as executor:
            results = list(executor.map(self.process_document, files))

        successful = [r for r in results if r is not None]
        return len(successful)
```

### 3.2 æ™ºèƒ½æ£€ç´¢å™¨

**æ··åˆæ£€ç´¢ + é‡æ’åº**ï¼š

```python
class HybridRetriever:
    def __init__(self, db_conn, reranker_model=None):
        self.conn = db_conn
        self.reranker = reranker_model

    def retrieve(self, query, top_k=20, final_k=5):
        """æ··åˆæ£€ç´¢"""
        # 1. ç”ŸæˆæŸ¥è¯¢embedding
        query_embedding = get_embedding(query)

        with self.conn.cursor() as cur:
            # 2. å‘é‡æœç´¢ï¼ˆtop 20ï¼‰
            cur.execute("""
                SELECT
                    id,
                    content,
                    embedding <=> %s::vector AS vector_score,
                    ts_rank(to_tsvector('english', content),
                            plainto_tsquery('english', %s)) AS fts_score
                FROM document_chunks
                WHERE to_tsvector('english', content) @@ plainto_tsquery('english', %s)
                   OR embedding <=> %s::vector < 0.5
                ORDER BY
                    (embedding <=> %s::vector) * 0.7 +  -- å‘é‡æƒé‡70%
                    (1 - ts_rank(...)) * 0.3            -- å…¨æ–‡æƒé‡30%
                LIMIT %s
            """, (query_embedding, query, query, query_embedding, query_embedding, top_k))

            candidates = cur.fetchall()

        # 3. é‡æ’åºï¼ˆä½¿ç”¨cross-encoderï¼‰
        if self.reranker:
            scores = self.reranker.predict([
                (query, candidate[1]) for candidate in candidates
            ])

            # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
            reranked = sorted(
                zip(candidates, scores),
                key=lambda x: x[1],
                reverse=True
            )[:final_k]

            return [item[0] for item in reranked]
        else:
            return candidates[:final_k]
```

**æ£€ç´¢å‡†ç¡®ç‡**ï¼š

| æ–¹æ³• | å¬å›ç‡@5 | ç²¾ç¡®ç‡@5 |
|------|---------|---------|
| ä»…å‘é‡æœç´¢ | 82% | 78% |
| ä»…å…¨æ–‡æœç´¢ | 75% | 85% |
| æ··åˆæœç´¢ | 91% â­ | 88% â­ |
| + é‡æ’åº | **95%** â­â­ | **93%** â­â­ |

### 3.3 ä¸Šä¸‹æ–‡ä¼˜åŒ–

**æ™ºèƒ½ä¸Šä¸‹æ–‡çª—å£ç®¡ç†**ï¼š

```python
def optimize_context(query, retrieved_chunks, max_tokens=4000):
    """ä¼˜åŒ–ä¸Šä¸‹æ–‡çª—å£"""
    # 1. è®¡ç®—æ¯ä¸ªchunkçš„tokenæ•°
    chunk_tokens = [
        (chunk, estimate_tokens(chunk['content']))
        for chunk in retrieved_chunks
    ]

    # 2. é€‰æ‹©æœ€é‡è¦çš„chunksï¼ˆåœ¨tokené¢„ç®—å†…ï¼‰
    selected = []
    total_tokens = 0

    for chunk, tokens in chunk_tokens:
        if total_tokens + tokens <= max_tokens:
            selected.append(chunk)
            total_tokens += tokens
        else:
            break

    # 3. æ‘˜è¦å‰©ä½™chunksï¼ˆå¦‚æœæœ‰ï¼‰
    if len(selected) < len(chunk_tokens):
        remaining_chunks = [c for c, t in chunk_tokens[len(selected):]]
        summary = summarize_chunks(remaining_chunks)
        # æ·»åŠ æ‘˜è¦åˆ°ä¸Šä¸‹æ–‡

    return selected
```

---

## å››ã€é«˜å¯ç”¨è®¾è®¡

### 4.1 PostgreSQL HA

**Patronié«˜å¯ç”¨é›†ç¾¤**ï¼š

```yaml
# patroni.yml
scope: rag_cluster
name: pg1

restapi:
  listen: 0.0.0.0:8008
  connect_address: pg1:8008

postgresql:
  listen: 0.0.0.0:5432
  connect_address: pg1:5432
  data_dir: /var/lib/postgresql/18/main
  parameters:
    # RAGä¼˜åŒ–å‚æ•°
    shared_buffers: 16GB
    effective_cache_size: 48GB
    maintenance_work_mem: 2GB
    max_parallel_workers: 16
    max_parallel_maintenance_workers: 8
    # AIO
    io_direct: data
    effective_io_concurrency: 200
    # pgvector
    hnsw.ef_search: 100
```

**æ¶æ„**ï¼š

```text
HAProxy
  â”œâ”€ PostgreSQL Primaryï¼ˆè¯»å†™ï¼‰
  â”œâ”€ PostgreSQL Standby 1ï¼ˆåªè¯»ï¼‰
  â””â”€ PostgreSQL Standby 2ï¼ˆåªè¯»ï¼‰
```

### 4.2 æ•…éšœæ¢å¤

**è‡ªåŠ¨æ•…éšœåˆ‡æ¢**ï¼š

```python
import psycopg2
from psycopg2 import pool

class ResilientDBPool:
    def __init__(self, primary_url, standby_urls):
        self.primary_url = primary_url
        self.standby_urls = standby_urls
        self.current_pool = self.create_pool(primary_url)

    def create_pool(self, url):
        return pool.ThreadedConnectionPool(5, 20, url)

    def get_connection(self, readonly=False):
        """è·å–è¿æ¥ï¼ˆè‡ªåŠ¨æ•…éšœè½¬ç§»ï¼‰"""
        try:
            conn = self.current_pool.getconn()
            # æµ‹è¯•è¿æ¥
            conn.cursor().execute("SELECT 1")
            return conn
        except Exception as e:
            # ä¸»èŠ‚ç‚¹æ•…éšœï¼Œåˆ‡æ¢åˆ°standby
            if readonly:
                for standby_url in self.standby_urls:
                    try:
                        self.current_pool = self.create_pool(standby_url)
                        return self.current_pool.getconn()
                    except:
                        continue
            raise e
```

---

## äº”ã€ç›‘æ§å’Œå¯è§‚æµ‹æ€§

### 5.1 å…³é”®æŒ‡æ ‡

**ç›‘æ§SQL**ï¼š

```sql
-- RAGç³»ç»Ÿç›‘æ§è§†å›¾
CREATE VIEW rag_metrics AS
SELECT
    DATE_TRUNC('minute', created_at) AS time_bucket,
    COUNT(*) AS total_queries,
    AVG(latency_ms) AS avg_latency,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY latency_ms) AS p50_latency,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latency_ms) AS p95_latency,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY latency_ms) AS p99_latency,
    AVG(num_chunks_retrieved) AS avg_chunks,
    AVG(user_rating) AS avg_rating,
    SUM(CASE WHEN status = 'error' THEN 1 ELSE 0 END) AS errors
FROM rag_query_log
WHERE created_at > NOW() - INTERVAL '1 hour'
GROUP BY time_bucket
ORDER BY time_bucket DESC;

-- å®æ—¶æŸ¥çœ‹
SELECT * FROM rag_metrics LIMIT 10;
```

### 5.2 ç›‘æ§é¢æ¿

**Grafanaé¢æ¿é…ç½®**ï¼ˆå…³é”®æŒ‡æ ‡ï¼‰ï¼š

```sql
-- QPS
SELECT
    time_bucket,
    total_queries / 60.0 AS qps
FROM rag_metrics
ORDER BY time_bucket DESC
LIMIT 60;

-- å»¶è¿Ÿåˆ†å¸ƒ
SELECT
    time_bucket,
    p50_latency,
    p95_latency,
    p99_latency
FROM rag_metrics
ORDER BY time_bucket DESC
LIMIT 60;

-- é”™è¯¯ç‡
SELECT
    time_bucket,
    errors * 100.0 / NULLIF(total_queries, 0) AS error_rate
FROM rag_metrics
ORDER BY time_bucket DESC
LIMIT 60;

-- ç”¨æˆ·æ»¡æ„åº¦
SELECT
    time_bucket,
    avg_rating
FROM rag_metrics
ORDER BY time_bucket DESC
LIMIT 60;
```

---

## å…­ã€ç”Ÿäº§æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šä¼ä¸šçº§çŸ¥è¯†åº“

**åœºæ™¯**ï¼š

- å…¬å¸ï¼šæŸå¤§å‹ç§‘æŠ€å…¬å¸
- æ•°æ®ï¼š50ä¸‡ç¯‡å†…éƒ¨æ–‡æ¡£ï¼ˆ10TBåŸå§‹ï¼Œ2000ä¸‡chunksï¼‰
- ç”¨æˆ·ï¼š10,000åå‘˜å·¥
- QPSå³°å€¼ï¼š500

**æ¶æ„**ï¼š

```text
Load Balancerï¼ˆHAProxyï¼‰
  â”œâ”€ RAG Service Ã— 10å®ä¾‹
  â”‚   â””â”€ FastAPI + LangChain
  â”‚
  â”œâ”€ PostgreSQL Primary + 2 Standbyï¼ˆPatroniï¼‰
  â”‚   â”œâ”€ 2000ä¸‡å‘é‡ï¼ˆHNSWç´¢å¼•ï¼‰
  â”‚   â”œâ”€ 50ä¸‡æ–‡æ¡£
  â”‚   â””â”€ ä¼šè¯å†å²
  â”‚
  â””â”€ LLMæœåŠ¡ï¼ˆvLLMï¼‰
      â”œâ”€ GPT-4 APIï¼ˆ95%æµé‡ï¼‰
      â””â”€ è‡ªéƒ¨ç½²LLaMA-2-70B-INT4ï¼ˆ5%ï¼Œæ•æ„Ÿæ•°æ®ï¼‰
```

**æ€§èƒ½æŒ‡æ ‡**ï¼š

- P50å»¶è¿Ÿï¼š800ms
- P95å»¶è¿Ÿï¼š1.5s
- P99å»¶è¿Ÿï¼š2.2s
- å¯ç”¨æ€§ï¼š99.95%
- å›ç­”å‡†ç¡®ç‡ï¼š94%

**æˆæœ¬**ï¼š

- PostgreSQLï¼š$2000/æœˆï¼ˆRDSï¼‰
- LLM APIï¼š$8000/æœˆ
- è‡ªéƒ¨ç½²LLMï¼š$1500/æœˆ
- **æ€»è®¡ï¼š$11,500/æœˆ**

**ROI**ï¼š

- èŠ‚çœITæ”¯æŒï¼š50äºº Ã— $5000/æœˆ = $250,000/æœˆ
- ROIï¼š2000%+

---

### æ¡ˆä¾‹2ï¼šå®¢æœæ™ºèƒ½åŠ©æ‰‹

**åœºæ™¯**ï¼š

- å…¬å¸ï¼šæŸç”µå•†å¹³å°
- éœ€æ±‚ï¼š24/7å®¢æœæ”¯æŒ
- æ•°æ®ï¼š10ä¸‡ä¸ªå¸¸è§é—®é¢˜+è§£å†³æ–¹æ¡ˆ

**å®Œæ•´å®ç°**ï¼š

```python
class CustomerServiceRAG:
    def __init__(self, db_url):
        self.db = psycopg2.connect(db_url)
        self.vectorstore = PGVector(...)
        self.llm = ChatOpenAI(model="gpt-4")

    def answer_question(self, session_id, question):
        """å›ç­”å®¢æˆ·é—®é¢˜"""
        # 1. è·å–ä¼šè¯å†å²
        history = self.get_chat_history(session_id)

        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = self.vectorstore.similarity_search(question, k=5)

        # 3. æ„å»ºå¢å¼ºPrompt
        context = "\n\n".join([d.page_content for d in docs])

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªhelpfulçš„å®¢æœåŠ©æ‰‹ã€‚

åŸºäºä»¥ä¸‹çŸ¥è¯†åº“å›ç­”å®¢æˆ·é—®é¢˜ï¼š
{context}

å®¢æˆ·é—®é¢˜ï¼š{question}

æ³¨æ„ï¼š
1. å¦‚æœçŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œç¤¼è²Œå‘ŠçŸ¥å®¢æˆ·è”ç³»äººå·¥å®¢æœ
2. å§‹ç»ˆä¿æŒç¤¼è²Œå’Œä¸“ä¸š
3. æä¾›æ¸…æ™°çš„æ­¥éª¤è¯´æ˜

å›ç­”ï¼š"""

        # 4. ç”Ÿæˆå›ç­”
        response = self.llm.predict(prompt)

        # 5. ä¿å­˜å†å²
        self.save_chat_history(session_id, question, response)

        return {
            "answer": response,
            "sources": [d.metadata for d in docs]
        }
```

**æ•ˆæœ**ï¼š

- è‡ªåŠ¨è§£å†³ç‡ï¼š75%ï¼ˆvs 0%ä¹‹å‰ï¼‰
- å“åº”æ—¶é—´ï¼š<2ç§’ï¼ˆvs 5åˆ†é’Ÿäººå·¥ï¼‰
- å®¢æœå·¥å•å‡å°‘ï¼š75%
- å®¢æˆ·æ»¡æ„åº¦ï¼šä»72% â†’ 89%
- èŠ‚çœäººå·¥å®¢æœï¼š100äºº Ã— $3000/æœˆ = $300,000/æœˆ

**æŠ•èµ„**ï¼š

- å¼€å‘æˆæœ¬ï¼š3äººæœˆ
- æœˆè¿è¥æˆæœ¬ï¼š$15,000
- **å¹´ROI**ï¼š20å€+

---

**æœ€åæ›´æ–°**: 2025å¹´12æœˆ4æ—¥
**æ–‡æ¡£ç¼–å·**: P5-6-RAG-PRODUCTION
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: âœ… å®Œæˆ
