# PostgreSQL分布式锁实战

## 1. 咨询锁（Advisory Lock）

### 1.1 基础使用

```sql
-- 会话级锁（持续到连接关闭）
SELECT pg_advisory_lock(12345);
-- 执行临界区代码
SELECT pg_advisory_unlock(12345);

-- 事务级锁（持续到事务结束）
BEGIN;
SELECT pg_advisory_xact_lock(12345);
-- 执行临界区代码
COMMIT;  -- 自动释放

-- 尝试获取锁（非阻塞）
SELECT pg_try_advisory_lock(12345);
-- 返回 true: 获取成功
-- 返回 false: 锁已被占用

-- 检查锁状态
SELECT * FROM pg_locks WHERE locktype = 'advisory';
```

---

## 2. 分布式任务锁

### 2.2 定时任务互斥

```python
import psycopg2
import hashlib

def run_distributed_job(job_name):
    """分布式环境下保证任务只运行一次"""

    # 生成job_name的唯一ID
    lock_id = int(hashlib.md5(job_name.encode()).hexdigest()[:8], 16)

    conn = psycopg2.connect("dbname=mydb")
    cursor = conn.cursor()

    try:
        # 尝试获取锁
        cursor.execute("SELECT pg_try_advisory_lock(%s)", (lock_id,))
        acquired = cursor.fetchone()[0]

        if not acquired:
            print(f"任务 {job_name} 已在其他节点运行")
            return

        print(f"节点获取锁，执行任务: {job_name}")

        # 执行任务
        execute_job(job_name)

    finally:
        # 释放锁
        cursor.execute("SELECT pg_advisory_unlock(%s)", (lock_id,))
        cursor.close()
        conn.close()

# 多节点环境
# Node1: run_distributed_job("daily_report")  → 执行
# Node2: run_distributed_job("daily_report")  → 跳过（锁被占用）
```

### 2.2 队列消费

```sql
-- 任务队列表
CREATE TABLE task_queue (
    id BIGSERIAL PRIMARY KEY,
    task_name VARCHAR(100),
    payload JSONB,
    status VARCHAR(20) DEFAULT 'pending',
    worker_id VARCHAR(50),
    created_at TIMESTAMPTZ DEFAULT now(),
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ
);

CREATE INDEX idx_status ON task_queue(status) WHERE status = 'pending';

-- 分布式消费者
CREATE OR REPLACE FUNCTION consume_task()
RETURNS TABLE(task_id BIGINT, task_name VARCHAR, payload JSONB)
LANGUAGE plpgsql AS $$
DECLARE
    v_task_id BIGINT;
BEGIN
    -- 使用FOR UPDATE SKIP LOCKED避免锁冲突
    SELECT id INTO v_task_id
    FROM task_queue
    WHERE status = 'pending'
    ORDER BY created_at
    LIMIT 1
    FOR UPDATE SKIP LOCKED;

    IF v_task_id IS NULL THEN
        RETURN;
    END IF;

    -- 使用咨询锁防止并发
    IF NOT pg_try_advisory_lock(v_task_id) THEN
        RETURN;
    END IF;

    -- 更新状态
    UPDATE task_queue
    SET
        status = 'processing',
        worker_id = inet_client_addr()::TEXT,
        started_at = now()
    WHERE id = v_task_id
    RETURNING id, task_name, payload INTO task_id, task_name, payload;

    RETURN NEXT;

    -- 注意: 调用者需要在任务完成后调用 pg_advisory_unlock(task_id)
END;
$$;

-- Python消费者
def worker():
    conn = psycopg2.connect("dbname=mydb")
    cursor = conn.cursor()

    while True:
        cursor.execute("SELECT * FROM consume_task()")
        task = cursor.fetchone()

        if not task:
            time.sleep(1)
            continue

        task_id, task_name, payload = task

        try:
            # 执行任务
            process_task(task_name, payload)

            # 标记完成
            cursor.execute("""
                UPDATE task_queue
                SET status = 'completed', completed_at = now()
                WHERE id = %s
            """, (task_id,))
            conn.commit()

        except Exception as e:
            # 标记失败
            cursor.execute("""
                UPDATE task_queue
                SET status = 'failed'
                WHERE id = %s
            """, (task_id,))
            conn.commit()

        finally:
            # 释放锁
            cursor.execute("SELECT pg_advisory_unlock(%s)", (task_id,))

# 多个worker并发运行，自动分配任务，无冲突
```

---

## 3. 分布式限流

```sql
-- 限流表
CREATE TABLE rate_limit (
    key VARCHAR(100) PRIMARY KEY,
    count INT DEFAULT 0,
    window_start TIMESTAMPTZ DEFAULT now()
);

-- 限流函数
CREATE OR REPLACE FUNCTION check_rate_limit(
    p_key VARCHAR,
    p_max_requests INT,
    p_window_seconds INT
)
RETURNS BOOLEAN
LANGUAGE plpgsql AS $$
DECLARE
    v_count INT;
    v_window_start TIMESTAMPTZ;
BEGIN
    -- 使用咨询锁保证原子性
    PERFORM pg_advisory_lock(hashtext(p_key)::INT);

    SELECT count, window_start INTO v_count, v_window_start
    FROM rate_limit
    WHERE key = p_key;

    IF v_count IS NULL OR v_window_start < now() - (p_window_seconds || ' seconds')::INTERVAL THEN
        -- 新窗口
        INSERT INTO rate_limit (key, count, window_start)
        VALUES (p_key, 1, now())
        ON CONFLICT (key) DO UPDATE
        SET count = 1, window_start = now();

        PERFORM pg_advisory_unlock(hashtext(p_key)::INT);
        RETURN true;
    END IF;

    IF v_count >= p_max_requests THEN
        -- 超出限制
        PERFORM pg_advisory_unlock(hashtext(p_key)::INT);
        RETURN false;
    END IF;

    -- 增加计数
    UPDATE rate_limit SET count = count + 1 WHERE key = p_key;

    PERFORM pg_advisory_unlock(hashtext(p_key)::INT);
    RETURN true;
END;
$$;

-- 使用
SELECT check_rate_limit('user:123:api', 100, 60);  -- 每分钟100次
-- true: 允许
-- false: 拒绝（超限）
```

---

## 4. 分布式ID生成

```sql
-- Snowflake ID生成器
CREATE TABLE id_generator (
    worker_id INT PRIMARY KEY,
    sequence INT DEFAULT 0,
    last_timestamp BIGINT DEFAULT 0
);

CREATE OR REPLACE FUNCTION generate_snowflake_id(p_worker_id INT)
RETURNS BIGINT
LANGUAGE plpgsql AS $$
DECLARE
    v_timestamp BIGINT;
    v_sequence INT;
    v_last_timestamp BIGINT;
    v_epoch BIGINT := 1609459200000; -- 2021-01-01 00:00:00
BEGIN
    -- 当前时间戳（毫秒）
    v_timestamp := (EXTRACT(EPOCH FROM now()) * 1000)::BIGINT - v_epoch;

    -- 使用咨询锁
    PERFORM pg_advisory_lock(p_worker_id);

    SELECT sequence, last_timestamp INTO v_sequence, v_last_timestamp
    FROM id_generator
    WHERE worker_id = p_worker_id;

    IF v_timestamp = v_last_timestamp THEN
        -- 同一毫秒内，递增序列号
        v_sequence := (v_sequence + 1) & 4095;  -- 12位序列号

        IF v_sequence = 0 THEN
            -- 序列号耗尽，等待下一毫秒
            PERFORM pg_sleep(0.001);
            v_timestamp := (EXTRACT(EPOCH FROM now()) * 1000)::BIGINT - v_epoch;
        END IF;
    ELSE
        -- 新的毫秒，重置序列号
        v_sequence := 0;
    END IF;

    -- 更新状态
    UPDATE id_generator
    SET sequence = v_sequence, last_timestamp = v_timestamp
    WHERE worker_id = p_worker_id;

    PERFORM pg_advisory_unlock(p_worker_id);

    -- 组装ID: 41位时间戳 + 10位worker_id + 12位序列号
    RETURN (v_timestamp << 22) | (p_worker_id << 12) | v_sequence;
END;
$$;

-- 初始化worker
INSERT INTO id_generator (worker_id) VALUES (1), (2), (3);

-- 生成ID
SELECT generate_snowflake_id(1);
-- 返回: 1234567890123456789
```

---

## 5. 乐观锁

```sql
-- 版本号乐观锁
CREATE TABLE accounts (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50),
    balance NUMERIC(10, 2),
    version INT DEFAULT 0
);

-- 更新（乐观锁）
UPDATE accounts
SET
    balance = balance - 100,
    version = version + 1
WHERE id = 123
  AND version = 5;  -- 必须匹配当前版本

-- 检查影响行数
GET DIAGNOSTICS updated_rows = ROW_COUNT;

IF updated_rows = 0 THEN
    RAISE EXCEPTION '并发冲突，请重试';
END IF;

-- Python实现
def transfer_optimistic(from_id, to_id, amount, max_retries=3):
    """乐观锁转账"""

    for attempt in range(max_retries):
        try:
            # 读取当前版本
            cursor.execute(
                "SELECT balance, version FROM accounts WHERE id = %s",
                (from_id,)
            )
            balance, version = cursor.fetchone()

            if balance < amount:
                raise ValueError("余额不足")

            # 尝试更新
            cursor.execute("""
                UPDATE accounts
                SET balance = balance - %s, version = version + 1
                WHERE id = %s AND version = %s
            """, (amount, from_id, version))

            if cursor.rowcount == 0:
                # 版本冲突，重试
                conn.rollback()
                continue

            # 对方账户
            cursor.execute("""
                UPDATE accounts
                SET balance = balance + %s, version = version + 1
                WHERE id = %s
            """, (amount, to_id))

            conn.commit()
            return True

        except Exception as e:
            conn.rollback()
            if attempt == max_retries - 1:
                raise

    raise Exception("超过最大重试次数")
```

---

## 6. 最佳实践

```text
选择锁类型:
✓ 咨询锁: 分布式任务、临界区
✓ FOR UPDATE SKIP LOCKED: 队列消费
✓ 乐观锁: 高并发、冲突少的场景
✓ 悲观锁: 冲突多、必须串行

注意事项:
✓ 锁超时机制（避免死锁）
✓ 锁粒度最小化
✓ 避免嵌套锁
✓ 记录锁持有时间
✓ 监控锁竞争

性能优化:
✓ 使用事务级锁而非会话级
✓ 尽早释放锁
✓ 批量操作减少锁次数
✓ 分段锁（减少竞争）
```

---

**完成**: PostgreSQL分布式锁实战
**字数**: ~10,000字
**涵盖**: 咨询锁、分布式任务、队列消费、限流、ID生成、乐观锁、最佳实践
