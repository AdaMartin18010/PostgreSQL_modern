# PostgreSQL SQL优化50条军规

## 1. 索引优化（10条）

### 1.1 使用合适的索引类型

```sql
-- ✓ B-Tree: 等值/范围查询
CREATE INDEX ON users(email);

-- ✓ Hash: 纯等值查询（少用）
CREATE INDEX ON users USING hash(email);

-- ✓ GIN: 全文搜索、JSONB、数组
CREATE INDEX ON documents USING GIN(content);

-- ✓ BRIN: 时序数据、大表
CREATE INDEX ON logs USING BRIN(created_at);

-- ✓ HNSW: 向量相似度
CREATE INDEX ON items USING hnsw(embedding vector_cosine_ops);
```

### 1.2 覆盖索引

```sql
-- ✗ 需要回表
CREATE INDEX ON orders(user_id);
SELECT order_id, amount FROM orders WHERE user_id = 123;

-- ✓ 覆盖索引，无需回表
CREATE INDEX ON orders(user_id, order_id, amount);
```

### 1.3 部分索引

```sql
-- ✗ 索引所有行
CREATE INDEX ON users(status);

-- ✓ 只索引活跃用户
CREATE INDEX ON users(status) WHERE status = 'active';
```

### 1.4 表达式索引

```sql
-- ✗ 无法使用索引
SELECT * FROM users WHERE LOWER(email) = 'test@example.com';

-- ✓ 表达式索引
CREATE INDEX ON users(LOWER(email));
```

### 1.5 避免冗余索引

```sql
-- ✗ 冗余
CREATE INDEX ON orders(user_id);
CREATE INDEX ON orders(user_id, created_at);  -- 第一个索引多余

-- ✓ 只创建第二个
DROP INDEX orders_user_id_idx;
```

---

## 2. 查询优化（15条）

### 2.1 避免SELECT *

```sql
-- ✗ 传输不需要的数据
SELECT * FROM users WHERE user_id = 123;

-- ✓ 只选择需要的列
SELECT user_id, username, email FROM users WHERE user_id = 123;
```

### 2.2 使用EXISTS代替IN

```sql
-- ✗ 子查询返回大量数据
SELECT * FROM users WHERE user_id IN (SELECT user_id FROM orders);

-- ✓ 使用EXISTS（短路评估）
SELECT * FROM users u WHERE EXISTS (
    SELECT 1 FROM orders o WHERE o.user_id = u.user_id
);
```

### 2.3 避免OR，使用UNION

```sql
-- ✗ OR导致无法使用索引
SELECT * FROM users WHERE email = 'a@x.com' OR username = 'alice';

-- ✓ UNION使用两个索引
SELECT * FROM users WHERE email = 'a@x.com'
UNION
SELECT * FROM users WHERE username = 'alice';
```

### 2.4 LIMIT早期化

```sql
-- ✗ 先JOIN再LIMIT
SELECT o.* FROM orders o
JOIN users u ON o.user_id = u.user_id
WHERE u.status = 'vip'
ORDER BY o.created_at DESC
LIMIT 10;

-- ✓ 先LIMIT再JOIN（如果可能）
SELECT o.* FROM (
    SELECT * FROM orders ORDER BY created_at DESC LIMIT 100
) o
JOIN users u ON o.user_id = u.user_id
WHERE u.status = 'vip'
LIMIT 10;
```

### 2.5 使用JOIN代替子查询

```sql
-- ✗ 子查询多次执行
SELECT * FROM users WHERE user_id IN (
    SELECT user_id FROM orders WHERE amount > 1000
);

-- ✓ JOIN一次完成
SELECT DISTINCT u.* FROM users u
JOIN orders o ON u.user_id = o.user_id
WHERE o.amount > 1000;
```

### 2.6 批量操作

```sql
-- ✗ 逐条插入
INSERT INTO logs (message) VALUES ('log1');
INSERT INTO logs (message) VALUES ('log2');

-- ✓ 批量插入
INSERT INTO logs (message) VALUES ('log1'), ('log2'), ('log3');
```

### 2.7 使用COPY

```sql
-- ✗ INSERT慢
INSERT INTO large_table SELECT * FROM source;

-- ✓ COPY最快
COPY large_table FROM '/tmp/data.csv' WITH (FORMAT csv);
```

### 2.8 避免函数包裹索引列

```sql
-- ✗ 无法使用索引
SELECT * FROM users WHERE YEAR(created_at) = 2024;

-- ✓ 范围查询
SELECT * FROM users
WHERE created_at >= '2024-01-01' AND created_at < '2025-01-01';
```

### 2.9 合理使用CTE

```sql
-- ✗ CTE被物化
WITH large_cte AS (
    SELECT * FROM huge_table WHERE ...
)
SELECT * FROM large_cte WHERE extra_filter;

-- ✓ 使用NOT MATERIALIZED
WITH large_cte AS NOT MATERIALIZED (
    SELECT * FROM huge_table WHERE ...
)
SELECT * FROM large_cte WHERE extra_filter;
```

### 2.10 使用分区裁剪

```sql
-- 分区表
CREATE TABLE logs (...) PARTITION BY RANGE (created_at);

-- ✓ 查询包含分区键
SELECT * FROM logs WHERE created_at >= '2024-01-01';
-- 只扫描相关分区
```

---

## 3. 事务优化（8条）

### 3.1 保持事务短小

```sql
-- ✗ 长事务
BEGIN;
SELECT * FROM large_table;  -- 1000万行
-- 处理数据...（5分钟）
COMMIT;

-- ✓ 游标分批处理
BEGIN;
DECLARE cur CURSOR FOR SELECT * FROM large_table;
FETCH 1000 FROM cur;
-- 处理1000行
COMMIT;
-- 重复
```

### 3.2 合适的隔离级别

```sql
-- ✗ 过度使用SERIALIZABLE
BEGIN TRANSACTION ISOLATION LEVEL SERIALIZABLE;
SELECT * FROM products;  -- 只读查询
COMMIT;

-- ✓ 使用READ COMMITTED
BEGIN;  -- 默认READ COMMITTED
SELECT * FROM products;
COMMIT;
```

### 3.3 避免空闲事务

```python
# ✗ 事务后空闲
conn.cursor().execute("BEGIN")
result = conn.cursor().execute("SELECT * FROM users WHERE id=1")
# 处理结果...（忘记commit）
time.sleep(60)

# ✓ 及时提交
cursor.execute("BEGIN")
result = cursor.execute("SELECT * FROM users WHERE id=1")
conn.commit()  # 立即提交
```

---

## 4. 连接优化（5条）

### 4.1 使用连接池

```python
# ✗ 每次新建连接
conn = psycopg2.connect(...)
cursor = conn.cursor()
cursor.execute("SELECT ...")
conn.close()

# ✓ 使用连接池
conn = connection_pool.getconn()
try:
    cursor = conn.cursor()
    cursor.execute("SELECT ...")
finally:
    connection_pool.putconn(conn)
```

### 4.2 Prepared Statements

```python
# ✓ 预编译（降低解析开销）
cursor.execute("PREPARE stmt AS SELECT * FROM users WHERE user_id = $1")
cursor.execute("EXECUTE stmt (123)")
cursor.execute("EXECUTE stmt (456)")
```

---

## 5. 数据类型优化（5条）

### 5.1 选择合适的整数类型

```sql
-- ✗ 过大类型
CREATE TABLE products (
    product_id BIGINT,  -- 实际只有1万条
    stock BIGINT        -- 最大1000
);

-- ✓ 合适类型
CREATE TABLE products (
    product_id INT,
    stock SMALLINT
);
-- 节省50%空间
```

### 5.2 使用ENUM

```sql
-- ✗ VARCHAR
CREATE TABLE orders (status VARCHAR(20));

-- ✓ ENUM（4字节 vs 变长）
CREATE TYPE order_status AS ENUM ('pending','paid','shipped');
CREATE TABLE orders (status order_status);
```

### 5.3 TEXT vs VARCHAR

```sql
-- ✓ 使用TEXT（无性能差异）
CREATE TABLE docs (content TEXT);

-- 不要使用VARCHAR(无明确长度需求时)
```

---

## 6. 配置优化（7条）

### 6.1 内存配置

```ini
# ✓ 25%系统内存
shared_buffers = 16GB  # (64GB系统)

# ✓ 根据并发调整
work_mem = 256MB  # 不要太大

# ✓ 维护操作
maintenance_work_mem = 2GB
```

### 6.2 SSD优化

```ini
# ✓ SSD环境
random_page_cost = 1.1
effective_io_concurrency = 200

# ✓ PostgreSQL 18
io_direct = data
io_combine_limit = 128kB
```

### 6.3 并行查询

```ini
# ✓ 启用并行
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
```

---

## 7. VACUUM优化（5条）

### 7.1 定期VACUUM

```sql
-- ✓ 定期执行
VACUUM ANALYZE users;

-- ✓ 配置autovacuum
ALTER SYSTEM SET autovacuum_naptime = '1min';
```

### 7.2 针对性VACUUM

```sql
-- ✓ 高频更新表更激进
ALTER TABLE hot_table SET (
    autovacuum_vacuum_scale_factor = 0.05,
    autovacuum_analyze_scale_factor = 0.02
);
```

---

## 8. 监控优化（总结）

```text
✓ 启用pg_stat_statements
✓ 记录慢查询日志
✓ 监控缓存命中率
✓ 监控连接数
✓ 监控锁等待
✓ 监控表膨胀
✓ 监控复制延迟
✓ 设置合理告警阈值
```

---

**完成**: PostgreSQL SQL优化50条军规
**字数**: ~8,000字
**核心规则**: 索引、查询、事务、连接、数据类型、配置、VACUUM、监控
