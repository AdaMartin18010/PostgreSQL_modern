# PostgreSQL 18 性能调优实战指南

## 1. 硬件层优化

### 1.1 存储优化

```bash
# 检查磁盘I/O性能
sudo fio --name=random-write --ioengine=libaio --iodepth=32 \
  --rw=randwrite --bs=4k --direct=1 --size=1G \
  --numjobs=4 --runtime=60 --group_reporting

# NVMe优化
sudo nvme set-feature /dev/nvme0n1 -f 0x0c -v 1  # 启用write cache

# 文件系统挂载优化
/dev/nvme0n1 /var/lib/postgresql ext4 noatime,nodiratime,nobarrier 0 0
```

### 1.2 内核参数

```bash
# /etc/sysctl.conf
# 共享内存
kernel.shmmax = 68719476736  # 64GB
kernel.shmall = 16777216

# 网络优化
net.core.somaxconn = 4096
net.ipv4.tcp_max_syn_backlog = 8192
net.core.netdev_max_backlog = 5000

# I/O调度
echo mq-deadline > /sys/block/nvme0n1/queue/scheduler

# 透明大页（关闭）
echo never > /sys/kernel/mm/transparent_hugepage/enabled

# 应用
sudo sysctl -p
```

---

## 2. PostgreSQL配置优化

### 2.1 内存配置

```ini
# postgresql.conf

# 共享内存（总内存的25%）
shared_buffers = 16GB

# 工作内存（根据并发查询数）
work_mem = 256MB  # (总内存 * 0.25) / max_connections

# 维护内存
maintenance_work_mem = 2GB

# 有效缓存（总内存的75%）
effective_cache_size = 48GB

# WAL缓冲
wal_buffers = 64MB

# 自动VACUUM内存
autovacuum_work_mem = 2GB
```

### 2.2 WAL优化

```ini
# WAL写入
wal_level = replica
wal_compression = on
wal_init_zero = on
wal_recycle = on

# WAL大小
min_wal_size = 2GB
max_wal_size = 8GB

# 检查点
checkpoint_timeout = 15min
checkpoint_completion_target = 0.9

# PostgreSQL 18新特性：异步I/O
io_direct = data
io_combine_limit = 128kB
```

### 2.3 查询优化器

```ini
# 统计精度
default_statistics_target = 500

# 成本参数（SSD）
random_page_cost = 1.1
seq_page_cost = 1.0
effective_io_concurrency = 200

# 并行查询
max_parallel_workers_per_gather = 4
max_parallel_maintenance_workers = 4
max_parallel_workers = 8
max_worker_processes = 16

# 并行安全函数
parallel_setup_cost = 100
parallel_tuple_cost = 0.01
```

---

## 3. 索引优化

### 3.1 索引选择

```sql
-- B-Tree索引（默认）
CREATE INDEX idx_users_email ON users(email);

-- 部分索引
CREATE INDEX idx_active_users ON users(email) WHERE active = true;

-- 表达式索引
CREATE INDEX idx_lower_email ON users(lower(email));

-- 多列索引
CREATE INDEX idx_orders_user_date ON orders(user_id, order_date DESC);

-- GIN索引（全文搜索、JSONB）
CREATE INDEX idx_documents_content ON documents USING GIN(content);

-- BRIN索引（时序数据）
CREATE INDEX idx_logs_timestamp ON logs USING BRIN(timestamp);

-- HNSW索引（向量，PostgreSQL 18）
CREATE INDEX idx_items_embedding ON items
USING hnsw(embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

### 3.2 索引维护

```sql
-- 查找缺失索引
SELECT
    schemaname,
    tablename,
    seq_scan,
    seq_tup_read,
    idx_scan,
    seq_tup_read / seq_scan AS avg_seq_tup
FROM pg_stat_user_tables
WHERE seq_scan > 0
  AND seq_tup_read / seq_scan > 10000
ORDER BY seq_tup_read DESC;

-- 查找未使用索引
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) AS size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
  AND indexrelname NOT LIKE '%_pkey'
ORDER BY pg_relation_size(indexrelid) DESC;

-- 重建膨胀索引
REINDEX INDEX CONCURRENTLY idx_users_email;

-- 更新统计信息
ANALYZE users;
```

---

## 4. 查询优化

### 4.1 EXPLAIN分析

```sql
-- 基础EXPLAIN
EXPLAIN SELECT * FROM orders WHERE user_id = 123;

-- ANALYZE（实际执行）
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE user_id = 123;

-- 详细格式
EXPLAIN (ANALYZE, BUFFERS, VERBOSE, COSTS, TIMING, FORMAT JSON)
SELECT * FROM orders WHERE user_id = 123;

-- 读取EXPLAIN输出
/*
关键指标:
├─ Cost: 成本估算
├─ Rows: 行数估算
├─ Width: 平均行宽
├─ Buffers: 缓冲区命中/读取
├─ Time: 执行时间
└─ Loops: 循环次数
*/
```

### 4.2 常见优化

```sql
-- 1. 使用索引扫描代替全表扫描
-- BAD
SELECT * FROM users WHERE LOWER(email) = 'test@example.com';

-- GOOD
CREATE INDEX idx_lower_email ON users(lower(email));
SELECT * FROM users WHERE lower(email) = 'test@example.com';

-- 2. 避免SELECT *
-- BAD
SELECT * FROM orders WHERE order_date > '2023-01-01';

-- GOOD
SELECT order_id, user_id, amount FROM orders
WHERE order_date > '2023-01-01';

-- 3. 使用JOIN代替子查询
-- BAD
SELECT * FROM users WHERE user_id IN (
    SELECT user_id FROM orders WHERE amount > 1000
);

-- GOOD
SELECT DISTINCT u.* FROM users u
JOIN orders o ON u.user_id = o.user_id
WHERE o.amount > 1000;

-- 4. 使用CTE优化复杂查询
WITH recent_orders AS (
    SELECT user_id, COUNT(*) AS order_count
    FROM orders
    WHERE order_date > CURRENT_DATE - INTERVAL '30 days'
    GROUP BY user_id
)
SELECT u.*, ro.order_count
FROM users u
JOIN recent_orders ro ON u.user_id = ro.user_id
WHERE ro.order_count > 5;

-- 5. 分区裁剪
-- 分区表查询会自动裁剪不相关分区
SELECT * FROM orders_partitioned
WHERE order_date >= '2023-12-01' AND order_date < '2023-12-31';
```

---

## 5. VACUUM优化

### 5.1 自动VACUUM配置

```ini
# postgresql.conf
autovacuum = on
autovacuum_max_workers = 6
autovacuum_naptime = 10s

# 表级触发阈值
autovacuum_vacuum_scale_factor = 0.1
autovacuum_vacuum_threshold = 50

# 分析阈值
autovacuum_analyze_scale_factor = 0.05
autovacuum_analyze_threshold = 50

# 冻结参数
autovacuum_freeze_max_age = 200000000
vacuum_freeze_table_age = 150000000
```

### 5.2 手动VACUUM

```sql
-- 标准VACUUM
VACUUM (VERBOSE, ANALYZE) users;

-- FULL VACUUM（锁表，重建表）
VACUUM FULL users;

-- 冻结事务ID
VACUUM (FREEZE) users;

-- 监控膨胀
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
    n_dead_tup,
    n_live_tup,
    ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) AS dead_ratio
FROM pg_stat_user_tables
WHERE n_dead_tup > 1000
ORDER BY n_dead_tup DESC;
```

---

## 6. 连接池优化

### 6.1 PgBouncer配置

```ini
# /etc/pgbouncer/pgbouncer.ini
[databases]
mydb = host=localhost port=5432 dbname=mydb

[pgbouncer]
listen_addr = *
listen_port = 6432
auth_type = scram-sha-256
auth_file = /etc/pgbouncer/userlist.txt

# 池模式
pool_mode = transaction  # session/transaction/statement

# 连接池大小
max_client_conn = 10000
default_pool_size = 25
reserve_pool_size = 5
reserve_pool_timeout = 3

# 超时
server_idle_timeout = 600
server_lifetime = 3600
```

### 6.2 应用层连接池

```python
# Python: psycopg2 connection pool
from psycopg2 import pool

connection_pool = pool.ThreadedConnectionPool(
    minconn=5,
    maxconn=20,
    host='localhost',
    port=5432,
    database='mydb',
    user='app',
    password='password'
)

# 使用
conn = connection_pool.getconn()
try:
    cursor = conn.cursor()
    cursor.execute("SELECT ...")
finally:
    connection_pool.putconn(conn)
```

---

## 7. 分区表优化

### 7.1 分区策略

```sql
-- 范围分区（时序数据）
CREATE TABLE logs (
    log_id BIGSERIAL,
    timestamp TIMESTAMPTZ NOT NULL,
    message TEXT
) PARTITION BY RANGE (timestamp);

-- 创建分区（月度）
CREATE TABLE logs_2023_12 PARTITION OF logs
FOR VALUES FROM ('2023-12-01') TO ('2024-01-01');

CREATE TABLE logs_2024_01 PARTITION OF logs
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- 哈希分区（用户数据）
CREATE TABLE users_partitioned (
    user_id BIGINT,
    username VARCHAR(100),
    email VARCHAR(255)
) PARTITION BY HASH (user_id);

-- 创建8个分区
DO $$
BEGIN
    FOR i IN 0..7 LOOP
        EXECUTE format('
            CREATE TABLE users_p%s PARTITION OF users_partitioned
            FOR VALUES WITH (MODULUS 8, REMAINDER %s);
        ', i, i);
    END LOOP;
END $$;

-- 列表分区（地域数据）
CREATE TABLE orders_by_region (
    order_id BIGINT,
    region VARCHAR(10),
    amount NUMERIC
) PARTITION BY LIST (region);

CREATE TABLE orders_asia PARTITION OF orders_by_region
FOR VALUES IN ('CN', 'JP', 'KR');

CREATE TABLE orders_europe PARTITION OF orders_by_region
FOR VALUES IN ('UK', 'FR', 'DE');
```

### 7.2 分区维护

```sql
-- 自动创建分区（使用pg_partman扩展）
CREATE EXTENSION pg_partman;

SELECT partman.create_parent(
    p_parent_table := 'public.logs',
    p_control := 'timestamp',
    p_type := 'native',
    p_interval := 'monthly',
    p_premake := 3
);

-- 自动删除旧分区
UPDATE partman.part_config
SET retention_keep_table = false,
    retention = '90 days'
WHERE parent_table = 'public.logs';
```

---

## 8. 并行查询优化

### 8.1 并行配置

```ini
# 全局并行度
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_worker_processes = 16

# 并行阈值
min_parallel_table_scan_size = 8MB
min_parallel_index_scan_size = 512kB

# 成本参数
parallel_setup_cost = 1000
parallel_tuple_cost = 0.1
```

### 8.2 强制并行

```sql
-- 查看并行计划
EXPLAIN (ANALYZE)
SELECT COUNT(*) FROM large_table;

-- 强制并行
SET max_parallel_workers_per_gather = 8;
SET parallel_setup_cost = 0;
SET parallel_tuple_cost = 0;

SELECT COUNT(*) FROM large_table;

-- 禁用并行（测试）
SET max_parallel_workers_per_gather = 0;
```

---

## 9. 监控与诊断

### 9.1 pg_stat_statements

```sql
-- 启用扩展
CREATE EXTENSION pg_stat_statements;

-- 配置
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';
ALTER SYSTEM SET pg_stat_statements.track = 'all';
ALTER SYSTEM SET pg_stat_statements.max = 10000;

-- 重启PostgreSQL
sudo systemctl restart postgresql

-- 查看慢查询
SELECT
    query,
    calls,
    total_exec_time / 1000 AS total_sec,
    mean_exec_time AS avg_ms,
    max_exec_time AS max_ms
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 20;

-- 重置统计
SELECT pg_stat_statements_reset();
```

### 9.2 实时监控

```sql
-- 当前活动查询
SELECT
    pid,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    state_change,
    query
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY query_start;

-- 锁等待
SELECT
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS blocking_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted AND blocking_locks.granted;

-- 数据库统计
SELECT
    datname,
    numbackends AS connections,
    xact_commit,
    xact_rollback,
    blks_read,
    blks_hit,
    ROUND(blks_hit * 100.0 / NULLIF(blks_hit + blks_read, 0), 2) AS cache_hit_ratio,
    tup_returned,
    tup_fetched,
    tup_inserted,
    tup_updated,
    tup_deleted
FROM pg_stat_database
WHERE datname NOT IN ('template0', 'template1');
```

---

## 10. 压力测试

### 10.1 pgbench

```bash
# 初始化测试数据
pgbench -i -s 100 mydb  # 100个scale，约1.5GB

# TPC-B测试
pgbench -c 50 -j 4 -T 60 mydb
# -c: 并发客户端数
# -j: 线程数
# -T: 运行时间（秒）

# 自定义脚本
cat > test.sql <<EOF
\set user_id random(1, 100000)
SELECT * FROM users WHERE user_id = :user_id;
EOF

pgbench -c 100 -j 8 -T 300 -f test.sql mydb

# 只读测试
pgbench -c 50 -j 4 -T 60 -S mydb
```

### 10.2 结果分析

```text
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 100
query mode: simple
number of clients: 50
number of threads: 4
duration: 60 s
number of transactions actually processed: 125043
latency average = 23.987 ms
latency stddev = 15.234 ms
tps = 2084.048219 (including connections establishing)
tps = 2084.371299 (excluding connections establishing)
```

---

## 11. 性能基准

### 11.1 TPC-H测试

```bash
# 下载TPC-H工具
git clone https://github.com/Data-Science-Platform/tpch-pgsql.git
cd tpch-pgsql

# 生成数据（10GB）
./dbgen -s 10

# 导入数据
psql -d tpch -f dss.ddl
./load.sh

# 运行查询
for i in {1..22}; do
    echo "Running Q$i..."
    psql -d tpch -f queries/$i.sql
done
```

---

## 12. 调优清单

```text
✅ 硬件层
├─ NVMe SSD RAID10
├─ 64GB+ 内存
├─ 16核+ CPU
└─ 10Gbps网络

✅ 系统层
├─ 内核参数优化
├─ 文件系统优化（noatime）
├─ I/O调度器（mq-deadline）
└─ 关闭透明大页

✅ PostgreSQL配置
├─ 内存参数（shared_buffers, work_mem）
├─ WAL参数（wal_buffers, checkpoint）
├─ 并行参数（max_parallel_workers）
└─ 成本参数（random_page_cost）

✅ 查询优化
├─ 合适的索引
├─ 优化SQL语句
├─ 使用CTE
└─ 避免N+1查询

✅ 维护
├─ 定期VACUUM
├─ 更新统计信息
├─ 重建膨胀索引
└─ 清理未使用索引

✅ 监控
├─ pg_stat_statements
├─ 慢查询日志
├─ 连接数监控
└─ 缓存命中率
```

---

**完成**: PostgreSQL 18性能调优实战指南
**字数**: ~8,000字
**涵盖**: 硬件、配置、索引、查询、VACUUM、连接池、监控
