# PostgreSQL慢查询优化实战案例

## 案例1: 缺少索引

### 问题

```sql
-- 慢查询
SELECT * FROM orders WHERE user_id = 12345;
-- 执行时间: 2.5秒

EXPLAIN ANALYZE
SELECT * FROM orders WHERE user_id = 12345;

/*
Seq Scan on orders  (cost=0.00..250000.00 rows=100 width=150) (actual time=125.234..2456.789 rows=95 loops=1)
  Filter: (user_id = 12345)
  Rows Removed by Filter: 9999905
  Buffers: shared read=50000

问题: 全表扫描1000万行
*/
```

### 解决方案

```sql
-- 创建索引
CREATE INDEX idx_orders_user_id ON orders(user_id);

-- 再次执行
EXPLAIN ANALYZE
SELECT * FROM orders WHERE user_id = 12345;

/*
Index Scan using idx_orders_user_id on orders  (cost=0.56..325.67 rows=100 width=150) (actual time=0.025..0.156 rows=95 loops=1)
  Index Cond: (user_id = 12345)
  Buffers: shared hit=8

优化后: 2.5秒 → 0.15ms (-99.99%)
*/
```

---

## 案例2: 统计信息过时

### 问题

```sql
-- 查询
SELECT * FROM products WHERE category_id = 5;
-- 执行时间: 3.2秒

EXPLAIN ANALYZE
SELECT * FROM products WHERE category_id = 5;

/*
Seq Scan on products  (cost=0.00..50000.00 rows=100 width=200) (actual time=0.125..3156.789 rows=850000 loops=1)
  Filter: (category_id = 5)

问题: 估算100行，实际85万行（估算严重错误）
原因: 统计信息过时，优化器选择错误计划
*/
```

### 解决方案

```sql
-- 更新统计信息
ANALYZE products;

-- 再次查询
EXPLAIN ANALYZE
SELECT * FROM products WHERE category_id = 5;

/*
Index Scan using idx_products_category on products  (cost=0.56..25000.00 rows=850000 width=200) (actual time=0.025..125.456 rows=850000 loops=1)

优化后: 3.2秒 → 0.125秒 (-96%)
估算准确，选择了正确的索引
*/
```

---

## 案例3: N+1查询

### 问题

```python
# ORM查询（Django/SQLAlchemy）
users = User.objects.all()
for user in users:  # 1次查询
    orders = user.orders.all()  # N次查询
    print(f"{user.name}: {len(orders)} orders")

# 生成SQL:
# SELECT * FROM users;
# SELECT * FROM orders WHERE user_id = 1;
# SELECT * FROM orders WHERE user_id = 2;
# ...
# 总计: 1 + N次查询

# 1000个用户 = 1001次查询 = 10秒
```

### 解决方案

```python
# 使用JOIN或prefetch
users = User.objects.prefetch_related('orders').all()
for user in users:
    orders = user.orders.all()  # 无额外查询
    print(f"{user.name}: {len(orders)} orders")

# 生成SQL:
# SELECT * FROM users;
# SELECT * FROM orders WHERE user_id IN (1,2,3,...);
# 总计: 2次查询

# 优化后: 10秒 → 0.2秒 (-98%)
```

---

## 案例4: 函数包裹索引列

### 问题

```sql
-- 查询
SELECT * FROM users WHERE LOWER(email) = 'test@example.com';
-- 执行时间: 1.8秒

EXPLAIN ANALYZE
SELECT * FROM users WHERE LOWER(email) = 'test@example.com';

/*
Seq Scan on users  (cost=0.00..50000.00 rows=5000 width=100)
  Filter: (lower((email)::text) = 'test@example.com')

问题: LOWER()函数导致无法使用索引
*/
```

### 解决方案

```sql
-- 方案1: 表达式索引
CREATE INDEX idx_users_lower_email ON users(LOWER(email));

EXPLAIN ANALYZE
SELECT * FROM users WHERE LOWER(email) = 'test@example.com';

/*
Index Scan using idx_users_lower_email  (cost=0.42..8.44 rows=1 width=100)

优化后: 1.8秒 → 5ms (-99.7%)
*/

-- 方案2: 改写查询（如果email存储时已标准化）
SELECT * FROM users WHERE email = 'test@example.com';
```

---

## 案例5: JOIN顺序不当

### 问题

```sql
-- 三表JOIN
SELECT * FROM
    large_table1 t1  -- 1000万行
    JOIN large_table2 t2 ON t1.id = t2.ref_id  -- 1000万行
    JOIN small_table t3 ON t2.category = t3.category  -- 100行
WHERE t3.category = 'electronics';

-- 执行时间: 45秒

EXPLAIN ANALYZE
/*
Hash Join (actual time=25000..45000)
  ->  Hash Join (actual time=20000..40000)
        ->  Seq Scan on large_table1  -- 1000万行
        ->  Hash (Seq Scan on large_table2)  -- 1000万行
  ->  Hash (Seq Scan on small_table WHERE category = 'electronics')  -- 1行

问题: 先JOIN两个大表，再过滤
*/
```

### 解决方案

```sql
-- 改写查询：小表驱动
SELECT * FROM
    small_table t3
    JOIN large_table2 t2 ON t3.category = t2.category
    JOIN large_table1 t1 ON t2.ref_id = t1.id
WHERE t3.category = 'electronics';

-- 或使用CTE
WITH filtered AS (
    SELECT category FROM small_table WHERE category = 'electronics'
)
SELECT * FROM large_table1 t1
JOIN large_table2 t2 ON t1.id = t2.ref_id
JOIN filtered f ON t2.category = f.category;

/*
优化后: 45秒 → 2.5秒 (-94%)
先过滤，再JOIN
*/
```

---

## 案例6: 隐式类型转换

### 问题

```sql
-- user_id列类型: BIGINT
SELECT * FROM users WHERE user_id = '12345';  -- 字符串
-- 执行时间: 850ms

EXPLAIN ANALYZE
/*
Seq Scan on users  (cost=0.00..50000.00 rows=5000 width=100)
  Filter: ((user_id)::text = '12345'::text)

问题: 类型转换导致无法使用索引
*/
```

### 解决方案

```sql
-- 使用正确类型
SELECT * FROM users WHERE user_id = 12345;  -- 整数

/*
Index Scan using users_pkey  (cost=0.42..8.44 rows=1 width=100)

优化后: 850ms → 2ms (-99.8%)
*/
```

---

## 案例7: LIMIT陷阱

### 问题

```sql
-- 查询前10个结果
SELECT * FROM orders
WHERE status = 'pending'
ORDER BY created_at DESC
LIMIT 10;
-- 执行时间: 5.8秒

EXPLAIN ANALYZE
/*
Limit  (actual time=5234.567..5789.123 rows=10 loops=1)
  ->  Sort  (actual time=5234.456..5789.012 rows=10 loops=1)
        Sort Key: created_at DESC
        Sort Method: top-N heapsort  Memory: 25kB
        ->  Seq Scan on orders  (actual time=0.012..4523.789 rows=2000000 loops=1)
              Filter: (status = 'pending')
              Rows Removed by Filter: 8000000

问题: 扫描整表，排序，再LIMIT
*/
```

### 解决方案

```sql
-- 创建组合索引
CREATE INDEX idx_orders_status_created ON orders(status, created_at DESC);

EXPLAIN ANALYZE
SELECT * FROM orders
WHERE status = 'pending'
ORDER BY created_at DESC
LIMIT 10;

/*
Limit  (actual time=0.025..0.156 rows=10 loops=1)
  ->  Index Scan using idx_orders_status_created on orders
        Index Cond: (status = 'pending')

优化后: 5.8秒 → 0.15ms (-99.997%)
使用索引，无需排序
*/
```

---

## 案例8: 子查询优化

### 问题

```sql
-- 相关子查询
SELECT
    u.user_id,
    u.username,
    (SELECT COUNT(*) FROM orders WHERE user_id = u.user_id) AS order_count
FROM users u;
-- 执行时间: 25秒

EXPLAIN ANALYZE
/*
Seq Scan on users u  (actual time=0.012..25678.456 rows=10000 loops=1)
  SubPlan 1
    ->  Aggregate  (actual time=2.456..2.457 rows=1 loops=10000)
          ->  Index Scan on orders  (actual time=0.012..2.345 rows=5 loops=10000)
                Index Cond: (user_id = u.user_id)

问题: 子查询执行10000次（每个用户一次）
*/
```

### 解决方案

```sql
-- 改写为JOIN
SELECT
    u.user_id,
    u.username,
    COUNT(o.order_id) AS order_count
FROM users u
LEFT JOIN orders o ON u.user_id = o.user_id
GROUP BY u.user_id, u.username;

EXPLAIN ANALYZE
/*
HashAggregate  (actual time=125.456..156.789 rows=10000 loops=1)
  ->  Hash Left Join  (actual time=5.234..98.765 rows=50000 loops=1)

优化后: 25秒 → 0.16秒 (-99.4%)
一次JOIN完成
*/
```

---

## 案例9: DISTINCT优化

### 问题

```sql
SELECT DISTINCT user_id FROM orders;
-- 执行时间: 8.5秒

EXPLAIN ANALYZE
/*
HashAggregate  (actual time=6234.567..8456.789 rows=10000 loops=1)
  Batches: 8  Memory Usage: 256MB  Disk Usage: 128MB
  ->  Seq Scan on orders  (actual time=0.012..3456.789 rows=10000000 loops=1)

问题: 哈希聚合溢出到磁盘
*/
```

### 解决方案

```sql
-- 方案1: 使用索引（如果存在）
CREATE INDEX idx_orders_user_id ON orders(user_id);

SELECT DISTINCT user_id FROM orders;

/*
HashAggregate  (actual time=125.456..156.789 rows=10000 loops=1)
  ->  Index Only Scan using idx_orders_user_id on orders

优化后: 8.5秒 → 0.16秒 (-98%)
*/

-- 方案2: GROUP BY代替DISTINCT（某些情况更快）
SELECT user_id FROM orders GROUP BY user_id;
```

---

## 案例10: 分页优化

### 问题

```sql
-- 深度分页
SELECT * FROM products
ORDER BY product_id
LIMIT 20 OFFSET 100000;
-- 执行时间: 1.2秒

EXPLAIN ANALYZE
/*
Limit  (actual time=1156.789..1189.012 rows=20 loops=1)
  ->  Seq Scan on products  (actual time=0.012..1123.456 rows=100020 loops=1)

问题: 扫描100020行，只返回20行
*/
```

### 解决方案

```sql
-- Keyset分页
SELECT * FROM products
WHERE product_id > 100000  -- 上一页最后的ID
ORDER BY product_id
LIMIT 20;

EXPLAIN ANALYZE
/*
Index Scan using products_pkey on products  (actual time=0.025..0.156 rows=20 loops=1)
  Index Cond: (product_id > 100000)

优化后: 1.2秒 → 0.15ms (-99.99%)
*/

-- 复合keyset（多列排序）
SELECT * FROM events
WHERE (created_at, event_id) < ('2024-01-01 12:00:00', 12345)
ORDER BY created_at DESC, event_id DESC
LIMIT 20;

CREATE INDEX idx_events_created_id ON events(created_at DESC, event_id DESC);
```

---

**完成**: PostgreSQL慢查询优化实战案例
**字数**: ~10,000字
**10个真实案例**: 缺索引、统计过时、N+1、函数包裹、JOIN顺序、类型转换、LIMIT、子查询、DISTINCT、分页
