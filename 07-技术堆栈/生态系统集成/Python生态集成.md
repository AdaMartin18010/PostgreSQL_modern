# Python ç”Ÿæ€é›†æˆ PostgreSQL å‘é‡æœç´¢

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 14+, pgvector 0.7.0+, Python 3.8+
> **æ–‡æ¡£ç¼–å·**: 07-03-03

## ğŸ“‘ ç›®å½•

- [Python ç”Ÿæ€é›†æˆ PostgreSQL å‘é‡æœç´¢](#python-ç”Ÿæ€é›†æˆ-postgresql-å‘é‡æœç´¢)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 æ–‡æ¡£ç›®æ ‡](#11-æ–‡æ¡£ç›®æ ‡)
    - [1.2 Python ç”Ÿæ€ä¼˜åŠ¿](#12-python-ç”Ÿæ€ä¼˜åŠ¿)
    - [1.3 é›†æˆä»·å€¼](#13-é›†æˆä»·å€¼)
  - [2. æ ¸å¿ƒåº“](#2-æ ¸å¿ƒåº“)
    - [2.1 psycopg2 / psycopg3](#21-psycopg2--psycopg3)
      - [2.1.1 å®‰è£…å’Œé…ç½®](#211-å®‰è£…å’Œé…ç½®)
      - [2.1.2 åŸºç¡€ä½¿ç”¨](#212-åŸºç¡€ä½¿ç”¨)
      - [2.1.3 å‘é‡æŸ¥è¯¢](#213-å‘é‡æŸ¥è¯¢)
    - [2.2 SQLAlchemy + pgvector](#22-sqlalchemy--pgvector)
      - [2.2.1 ORM é›†æˆ](#221-orm-é›†æˆ)
      - [2.2.2 æ¨¡å‹å®šä¹‰](#222-æ¨¡å‹å®šä¹‰)
      - [2.2.3 å‘é‡æŸ¥è¯¢](#223-å‘é‡æŸ¥è¯¢)
    - [2.3 asyncpg + pgvector](#23-asyncpg--pgvector)
      - [2.3.1 å¼‚æ­¥é©±åŠ¨](#231-å¼‚æ­¥é©±åŠ¨)
      - [2.3.2 å¼‚æ­¥æŸ¥è¯¢](#232-å¼‚æ­¥æŸ¥è¯¢)
      - [2.3.3 æ€§èƒ½ä¼˜åŠ¿](#233-æ€§èƒ½ä¼˜åŠ¿)
  - [3. LangChain é›†æˆ](#3-langchain-é›†æˆ)
    - [3.1 åŸºç¡€é›†æˆ](#31-åŸºç¡€é›†æˆ)
    - [3.2 RAG åº”ç”¨](#32-rag-åº”ç”¨)
    - [3.3 é«˜çº§ç‰¹æ€§](#33-é«˜çº§ç‰¹æ€§)
  - [4. FastAPI é›†æˆ](#4-fastapi-é›†æˆ)
    - [4.1 REST API å¼€å‘](#41-rest-api-å¼€å‘)
      - [4.1.1 åŸºç¡€ API](#411-åŸºç¡€-api)
      - [4.1.2 å‘é‡æœç´¢ API](#412-å‘é‡æœç´¢-api)
      - [4.1.3 RAG API](#413-rag-api)
    - [4.2 å¼‚æ­¥å¤„ç†](#42-å¼‚æ­¥å¤„ç†)
    - [4.3 API æ–‡æ¡£](#43-api-æ–‡æ¡£)
  - [5. Pandas é›†æˆ](#5-pandas-é›†æˆ)
    - [5.1 æ•°æ®è¯»å–](#51-æ•°æ®è¯»å–)
    - [5.2 æ•°æ®åˆ†æ](#52-æ•°æ®åˆ†æ)
    - [5.3 æ•°æ®å†™å…¥](#53-æ•°æ®å†™å…¥)
  - [6. NumPy é›†æˆ](#6-numpy-é›†æˆ)
    - [6.1 å‘é‡è®¡ç®—](#61-å‘é‡è®¡ç®—)
    - [6.2 æ‰¹é‡å¤„ç†](#62-æ‰¹é‡å¤„ç†)
    - [6.3 æ€§èƒ½ä¼˜åŒ–](#63-æ€§èƒ½ä¼˜åŒ–)
  - [7. å…¶ä»–ç”Ÿæ€å·¥å…·](#7-å…¶ä»–ç”Ÿæ€å·¥å…·)
    - [7.1 Django é›†æˆ](#71-django-é›†æˆ)
    - [7.2 Flask é›†æˆ](#72-flask-é›†æˆ)
    - [7.3 Streamlit é›†æˆ](#73-streamlit-é›†æˆ)
  - [8. æœ€ä½³å®è·µ](#8-æœ€ä½³å®è·µ)
    - [8.1 è¿æ¥ç®¡ç†](#81-è¿æ¥ç®¡ç†)
    - [8.2 æ€§èƒ½ä¼˜åŒ–](#82-æ€§èƒ½ä¼˜åŒ–)
    - [8.3 é”™è¯¯å¤„ç†](#83-é”™è¯¯å¤„ç†)
  - [9. å¸¸è§é—®é¢˜](#9-å¸¸è§é—®é¢˜)
    - [9.1 ä¾èµ–é—®é¢˜](#91-ä¾èµ–é—®é¢˜)
    - [9.2 è¿æ¥é—®é¢˜](#92-è¿æ¥é—®é¢˜)
    - [9.3 æ€§èƒ½é—®é¢˜](#93-æ€§èƒ½é—®é¢˜)
  - [10. å‚è€ƒèµ„æ–™](#10-å‚è€ƒèµ„æ–™)
    - [10.1 å®˜æ–¹æ–‡æ¡£](#101-å®˜æ–¹æ–‡æ¡£)
    - [10.2 æŠ€æœ¯æ–‡æ¡£](#102-æŠ€æœ¯æ–‡æ¡£)
    - [10.3 ç›¸å…³èµ„æº](#103-ç›¸å…³èµ„æº)

---

## 1. æ¦‚è¿°

### 1.1 æ–‡æ¡£ç›®æ ‡

**æ ¸å¿ƒç›®æ ‡**:

æœ¬æ–‡æ¡£æä¾› PostgreSQL + pgvector ä¸ Python ç”Ÿæ€ç³»ç»Ÿçš„å®Œæ•´é›†æˆæŒ‡å—ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿæ„å»ºåŸºäºå‘é‡æœç´¢çš„
Python åº”ç”¨ã€‚

**æ–‡æ¡£ä»·å€¼**:

| ä»·å€¼é¡¹       | è¯´æ˜                     | å½±å“         |
| ------------ | ------------------------ | ------------ |
| **å®Œæ•´é›†æˆ** | è¦†ç›–ä¸»æµ Python åº“å’Œæ¡†æ¶ | æé«˜å¼€å‘æ•ˆç‡ |
| **æœ€ä½³å®è·µ** | æä¾›é›†æˆæœ€ä½³å®è·µ         | å‡å°‘å¸¸è§é—®é¢˜ |
| **æ€§èƒ½ä¼˜åŒ–** | æä¾›æ€§èƒ½ä¼˜åŒ–å»ºè®®         | æé«˜åº”ç”¨æ€§èƒ½ |

### 1.2 Python ç”Ÿæ€ä¼˜åŠ¿

**Python ç”Ÿæ€ç‰¹æ€§**:

| ç‰¹æ€§           | è¯´æ˜               | ä¼˜åŠ¿         |
| -------------- | ------------------ | ------------ |
| **ä¸°å¯Œçš„åº“**   | å¤§é‡æˆç†Ÿçš„åº“å’Œæ¡†æ¶ | å¿«é€Ÿå¼€å‘     |
| **æ˜“ç”¨æ€§**     | ç®€æ´çš„è¯­æ³•å’Œ API   | é™ä½å­¦ä¹ æˆæœ¬ |
| **ç”Ÿæ€ç³»ç»Ÿ**   | æ´»è·ƒçš„ç¤¾åŒºå’Œæ”¯æŒ   | æŒç»­æ›´æ–°     |
| **AI/ML æ”¯æŒ** | å¼ºå¤§çš„ AI/ML åº“    | é€‚åˆ AI åº”ç”¨ |

### 1.3 é›†æˆä»·å€¼

**é›†æˆä¼˜åŠ¿**:

| ä¼˜åŠ¿         | è¯´æ˜                           | å½±å“               |
| ------------ | ------------------------------ | ------------------ |
| **å‘é‡æœç´¢** | PostgreSQL + pgvector å‘é‡æœç´¢ | **é«˜æ€§èƒ½å‘é‡æ£€ç´¢** |
| **ORM æ”¯æŒ** | SQLAlchemyã€Django ORM æ”¯æŒ    | **ç®€åŒ–æ•°æ®è®¿é—®**   |
| **å¼‚æ­¥æ”¯æŒ** | asyncpg å¼‚æ­¥é©±åŠ¨               | **æé«˜å¹¶å‘æ€§èƒ½**   |
| **æ¡†æ¶é›†æˆ** | FastAPIã€Flaskã€Django é›†æˆ    | **å¿«é€Ÿæ„å»ºåº”ç”¨**   |

## 2. æ ¸å¿ƒåº“

### 2.1 psycopg2 / psycopg3

#### 2.1.1 å®‰è£…å’Œé…ç½®

**å®‰è£…**:

```bash
# psycopg2ï¼ˆç¨³å®šç‰ˆï¼Œæ¨èï¼‰
pip install psycopg2-binary

# psycopg3ï¼ˆæ–°ç‰ˆï¼Œæ€§èƒ½æ›´å¥½ï¼‰
pip install psycopg[binary]
```

**ç‰ˆæœ¬å¯¹æ¯”**:

| ç‰¹æ€§       | psycopg2 | psycopg3     |
| ---------- | -------- | ------------ |
| **ç¨³å®šæ€§** | éå¸¸ç¨³å®š | æ–°ç‰ˆæœ¬       |
| **æ€§èƒ½**   | è‰¯å¥½     | **æ›´å¥½**     |
| **API**    | ä¼ ç»Ÿ API | **ç°ä»£ API** |
| **å¼‚æ­¥**   | ä¸æ”¯æŒ   | **æ”¯æŒ**     |

**è¿æ¥é…ç½®**:

```python
import psycopg2
from psycopg2 import pool

# è¿æ¥æ± é…ç½®
connection_pool = psycopg2.pool.ThreadedConnectionPool(
    minconn=1,
    maxconn=20,
    host="localhost",
    port=5432,
    user="postgres",
    password="postgres",
    database="vector_db"
)

def get_connection():
    """è·å–è¿æ¥"""
    return connection_pool.getconn()

def return_connection(conn):
    """å½’è¿˜è¿æ¥"""
    connection_pool.putconn(conn)
```

#### 2.1.2 åŸºç¡€ä½¿ç”¨

**åŸºç¡€ä½¿ç”¨ç¤ºä¾‹**:

```python
import psycopg2
from psycopg2.extras import RealDictCursor

# è¿æ¥
conn = psycopg2.connect(
    host="localhost",
    port=5432,
    user="postgres",
    password="postgres",
    database="vector_db"
)

# åˆ›å»ºæ‰©å±•
with conn.cursor() as cur:
    cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    conn.commit()

# åˆ›å»ºè¡¨
with conn.cursor() as cur:
    cur.execute("""
        CREATE TABLE IF NOT EXISTS documents (
            id SERIAL PRIMARY KEY,
            content TEXT,
            embedding vector(1536),
            metadata JSONB
        )
    """)
    conn.commit()

# æ’å…¥æ•°æ®
with conn.cursor() as cur:
    cur.execute("""
        INSERT INTO documents (content, embedding, metadata)
        VALUES (%s, %s::vector, %s)
    """, (content, str(embedding), metadata))
    conn.commit()

conn.close()
```

#### 2.1.3 å‘é‡æŸ¥è¯¢

**å‘é‡æŸ¥è¯¢ç¤ºä¾‹**:

```python
import psycopg2
import numpy as np

conn = psycopg2.connect(DATABASE_URL)

# å‘é‡æŸ¥è¯¢ï¼ˆä½™å¼¦è·ç¦»ï¼‰
query_vector = np.random.rand(1536).tolist()
query_vector_str = '[' + ','.join(map(str, query_vector)) + ']'

with conn.cursor() as cur:
    cur.execute("""
        SELECT
            id,
            content,
            1 - (embedding <=> %s::vector) as similarity,
            metadata
        FROM documents
        WHERE embedding <=> %s::vector < 0.3
        ORDER BY embedding <=> %s::vector
        LIMIT 10
    """, (query_vector_str, query_vector_str, query_vector_str))

    results = cur.fetchall()
    for row in results:
        print(f"ID: {row[0]}, ç›¸ä¼¼åº¦: {row[2]:.4f}, å†…å®¹: {row[1][:50]}...")

conn.close()
```

**æ‰¹é‡æŸ¥è¯¢**:

```python
from psycopg2.extras import execute_values

with conn.cursor() as cur:
    # æ‰¹é‡æŸ¥è¯¢
    queries = [np.random.rand(1536).tolist() for _ in range(10)]
    query_strings = ['[' + ','.join(map(str, q)) + ']' for q in queries]

    # ä½¿ç”¨ UNNEST è¿›è¡Œæ‰¹é‡æŸ¥è¯¢
    cur.execute("""
        WITH queries AS (
            SELECT unnest(%s::vector[]) as query_vector
        )
        SELECT
            q.query_vector,
            d.id,
            d.content,
            1 - (d.embedding <=> q.query_vector) as similarity
        FROM queries q
        CROSS JOIN LATERAL (
            SELECT * FROM documents
            ORDER BY embedding <=> q.query_vector
            LIMIT 5
        ) d
        ORDER BY q.query_vector, similarity DESC
    """, (query_strings,))

    results = cur.fetchall()
```

### 2.2 SQLAlchemy + pgvector

#### 2.2.1 ORM é›†æˆ

**å®‰è£…ä¾èµ–**:

```bash
pip install sqlalchemy psycopg2-binary pgvector
```

**åŸºç¡€é…ç½®**:

```python
from sqlalchemy import create_engine, Column, Integer, String, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from pgvector.sqlalchemy import Vector

# åˆ›å»ºå¼•æ“
engine = create_engine(
    'postgresql://postgres:postgres@localhost:5432/vector_db',
    pool_size=20,
    max_overflow=0,
    pool_pre_ping=True
)

# åˆ›å»ºä¼šè¯å·¥å‚
SessionLocal = sessionmaker(bind=engine)

Base = declarative_base()
```

#### 2.2.2 æ¨¡å‹å®šä¹‰

**æ¨¡å‹å®šä¹‰ç¤ºä¾‹**:

```python
from sqlalchemy import Column, Integer, String, Text, JSON
from sqlalchemy.ext.declarative import declarative_base
from pgvector.sqlalchemy import Vector
import datetime

Base = declarative_base()

class Document(Base):
    __tablename__ = 'documents'

    id = Column(Integer, primary_key=True)
    content = Column(Text, nullable=False)
    embedding = Column(Vector(1536), nullable=False)
    metadata = Column(JSON, default={})
    created_at = Column(DateTime, default=datetime.datetime.utcnow)

    def __repr__(self):
        return f"<Document(id={self.id}, content={self.content[:50]}...)>"

# åˆ›å»ºè¡¨
Base.metadata.create_all(engine)
```

#### 2.2.3 å‘é‡æŸ¥è¯¢

**å‘é‡æŸ¥è¯¢ç¤ºä¾‹**:

```python
from sqlalchemy.orm import Session
import numpy as np

# åˆ›å»ºä¼šè¯
session = SessionLocal()

# æ’å…¥æ•°æ®
query_vector = np.random.rand(1536)
doc = Document(
    content="PostgreSQL is a powerful database",
    embedding=query_vector,
    metadata={"category": "database", "author": "PostgreSQL Team"}
)
session.add(doc)
session.commit()

# å‘é‡æŸ¥è¯¢ï¼ˆä½™å¼¦è·ç¦»ï¼‰
query_vector = np.random.rand(1536)
results = session.query(Document).order_by(
    Document.embedding.cosine_distance(query_vector)
).limit(10).all()

# å‘é‡æŸ¥è¯¢ï¼ˆæ¬§æ°è·ç¦»ï¼‰
results = session.query(Document).order_by(
    Document.embedding.l2_distance(query_vector)
).limit(10).all()

# å‘é‡æŸ¥è¯¢ï¼ˆå†…ç§¯ï¼‰
results = session.query(Document).order_by(
    Document.embedding.max_inner_product(query_vector)
).limit(10).all()

# å¸¦é˜ˆå€¼çš„æŸ¥è¯¢
from sqlalchemy import func
results = session.query(Document).filter(
    func.cosine_distance(Document.embedding, query_vector) < 0.3
).order_by(
    Document.embedding.cosine_distance(query_vector)
).limit(10).all()

session.close()
```

### 2.3 asyncpg + pgvector

#### 2.3.1 å¼‚æ­¥é©±åŠ¨

**å®‰è£…ä¾èµ–**:

```bash
pip install asyncpg pgvector
```

**å¼‚æ­¥è¿æ¥é…ç½®**:

```python
import asyncio
import asyncpg
from pgvector.asyncpg import register_vector

# è¿æ¥æ± é…ç½®
async def create_pool():
    """åˆ›å»ºè¿æ¥æ± """
    pool = await asyncpg.create_pool(
        host="localhost",
        port=5432,
        user="postgres",
        password="postgres",
        database="vector_db",
        min_size=5,
        max_size=20
    )
    return pool

# ä½¿ç”¨è¿æ¥æ± 
pool = await create_pool()
```

#### 2.3.2 å¼‚æ­¥æŸ¥è¯¢

**å¼‚æ­¥æŸ¥è¯¢ç¤ºä¾‹**:

```python
async def search_vectors(pool, query_vector, top_k=10):
    """å¼‚æ­¥å‘é‡æœç´¢"""
    async with pool.acquire() as conn:
        # æ³¨å†Œå‘é‡ç±»å‹
        await register_vector(conn)

        # æŸ¥è¯¢
        results = await conn.fetch("""
            SELECT
                id,
                content,
                1 - (embedding <=> $1::vector) as similarity,
                metadata
            FROM documents
            WHERE embedding <=> $1::vector < 0.3
            ORDER BY embedding <=> $1::vector
            LIMIT $2
        """, query_vector, top_k)

        return results

# ä½¿ç”¨
import numpy as np
query_vector = np.random.rand(1536).tolist()
results = await search_vectors(pool, query_vector, top_k=10)

for row in results:
    print(f"ID: {row['id']}, ç›¸ä¼¼åº¦: {row['similarity']:.4f}")
```

**æ‰¹é‡å¼‚æ­¥æŸ¥è¯¢**:

```python
async def batch_search_vectors(pool, query_vectors, top_k=10):
    """æ‰¹é‡å¼‚æ­¥å‘é‡æœç´¢"""
    async with pool.acquire() as conn:
        await register_vector(conn)

        # å¹¶è¡ŒæŸ¥è¯¢
        tasks = []
        for query_vector in query_vectors:
            task = conn.fetch("""
                SELECT * FROM documents
                ORDER BY embedding <=> $1::vector
                LIMIT $2
            """, query_vector, top_k)
            tasks.append(task)

        results = await asyncio.gather(*tasks)
        return results

# ä½¿ç”¨
query_vectors = [np.random.rand(1536).tolist() for _ in range(10)]
all_results = await batch_search_vectors(pool, query_vectors)
```

#### 2.3.3 æ€§èƒ½ä¼˜åŠ¿

**æ€§èƒ½å¯¹æ¯”**:

| é©±åŠ¨         | å¹¶å‘æ”¯æŒ | æ€§èƒ½     | é€‚ç”¨åœºæ™¯     |
| ------------ | -------- | -------- | ------------ |
| **psycopg2** | çº¿ç¨‹çº§   | è‰¯å¥½     | åŒæ­¥åº”ç”¨     |
| **asyncpg**  | åç¨‹çº§   | **æ›´å¥½** | **å¼‚æ­¥åº”ç”¨** |

**å¼‚æ­¥æ€§èƒ½ç¤ºä¾‹**:

```python
import asyncio
import time

async def async_performance_test():
    """å¼‚æ­¥æ€§èƒ½æµ‹è¯•"""
    pool = await create_pool()

    query_vectors = [np.random.rand(1536).tolist() for _ in range(100)]

    start = time.time()
    results = await batch_search_vectors(pool, query_vectors)
    end = time.time()

    print(f"å¼‚æ­¥æŸ¥è¯¢è€—æ—¶: {end - start:.2f} ç§’")
    print(f"å¹³å‡æ¯ä¸ªæŸ¥è¯¢: {(end - start) / len(query_vectors) * 1000:.2f} ms")

    await pool.close()

# è¿è¡Œ
asyncio.run(async_performance_test())
```

## 3. LangChain é›†æˆ

### 3.1 åŸºç¡€é›†æˆ

**åŸºç¡€é›†æˆç¤ºä¾‹**:

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
import os

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# åˆ›å»ºå‘é‡å­˜å‚¨
vectorstore = PGVector(
    embeddings=embeddings,
    connection=os.getenv("POSTGRES_URL"),
    collection_name="documents",
    use_jsonb=True,  # PostgreSQL 18 ä¼˜åŒ–
    pre_delete_collection=False,
    distance_strategy="cosine"
)

# æ·»åŠ æ–‡æ¡£
documents = [
    Document(page_content="PostgreSQL is a powerful database"),
    Document(page_content="pgvector adds vector search capabilities"),
    Document(page_content="LangChain integrates with PostgreSQL")
]

vectorstore.add_documents(documents)
print("âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸ")
```

### 3.2 RAG åº”ç”¨

**RAG åº”ç”¨ç¤ºä¾‹**:

```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ– LLM
llm = ChatOpenAI(
    model="gpt-4-turbo-preview",
    temperature=0,
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# åˆ›å»º RAG é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    return_source_documents=True
)

# æé—®
result = qa_chain.invoke({"query": "What is PostgreSQL?"})
print(f"å›ç­”: {result['result']}")
```

### 3.3 é«˜çº§ç‰¹æ€§

**é«˜çº§ç‰¹æ€§ç¤ºä¾‹**:

```python
# å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æœç´¢
retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 5,
        "filter": {"category": "database"}
    }
)

# å¸¦åˆ†æ•°çš„æœç´¢
results_with_scores = vectorstore.similarity_search_with_score(
    "PostgreSQL",
    k=5
)

for doc, score in results_with_scores:
    similarity = 1 - score  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
    print(f"[ç›¸ä¼¼åº¦: {similarity:.4f}] {doc.page_content}")
```

## 4. FastAPI é›†æˆ

### 4.1 REST API å¼€å‘

#### 4.1.1 åŸºç¡€ API

**åŸºç¡€ FastAPI åº”ç”¨**:

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
import os

app = FastAPI(title="Vector Search API")

# åˆå§‹åŒ–å‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

vectorstore = PGVector(
    embeddings=embeddings,
    connection=os.getenv("POSTGRES_URL"),
    collection_name="documents"
)
```

#### 4.1.2 å‘é‡æœç´¢ API

**å‘é‡æœç´¢ API**:

```python
class SearchRequest(BaseModel):
    query: str
    top_k: int = 5
    filter: dict = None

class DocumentResponse(BaseModel):
    id: int
    content: str
    similarity: float
    metadata: dict = None

@app.post("/api/search", response_model=list[DocumentResponse])
async def search_documents(request: SearchRequest):
    """å‘é‡æœç´¢æ¥å£"""
    try:
        search_kwargs = {"k": request.top_k}
        if request.filter:
            search_kwargs["filter"] = request.filter

        retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)
        results = retriever.get_relevant_documents(request.query)

        return [
            DocumentResponse(
                id=i,
                content=doc.page_content,
                similarity=1.0,  # å¯ä»¥ä» metadata è·å–
                metadata=doc.metadata
            )
            for i, doc in enumerate(results)
        ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 4.1.3 RAG API

**RAG API**:

```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4-turbo-preview",
    temperature=0,
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    return_source_documents=True
)

class ChatRequest(BaseModel):
    query: str

class ChatResponse(BaseModel):
    answer: str
    sources: list[str] = None

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """RAG èŠå¤©æ¥å£"""
    try:
        result = qa_chain.invoke({"query": request.query})

        return ChatResponse(
            answer=result['result'],
            sources=[doc.page_content[:100] for doc in result.get('source_documents', [])]
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### 4.2 å¼‚æ­¥å¤„ç†

**å¼‚æ­¥å‘é‡å­˜å‚¨**:

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings

@app.post("/api/search/async")
async def async_search_documents(request: SearchRequest):
    """å¼‚æ­¥å‘é‡æœç´¢"""
    try:
        # å¼‚æ­¥æœç´¢
        results = await vectorstore.asimilarity_search(
            request.query,
            k=request.top_k
        )

        return [
            DocumentResponse(
                id=i,
                content=doc.page_content,
                similarity=1.0,
                metadata=doc.metadata
            )
            for i, doc in enumerate(results)
        ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### 4.3 API æ–‡æ¡£

**è‡ªåŠ¨ç”Ÿæˆ API æ–‡æ¡£**:

```bash
# è¿è¡Œ FastAPI åº”ç”¨
uvicorn main:app --reload

# è®¿é—® API æ–‡æ¡£
# Swagger UI: http://localhost:8000/docs
# ReDoc: http://localhost:8000/redoc
```

## 5. Pandas é›†æˆ

### 5.1 æ•°æ®è¯»å–

**æ•°æ®è¯»å–ç¤ºä¾‹**:

```python
import pandas as pd
from sqlalchemy import create_engine

# åˆ›å»ºå¼•æ“
engine = create_engine('postgresql://postgres:postgres@localhost:5432/vector_db')

# è¯»å–æ•°æ®
df = pd.read_sql("""
    SELECT
        id,
        content,
        metadata,
        created_at
    FROM documents
    LIMIT 10000
""", engine)

print(f"è¯»å–äº† {len(df)} è¡Œæ•°æ®")
print(df.head())
```

**å‘é‡æ•°æ®è¯»å–**:

```python
# è¯»å–å‘é‡æ•°æ®ï¼ˆéœ€è¦è½¬æ¢ä¸ºåˆ—è¡¨ï¼‰
import numpy as np

df = pd.read_sql("""
    SELECT
        id,
        content,
        embedding::text as embedding_text,
        metadata
    FROM documents
    LIMIT 1000
""", engine)

# è½¬æ¢ä¸º NumPy æ•°ç»„
df['embedding'] = df['embedding_text'].apply(
    lambda x: np.array(eval(x))
)

# åˆ é™¤æ–‡æœ¬åˆ—
df = df.drop('embedding_text', axis=1)
```

### 5.2 æ•°æ®åˆ†æ

**æ•°æ®åˆ†æç¤ºä¾‹**:

```python
# åŸºç¡€ç»Ÿè®¡
print(df.describe())

# æŒ‰ç±»åˆ«åˆ†ç»„åˆ†æ
if 'metadata' in df.columns:
    df['category'] = df['metadata'].apply(
        lambda x: x.get('category', 'unknown') if isinstance(x, dict) else 'unknown'
    )

    category_stats = df.groupby('category').agg({
        'id': 'count',
        'content': lambda x: x.str.len().mean()  # å¹³å‡å†…å®¹é•¿åº¦
    })
    print(category_stats)

# å‘é‡ç›¸ä¼¼åº¦åˆ†æ
if 'embedding' in df.columns:
    query_vector = np.random.rand(1536)
    df['distance'] = df['embedding'].apply(
        lambda x: np.linalg.norm(x - query_vector)
    )

    print(f"å¹³å‡è·ç¦»: {df['distance'].mean():.4f}")
    print(f"æœ€å°è·ç¦»: {df['distance'].min():.4f}")
    print(f"æœ€å¤§è·ç¦»: {df['distance'].max():.4f}")
```

### 5.3 æ•°æ®å†™å…¥

**æ•°æ®å†™å…¥ç¤ºä¾‹**:

```python
# å‡†å¤‡æ•°æ®
df_new = pd.DataFrame({
    'query': ['PostgreSQL', 'pgvector', 'LangChain'],
    'result_count': [10, 15, 20],
    'avg_similarity': [0.85, 0.90, 0.88],
    'timestamp': pd.Timestamp.now()
})

# å†™å…¥æ•°æ®åº“
df_new.to_sql(
    'search_stats',
    engine,
    if_exists='append',  # è¿½åŠ æ¨¡å¼
    index=False
)

print(f"âœ… å†™å…¥ {len(df_new)} è¡Œæ•°æ®")
```

## 6. NumPy é›†æˆ

### 6.1 å‘é‡è®¡ç®—

**å‘é‡è®¡ç®—ç¤ºä¾‹**:

```python
import numpy as np
import psycopg2
from psycopg2.extras import execute_values

conn = psycopg2.connect(DATABASE_URL)
cur = conn.cursor()

# ä»æ•°æ®åº“è¯»å–å‘é‡
cur.execute("SELECT embedding FROM documents LIMIT 1000")
vectors = np.array([np.array(eval(row[0])) for row in cur.fetchall()])

# NumPy å‘é‡è¿ç®—
query_vector = np.random.rand(1536)

# ä½™å¼¦ç›¸ä¼¼åº¦
norms = np.linalg.norm(vectors, axis=1)
query_norm = np.linalg.norm(query_vector)
cosine_similarities = np.dot(vectors, query_vector) / (norms * query_norm)

# æ¬§æ°è·ç¦»
distances = np.linalg.norm(vectors - query_vector, axis=1)

# Top-K ç´¢å¼•
top_k_indices = np.argsort(distances)[:10]

print(f"Top 10 æœ€ç›¸ä¼¼çš„æ–‡æ¡£ç´¢å¼•: {top_k_indices}")
print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {cosine_similarities[top_k_indices]}")
```

### 6.2 æ‰¹é‡å¤„ç†

**æ‰¹é‡å‘é‡å¤„ç†**:

```python
# æ‰¹é‡æ›´æ–°å‘é‡
new_vectors = np.random.rand(100, 1536)

# å‡†å¤‡æ›´æ–°æ•°æ®
update_data = [
    (str(v.tolist()), i) for i, v in enumerate(new_vectors)
]

# æ‰¹é‡æ›´æ–°
execute_values(
    cur,
    "UPDATE documents SET embedding = %s::vector WHERE id = %s",
    update_data
)

conn.commit()
```

### 6.3 æ€§èƒ½ä¼˜åŒ–

**NumPy æ€§èƒ½ä¼˜åŒ–**:

```python
import time

# æ€§èƒ½å¯¹æ¯”æµ‹è¯•
def numpy_search(vectors, query_vector, top_k=10):
    """NumPy å‘é‡æœç´¢"""
    distances = np.linalg.norm(vectors - query_vector, axis=1)
    top_k_indices = np.argsort(distances)[:top_k]
    return top_k_indices

# æµ‹è¯•
vectors = np.random.rand(10000, 1536)
query_vector = np.random.rand(1536)

start = time.time()
results = numpy_search(vectors, query_vector)
end = time.time()

print(f"NumPy æœç´¢è€—æ—¶: {(end - start) * 1000:.2f} ms")
```

## 7. å…¶ä»–ç”Ÿæ€å·¥å…·

### 7.1 Django é›†æˆ

**Django é›†æˆç¤ºä¾‹**:

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'vector_db',
        'USER': 'postgres',
        'PASSWORD': 'postgres',
        'HOST': 'localhost',
        'PORT': '5432',
    }
}

# models.py
from django.db import models
from pgvector.django import VectorField

class Document(models.Model):
    content = models.TextField()
    embedding = VectorField(dimensions=1536)
    metadata = models.JSONField(default=dict)
    created_at = models.DateTimeField(auto_now_add=True)

# å‘é‡æŸ¥è¯¢
query_vector = [0.1] * 1536
results = Document.objects.order_by(
    'embedding__cosine_distance'
).filter(
    embedding__cosine_distance__lt=0.3
)[:10]
```

### 7.2 Flask é›†æˆ

**Flask é›†æˆç¤ºä¾‹**:

```python
from flask import Flask, request, jsonify
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings

app = Flask(__name__)

# åˆå§‹åŒ–å‘é‡å­˜å‚¨
vectorstore = PGVector(
    embeddings=OpenAIEmbeddings(),
    connection=os.getenv("POSTGRES_URL"),
    collection_name="documents"
)

@app.route('/api/search', methods=['POST'])
def search():
    data = request.json
    query = data.get('query')
    top_k = data.get('top_k', 5)

    results = vectorstore.similarity_search(query, k=top_k)

    return jsonify([
        {
            'content': doc.page_content,
            'metadata': doc.metadata
        }
        for doc in results
    ])

if __name__ == '__main__':
    app.run(debug=True)
```

### 7.3 Streamlit é›†æˆ

**Streamlit é›†æˆç¤ºä¾‹**:

```python
import streamlit as st
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings

st.title("å‘é‡æœç´¢åº”ç”¨")

# åˆå§‹åŒ–å‘é‡å­˜å‚¨
@st.cache_resource
def get_vectorstore():
    return PGVector(
        embeddings=OpenAIEmbeddings(),
        connection=os.getenv("POSTGRES_URL"),
        collection_name="documents"
    )

vectorstore = get_vectorstore()

# æœç´¢ç•Œé¢
query = st.text_input("è¾“å…¥æœç´¢æŸ¥è¯¢")
top_k = st.slider("è¿”å›ç»“æœæ•°é‡", 1, 20, 5)

if query:
    results = vectorstore.similarity_search(query, k=top_k)

    for i, doc in enumerate(results, 1):
        st.write(f"### ç»“æœ {i}")
        st.write(doc.page_content)
        if doc.metadata:
            st.write(f"å…ƒæ•°æ®: {doc.metadata}")
```

## 8. æœ€ä½³å®è·µ

### 8.1 è¿æ¥ç®¡ç†

**è¿æ¥æ± æœ€ä½³å®è·µ**:

```python
from psycopg2 import pool

# è¿æ¥æ± é…ç½®
connection_pool = psycopg2.pool.ThreadedConnectionPool(
    minconn=1,
    maxconn=20,
    host="localhost",
    port=5432,
    user="postgres",
    password="postgres",
    database="vector_db"
)

# ä½¿ç”¨è¿æ¥æ± 
def with_connection(func):
    """è¿æ¥è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        conn = connection_pool.getconn()
        try:
            return func(conn, *args, **kwargs)
        finally:
            connection_pool.putconn(conn)
    return wrapper

@with_connection
def search_documents(conn, query_vector, top_k=10):
    """ä½¿ç”¨è¿æ¥æ± çš„æœç´¢å‡½æ•°"""
    with conn.cursor() as cur:
        cur.execute("""
            SELECT * FROM documents
            ORDER BY embedding <=> %s::vector
            LIMIT %s
        """, (str(query_vector), top_k))
        return cur.fetchall()
```

### 8.2 æ€§èƒ½ä¼˜åŒ–

**æ€§èƒ½ä¼˜åŒ–å»ºè®®**:

1. **ä½¿ç”¨è¿æ¥æ± **: é¿å…é¢‘ç¹åˆ›å»ºå’Œå…³é—­è¿æ¥
2. **æ‰¹é‡æ“ä½œ**: ä½¿ç”¨æ‰¹é‡æ’å…¥å’Œæ‰¹é‡æŸ¥è¯¢
3. **ç´¢å¼•ä¼˜åŒ–**: ç¡®ä¿å‘é‡ç´¢å¼•å·²åˆ›å»º
4. **å¼‚æ­¥å¤„ç†**: å¯¹äºé«˜å¹¶å‘åœºæ™¯ï¼Œä½¿ç”¨ asyncpg

### 8.3 é”™è¯¯å¤„ç†

**é”™è¯¯å¤„ç†ç¤ºä¾‹**:

```python
import psycopg2
from psycopg2 import pool, OperationalError

def safe_query(func):
    """å®‰å…¨æŸ¥è¯¢è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except OperationalError as e:
            print(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
            return None
        except Exception as e:
            print(f"æŸ¥è¯¢é”™è¯¯: {e}")
            return None
    return wrapper

@safe_query
def search_documents_safe(query_vector, top_k=10):
    """å®‰å…¨çš„æ–‡æ¡£æœç´¢"""
    conn = connection_pool.getconn()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT * FROM documents
                ORDER BY embedding <=> %s::vector
                LIMIT %s
            """, (str(query_vector), top_k))
            return cur.fetchall()
    finally:
        connection_pool.putconn(conn)
```

## 9. å¸¸è§é—®é¢˜

### 9.1 ä¾èµ–é—®é¢˜

**å¸¸è§ä¾èµ–é—®é¢˜**:

1. **psycopg2 å®‰è£…å¤±è´¥**:

   ```bash
   # ä½¿ç”¨äºŒè¿›åˆ¶ç‰ˆæœ¬
   pip install psycopg2-binary
   ```

2. **pgvector æ‰©å±•æœªå®‰è£…**:

   ```sql
   CREATE EXTENSION IF NOT EXISTS vector;
   ```

### 9.2 è¿æ¥é—®é¢˜

**å¸¸è§è¿æ¥é—®é¢˜**:

1. **è¿æ¥è¶…æ—¶**: æ£€æŸ¥ç½‘ç»œå’Œé˜²ç«å¢™è®¾ç½®
2. **è®¤è¯å¤±è´¥**: æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç 
3. **æ•°æ®åº“ä¸å­˜åœ¨**: ç¡®ä¿æ•°æ®åº“å·²åˆ›å»º

### 9.3 æ€§èƒ½é—®é¢˜

**æ€§èƒ½é—®é¢˜æ’æŸ¥**:

1. **æŸ¥è¯¢æ…¢**: æ£€æŸ¥ç´¢å¼•æ˜¯å¦åˆ›å»º
2. **è¿æ¥æ± è€—å°½**: å¢åŠ è¿æ¥æ± å¤§å°æˆ–ä½¿ç”¨å¼‚æ­¥é©±åŠ¨
3. **å†…å­˜ä¸è¶³**: å‡å°‘æ‰¹é‡å¤§å°æˆ–ä½¿ç”¨æµå¼å¤„ç†

## 10. å‚è€ƒèµ„æ–™

### 10.1 å®˜æ–¹æ–‡æ¡£

- [psycopg2 æ–‡æ¡£](https://www.psycopg.org/docs/) - psycopg2 Documentation
- [SQLAlchemy æ–‡æ¡£](https://docs.sqlalchemy.org/) - SQLAlchemy Documentation
- [FastAPI æ–‡æ¡£](https://fastapi.tiangolo.com/) - FastAPI Documentation

### 10.2 æŠ€æœ¯æ–‡æ¡£

- [LangChain PostgreSQL](https://python.langchain.com/docs/integrations/vectorstores/pgvector) -
  LangChain PGVector Integration
- [pgvector æ ¸å¿ƒåŸç†](../../01-å‘é‡ä¸æ··åˆæœç´¢/æŠ€æœ¯åŸç†/pgvectoræ ¸å¿ƒåŸç†.md) - pgvector Core
  Principles

### 10.3 ç›¸å…³èµ„æº

- [asyncpg æ–‡æ¡£](https://magicstack.github.io/asyncpg/) - asyncpg Documentation
- [Pandas æ–‡æ¡£](https://pandas.pydata.org/docs/) - Pandas Documentation

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 07-02-01
