#!/usr/bin/env python3
"""
PostgreSQLæ™ºèƒ½VACUUMè°ƒåº¦å™¨
æ ¹æ®è¡¨ç»Ÿè®¡è‡ªåŠ¨å®‰æ’VACUUMæ“ä½œ
"""

import psycopg2
from psycopg2.extras import RealDictCursor
import argparse
from datetime import datetime
import time

class VacuumScheduler:
    """æ™ºèƒ½VACUUMè°ƒåº¦å™¨"""

    def __init__(self, conn_str: str, dry_run: bool = False):
        self.conn = psycopg2.connect(conn_str, cursor_factory=RealDictCursor)
        self.cursor = self.conn.cursor()
        self.dry_run = dry_run

    def analyze_tables(self):
        """åˆ†æéœ€è¦VACUUMçš„è¡¨"""

        print("åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯...")

        self.cursor.execute("""
            SELECT
                schemaname,
                tablename,
                n_live_tup,
                n_dead_tup,
                ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) AS dead_pct,
                last_vacuum,
                last_autovacuum,
                GREATEST(last_vacuum, last_autovacuum) AS last_vacuum_time,
                pg_size_pretty(pg_total_relation_size(schemaname || '.' || tablename)) AS table_size,
                pg_total_relation_size(schemaname || '.' || tablename) AS size_bytes
            FROM pg_stat_user_tables
            WHERE schemaname = 'public'
            ORDER BY n_dead_tup DESC;
        """)

        tables = self.cursor.fetchall()

        # åˆ†ç±»
        critical = []  # æ­»å…ƒç»„>20%
        high = []      # æ­»å…ƒç»„10-20%
        normal = []    # æ­»å…ƒç»„5-10%
        low = []       # æ­»å…ƒç»„<5%

        for table in tables:
            dead_pct = table['dead_pct'] or 0
            dead_count = table['n_dead_tup']

            if dead_pct > 20 or dead_count > 100000:
                critical.append(table)
            elif dead_pct > 10 or dead_count > 50000:
                high.append(table)
            elif dead_pct > 5 or dead_count > 10000:
                normal.append(table)
            else:
                low.append(table)

        return {
            'critical': critical,
            'high': high,
            'normal': normal,
            'low': low,
            'total': len(tables)
        }

    def vacuum_table(self, table: dict, mode: str = 'VACUUM'):
        """VACUUMå•ä¸ªè¡¨"""

        table_name = f"{table['schemaname']}.{table['tablename']}"

        if self.dry_run:
            print(f"[DRY-RUN] {mode} ANALYZE {table_name}")
            return

        start = datetime.now()

        try:
            if mode == 'VACUUM FULL':
                # VACUUM FULLä¼šé”è¡¨ï¼Œéœ€è¦è°¨æ…
                print(f"âš ï¸  {mode} {table_name}ï¼ˆä¼šé”è¡¨ï¼‰...")
                self.cursor.execute(f"{mode} ANALYZE {table_name};")
            else:
                print(f"æ­£åœ¨ {mode} {table_name}...")
                self.cursor.execute(f"{mode} ANALYZE {table_name};")

            self.conn.commit()

            duration = (datetime.now() - start).total_seconds()
            print(f"  âœ“ å®Œæˆï¼ˆè€—æ—¶: {duration:.2f}ç§’ï¼‰")

        except Exception as e:
            print(f"  âœ— å¤±è´¥: {e}")
            self.conn.rollback()

    def schedule_vacuum(self, analysis: dict):
        """è°ƒåº¦VACUUMæ“ä½œ"""

        print("\n" + "="*80)
        print("VACUUMè°ƒåº¦è®¡åˆ’")
        print("="*80)

        # ä¸¥é‡ä¼˜å…ˆçº§
        if analysis['critical']:
            print(f"\nğŸ”´ ä¸¥é‡ä¼˜å…ˆçº§ï¼ˆ{len(analysis['critical'])}ä¸ªè¡¨ï¼‰:")
            for table in analysis['critical']:
                print(f"  - {table['tablename']}: {table['dead_pct']:.1f}% æ­»å…ƒç»„, {table['table_size']}")

        # é«˜ä¼˜å…ˆçº§
        if analysis['high']:
            print(f"\nğŸŸ  é«˜ä¼˜å…ˆçº§ï¼ˆ{len(analysis['high'])}ä¸ªè¡¨ï¼‰:")
            for table in analysis['high']:
                print(f"  - {table['tablename']}: {table['dead_pct']:.1f}% æ­»å…ƒç»„, {table['table_size']}")

        # æ™®é€šä¼˜å…ˆçº§
        if analysis['normal']:
            print(f"\nğŸŸ¡ æ™®é€šä¼˜å…ˆçº§ï¼ˆ{len(analysis['normal'])}ä¸ªè¡¨ï¼‰:")
            for table in analysis['normal'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  - {table['tablename']}: {table['dead_pct']:.1f}% æ­»å…ƒç»„, {table['table_size']}")
            if len(analysis['normal']) > 5:
                print(f"  ... è¿˜æœ‰ {len(analysis['normal']) - 5} ä¸ªè¡¨")

        if not self.dry_run:
            print(f"\nå¼€å§‹æ‰§è¡ŒVACUUM...")
            print("="*80)

            # æ‰§è¡Œä¸¥é‡ä¼˜å…ˆçº§
            for table in analysis['critical']:
                self.vacuum_table(table, 'VACUUM')
                time.sleep(1)  # çŸ­æš‚ä¼‘æ¯

            # æ‰§è¡Œé«˜ä¼˜å…ˆçº§
            for table in analysis['high']:
                self.vacuum_table(table, 'VACUUM')
                time.sleep(1)

            # æ‰§è¡Œæ™®é€šä¼˜å…ˆçº§ï¼ˆå¯é€‰ï¼‰
            if len(analysis['normal']) <= 10:
                for table in analysis['normal']:
                    self.vacuum_table(table, 'VACUUM')
                    time.sleep(1)
            else:
                print(f"\nâ­ï¸  è·³è¿‡{len(analysis['normal'])}ä¸ªæ™®é€šä¼˜å…ˆçº§è¡¨ï¼ˆæ•°é‡è¿‡å¤šï¼‰")

        else:
            print(f"\n[DRY-RUNæ¨¡å¼] æœªæ‰§è¡Œå®é™…VACUUMæ“ä½œ")

    def generate_cron_jobs(self, analysis: dict):
        """ç”Ÿæˆcronä»»åŠ¡å»ºè®®"""

        print("\n" + "="*80)
        print("æ¨èçš„Cronä»»åŠ¡é…ç½®")
        print("="*80)

        print("\n# æ¯æ—¥å‡Œæ™¨3ç‚¹æ‰§è¡ŒVACUUMï¼ˆä½å³°æœŸï¼‰")
        print("0 3 * * * python3 /path/to/vacuum-scheduler.py --dbname mydb --auto")

        print("\n# æ¯å‘¨æ—¥æ‰§è¡Œæ›´æ·±åº¦çš„VACUUM")
        print("0 2 * * 0 python3 /path/to/vacuum-scheduler.py --dbname mydb --auto --deep")

        print("\n# æ¯æœˆç¬¬ä¸€å¤©æ‰§è¡ŒVACUUM FULLï¼ˆç»´æŠ¤çª—å£ï¼‰")
        print("0 1 1 * * python3 /path/to/vacuum-scheduler.py --dbname mydb --auto --full")

    def run(self, auto: bool = False, deep: bool = False, full: bool = False):
        """è¿è¡Œè°ƒåº¦å™¨"""

        print("="*80)
        print("PostgreSQLæ™ºèƒ½VACUUMè°ƒåº¦å™¨")
        print(f"æ—¶é—´: {datetime.now()}")
        print(f"æ¨¡å¼: {'è‡ªåŠ¨æ‰§è¡Œ' if auto else 'DRY-RUN'}")
        print("="*80)

        # åˆ†æ
        analysis = self.analyze_tables()

        print(f"\næ€»è¡¨æ•°: {analysis['total']}")
        print(f"  ä¸¥é‡: {len(analysis['critical'])}")
        print(f"  é«˜: {len(analysis['high'])}")
        print(f"  æ™®é€š: {len(analysis['normal'])}")
        print(f"  ä½: {len(analysis['low'])}")

        # è°ƒåº¦
        if auto:
            self.schedule_vacuum(analysis)
        else:
            self.schedule_vacuum(analysis)
            self.generate_cron_jobs(analysis)

    def close(self):
        self.cursor.close()
        self.conn.close()

def main():
    parser = argparse.ArgumentParser(description='PostgreSQLæ™ºèƒ½VACUUMè°ƒåº¦å™¨')
    parser.add_argument('--host', default='localhost')
    parser.add_argument('--port', type=int, default=5432)
    parser.add_argument('--dbname', required=True)
    parser.add_argument('--user', default='postgres')
    parser.add_argument('--password')
    parser.add_argument('--auto', action='store_true', help='è‡ªåŠ¨æ‰§è¡ŒVACUUM')
    parser.add_argument('--dry-run', action='store_true', help='ä»…æ˜¾ç¤ºè®¡åˆ’ï¼Œä¸æ‰§è¡Œ')
    parser.add_argument('--deep', action='store_true', help='æ·±åº¦VACUUM')
    parser.add_argument('--full', action='store_true', help='VACUUM FULLï¼ˆä¼šé”è¡¨ï¼‰')

    args = parser.parse_args()

    conn_str = f"host={args.host} port={args.port} dbname={args.dbname} user={args.user}"
    if args.password:
        conn_str += f" password={args.password}"

    try:
        scheduler = VacuumScheduler(conn_str, dry_run=args.dry_run or not args.auto)
        scheduler.run(auto=args.auto, deep=args.deep, full=args.full)
        scheduler.close()

    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == '__main__':
    main()
