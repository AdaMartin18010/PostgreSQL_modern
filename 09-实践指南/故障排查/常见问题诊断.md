# 9.3.1 常见问题诊断

> **更新时间**: 2025 年 11 月 1 日  
> **文档编号**: 09-03-01

## 📑 目录

- [9.3.1 常见问题诊断](#931-常见问题诊断)
  - [📑 目录](#-目录)
  - [1. 概述](#1-概述)
    - [1.1 文档目标](#11-文档目标)
    - [1.2 问题分类](#12-问题分类)
    - [1.3 诊断流程](#13-诊断流程)
  - [2. 性能问题](#2-性能问题)
    - [2.1 向量查询性能慢](#21-向量查询性能慢)
      - [2.1.1 症状描述](#211-症状描述)
      - [2.1.2 诊断步骤](#212-诊断步骤)
      - [2.1.3 解决方案](#213-解决方案)
      - [2.1.4 性能优化](#214-性能优化)
    - [2.2 索引构建失败](#22-索引构建失败)
      - [2.2.1 症状描述](#221-症状描述)
      - [2.2.2 诊断步骤](#222-诊断步骤)
      - [2.2.3 解决方案](#223-解决方案)
  - [3. 资源问题](#3-资源问题)
    - [3.1 内存不足](#31-内存不足)
      - [3.1.1 症状描述](#311-症状描述)
      - [3.1.2 诊断步骤](#312-诊断步骤)
      - [3.1.3 解决方案](#313-解决方案)
    - [3.2 连接数超限](#32-连接数超限)
      - [3.2.1 症状描述](#321-症状描述)
      - [3.2.2 诊断步骤](#322-诊断步骤)
      - [3.2.3 解决方案](#323-解决方案)
  - [4. 数据问题](#4-数据问题)
    - [4.1 查询结果不准确](#41-查询结果不准确)
      - [4.1.1 症状描述](#411-症状描述)
      - [4.1.2 诊断步骤](#412-诊断步骤)
      - [4.1.3 解决方案](#413-解决方案)
    - [4.2 数据不一致](#42-数据不一致)
      - [4.2.1 症状描述](#421-症状描述)
      - [4.2.2 诊断步骤](#422-诊断步骤)
      - [4.2.3 解决方案](#423-解决方案)
  - [5. 扩展问题](#5-扩展问题)
    - [5.1 pgvector 扩展问题](#51-pgvector-扩展问题)
    - [5.2 TimescaleDB 扩展问题](#52-timescaledb-扩展问题)
  - [6. 诊断工具](#6-诊断工具)
    - [6.1 性能诊断脚本](#61-性能诊断脚本)
    - [6.2 监控查询](#62-监控查询)
    - [6.3 自动化诊断](#63-自动化诊断)
  - [7. 最佳实践](#7-最佳实践)
    - [7.1 预防措施](#71-预防措施)
    - [7.2 故障响应](#72-故障响应)
  - [8. 参考资料](#8-参考资料)
    - [8.1 官方文档](#81-官方文档)
    - [8.2 技术文档](#82-技术文档)
    - [8.3 相关资源](#83-相关资源)

---

## 1. 概述

### 1.1 文档目标

**核心目标**:

本文档提供 PostgreSQL + pgvector 常见问题的诊断和解决方案，帮助您快速定位和解决问题。

**文档价值**:

| 价值项       | 说明               | 影响         |
| ------------ | ------------------ | ------------ |
| **快速诊断** | 提供系统化诊断流程 | 减少故障时间 |
| **解决方案** | 提供多种解决方案   | 提高解决效率 |
| **预防措施** | 提供预防建议       | 减少故障发生 |

### 1.2 问题分类

**问题分类**:

1. **性能问题**:

   - 向量查询性能慢
   - 索引构建失败
   - 查询超时

2. **资源问题**:

   - 内存不足
   - 连接数超限
   - 磁盘空间不足

3. **数据问题**:

   - 查询结果不准确
   - 数据不一致
   - 数据损坏

4. **扩展问题**:
   - pgvector 扩展问题
   - TimescaleDB 扩展问题
   - 其他扩展问题

**问题优先级**:

| 优先级        | 问题类型     | 响应时间     |
| ------------- | ------------ | ------------ |
| **P0 - 紧急** | 服务不可用   | **<15 分钟** |
| **P1 - 高**   | 性能严重下降 | **<1 小时**  |
| **P2 - 中**   | 功能异常     | **<4 小时**  |
| **P3 - 低**   | 优化建议     | **<24 小时** |

### 1.3 诊断流程

**诊断流程**:

```text
问题报告
    ↓
1. 问题分类（性能/资源/数据/扩展）
    ↓
2. 症状识别（错误信息、性能指标）
    ↓
3. 诊断步骤（执行诊断查询）
    ↓
4. 问题定位（确定根本原因）
    ↓
5. 解决方案（选择合适方案）
    ↓
6. 验证修复（确认问题解决）
    ↓
7. 预防措施（避免再次发生）
```

## 2. 性能问题

### 2.1 向量查询性能慢

#### 2.1.1 症状描述

**常见症状**:

1. **查询延迟高**:

   - 向量查询延迟 >100ms
   - 用户反馈查询慢
   - 系统响应时间长

2. **性能指标异常**:
   - QPS 下降
   - CPU 使用率升高
   - 缓存命中率下降

**性能基准**:

| 数据量     | 正常延迟  | 警告延迟     | 严重延迟   |
| ---------- | --------- | ------------ | ---------- |
| **1 万**   | **<5ms**  | **5-10ms**   | **>10ms**  |
| **10 万**  | **<10ms** | **10-20ms**  | **>20ms**  |
| **100 万** | **<50ms** | **50-100ms** | **>100ms** |

#### 2.1.2 诊断步骤

**诊断步骤详解**:

```sql
-- 步骤 1: 检查索引是否存在
SELECT
    indexname,
    indexdef,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_indexes
WHERE tablename = 'documents'
  AND indexdef LIKE '%vector%';

-- 预期结果：应该至少有一个向量索引
-- 如果为空，说明缺少索引

-- 步骤 2: 检查索引使用情况
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan as scan_count,
    idx_tup_read as tuples_read,
    idx_tup_fetch as tuples_fetched,
    CASE
        WHEN idx_scan = 0 THEN '未使用'
        WHEN idx_scan < 10 THEN '低使用'
        WHEN idx_scan < 100 THEN '中使用'
        ELSE '高使用'
    END as usage_status
FROM pg_stat_user_indexes
WHERE tablename = 'documents'
  AND indexdef LIKE '%vector%';

-- 步骤 3: 检查查询计划
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT
    id,
    content,
    1 - (embedding <=> '[0.1, 0.2, ...]'::vector(1536)) as similarity
FROM documents
ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector(1536)
LIMIT 10;

-- 关键指标：
-- - 是否使用索引（应该显示 Index Scan using ...）
-- - 执行时间（Execution Time）
-- - 缓存命中率（Buffers: shared hit）
```

**诊断指标说明**:

| 指标             | 正常值    | 警告值  | 严重值    |
| ---------------- | --------- | ------- | --------- |
| **索引扫描次数** | **>100**  | 10-100  | **<10**   |
| **查询延迟**     | **<10ms** | 10-50ms | **>50ms** |
| **缓存命中率**   | **>90%**  | 80-90%  | **<80%**  |

#### 2.1.3 解决方案

**解决方案详解**:

```sql
-- 方案 1: 创建 HNSW 索引（高精度场景，<100 万数据）
CREATE INDEX documents_embedding_hnsw_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 16,              -- 每层最大连接数
    ef_construction = 64  -- 构建时搜索范围
);

-- 查询时调整搜索范围
SET hnsw.ef_search = 40;  -- 提高召回率，可能降低速度

-- 方案 2: 使用 IVFFlat（大规模场景，>100 万数据）
CREATE INDEX documents_embedding_ivfflat_idx ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (
    lists = 1000  -- 聚类数量，建议 = rows/1000
);

-- 查询时调整搜索聚类数
SET ivfflat.probes = 10;  -- 搜索的聚类数量

-- 方案 3: 优化现有索引参数
-- 如果索引已存在但性能不佳，可以重建索引

-- 先删除旧索引
DROP INDEX IF EXISTS documents_embedding_idx;

-- 重建索引（使用更优参数）
CREATE INDEX documents_embedding_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 32,              -- 提高精度
    ef_construction = 200  -- 提高构建质量
);

-- 方案 4: 分区表优化
-- 对于超大规模数据，使用分区表

CREATE TABLE documents (
    id SERIAL,
    content TEXT,
    embedding vector(1536),
    created_at TIMESTAMPTZ DEFAULT NOW()
) PARTITION BY RANGE (created_at);

CREATE TABLE documents_recent PARTITION OF documents
FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');

CREATE TABLE documents_archive PARTITION OF documents
FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

-- 为每个分区创建索引
CREATE INDEX ON documents_recent
USING hnsw (embedding vector_cosine_ops);

CREATE INDEX ON documents_archive
USING ivfflat (embedding vector_cosine_ops);
```

**方案选择建议**:

| 场景                    | 推荐方案       | 理由             |
| ----------------------- | -------------- | ---------------- |
| **<100 万数据，高精度** | HNSW (m=32)    | 精度和速度都优秀 |
| **<100 万数据，高性能** | HNSW (m=16)    | 平衡性能和精度   |
| **>100 万数据**         | IVFFlat        | 适合大规模数据   |
| **>1000 万数据**        | 分区 + IVFFlat | 超大规模优化     |

#### 2.1.4 性能优化

**性能优化技巧**:

```sql
-- 1. 调整查询时参数
SET hnsw.ef_search = 40;  -- HNSW 搜索范围（默认 40）

-- 2. 调整 IVFFlat 探测数
SET ivfflat.probes = 10;  -- IVFFlat 搜索聚类数（默认 1）

-- 3. 使用批量查询（减少数据库往返）
WITH queries AS (
    SELECT query_vector1::vector as vec, 1 as query_id UNION ALL
    SELECT query_vector2::vector, 2
)
SELECT
    q.query_id,
    d.*,
    d.embedding <=> q.vec as distance
FROM queries q
CROSS JOIN LATERAL (
    SELECT * FROM documents
    ORDER BY embedding <=> q.vec
    LIMIT 10
) d
ORDER BY q.query_id, distance;

-- 4. 使用连接池（提高并发性能）
-- 配置 PgBouncer 或其他连接池工具
```

### 2.2 索引构建失败

#### 2.2.1 症状描述

**常见错误**:

1. **索引行大小超限**:

   ```text
   ERROR: index row size exceeds maximum
   DETAIL: Maximum size is 2712, but index row size is 3072
   ```

2. **内存不足**:

   ```text
   ERROR: out of memory
   DETAIL: Failed on request of size 4294967296
   ```

3. **构建超时**:

   ```text
   ERROR: canceling statement due to statement timeout
   ```

**常见原因**:

| 原因             | 说明     | 影响           |
| ---------------- | -------- | -------------- |
| **向量维度过高** | >1536 维 | 索引行大小超限 |
| **数据量过大**   | >1 亿    | 内存不足       |
| **索引参数过大** | m > 64   | 内存占用过大   |

#### 2.2.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查向量维度
SELECT
    table_name,
    column_name,
    data_type,
    udt_name
FROM information_schema.columns
WHERE table_name = 'documents'
  AND column_name = 'embedding';

-- 步骤 2: 检查数据分布
SELECT
    COUNT(*) as total_rows,
    COUNT(DISTINCT embedding) as unique_vectors,
    pg_size_pretty(pg_total_relation_size('documents')) as table_size
FROM documents;

-- 步骤 3: 检查内存配置
SELECT
    name,
    setting,
    unit,
    context
FROM pg_settings
WHERE name IN (
    'shared_buffers',
    'work_mem',
    'maintenance_work_mem',
    'max_connections'
);

-- 步骤 4: 测试索引创建（小数据集）
CREATE TABLE test_documents (
    id SERIAL PRIMARY KEY,
    embedding vector(1536)
);

INSERT INTO test_documents (embedding)
SELECT (SELECT array_agg(random())::vector(1536)
        FROM generate_series(1, 1536))
FROM generate_series(1, 1000);

-- 尝试创建索引
CREATE INDEX test_documents_idx ON test_documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 如果成功，说明配置没问题，问题在数据规模或维度
```

#### 2.2.3 解决方案

**解决方案详解**:

```sql
-- 方案 1: 降维（推荐）
-- 使用 PCA 或其他降维技术，从 3072 维降到 768 维
-- Python 示例：
-- from sklearn.decomposition import PCA
-- pca = PCA(n_components=768)
-- embeddings_768d = pca.fit_transform(embeddings_3072d)

-- 更新表结构
ALTER TABLE documents ALTER COLUMN embedding TYPE vector(768);

-- 方案 2: 使用 IVFFlat（适合高维）
CREATE INDEX documents_embedding_idx ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (
    lists = 1000  -- 根据数据量调整
);

-- 方案 3: 减小 HNSW 参数
CREATE INDEX documents_embedding_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 8,               -- 减小 m 值（默认 16）
    ef_construction = 32  -- 减小 ef_construction（默认 64）
);

-- 方案 4: 分区表 + 分区索引
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding vector(1536)
) PARTITION BY RANGE (id);

CREATE TABLE documents_p1 PARTITION OF documents
FOR VALUES FROM (1) TO (1000000);

CREATE TABLE documents_p2 PARTITION OF documents
FOR VALUES FROM (1000000) TO (2000000);

-- 为每个分区创建索引
CREATE INDEX ON documents_p1
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

CREATE INDEX ON documents_p2
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 方案 5: 增加内存配置
ALTER SYSTEM SET shared_buffers = '8GB';
ALTER SYSTEM SET maintenance_work_mem = '2GB';
SELECT pg_reload_conf();
```

**方案选择矩阵**:

| 向量维度  | 数据量       | 推荐方案       | 说明         |
| --------- | ------------ | -------------- | ------------ |
| **<768**  | **<100 万**  | HNSW (m=16)    | 标准配置     |
| **<1536** | **<1000 万** | IVFFlat        | 适合中大规模 |
| **>1536** | **<100 万**  | 降维 + HNSW    | 必须降维     |
| **>1536** | **>100 万**  | 降维 + IVFFlat | 必须降维     |

## 3. 资源问题

### 3.1 内存不足

#### 3.1.1 症状描述

**常见症状**:

1. **错误信息**:

   ```text
   ERROR: out of memory
   DETAIL: Failed on request of size 4294967296
   ERROR: could not allocate memory for query
   ```

2. **性能下降**:
   - 查询超时
   - 索引构建失败
   - 系统响应缓慢

**内存使用分析**:

| 操作              | 内存需求            | 说明         |
| ----------------- | ------------------- | ------------ |
| **HNSW 索引构建** | 数据大小 × 2-3 倍   | 需要较大内存 |
| **向量查询**      | 查询数量 × 向量大小 | 相对较小     |
| **批量插入**      | 批次大小 × 向量大小 | 可调整       |

#### 3.1.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查内存配置
SELECT
    name,
    setting,
    unit,
    context,
    CASE
        WHEN name = 'shared_buffers' AND setting::INTEGER < 1024 THEN '警告：内存配置过低'
        WHEN name = 'work_mem' AND setting::INTEGER < 64 THEN '警告：工作内存不足'
        ELSE '正常'
    END as status
FROM pg_settings
WHERE name IN (
    'shared_buffers',
    'work_mem',
    'maintenance_work_mem',
    'effective_cache_size',
    'max_connections'
);

-- 步骤 2: 检查当前内存使用
SELECT
    pid,
    usename,
    datname,
    application_name,
    state,
    query_start,
    state_change,
    wait_event_type,
    wait_event
FROM pg_stat_activity
WHERE state = 'active'
ORDER BY query_start;

-- 步骤 3: 检查索引大小
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as table_size
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC
LIMIT 10;

-- 步骤 4: 检查连接数和内存计算
SELECT
    setting::INTEGER as max_connections,
    (SELECT COUNT(*) FROM pg_stat_activity) as current_connections,
    (SELECT setting FROM pg_settings WHERE name = 'work_mem')::INTEGER as work_mem_mb,
    (SELECT setting::INTEGER FROM pg_settings WHERE name = 'max_connections') *
    (SELECT setting::INTEGER FROM pg_settings WHERE name = 'work_mem') as max_work_mem_mb
FROM pg_settings
WHERE name = 'max_connections';
```

#### 3.1.3 解决方案

**解决方案详解**:

```sql
-- 方案 1: 增加内存配置（推荐）
-- 编辑 postgresql.conf 或使用 ALTER SYSTEM

ALTER SYSTEM SET shared_buffers = '4GB';  -- 总内存的 25%
ALTER SYSTEM SET work_mem = '256MB';  -- 根据 max_connections 调整
ALTER SYSTEM SET maintenance_work_mem = '1GB';  -- 索引构建和 VACUUM
ALTER SYSTEM SET effective_cache_size = '12GB';  -- 总内存的 50-75%

-- 重新加载配置
SELECT pg_reload_conf();

-- 注意：某些参数需要重启 PostgreSQL
SELECT pg_reload_conf();  -- 部分参数可热重载
-- systemctl restart postgresql  -- 某些参数需重启

-- 方案 2: 使用 IVFFlat（内存占用小）
-- IVFFlat 索引内存占用约为 HNSW 的 1/3

DROP INDEX IF EXISTS documents_embedding_idx;
CREATE INDEX documents_embedding_idx ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 1000);

-- 方案 3: 减小 HNSW 索引参数
DROP INDEX IF EXISTS documents_embedding_idx;
CREATE INDEX documents_embedding_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 8,               -- 减小 m（默认 16）
    ef_construction = 32  -- 减小 ef_construction（默认 64）
);

-- 方案 4: 分批构建索引
-- 对于超大规模数据，分批处理

-- 创建临时表
CREATE TABLE documents_temp AS
SELECT * FROM documents
WHERE id % 10 = 0;  -- 每次处理 10% 数据

-- 为临时表创建索引
CREATE INDEX documents_temp_idx ON documents_temp
USING hnsw (embedding vector_cosine_ops);

-- 方案 5: 减少并发连接数
ALTER SYSTEM SET max_connections = 100;  -- 减少最大连接数
SELECT pg_reload_conf();

-- 或使用连接池（PgBouncer）限制连接数
```

**内存配置建议**:

| 总内存   | shared_buffers | work_mem | maintenance_work_mem | effective_cache_size |
| -------- | -------------- | -------- | -------------------- | -------------------- |
| **8GB**  | 2GB            | 64MB     | 512MB                | 6GB                  |
| **16GB** | 4GB            | 128MB    | 1GB                  | 12GB                 |
| **32GB** | 8GB            | 256MB    | 2GB                  | 24GB                 |

### 3.2 连接数超限

#### 3.2.1 症状描述

**常见错误**:

```text
ERROR: remaining connection slots are reserved
FATAL: too many connections
ERROR: new connection rejected because system limit exceeded
```

**常见原因**:

| 原因         | 说明                     | 影响           |
| ------------ | ------------------------ | -------------- |
| **连接泄漏** | 应用未正确关闭连接       | 连接数持续增长 |
| **并发过高** | 实际并发超过配置         | 连接数耗尽     |
| **配置过低** | max_connections 设置过小 | 无法满足需求   |

#### 3.2.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查最大连接数配置
SHOW max_connections;

-- 步骤 2: 检查当前连接数
SELECT
    COUNT(*) as total_connections,
    COUNT(*) FILTER (WHERE state = 'active') as active_connections,
    COUNT(*) FILTER (WHERE state = 'idle') as idle_connections,
    COUNT(*) FILTER (WHERE state = 'idle in transaction') as idle_in_transaction
FROM pg_stat_activity;

-- 步骤 3: 检查连接详情
SELECT
    datname,
    usename,
    application_name,
    state,
    state_change,
    wait_event_type,
    wait_event,
    query_start,
    LEFT(query, 100) as query_preview
FROM pg_stat_activity
WHERE datname = 'vector_db'
ORDER BY state_change DESC;

-- 步骤 4: 检查长时间空闲的连接
SELECT
    pid,
    usename,
    application_name,
    state,
    state_change,
    NOW() - state_change as idle_duration
FROM pg_stat_activity
WHERE state = 'idle'
  AND state_change < NOW() - INTERVAL '10 minutes'
ORDER BY state_change;

-- 步骤 5: 检查连接数趋势（需要监控工具）
-- 可以使用 pg_stat_statements 或监控系统
```

#### 3.2.3 解决方案

**解决方案详解**:

```sql
-- 方案 1: 增加最大连接数
ALTER SYSTEM SET max_connections = 200;
SELECT pg_reload_conf();

-- 注意：max_connections 需要重启 PostgreSQL
-- systemctl restart postgresql

-- 方案 2: 清理空闲连接
-- 清理长时间空闲的连接
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE datname = 'vector_db'
  AND state = 'idle'
  AND state_change < NOW() - INTERVAL '10 minutes';

-- 方案 3: 使用连接池（PgBouncer）（强烈推荐）
-- 配置 PgBouncer，减少数据库连接数

-- PgBouncer 配置示例（pgbouncer.ini）
-- [databases]
-- vector_db = host=localhost port=5432 dbname=vector_db
--
-- [pgbouncer]
-- pool_mode = transaction
-- max_client_conn = 1000
-- default_pool_size = 25
-- reserve_pool_size = 5

-- 方案 4: 优化应用连接管理
-- 使用连接池，及时释放连接
-- Python 示例：
-- from psycopg2 import pool
-- connection_pool = pool.SimpleConnectionPool(5, 20, ...)

-- 方案 5: 监控和告警
-- 设置连接数监控和告警
-- 当连接数 > 80% max_connections 时告警
```

**连接数配置建议**:

| 场景         | max_connections | 连接池   | 说明       |
| ------------ | --------------- | -------- | ---------- |
| **小型应用** | 50              | 不需要   | 低并发     |
| **中型应用** | 100             | 推荐     | 中等并发   |
| **大型应用** | 200             | **必需** | **高并发** |

## 4. 数据问题

### 4.1 查询结果不准确

#### 4.1.1 症状描述

**常见症状**:

1. **召回率低**:

   - 查询结果不相关
   - 相关文档未被检索到
   - 结果顺序不合理

2. **相似度异常**:
   - 相似度分数异常
   - 排序不正确

**准确率基准**:

| 索引类型                 | 召回率    | 说明         |
| ------------------------ | --------- | ------------ |
| **HNSW (ef_search=40)**  | **98%**   | 接近精确搜索 |
| **HNSW (ef_search=100)** | **99.5%** | 高精度       |
| **IVFFlat (probes=10)**  | **95%**   | 中等精度     |
| **IVFFlat (probes=50)**  | **98%**   | 高精度       |

#### 4.1.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查索引参数
SELECT
    indexname,
    indexdef
FROM pg_indexes
WHERE tablename = 'documents'
  AND indexname LIKE '%embedding%';

-- 步骤 2: 检查查询时参数
SHOW hnsw.ef_search;
SHOW ivfflat.probes;

-- 步骤 3: 对比索引查询和精确查询
-- 使用索引（近似搜索）
SET hnsw.ef_search = 40;
EXPLAIN ANALYZE
SELECT
    id,
    content,
    1 - (embedding <=> query_vector::vector) as similarity
FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 10;

-- 禁用索引（精确搜索）
SET enable_indexscan = off;
EXPLAIN ANALYZE
SELECT
    id,
    content,
    1 - (embedding <=> query_vector::vector) as similarity
FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 10;

-- 对比结果，计算召回率

-- 步骤 4: 检查向量数据质量
SELECT
    COUNT(*) as total_vectors,
    COUNT(DISTINCT embedding) as unique_vectors,
    COUNT(*) FILTER (WHERE embedding IS NULL) as null_vectors
FROM documents;
```

#### 4.1.3 解决方案

**解决方案详解**:

```sql
-- 方案 1: 提高 HNSW 搜索精度
SET hnsw.ef_search = 100;  -- 增加搜索范围（默认 40）

-- 注意：ef_search 越大，精度越高，但速度越慢

-- 方案 2: 提高 IVFFlat 搜索聚类数
SET ivfflat.probes = 50;  -- 增加搜索聚类数（默认 1）

-- 注意：probes 越大，精度越高，但速度越慢

-- 方案 3: 重建索引（提高构建精度）
DROP INDEX documents_embedding_idx;
CREATE INDEX documents_embedding_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 32,              -- 提高 m 值（默认 16）
    ef_construction = 200  -- 提高 ef_construction（默认 64）
);

-- 方案 4: 使用精确搜索（小数据集）
-- 如果数据量不大，可以直接使用精确搜索
SET enable_indexscan = off;

SELECT
    id,
    content,
    1 - (embedding <=> query_vector::vector) as similarity
FROM documents
ORDER BY embedding <=> query_vector::vector
LIMIT 10;

-- 方案 5: 验证向量数据质量
-- 检查向量是否归一化
SELECT
    AVG(array_length(embedding::text::numeric[], 1)) as avg_dimensions,
    MIN(array_length(embedding::text::numeric[], 1)) as min_dimensions,
    MAX(array_length(embedding::text::numeric[], 1)) as max_dimensions
FROM documents
LIMIT 1000;
```

**精度优化建议**:

| 场景           | 推荐配置             | 召回率    | 查询延迟 |
| -------------- | -------------------- | --------- | -------- |
| **高精度需求** | HNSW (ef_search=100) | **99.5%** | ~20ms    |
| **平衡需求**   | HNSW (ef_search=40)  | **98%**   | ~10ms    |
| **高性能需求** | HNSW (ef_search=20)  | **95%**   | ~5ms     |

### 4.2 数据不一致

#### 4.2.1 症状描述

**常见症状**:

1. **统计信息不一致**:

   - `COUNT(*)` 结果异常
   - 索引统计信息过期
   - 查询结果数量不匹配

2. **数据不一致**:
   - 死元组过多
   - 索引与实际数据不符
   - 查询结果重复

**常见原因**:

| 原因                | 说明               | 影响         |
| ------------------- | ------------------ | ------------ |
| **长时间未 VACUUM** | 死元组积累         | 查询性能下降 |
| **统计信息过期**    | 长时间未 ANALYZE   | 查询计划不优 |
| **索引损坏**        | 索引与实际数据不符 | 查询结果错误 |

#### 4.2.2 诊断步骤

**诊断步骤**:

```sql
-- 步骤 1: 检查表统计信息
SELECT
    schemaname,
    tablename,
    n_live_tup as live_tuples,
    n_dead_tup as dead_tuples,
    (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) * 100 as dead_tuple_ratio,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze,
    vacuum_count,
    autovacuum_count,
    analyze_count,
    autoanalyze_count
FROM pg_stat_user_tables
WHERE tablename = 'documents';

-- 步骤 2: 检查死元组比例
SELECT
    schemaname,
    tablename,
    n_live_tup,
    n_dead_tup,
    (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) * 100 as dead_ratio,
    CASE
        WHEN (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) > 0.2 THEN '紧急 VACUUM'
        WHEN (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) > 0.1 THEN '建议 VACUUM'
        ELSE '正常'
    END as recommendation
FROM pg_stat_user_tables
WHERE tablename = 'documents';

-- 步骤 3: 检查索引健康度
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_stat_user_indexes
WHERE tablename = 'documents';

-- 步骤 4: 对比实际数据和统计信息
SELECT
    COUNT(*) as actual_count
FROM documents;

-- 对比 pg_stat_user_tables 中的 n_live_tup
```

#### 4.2.3 解决方案

**解决方案详解**:

```sql
-- 方案 1: 执行 VACUUM ANALYZE（推荐）
VACUUM ANALYZE documents;

-- VACUUM: 清理死元组，回收空间
-- ANALYZE: 更新统计信息，优化查询计划

-- 方案 2: 并发 VACUUM（不锁表）
VACUUM ANALYZE documents;

-- PostgreSQL 13+ 支持 VACUUM ANALYZE 的并发版本
-- 不会阻塞查询

-- 方案 3: 重建索引
REINDEX INDEX CONCURRENTLY documents_embedding_idx;

-- CONCURRENTLY: 在线重建，不阻塞查询
-- 适用于索引损坏或统计信息异常

-- 方案 4: 更新统计信息
ANALYZE documents;

-- 仅更新统计信息，不清理死元组
-- 执行速度快，适合频繁执行

-- 方案 5: 配置自动 VACUUM
ALTER TABLE documents SET (
    autovacuum_vacuum_scale_factor = 0.1,  -- 死元组 >10% 时触发
    autovacuum_analyze_scale_factor = 0.05,  -- 变更 >5% 时触发
    autovacuum_vacuum_cost_delay = 10,  -- 延迟 10ms（减少 I/O 影响）
    autovacuum_vacuum_cost_limit = 200  -- 每次处理成本限制
);

-- 全局配置（postgresql.conf）
autovacuum = on
autovacuum_max_workers = 3
autovacuum_naptime = 1min
```

**VACUUM 策略建议**:

| 死元组比例 | 操作            | 频率             |
| ---------- | --------------- | ---------------- |
| **>20%**   | **紧急 VACUUM** | 立即执行         |
| **>10%**   | **建议 VACUUM** | 尽快执行         |
| **<10%**   | **正常**        | 自动 VACUUM 处理 |

## 5. 扩展问题

### 5.1 pgvector 扩展问题

**常见问题**:

```sql
-- 问题 1: 扩展未找到
ERROR: extension "vector" does not exist

-- 解决方案：
-- 1. 检查扩展是否安装
SELECT * FROM pg_available_extensions WHERE name = 'vector';

-- 2. 如果没有，需要安装 pgvector
-- Ubuntu/Debian:
-- sudo apt-get install postgresql-18-pgvector
-- 或从源码安装

-- 问题 2: 版本不兼容
ERROR: incompatible extension version

-- 解决方案：
-- 1. 检查 PostgreSQL 版本
SELECT version();

-- 2. 检查 pgvector 版本
SELECT extversion FROM pg_extension WHERE extname = 'vector';

-- 3. 升级 pgvector 到兼容版本

-- 问题 3: 向量维度不匹配
ERROR: operator does not exist: vector(768) <=> vector(1536)

-- 解决方案：
-- 确保所有向量使用相同维度
ALTER TABLE documents ALTER COLUMN embedding TYPE vector(1536);
```

### 5.2 TimescaleDB 扩展问题

**常见问题**:

```sql
-- 问题 1: TimescaleDB 扩展未加载
ERROR: could not access file "$libdir/timescaledb-2.11"

-- 解决方案：
-- 1. 检查 TimescaleDB 是否安装
SELECT * FROM pg_available_extensions WHERE name = 'timescaledb';

-- 2. 重新配置 TimescaleDB
-- sudo timescaledb-tune --quiet --yes
-- sudo systemctl restart postgresql

-- 问题 2: 超表创建失败
ERROR: hypertable does not exist

-- 解决方案：
-- 确保表存在且符合超表要求
SELECT create_hypertable('table_name', 'time_column');
```

## 6. 诊断工具

### 6.1 性能诊断脚本

**性能诊断函数**:

```sql
-- 创建综合诊断函数
CREATE OR REPLACE FUNCTION diagnose_vector_performance(
    p_table_name TEXT DEFAULT 'documents'
)
RETURNS TABLE (
    check_item TEXT,
    status TEXT,
    details TEXT,
    recommendation TEXT
) AS $$
BEGIN
    -- 1. 检查索引
    RETURN QUERY
    SELECT
        '索引检查'::TEXT,
        CASE WHEN COUNT(*) > 0 THEN '正常' ELSE '缺失' END,
        COALESCE(STRING_AGG(indexname, ', '), '无向量索引'),
        CASE
            WHEN COUNT(*) = 0 THEN '创建 HNSW 或 IVFFlat 索引'
            ELSE '索引存在，检查参数'
        END
    FROM pg_indexes
    WHERE tablename = p_table_name
      AND indexdef LIKE '%vector%';

    -- 2. 检查统计信息
    RETURN QUERY
    SELECT
        '统计信息'::TEXT,
        CASE
            WHEN last_autovacuum > NOW() - INTERVAL '7 days' THEN '正常'
            WHEN last_autovacuum > NOW() - INTERVAL '30 days' THEN '需要更新'
            ELSE '严重过期'
        END,
        COALESCE(last_autovacuum::TEXT, '从未执行'),
        CASE
            WHEN last_autovacuum IS NULL OR last_autovacuum < NOW() - INTERVAL '7 days'
            THEN '执行 VACUUM ANALYZE ' || p_table_name
            ELSE '统计信息正常'
        END
    FROM pg_stat_user_tables
    WHERE tablename = p_table_name;

    -- 3. 检查内存配置
    RETURN QUERY
    SELECT
        '内存配置'::TEXT,
        CASE
            WHEN setting::INTEGER >= 4096 THEN '充足'
            WHEN setting::INTEGER >= 2048 THEN '一般'
            ELSE '不足'
        END,
        setting || ' ' || unit,
        CASE
            WHEN setting::INTEGER < 2048 THEN '建议增加 shared_buffers 到 4GB+'
            ELSE '内存配置正常'
        END
    FROM pg_settings
    WHERE name = 'shared_buffers';

    -- 4. 检查连接数
    RETURN QUERY
    SELECT
        '连接数检查'::TEXT,
        CASE
            WHEN (SELECT COUNT(*) FROM pg_stat_activity)::NUMERIC /
                 (SELECT setting::NUMERIC FROM pg_settings WHERE name = 'max_connections') > 0.8
            THEN '警告'
            ELSE '正常'
        END,
        (SELECT COUNT(*) FROM pg_stat_activity)::TEXT || ' / ' ||
        (SELECT setting FROM pg_settings WHERE name = 'max_connections'),
        CASE
            WHEN (SELECT COUNT(*) FROM pg_stat_activity)::NUMERIC /
                 (SELECT setting::NUMERIC FROM pg_settings WHERE name = 'max_connections') > 0.8
            THEN '考虑使用连接池或增加 max_connections'
            ELSE '连接数正常'
        END
    FROM pg_settings
    WHERE name = 'max_connections'
    LIMIT 1;

    -- 5. 检查死元组
    RETURN QUERY
    SELECT
        '死元组检查'::TEXT,
        CASE
            WHEN (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) > 0.2 THEN '严重'
            WHEN (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) > 0.1 THEN '警告'
            ELSE '正常'
        END,
        n_dead_tup::TEXT || ' / ' || (n_live_tup + n_dead_tup)::TEXT ||
        ' (' || ROUND((n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) * 100, 2) || '%)',
        CASE
            WHEN (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) > 0.2
            THEN '紧急执行 VACUUM ANALYZE ' || p_table_name
            WHEN (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) > 0.1
            THEN '建议执行 VACUUM ANALYZE ' || p_table_name
            ELSE '死元组比例正常'
        END
    FROM pg_stat_user_tables
    WHERE tablename = p_table_name;
END;
$$ LANGUAGE plpgsql;

-- 使用诊断函数
SELECT * FROM diagnose_vector_performance('documents');
```

### 6.2 监控查询

**监控查询集合**:

```sql
-- 慢查询监控
SELECT
    LEFT(query, 100) as query_preview,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time,
    (shared_blks_hit::float / NULLIF(shared_blks_hit + shared_blks_read, 0)) * 100 as cache_hit_rate,
    CASE
        WHEN mean_exec_time > 1000 THEN '严重'
        WHEN mean_exec_time > 500 THEN '警告'
        WHEN mean_exec_time > 100 THEN '注意'
        ELSE '正常'
    END as severity
FROM pg_stat_statements
WHERE query LIKE '%<=>%' OR query LIKE '%<->%' OR query LIKE '%<#%'
ORDER BY mean_exec_time DESC
LIMIT 20;

-- 索引使用监控
SELECT
    tablename,
    indexname,
    idx_scan as scan_count,
    idx_tup_read as tuples_read,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
    CASE
        WHEN idx_scan = 0 THEN '未使用 - 考虑删除'
        WHEN idx_scan < 10 THEN '低使用 - 监控'
        ELSE '正常使用'
    END as usage_status
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan;
```

### 6.3 自动化诊断

**Python 自动化诊断脚本**:

```python
# diagnose.py
import psycopg2
from psycopg2.extras import RealDictCursor
import sys

def diagnose_database(conn_params):
    """自动化诊断"""
    conn = psycopg2.connect(**conn_params)
    cur = conn.cursor(cursor_factory=RealDictCursor)

    issues = []

    # 1. 检查索引
    cur.execute("""
        SELECT COUNT(*) as index_count
        FROM pg_indexes
        WHERE tablename = 'documents'
          AND indexdef LIKE '%vector%'
    """)
    if cur.fetchone()['index_count'] == 0:
        issues.append({
            'severity': 'CRITICAL',
            'issue': '缺少向量索引',
            'recommendation': '创建 HNSW 或 IVFFlat 索引'
        })

    # 2. 检查死元组
    cur.execute("""
        SELECT
            n_dead_tup,
            n_live_tup,
            (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) * 100 as dead_ratio
        FROM pg_stat_user_tables
        WHERE tablename = 'documents'
    """)
    row = cur.fetchone()
    if row and row['dead_ratio'] > 20:
        issues.append({
            'severity': 'WARNING',
            'issue': f"死元组比例过高: {row['dead_ratio']:.2f}%",
            'recommendation': '执行 VACUUM ANALYZE documents'
        })

    # 3. 检查连接数
    cur.execute("""
        SELECT
            (SELECT COUNT(*) FROM pg_stat_activity)::NUMERIC as current,
            (SELECT setting::NUMERIC FROM pg_settings WHERE name = 'max_connections') as max_conn
    """)
    row = cur.fetchone()
    if row and row['current'] / row['max_conn'] > 0.8:
        issues.append({
            'severity': 'WARNING',
            'issue': f"连接数接近上限: {row['current']}/{row['max_conn']}",
            'recommendation': '考虑使用连接池或增加 max_connections'
        })

    # 输出诊断结果
    if issues:
        print("发现问题:")
        for issue in issues:
            print(f"  [{issue['severity']}] {issue['issue']}")
            print(f"    建议: {issue['recommendation']}")
        return False
    else:
        print("✅ 未发现问题")
        return True

if __name__ == "__main__":
    conn_params = {
        'host': 'localhost',
        'port': 5432,
        'user': 'postgres',
        'password': 'postgres',
        'database': 'vector_db'
    }
    diagnose_database(conn_params)
```

## 7. 最佳实践

### 7.1 预防措施

**预防措施清单**:

1. **定期监控**:

   - 每天检查慢查询日志
   - 每周检查索引使用情况
   - 每月检查统计数据

2. **定期维护**:

   - 每天执行 ANALYZE
   - 每周执行 VACUUM ANALYZE
   - 每月检查索引效率

3. **配置优化**:
   - 合理配置内存参数
   - 使用连接池
   - 启用自动 VACUUM

### 7.2 故障响应

**故障响应流程**:

1. **问题报告**: 记录问题症状和错误信息
2. **快速诊断**: 使用诊断工具快速定位问题
3. **解决方案**: 选择合适的解决方案
4. **验证修复**: 确认问题已解决
5. **总结记录**: 记录问题和解决方案

## 8. 参考资料

### 8.1 官方文档

- [PostgreSQL 性能调优](https://www.postgresql.org/docs/current/performance-tips.html) - Performance
  Tips
- [pgvector 故障排查](https://github.com/pgvector/pgvector#troubleshooting) - pgvector
  Troubleshooting

### 8.2 技术文档

- [性能调优技巧](../../01-向量与混合搜索/最佳实践/性能调优技巧.md) - Performance Tuning
- [监控与告警](../运维手册/监控与告警.md) - Monitoring and Alerting

### 8.3 相关资源

- [PostgreSQL 故障排查指南](https://www.postgresql.org/docs/current/maintenance.html) - Maintenance
- [pg_stat_statements 文档](https://www.postgresql.org/docs/current/pgstatstatements.html) -
  pg_stat_statements

---

**最后更新**: 2025 年 11 月 1 日  
**维护者**: PostgreSQL Modern Team  
**文档编号**: 09-03-01
