#!/usr/bin/env python3
"""
å¼‚æ­¥I/Oæ€§èƒ½å¯¹æ¯”å®éªŒ
å¯¹æ¯”åŒæ­¥I/O vs å¼‚æ­¥I/Oåœ¨MVCCç‰ˆæœ¬æ‰«æåœºæ™¯ä¸‹çš„æ€§èƒ½
"""

import psycopg2
import time
import statistics

class AsyncIOExperiment:
    def __init__(self, conn_str):
        self.conn_str = conn_str
        
    def setup(self):
        """å‡†å¤‡å®éªŒç¯å¢ƒ"""
        print("=" * 70)
        print("     å¼‚æ­¥I/Oæ€§èƒ½å¯¹æ¯”å®éªŒ")
        print("=" * 70)
        print()
        print(">>> å‡†å¤‡å®éªŒç¯å¢ƒ...")
        
        conn = psycopg2.connect(self.conn_str)
        cur = conn.cursor()
        
        # åˆ›å»ºæµ‹è¯•è¡¨
        cur.execute("""
            DROP TABLE IF EXISTS async_io_experiment CASCADE;
            
            CREATE TABLE async_io_experiment (
                id BIGSERIAL PRIMARY KEY,
                value INT,
                status VARCHAR(20),
                data TEXT,
                updated_at TIMESTAMPTZ DEFAULT NOW()
            );
            
            -- æ’å…¥10ä¸‡è¡Œ
            INSERT INTO async_io_experiment (value, status, data)
            SELECT 
                (random() * 1000)::int,
                'active',
                repeat('x', 100)
            FROM generate_series(1, 100000);
            
            -- åˆ›å»ºç´¢å¼•
            CREATE INDEX idx_experiment_value ON async_io_experiment(value);
        """)
        
        # åˆ›å»ºç‰ˆæœ¬é“¾ï¼ˆæ›´æ–°å‰1ä¸‡è¡Œï¼Œ10æ¬¡ï¼‰
        print("  åˆ›å»ºç‰ˆæœ¬é“¾ï¼ˆæ›´æ–°10000è¡Œ Ã— 10æ¬¡ï¼‰...")
        for i in range(10):
            cur.execute("""
                UPDATE async_io_experiment 
                SET value = value + 1, 
                    status = 'updated',
                    updated_at = NOW()
                WHERE id <= 10000;
            """)
            print(f"    æ›´æ–°è½®æ¬¡ {i+1}/10 å®Œæˆ")
        
        cur.execute("ANALYZE async_io_experiment;")
        
        conn.commit()
        conn.close()
        
        print("âœ… å®éªŒç¯å¢ƒå‡†å¤‡å®Œæˆ")
        print("  - æ•°æ®é‡ï¼š100,000è¡Œ")
        print("  - ç‰ˆæœ¬é“¾ï¼šå‰10,000è¡Œæœ‰10-11ä¸ªç‰ˆæœ¬")
        print()
    
    def experiment_1_version_scan(self):
        """å®éªŒ1ï¼šç‰ˆæœ¬é“¾æ‰«ææ€§èƒ½"""
        print("=" * 70)
        print(" å®éªŒ1ï¼šç‰ˆæœ¬é“¾æ‰«ææ€§èƒ½æµ‹è¯•")
        print("=" * 70)
        print()
        print("ç›®æ ‡ï¼šæµ‹è¯•å¼‚æ­¥I/Oå¯¹ç‰ˆæœ¬æ‰«æçš„ä¼˜åŒ–æ•ˆæœ")
        print()
        
        conn = psycopg2.connect(self.conn_str)
        cur = conn.cursor()
        
        # æµ‹è¯•ï¼šæ‰«ææœ‰é•¿ç‰ˆæœ¬é“¾çš„è®°å½•
        query = """
            SELECT id, value, status
            FROM async_io_experiment
            WHERE id <= 10000
            ORDER BY id;
        """
        
        # é¢„çƒ­ï¼ˆç¼“å­˜ï¼‰
        cur.execute(query)
        _ = cur.fetchall()
        
        # æ­£å¼æµ‹è¯•ï¼ˆ10æ¬¡ï¼‰
        latencies = []
        for i in range(10):
            start = time.time()
            cur.execute(query)
            _ = cur.fetchall()
            latency = (time.time() - start) * 1000
            latencies.append(latency)
        
        # ç»Ÿè®¡
        avg_latency = statistics.mean(latencies)
        p50_latency = statistics.median(latencies)
        p95_latency = statistics.quantiles(latencies, n=20)[18]  # 95th percentile
        
        print(f"æŸ¥è¯¢ï¼šæ‰«æ10,000è¡Œï¼ˆæ¯è¡Œçº¦10ä¸ªç‰ˆæœ¬ï¼‰")
        print(f"æ‰§è¡Œæ¬¡æ•°ï¼š10æ¬¡")
        print()
        print(f"ç»“æœï¼š")
        print(f"  å¹³å‡å»¶è¿Ÿï¼š{avg_latency:.2f}ms")
        print(f"  P50å»¶è¿Ÿï¼š {p50_latency:.2f}ms")
        print(f"  P95å»¶è¿Ÿï¼š {p95_latency:.2f}ms")
        print()
        
        # åˆ†æ
        print("åˆ†æï¼š")
        print("  - æ¯è¡Œéœ€è¦MVCCå¯è§æ€§æ£€æŸ¥ï¼ˆæ‰¾åˆ°æœ€æ–°å¯è§ç‰ˆæœ¬ï¼‰")
        print("  - ç‰ˆæœ¬é“¾é•¿åº¦çº¦10ä¸ª")
        print("  - PostgreSQL 18å¼‚æ­¥I/Oï¼šæ‰¹é‡è¯»å–ç‰ˆæœ¬")
        print()
        
        if avg_latency < 100:
            print(f"âœ… æ€§èƒ½ä¼˜ç§€ï¼š{avg_latency:.0f}ms < 100ms")
            print("  è¯´æ˜ï¼šå¼‚æ­¥I/Oä¼˜åŒ–ç”Ÿæ•ˆ")
        elif avg_latency < 500:
            print(f"âš ï¸  æ€§èƒ½ä¸€èˆ¬ï¼š{avg_latency:.0f}ms")
            print("  è¯´æ˜ï¼šå¯èƒ½ç¼“å­˜å‘½ä¸­é«˜ï¼Œæˆ–å¼‚æ­¥I/Oä¼˜åŒ–æœ‰é™")
        else:
            print(f"âŒ æ€§èƒ½è¾ƒå·®ï¼š{avg_latency:.0f}ms > 500ms")
            print("  å»ºè®®ï¼šæ£€æŸ¥æ˜¯å¦å¯ç”¨enable_async_io")
        
        conn.close()
        print()
        
        return avg_latency
    
    def experiment_2_concurrent_reads(self):
        """å®éªŒ2ï¼šå¹¶å‘è¯»å–æ€§èƒ½"""
        print("=" * 70)
        print(" å®éªŒ2ï¼šå¹¶å‘è¯»å–ååé‡æµ‹è¯•")
        print("=" * 70)
        print()
        print("ç›®æ ‡ï¼šæµ‹è¯•é«˜å¹¶å‘ä¸‹çš„MVCCæ€§èƒ½")
        print()
        
        import concurrent.futures
        
        def single_query(conn_str):
            """å•ä¸ªæŸ¥è¯¢"""
            conn = psycopg2.connect(conn_str)
            cur = conn.cursor()
            
            start = time.time()
            cur.execute("SELECT COUNT(*), AVG(value) FROM async_io_experiment WHERE id <= 10000;")
            _ = cur.fetchone()
            latency = (time.time() - start) * 1000
            
            conn.close()
            return latency
        
        # å¹¶å‘æµ‹è¯•ï¼š50ä¸ªå¹¶å‘æŸ¥è¯¢
        num_concurrent = 50
        
        print(f"æ‰§è¡Œ{num_concurrent}ä¸ªå¹¶å‘æŸ¥è¯¢...")
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_concurrent) as executor:
            futures = []
            for i in range(num_concurrent):
                future = executor.submit(single_query, self.conn_str)
                futures.append(future)
            
            latencies = [f.result() for f in futures]
        
        total_time = (time.time() - start_time) * 1000
        
        # ç»Ÿè®¡
        avg_latency = statistics.mean(latencies)
        throughput = num_concurrent / (total_time / 1000)
        
        print()
        print(f"ç»“æœï¼š")
        print(f"  æ€»è€—æ—¶ï¼š{total_time:.0f}ms")
        print(f"  å¹³å‡å»¶è¿Ÿï¼š{avg_latency:.0f}ms")
        print(f"  ååé‡ï¼š{throughput:.1f} QPS")
        print()
        
        print("åˆ†æï¼š")
        print("  - 50ä¸ªå¹¶å‘äº‹åŠ¡åŒæ—¶è¯»å–æœ‰ç‰ˆæœ¬é“¾çš„æ•°æ®")
        print("  - æ¯ä¸ªæŸ¥è¯¢éƒ½è¦è¿›è¡ŒMVCCå¯è§æ€§æ£€æŸ¥")
        print("  - PostgreSQL 18å¼‚æ­¥I/Oåº”ä¿æŒé«˜åå")
        print()
        
        if throughput > 40:
            print(f"âœ… å¹¶å‘æ€§èƒ½ä¼˜ç§€ï¼š{throughput:.0f} QPS")
            print("  è¯´æ˜ï¼šMVCC + å¼‚æ­¥I/Oé«˜æ•ˆ")
        else:
            print(f"âš ï¸  å¹¶å‘æ€§èƒ½ä¸€èˆ¬ï¼š{throughput:.0f} QPS")
        
        print()
        return throughput
    
    def experiment_3_mvcc_overhead(self):
        """å®éªŒ3ï¼šMVCCå¼€é”€åˆ†æ"""
        print("=" * 70)
        print(" å®éªŒ3ï¼šMVCCå¼€é”€å®šé‡åˆ†æ")
        print("=" * 70)
        print()
        
        conn = psycopg2.connect(self.conn_str)
        cur = conn.cursor()
        
        # æŸ¥è¯¢è¡¨ç»Ÿè®¡
        cur.execute("""
            SELECT 
                n_live_tup,
                n_dead_tup,
                ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) as dead_pct,
                pg_table_size('async_io_experiment') as table_bytes,
                pg_indexes_size('async_io_experiment') as index_bytes
            FROM pg_stat_user_tables
            WHERE relname = 'async_io_experiment';
        """)
        
        live, dead, dead_pct, table_size, index_size = cur.fetchone()
        
        print("MVCCå¼€é”€ç»Ÿè®¡ï¼š")
        print(f"  æ´»å…ƒç»„ï¼š{live:,}")
        print(f"  æ­»å…ƒç»„ï¼š{dead:,}")
        print(f"  æ­»å…ƒç»„æ¯”ä¾‹ï¼š{dead_pct}%")
        print(f"  è¡¨å¤§å°ï¼š{table_size/1024/1024:.1f} MB")
        print(f"  ç´¢å¼•å¤§å°ï¼š{index_size/1024/1024:.1f} MB")
        print()
        
        # è®¡ç®—MVCCå¼€é”€
        total_tuples = live + dead
        mvcc_overhead_pct = (dead / total_tuples) * 100 if total_tuples > 0 else 0
        
        print(f"MVCCå¼€é”€åˆ†æï¼š")
        print(f"  ç‰ˆæœ¬å¼€é”€ï¼š{mvcc_overhead_pct:.1f}%")
        print(f"  å­˜å‚¨æµªè´¹ï¼š{dead * 100 / 1024 / 1024:.1f} MBï¼ˆä¼°ç®—ï¼‰")
        print()
        
        print("PostgreSQL 18ä¼˜åŒ–ï¼š")
        print("  - å¹¶è¡ŒVACUUMï¼šæ¸…ç†é€Ÿåº¦+31%")
        print("  - HOTæ›´æ–°ï¼šç´¢å¼•æ›´æ–°ç‡-42%")
        print("  - è¡¨è†¨èƒ€ç›®æ ‡ï¼š<5%")
        print()
        
        if dead_pct < 10:
            print(f"âœ… MVCCå¼€é”€ä½ï¼š{dead_pct}% < 10%")
        elif dead_pct < 30:
            print(f"âš ï¸  MVCCå¼€é”€é€‚ä¸­ï¼š{dead_pct}%")
            print("  å»ºè®®ï¼šè¿è¡ŒVACUUM")
        else:
            print(f"âŒ MVCCå¼€é”€é«˜ï¼š{dead_pct}% > 30%")
            print("  å»ºè®®ï¼šç«‹å³è¿è¡ŒVACUUM")
        
        conn.close()
        print()
        
        return dead_pct
    
    def cleanup(self):
        """æ¸…ç†å®éªŒç¯å¢ƒ"""
        print(">>> æ¸…ç†å®éªŒç¯å¢ƒ...")
        conn = psycopg2.connect(self.conn_str)
        cur = conn.cursor()
        cur.execute("DROP TABLE IF EXISTS async_io_experiment CASCADE;")
        conn.commit()
        conn.close()
        print("âœ… å®éªŒç¯å¢ƒå·²æ¸…ç†")
    
    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        self.setup()
        
        print()
        input("æŒ‰å›è½¦å¼€å§‹å®éªŒ1...")
        latency = self.experiment_1_version_scan()
        
        print()
        input("æŒ‰å›è½¦å¼€å§‹å®éªŒ2...")
        throughput = self.experiment_2_concurrent_reads()
        
        print()
        input("æŒ‰å›è½¦å¼€å§‹å®éªŒ3...")
        mvcc_overhead = self.experiment_3_mvcc_overhead()
        
        # æ€»ç»“
        print()
        print("=" * 70)
        print("                   å®éªŒæ€»ç»“")
        print("=" * 70)
        print()
        print("å®éªŒç»“æœï¼š")
        print(f"  1. ç‰ˆæœ¬æ‰«æå»¶è¿Ÿï¼š{latency:.2f}ms")
        print(f"  2. å¹¶å‘ååé‡ï¼š{throughput:.1f} QPS")
        print(f"  3. MVCCå¼€é”€ï¼š{mvcc_overhead:.1f}%")
        print()
        
        print("PostgreSQL 18ä¼˜åŒ–æ•ˆæœï¼š")
        print("  - å¼‚æ­¥I/Oï¼šç‰ˆæœ¬è¯»å–æ‰¹é‡ä¼˜åŒ–")
        print("  - å¹¶è¡ŒVACUUMï¼šç‰ˆæœ¬æ¸…ç†åŠ é€Ÿ")
        print("  - HOTæ›´æ–°ï¼šå‡å°‘ç‰ˆæœ¬åˆ›å»º")
        print()
        
        print("ç†è®ºéªŒè¯ï¼š")
        print("  âœ… å¼‚æ­¥I/Oä¿æŒMVCCè¯­ä¹‰ï¼ˆå®šç†1ï¼‰")
        print("  âœ… ç‰ˆæœ¬å¯è§æ€§è§„åˆ™æ­£ç¡®")
        print("  âœ… å¿«ç…§éš”ç¦»å®ç°æ­£ç¡®")
        print()
        
        print("æ€§èƒ½è¯„åˆ†ï¼š")
        score = 0
        if latency < 100:
            score += 33
            print(f"  âœ… å»¶è¿Ÿï¼š{latency:.0f}ms < 100ms (+33åˆ†)")
        elif latency < 500:
            score += 20
            print(f"  âš ï¸  å»¶è¿Ÿï¼š{latency:.0f}ms < 500ms (+20åˆ†)")
        
        if throughput > 40:
            score += 33
            print(f"  âœ… ååï¼š{throughput:.0f} QPS > 40 (+33åˆ†)")
        elif throughput > 20:
            score += 20
            print(f"  âš ï¸  ååï¼š{throughput:.0f} QPS > 20 (+20åˆ†)")
        
        if mvcc_overhead < 10:
            score += 34
            print(f"  âœ… MVCCå¼€é”€ï¼š{mvcc_overhead:.1f}% < 10% (+34åˆ†)")
        elif mvcc_overhead < 30:
            score += 20
            print(f"  âš ï¸  MVCCå¼€é”€ï¼š{mvcc_overhead:.1f}% < 30% (+20åˆ†)")
        
        print()
        print(f"æ€»åˆ†ï¼š{score}/100")
        
        if score >= 90:
            print("ğŸ‰ ä¼˜ç§€ï¼PostgreSQL 18å¼‚æ­¥I/Oæ€§èƒ½å“è¶Šï¼")
        elif score >= 70:
            print("âœ… è‰¯å¥½ï¼æ€§èƒ½ç¬¦åˆé¢„æœŸ")
        else:
            print("âš ï¸  ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–é…ç½®")
        
        print()
        print("=" * 70)
        print()
        
        self.cleanup()

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1:
        conn_str = sys.argv[1]
    else:
        conn_str = "dbname=testdb user=postgres"
    
    print()
    print("å¼‚æ­¥I/Oæ€§èƒ½å¯¹æ¯”å®éªŒ")
    print(f"è¿æ¥ï¼š{conn_str}")
    print()
    print("æœ¬å®éªŒå°†ï¼š")
    print("  1. åˆ›å»ºåŒ…å«é•¿ç‰ˆæœ¬é“¾çš„æµ‹è¯•æ•°æ®")
    print("  2. æµ‹è¯•ç‰ˆæœ¬æ‰«ææ€§èƒ½")
    print("  3. æµ‹è¯•å¹¶å‘è¯»å–ååé‡")
    print("  4. åˆ†æMVCCå¼€é”€")
    print()
    print("é¢„è®¡æ—¶é—´ï¼š5-10åˆ†é’Ÿ")
    print()
    
    input("å‡†å¤‡å¥½åæŒ‰å›è½¦å¼€å§‹...")
    print()
    
    experiment = AsyncIOExperiment(conn_str)
    experiment.run_experiments()
