# 知识图谱问答系统 - 架构设计

## 元数据

- **创建日期**: 2025-12-04
- **架构类型**: KBQA + Text-to-Cypher + 微服务
- **技术栈**: Apache AGE + pgvector + GPT-4 + LangChain + FastAPI

---

## 1. 整体架构

```
                    用户问题（自然语言）
                           ↓
┌──────────────────────────────────────────────────────────┐
│                   问答API服务 (FastAPI)                   │
└────────────────────┬─────────────────────────────────────┘
                     ↓
┌──────────────────────────────────────────────────────────┐
│                  KBQA核心引擎                             │
├──────────────────────────────────────────────────────────┤
│                                                            │
│  Step 1: 问题理解                                         │
│  ┌─────────────────────────────────────────┐            │
│  │ - 意图识别 (GPT-4)                       │            │
│  │ - 实体识别 (NER)                        │            │
│  │ - 约束提取                              │            │
│  └─────────────────────────────────────────┘            │
│                     ↓                                     │
│  Step 2: Text-to-Cypher生成                              │
│  ┌─────────────────────────────────────────┐            │
│  │ - Schema感知Prompt                      │            │
│  │ - Few-Shot动态选择                      │            │
│  │ - GPT-4生成Cypher                       │            │
│  │ - 自动错误修复                          │            │
│  └─────────────────────────────────────────┘            │
│                     ↓                                     │
│  Step 3: 实体链接                                        │
│  ┌─────────────────────────────────────────┐            │
│  │ - 精确匹配 (SQL)                        │            │
│  │ - 模糊匹配 (Levenshtein)                │            │
│  │ - 语义匹配 (pgvector)                   │            │
│  └─────────────────────────────────────────┘            │
│                     ↓                                     │
│  Step 4: 图查询执行                                      │
│  ┌─────────────────────────────────────────┐            │
│  │ - Apache AGE执行Cypher                  │            │
│  │ - 子图检索                              │            │
│  │ - 多跳推理                              │            │
│  └─────────────────────────────────────────┘            │
│                     ↓                                     │
│  Step 5: 答案生成                                        │
│  ┌─────────────────────────────────────────┐            │
│  │ - 结果格式化                            │            │
│  │ - LLM生成自然语言答案                   │            │
│  │ - 推理路径解释                          │            │
│  └─────────────────────────────────────────┘            │
│                                                            │
└────────────────────┬─────────────────────────────────────┘
                     ↓
┌──────────────────────────────────────────────────────────┐
│               数据存储层 (PostgreSQL 18)                  │
├──────────────────────────────────────────────────────────┤
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │ 关系数据     │  │ AGE图数据    │  │ pgvector     │  │
│  │ (员工/部门)  │  │ (节点/边)    │  │ (语义向量)   │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  │
└──────────────────────┬─────────────────────────────────────┘
                       ↓
┌──────────────────────────────────────────────────────────┐
│                缓存层 (Redis)                             │
│  - Cypher查询缓存                                        │
│  - 实体链接缓存                                          │
│  - LLM结果缓存                                           │
└──────────────────────────────────────────────────────────┘
```

---

## 2. 核心组件设计

### 2.1 问题理解模块

```python
from openai import OpenAI
from transformers import pipeline
from typing import Dict, List

class QuestionUnderstanding:
    """问题理解与分析"""

    def __init__(self, openai_client: OpenAI):
        self.llm = openai_client
        self.ner_model = pipeline("ner", model="dslim/bert-base-NER")

    def analyze(self, question: str) -> Dict:
        """完整的问题分析"""

        return {
            'intent': self._classify_intent(question),
            'entities': self._extract_entities(question),
            'constraints': self._extract_constraints(question),
            'answer_type': self._determine_answer_type(question),
            'complexity': self._assess_complexity(question)
        }

    def _classify_intent(self, question: str) -> str:
        """意图分类"""
        prompt = f"""分析问题的查询意图:

问题: {question}

从以下类别选择一个:
- count: 统计数量
- find: 查找实体
- compare: 比较对比
- recommend: 推荐
- reason: 推理解释
- aggregate: 聚合分析

只返回类别名称。
"""

        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )

        return response.choices[0].message.content.strip().lower()

    def _extract_entities(self, question: str) -> List[Dict]:
        """提取实体"""
        ner_results = self.ner_model(question)

        entities = []
        for result in ner_results:
            entities.append({
                'text': result['word'],
                'type': result['entity_group'],
                'score': result['score']
            })

        return entities

    def _extract_constraints(self, question: str) -> List[Dict]:
        """提取约束条件"""
        prompt = f"""从问题中提取约束条件:

问题: {question}

以JSON格式返回约束列表,每个约束包含:
- property: 属性名
- operator: 操作符 (>, <, =, contains)
- value: 约束值

只返回JSON。
"""

        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0
        )

        import json
        try:
            result = json.loads(response.choices[0].message.content)
            return result.get('constraints', [])
        except:
            return []

    def _determine_answer_type(self, question: str) -> str:
        """确定答案类型"""
        if any(word in question for word in ['多少', 'how many', 'count']):
            return 'number'
        elif any(word in question for word in ['是否', 'whether']):
            return 'boolean'
        elif any(word in question for word in ['哪些', 'list']):
            return 'list'
        else:
            return 'text'

    def _assess_complexity(self, question: str) -> str:
        """评估问题复杂度"""
        # 简单启发式规则
        if '的' in question and question.count('的') >= 2:
            return 'complex'  # 多跳推理
        elif any(word in question for word in ['平均', '总', '最']):
            return 'aggregate'  # 聚合查询
        else:
            return 'simple'
```

### 2.2 Text-to-Cypher生成器

```python
import redis
import hashlib

class Text2CypherGenerator:
    """Text-to-Cypher生成器（带缓存）"""

    def __init__(self, db_conn, graph_name: str, openai_client: OpenAI, redis_client: redis.Redis):
        self.db = db_conn
        self.graph_name = graph_name
        self.llm = openai_client
        self.redis = redis_client

        # 提取图Schema
        self.schema = self._extract_schema()
        self.schema_version = self._compute_schema_version()

        # Few-Shot示例库
        self.example_bank = self._load_examples()

    def generate(self, question: str) -> tuple:
        """
        生成Cypher查询

        Returns:
            (cypher_query, is_from_cache)
        """

        # 1. 检查缓存
        cache_key = self._get_cache_key(question)
        cached = self.redis.get(cache_key)
        if cached:
            return (cached.decode(), True)

        # 2. 动态选择Few-Shot示例
        relevant_examples = self._select_examples(question, top_k=3)

        # 3. 构建Prompt
        prompt = self._build_prompt(question, relevant_examples)

        # 4. 调用GPT-4生成
        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": self._get_system_prompt()},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )

        cypher = response.choices[0].message.content.strip()
        cypher = self._clean_cypher(cypher)

        # 5. 缓存结果
        self.redis.setex(cache_key, 3600, cypher)

        return (cypher, False)

    def _get_cache_key(self, question: str) -> str:
        """生成缓存键"""
        content = f"{question}|{self.schema_version}"
        return f"cypher:{hashlib.md5(content.encode()).hexdigest()}"

    def _get_system_prompt(self) -> str:
        """系统提示词"""
        return f"""你是Cypher查询专家。基于企业知识图谱Schema，将自然语言转换为Cypher查询。

# Schema
{json.dumps(self.schema, indent=2, ensure_ascii=False)}

# 规则
1. 使用MATCH模式匹配
2. 属性访问: node.property
3. 使用WHERE过滤
4. 添加LIMIT限制结果
5. 只返回Cypher，不要解释

# 输出
只返回Cypher查询本身。
"""

    def _build_prompt(self, question: str, examples: List[Dict]) -> str:
        """构建用户提示词"""
        prompt = "# 参考示例\n\n"

        for ex in examples:
            prompt += f"问题: {ex['question']}\n"
            prompt += f"Cypher:\n```cypher\n{ex['cypher']}\n```\n\n"

        prompt += f"# 当前问题\n\n问题: {question}\n\nCypher:\n"

        return prompt

    def _select_examples(self, question: str, top_k: int = 3) -> List[Dict]:
        """动态选择最相关的Few-Shot示例"""
        from sentence_transformers import SentenceTransformer
        import numpy as np

        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

        # 问题向量
        question_emb = embedding_model.encode(question)

        # 示例向量
        example_questions = [ex['question'] for ex in self.example_bank]
        example_embs = embedding_model.encode(example_questions)

        # 计算相似度
        similarities = np.dot(example_embs, question_emb) / (
            np.linalg.norm(example_embs, axis=1) * np.linalg.norm(question_emb)
        )

        # 选择Top-K
        top_indices = np.argsort(similarities)[-top_k:][::-1]

        return [self.example_bank[i] for i in top_indices]

    def _load_examples(self) -> List[Dict]:
        """加载Few-Shot示例库"""
        return [
            {
                "question": "有多少员工?",
                "cypher": "MATCH (e:Employee) RETURN COUNT(e) AS employee_count"
            },
            {
                "question": "张三在哪个部门?",
                "cypher": "MATCH (e:Employee {name: '张三'})-[:WORKS_IN]->(d:Department) RETURN d.name"
            },
            {
                "question": "研发中心有哪些Python工程师?",
                "cypher": """MATCH (d:Department {name: '研发中心'})<-[:WORKS_IN]-(e:Employee)
WHERE 'Python' IN e.skills
RETURN e.name, e.title, e.years_experience"""
            },
            {
                "question": "张三的直接下属有谁?",
                "cypher": """MATCH (manager:Employee {name: '张三'})<-[:REPORTS_TO]-(subordinate:Employee)
RETURN subordinate.name, subordinate.title"""
            },
            {
                "question": "每个部门有多少员工?",
                "cypher": """MATCH (d:Department)<-[:WORKS_IN]-(e:Employee)
RETURN d.name, COUNT(e) AS employee_count
ORDER BY employee_count DESC"""
            }
        ]
```

---

## 3. 实体链接模块

```python
from sentence_transformers import SentenceTransformer
import Levenshtein

class EntityLinker:
    """实体链接器"""

    def __init__(self, db_conn, graph_name: str, embedding_model: SentenceTransformer):
        self.db = db_conn
        self.graph_name = graph_name
        self.embedding_model = embedding_model

    def link_entities(self, entities: List[Dict]) -> List[Dict]:
        """链接实体到知识图谱"""
        linked = []

        for entity in entities:
            mention = entity['text']
            entity_type = entity.get('type')

            # 三级匹配
            match = (
                self._exact_match(mention, entity_type) or
                self._fuzzy_match(mention, entity_type) or
                self._semantic_match(mention, entity_type)
            )

            if match:
                linked.append({
                    'mention': mention,
                    'linked_to': match,
                    'confidence': match['confidence']
                })
            else:
                # 未链接
                linked.append({
                    'mention': mention,
                    'linked_to': None,
                    'confidence': 0.0
                })

        return linked

    def _exact_match(self, mention: str, entity_type: str = None) -> Dict:
        """精确匹配"""
        query = f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                WHERE n.name = '{mention}'
                RETURN id(n) AS node_id, n.name AS name, labels(n) AS types
                LIMIT 1
            $$) AS (node_id agtype, name agtype, types agtype);
        """

        result = self.db.fetchone(query)
        if result:
            return {
                'node_id': int(json.loads(result[0])),
                'name': json.loads(result[1]),
                'types': json.loads(result[2]),
                'confidence': 1.0,
                'method': 'exact'
            }
        return None

    def _fuzzy_match(self, mention: str, entity_type: str = None, threshold=0.8) -> Dict:
        """模糊匹配（Levenshtein距离）"""
        query = f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                MATCH (n)
                RETURN id(n) AS node_id, n.name AS name, labels(n) AS types
            $$) AS (node_id agtype, name agtype, types agtype);
        """

        results = self.db.fetchall(query)

        best_match = None
        best_score = 0

        for row in results:
            name = json.loads(row[1])
            distance = Levenshtein.distance(mention.lower(), name.lower())
            max_len = max(len(mention), len(name))
            similarity = 1 - (distance / max_len)

            if similarity > threshold and similarity > best_score:
                best_score = similarity
                best_match = {
                    'node_id': int(json.loads(row[0])),
                    'name': name,
                    'types': json.loads(row[2]),
                    'confidence': similarity,
                    'method': 'fuzzy'
                }

        return best_match

    def _semantic_match(self, mention: str, entity_type: str = None) -> Dict:
        """语义匹配（向量相似度）"""
        # 生成mention向量
        mention_emb = self.embedding_model.encode(mention)

        query = """
            SELECT
                node_id,
                name,
                types,
                1 - (embedding <=> %(mention_emb)s::vector) AS similarity
            FROM entity_embeddings
            ORDER BY embedding <=> %(mention_emb)s::vector
            LIMIT 1;
        """

        result = self.db.fetchone(query, {'mention_emb': mention_emb.tolist()})

        if result and result[3] > 0.7:
            return {
                'node_id': result[0],
                'name': result[1],
                'types': result[2],
                'confidence': float(result[3]),
                'method': 'semantic'
            }

        return None
```

---

## 4. 查询执行引擎

```python
class QueryExecutor:
    """Cypher查询执行器（带错误修复）"""

    def __init__(self, db_conn, graph_name: str, llm_client: OpenAI):
        self.db = db_conn
        self.graph_name = graph_name
        self.llm = llm_client

    def execute_with_retry(self, cypher: str, max_retries: int = 3) -> tuple:
        """带重试的查询执行"""

        for attempt in range(max_retries):
            try:
                result = self._execute(cypher)
                return (True, result, cypher)

            except Exception as e:
                error_msg = str(e)

                # 自动修复
                fixed_cypher = self._auto_fix(cypher, error_msg)

                if fixed_cypher != cypher:
                    cypher = fixed_cypher
                    continue

                # LLM修复
                if attempt < max_retries - 1:
                    cypher = self._llm_fix(cypher, error_msg)
                    continue

                return (False, None, error_msg)

        return (False, None, "Max retries exceeded")

    def _execute(self, cypher: str) -> List[Dict]:
        """执行Cypher查询"""
        # 提取RETURN列
        columns = self._extract_return_columns(cypher)

        query = f"""
            SELECT * FROM cypher('{self.graph_name}', $$
                {cypher}
            $$) AS ({', '.join([f'{col} agtype' for col in columns])});
        """

        results = self.db.fetchall(query)

        return [{col: json.loads(row[i]) for i, col in enumerate(columns)}
                for row in results]

    def _auto_fix(self, cypher: str, error_msg: str) -> str:
        """基于规则的自动修复"""
        import re

        # 规则1: 属性访问错误
        cypher = re.sub(r"(\w+)\['(\w+)'\]", r"\1.\2", cypher)

        # 规则2: 缺少RETURN
        if "RETURN" not in cypher.upper():
            cypher += "\nRETURN *"

        # 规则3: 关系方向错误
        if "undirected" in error_msg.lower():
            cypher = cypher.replace("--", "-->")

        return cypher

    def _llm_fix(self, cypher: str, error_msg: str) -> str:
        """LLM修复错误"""
        prompt = f"""修复以下Cypher查询：

原始查询:
```cypher
{cypher}
```

错误: {error_msg}

返回修复后的Cypher，只返回查询本身。
"""

        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )

        fixed = response.choices[0].message.content.strip()
        return fixed.replace("```cypher", "").replace("```", "").strip()

```

---

## 5. 答案生成模块

```python
class AnswerGenerator:
    """答案生成器"""

    def __init__(self, llm_client: OpenAI):
        self.llm = llm_client

    def generate(self, question: str, query_results: List[Dict],
                 cypher: str = None) -> Dict:
        """生成自然语言答案"""

        if not query_results:
            return {
                'answer': "抱歉，没有找到相关信息。",
                'confidence': 0.0
            }

        # 构建上下文
        context = json.dumps(query_results, ensure_ascii=False, indent=2)

        prompt = f"""基于查询结果回答问题：

问题: {question}

查询结果:
{context}

请用自然、友好的语言回答问题。如果结果是列表，请适当总结。
"""

        response = self.llm.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "你是友好的企业知识助手。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )

        answer = response.choices[0].message.content

        return {
            'answer': answer,
            'query_results': query_results,
            'cypher': cypher,
            'result_count': len(query_results)
        }
```

---

## 6. 完整KBQA系统

```python
class KBQASystem:
    """知识图谱问答系统"""

    def __init__(self, config: Dict):
        self.db = connect_database(config['database'])
        self.redis = redis.Redis(**config['redis'])
        self.openai = OpenAI(api_key=config['openai_key'])

        # 初始化各模块
        self.question_understanding = QuestionUnderstanding(self.openai)
        self.text2cypher = Text2CypherGenerator(
            self.db,
            config['graph_name'],
            self.openai,
            self.redis
        )
        self.entity_linker = EntityLinker(
            self.db,
            config['graph_name'],
            SentenceTransformer('all-MiniLM-L6-v2')
        )
        self.query_executor = QueryExecutor(
            self.db,
            config['graph_name'],
            self.openai
        )
        self.answer_generator = AnswerGenerator(self.openai)

    async def answer(self, question: str) -> Dict:
        """完整的问答流程"""
        import time
        start_time = time.time()

        # Step 1: 问题理解
        understanding = self.question_understanding.analyze(question)

        # Step 2: 生成Cypher
        cypher, from_cache = self.text2cypher.generate(question)

        # Step 3: 实体链接
        linked_entities = self.entity_linker.link_entities(understanding['entities'])

        # Step 4: 执行查询
        success, results, final_cypher = self.query_executor.execute_with_retry(cypher)

        if not success:
            return {
                'success': False,
                'error': results,
                'latency_ms': (time.time() - start_time) * 1000
            }

        # Step 5: 生成答案
        answer_data = self.answer_generator.generate(question, results, final_cypher)

        latency_ms = (time.time() - start_time) * 1000

        return {
            'success': True,
            'question': question,
            'understanding': understanding,
            'cypher': final_cypher,
            'cypher_from_cache': from_cache,
            'linked_entities': linked_entities,
            'query_results': results,
            'answer': answer_data['answer'],
            'latency_ms': latency_ms
        }
```

---

## 7. API服务设计

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="知识图谱问答API")

# 请求模型
class QuestionRequest(BaseModel):
    question: str
    context: Dict = {}

# 响应模型
class AnswerResponse(BaseModel):
    success: bool
    answer: str
    cypher: str = None
    latency_ms: float
    result_count: int = 0

# 全局KBQA系统
kbqa_system = KBQASystem(config)

@app.post("/api/v1/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """问答API"""
    try:
        result = await kbqa_system.answer(request.question)

        if not result['success']:
            raise HTTPException(status_code=500, detail=result.get('error'))

        return AnswerResponse(
            success=True,
            answer=result['answer'],
            cypher=result['cypher'],
            latency_ms=result['latency_ms'],
            result_count=len(result['query_results'])
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/health")
async def health_check():
    """健康检查"""
    return {"status": "ok"}
```

---

## 8. 监控与日志

```python
# Prometheus指标
from prometheus_client import Counter, Histogram, Gauge

# 请求计数
kbqa_requests_total = Counter(
    'kbqa_requests_total',
    'Total KBQA requests',
    ['intent', 'success']
)

# 延迟分布
kbqa_latency = Histogram(
    'kbqa_latency_seconds',
    'KBQA latency',
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0]
)

# Cypher缓存命中率
cypher_cache_hits = Counter('cypher_cache_hits_total', 'Cypher cache hits')
cypher_cache_misses = Counter('cypher_cache_misses_total', 'Cypher cache misses')

# 在代码中埋点
@app.post("/api/v1/ask")
async def ask_question(request: QuestionRequest):
    with kbqa_latency.time():
        result = await kbqa_system.answer(request.question)

        kbqa_requests_total.labels(
            intent=result['understanding']['intent'],
            success=result['success']
        ).inc()

        if result['cypher_from_cache']:
            cypher_cache_hits.inc()
        else:
            cypher_cache_misses.inc()

        return result
```

---

**下一步**: [03-数据库设计](./03-数据库设计.md) | [返回首页](./README.md)
