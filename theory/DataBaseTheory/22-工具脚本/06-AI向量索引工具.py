#!/usr/bin/env python3
"""
AIå‘é‡ç´¢å¼•æ„å»ºä¸ç®¡ç†å·¥å…·
ç”¨é€”: æ‰¹é‡æ„å»ºpgvectorç´¢å¼•ã€ç›‘æ§ç´¢å¼•å¥åº·åº¦
åˆ›å»º: 2025-12-04
"""

import psycopg2
from sentence_transformers import SentenceTransformer
import argparse
from tqdm import tqdm

def build_vector_index(conn_str, table, text_column, embedding_column='embedding', 
                      batch_size=1000, model_name='all-MiniLM-L6-v2'):
    """
    æ‰¹é‡æ„å»ºå‘é‡ç´¢å¼•
    
    Args:
        conn_str: æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
        table: è¡¨å
        text_column: æ–‡æœ¬åˆ—å
        embedding_column: å‘é‡åˆ—å
        batch_size: æ‰¹å¤„ç†å¤§å°
        model_name: å‘é‡æ¨¡å‹
    """
    
    print(f"ğŸš€ å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•...")
    print(f"   è¡¨: {table}")
    print(f"   æ–‡æœ¬åˆ—: {text_column}")
    print(f"   æ¨¡å‹: {model_name}")
    
    # è¿æ¥æ•°æ®åº“
    conn = psycopg2.connect(conn_str)
    cursor = conn.cursor()
    
    # åŠ è½½æ¨¡å‹
    print(f"ğŸ“¦ åŠ è½½å‘é‡æ¨¡å‹...")
    model = SentenceTransformer(model_name)
    embedding_dim = model.get_sentence_embedding_dimension()
    
    # ç¡®ä¿è¡¨æœ‰embeddingåˆ—
    cursor.execute(f"""
        ALTER TABLE {table} 
        ADD COLUMN IF NOT EXISTS {embedding_column} vector({embedding_dim});
    """)
    conn.commit()
    
    # è·å–æ€»è¡Œæ•°
    cursor.execute(f"SELECT COUNT(*) FROM {table} WHERE {embedding_column} IS NULL")
    total_rows = cursor.fetchone()[0]
    
    print(f"ğŸ“Š éœ€è¦å¤„ç† {total_rows} è¡Œ")
    
    # æ‰¹é‡å¤„ç†
    offset = 0
    with tqdm(total=total_rows, desc="ç”Ÿæˆå‘é‡") as pbar:
        while True:
            cursor.execute(f"""
                SELECT id, {text_column}
                FROM {table}
                WHERE {embedding_column} IS NULL
                ORDER BY id
                LIMIT {batch_size}
            """)
            
            batch = cursor.fetchall()
            if not batch:
                break
            
            # ç”Ÿæˆå‘é‡
            texts = [row[1] for row in batch]
            embeddings = model.encode(texts, show_progress_bar=False)
            
            # æ›´æ–°æ•°æ®åº“
            for (id, _), emb in zip(batch, embeddings):
                cursor.execute(f"""
                    UPDATE {table}
                    SET {embedding_column} = %s
                    WHERE id = %s
                """, (emb.tolist(), id))
            
            conn.commit()
            pbar.update(len(batch))
            offset += batch_size
    
    # åˆ›å»ºHNSWç´¢å¼•
    print(f"ğŸ”¨ åˆ›å»ºHNSWç´¢å¼•...")
    cursor.execute(f"""
        CREATE INDEX IF NOT EXISTS idx_{table}_{embedding_column}
        ON {table}
        USING hnsw ({embedding_column} vector_cosine_ops)
        WITH (m = 16, ef_construction = 64);
    """)
    conn.commit()
    
    print(f"âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ!")
    
    cursor.close()
    conn.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='æ„å»ºpgvectorç´¢å¼•')
    parser.add_argument('--conn', required=True, help='æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²')
    parser.add_argument('--table', required=True, help='è¡¨å')
    parser.add_argument('--text-column', required=True, help='æ–‡æœ¬åˆ—å')
    parser.add_argument('--batch-size', type=int, default=1000, help='æ‰¹å¤„ç†å¤§å°')
    
    args = parser.parse_args()
    
    build_vector_index(
        args.conn,
        args.table,
        args.text_column,
        batch_size=args.batch_size
    )
