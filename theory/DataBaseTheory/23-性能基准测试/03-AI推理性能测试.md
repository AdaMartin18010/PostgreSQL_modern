# AIæ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•

## å…ƒæ•°æ®
- **åˆ›å»ºæ—¥æœŸ**: 2025-12-04
- **æµ‹è¯•å¯¹è±¡**: pgvector + Apache AGE + LLM
- **æµ‹è¯•å·¥å…·**: Python + pgbench

---

## 1. pgvectoræ€§èƒ½æµ‹è¯•

### 1.1 HNSW vs IVFFlat

```python
import psycopg2
import numpy as np
from sentence_transformers import SentenceTransformer
import time

def benchmark_pgvector(conn_str, num_queries=1000):
    """æµ‹è¯•pgvectoræ€§èƒ½"""

    conn = psycopg2.connect(conn_str)
    cursor = conn.cursor()
    model = SentenceTransformer('all-MiniLM-L6-v2')

    # ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢
    test_queries = ["sample query " + str(i) for i in range(num_queries)]
    query_embs = model.encode(test_queries)

    # æµ‹è¯•HNSW
    print("Testing HNSW...")
    hnsw_latencies = []
    for emb in query_embs:
        start = time.time()
        cursor.execute("""
            SELECT id FROM documents
            ORDER BY embedding <=> %s::vector
            LIMIT 10;
        """, (emb.tolist(),))
        cursor.fetchall()
        hnsw_latencies.append((time.time() - start) * 1000)

    return {
        'index_type': 'HNSW',
        'avg_latency_ms': np.mean(hnsw_latencies),
        'p95_latency_ms': np.percentile(hnsw_latencies, 95),
        'p99_latency_ms': np.percentile(hnsw_latencies, 99),
        'qps': 1000 / np.mean(hnsw_latencies)
    }

# è¿è¡Œæµ‹è¯•
result = benchmark_pgvector('postgresql://localhost/test_db')
print(f"å¹³å‡å»¶è¿Ÿ: {result['avg_latency_ms']:.2f}ms")
print(f"P95å»¶è¿Ÿ: {result['p95_latency_ms']:.2f}ms")
print(f"QPS: {result['qps']:.0f}")

# é¢„æœŸç»“æœ:
# HNSW: å¹³å‡3ms, QPS 2000+
# IVFFlat: å¹³å‡10ms, QPS 700+
```

---

## 2. Apache AGEå›¾æŸ¥è¯¢æ€§èƒ½

### 2.1 å›¾éå†åŸºå‡†

```bash
#!/bin/bash
# Apache AGEæ€§èƒ½æµ‹è¯•

echo "ğŸš€ Apache AGEå›¾æŸ¥è¯¢æ€§èƒ½æµ‹è¯•"

# æµ‹è¯•1-hopæŸ¥è¯¢
psql -d test_db -c "
SELECT AVG(query_time) FROM (
    SELECT
        id,
        (SELECT COUNT(*) FROM cypher('test_graph', \$\$
            MATCH (n)-[]->(m)
            WHERE id(n) = \$id
            RETURN m
        \$\$, 'id', id::agtype) AS (m agtype)) AS result,
        EXTRACT(EPOCH FROM (clock_timestamp() - statement_timestamp())) * 1000 AS query_time
    FROM generate_series(1, 100) id
) t;
"

# æµ‹è¯•2-hopæŸ¥è¯¢
echo "æµ‹è¯•2-hopå›¾éå†..."
# ...

# é¢„æœŸç»“æœ:
# 1-hop: <50ms
# 2-hop: <150ms
# 3-hop: <500ms
```

---

## 3. LLMè°ƒç”¨æ€§èƒ½

### 3.1 Text-to-Cypherç”Ÿæˆå»¶è¿Ÿ

```python
def benchmark_text2cypher(num_requests=100):
    """æµ‹è¯•Text-to-Cypheræ€§èƒ½"""

    generator = Text2CypherGenerator(...)

    questions = [
        "æœ‰å¤šå°‘å‘˜å·¥?",
        "å¼ ä¸‰åœ¨å“ªä¸ªéƒ¨é—¨?",
        "ç ”å‘ä¸­å¿ƒçš„Pythonå·¥ç¨‹å¸ˆ",
        # ... æ›´å¤šé—®é¢˜
    ]

    # æµ‹è¯•æ— ç¼“å­˜
    cache_miss_latencies = []
    for q in questions * (num_requests // len(questions)):
        start = time.time()
        generator.redis.flushdb()  # æ¸…ç©ºç¼“å­˜
        cypher, _ = generator.generate(q)
        latency = (time.time() - start) * 1000
        cache_miss_latencies.append(latency)

    # æµ‹è¯•æœ‰ç¼“å­˜
    cache_hit_latencies = []
    for q in questions * (num_requests // len(questions)):
        start = time.time()
        cypher, from_cache = generator.generate(q)
        latency = (time.time() - start) * 1000
        cache_hit_latencies.append(latency)

    return {
        'cache_miss_avg_ms': np.mean(cache_miss_latencies),
        'cache_hit_avg_ms': np.mean(cache_hit_latencies),
        'speedup': np.mean(cache_miss_latencies) / np.mean(cache_hit_latencies)
    }

# é¢„æœŸç»“æœ:
# ç¼“å­˜æœªå‘½ä¸­: 500-800ms (GPT-4è°ƒç”¨)
# ç¼“å­˜å‘½ä¸­: 1-3ms (Redisè¯»å–)
# åŠ é€Ÿæ¯”: 200-500å€
```

---

## 4. ç«¯åˆ°ç«¯KBQAæ€§èƒ½

```python
def benchmark_kbqa_e2e(api_url, num_requests=100):
    """ç«¯åˆ°ç«¯KBQAæ€§èƒ½æµ‹è¯•"""

    questions = ["æœ‰å¤šå°‘å‘˜å·¥?", "å¼ ä¸‰åœ¨å“ªä¸ªéƒ¨é—¨?", ...]

    latencies = []
    success_count = 0

    for _ in range(num_requests):
        q = random.choice(questions)

        start = time.time()
        response = requests.post(
            f"{api_url}/api/ask",
            json={"question": q},
            timeout=10
        )
        latency = (time.time() - start) * 1000

        if response.status_code == 200:
            success_count += 1
            latencies.append(latency)

    return {
        'success_rate': success_count / num_requests,
        'avg_latency_ms': np.mean(latencies),
        'p50_latency_ms': np.percentile(latencies, 50),
        'p95_latency_ms': np.percentile(latencies, 95),
        'p99_latency_ms': np.percentile(latencies, 99)
    }

# é¢„æœŸç»“æœ:
# æˆåŠŸç‡: >95%
# P95å»¶è¿Ÿ: <2000ms
# P99å»¶è¿Ÿ: <3000ms
```

---

## 5. ç»¼åˆæ€§èƒ½æŠ¥å‘Š

```python
def generate_performance_report():
    """ç”Ÿæˆå®Œæ•´æ€§èƒ½æŠ¥å‘Š"""

    print("=" * 80)
    print("PostgreSQL AIç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
    print("=" * 80)

    # 1. pgvectoræµ‹è¯•
    print("\nã€1ã€‘pgvectorå‘é‡æ£€ç´¢")
    vector_result = benchmark_pgvector(...)
    print(f"   å¹³å‡å»¶è¿Ÿ: {vector_result['avg_latency_ms']:.2f}ms")
    print(f"   P95å»¶è¿Ÿ: {vector_result['p95_latency_ms']:.2f}ms")
    print(f"   QPS: {vector_result['qps']:.0f}")

    # 2. Apache AGEæµ‹è¯•
    print("\nã€2ã€‘Apache AGEå›¾æŸ¥è¯¢")
    # ...

    # 3. Text-to-Cypheræµ‹è¯•
    print("\nã€3ã€‘Text-to-Cypherç”Ÿæˆ")
    t2c_result = benchmark_text2cypher(...)
    print(f"   ç¼“å­˜æœªå‘½ä¸­: {t2c_result['cache_miss_avg_ms']:.0f}ms")
    print(f"   ç¼“å­˜å‘½ä¸­: {t2c_result['cache_hit_avg_ms']:.0f}ms")
    print(f"   åŠ é€Ÿæ¯”: {t2c_result['speedup']:.0f}x")

    # 4. ç«¯åˆ°ç«¯KBQAæµ‹è¯•
    print("\nã€4ã€‘KBQAç«¯åˆ°ç«¯")
    kbqa_result = benchmark_kbqa_e2e(...)
    print(f"   æˆåŠŸç‡: {kbqa_result['success_rate']:.2%}")
    print(f"   P95å»¶è¿Ÿ: {kbqa_result['p95_latency_ms']:.0f}ms")
    print(f"   P99å»¶è¿Ÿ: {kbqa_result['p99_latency_ms']:.0f}ms")

    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆï¼")

if __name__ == '__main__':
    generate_performance_report()
```

---

## 6. æ€§èƒ½ä¼˜åŒ–å»ºè®®

åŸºäºæµ‹è¯•ç»“æœçš„ä¼˜åŒ–å»ºè®®ï¼š

| ç»„ä»¶ | å½“å‰ | ç›®æ ‡ | ä¼˜åŒ–æªæ–½ |
|------|------|------|----------|
| pgvector | 3ms | <2ms | è°ƒæ•´ef_searchå‚æ•° |
| AGEå›¾æŸ¥è¯¢ | 150ms | <100ms | æ·»åŠ å›¾ç´¢å¼• |
| LLMè°ƒç”¨ | 600ms | <500ms | ä½¿ç”¨GPT-4-turbo |
| ç«¯åˆ°ç«¯ | 2000ms | <1500ms | å¼‚æ­¥å¹¶è¡Œ |

---

**è¿”å›**: [æ€§èƒ½åŸºå‡†æµ‹è¯•é¦–é¡µ](./README.md)
