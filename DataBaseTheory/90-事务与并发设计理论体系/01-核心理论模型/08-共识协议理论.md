# 08 | 共识协议理论

> **理论定位**: 共识协议是分布式系统一致性的核心，本文档提供Raft和Paxos的理论分析，并映射到LSEM L2层。

---

## 一、共识问题

### 1.1 问题定义

**定义1.1 (共识问题)**:

$$Consensus: \text{Multiple processes agree on a single value}$$

**形式化要求**:

1. **终止性** (Termination): 所有正确进程最终决定一个值
2. **一致性** (Agreement): 所有正确进程决定相同的值
3. **有效性** (Validity): 决定的值必须是某个进程提议的

**数学表达**:

$$\forall i, j \in \text{Processes}: decided(i) = decided(j)$$

### 1.2 FLP不可能定理

**定理1.1 (FLP Impossibility, 1985)**:

$$\text{Asynchronous network} \land \text{1 process may fail} \implies$$
$$\neg\exists \text{deterministic consensus algorithm with guaranteed termination}$$

**证明思路**:

1. 存在**临界配置** (Critical Configuration): 一个消息的延迟决定结果
2. 可以构造**无限延迟**的执行序列
3. 导致算法永远无法终止

**实际影响**: 实际系统使用**随机化**或**超时**绕过

---

## 二、Raft协议

### 2.1 核心思想

**设计目标**: **可理解性** (Understandability)

**关键机制**:

- Leader选举
- 日志复制
- 安全性保证

### 2.2 Leader选举

**算法2.1: RequestVote RPC**

```python
class RaftNode:
    def request_vote(self, term, candidate_id, last_log_index, last_log_term):
        # 规则1: term过期，拒绝
        if term < self.current_term:
            return (self.current_term, False)

        # 规则2: 已投票给其他候选人，拒绝
        if self.voted_for is not None and self.voted_for != candidate_id:
            return (self.current_term, False)

        # 规则3: 候选人日志不够新，拒绝
        my_last_term = self.log[-1].term if self.log else 0
        my_last_index = len(self.log)

        if (last_log_term < my_last_term or
            (last_log_term == my_last_term and last_log_index < my_last_index)):
            return (self.current_term, False)

        # 投票给候选人
        self.voted_for = candidate_id
        self.reset_election_timer()
        return (self.current_term, True)
```

**定理2.1 (Election Safety)**:

$$\forall \text{term } t: \text{At most one leader in term } t$$

**证明**:

假设在term $t$有两个Leader: $L_1, L_2$

则两者都获得了**多数派**投票:

$$Votes(L_1) > \frac{n}{2} \land Votes(L_2) > \frac{n}{2}$$

因为 $n$ 个节点，多数派至少 $\lceil\frac{n+1}{2}\rceil$ 个

$$Votes(L_1) + Votes(L_2) > n$$

**矛盾**: 总投票数超过节点数（每个节点只能投一票）

$$\therefore \text{At most one leader} \quad \square$$

### 2.3 日志复制

**算法2.2: AppendEntries RPC**

```python
class RaftLeader:
    def replicate_entry(self, entry):
        # 1. 追加到本地日志
        entry.term = self.current_term
        entry.index = len(self.log) + 1
        self.log.append(entry)

        # 2. 并行发送给所有Follower
        acks = 1  # 自己算一个

        for follower in self.followers:
            success = self.send_append_entries(
                follower,
                prev_log_index=entry.index - 1,
                prev_log_term=self.log[entry.index - 2].term if entry.index > 1 else 0,
                entries=[entry],
                leader_commit=self.commit_index
            )

            if success:
                acks += 1

        # 3. 多数派确认后提交
        if acks > len(self.followers) // 2:
            self.commit_index = entry.index
            return True

        return False
```

**定理2.2 (Log Matching)**:

$$\forall i, j, k: log_i[k].term = log_j[k].term \implies$$
$$\forall m \leq k: log_i[m] = log_j[m]$$

**语义**: 如果两个日志在某索引处term相同，则之前的所有条目都相同

**证明**: 归纳法

**Base case** ($k=1$): 显然成立

**Inductive step**: 假设 $k-1$ 成立，证明 $k$ 成立

- AppendEntries RPC要求 `prev_log_term` 匹配
- 匹配成功说明前 $k-1$ 条相同（归纳假设）
- Leader只在前条目匹配时才追加
- 因此第 $k$ 条也相同 ∎

### 2.4 安全性定理

**定理2.3 (State Machine Safety)**:

$$\forall i, j: commit\_index_i = commit\_index_j \implies$$
$$log_i[1..commit\_index_i] = log_j[1..commit\_index_j]$$

**语义**: 已提交的日志不会丢失

**证明要点**:

1. **Leader Completeness**: 新Leader包含所有已提交日志
2. **Log Matching**: term相同的条目之前的都相同
3. **Election Restriction**: 日志不够新的节点无法当选

完整证明见: `03-证明与形式化/05-共识协议证明.md#定理2.3`

---

## 三、Paxos协议

### 3.1 Basic Paxos

**角色**:

- **Proposer**: 提议值
- **Acceptor**: 投票决定
- **Learner**: 学习决定的值

**两阶段**:

**Phase 1a (Prepare)**:

```python
class Proposer:
    def prepare(self, n):
        """
        n: 提案编号（全局唯一且递增）
        """
        for acceptor in self.acceptors:
            acceptor.prepare(n)
```

**Phase 1b (Promise)**:

```python
class Acceptor:
    def prepare(self, n):
        """返回Promise或拒绝"""
        if n > self.max_prepare_n:
            self.max_prepare_n = n

            # 返回之前接受的最大提案
            return Promise(n, self.accepted_n, self.accepted_value)
        else:
            return Reject(self.max_prepare_n)
```

**Phase 2a (Accept)**:

```python
class Proposer:
    def accept(self, n, value):
        """选择value并请求接受"""
        # 收集Promise，选择已接受中n最大的value
        # 如果没有已接受的，使用自己的value

        for acceptor in self.acceptors:
            acceptor.accept(n, value)
```

**Phase 2b (Accepted)**:

```python
class Acceptor:
    def accept(self, n, value):
        """接受提案"""
        if n >= self.max_prepare_n:
            self.max_prepare_n = n
            self.accepted_n = n
            self.accepted_value = value
            return Accepted(n, value)
        else:
            return Reject(self.max_prepare_n)
```

**定理3.1 (Paxos正确性)**:

$$\forall \text{decided values } v_1, v_2: v_1 = v_2$$

**证明**: 通过提案编号的全序性保证

### 3.2 Multi-Paxos

**改进**: 选举稳定的Leader，减少Phase 1

```python
class MultiPaxos:
    def __init__(self):
        self.leader = None
        self.log = []

    def propose(self, value):
        if self.leader is None:
            # 需要Leader选举（执行Phase 1）
            self.elect_leader()

        # Leader直接执行Phase 2
        index = len(self.log) + 1
        self.leader.accept(index, value)

        if self.receive_majority_acks():
            self.log.append(value)
            return SUCCESS
```

**与Raft的关系**:

$$Raft \approx Multi\text{-}Paxos + \text{Strong Leader} + \text{Log Matching}$$

---

## 四、共识协议对比

### 4.1 Raft vs Paxos

| 维度 | Raft | Paxos |
|-----|------|-------|
| **可理解性** | 高（设计目标） | 低（难理解） |
| **Leader** | 强Leader | 弱Leader |
| **日志顺序** | 严格连续 | 可有空洞 |
| **选举** | 随机超时 | 提案编号 |
| **实现复杂度** | 低 | 高 |
| **理论优雅性** | 中 | 高 |

### 4.2 性能对比

| 指标 | Raft | Multi-Paxos | 说明 |
|-----|------|------------|------|
| **延迟** | 1.5 RTT | 1 RTT | Paxos可跳过Phase 1 |
| **吞吐量** | 相似 | 相似 | 都是多数派 |
| **Leader变更** | 快 | 慢 | Raft有超时机制 |

---

## 五、与LSEM L2层的映射

### 5.1 状态空间映射

| LSEM L2 | Raft | Paxos |
|---------|------|-------|
| **状态单元** | Log Entry | Accepted Proposal |
| **时空戳** | (term, index) | Proposal Number |
| **可见性** | commitIndex | Learned Value |
| **冲突仲裁** | Leader选举 | 提案编号竞争 |

### 5.2 可见性规则

**L2可见性 (Raft)**:

$$Visible_{L2}(entry) \iff entry.index \leq commitIndex$$

**实现**:

```python
def visible_l2_raft(entry, commit_index, node_id):
    if entry.index <= commit_index:
        return True  # 已提交，对所有节点可见

    # 未提交的日志仅对Leader可见
    return node_id == current_leader_id
```

**L2可见性 (Paxos)**:

$$Visible_{L2}(value) \iff \text{Learned by majority}$$

### 5.3 与L0/L1对比

| 层次 | 协调机制 | 一致性 | 容错性 |
|-----|---------|--------|--------|
| **L0** | 锁管理器 | 串行化 | 无（单机） |
| **L1** | 借用检查 | 编译期 | 无（进程） |
| **L2** | 共识协议 | 线性一致 | ⌊n/2⌋故障 |

**跨层映射**:

$$\text{L2 Raft日志} \approx \text{L0 WAL日志}$$
$$\text{L2 Leader选举} \approx \text{L0 Master选举}$$

---

## 六、CAP与共识

### 6.1 Raft的CAP定位

**选择**: **CP系统**（一致性 + 分区容错）

**分析**:

- **C**: ✅ 多数派写入保证一致性
- **A**: ❌ 少数派分区无法提供服务
- **P**: ✅ 网络分区时选择多数派

**可用性计算**:

$$A_{Raft} = P(\text{majority alive}) = \sum_{k=\lceil\frac{n+1}{2}\rceil}^{n} \binom{n}{k} p^k (1-p)^{n-k}$$

其中 $p$ 是单节点可用性

**示例** (n=5, p=0.99):

$$A_{Raft} \approx 0.9999 = 99.99\%$$

### 6.2 网络分区处理

**场景**: 5节点集群分区为 {N1, N2} 和 {N3, N4, N5}

```
正常状态:
N1(Leader) ←→ N2 ←→ N3 ←→ N4 ←→ N5

分区后:
Partition 1: N1(Leader) ←→ N2  (少数派)
Partition 2: N3 ←→ N4 ←→ N5     (多数派)
```

**Raft行为**:

```python
# Partition 1 (少数派)
def partition1_behavior():
    # N1收不到多数派心跳应答
    if majority_acks < 3:
        # 停止接受写入
        return NOT_AVAILABLE

    # 可能被新Leader取代

# Partition 2 (多数派)
def partition2_behavior():
    # 选举超时触发
    if no_leader_heartbeat():
        start_election()

    # N3或N4或N5当选为新Leader
    new_leader = elect_leader()

    # 多数派继续服务
    return AVAILABLE
```

**一致性保证**:

- Partition 1的N1发现自己是少数派后**停止服务**
- Partition 2选举新Leader继续服务
- 网络恢复后，N1的日志被覆盖（term更大）

---

## 七、活性分析

### 7.1 活性保证

**定理7.1 (Raft活性)**:

$$\text{Eventually stable network} \implies \text{Eventually elect a leader}$$

**假设**:

1. 网络最终恢复
2. 节点时钟漂移有界
3. 消息延迟有上界

**证明要点**:

1. **随机超时**: 避免选举冲突
2. **term递增**: 保证进展
3. **多数派**: 总能形成quorum

**引理7.1**: 如果两个候选人同时开始选举，随机超时保证其中一个会先获得多数派投票

### 7.2 网络分区恢复

**场景**: 分区恢复后的同步

```python
def handle_partition_recovery():
    # 旧Leader (term=5) 检测到新Leader (term=8)
    if received_term > self.current_term:
        # 降级为Follower
        self.state = FOLLOWER
        self.current_term = received_term
        self.leader = new_leader_id

    # 日志同步
    def sync_log():
        # 找到最后一个匹配点
        match_index = find_last_match()

        # 删除冲突条目
        self.log = self.log[:match_index]

        # 复制新Leader的日志
        self.log.extend(new_leader_log[match_index:])
```

---

## 八、工程实践

### 8.1 etcd (Raft实现)

**架构**:

```
┌─────────────────────────────────┐
│          etcd Cluster            │
├─────────────────────────────────┤
│                                 │
│  Client → Leader (写请求)        │
│            ↓                    │
│         Raft Module             │
│            ↓                    │
│      Log Replication            │
│         ↓     ↓     ↓           │
│      Follower1  Follower2       │
│            ↓                    │
│      多数派确认                   │
│            ↓                    │
│      Apply to StateMachine      │
│            ↓                    │
│      Return to Client           │
│                                 │
└─────────────────────────────────┘
```

**关键配置**:

```yaml
# etcd配置
election-timeout: 1000ms      # 选举超时
heartbeat-interval: 100ms     # 心跳间隔
snapshot-count: 10000         # 快照间隔
max-wal-size: 1GB            # WAL上限
```

**性能指标**:

- 写入延迟: P99 <10ms
- 吞吐量: ~10K writes/sec (3节点)

### 8.2 TiKV (Raft + RocksDB)

**分层架构**:

```
应用层 (TiDB)
    ↓ SQL
调度层 (PD - Placement Driver)
    ↓ 分区路由
存储层 (TiKV)
    ├─ Raft (复制)
    └─ RocksDB (持久化)
```

**Region概念**:

```python
class Region:
    """
    数据分片单位
    每个Region是一个Raft Group
    """
    def __init__(self, id, start_key, end_key):
        self.id = id
        self.start_key = start_key
        self.end_key = end_key
        self.peers = []  # Raft节点列表
        self.leader = None

    def write(self, key, value):
        # 路由到Leader
        if key not in (self.start_key, self.end_key):
            return ERROR_OUT_OF_RANGE

        # 通过Raft复制
        return self.leader.raft_propose(key, value)
```

---

## 九、总结

### 9.1 核心贡献

**理论贡献**:

1. **共识问题形式化**（第一章）
2. **FLP不可能定理**（第1.2节）
3. **Raft安全性定理**（定理2.1-2.3）
4. **与LSEM L2映射**（第五章）

**工程价值**:

1. **Raft算法详解**（第二章）
2. **Paxos协议分析**（第三章）
3. **工程实践案例**（第八章）

### 9.2 关键公式

**共识一致性**:

$$\forall i, j: decided_i = decided_j$$

**Raft安全性**:

$$commitIndex_i = commitIndex_j \implies log_i[1..k] = log_j[1..k]$$

**可用性计算**:

$$A_{Raft} = P(\text{majority alive})$$

### 9.3 设计原则

1. **多数派原则**: 容忍⌊n/2⌋故障
2. **强Leader**: 简化日志复制
3. **term递增**: 保证活性
4. **随机化**: 避免冲突

---

## 十、延伸阅读

**理论基础**:

- Fischer, M. J., et al. (1985). "Impossibility of Distributed Consensus with One Faulty Process" (FLP定理)
- Lamport, L. (1998). "The Part-Time Parliament" (Paxos原始论文)
- Lamport, L. (2001). "Paxos Made Simple"

**Raft**:

- Ongaro, D., & Ousterhout, J. (2014). "In Search of an Understandable Consensus Algorithm"
- Ongaro, D. (2014). PhD Thesis (Stanford)

**工程实践**:

- etcd Documentation
- TiKV Design Documents
- Consul Architecture

**扩展方向**:

- `03-证明与形式化/05-共识协议证明.md` → Raft完整证明
- `04-分布式扩展/03-共识协议(Raft_Paxos).md` → 详细协议分析
- `05-实现机制/06-跨层协同设计.md` → Raft + PostgreSQL集成

---

**版本**: 1.0.0
**最后更新**: 2025-12-05
**关联文档**:

- `01-核心理论模型/01-分层状态演化模型(LSEM).md`
- `01-核心理论模型/04-CAP理论与权衡.md`
- `04-分布式扩展/03-共识协议(Raft_Paxos).md`
