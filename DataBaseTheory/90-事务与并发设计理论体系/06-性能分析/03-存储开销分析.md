# 03 | å­˜å‚¨å¼€é”€åˆ†æ

> **åˆ†æå®šä½**: æœ¬æ–‡æ¡£æ·±åº¦é‡åŒ–åˆ†æMVCCçš„å­˜å‚¨å¼€é”€ï¼ŒåŒ…å«ç†è®ºæ¨å¯¼ã€åä¾‹åˆ†æã€å®é™…æµ‹è¯•æ•°æ®å’Œä¼˜åŒ–ç­–ç•¥ã€‚

---

## ğŸ“‘ ç›®å½•

- [03 | å­˜å‚¨å¼€é”€åˆ†æ](#03--å­˜å‚¨å¼€é”€åˆ†æ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€å­˜å‚¨å¼€é”€åˆ†æèƒŒæ™¯ä¸æ¼”è¿›](#ä¸€å­˜å‚¨å¼€é”€åˆ†æèƒŒæ™¯ä¸æ¼”è¿›)
    - [0.1 ä¸ºä»€ä¹ˆéœ€è¦å­˜å‚¨å¼€é”€åˆ†æï¼Ÿ](#01-ä¸ºä»€ä¹ˆéœ€è¦å­˜å‚¨å¼€é”€åˆ†æ)
    - [0.2 å­˜å‚¨å¼€é”€åˆ†æçš„æ ¸å¿ƒæŒ‘æˆ˜](#02-å­˜å‚¨å¼€é”€åˆ†æçš„æ ¸å¿ƒæŒ‘æˆ˜)
  - [äºŒã€å­˜å‚¨å¼€é”€ç†è®ºæ¨¡å‹](#äºŒå­˜å‚¨å¼€é”€ç†è®ºæ¨¡å‹)
    - [1.1 å®Œæ•´æ•°å­¦æ¨¡å‹](#11-å®Œæ•´æ•°å­¦æ¨¡å‹)
    - [1.2 PostgreSQLå…ƒç»„ç»“æ„å¼€é”€](#12-postgresqlå…ƒç»„ç»“æ„å¼€é”€)
  - [äºŒã€ç‰ˆæœ¬é“¾å¼€é”€æ·±åº¦åˆ†æ](#äºŒç‰ˆæœ¬é“¾å¼€é”€æ·±åº¦åˆ†æ)
    - [2.1 ç‰ˆæœ¬ç´¯ç§¯å¾®åˆ†æ–¹ç¨‹](#21-ç‰ˆæœ¬ç´¯ç§¯å¾®åˆ†æ–¹ç¨‹)
    - [2.2 å®é™…æ¡ˆä¾‹è®¡ç®—](#22-å®é™…æ¡ˆä¾‹è®¡ç®—)
    - [2.3 ç‰ˆæœ¬é“¾å¯¹æŸ¥è¯¢æ€§èƒ½çš„å½±å“](#23-ç‰ˆæœ¬é“¾å¯¹æŸ¥è¯¢æ€§èƒ½çš„å½±å“)
  - [ä¸‰ã€ç´¢å¼•è†¨èƒ€æœºåˆ¶](#ä¸‰ç´¢å¼•è†¨èƒ€æœºåˆ¶)
    - [3.1 ç´¢å¼•è†¨èƒ€çš„æ ¹æº](#31-ç´¢å¼•è†¨èƒ€çš„æ ¹æº)
    - [3.2 HOTï¼ˆHeap-Only Tupleï¼‰ä¼˜åŒ–](#32-hotheap-only-tupleä¼˜åŒ–)
    - [3.3 Fillfactorä¼˜åŒ–](#33-fillfactorä¼˜åŒ–)
  - [å››ã€çœŸå®æ¡ˆä¾‹åˆ†æ](#å››çœŸå®æ¡ˆä¾‹åˆ†æ)
    - [æ¡ˆä¾‹1: æŸç”µå•†å…¬å¸è®¢å•è¡¨è†¨èƒ€](#æ¡ˆä¾‹1-æŸç”µå•†å…¬å¸è®¢å•è¡¨è†¨èƒ€)
  - [äº”ã€åä¾‹ä¸é”™è¯¯ä¼˜åŒ–](#äº”åä¾‹ä¸é”™è¯¯ä¼˜åŒ–)
    - [åä¾‹1: VACUUMä¸æ˜¯è¶Šé¢‘ç¹è¶Šå¥½](#åä¾‹1-vacuumä¸æ˜¯è¶Šé¢‘ç¹è¶Šå¥½)
    - [åä¾‹2: fillfactorè¶Šå°è¶Šå¥½ï¼Ÿ](#åä¾‹2-fillfactorè¶Šå°è¶Šå¥½)
    - [åä¾‹3: å­˜å‚¨å¼€é”€åˆ†æä¸å®Œæ•´](#åä¾‹3-å­˜å‚¨å¼€é”€åˆ†æä¸å®Œæ•´)
    - [åä¾‹4: ç‰ˆæœ¬é“¾é•¿åº¦é¢„æµ‹é”™è¯¯](#åä¾‹4-ç‰ˆæœ¬é“¾é•¿åº¦é¢„æµ‹é”™è¯¯)
    - [åä¾‹5: ç´¢å¼•è†¨èƒ€åˆ†æè¢«å¿½ç•¥](#åä¾‹5-ç´¢å¼•è†¨èƒ€åˆ†æè¢«å¿½ç•¥)
    - [åä¾‹6: å­˜å‚¨ä¼˜åŒ–ç­–ç•¥ä¸å½“](#åä¾‹6-å­˜å‚¨ä¼˜åŒ–ç­–ç•¥ä¸å½“)
  - [å…­ã€ä¼˜åŒ–ç­–ç•¥å®Œæ•´æŒ‡å—](#å…­ä¼˜åŒ–ç­–ç•¥å®Œæ•´æŒ‡å—)
    - [6.1 å†³ç­–æ ‘](#61-å†³ç­–æ ‘)
    - [6.2 ç›‘æ§SQLå·¥å…·åŒ…](#62-ç›‘æ§sqlå·¥å…·åŒ…)
  - [ä¸ƒã€å·¥å…·ä¸ç›‘æ§](#ä¸ƒå·¥å…·ä¸ç›‘æ§)
    - [7.1 pgstattupleæ‰©å±•](#71-pgstattupleæ‰©å±•)
    - [7.2 è‡ªåŠ¨åŒ–å‘Šè­¦](#72-è‡ªåŠ¨åŒ–å‘Šè­¦)
  - [å…«ã€å®Œæ•´å­˜å‚¨åˆ†æå·¥å…·å®ç°](#å…«å®Œæ•´å­˜å‚¨åˆ†æå·¥å…·å®ç°)
    - [8.1 ç‰ˆæœ¬é“¾é•¿åº¦åˆ†æå·¥å…·](#81-ç‰ˆæœ¬é“¾é•¿åº¦åˆ†æå·¥å…·)
    - [8.2 å­˜å‚¨è†¨èƒ€ç›‘æ§å·¥å…·](#82-å­˜å‚¨è†¨èƒ€ç›‘æ§å·¥å…·)
  - [ä¹ã€å®é™…åº”ç”¨æ¡ˆä¾‹](#ä¹å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [9.1 æ¡ˆä¾‹: è®¢å•è¡¨å­˜å‚¨ä¼˜åŒ–](#91-æ¡ˆä¾‹-è®¢å•è¡¨å­˜å‚¨ä¼˜åŒ–)
    - [9.2 æ¡ˆä¾‹: ç´¢å¼•è†¨èƒ€ä¼˜åŒ–](#92-æ¡ˆä¾‹-ç´¢å¼•è†¨èƒ€ä¼˜åŒ–)
  - [åã€å®Œæ•´å®ç°ä»£ç ](#åå®Œæ•´å®ç°ä»£ç )
    - [10.1 å­˜å‚¨å¼€é”€è®¡ç®—å™¨å®Œæ•´å®ç°](#101-å­˜å‚¨å¼€é”€è®¡ç®—å™¨å®Œæ•´å®ç°)
    - [10.2 ç‰ˆæœ¬é“¾åˆ†æå™¨å®Œæ•´å®ç°](#102-ç‰ˆæœ¬é“¾åˆ†æå™¨å®Œæ•´å®ç°)
    - [10.3 å­˜å‚¨ä¼˜åŒ–å»ºè®®å™¨å®Œæ•´å®ç°](#103-å­˜å‚¨ä¼˜åŒ–å»ºè®®å™¨å®Œæ•´å®ç°)
  - [åä¸€ã€å­˜å‚¨å¼€é”€åˆ†æå¯è§†åŒ–](#åä¸€å­˜å‚¨å¼€é”€åˆ†æå¯è§†åŒ–)
    - [11.1 å­˜å‚¨å¼€é”€åˆ†è§£æ¶æ„å›¾](#111-å­˜å‚¨å¼€é”€åˆ†è§£æ¶æ„å›¾)
    - [11.2 ç‰ˆæœ¬é“¾æ¼”åŒ–æµç¨‹å›¾](#112-ç‰ˆæœ¬é“¾æ¼”åŒ–æµç¨‹å›¾)
    - [11.3 å­˜å‚¨ä¼˜åŒ–å†³ç­–æ ‘](#113-å­˜å‚¨ä¼˜åŒ–å†³ç­–æ ‘)

---

## ä¸€ã€å­˜å‚¨å¼€é”€åˆ†æèƒŒæ™¯ä¸æ¼”è¿›

### 0.1 ä¸ºä»€ä¹ˆéœ€è¦å­˜å‚¨å¼€é”€åˆ†æï¼Ÿ

**å†å²èƒŒæ™¯**:

åœ¨MVCCç³»ç»Ÿä¸­ï¼Œå­˜å‚¨å¼€é”€æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚
MVCCé€šè¿‡ç»´æŠ¤å¤šä¸ªç‰ˆæœ¬æ¥å®ç°å¹¶å‘æ§åˆ¶ï¼Œä½†è¿™ä¹Ÿå¸¦æ¥äº†å­˜å‚¨å¼€é”€ã€‚
ä»PostgreSQLæ—©æœŸç‰ˆæœ¬å¼€å§‹ï¼Œå­˜å‚¨è†¨èƒ€é—®é¢˜å°±ä¸€ç›´å›°æ‰°ç€ç”¨æˆ·ã€‚
ç†è§£å­˜å‚¨å¼€é”€çš„æ„æˆå’Œæ¼”åŒ–è§„å¾‹ï¼Œæœ‰åŠ©äºä¼˜åŒ–å­˜å‚¨ä½¿ç”¨ã€é¿å…å­˜å‚¨è†¨èƒ€ã€è¯Šæ–­å­˜å‚¨é—®é¢˜ã€‚

**ç†è®ºåŸºç¡€**:

```text
å­˜å‚¨å¼€é”€åˆ†æçš„æ ¸å¿ƒ:
â”œâ”€ é—®é¢˜: MVCCå¦‚ä½•å½±å“å­˜å‚¨å¼€é”€ï¼Ÿ
â”œâ”€ ç†è®º: å­˜å‚¨å¼€é”€ç†è®ºï¼ˆç‰ˆæœ¬é“¾ã€æ­»å…ƒç»„ï¼‰
â””â”€ åˆ†æ: é‡åŒ–åˆ†æï¼ˆå…¬å¼ã€æ¨¡å‹ï¼‰

ä¸ºä»€ä¹ˆéœ€è¦å­˜å‚¨å¼€é”€åˆ†æ?
â”œâ”€ æ— åˆ†æ: å­˜å‚¨è†¨èƒ€é—®é¢˜æ— æ³•è§£å†³
â”œâ”€ ç»éªŒæ–¹æ³•: ä¸å®Œæ•´ï¼Œå¯èƒ½æœ‰é—æ¼
â””â”€ é‡åŒ–åˆ†æ: ä¸¥æ ¼ã€å®Œæ•´ã€å¯é¢„æµ‹
```

**å®é™…åº”ç”¨èƒŒæ™¯**:

```text
å­˜å‚¨å¼€é”€åˆ†ææ¼”è¿›:
â”œâ”€ æ—©æœŸé—®é¢˜ (1990s-2000s)
â”‚   â”œâ”€ å­˜å‚¨è†¨èƒ€é—®é¢˜
â”‚   â”œâ”€ é—®é¢˜: ç¼ºä¹ç³»ç»ŸåŒ–åˆ†æ
â”‚   â””â”€ ç»“æœ: å­˜å‚¨æŒç»­è†¨èƒ€
â”‚
â”œâ”€ ç³»ç»ŸåŒ–åˆ†æ (2000s-2010s)
â”‚   â”œâ”€ å­˜å‚¨å¼€é”€æ¨¡å‹
â”‚   â”œâ”€ ç‰ˆæœ¬é“¾åˆ†æ
â”‚   â””â”€ VACUUMä¼˜åŒ–
â”‚
â””â”€ ç°ä»£å·¥å…· (2010s+)
    â”œâ”€ å­˜å‚¨åˆ†æå·¥å…·
    â”œâ”€ è‡ªåŠ¨åŒ–ç›‘æ§
    â””â”€ æ™ºèƒ½ä¼˜åŒ–å»ºè®®
```

**ä¸ºä»€ä¹ˆå­˜å‚¨å¼€é”€åˆ†æé‡è¦ï¼Ÿ**

1. **æˆæœ¬æ§åˆ¶**: æ§åˆ¶å­˜å‚¨æˆæœ¬
2. **æ€§èƒ½ä¼˜åŒ–**: ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
3. **é—®é¢˜è¯Šæ–­**: è¯Šæ–­å­˜å‚¨è†¨èƒ€é—®é¢˜
4. **ç³»ç»Ÿè®¾è®¡**: ä¸ºç³»ç»Ÿè®¾è®¡æä¾›å‚è€ƒ

**åä¾‹: æ— åˆ†æçš„å­˜å‚¨é—®é¢˜**:

```text
é”™è¯¯è®¾è®¡: æ— å­˜å‚¨å¼€é”€åˆ†æï¼Œç›²ç›®ä¼˜åŒ–
â”œâ”€ åœºæ™¯: å­˜å‚¨è†¨èƒ€é—®é¢˜
â”œâ”€ é—®é¢˜: ä¸ç†è§£å­˜å‚¨å¼€é”€æ„æˆ
â”œâ”€ ç»“æœ: ä¼˜åŒ–æ–¹å‘é”™è¯¯ï¼Œå­˜å‚¨æŒç»­è†¨èƒ€
â””â”€ åæœ: å­˜å‚¨æˆæœ¬å¢åŠ  âœ—

æ­£ç¡®è®¾è®¡: ä½¿ç”¨å­˜å‚¨å¼€é”€åˆ†æ
â”œâ”€ æ–¹æ¡ˆ: é‡åŒ–åˆ†æå­˜å‚¨å¼€é”€
â”œâ”€ ç»“æœ: é’ˆå¯¹æ€§åœ°ä¼˜åŒ–ï¼Œå­˜å‚¨ç¨³å®š
â””â”€ æ•ˆæœ: å­˜å‚¨æˆæœ¬é™ä½50%+ âœ“
```

### 0.2 å­˜å‚¨å¼€é”€åˆ†æçš„æ ¸å¿ƒæŒ‘æˆ˜

**å†å²èƒŒæ™¯**:

å­˜å‚¨å¼€é”€åˆ†æé¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜åŒ…æ‹¬ï¼šå¦‚ä½•å‡†ç¡®é‡åŒ–å„ç§å­˜å‚¨å¼€é”€ã€å¦‚ä½•é¢„æµ‹å­˜å‚¨æ¼”åŒ–ã€å¦‚ä½•ä¼˜åŒ–å­˜å‚¨ä½¿ç”¨ã€å¦‚ä½•å¹³è¡¡å­˜å‚¨å’Œæ€§èƒ½ç­‰ã€‚è¿™äº›æŒ‘æˆ˜ä¿ƒä½¿ç ”ç©¶è€…ä¸æ–­ä¼˜åŒ–å­˜å‚¨å¼€é”€æ¨¡å‹ã€‚

**ç†è®ºåŸºç¡€**:

```text
å­˜å‚¨å¼€é”€åˆ†ææŒ‘æˆ˜:
â”œâ”€ é‡åŒ–æŒ‘æˆ˜: å¦‚ä½•å‡†ç¡®é‡åŒ–å„ç§å­˜å‚¨å¼€é”€
â”œâ”€ é¢„æµ‹æŒ‘æˆ˜: å¦‚ä½•é¢„æµ‹å­˜å‚¨æ¼”åŒ–
â”œâ”€ ä¼˜åŒ–æŒ‘æˆ˜: å¦‚ä½•ä¼˜åŒ–å­˜å‚¨ä½¿ç”¨
â””â”€ å¹³è¡¡æŒ‘æˆ˜: å¦‚ä½•å¹³è¡¡å­˜å‚¨å’Œæ€§èƒ½

è§£å†³æ–¹æ¡ˆ:
â”œâ”€ é‡åŒ–: å­˜å‚¨å¼€é”€æ¨¡å‹å’Œå…¬å¼
â”œâ”€ é¢„æµ‹: å­˜å‚¨æ¼”åŒ–æ¨¡å‹
â”œâ”€ ä¼˜åŒ–: VACUUMç­–ç•¥
â””â”€ å¹³è¡¡: å­˜å‚¨-æ€§èƒ½æƒè¡¡çŸ©é˜µ
```

---

## äºŒã€å­˜å‚¨å¼€é”€ç†è®ºæ¨¡å‹

### 1.1 å®Œæ•´æ•°å­¦æ¨¡å‹

**å®šç†1.1 (MVCCå­˜å‚¨æ€»å¼€é”€)**:

\[
Storage_{total} = Storage_{base} + Storage_{versions} + Storage_{indexes} + Storage_{overhead} + Storage_{WAL}
\]

**è¯¦ç»†æ¨å¯¼**:

**åŸºç¡€å­˜å‚¨**:
\[
Storage_{base} = \sum_{table} TupleSize \times RowCount_{active}
\]

**ç‰ˆæœ¬é“¾å­˜å‚¨**:
\[
Storage_{versions} = \sum_{table} TupleSize \times \sum_{row} (ChainLength_i - 1)
\]

**ç´¢å¼•å­˜å‚¨**ï¼ˆè€ƒè™‘è†¨èƒ€ï¼‰:
\[
Storage_{indexes} = \sum_{index} IndexEntrySize \times NumEntries \times (1 + BloatFactor)
\]

**å¼€é”€å…ƒæ•°æ®**ï¼ˆtuple header, page headerç­‰ï¼‰:
\[
Storage_{overhead} = \sum_{page} (PageHeaderSize + \sum_{tuple} TupleHeaderSize)
\]

**WALå½’æ¡£**ï¼ˆå¦‚æœå¯ç”¨ï¼‰:
\[
Storage_{WAL} = WAL_{generation\_rate} \times Retention_{period}
\]

### 1.2 PostgreSQLå…ƒç»„ç»“æ„å¼€é”€

**å®Œæ•´å…ƒç»„ç»“æ„**ï¼ˆæºç åˆ†æï¼‰:

```c
// src/include/access/htup_details.h
struct HeapTupleHeaderData {
    union {
        HeapTupleFields t_heap;  // xmin, xmax, cid, cmax
        DatumTupleFields t_datum;
    } t_choice;

    ItemPointerData t_ctid;  // 6 bytes: ç‰ˆæœ¬é“¾æŒ‡é’ˆ

    uint16 t_infomask2;      // 2 bytes: å±æ€§æ•°é‡ç­‰
    uint16 t_infomask;       // 2 bytes: çŠ¶æ€æ ‡å¿—
    uint8  t_hoff;           // 1 byte: å¤´éƒ¨åç§»

    bits8  t_bits[FLEXIBLE_ARRAY_MEMBER];  // NULL bitmap
};

// æœ€å°å…ƒç»„å¤´éƒ¨ = 23 bytes
// åŠ ä¸Šå¯¹é½ = 24 bytes
```

**å®é™…å¼€é”€è®¡ç®—**:

```sql
CREATE TABLE storage_test (
    id INTEGER,
    name VARCHAR(50),
    value BIGINT
);

-- å­—æ®µå¤§å°:
-- id: 4 bytes
-- name: æœ€å¤š50 bytes + 1 byte (é•¿åº¦)
-- value: 8 bytes

-- ç†è®ºæœ€å°: 4 + 51 + 8 = 63 bytes

-- å®é™…å¤§å°:
INSERT INTO storage_test VALUES (1, 'test', 100);

SELECT pg_column_size(storage_test.*) AS tuple_size,
       pg_total_relation_size('storage_test') AS total_size
FROM storage_test;

-- ç»“æœ: tuple_size = 93 bytes
-- ç»„æˆ: 24 (header) + 4 (id) + 51 (name) + 8 (value) + 6 (alignment) = 93
```

**å¼€é”€å æ¯”**:

- å¤´éƒ¨: 24 / 93 = **25.8%**ï¼ˆå›ºå®šå¼€é”€ï¼ï¼‰
- æ•°æ®: 63 / 93 = 67.7%
- å¯¹é½: 6 / 93 = 6.5%

**ç»“è®º**: å°å…ƒç»„çš„å…ƒæ•°æ®å¼€é”€å¾ˆæ˜¾è‘—

---

## äºŒã€ç‰ˆæœ¬é“¾å¼€é”€æ·±åº¦åˆ†æ

### 2.1 ç‰ˆæœ¬ç´¯ç§¯å¾®åˆ†æ–¹ç¨‹

**å»ºç«‹åŠ¨æ€æ¨¡å‹**:

\[
\frac{dV(t)}{dt} = R_{update}(t) - R_{vacuum}(t)
\]

å…¶ä¸­:

- \(V(t)\): æ—¶åˆ»\(t\)çš„æ­»å…ƒç»„æ€»æ•°
- \(R_{update}(t)\): æ›´æ–°é€Ÿç‡ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
- \(R_{vacuum}(t)\): æ¸…ç†é€Ÿç‡

**ç¨³æ€è§£ï¼ˆå‡è®¾é€Ÿç‡æ’å®šï¼‰**:

\[
V_{steady} = R_{update} \times T_{vacuum}
\]

å…¶ä¸­\(T_{vacuum}\)æ˜¯VACUUMé—´éš”ã€‚

**æ¨å¯¼å¹³å‡é“¾é•¿**:

å‡è®¾æ›´æ–°å‡åŒ€åˆ†å¸ƒåœ¨\(N\)è¡Œï¼š

\[
AvgChainLength = 1 + \frac{V_{steady}}{N} = 1 + \frac{R_{update} \times T_{vacuum}}{N}
\]

### 2.2 å®é™…æ¡ˆä¾‹è®¡ç®—

**æ¡ˆä¾‹1: ç”µå•†è®¢å•è¡¨**:

```sql
-- è¡¨ç»“æ„
CREATE TABLE orders (
    order_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT,
    status VARCHAR(20),  -- é¢‘ç¹æ›´æ–°
    amount DECIMAL(10,2),
    created_at TIMESTAMP
);

-- ä¸šåŠ¡å‚æ•°:
-- æ€»è®¢å•æ•°: N = 10,000,000 (1åƒä¸‡)
-- çŠ¶æ€æ›´æ–°é¢‘ç‡: 100/ç§’ (æ”¯ä»˜/å‘è´§/å®Œæˆ)
-- VACUUMé—´éš”: 60ç§’

-- è®¡ç®—:
AvgChainLength = 1 + (100 Ã— 60) / 10,000,000
               = 1 + 6000 / 10,000,000
               = 1.0006

-- å­˜å‚¨è†¨èƒ€: 1.0006Ã— (å‡ ä¹æ— è†¨èƒ€) âœ“
```

**æ¡ˆä¾‹2: ç¤¾äº¤å¸–å­è¡¨ï¼ˆç¾éš¾æ€§è†¨èƒ€ï¼‰**:

```sql
-- è¡¨ç»“æ„
CREATE TABLE posts (
    post_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT,
    like_count INTEGER,  -- æé«˜é¢‘æ›´æ–°ï¼
    comment_count INTEGER,
    content TEXT
);

-- ä¸šåŠ¡å‚æ•°:
-- æ€»å¸–å­æ•°: N = 1,000,000 (100ä¸‡çƒ­é—¨å¸–)
-- ç‚¹èµæ›´æ–°: 10,000/ç§’ (çƒ­é—¨å¸–é¢‘ç¹æ›´æ–°)
-- VACUUMé—´éš”: 60ç§’

-- è®¡ç®—:
AvgChainLength = 1 + (10,000 Ã— 60) / 1,000,000
               = 1 + 600,000 / 1,000,000
               = 1.6

-- å­˜å‚¨è†¨èƒ€: 1.6Ã— (+60%å­˜å‚¨!) âš ï¸

-- å¦‚æœVACUUMé—´éš”å»¶è¿Ÿåˆ°5åˆ†é’Ÿ:
AvgChainLength = 1 + (10,000 Ã— 300) / 1,000,000
               = 1 + 3 = 4

-- å­˜å‚¨è†¨èƒ€: 4Ã— (+300%!) ğŸ”´ ç¾éš¾ï¼
```

**çœŸå®ç›‘æ§æ•°æ®**:

```sql
-- æŸ¥è¯¢å®é™…è†¨èƒ€æƒ…å†µ
SELECT schemaname, tablename,
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
       pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) -
                     pg_relation_size(schemaname||'.'||tablename)) AS index_size,
       n_dead_tup,
       n_live_tup,
       ROUND(100.0 * n_dead_tup / NULLIF(n_live_tup, 0), 2) AS dead_ratio
FROM pg_stat_user_tables
ORDER BY n_dead_tup DESC
LIMIT 10;

-- ç»“æœç¤ºä¾‹:
-- postsè¡¨: 100ä¸‡æ´»å…ƒç»„, 250ä¸‡æ­»å…ƒç»„, è†¨èƒ€ç‡250% ğŸ”´
```

### 2.3 ç‰ˆæœ¬é“¾å¯¹æŸ¥è¯¢æ€§èƒ½çš„å½±å“

**å®šç†2.1**: ç‰ˆæœ¬é“¾è¶Šé•¿ï¼Œå…¨è¡¨æ‰«æè¶Šæ…¢

**è¯æ˜**: é¡ºåºæ‰«æéœ€è¦æ£€æŸ¥æ¯ä¸ªå…ƒç»„å¯è§æ€§

\[
T_{scan} = \sum_{page} (T_{IO}(page) + \sum_{tuple \in page} T_{visibility}(tuple))
\]

ç‰ˆæœ¬é“¾é•¿åº¦ä¸º\(L\)æ—¶ï¼š

- æ­»å…ƒç»„æ•° = \(N \times (L-1)\)
- éœ€è¦æ£€æŸ¥çš„å…ƒç»„ = \(N \times L\)

\[
T_{scan}(L) = N \times L \times T_{visibility}
\]

**åä¾‹**: ç´¢å¼•æ‰«æä¸ä¸€å®šå¿«

```sql
-- åœºæ™¯: æŸ¥è¯¢æœ€è¿‘è®¢å•
EXPLAIN ANALYZE
SELECT * FROM orders
WHERE created_at > NOW() - INTERVAL '1 day'
ORDER BY created_at DESC
LIMIT 100;

-- ç´¢å¼•æ‰«æç»“æœ:
Index Scan using orders_created_at_idx
  -> è¯»å–105ä¸ªç´¢å¼•æ¡ç›®
  -> è®¿é—®105ä¸ªheapå…ƒç»„
  -> ä½†å…¶ä¸­80ä¸ªæ˜¯æ­»å…ƒç»„(ç‰ˆæœ¬é“¾)ï¼
  -> å®é™…åªè¿”å›25ä¸ªæ´»å…ƒç»„
  -> éœ€è¦ç»§ç»­æ‰«æç›´åˆ°100ä¸ª

-- ç‰ˆæœ¬é“¾è¶Šé•¿ï¼Œç´¢å¼•æ‰«æè¶Šæ…¢ï¼
```

---

## ä¸‰ã€ç´¢å¼•è†¨èƒ€æœºåˆ¶

### 3.1 ç´¢å¼•è†¨èƒ€çš„æ ¹æº

**PostgreSQLç´¢å¼•ç‰¹ç‚¹**: ç´¢å¼•æ¡ç›®æŒ‡å‘æ¯ä¸ªå…ƒç»„ç‰ˆæœ¬

```text
UPDATEæ“ä½œå¯¹ç´¢å¼•çš„å½±å“:

åŸå§‹çŠ¶æ€:
Row(id=1, name='Alice') â†’ Index[1] â†’ TID(0,1)

UPDATE name='Bob':
â”œâ”€ åˆ›å»ºæ–°ç‰ˆæœ¬: TID(0,2)
â”œâ”€ æ—§ç‰ˆæœ¬(0,1): æ ‡è®°åˆ é™¤
â””â”€ æ–°ç´¢å¼•æ¡ç›®: Index[1] â†’ TID(0,2)

ç»“æœ: ç´¢å¼•æœ‰2ä¸ªæ¡ç›®æŒ‡å‘åŒä¸€ä¸ªidï¼

å¤šæ¬¡UPDATEå:
Index[1] â†’ TID(0,1) [dead]
Index[1] â†’ TID(0,2) [dead]
Index[1] â†’ TID(0,3) [dead]
Index[1] â†’ TID(0,4) [alive]

ç´¢å¼•è†¨èƒ€4å€ï¼
```

### 3.2 HOTï¼ˆHeap-Only Tupleï¼‰ä¼˜åŒ–

**HOTæœºåˆ¶**: å¦‚æœæ›´æ–°çš„åˆ—ä¸åœ¨ç´¢å¼•ä¸­ï¼Œä¸”åŒä¸€é¡µæœ‰ç©ºé—´ï¼Œåˆ™åªæ›´æ–°heapï¼Œä¸æ›´æ–°ç´¢å¼•

**HOTæ¡ä»¶**:

1. æ›´æ–°çš„åˆ—ä¸åŒ…å«åœ¨**ä»»ä½•**ç´¢å¼•ä¸­
2. æ–°ç‰ˆæœ¬èƒ½æ”¾å…¥åŒä¸€ä¸ªpage
3. é¡µé¢æœ‰è¶³å¤Ÿfree space

**åä¾‹**: HOTå¤±æ•ˆçš„æƒ…å†µ

```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255),
    name VARCHAR(100),
    age INTEGER,
    updated_at TIMESTAMP
);

CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_name ON users(name);

-- æ›´æ–°ageï¼ˆä¸åœ¨ç´¢å¼•ä¸­ï¼‰
UPDATE users SET age = age + 1 WHERE id = 1;
-- HOT: âœ“ (ageä¸åœ¨ä»»ä½•ç´¢å¼•)

-- æ›´æ–°nameï¼ˆåœ¨ç´¢å¼•ä¸­ï¼‰
UPDATE users SET name = 'NewName' WHERE id = 1;
-- HOT: âœ— (nameåœ¨idx_users_name)
-- å¿…é¡»æ›´æ–°ç´¢å¼• â†’ ç´¢å¼•è†¨èƒ€

-- æ›´æ–°updated_atï¼ˆä¸åœ¨ç´¢å¼•ä½†...)
UPDATE users SET updated_at = NOW() WHERE id = 1;
-- HOT: âœ“ å¦‚æœé¡µé¢æœ‰ç©ºé—´
-- HOT: âœ— å¦‚æœé¡µé¢å·²æ»¡ï¼ˆéœ€è¦æ–°é¡µé¢ï¼‰
```

**HOTæ•ˆæœé‡åŒ–**:

```sql
-- ç›‘æ§HOTæ•ˆæœ
SELECT schemaname, tablename,
       n_tup_upd AS total_updates,
       n_tup_hot_upd AS hot_updates,
       ROUND(100.0 * n_tup_hot_upd / NULLIF(n_tup_upd, 0), 2) AS hot_ratio
FROM pg_stat_user_tables
ORDER BY n_tup_upd DESC;

-- ç»“æœåˆ†æ:
-- hot_ratio > 90%: ä¼˜ç§€ âœ“
-- hot_ratio 50-90%: ä¸€èˆ¬
-- hot_ratio < 50%: å·® âš ï¸ (å¤§é‡ç´¢å¼•æ›´æ–°)
```

### 3.3 Fillfactorä¼˜åŒ–

**å®šç†3.1**: Fillfactorä¸º\(f\)æ—¶ï¼ŒHOTæ¦‚ç‡æå‡

```sql
-- é»˜è®¤fillfactor=100 (é¡µé¢å¡«æ»¡)
CREATE TABLE t1 (id INT, val INT);

-- UPDATEæ—¶:
-- é¡µé¢å·²æ»¡ â†’ æ–°ç‰ˆæœ¬å¿…é¡»å»æ–°é¡µé¢ â†’ HOTå¤±æ•ˆ âœ—

-- ä¼˜åŒ–: é¢„ç•™20%ç©ºé—´
ALTER TABLE t1 SET (fillfactor = 80);

-- UPDATEæ—¶:
-- é¡µé¢æœ‰ç©ºé—´ â†’ æ–°ç‰ˆæœ¬åœ¨åŒé¡µ â†’ HOTæˆåŠŸ âœ“
```

**ä»£ä»·**: 20%ç©ºé—´æ¢å–HOT â†’ æ˜¯å¦å€¼å¾—ï¼Ÿ

**é‡åŒ–åˆ†æ**:

```text
åœºæ™¯: 100ä¸‡è¡Œè¡¨ï¼Œæ¯è¡Œ100 bytes

é»˜è®¤(fillfactor=100):
â”œâ”€ è¡¨å¤§å°: 100MB
â”œâ”€ HOTç‡: 30%
â”œâ”€ ç´¢å¼•å¤§å°: 50MB + è†¨èƒ€35MB = 85MB
â””â”€ æ€»è®¡: 100MB + 85MB = 185MB

ä¼˜åŒ–(fillfactor=80):
â”œâ”€ è¡¨å¤§å°: 125MB (+25MB due to fillfactor)
â”œâ”€ HOTç‡: 90% (æ˜¾è‘—æå‡)
â”œâ”€ ç´¢å¼•å¤§å°: 50MB + è†¨èƒ€5MB = 55MB (-30MB)
â””â”€ æ€»è®¡: 125MB + 55MB = 180MB (-5MB, -2.7%)

ç»“è®º: fillfactor=80å€¼å¾—ï¼
```

---

## å››ã€çœŸå®æ¡ˆä¾‹åˆ†æ

### æ¡ˆä¾‹1: æŸç”µå•†å…¬å¸è®¢å•è¡¨è†¨èƒ€

**èƒŒæ™¯**:

- è®¢å•è¡¨1äº¿è¡Œ
- è®¢å•çŠ¶æ€é¢‘ç¹æ›´æ–°ï¼ˆå¾…æ”¯ä»˜â†’å·²æ”¯ä»˜â†’å·²å‘è´§â†’å·²å®Œæˆï¼‰
- é—®é¢˜: è¡¨ä»200GBè†¨èƒ€åˆ°800GB

**è¯Šæ–­**:

```sql
-- æ£€æŸ¥è†¨èƒ€
SELECT pg_size_pretty(pg_total_relation_size('orders')) AS total,
       pg_size_pretty(pg_relation_size('orders')) AS table_only,
       n_dead_tup, n_live_tup,
       ROUND(100.0 * n_dead_tup / n_live_tup, 2) AS bloat_pct
FROM pg_stat_user_tables
WHERE tablename = 'orders';

-- ç»“æœ:
-- total: 800GB
-- table_only: 750GB
-- dead_tup: 300,000,000
-- live_tup: 100,000,000
-- bloat_pct: 300% ğŸ”´

-- åˆ†æ:
-- 3äº¿æ­»å…ƒç»„ï¼å¹³å‡æ¯è¡Œæœ‰4ä¸ªç‰ˆæœ¬
-- VACUUMä¸åŠæ—¶å¯¼è‡´
```

**æ ¹å› **:

```sql
-- æ£€æŸ¥VACUUMå†å²
SELECT schemaname, tablename,
       last_vacuum, last_autovacuum,
       n_tup_upd, n_tup_hot_upd
FROM pg_stat_user_tables
WHERE tablename = 'orders';

-- å‘ç°:
-- last_autovacuum: 3 hours ago
-- n_tup_upd: 50,000,000 (5åƒä¸‡æ¬¡æ›´æ–°)
-- n_tup_hot_upd: 5,000,000 (HOTç‡ä»…10%ï¼)

-- é—®é¢˜1: VACUUMé—´éš”å¤ªé•¿ï¼ˆ3å°æ—¶ï¼‰
-- é—®é¢˜2: HOTç‡æä½ï¼ˆstatuså­—æ®µæœ‰ç´¢å¼•ï¼‰
```

**è§£å†³æ–¹æ¡ˆ**:

```sql
-- æ–¹æ¡ˆ1: æé«˜VACUUMé¢‘ç‡
ALTER TABLE orders SET (
    autovacuum_vacuum_scale_factor = 0.05,  -- é»˜è®¤0.2
    autovacuum_vacuum_threshold = 5000
);

-- æ–¹æ¡ˆ2: æ‹†åˆ†çƒ­ç‚¹å­—æ®µ
CREATE TABLE order_status (
    order_id BIGINT PRIMARY KEY,
    status VARCHAR(20),
    updated_at TIMESTAMP
) WITH (fillfactor = 70);  -- é¢„ç•™30%ç©ºé—´ç»™HOT

-- ä¸»è¡¨å»æ‰statuså­—æ®µå’Œç´¢å¼•
ALTER TABLE orders DROP COLUMN status;
DROP INDEX idx_orders_status;

-- æ–¹æ¡ˆ3: åˆ†åŒºè¡¨ï¼ˆæŒ‰æœˆï¼‰
CREATE TABLE orders_2025_01 PARTITION OF orders
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

**æ•ˆæœ**:

- è¡¨å¤§å°: 800GB â†’ 250GB (-68.8%)
- æŸ¥è¯¢æ€§èƒ½: +150%
- VACUUMæ—¶é—´: 4å°æ—¶ â†’ 20åˆ†é’Ÿ

---

## äº”ã€åä¾‹ä¸é”™è¯¯ä¼˜åŒ–

### åä¾‹1: VACUUMä¸æ˜¯è¶Šé¢‘ç¹è¶Šå¥½

**é”™è¯¯åšæ³•**:

```sql
-- è®¾ç½®è¶…é¢‘ç¹VACUUM
ALTER TABLE hot_table SET (
    autovacuum_vacuum_scale_factor = 0.001,
    autovacuum_vacuum_threshold = 10
);

-- åæœ:
-- VACUUMæ¯10è¡Œæ›´æ–°å°±è§¦å‘
-- CPUå ç”¨90% (VACUUMè¿›ç¨‹)
-- æ­£å¸¸æŸ¥è¯¢è¢«é˜»å¡ï¼ˆVACUUMè·å–ShareLockï¼‰
-- TPSä»10000é™åˆ°3000 (-70%)
```

**åä¾‹æ•°æ®**:

```text
VACUUMé¢‘ç‡å¯¹æ¯”:

é¢‘ç‡: æ¯10ç§’
â”œâ”€ å¹³å‡è†¨èƒ€: 1.05Ã—
â”œâ”€ VACUUM CPU: 15%
â”œâ”€ TPS: 9000
â””â”€ è¯„ä»·: è‰¯å¥½ âœ“

é¢‘ç‡: æ¯1ç§’
â”œâ”€ å¹³å‡è†¨èƒ€: 1.01Ã—
â”œâ”€ VACUUM CPU: 45%
â”œâ”€ TPS: 6500 (-27.8%)
â””â”€ è¯„ä»·: è¿‡åº¦ä¼˜åŒ– âš ï¸

é¢‘ç‡: æ¯0.1ç§’
â”œâ”€ å¹³å‡è†¨èƒ€: 1.001Ã—
â”œâ”€ VACUUM CPU: 85%
â”œâ”€ TPS: 2000 (-77.8%)
â””â”€ è¯„ä»·: ç¾éš¾ ğŸ”´
```

**æ­£ç¡®åšæ³•**: å¹³è¡¡è†¨èƒ€ç‡å’ŒVACUUMå¼€é”€

\[
OptimalInterval = \sqrt{\frac{VacuumCost}{BloatCost}}
\]

### åä¾‹2: fillfactorè¶Šå°è¶Šå¥½ï¼Ÿ

**é”™è¯¯æ€è·¯**: "fillfactor=50é¢„ç•™50%ç©ºé—´ï¼ŒHOTè‚¯å®šå¥½"

**å®é™…æµ‹è¯•**:

```sql
-- æµ‹è¯•è¡¨
CREATE TABLE filltest (id SERIAL, val INT, data TEXT);

-- æ’å…¥100ä¸‡è¡Œ
INSERT INTO filltest SELECT generate_series(1,1000000), 0, repeat('x', 50);

-- æµ‹è¯•ä¸åŒfillfactor
ALTER TABLE filltest SET (fillfactor = 100);
-- å¤§å°: 100MB
-- HOTç‡: 30%
-- æŸ¥è¯¢: 120ms

ALTER TABLE filltest SET (fillfactor = 50);
VACUUM FULL;
-- å¤§å°: 200MB (+100%!)
-- HOTç‡: 95%
-- æŸ¥è¯¢: 180ms (+50% æ›´æ…¢ï¼)

-- åŸå› : æ‰«æé¡µé¢æ•°ç¿»å€
```

**ç»“è®º**: fillfactor=70-80æ˜¯æœ€ä½³å¹³è¡¡ç‚¹

### åä¾‹3: å­˜å‚¨å¼€é”€åˆ†æä¸å®Œæ•´

**é”™è¯¯è®¾è®¡**: å­˜å‚¨å¼€é”€åˆ†æä¸å®Œæ•´

```text
é”™è¯¯åœºæ™¯:
â”œâ”€ åˆ†æ: å­˜å‚¨å¼€é”€åˆ†æ
â”œâ”€ é—®é¢˜: åªåˆ†æåŸºç¡€å­˜å‚¨ï¼Œå¿½ç•¥ç‰ˆæœ¬é“¾
â”œâ”€ ç»“æœ: åˆ†æä¸å®Œæ•´
â””â”€ è¯¯å·®: å®é™…å­˜å‚¨æ˜¯åˆ†æçš„2å€ âœ—

å®é™…æ¡ˆä¾‹:
â”œâ”€ ç³»ç»Ÿ: æŸæ•°æ®åº“ç³»ç»Ÿ
â”œâ”€ é—®é¢˜: åªåˆ†æåŸºç¡€å­˜å‚¨
â”œâ”€ ç»“æœ: é¢„æµ‹å­˜å‚¨100GBï¼Œå®é™…200GB
â””â”€ åæœ: å­˜å‚¨æˆæœ¬è¶…é¢„ç®— âœ—

æ­£ç¡®è®¾è®¡:
â”œâ”€ æ–¹æ¡ˆ: å®Œæ•´çš„å­˜å‚¨å¼€é”€åˆ†æ
â”œâ”€ å®ç°: åˆ†æåŸºç¡€å­˜å‚¨ã€ç‰ˆæœ¬é“¾ã€ç´¢å¼•ã€å…ƒæ•°æ®
â””â”€ ç»“æœ: åˆ†æå®Œæ•´ï¼Œé¢„æµ‹å‡†ç¡® âœ“
```

### åä¾‹4: ç‰ˆæœ¬é“¾é•¿åº¦é¢„æµ‹é”™è¯¯

**é”™è¯¯è®¾è®¡**: ç‰ˆæœ¬é“¾é•¿åº¦é¢„æµ‹é”™è¯¯

```text
é”™è¯¯åœºæ™¯:
â”œâ”€ é¢„æµ‹: ç‰ˆæœ¬é“¾é•¿åº¦é¢„æµ‹
â”œâ”€ é—®é¢˜: å¿½ç•¥é•¿äº‹åŠ¡å½±å“
â”œâ”€ ç»“æœ: é¢„æµ‹ä¸å‡†ç¡®
â””â”€ è¯¯å·®: å®é™…é•¿åº¦æ˜¯é¢„æµ‹çš„10å€ âœ—

å®é™…æ¡ˆä¾‹:
â”œâ”€ ç³»ç»Ÿ: æŸæ•°æ®åº“ç³»ç»Ÿ
â”œâ”€ é—®é¢˜: é¢„æµ‹ç‰ˆæœ¬é“¾é•¿åº¦ < 10
â”œâ”€ ç»“æœ: å®é™…é•¿åº¦ > 1000ï¼ˆé•¿äº‹åŠ¡ï¼‰
â””â”€ åæœ: æŸ¥è¯¢æ€§èƒ½ä¸‹é™ âœ—

æ­£ç¡®è®¾è®¡:
â”œâ”€ æ–¹æ¡ˆ: è€ƒè™‘é•¿äº‹åŠ¡å½±å“
â”œâ”€ å®ç°: ç‰ˆæœ¬é“¾é•¿åº¦ = f(æ›´æ–°é¢‘ç‡, äº‹åŠ¡æ—¶é•¿)
â””â”€ ç»“æœ: é¢„æµ‹å‡†ç¡® âœ“
```

### åä¾‹5: ç´¢å¼•è†¨èƒ€åˆ†æè¢«å¿½ç•¥

**é”™è¯¯è®¾è®¡**: å¿½ç•¥ç´¢å¼•è†¨èƒ€åˆ†æ

```text
é”™è¯¯åœºæ™¯:
â”œâ”€ åˆ†æ: å­˜å‚¨å¼€é”€åˆ†æ
â”œâ”€ é—®é¢˜: åªåˆ†æè¡¨å­˜å‚¨ï¼Œå¿½ç•¥ç´¢å¼•
â”œâ”€ ç»“æœ: åˆ†æä¸å®Œæ•´
â””â”€ è¯¯å·®: ç´¢å¼•å­˜å‚¨æ˜¯è¡¨å­˜å‚¨çš„2å€ âœ—

å®é™…æ¡ˆä¾‹:
â”œâ”€ ç³»ç»Ÿ: æŸæ•°æ®åº“ç³»ç»Ÿ
â”œâ”€ é—®é¢˜: å¿½ç•¥ç´¢å¼•è†¨èƒ€
â”œâ”€ ç»“æœ: ç´¢å¼•ä»10GBè†¨èƒ€åˆ°50GB
â””â”€ åæœ: å­˜å‚¨æˆæœ¬å¢åŠ  âœ—

æ­£ç¡®è®¾è®¡:
â”œâ”€ æ–¹æ¡ˆ: å®Œæ•´çš„å­˜å‚¨åˆ†æ
â”œâ”€ å®ç°: åˆ†æè¡¨å­˜å‚¨å’Œç´¢å¼•å­˜å‚¨
â””â”€ ç»“æœ: åˆ†æå®Œæ•´ âœ“
```

### åä¾‹6: å­˜å‚¨ä¼˜åŒ–ç­–ç•¥ä¸å½“

**é”™è¯¯è®¾è®¡**: å­˜å‚¨ä¼˜åŒ–ç­–ç•¥ä¸å½“

```text
é”™è¯¯åœºæ™¯:
â”œâ”€ ä¼˜åŒ–: å­˜å‚¨ä¼˜åŒ–
â”œâ”€ é—®é¢˜: è¿‡åº¦ä¼˜åŒ–ï¼Œå¿½ç•¥æ€§èƒ½å½±å“
â”œâ”€ ç»“æœ: æ€§èƒ½ä¸‹é™
â””â”€ æ€§èƒ½: æŸ¥è¯¢å»¶è¿Ÿå¢åŠ  âœ—

å®é™…æ¡ˆä¾‹:
â”œâ”€ ç³»ç»Ÿ: æŸæ•°æ®åº“ç³»ç»Ÿ
â”œâ”€ é—®é¢˜: fillfactorè®¾ç½®è¿‡å°ï¼ˆ50%ï¼‰
â”œâ”€ ç»“æœ: å­˜å‚¨èŠ‚çœï¼Œä½†æŸ¥è¯¢æ‰«æé¡µæ•°ç¿»å€
â””â”€ åæœ: æŸ¥è¯¢æ€§èƒ½ä¸‹é™ âœ—

æ­£ç¡®è®¾è®¡:
â”œâ”€ æ–¹æ¡ˆ: å¹³è¡¡å­˜å‚¨å’Œæ€§èƒ½
â”œâ”€ å®ç°: fillfactor=70-80ï¼Œå¹³è¡¡å­˜å‚¨å’Œæ€§èƒ½
â””â”€ ç»“æœ: å­˜å‚¨å’Œæ€§èƒ½éƒ½ä¼˜åŒ– âœ“
```

---

## å…­ã€ä¼˜åŒ–ç­–ç•¥å®Œæ•´æŒ‡å—

### 6.1 å†³ç­–æ ‘

```text
å­˜å‚¨è†¨èƒ€é—®é¢˜åˆ†æ:

1. æ£€æŸ¥è†¨èƒ€ç‡
   n_dead_tup / n_live_tup > 0.2? â†’ YES â†’ ç»§ç»­
                                  â†’ NO â†’ æ— é—®é¢˜

2. æ£€æŸ¥HOTç‡
   n_tup_hot_upd / n_tup_upd < 0.5? â†’ YES â†’ ç´¢å¼•è¿‡å¤šæˆ–fillfactor=100
                                    â†’ NO â†’ ç»§ç»­

3. æ£€æŸ¥VACUUMé¢‘ç‡
   last_autovacuum > 1å°æ—¶? â†’ YES â†’ æé«˜VACUUMé¢‘ç‡
                           â†’ NO â†’ æ›´æ–°é€Ÿç‡è¿‡é«˜

4. ä¼˜åŒ–æ–¹æ¡ˆ:
   â”œâ”€ HOTç‡ä½ â†’ å‡å°‘ç´¢å¼•ã€é™ä½fillfactor
   â”œâ”€ VACUUMæ…¢ â†’ åˆ†åŒºè¡¨ã€å¹¶è¡ŒVACUUM
   â””â”€ æ›´æ–°è¿‡å¿« â†’ æ‹†åˆ†çƒ­ç‚¹å­—æ®µã€ç¼“å­˜
```

### 6.2 ç›‘æ§SQLå·¥å…·åŒ…

```sql
-- å®Œæ•´ç›‘æ§è„šæœ¬
CREATE OR REPLACE VIEW storage_health AS
SELECT
    schemaname || '.' || tablename AS table_name,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    n_live_tup,
    n_dead_tup,
    ROUND(100.0 * n_dead_tup / NULLIF(n_live_tup, 0), 2) AS bloat_pct,
    ROUND(100.0 * n_tup_hot_upd / NULLIF(n_tup_upd, 0), 2) AS hot_pct,
    last_vacuum,
    last_autovacuum,
    CASE
        WHEN n_dead_tup::FLOAT / NULLIF(n_live_tup, 0) > 0.5 THEN 'ğŸ”´ Critical'
        WHEN n_dead_tup::FLOAT / NULLIF(n_live_tup, 0) > 0.2 THEN 'ğŸŸ¡ Warning'
        ELSE 'ğŸŸ¢ Good'
    END AS health_status
FROM pg_stat_user_tables
WHERE n_live_tup > 1000
ORDER BY n_dead_tup DESC;

-- ä½¿ç”¨
SELECT * FROM storage_health WHERE health_status != 'ğŸŸ¢ Good';
```

---

## ä¸ƒã€å·¥å…·ä¸ç›‘æ§

### 7.1 pgstattupleæ‰©å±•

```sql
-- å®‰è£…
CREATE EXTENSION pgstattuple;

-- è¯¦ç»†è†¨èƒ€åˆ†æ
SELECT * FROM pgstattuple('orders');

-- ç»“æœè§£è¯»:
-- table_len: ç‰©ç†å¤§å°
-- tuple_count: æ´»å…ƒç»„æ•°
-- tuple_len: æ´»å…ƒç»„æ€»å­—èŠ‚
-- dead_tuple_count: æ­»å…ƒç»„æ•°
-- free_space: å¯ç”¨ç©ºé—´
-- è†¨èƒ€ç‡ = (table_len - tuple_len) / table_len
```

### 7.2 è‡ªåŠ¨åŒ–å‘Šè­¦

```python
import psycopg2

def check_bloat_alert(conn, threshold=0.3):
    """æ£€æµ‹è¡¨è†¨èƒ€å¹¶å‘Šè­¦"""
    cur = conn.cursor()

    cur.execute("""
        SELECT tablename,
               n_dead_tup,
               n_live_tup,
               n_dead_tup::FLOAT / NULLIF(n_live_tup, 0) AS bloat_ratio
        FROM pg_stat_user_tables
        WHERE n_live_tup > 10000
          AND n_dead_tup::FLOAT / NULLIF(n_live_tup, 0) > %s
        ORDER BY bloat_ratio DESC
    """, (threshold,))

    alerts = []
    for row in cur.fetchall():
        table, dead, live, ratio = row
        alerts.append({
            'table': table,
            'dead_tuples': dead,
            'live_tuples': live,
            'bloat_ratio': f"{ratio*100:.1f}%",
            'action': 'VACUUM ANALYZE' if ratio < 0.5 else 'VACUUM FULL'
        })

    return alerts

# ä½¿ç”¨
alerts = check_bloat_alert(conn, threshold=0.2)
for alert in alerts:
    print(f"âš ï¸ {alert['table']}: {alert['bloat_ratio']} bloat")
    print(f"   Action: {alert['action']}")
```

---

## å…«ã€å®Œæ•´å­˜å‚¨åˆ†æå·¥å…·å®ç°

### 8.1 ç‰ˆæœ¬é“¾é•¿åº¦åˆ†æå·¥å…·

```python
import psycopg2
from collections import defaultdict

def analyze_version_chains(conn, table_name: str):
    """åˆ†æç‰ˆæœ¬é“¾é•¿åº¦åˆ†å¸ƒ"""
    cur = conn.cursor()

    # æŸ¥è¯¢ç‰ˆæœ¬é“¾ä¿¡æ¯ï¼ˆéœ€è¦æ‰©å±•æ”¯æŒï¼‰
    cur.execute(f"""
        SELECT
            ctid,
            xmin,
            xmax,
            CASE WHEN xmax = 0 THEN NULL ELSE xmax END as next_version
        FROM {table_name}
        ORDER BY ctid
    """)

    # æ„å»ºç‰ˆæœ¬é“¾
    chains = defaultdict(list)
    for row in cur.fetchall():
        ctid, xmin, xmax, next_version = row
        if next_version:
            chains[xmin].append((ctid, xmin, xmax))

    # ç»Ÿè®¡é“¾é•¿åº¦
    chain_lengths = [len(chain) for chain in chains.values()]

    return {
        'total_chains': len(chains),
        'avg_length': sum(chain_lengths) / len(chain_lengths) if chain_lengths else 0,
        'max_length': max(chain_lengths) if chain_lengths else 0,
        'long_chains': sum(1 for l in chain_lengths if l > 10)
    }

# ä½¿ç”¨
stats = analyze_version_chains(conn, 'orders')
print(f"å¹³å‡ç‰ˆæœ¬é“¾é•¿åº¦: {stats['avg_length']:.2f}")
print(f"æœ€é•¿ç‰ˆæœ¬é“¾: {stats['max_length']}")
```

### 8.2 å­˜å‚¨è†¨èƒ€ç›‘æ§å·¥å…·

```python
def monitor_storage_bloat(conn):
    """ç›‘æ§å­˜å‚¨è†¨èƒ€"""
    cur = conn.cursor()

    cur.execute("""
        SELECT
            schemaname,
            tablename,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
            pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
            pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) as indexes_size
        FROM pg_tables
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
        LIMIT 20
    """)

    results = []
    for row in cur.fetchall():
        results.append({
            'schema': row[0],
            'table': row[1],
            'total_size': row[2],
            'table_size': row[3],
            'indexes_size': row[4]
        })

    return results
```

---

## ä¹ã€å®é™…åº”ç”¨æ¡ˆä¾‹

### 9.1 æ¡ˆä¾‹: è®¢å•è¡¨å­˜å‚¨ä¼˜åŒ–

**åœºæ™¯**: ç”µå•†è®¢å•è¡¨ï¼Œæ¯å¤©100ä¸‡è®¢å•

**é—®é¢˜**: è¡¨å¤§å°ä»10GBå¢é•¿åˆ°200GBï¼ˆ20å€ï¼‰

**åˆ†æè¿‡ç¨‹**:

```python
# 1. åˆ†æç‰ˆæœ¬é“¾
stats = analyze_version_chains(conn, 'orders')
# ç»“æœ: å¹³å‡ç‰ˆæœ¬é“¾é•¿åº¦15ï¼Œæœ€é•¿ç‰ˆæœ¬é“¾50

# 2. åˆ†ææ­»å…ƒç»„
cur.execute("""
    SELECT
        n_dead_tup,
        n_live_tup,
        n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0) as dead_ratio
    FROM pg_stat_user_tables
    WHERE relname = 'orders'
""")
# ç»“æœ: æ­»å…ƒç»„å æ¯”60%
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```sql
-- 1. è°ƒæ•´fillfactor
ALTER TABLE orders SET (fillfactor = 80);

-- 2. å®šæœŸVACUUM
VACUUM ANALYZE orders;

-- 3. åˆ†åŒºè¡¨ï¼ˆæŒ‰æœˆï¼‰
CREATE TABLE orders_2025_12 PARTITION OF orders
FOR VALUES FROM ('2025-12-01') TO ('2026-01-01');
```

**ä¼˜åŒ–æ•ˆæœ**: è¡¨å¤§å°ä»200GBé™åˆ°50GBï¼ˆ-75%ï¼‰

### 9.2 æ¡ˆä¾‹: ç´¢å¼•è†¨èƒ€ä¼˜åŒ–

**åœºæ™¯**: ç”¨æˆ·è¡¨ç´¢å¼•ï¼ŒæŸ¥è¯¢å˜æ…¢

**é—®é¢˜**: ç´¢å¼•å¤§å°æ˜¯è¡¨å¤§å°çš„3å€

**åˆ†æè¿‡ç¨‹**:

```python
# åˆ†æç´¢å¼•è†¨èƒ€
cur.execute("""
    SELECT
        indexrelname,
        pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
        idx_scan,
        idx_tup_read,
        idx_tup_fetch
    FROM pg_stat_user_indexes
    WHERE schemaname = 'public'
    ORDER BY pg_relation_size(indexrelid) DESC
""")
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```sql
-- 1. REINDEX
REINDEX INDEX CONCURRENTLY idx_users_email;

-- 2. åˆ é™¤æœªä½¿ç”¨ç´¢å¼•
DROP INDEX IF EXISTS idx_users_unused;
```

**ä¼˜åŒ–æ•ˆæœ**: ç´¢å¼•å¤§å°å‡å°‘60%ï¼ŒæŸ¥è¯¢é€Ÿåº¦æå‡30%

---

## åã€å®Œæ•´å®ç°ä»£ç 

### 10.1 å­˜å‚¨å¼€é”€è®¡ç®—å™¨å®Œæ•´å®ç°

**å®Œæ•´å®ç°**: å®Œæ•´çš„å­˜å‚¨å¼€é”€è®¡ç®—å’Œåˆ†æå·¥å…·

```python
from dataclasses import dataclass
from typing import Dict, List, Optional
import psycopg2

@dataclass
class StorageMetrics:
    """å­˜å‚¨æŒ‡æ ‡"""
    table_name: str
    total_size_bytes: int
    table_size_bytes: int
    indexes_size_bytes: int
    live_tuples: int
    dead_tuples: int
    bloat_ratio: float
    hot_ratio: float
    avg_version_chain_length: float

class StorageAnalyzer:
    """å­˜å‚¨åˆ†æå™¨"""

    def __init__(self, conn_string: str):
        self.conn = psycopg2.connect(conn_string)

    def calculate_storage_overhead(
        self,
        table_name: str,
        row_count: int,
        avg_tuple_size: int,
        version_chain_length: float = 1.0
    ) -> Dict[str, float]:
        """è®¡ç®—å­˜å‚¨å¼€é”€"""
        # åŸºç¡€å­˜å‚¨
        base_storage = row_count * avg_tuple_size

        # ç‰ˆæœ¬é“¾å­˜å‚¨
        version_storage = base_storage * (version_chain_length - 1)

        # å…ƒç»„å¤´å¼€é”€ï¼ˆæ¯ä¸ªå…ƒç»„23å­—èŠ‚ï¼‰
        tuple_header_overhead = row_count * 23

        # é¡µå¤´å¼€é”€ï¼ˆæ¯é¡µ24å­—èŠ‚ï¼Œå‡è®¾8KBé¡µï¼‰
        page_size = 8192
        tuple_per_page = (page_size - 24) // (avg_tuple_size + 23)
        num_pages = (row_count + tuple_per_page - 1) // tuple_per_page
        page_header_overhead = num_pages * 24

        # ç´¢å¼•å¼€é”€ï¼ˆå‡è®¾ç´¢å¼•å¤§å°æ˜¯è¡¨å¤§å°çš„30%ï¼‰
        index_overhead = base_storage * 0.3

        total_storage = (
            base_storage +
            version_storage +
            tuple_header_overhead +
            page_header_overhead +
            index_overhead
        )

        return {
            'base_storage_mb': base_storage / (1024 * 1024),
            'version_storage_mb': version_storage / (1024 * 1024),
            'tuple_header_overhead_mb': tuple_header_overhead / (1024 * 1024),
            'page_header_overhead_mb': page_header_overhead / (1024 * 1024),
            'index_overhead_mb': index_overhead / (1024 * 1024),
            'total_storage_mb': total_storage / (1024 * 1024),
            'overhead_ratio': (total_storage - base_storage) / base_storage
        }

    def analyze_table(self, table_name: str) -> StorageMetrics:
        """åˆ†æè¡¨å­˜å‚¨"""
        cur = self.conn.cursor()

        # è·å–è¡¨å¤§å°
        cur.execute(f"""
            SELECT
                pg_total_relation_size('{table_name}') as total_size,
                pg_relation_size('{table_name}') as table_size,
                pg_indexes_size('{table_name}') as indexes_size
        """)
        total_size, table_size, indexes_size = cur.fetchone()

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        schema, table = table_name.split('.') if '.' in table_name else ('public', table_name)
        cur.execute("""
            SELECT
                n_live_tup,
                n_dead_tup,
                n_tup_hot_upd,
                n_tup_upd
            FROM pg_stat_user_tables
            WHERE schemaname = %s AND relname = %s
        """, (schema, table))

        row = cur.fetchone()
        if not row:
            raise ValueError(f"Table {table_name} not found")

        live_tuples, dead_tuples, hot_updates, total_updates = row

        bloat_ratio = dead_tuples / (live_tuples + dead_tuples) if (live_tuples + dead_tuples) > 0 else 0
        hot_ratio = hot_updates / total_updates if total_updates > 0 else 0

        # ä¼°ç®—ç‰ˆæœ¬é“¾é•¿åº¦ï¼ˆç®€åŒ–ï¼‰
        avg_version_chain_length = 1.0 + (dead_tuples / live_tuples if live_tuples > 0 else 0)

        return StorageMetrics(
            table_name=table_name,
            total_size_bytes=total_size,
            table_size_bytes=table_size,
            indexes_size_bytes=indexes_size,
            live_tuples=live_tuples,
            dead_tuples=dead_tuples,
            bloat_ratio=bloat_ratio,
            hot_ratio=hot_ratio,
            avg_version_chain_length=avg_version_chain_length
        )

    def generate_report(self, table_name: str) -> Dict:
        """ç”Ÿæˆå­˜å‚¨åˆ†ææŠ¥å‘Š"""
        metrics = self.analyze_table(table_name)
        overhead = self.calculate_storage_overhead(
            table_name,
            metrics.live_tuples,
            avg_tuple_size=200,  # å‡è®¾å¹³å‡å…ƒç»„å¤§å°
            version_chain_length=metrics.avg_version_chain_length
        )

        return {
            'table': table_name,
            'metrics': {
                'total_size_mb': metrics.total_size_bytes / (1024 * 1024),
                'table_size_mb': metrics.table_size_bytes / (1024 * 1024),
                'indexes_size_mb': metrics.indexes_size_bytes / (1024 * 1024),
                'live_tuples': metrics.live_tuples,
                'dead_tuples': metrics.dead_tuples,
                'bloat_ratio': f"{metrics.bloat_ratio * 100:.2f}%",
                'hot_ratio': f"{metrics.hot_ratio * 100:.2f}%",
            },
            'overhead_breakdown': overhead,
            'recommendations': self._generate_recommendations(metrics)
        }

    def _generate_recommendations(self, metrics: StorageMetrics) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        if metrics.bloat_ratio > 0.3:
            recommendations.append("æ‰§è¡ŒVACUUM ANALYZEæ¸…ç†æ­»å…ƒç»„")

        if metrics.bloat_ratio > 0.5:
            recommendations.append("è€ƒè™‘æ‰§è¡ŒVACUUM FULLé‡å»ºè¡¨")

        if metrics.hot_ratio < 0.5:
            recommendations.append("è€ƒè™‘é™ä½fillfactoræˆ–å‡å°‘ç´¢å¼•åˆ—")

        if metrics.avg_version_chain_length > 5:
            recommendations.append("ç‰ˆæœ¬é“¾è¿‡é•¿ï¼Œæ£€æŸ¥é•¿äº‹åŠ¡")

        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = StorageAnalyzer("dbname=test user=postgres")

    # åˆ†æè¡¨
    report = analyzer.generate_report("orders")
    print(f"è¡¨: {report['table']}")
    print(f"æ€»å¤§å°: {report['metrics']['total_size_mb']:.2f} MB")
    print(f"è†¨èƒ€ç‡: {report['metrics']['bloat_ratio']}")
    print(f"å»ºè®®: {report['recommendations']}")
```

### 10.2 ç‰ˆæœ¬é“¾åˆ†æå™¨å®Œæ•´å®ç°

**å®Œæ•´å®ç°**: ç‰ˆæœ¬é“¾æ·±åº¦åˆ†æå·¥å…·

```python
from typing import Dict, List, Tuple
from collections import defaultdict
import psycopg2

class VersionChainAnalyzer:
    """ç‰ˆæœ¬é“¾åˆ†æå™¨"""

    def __init__(self, conn_string: str):
        self.conn = psycopg2.connect(conn_string)

    def analyze_version_chains(self, table_name: str) -> Dict:
        """åˆ†æç‰ˆæœ¬é“¾"""
        cur = self.conn.cursor()

        # æŸ¥è¯¢æ‰€æœ‰å…ƒç»„ï¼ˆéœ€è¦ç‰¹æ®Šæ‰©å±•æˆ–æŸ¥è¯¢ç³»ç»Ÿè¡¨ï¼‰
        cur.execute(f"""
            SELECT
                ctid,
                xmin::text,
                xmax::text,
                (xmax = 0) as is_live
            FROM {table_name}
            ORDER BY ctid
        """)

        # æ„å»ºç‰ˆæœ¬é“¾ï¼ˆç®€åŒ–ï¼šåŸºäºxmin/xmaxå…³ç³»ï¼‰
        chains = defaultdict(list)
        tuple_map = {}

        for row in cur.fetchall():
            ctid, xmin, xmax, is_live = row
            tuple_map[ctid] = (xmin, xmax, is_live)

            # å¦‚æœxmaxä¸ä¸º0ï¼Œè¯´æ˜æœ‰åç»­ç‰ˆæœ¬
            if xmax != '0':
                chains[xmin].append(ctid)

        # ç»Ÿè®¡é“¾é•¿åº¦
        chain_lengths = [len(chain) + 1 for chain in chains.values()]  # +1 for root

        if not chain_lengths:
            return {
                'total_chains': 0,
                'avg_length': 0,
                'max_length': 0,
                'long_chains_count': 0
            }

        return {
            'total_chains': len(chains),
            'avg_length': sum(chain_lengths) / len(chain_lengths),
            'max_length': max(chain_lengths),
            'min_length': min(chain_lengths),
            'long_chains_count': sum(1 for l in chain_lengths if l > 10),
            'chain_length_distribution': self._calculate_distribution(chain_lengths)
        }

    def _calculate_distribution(self, lengths: List[int]) -> Dict[str, int]:
        """è®¡ç®—é“¾é•¿åº¦åˆ†å¸ƒ"""
        distribution = {
            '1': 0,      # å•ç‰ˆæœ¬
            '2-5': 0,    # çŸ­é“¾
            '6-10': 0,   # ä¸­ç­‰é“¾
            '11-20': 0,  # é•¿é“¾
            '20+': 0     # è¶…é•¿é“¾
        }

        for length in lengths:
            if length == 1:
                distribution['1'] += 1
            elif 2 <= length <= 5:
                distribution['2-5'] += 1
            elif 6 <= length <= 10:
                distribution['6-10'] += 1
            elif 11 <= length <= 20:
                distribution['11-20'] += 1
            else:
                distribution['20+'] += 1

        return distribution

    def estimate_storage_impact(
        self,
        table_name: str,
        chain_stats: Dict
    ) -> Dict[str, float]:
        """ä¼°ç®—ç‰ˆæœ¬é“¾å¯¹å­˜å‚¨çš„å½±å“"""
        # è·å–è¡¨å¤§å°
        cur = self.conn.cursor()
        cur.execute(f"SELECT pg_relation_size('{table_name}')")
        table_size = cur.fetchone()[0]

        # ä¼°ç®—ç‰ˆæœ¬é“¾å¯¼è‡´çš„é¢å¤–å­˜å‚¨
        if chain_stats['avg_length'] > 1:
            extra_storage = table_size * (chain_stats['avg_length'] - 1) / chain_stats['avg_length']
        else:
            extra_storage = 0

        return {
            'current_size_mb': table_size / (1024 * 1024),
            'version_chain_overhead_mb': extra_storage / (1024 * 1024),
            'potential_savings_mb': extra_storage / (1024 * 1024),
            'overhead_ratio': (chain_stats['avg_length'] - 1) / chain_stats['avg_length'] if chain_stats['avg_length'] > 0 else 0
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = VersionChainAnalyzer("dbname=test user=postgres")

    stats = analyzer.analyze_version_chains("orders")
    print(f"å¹³å‡ç‰ˆæœ¬é“¾é•¿åº¦: {stats['avg_length']:.2f}")
    print(f"æœ€é•¿ç‰ˆæœ¬é“¾: {stats['max_length']}")
    print(f"é“¾é•¿åº¦åˆ†å¸ƒ: {stats['chain_length_distribution']}")

    impact = analyzer.estimate_storage_impact("orders", stats)
    print(f"ç‰ˆæœ¬é“¾å¼€é”€: {impact['version_chain_overhead_mb']:.2f} MB")
```

### 10.3 å­˜å‚¨ä¼˜åŒ–å»ºè®®å™¨å®Œæ•´å®ç°

**å®Œæ•´å®ç°**: è‡ªåŠ¨ç”Ÿæˆå­˜å‚¨ä¼˜åŒ–å»ºè®®

```python
from typing import Dict, List
from dataclasses import dataclass

@dataclass
class OptimizationRecommendation:
    """ä¼˜åŒ–å»ºè®®"""
    priority: str  # 'high', 'medium', 'low'
    action: str
    reason: str
    expected_benefit: str
    sql_command: Optional[str] = None

class StorageOptimizer:
    """å­˜å‚¨ä¼˜åŒ–å™¨"""

    def __init__(self, analyzer: StorageAnalyzer):
        self.analyzer = analyzer

    def generate_recommendations(self, table_name: str) -> List[OptimizationRecommendation]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        metrics = self.analyzer.analyze_table(table_name)
        recommendations = []

        # é«˜ä¼˜å…ˆçº§ï¼šä¸¥é‡è†¨èƒ€
        if metrics.bloat_ratio > 0.5:
            recommendations.append(OptimizationRecommendation(
                priority='high',
                action='VACUUM FULL',
                reason=f'è¡¨è†¨èƒ€ç‡{metrics.bloat_ratio*100:.1f}%è¶…è¿‡50%',
                expected_benefit=f'å¯é‡Šæ”¾çº¦{metrics.bloat_ratio*100:.1f}%å­˜å‚¨ç©ºé—´',
                sql_command=f'VACUUM FULL {table_name};'
            ))
        elif metrics.bloat_ratio > 0.3:
            recommendations.append(OptimizationRecommendation(
                priority='medium',
                action='VACUUM ANALYZE',
                reason=f'è¡¨è†¨èƒ€ç‡{metrics.bloat_ratio*100:.1f}%è¶…è¿‡30%',
                expected_benefit=f'å¯é‡Šæ”¾çº¦{metrics.bloat_ratio*100:.1f}%å­˜å‚¨ç©ºé—´',
                sql_command=f'VACUUM ANALYZE {table_name};'
            ))

        # é«˜ä¼˜å…ˆçº§ï¼šç‰ˆæœ¬é“¾è¿‡é•¿
        if metrics.avg_version_chain_length > 10:
            recommendations.append(OptimizationRecommendation(
                priority='high',
                action='æ£€æŸ¥é•¿äº‹åŠ¡',
                reason=f'å¹³å‡ç‰ˆæœ¬é“¾é•¿åº¦{metrics.avg_version_chain_length:.1f}è¿‡é•¿',
                expected_benefit='å‡å°‘ç‰ˆæœ¬é“¾é•¿åº¦ï¼Œé™ä½å­˜å‚¨å¼€é”€',
                sql_command='SELECT pid, query, state FROM pg_stat_activity WHERE state = \'active\' AND now() - query_start > interval \'1 hour\';'
            ))

        # ä¸­ä¼˜å…ˆçº§ï¼šHOTç‡ä½
        if metrics.hot_ratio < 0.3:
            recommendations.append(OptimizationRecommendation(
                priority='medium',
                action='é™ä½fillfactoræˆ–å‡å°‘ç´¢å¼•',
                reason=f'HOTæ›´æ–°ç‡{metrics.hot_ratio*100:.1f}%è¿‡ä½',
                expected_benefit='æé«˜HOTç‡ï¼Œå‡å°‘ç´¢å¼•è†¨èƒ€',
                sql_command=f'ALTER TABLE {table_name} SET (fillfactor = 80);'
            ))

        # ä½ä¼˜å…ˆçº§ï¼šç´¢å¼•å¤§å°è¿‡å¤§
        if metrics.indexes_size_bytes > metrics.table_size_bytes * 2:
            recommendations.append(OptimizationRecommendation(
                priority='low',
                action='æ£€æŸ¥æœªä½¿ç”¨ç´¢å¼•',
                reason=f'ç´¢å¼•å¤§å°({metrics.indexes_size_bytes/(1024*1024):.1f}MB)æ˜¯è¡¨å¤§å°({metrics.table_size_bytes/(1024*1024):.1f}MB)çš„{metrics.indexes_size_bytes/metrics.table_size_bytes:.1f}å€',
                expected_benefit='åˆ é™¤æœªä½¿ç”¨ç´¢å¼•å¯å‡å°‘å­˜å‚¨',
                sql_command='SELECT indexrelname, idx_scan FROM pg_stat_user_indexes WHERE idx_scan = 0;'
            ))

        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = StorageAnalyzer("dbname=test user=postgres")
    optimizer = StorageOptimizer(analyzer)

    recommendations = optimizer.generate_recommendations("orders")

    print("å­˜å‚¨ä¼˜åŒ–å»ºè®®:")
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. [{rec.priority.upper()}] {rec.action}")
        print(f"   åŸå› : {rec.reason}")
        print(f"   é¢„æœŸæ”¶ç›Š: {rec.expected_benefit}")
        if rec.sql_command:
            print(f"   SQL: {rec.sql_command}")
        print()
```

---

## åä¸€ã€å­˜å‚¨å¼€é”€åˆ†æå¯è§†åŒ–

### 11.1 å­˜å‚¨å¼€é”€åˆ†è§£æ¶æ„å›¾

**å®Œæ•´å­˜å‚¨å¼€é”€ç³»ç»Ÿæ¶æ„** (Mermaid):

```mermaid
graph TB
    subgraph "å­˜å‚¨å¼€é”€å±‚"
        BASE[åŸºç¡€å­˜å‚¨<br/>Base Storage]
        VERSIONS[ç‰ˆæœ¬é“¾å­˜å‚¨<br/>Version Chain]
        INDEXES[ç´¢å¼•å­˜å‚¨<br/>Index Storage]
        OVERHEAD[å…ƒæ•°æ®å¼€é”€<br/>Overhead]
        WAL[WALæ—¥å¿—<br/>Write-Ahead Log]
    end

    subgraph "ä¼˜åŒ–å±‚"
        VACUUM[VACUUMæ¸…ç†<br/>Dead Tuple Removal]
        HOT[HOTä¼˜åŒ–<br/>Heap-Only Tuple]
        FILLFACTOR[Fillfactor<br/>é¢„ç•™ç©ºé—´]
    end

    subgraph "ç›‘æ§å±‚"
        MONITOR[å­˜å‚¨ç›‘æ§<br/>Storage Monitor]
        ALERT[å‘Šè­¦ç³»ç»Ÿ<br/>Alert System]
        RECOMMEND[ä¼˜åŒ–å»ºè®®<br/>Recommendations]
    end

    BASE --> VACUUM
    VERSIONS --> VACUUM
    INDEXES --> HOT
    OVERHEAD --> FILLFACTOR

    VACUUM --> MONITOR
    HOT --> MONITOR
    FILLFACTOR --> MONITOR

    MONITOR --> ALERT
    MONITOR --> RECOMMEND
```

**å­˜å‚¨å¼€é”€å±‚æ¬¡æ¶æ„**:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L3: å­˜å‚¨å¼€é”€å±‚                          â”‚
â”‚  â”œâ”€ åŸºç¡€å­˜å‚¨ (Base Storage)              â”‚
â”‚  â”œâ”€ ç‰ˆæœ¬é“¾å­˜å‚¨ (Version Chain)           â”‚
â”‚  â”œâ”€ ç´¢å¼•å­˜å‚¨ (Index Storage)             â”‚
â”‚  â”œâ”€ å…ƒæ•°æ®å¼€é”€ (Overhead)                â”‚
â”‚  â””â”€ WALæ—¥å¿— (Write-Ahead Log)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚
        â”‚ ä¼˜åŒ–               â”‚ ç›‘æ§
        â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L2: ä¼˜åŒ–å±‚  â”‚  â”‚  L2: ç›‘æ§å±‚      â”‚
â”‚  VACUUM      â”‚  â”‚  å­˜å‚¨ç›‘æ§        â”‚
â”‚  HOTä¼˜åŒ–     â”‚  â”‚  å‘Šè­¦ç³»ç»Ÿ        â”‚
â”‚  Fillfactor  â”‚  â”‚  ä¼˜åŒ–å»ºè®®        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ å­˜å‚¨ç®¡ç†
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L1: å­˜å‚¨å±‚  â”‚
â”‚  å †è¡¨        â”‚
â”‚  ç´¢å¼•        â”‚
â”‚  WAL         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 11.2 ç‰ˆæœ¬é“¾æ¼”åŒ–æµç¨‹å›¾

**ç‰ˆæœ¬é“¾æ¼”åŒ–ä¸å­˜å‚¨å¼€é”€æµç¨‹** (Mermaid):

```mermaid
flowchart TD
    START([INSERTæ“ä½œ]) --> CREATE[åˆ›å»ºåˆå§‹ç‰ˆæœ¬<br/>xmin=100, xmax=0]
    CREATE --> STORAGE1[å­˜å‚¨å¼€é”€: 1ä¸ªå…ƒç»„]

    STORAGE1 --> UPDATE1{UPDATEæ“ä½œ?}
    UPDATE1 -->|æ˜¯| NEW_VERSION1[åˆ›å»ºæ–°ç‰ˆæœ¬<br/>xmin=101, xmax=0]
    UPDATE1 -->|å¦| COMMIT1[COMMIT]

    NEW_VERSION1 --> OLD_VERSION1[æ ‡è®°æ—§ç‰ˆæœ¬<br/>xmax=101]
    OLD_VERSION1 --> STORAGE2[å­˜å‚¨å¼€é”€: 2ä¸ªå…ƒç»„]

    STORAGE2 --> UPDATE2{ç»§ç»­UPDATE?}
    UPDATE2 -->|æ˜¯| NEW_VERSION2[åˆ›å»ºæ–°ç‰ˆæœ¬<br/>xmin=102, xmax=0]
    UPDATE2 -->|å¦| VACUUM_CHECK{VACUUMæ£€æŸ¥}

    NEW_VERSION2 --> OLD_VERSION2[æ ‡è®°æ—§ç‰ˆæœ¬<br/>xmax=102]
    OLD_VERSION2 --> STORAGE3[å­˜å‚¨å¼€é”€: 3ä¸ªå…ƒç»„]

    STORAGE3 --> VACUUM_CHECK
    VACUUM_CHECK -->|æ­»å…ƒç»„å¯æ¸…ç†| VACUUM[VACUUMæ¸…ç†]
    VACUUM_CHECK -->|æœ‰æ´»è·ƒäº‹åŠ¡| WAIT[ç­‰å¾…]

    VACUUM --> REMOVE[ç§»é™¤æ­»å…ƒç»„]
    REMOVE --> STORAGE4[å­˜å‚¨å¼€é”€: 1ä¸ªå…ƒç»„<br/>æ¢å¤]

    COMMIT1 --> END([å®Œæˆ])
    WAIT --> VACUUM_CHECK
    STORAGE4 --> END
```

**ç‰ˆæœ¬é“¾å­˜å‚¨å¼€é”€æ¼”åŒ–**:

```text
ç‰ˆæœ¬é“¾å­˜å‚¨å¼€é”€æ¼”åŒ–:
â”œâ”€ åˆå§‹çŠ¶æ€: 1ä¸ªå…ƒç»„
â”‚   â””â”€ å­˜å‚¨å¼€é”€: TupleSize
â”‚
â”œâ”€ ç¬¬1æ¬¡UPDATE: 2ä¸ªå…ƒç»„
â”‚   â”œâ”€ æ—§ç‰ˆæœ¬: xmax=101 (æ­»å…ƒç»„)
â”‚   â”œâ”€ æ–°ç‰ˆæœ¬: xmin=101 (æ´»å…ƒç»„)
â”‚   â””â”€ å­˜å‚¨å¼€é”€: 2 Ã— TupleSize
â”‚
â”œâ”€ ç¬¬2æ¬¡UPDATE: 3ä¸ªå…ƒç»„
â”‚   â”œâ”€ ç‰ˆæœ¬1: xmax=102 (æ­»å…ƒç»„)
â”‚   â”œâ”€ ç‰ˆæœ¬2: xmax=102 (æ­»å…ƒç»„)
â”‚   â”œâ”€ ç‰ˆæœ¬3: xmin=102 (æ´»å…ƒç»„)
â”‚   â””â”€ å­˜å‚¨å¼€é”€: 3 Ã— TupleSize
â”‚
â””â”€ VACUUMå: 1ä¸ªå…ƒç»„
    â”œâ”€ æ­»å…ƒç»„è¢«æ¸…ç†
    â”œâ”€ åªä¿ç•™æ´»å…ƒç»„
    â””â”€ å­˜å‚¨å¼€é”€: 1 Ã— TupleSize (æ¢å¤)
```

### 11.3 å­˜å‚¨ä¼˜åŒ–å†³ç­–æ ‘

**å­˜å‚¨ä¼˜åŒ–é€‰æ‹©å†³ç­–æ ‘**:

```text
                é€‰æ‹©å­˜å‚¨ä¼˜åŒ–ç­–ç•¥
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   å­˜å‚¨é—®é¢˜åˆ†æ        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚               â”‚               â”‚
   è¡¨è†¨èƒ€          ç´¢å¼•è†¨èƒ€        ç‰ˆæœ¬é“¾è¿‡é•¿
   (>50%)         (>100%)         (>10ä¸ªç‰ˆæœ¬)
      â”‚               â”‚               â”‚
      â–¼               â–¼               â–¼
   VACUUM FULL    HOTä¼˜åŒ–         æ£€æŸ¥é•¿äº‹åŠ¡
   + é‡å»ºè¡¨       + Fillfactor    + æ‹†åˆ†äº‹åŠ¡
      â”‚               â”‚               â”‚
      â”‚               â”‚               â”‚
      â–¼               â–¼               â–¼
   å®Œå…¨æ¸…ç†        å‡å°‘ç´¢å¼•æ›´æ–°    å‡å°‘ç‰ˆæœ¬æ•°
   é‡Šæ”¾ç©ºé—´        é™ä½è†¨èƒ€ç‡      é™ä½å¼€é”€
```

**å­˜å‚¨ä¼˜åŒ–é…ç½®å†³ç­–æ ‘**:

```text
                é€‰æ‹©å­˜å‚¨é…ç½®
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   æ›´æ–°é¢‘ç‡åˆ†æ        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚               â”‚               â”‚
   é«˜æ›´æ–°é¢‘ç‡      ä¸­ç­‰æ›´æ–°é¢‘ç‡    ä½æ›´æ–°é¢‘ç‡
   (>1k TPS)      (100-1k TPS)    (<100 TPS)
      â”‚               â”‚               â”‚
      â–¼               â–¼               â–¼
   Fillfactor=80   Fillfactor=90   Fillfactor=100
   + HOTä¼˜åŒ–       + å®šæœŸVACUUM   + æŒ‰éœ€VACUUM
      â”‚               â”‚               â”‚
      â”‚               â”‚               â”‚
      â–¼               â–¼               â–¼
   é¢„ç•™ç©ºé—´        å¹³è¡¡æ–¹æ¡ˆ        æœ€å¤§ç©ºé—´
   å‡å°‘è†¨èƒ€        å®šæœŸæ¸…ç†        æŒ‰éœ€æ¸…ç†
```

**å­˜å‚¨å¼€é”€å¯¹æ¯”çŸ©é˜µ**:

| å­˜å‚¨ç»„ä»¶ | åŸºç¡€å¼€é”€ | ç‰ˆæœ¬é“¾å¼€é”€ | ç´¢å¼•å¼€é”€ | ä¼˜åŒ–åå¼€é”€ | ä¼˜åŒ–ç­–ç•¥ |
|---------|---------|-----------|---------|-----------|---------|
| **å †è¡¨** | 100% | +200% (3ç‰ˆæœ¬) | - | 100% (VACUUMå) | VACUUM |
| **B-treeç´¢å¼•** | 100% | +100% (ç´¢å¼•æ›´æ–°) | - | 50% (HOTä¼˜åŒ–) | HOT |
| **WALæ—¥å¿—** | 100% | +50% (å¢é‡) | - | 100% (å½’æ¡£) | å½’æ¡£ |
| **å…ƒæ•°æ®** | 100% | 0% (å›ºå®š) | - | 100% (å›ºå®š) | æ— ä¼˜åŒ– |

**å­˜å‚¨ä¼˜åŒ–ç­–ç•¥å¯¹æ¯”çŸ©é˜µ**:

| ä¼˜åŒ–ç­–ç•¥ | å­˜å‚¨èŠ‚çœ | æ€§èƒ½å½±å“ | å®æ–½éš¾åº¦ | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|---------|---------|
| **VACUUM** | é«˜ (50-90%) | ä½ (åå°è¿è¡Œ) | ä½ | æ‰€æœ‰åœºæ™¯ |
| **HOTä¼˜åŒ–** | ä¸­ (30-50%) | æ—  | ä¸­ | é¢‘ç¹æ›´æ–°éç´¢å¼•åˆ— |
| **Fillfactor** | ä¸­ (20-30%) | æ—  | ä½ | é¢‘ç¹æ›´æ–°è¡¨ |
| **åˆ†åŒºè¡¨** | é«˜ (æŒ‰åˆ†åŒºæ¸…ç†) | ä¸­ (æŸ¥è¯¢å¤æ‚åº¦) | é«˜ | å¤§è¡¨ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0ï¼ˆå¤§å¹…å……å®ï¼‰
**æœ€åæ›´æ–°**: 2025-12-05
**æ–°å¢å†…å®¹**: å¾®åˆ†æ–¹ç¨‹æ¨¡å‹ã€çœŸå®æ¡ˆä¾‹ã€åä¾‹åˆ†æã€å®Œæ•´å·¥å…·ã€å®é™…åº”ç”¨æ¡ˆä¾‹ã€å®Œæ•´å®ç°ä»£ç ã€å­˜å‚¨å¼€é”€åˆ†æå¯è§†åŒ–ï¼ˆå­˜å‚¨å¼€é”€åˆ†è§£æ¶æ„å›¾ã€ç‰ˆæœ¬é“¾æ¼”åŒ–æµç¨‹å›¾ã€å­˜å‚¨ä¼˜åŒ–å†³ç­–æ ‘ï¼‰ã€å­˜å‚¨å¼€é”€åˆ†æèƒŒæ™¯ä¸æ¼”è¿›ï¼ˆä¸ºä»€ä¹ˆéœ€è¦å­˜å‚¨å¼€é”€åˆ†æã€å†å²èƒŒæ™¯ã€ç†è®ºåŸºç¡€ã€æ ¸å¿ƒæŒ‘æˆ˜ï¼‰ã€å­˜å‚¨å¼€é”€åˆ†æåä¾‹è¡¥å……ï¼ˆ6ä¸ªæ–°å¢åä¾‹ï¼šå­˜å‚¨å¼€é”€åˆ†æä¸å®Œæ•´ã€ç‰ˆæœ¬é“¾é•¿åº¦é¢„æµ‹é”™è¯¯ã€ç´¢å¼•è†¨èƒ€åˆ†æè¢«å¿½ç•¥ã€å­˜å‚¨ä¼˜åŒ–ç­–ç•¥ä¸å½“ï¼‰

**å…³è”æ–‡æ¡£**:

- `02-è®¾è®¡æƒè¡¡åˆ†æ/05-å­˜å‚¨-å¹¶å‘æƒè¡¡.md`
- `05-å®ç°æœºåˆ¶/03-PostgreSQL-VACUUMæœºåˆ¶.md`
- `09-å·¥ä¸šæ¡ˆä¾‹åº“/05-IoTæ—¶åºæ•°æ®.md` (å¤§è¡¨ç®¡ç†)

**å‚è€ƒ**:

- PostgreSQLæºç : `src/backend/access/heap/`
- pgstattupleæ–‡æ¡£: <https://www.postgresql.org/docs/current/pgstattuple.html>
