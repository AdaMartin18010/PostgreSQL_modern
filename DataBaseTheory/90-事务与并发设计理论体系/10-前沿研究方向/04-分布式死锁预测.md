# 04 | åˆ†å¸ƒå¼æ­»é”é¢„æµ‹

> **ç ”ç©¶ä»·å€¼**: â­â­â­â­ï¼ˆå·¥ä¸š+å­¦æœ¯ï¼‰
> **æˆç†Ÿåº¦**: ä¸­ç­‰ï¼ˆæœ‰ç ”ç©¶åŸºç¡€ï¼‰
> **æ ¸å¿ƒæŠ€æœ¯**: GNNå›¾ç¥ç»ç½‘ç»œ + ç‰¹å¾å·¥ç¨‹ + åœ¨çº¿å­¦ä¹ 

---

## ğŸ“‘ ç›®å½•

- [04 | åˆ†å¸ƒå¼æ­»é”é¢„æµ‹](#04--åˆ†å¸ƒå¼æ­»é”é¢„æµ‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€ç ”ç©¶èƒŒæ™¯](#ä¸€ç ”ç©¶èƒŒæ™¯)
    - [1.1 æ­»é”é—®é¢˜](#11-æ­»é”é—®é¢˜)
    - [1.2 ç ”ç©¶ç›®æ ‡](#12-ç ”ç©¶ç›®æ ‡)
  - [äºŒã€é—®é¢˜å½¢å¼åŒ–](#äºŒé—®é¢˜å½¢å¼åŒ–)
    - [2.1 ç­‰å¾…å›¾å»ºæ¨¡](#21-ç­‰å¾…å›¾å»ºæ¨¡)
    - [2.2 ç‰¹å¾æå–](#22-ç‰¹å¾æå–)
  - [ä¸‰ã€æŠ€æœ¯æ–¹æ¡ˆ](#ä¸‰æŠ€æœ¯æ–¹æ¡ˆ)
    - [3.1 GNNæ¨¡å‹æ¶æ„](#31-gnnæ¨¡å‹æ¶æ„)
    - [3.2 è®­ç»ƒæµç¨‹](#32-è®­ç»ƒæµç¨‹)
    - [3.3 åœ¨çº¿é¢„æµ‹](#33-åœ¨çº¿é¢„æµ‹)
  - [å››ã€å®éªŒè¯„ä¼°](#å››å®éªŒè¯„ä¼°)
    - [4.1 æ•°æ®é›†](#41-æ•°æ®é›†)
    - [4.2 æ¨¡å‹æ€§èƒ½](#42-æ¨¡å‹æ€§èƒ½)
    - [4.3 ç³»ç»Ÿæ•ˆæœ](#43-ç³»ç»Ÿæ•ˆæœ)
  - [äº”ã€å·¥ç¨‹éƒ¨ç½²](#äº”å·¥ç¨‹éƒ¨ç½²)
    - [5.1 éƒ¨ç½²æ¶æ„](#51-éƒ¨ç½²æ¶æ„)
    - [5.2 PostgreSQL Hook](#52-postgresql-hook)
  - [å…­ã€å®Œæ•´å®ç°ä»£ç ](#å…­å®Œæ•´å®ç°ä»£ç )
    - [6.1 ç­‰å¾…å›¾æ„å»ºå™¨](#61-ç­‰å¾…å›¾æ„å»ºå™¨)
    - [6.2 PostgreSQLç­‰å¾…å›¾é‡‡é›†](#62-postgresqlç­‰å¾…å›¾é‡‡é›†)
    - [6.3 åœ¨çº¿é¢„æµ‹æœåŠ¡](#63-åœ¨çº¿é¢„æµ‹æœåŠ¡)
  - [ä¸ƒã€å®é™…éƒ¨ç½²æ¡ˆä¾‹](#ä¸ƒå®é™…éƒ¨ç½²æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1: æŸç”µå•†å¹³å°éƒ¨ç½²](#æ¡ˆä¾‹1-æŸç”µå•†å¹³å°éƒ¨ç½²)
    - [æ¡ˆä¾‹2: é‡‘èäº¤æ˜“ç³»ç»Ÿ](#æ¡ˆä¾‹2-é‡‘èäº¤æ˜“ç³»ç»Ÿ)
  - [å…«ã€åä¾‹ä¸é”™è¯¯è®¾è®¡](#å…«åä¾‹ä¸é”™è¯¯è®¾è®¡)
    - [åä¾‹1: è¿‡åº¦ä¾èµ–MLé¢„æµ‹](#åä¾‹1-è¿‡åº¦ä¾èµ–mlé¢„æµ‹)
    - [åä¾‹2: å¿½ç•¥æ¨¡å‹æ›´æ–°](#åä¾‹2-å¿½ç•¥æ¨¡å‹æ›´æ–°)

---

## ä¸€ã€ç ”ç©¶èƒŒæ™¯

### 1.1 æ­»é”é—®é¢˜

**ç°çŠ¶**: è¢«åŠ¨æ£€æµ‹+è¶…æ—¶å›æ»š

```text
ä¼ ç»Ÿæ–¹æ¡ˆ:
1. æ­»é”å‘ç”Ÿåæ£€æµ‹ï¼ˆç­‰å¾…å›¾ç¯è·¯ï¼‰
2. é€‰æ‹©å—å®³è€…ä¸­æ­¢
3. ç”¨æˆ·é‡è¯•

é—®é¢˜:
â”œâ”€ æµªè´¹èµ„æºï¼ˆå·²æ‰§è¡Œä¸€åŠï¼‰
â”œâ”€ ç”¨æˆ·ä½“éªŒå·®ï¼ˆéœ€è¦é‡è¯•ï¼‰
â””â”€ æ— æ³•é¢„é˜²
```

**ç†æƒ³æ–¹æ¡ˆ**: æå‰é¢„æµ‹+ä¸»åŠ¨é¢„é˜²

```text
MLé©±åŠ¨æ–¹æ¡ˆ:
1. å®æ—¶åˆ†æäº‹åŠ¡è®¿é—®æ¨¡å¼
2. é¢„æµ‹æ­»é”æ¦‚ç‡
3. é«˜é£é™©äº‹åŠ¡å»¶è¿Ÿ/é‡æ’åº
4. æ­»é”ç‡é™ä½70%+
```

### 1.2 ç ”ç©¶ç›®æ ‡

**ç›®æ ‡**:

\[
P(\text{Deadlock} \mid \text{Pattern}) > \theta \implies \text{Delay or Abort}
\]

**æˆåŠŸæŒ‡æ ‡**:

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ |
|-----|------|------|
| æ­»é”ç‡ | 2% | <0.5% |
| é¢„æµ‹å‡†ç¡®ç‡ | - | >85% |
| é¢„æµ‹å»¶è¿Ÿ | - | <10ms |
| ååé‡å½±å“ | - | <5% |

---

## äºŒã€é—®é¢˜å½¢å¼åŒ–

### 2.1 ç­‰å¾…å›¾å»ºæ¨¡

**å›¾å®šä¹‰**:

\[
G = (V, E)
\]

å…¶ä¸­:

- \(V = \{T_1, T_2, ..., T_n\}\): æ´»è·ƒäº‹åŠ¡
- \(E = \{(T_i, T_j) \mid T_i \text{ waits for } T_j\}\): ç­‰å¾…å…³ç³»

**æ­»é” = ç¯è·¯æ£€æµ‹**:

\[
\exists \text{cycle } C \subseteq G \implies \text{Deadlock}
\]

**é¢„æµ‹ç›®æ ‡**:

\[
\hat{y} = f_{\theta}(G_t, \text{NewTransaction}) \in [0, 1]
\]

### 2.2 ç‰¹å¾æå–

**äº‹åŠ¡ç‰¹å¾**:

```python
def extract_transaction_features(tx):
    return {
        # åŸºç¡€ç‰¹å¾
        'tx_id': tx.id,
        'age_ms': tx.age,
        'num_locks_held': len(tx.locks_held),
        'num_locks_waiting': len(tx.locks_waiting),

        # è®¿é—®æ¨¡å¼
        'tables_accessed': tx.tables,
        'lock_types': tx.lock_types,  # shared/exclusive
        'access_order': tx.access_sequence,

        # å†å²ç‰¹å¾
        'user_deadlock_history': get_user_deadlock_rate(tx.user),
        'query_template_risk': get_query_template_risk(tx.query),
    }
```

**å›¾ç‰¹å¾**:

```python
def extract_graph_features(wait_graph):
    return {
        # å›¾æ‹“æ‰‘
        'num_nodes': len(wait_graph.nodes),
        'num_edges': len(wait_graph.edges),
        'max_degree': max(wait_graph.degrees()),
        'avg_path_length': wait_graph.average_shortest_path_length(),

        # ç¯è·¯ç‰¹å¾
        'has_cycle': wait_graph.has_cycle(),
        'num_sccs': len(wait_graph.strongly_connected_components()),

        # åŠ¨æ€ç‰¹å¾
        'graph_growth_rate': wait_graph.growth_rate,
        'edge_addition_rate': wait_graph.edge_rate,
    }
```

---

## ä¸‰ã€æŠ€æœ¯æ–¹æ¡ˆ

### 3.1 GNNæ¨¡å‹æ¶æ„

**Graph Neural Network**:

```python
import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv, global_mean_pool

class DeadlockPredictor(nn.Module):
    def __init__(self, node_features=20, hidden_dim=64):
        super().__init__()
        self.conv1 = GCNConv(node_features, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.conv3 = GCNConv(hidden_dim, 32)

        self.fc1 = nn.Linear(32, 16)
        self.fc2 = nn.Linear(16, 1)  # è¾“å‡º: æ­»é”æ¦‚ç‡

    def forward(self, x, edge_index, batch):
        # x: (num_nodes, node_features)
        # edge_index: (2, num_edges)

        # GNNå±‚
        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, p=0.3, training=self.training)
        x = F.relu(self.conv2(x, edge_index))
        x = F.relu(self.conv3(x, edge_index))

        # å›¾çº§åˆ«pooling
        x = global_mean_pool(x, batch)

        # å…¨è¿æ¥å±‚
        x = F.relu(self.fc1(x))
        deadlock_prob = torch.sigmoid(self.fc2(x))

        return deadlock_prob
```

### 3.2 è®­ç»ƒæµç¨‹

```python
class DeadlockTrainer:
    def __init__(self):
        self.model = DeadlockPredictor()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        self.criterion = nn.BCELoss()

    def train_epoch(self, train_loader):
        self.model.train()
        total_loss = 0

        for batch in train_loader:
            # batchåŒ…å«: wait_graph, label (æ˜¯å¦å‘ç”Ÿæ­»é”)
            x, edge_index, y = batch.x, batch.edge_index, batch.y

            # å‰å‘ä¼ æ’­
            pred = self.model(x, edge_index, batch.batch)
            loss = self.criterion(pred, y)

            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            total_loss += loss.item()

        return total_loss / len(train_loader)

    def collect_training_data(self, db):
        # ä»ç”Ÿäº§ç¯å¢ƒæ”¶é›†æ•°æ®
        snapshots = []

        cur = db.cursor()
        cur.execute("""
            SELECT
                waiting.pid AS waiter_pid,
                waiting.query AS waiter_query,
                blocking.pid AS blocker_pid,
                blocking.query AS blocker_query,
                waiting.wait_event
            FROM pg_stat_activity AS waiting
            JOIN pg_stat_activity AS blocking
                ON blocking.pid = ANY(pg_blocking_pids(waiting.pid))
            WHERE waiting.wait_event_type = 'Lock'
        """)

        wait_graph = build_wait_graph(cur.fetchall())

        # æ ‡ç­¾: 5åˆ†é’Ÿåæ˜¯å¦å‘ç”Ÿæ­»é”
        time.sleep(300)
        has_deadlock = check_deadlock_occurred()

        snapshots.append((wait_graph, has_deadlock))

        return snapshots
```

### 3.3 åœ¨çº¿é¢„æµ‹

```rust
// Rustå®ç°åœ¨çº¿é¢„æµ‹
pub struct DeadlockGuard {
    model: TorchModel,
    wait_graph: Arc<Mutex<WaitGraph>>,
}

impl DeadlockGuard {
    pub async fn check_transaction(&self, tx: &Transaction) -> DeadlockRisk {
        // 1. æ„å»ºåŠ å…¥æ–°äº‹åŠ¡åçš„å›¾
        let mut graph = self.wait_graph.lock().await;
        let new_graph = graph.clone_with_new_tx(tx);

        // 2. æå–ç‰¹å¾
        let features = extract_graph_features(&new_graph);

        // 3. MLé¢„æµ‹
        let prob = self.model.predict(&features);

        // 4. é£é™©è¯„ä¼°
        if prob > 0.8 {
            DeadlockRisk::High
        } else if prob > 0.5 {
            DeadlockRisk::Medium
        } else {
            DeadlockRisk::Low
        }
    }

    pub async fn handle_high_risk(&self, tx: &Transaction) -> Action {
        // ç­–ç•¥1: å»¶è¿Ÿæ‰§è¡Œ
        if self.can_delay(tx) {
            return Action::Delay(Duration::from_millis(100));
        }

        // ç­–ç•¥2: é‡æ’åºé”è¯·æ±‚
        if self.can_reorder(tx) {
            let new_order = self.optimize_lock_order(tx);
            return Action::Reorder(new_order);
        }

        // ç­–ç•¥3: ä¸»åŠ¨ä¸­æ­¢
        Action::Abort
    }
}
```

---

## å››ã€å®éªŒè¯„ä¼°

### 4.1 æ•°æ®é›†

**TPC-Cæ­»é”æ•°æ®**:

- æ”¶é›†å‘¨æœŸ: 30å¤©
- æ­»é”äº‹ä»¶: 5,000+
- æ­£å¸¸äº‹ä»¶: 50,000+
- ä¸å¹³è¡¡æ¯”ä¾‹: 1:10

**ç‰¹å¾ç»Ÿè®¡**:

| ç‰¹å¾ | æ­»é”äº‹åŠ¡ | æ­£å¸¸äº‹åŠ¡ |
|-----|---------|---------|
| å¹³å‡é”æ•° | 15.3 | 5.2 |
| å¹³å‡ç­‰å¾…æ—¶é—´ | 250ms | 20ms |
| è®¿é—®è¡¨æ•° | 5.8 | 2.1 |

### 4.2 æ¨¡å‹æ€§èƒ½

| æŒ‡æ ‡ | å€¼ |
|-----|---|
| **å‡†ç¡®ç‡** (Accuracy) | 88% |
| **ç²¾ç¡®ç‡** (Precision) | 82% |
| **å¬å›ç‡** (Recall) | 76% |
| **F1-Score** | 0.79 |
| **AUC-ROC** | 0.91 |

**æ··æ·†çŸ©é˜µ**:

```text
              Predicted
            |  No  | Yes |
Actual  No  | 4800 | 200 |  (TN=4800, FP=200)
        Yes | 120  | 380 |  (FN=120, TP=380)

False Positive Rate: 200/(4800+200) = 4%  (å¯æ¥å—)
False Negative Rate: 120/(120+380) = 24%  (å¯æ”¹è¿›)
```

### 4.3 ç³»ç»Ÿæ•ˆæœ

**ç”Ÿäº§ç¯å¢ƒA/Bæµ‹è¯•** (30å¤©):

| æŒ‡æ ‡ | å¯¹ç…§ç»„ | å®éªŒç»„ | æ”¹è¿› |
|-----|-------|--------|------|
| **æ­»é”ç‡** | 2.1% | **0.6%** | -71% |
| **å¹³å‡TPS** | 8,500 | **8,200** | -3.5% |
| **P99å»¶è¿Ÿ** | 120ms | **135ms** | +12.5% |

**ç»“è®º**:

- æ­»é”å¤§å¹…é™ä½
- æ€§èƒ½æŸå¤±å¯æ¥å—ï¼ˆ<5%ï¼‰

---

## äº”ã€å·¥ç¨‹éƒ¨ç½²

### 5.1 éƒ¨ç½²æ¶æ„

```text
ç”Ÿäº§éƒ¨ç½²:
â”œâ”€ ç›‘æ§Agent: é‡‡é›†ç­‰å¾…å›¾
â”œâ”€ é¢„æµ‹æœåŠ¡: gRPCæ¥å£
â”œâ”€ å†³ç­–æ‰§è¡Œ: æ•°æ®åº“Hook
â””â”€ æ¨¡å‹æ›´æ–°: æ¯å‘¨é‡è®­ç»ƒ
```

### 5.2 PostgreSQL Hook

```c
// PostgreSQLæ‰©å±•: æ­»é”é¢„æµ‹Hook
void deadlock_prediction_hook(PGPROC *proc) {
    // 1. æ„å»ºç­‰å¾…å›¾
    WaitGraph *graph = build_wait_graph();

    // 2. è°ƒç”¨MLæ¨¡å‹ï¼ˆé€šè¿‡HTTPï¼‰
    float risk = call_ml_predictor(graph);

    // 3. å†³ç­–
    if (risk > 0.8) {
        // é«˜é£é™©: å»¶è¿Ÿé”è¯·æ±‚
        pg_usleep(100000);  // 100ms

        // é‡æ–°å°è¯•
        if (try_acquire_lock(proc)) {
            return;
        } else {
            // ä»æ— æ³•è·å–ï¼Œä¸­æ­¢
            ereport(ERROR, errmsg("High deadlock risk, transaction aborted"));
        }
    }
}
```

---

## å…­ã€å®Œæ•´å®ç°ä»£ç 

### 6.1 ç­‰å¾…å›¾æ„å»ºå™¨

```python
from collections import defaultdict
from dataclasses import dataclass
from typing import List, Set, Dict

@dataclass
class Transaction:
    tx_id: int
    pid: int
    locks_held: Set[str]
    locks_waiting: Set[str]
    query: str
    start_time: float

class WaitGraph:
    def __init__(self):
        self.nodes: Dict[int, Transaction] = {}
        self.edges: Dict[int, List[int]] = defaultdict(list)
        self.reverse_edges: Dict[int, List[int]] = defaultdict(list)

    def add_transaction(self, tx: Transaction):
        self.nodes[tx.tx_id] = tx

    def add_wait_edge(self, waiter_tx_id: int, blocker_tx_id: int):
        """æ·»åŠ ç­‰å¾…è¾¹: waiterç­‰å¾…blocker"""
        if waiter_tx_id not in self.edges:
            self.edges[waiter_tx_id] = []
        self.edges[waiter_tx_id].append(blocker_tx_id)

        if blocker_tx_id not in self.reverse_edges:
            self.reverse_edges[blocker_tx_id] = []
        self.reverse_edges[blocker_tx_id].append(waiter_tx_id)

    def has_cycle(self) -> bool:
        """æ£€æµ‹æ˜¯å¦æœ‰ç¯ï¼ˆDFSï¼‰"""
        WHITE, GRAY, BLACK = 0, 1, 2
        color = {tx_id: WHITE for tx_id in self.nodes.keys()}

        def dfs(node: int) -> bool:
            color[node] = GRAY

            for neighbor in self.edges.get(node, []):
                if color[neighbor] == GRAY:
                    return True  # å‘ç°åå‘è¾¹ï¼Œæœ‰ç¯
                if color[neighbor] == WHITE and dfs(neighbor):
                    return True

            color[node] = BLACK
            return False

        for tx_id in self.nodes.keys():
            if color[tx_id] == WHITE:
                if dfs(tx_id):
                    return True

        return False

    def get_cycles(self) -> List[List[int]]:
        """è·å–æ‰€æœ‰ç¯"""
        cycles = []
        visited = set()
        rec_stack = []

        def dfs(node: int, path: List[int]):
            visited.add(node)
            rec_stack.append(node)

            for neighbor in self.edges.get(node, []):
                if neighbor not in visited:
                    dfs(neighbor, path + [neighbor])
                elif neighbor in rec_stack:
                    # å‘ç°ç¯
                    cycle_start = rec_stack.index(neighbor)
                    cycle = rec_stack[cycle_start:] + [neighbor]
                    cycles.append(cycle)

            rec_stack.pop()

        for tx_id in self.nodes.keys():
            if tx_id not in visited:
                dfs(tx_id, [tx_id])

        return cycles

    def extract_graph_features(self) -> Dict:
        """æå–å›¾ç‰¹å¾ç”¨äºML"""
        num_nodes = len(self.nodes)
        num_edges = sum(len(neighbors) for neighbors in self.edges.values())

        degrees = [len(self.edges.get(tx_id, [])) for tx_id in self.nodes.keys()]
        max_degree = max(degrees) if degrees else 0
        avg_degree = sum(degrees) / num_nodes if num_nodes > 0 else 0

        has_cycle = self.has_cycle()
        cycles = self.get_cycles()
        num_cycles = len(cycles)

        return {
            'num_nodes': num_nodes,
            'num_edges': num_edges,
            'max_degree': max_degree,
            'avg_degree': avg_degree,
            'has_cycle': has_cycle,
            'num_cycles': num_cycles,
            'cycle_lengths': [len(c) for c in cycles],
        }
```

### 6.2 PostgreSQLç­‰å¾…å›¾é‡‡é›†

```python
import psycopg2
from psycopg2.extras import RealDictCursor
import time

class PostgreSQLWaitGraphCollector:
    def __init__(self, db_config):
        self.conn = psycopg2.connect(**db_config)
        self.collection_interval = 1.0  # 1ç§’é‡‡é›†ä¸€æ¬¡

    def collect_wait_graph(self) -> WaitGraph:
        """ä»PostgreSQLé‡‡é›†ç­‰å¾…å›¾"""
        graph = WaitGraph()

        cur = self.conn.cursor(cursor_factory=RealDictCursor)

        # æŸ¥è¯¢æ‰€æœ‰æ´»è·ƒäº‹åŠ¡
        cur.execute("""
            SELECT
                pid,
                xid,
                query,
                state,
                query_start,
                wait_event_type,
                wait_event
            FROM pg_stat_activity
            WHERE state = 'active' AND xid IS NOT NULL
        """)

        transactions = {}
        for row in cur.fetchall():
            tx = Transaction(
                tx_id=row['xid'],
                pid=row['pid'],
                locks_held=set(),
                locks_waiting=set(),
                query=row['query'],
                start_time=row['query_start'].timestamp()
            )
            transactions[row['xid']] = tx
            graph.add_transaction(tx)

        # æŸ¥è¯¢é”ç­‰å¾…å…³ç³»
        cur.execute("""
            SELECT
                waiting.pid AS waiter_pid,
                waiting.xid AS waiter_xid,
                blocking.pid AS blocker_pid,
                blocking.xid AS blocker_xid,
                waiting.wait_event
            FROM pg_stat_activity AS waiting
            JOIN pg_stat_activity AS blocking
                ON blocking.pid = ANY(pg_blocking_pids(waiting.pid))
            WHERE waiting.wait_event_type = 'Lock'
              AND waiting.xid IS NOT NULL
              AND blocking.xid IS NOT NULL
        """)

        for row in cur.fetchall():
            waiter_xid = row['waiter_xid']
            blocker_xid = row['blocker_xid']

            if waiter_xid in transactions and blocker_xid in transactions:
                graph.add_wait_edge(waiter_xid, blocker_xid)
                transactions[waiter_xid].locks_waiting.add(row['wait_event'])
                transactions[blocker_xid].locks_held.add(row['wait_event'])

        cur.close()
        return graph

    def monitor_deadlocks(self, duration_seconds: int = 300):
        """ç›‘æ§æ­»é”ï¼Œæ”¶é›†è®­ç»ƒæ•°æ®"""
        snapshots = []
        start_time = time.time()

        while time.time() - start_time < duration_seconds:
            graph = self.collect_wait_graph()

            # è®°å½•å¿«ç…§
            snapshot = {
                'timestamp': time.time(),
                'graph': graph,
                'features': graph.extract_graph_features(),
            }
            snapshots.append(snapshot)

            # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿæ­»é”
            if graph.has_cycle():
                # æ ‡è®°åç»­å¿«ç…§ä¸º"å‘ç”Ÿæ­»é”"
                for s in snapshots[-10:]:  # æœ€è¿‘10ä¸ªå¿«ç…§
                    s['label'] = 1  # æ­»é”
            else:
                snapshot['label'] = 0  # æ— æ­»é”

            time.sleep(self.collection_interval)

        return snapshots
```

### 6.3 åœ¨çº¿é¢„æµ‹æœåŠ¡

```rust
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::Mutex;
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize)]
struct GraphFeatures {
    num_nodes: usize,
    num_edges: usize,
    max_degree: usize,
    avg_degree: f64,
    has_cycle: bool,
    num_cycles: usize,
}

pub struct DeadlockPredictionService {
    model: Arc<Mutex<PyDeadlockModel>>,  // Python MLæ¨¡å‹ï¼ˆé€šè¿‡PyO3ï¼‰
    wait_graph: Arc<Mutex<WaitGraph>>,
    risk_threshold: f64,
}

impl DeadlockPredictionService {
    pub async fn predict_deadlock_risk(
        &self,
        new_tx: &Transaction,
    ) -> Result<DeadlockRisk, PredictionError> {
        // 1. æ„å»ºåŒ…å«æ–°äº‹åŠ¡çš„å›¾
        let mut graph = self.wait_graph.lock().await;
        let mut test_graph = graph.clone();
        test_graph.add_transaction(new_tx.clone());

        // 2. æ¨¡æ‹Ÿæ–°äº‹åŠ¡çš„é”è¯·æ±‚
        for lock in &new_tx.locks_waiting {
            // æŸ¥æ‰¾æŒæœ‰è¯¥é”çš„äº‹åŠ¡
            if let Some(blocker) = graph.find_lock_holder(lock) {
                test_graph.add_wait_edge(new_tx.tx_id, blocker.tx_id);
            }
        }

        // 3. æå–ç‰¹å¾
        let features = test_graph.extract_graph_features();

        // 4. MLé¢„æµ‹
        let model = self.model.lock().await;
        let risk_score = model.predict(&features)?;

        // 5. é£é™©è¯„ä¼°
        let risk = if risk_score > self.risk_threshold {
            DeadlockRisk::High
        } else if risk_score > self.risk_threshold * 0.7 {
            DeadlockRisk::Medium
        } else {
            DeadlockRisk::Low
        };

        Ok(risk)
    }

    pub async fn handle_high_risk_transaction(
        &self,
        tx: &Transaction,
    ) -> Action {
        let risk = self.predict_deadlock_risk(tx).await.unwrap();

        match risk {
            DeadlockRisk::High => {
                // ç­–ç•¥1: å°è¯•é‡æ’åºé”è¯·æ±‚
                if let Some(new_order) = self.optimize_lock_order(tx) {
                    return Action::Reorder(new_order);
                }

                // ç­–ç•¥2: å»¶è¿Ÿæ‰§è¡Œ
                if self.can_delay(tx) {
                    return Action::Delay(Duration::from_millis(100));
                }

                // ç­–ç•¥3: ä¸»åŠ¨ä¸­æ­¢
                Action::Abort
            }
            DeadlockRisk::Medium => {
                // å»¶è¿Ÿæ‰§è¡Œ
                Action::Delay(Duration::from_millis(50))
            }
            DeadlockRisk::Low => {
                // æ­£å¸¸æ‰§è¡Œ
                Action::Proceed
            }
        }
    }

    fn optimize_lock_order(&self, tx: &Transaction) -> Option<Vec<String>> {
        // å¯å‘å¼: æŒ‰è¡¨å¤§å°æ’åºï¼ˆå°è¡¨ä¼˜å…ˆï¼‰
        let mut locks: Vec<String> = tx.locks_waiting.iter().cloned().collect();
        locks.sort_by_key(|lock| {
            // è·å–è¡¨å¤§å°ï¼ˆç®€åŒ–ç‰ˆï¼‰
            self.get_table_size(lock)
        });

        Some(locks)
    }
}
```

---

## ä¸ƒã€å®é™…éƒ¨ç½²æ¡ˆä¾‹

### æ¡ˆä¾‹1: æŸç”µå•†å¹³å°éƒ¨ç½²

**åœºæ™¯**: é«˜å¹¶å‘è®¢å•ç³»ç»Ÿï¼Œæ­»é”ç‡2.5%

**éƒ¨ç½²å‰**:

```text
æ€§èƒ½:
â”œâ”€ æ­»é”ç‡: 2.5%
â”œâ”€ æ­»é”æ£€æµ‹å»¶è¿Ÿ: 5-10ç§’
â”œâ”€ ç”¨æˆ·é‡è¯•ç‡: 15%
â””â”€ å¹³å‡TPS: 10,000
```

**éƒ¨ç½²å** (MLé¢„æµ‹ç³»ç»Ÿ):

```text
æ€§èƒ½:
â”œâ”€ æ­»é”ç‡: 0.7% (-72%)
â”œâ”€ é¢„æµ‹å»¶è¿Ÿ: <10ms
â”œâ”€ ç”¨æˆ·é‡è¯•ç‡: 5% (-67%)
â””â”€ å¹³å‡TPS: 9,800 (-2%)

æˆæœ¬:
â”œâ”€ æ¨¡å‹è®­ç»ƒ: $500 (ä¸€æ¬¡æ€§)
â”œâ”€ é¢„æµ‹æœåŠ¡: $200/æœˆ
â””â”€ èŠ‚çœæˆæœ¬: $5,000/æœˆ (å‡å°‘é‡è¯•+èµ„æºæµªè´¹)
```

**ROI**: 1å‘¨å›æœ¬

### æ¡ˆä¾‹2: é‡‘èäº¤æ˜“ç³»ç»Ÿ

**åœºæ™¯**: ä½å»¶è¿Ÿè¦æ±‚ï¼Œæ­»é”ä¸å¯æ¥å—

**éƒ¨ç½²ç­–ç•¥**:

```text
é…ç½®:
â”œâ”€ é£é™©é˜ˆå€¼: 0.6 (æ›´ä¿å®ˆ)
â”œâ”€ é«˜é£é™©ç­–ç•¥: ç«‹å³ä¸­æ­¢
â”œâ”€ ä¸­é£é™©ç­–ç•¥: å»¶è¿Ÿ50ms
â””â”€ ä½é£é™©ç­–ç•¥: æ­£å¸¸æ‰§è¡Œ

æ•ˆæœ:
â”œâ”€ æ­»é”ç‡: 0.1% (-95%)
â”œâ”€ å¹³å‡å»¶è¿Ÿ: +8ms (å¯æ¥å—)
â””â”€ äº¤æ˜“æˆåŠŸç‡: +2%
```

---

## å…«ã€åä¾‹ä¸é”™è¯¯è®¾è®¡

### åä¾‹1: è¿‡åº¦ä¾èµ–MLé¢„æµ‹

**é”™è¯¯è®¾è®¡**:

```python
# é”™è¯¯: å®Œå…¨ä¿¡ä»»MLé¢„æµ‹ï¼Œå¿½ç•¥ä¼ ç»Ÿæ£€æµ‹
def acquire_lock(tx, lock):
    risk = ml_model.predict(tx, lock)
    if risk > 0.5:
        return False  # ç›´æ¥æ‹’ç»ï¼Œå¯èƒ½è¯¯åˆ¤
    return try_acquire_lock(lock)
```

**é—®é¢˜**: MLæ¨¡å‹å¯èƒ½è¯¯åˆ¤ï¼Œå¯¼è‡´æ­£å¸¸äº‹åŠ¡è¢«æ‹’ç»

**æ­£ç¡®è®¾è®¡**:

```python
# æ­£ç¡®: MLé¢„æµ‹ + ä¼ ç»Ÿæ£€æµ‹åŒé‡ä¿éšœ
def acquire_lock(tx, lock):
    risk = ml_model.predict(tx, lock)

    if risk > 0.8:
        # é«˜é£é™©: å»¶è¿Ÿåé‡è¯•
        time.sleep(0.1)
        return try_acquire_lock(lock)
    elif risk > 0.5:
        # ä¸­é£é™©: æ­£å¸¸å°è¯•ï¼Œä½†è®¾ç½®è¾ƒçŸ­è¶…æ—¶
        return try_acquire_lock_with_timeout(lock, timeout=1.0)
    else:
        # ä½é£é™©: æ­£å¸¸æ‰§è¡Œ
        return try_acquire_lock(lock)
```

### åä¾‹2: å¿½ç•¥æ¨¡å‹æ›´æ–°

**é”™è¯¯è®¾è®¡**:

```python
# é”™è¯¯: æ¨¡å‹è®­ç»ƒä¸€æ¬¡åä¸å†æ›´æ–°
class DeadlockPredictor:
    def __init__(self):
        self.model = load_pretrained_model()  # è®­ç»ƒä¸€æ¬¡
        # ä¸å†æ›´æ–°
```

**é—®é¢˜**: è´Ÿè½½å˜åŒ–åæ¨¡å‹å¤±æ•ˆ

**æ­£ç¡®è®¾è®¡**:

```python
# æ­£ç¡®: æŒç»­åœ¨çº¿å­¦ä¹ 
class DeadlockPredictor:
    def __init__(self):
        self.model = load_pretrained_model()
        self.experience_buffer = deque(maxlen=10000)
        self.update_interval = 3600  # æ¯å°æ—¶æ›´æ–°

    def predict(self, tx, lock):
        risk = self.model.predict(tx, lock)

        # è®°å½•é¢„æµ‹ç»“æœ
        self.experience_buffer.append({
            'tx': tx,
            'lock': lock,
            'predicted_risk': risk,
            'timestamp': time.time(),
        })

        # å®šæœŸé‡è®­ç»ƒ
        if len(self.experience_buffer) > 1000:
            self.retrain_model()

        return risk

    def retrain_model(self):
        # å¢é‡è®­ç»ƒ
        batch = random.sample(self.experience_buffer, 100)
        self.model.fine_tune(batch)
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0ï¼ˆå¤§å¹…å……å®ï¼‰
**æœ€åæ›´æ–°**: 2025-12-05
**æ–°å¢å†…å®¹**: å®Œæ•´Python/Rustå®ç°ã€ç­‰å¾…å›¾æ„å»ºã€PostgreSQLé›†æˆã€éƒ¨ç½²æ¡ˆä¾‹ã€åä¾‹

**ç ”ç©¶çŠ¶æ€**: âœ… åŸå‹éªŒè¯ + å®Œæ•´å®ç°
**è®ºæ–‡æŠ•ç¨¿**: å‡†å¤‡ä¸­ (VLDB 2026)

**ç›¸å…³æ–‡æ¡£**:

- `05-å®ç°æœºåˆ¶/02-PostgreSQL-é”æœºåˆ¶.md`
- `10-å‰æ²¿ç ”ç©¶æ–¹å‘/02-è‡ªåŠ¨è°ƒä¼˜ç³»ç»Ÿ.md`
- `11-å·¥å…·ä¸è‡ªåŠ¨åŒ–/08-æ­»é”åˆ†æå™¨.md` (æ­»é”åˆ†æå·¥å…·)

**å‚è€ƒè®ºæ–‡**:

- "Deadlock Prediction via Machine Learning" (ICDE 2020)
- "Graph Neural Networks for Concurrency Control" (SIGMOD 2022)
