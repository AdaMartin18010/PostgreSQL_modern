# 全文搜索系统 - 高级特性

## 1. 多语言支持

### 1.1 配置多语言

```sql
-- 创建多语言配置
CREATE TEXT SEARCH CONFIGURATION zh_en (COPY = simple);
ALTER TEXT SEARCH CONFIGURATION zh_en
    ADD MAPPING FOR asciiword WITH english_stem;
ALTER TEXT SEARCH CONFIGURATION zh_en
    ADD MAPPING FOR word WITH simple;

-- 使用zhparser（中文分词）
CREATE EXTENSION zhparser;
CREATE TEXT SEARCH CONFIGURATION chinese_zh (PARSER = zhparser);
ALTER TEXT SEARCH CONFIGURATION chinese_zh ADD MAPPING FOR n,v,a,i,e,l WITH simple;

-- 多语言文档表
CREATE TABLE documents_multilang (
    id BIGSERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    language VARCHAR(10),  -- 'zh', 'en', 'ja'
    search_vector_zh TSVECTOR,
    search_vector_en TSVECTOR
);

-- 自动生成搜索向量
CREATE OR REPLACE FUNCTION update_search_vectors()
RETURNS TRIGGER AS $$
BEGIN
    IF NEW.language = 'zh' THEN
        NEW.search_vector_zh := to_tsvector('chinese_zh', COALESCE(NEW.title, '') || ' ' || COALESCE(NEW.content, ''));
    ELSIF NEW.language = 'en' THEN
        NEW.search_vector_en := to_tsvector('english', COALESCE(NEW.title, '') || ' ' || COALESCE(NEW.content, ''));
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_update_search_vectors
BEFORE INSERT OR UPDATE ON documents_multilang
FOR EACH ROW
EXECUTE FUNCTION update_search_vectors();

-- GIN索引
CREATE INDEX idx_docs_zh_fts ON documents_multilang USING GIN (search_vector_zh);
CREATE INDEX idx_docs_en_fts ON documents_multilang USING GIN (search_vector_en);

-- 搜索
SELECT * FROM documents_multilang
WHERE search_vector_zh @@ to_tsquery('chinese_zh', '数据库 & 优化');
```

---

## 2. 相关性排序优化

### 2.1 多因素排序

```sql
-- 综合排序函数
CREATE OR REPLACE FUNCTION calculate_relevance(
    doc documents,
    query_text TEXT
) RETURNS NUMERIC AS $$
DECLARE
    ts_rank_score NUMERIC;
    freshness_score NUMERIC;
    popularity_score NUMERIC;
    final_score NUMERIC;
BEGIN
    -- 文本相关性（权重50%）
    ts_rank_score := ts_rank(
        to_tsvector('chinese', doc.title || ' ' || doc.content),
        plainto_tsquery('chinese', query_text)
    );

    -- 时效性（权重30%）
    freshness_score := EXTRACT(EPOCH FROM (
        now() - doc.created_at
    )) / 86400.0;  -- 天数
    freshness_score := 1.0 / (1.0 + freshness_score / 30.0);  -- 30天衰减

    -- 热度（权重20%）
    popularity_score := LOG(1 + doc.view_count) / 10.0;

    -- 综合得分
    final_score :=
        ts_rank_score * 0.5 +
        freshness_score * 0.3 +
        popularity_score * 0.2;

    RETURN final_score;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- 使用综合排序
SELECT
    doc_id,
    title,
    calculate_relevance(documents, '数据库优化') AS score
FROM documents
WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', '数据库优化')
ORDER BY score DESC
LIMIT 20;
```

### 2.2 字段权重

```sql
-- 标题权重高于内容
SELECT
    doc_id,
    title,
    ts_rank(
        setweight(to_tsvector('chinese', title), 'A') ||
        setweight(to_tsvector('chinese', content), 'B'),
        plainto_tsquery('chinese', '数据库')
    ) AS rank
FROM documents
WHERE
    to_tsvector('chinese', title || ' ' || content) @@
    plainto_tsquery('chinese', '数据库')
ORDER BY rank DESC;
```

---

## 3. 高亮显示

### 3.1 搜索词高亮

```sql
-- 高亮函数
SELECT
    doc_id,
    title,
    ts_headline(
        'chinese',
        content,
        plainto_tsquery('chinese', '数据库优化'),
        'StartSel=<b>, StopSel=</b>, MaxWords=50, MinWords=20'
    ) AS highlighted_snippet
FROM documents
WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', '数据库优化')
ORDER BY ts_rank(to_tsvector('chinese', content), plainto_tsquery('chinese', '数据库优化')) DESC
LIMIT 10;

/*
结果示例:
doc_id | 1
title  | PostgreSQL性能优化
highlighted_snippet | ...讨论<b>数据库</b>的性能<b>优化</b>技巧...
*/
```

---

## 4. 拼写纠错

### 4.1 模糊搜索

```sql
-- 安装pg_trgm扩展
CREATE EXTENSION pg_trgm;

-- 创建trigram索引
CREATE INDEX idx_documents_title_trgm ON documents USING GIN (title gin_trgm_ops);
CREATE INDEX idx_documents_content_trgm ON documents USING GIN (content gin_trgm_ops);

-- 模糊搜索
SELECT
    doc_id,
    title,
    similarity(title, 'databse') AS sim  -- 拼写错误
FROM documents
WHERE title % 'databse'  -- % 是相似度操作符
ORDER BY sim DESC
LIMIT 10;

-- 结果：
-- "database" 相似度 0.8
-- "data base" 相似度 0.6

-- 拼写建议
SELECT word, similarity(word, 'databse') AS sim
FROM (
    SELECT DISTINCT title AS word FROM documents
) words
WHERE word % 'databse'
ORDER BY sim DESC
LIMIT 5;
```

---

## 5. 搜索建议（自动补全）

### 5.1 前缀搜索

```sql
-- 搜索历史表
CREATE TABLE search_queries (
    id BIGSERIAL PRIMARY KEY,
    query TEXT,
    user_id INT,
    result_count INT,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- 前缀索引
CREATE INDEX idx_search_queries_prefix ON search_queries (query text_pattern_ops);

-- 搜索建议
SELECT query, COUNT(*) AS frequency
FROM search_queries
WHERE query LIKE '数据%'
GROUP BY query
ORDER BY frequency DESC
LIMIT 10;

-- 结果：
-- 数据库优化: 1250次
-- 数据库设计: 850次
-- 数据结构: 620次
```

### 5.2 智能建议

```sql
-- 结合全文搜索和trigram
WITH suggestions AS (
    -- 全文匹配
    SELECT query, COUNT(*) AS freq, 1 AS source_type
    FROM search_queries
    WHERE to_tsvector('chinese', query) @@ plainto_tsquery('chinese', '数据库')
    GROUP BY query

    UNION ALL

    -- 模糊匹配
    SELECT query, COUNT(*) AS freq, 2 AS source_type
    FROM search_queries
    WHERE query % '数据库'
    GROUP BY query
)
SELECT
    query,
    SUM(freq) AS total_frequency,
    MIN(source_type) AS match_type  -- 1=精确, 2=模糊
FROM suggestions
GROUP BY query
ORDER BY total_frequency DESC, match_type
LIMIT 10;
```

---

## 6. 搜索分析

### 6.1 热门搜索词

```sql
-- 实时热搜
SELECT
    query,
    COUNT(*) AS search_count,
    COUNT(DISTINCT user_id) AS unique_users
FROM search_queries
WHERE created_at >= now() - INTERVAL '1 hour'
GROUP BY query
ORDER BY search_count DESC
LIMIT 20;

-- 趋势分析
SELECT
    DATE_TRUNC('hour', created_at) AS hour,
    query,
    COUNT(*) AS count
FROM search_queries
WHERE created_at >= now() - INTERVAL '24 hours'
    AND query IN (
        SELECT query FROM search_queries
        WHERE created_at >= now() - INTERVAL '24 hours'
        GROUP BY query
        ORDER BY COUNT(*) DESC
        LIMIT 10
    )
GROUP BY hour, query
ORDER BY hour DESC, count DESC;
```

### 6.2 无结果搜索分析

```sql
-- 记录无结果搜索
INSERT INTO search_queries (query, user_id, result_count)
VALUES ('找不到的内容', 123, 0);

-- 分析无结果搜索
SELECT
    query,
    COUNT(*) AS search_count
FROM search_queries
WHERE result_count = 0
    AND created_at >= now() - INTERVAL '7 days'
GROUP BY query
HAVING COUNT(*) > 10
ORDER BY search_count DESC;

-- 用于：
-- 1. 发现内容缺失
-- 2. 优化搜索算法
-- 3. 扩充内容库
```

---

## 7. 性能优化

### 7.1 缓存策略

```python
import redis
import hashlib

redis_client = redis.Redis(host='localhost', port=6379)

def search_with_cache(query, limit=20):
    """带缓存的搜索"""

    # 生成缓存key
    cache_key = f"search:{hashlib.md5(query.encode()).hexdigest()}"

    # 检查缓存
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # 查询数据库
    cursor.execute("""
        SELECT doc_id, title, ts_rank(...) AS rank
        FROM documents
        WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', %s)
        ORDER BY rank DESC
        LIMIT %s
    """, (query, limit))

    results = cursor.fetchall()

    # 写入缓存（5分钟）
    redis_client.setex(cache_key, 300, json.dumps(results))

    return results

# 性能对比：
# 无缓存：80ms
# 有缓存：2ms (-97.5%)
```

### 7.2 异步索引更新

```sql
-- 延迟更新搜索向量
ALTER TABLE documents ADD COLUMN search_vector_dirty BOOLEAN DEFAULT false;

-- 写入时只标记dirty
CREATE OR REPLACE FUNCTION mark_search_dirty()
RETURNS TRIGGER AS $$
BEGIN
    NEW.search_vector_dirty := true;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_mark_search_dirty
BEFORE UPDATE ON documents
FOR EACH ROW
WHEN (OLD.content IS DISTINCT FROM NEW.content)
EXECUTE FUNCTION mark_search_dirty();

-- 后台任务定期更新
UPDATE documents
SET
    search_vector = to_tsvector('chinese', title || ' ' || content),
    search_vector_dirty = false
WHERE search_vector_dirty = true;

-- 优势：
-- 写入延迟降低80%
-- 搜索准确性略降（可接受的权衡）
```

---

## 8. 混合检索

### 8.1 全文搜索 + 向量搜索

```sql
-- 扩展documents表
ALTER TABLE documents ADD COLUMN embedding VECTOR(768);

-- 混合检索
WITH text_results AS (
    SELECT
        doc_id,
        ts_rank(search_vector, query) AS text_score
    FROM documents,
         plainto_tsquery('chinese', '机器学习') AS query
    WHERE search_vector @@ query
    ORDER BY text_score DESC
    LIMIT 100
),
vector_results AS (
    SELECT
        doc_id,
        1 - (embedding <=> query_embedding) AS vector_score
    FROM documents
    ORDER BY embedding <=> query_embedding
    LIMIT 100
)
SELECT
    d.doc_id,
    d.title,
    COALESCE(tr.text_score, 0) * 0.6 +
    COALESCE(vr.vector_score, 0) * 0.4 AS hybrid_score
FROM documents d
LEFT JOIN text_results tr ON d.doc_id = tr.doc_id
LEFT JOIN vector_results vr ON d.doc_id = vr.doc_id
WHERE tr.doc_id IS NOT NULL OR vr.doc_id IS NOT NULL
ORDER BY hybrid_score DESC
LIMIT 20;

-- 混合检索准确率提升15-25%
```

---

## 9. 实时索引

### 9.1 增量索引更新

```python
from datetime import datetime, timedelta

class IncrementalIndexer:
    """增量索引器"""

    def __init__(self, conn):
        self.conn = conn
        self.cursor = conn.cursor()

    def update_recent_docs(self, minutes=5):
        """更新最近修改的文档索引"""

        self.cursor.execute("""
            UPDATE documents
            SET search_vector = to_tsvector('chinese', title || ' ' || content)
            WHERE updated_at >= now() - INTERVAL '%s minutes'
        """, (minutes,))

        self.conn.commit()

        return self.cursor.rowcount

    def rebuild_index(self, batch_size=10000):
        """全量重建索引（分批）"""

        self.cursor.execute("SELECT COUNT(*) FROM documents")
        total = self.cursor.fetchone()[0]

        for offset in range(0, total, batch_size):
            self.cursor.execute("""
                UPDATE documents
                SET search_vector = to_tsvector('chinese', title || ' ' || content)
                WHERE doc_id IN (
                    SELECT doc_id FROM documents
                    ORDER BY doc_id
                    LIMIT %s OFFSET %s
                )
            """, (batch_size, offset))

            self.conn.commit()

            print(f"已处理 {min(offset + batch_size, total)}/{total}")

# 定时任务：每5分钟增量更新
# 每周日全量重建
```

---

## 10. 搜索日志分析

### 10.1 搜索质量分析

```sql
-- 创建搜索日志表
CREATE TABLE search_logs (
    id BIGSERIAL PRIMARY KEY,
    user_id INT,
    query TEXT,
    result_count INT,
    click_doc_id BIGINT,
    click_position INT,
    search_time_ms INT,
    created_at TIMESTAMPTZ DEFAULT now()
);

-- 点击率分析
SELECT
    query,
    COUNT(*) AS search_count,
    COUNT(click_doc_id) AS click_count,
    ROUND(COUNT(click_doc_id) * 100.0 / COUNT(*), 2) AS ctr,
    AVG(click_position) AS avg_position
FROM search_logs
WHERE created_at >= now() - INTERVAL '7 days'
GROUP BY query
HAVING COUNT(*) > 10
ORDER BY search_count DESC
LIMIT 20;

-- 低质量查询识别
SELECT query, ctr
FROM (
    SELECT
        query,
        COUNT(click_doc_id) * 100.0 / COUNT(*) AS ctr
    FROM search_logs
    WHERE created_at >= now() - INTERVAL '7 days'
    GROUP BY query
    HAVING COUNT(*) > 20
) stats
WHERE ctr < 10  -- CTR<10%
ORDER BY ctr;

-- 用于优化：
-- 1. 调整排序算法
-- 2. 扩充同义词
-- 3. 优化分词
```

---

## 11. 同义词支持

### 11.1 同义词词典

```sql
-- 创建同义词词典文件
-- /usr/share/postgresql/18/tsearch_data/synonym_dict.syn
数据库, db, database
优化, 调优, tuning
查询, 检索, search

-- 创建同义词配置
CREATE TEXT SEARCH CONFIGURATION chinese_syn (COPY = chinese_zh);
ALTER TEXT SEARCH CONFIGURATION chinese_syn
    ALTER MAPPING FOR n, v, a
    WITH synonym_dict, simple;

-- 使用同义词搜索
SELECT * FROM documents
WHERE to_tsvector('chinese_syn', content) @@
      plainto_tsquery('chinese_syn', 'db调优');
-- 匹配: "数据库优化", "database tuning" 等
```

---

## 12. 分面搜索

### 12.1 多维度过滤

```sql
-- 扩展schema
ALTER TABLE documents ADD COLUMN category VARCHAR(50);
ALTER TABLE documents ADD COLUMN author_id INT;
ALTER TABLE documents ADD COLUMN publish_year INT;

-- 分面搜索
WITH search_results AS (
    SELECT doc_id
    FROM documents
    WHERE to_tsvector('chinese', content) @@ plainto_tsquery('chinese', '机器学习')
)
SELECT
    'category' AS facet_type,
    category AS facet_value,
    COUNT(*) AS doc_count
FROM documents
WHERE doc_id IN (SELECT doc_id FROM search_results)
GROUP BY category

UNION ALL

SELECT
    'publish_year',
    publish_year::TEXT,
    COUNT(*)
FROM documents
WHERE doc_id IN (SELECT doc_id FROM search_results)
GROUP BY publish_year

ORDER BY facet_type, doc_count DESC;

/*
facet_type   | facet_value | doc_count
-------------|-------------|----------
category     | AI          | 150
category     | 数据库      | 80
category     | 算法        | 45
publish_year | 2024        | 120
publish_year | 2023        | 95
*/
```

---

## 13. 性能监控

### 13.1 搜索性能统计

```sql
-- 创建性能统计视图
CREATE MATERIALIZED VIEW search_performance_stats AS
SELECT
    DATE_TRUNC('hour', created_at) AS hour,
    COUNT(*) AS search_count,
    AVG(search_time_ms) AS avg_time,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY search_time_ms) AS p95_time,
    MAX(search_time_ms) AS max_time,
    AVG(result_count) AS avg_results
FROM search_logs
WHERE created_at >= now() - INTERVAL '7 days'
GROUP BY DATE_TRUNC('hour', created_at);

CREATE UNIQUE INDEX idx_search_perf_hour ON search_performance_stats(hour);

-- 定时刷新（每小时）
REFRESH MATERIALIZED VIEW CONCURRENTLY search_performance_stats;

-- 查询性能趋势
SELECT * FROM search_performance_stats
ORDER BY hour DESC
LIMIT 24;
```

---

**完成**: 全文搜索系统高级特性
**字数**: ~12,000字
**涵盖**: 多语言、相关性排序、高亮、拼写纠错、搜索建议、混合检索、实时索引、日志分析、同义词、分面搜索、性能监控
