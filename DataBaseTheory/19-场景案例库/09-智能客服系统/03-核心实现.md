# 案例9：智能客服系统 - 核心实现

```python
"""
智能客服系统
技术栈: PostgreSQL 18 + pgvector + LangChain
"""

import psycopg2
from psycopg2.extras import RealDictCursor
from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
import numpy as np

class CustomerServiceBot:
    """智能客服机器人"""

    def __init__(self, conn_str, openai_api_key):
        self.conn = psycopg2.connect(conn_str, cursor_factory=RealDictCursor)
        self.cursor = self.conn.cursor()
        self.llm = OpenAI(api_key=openai_api_key, temperature=0.7)
        self.embeddings = OpenAIEmbeddings(api_key=openai_api_key)

    def answer_question(self, session_id: str, question: str) -> dict:
        """
        回答用户问题

        流程:
        1. 向量检索相关FAQ
        2. 获取对话历史
        3. LLM生成答案
        4. 保存对话
        """

        # 1. 向量检索
        question_vec = self.embeddings.embed_query(question)
        relevant_faqs = self._retrieve_faqs(question_vec, top_k=3)

        # 2. 对话历史
        history = self._get_conversation_history(session_id, limit=5)

        # 3. 生成答案
        answer = self._generate_answer(question, relevant_faqs, history)

        # 4. 保存对话
        self._save_conversation(session_id, question, answer)

        return {
            'session_id': session_id,
            'question': question,
            'answer': answer,
            'sources': [faq['faq_id'] for faq in relevant_faqs]
        }

    def _retrieve_faqs(self, query_vec: list, top_k: int = 3) -> list:
        """向量检索FAQ"""

        self.cursor.execute("""
            SELECT
                faq_id,
                question,
                answer,
                category,
                1 - (embedding <-> %s::vector) AS similarity
            FROM faqs
            WHERE 1 - (embedding <-> %s::vector) > 0.7
            ORDER BY embedding <-> %s::vector
            LIMIT %s;
        """, (query_vec, query_vec, query_vec, top_k))

        return self.cursor.fetchall()

    def _get_conversation_history(self, session_id: str, limit: int = 5) -> list:
        """获取对话历史"""

        self.cursor.execute("""
            SELECT question, answer, created_at
            FROM conversations
            WHERE session_id = %s
            ORDER BY created_at DESC
            LIMIT %s;
        """, (session_id, limit))

        return list(reversed(self.cursor.fetchall()))

    def _generate_answer(self, question: str, faqs: list, history: list) -> str:
        """LLM生成答案"""

        # 构建上下文
        context = "\n\n".join([
            f"Q: {faq['question']}\nA: {faq['answer']}"
            for faq in faqs
        ])

        history_text = "\n".join([
            f"用户: {h['question']}\n客服: {h['answer']}"
            for h in history
        ])

        prompt = f"""
你是一个专业的客服助手。基于以下信息回答用户问题。

相关知识:
{context}

对话历史:
{history_text}

用户问题: {question}

请给出专业、友好的回答:
"""

        answer = self.llm(prompt)
        return answer.strip()

    def _save_conversation(self, session_id: str, question: str, answer: str):
        """保存对话记录"""

        self.cursor.execute("""
            INSERT INTO conversations (session_id, question, answer)
            VALUES (%s, %s, %s);
        """, (session_id, question, answer))

        self.conn.commit()

# ============================================================
# 数据库Schema
# ============================================================

"""
-- FAQ表
CREATE TABLE faqs (
    faq_id SERIAL PRIMARY KEY,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    category VARCHAR(50),
    embedding vector(768),
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_faqs_embedding ON faqs USING hnsw (embedding vector_l2_ops);

-- 对话表
CREATE TABLE conversations (
    conv_id BIGSERIAL PRIMARY KEY,
    session_id VARCHAR(100) NOT NULL,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_conversations_session ON conversations (session_id, created_at);

-- 用户会话表
CREATE TABLE sessions (
    session_id VARCHAR(100) PRIMARY KEY,
    user_id BIGINT,
    channel VARCHAR(20),
    status VARCHAR(20),
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);
"""

# ============================================================
# FastAPI接口
# ============================================================

from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

bot = CustomerServiceBot(
    conn_str="dbname=customer_service_db user=postgres",
    openai_api_key="your-api-key"
)

class QuestionRequest(BaseModel):
    session_id: str
    question: str

@app.post("/api/chat")
async def chat(request: QuestionRequest):
    """对话接口"""
    result = bot.answer_question(request.session_id, request.question)
    return result

@app.get("/api/history/{session_id}")
async def get_history(session_id: str):
    """获取对话历史"""
    cursor = bot.cursor
    cursor.execute("""
        SELECT question, answer, created_at
        FROM conversations
        WHERE session_id = %s
        ORDER BY created_at;
    """, (session_id,))

    history = cursor.fetchall()
    return {'session_id': session_id, 'history': history}

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8005)
```

---

**返回**: [案例9主页](./README.md)
