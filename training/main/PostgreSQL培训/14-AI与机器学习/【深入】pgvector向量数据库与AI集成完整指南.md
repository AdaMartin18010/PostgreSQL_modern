# ã€æ·±å…¥ã€‘pgvectorå‘é‡æ•°æ®åº“ä¸AIé›†æˆå®Œæ•´æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0 | **åˆ›å»ºæ—¥æœŸ**: 2025-01 | **é€‚ç”¨ç‰ˆæœ¬**: PostgreSQL 12+, pgvector 0.5+
> **éš¾åº¦ç­‰çº§**: â­â­â­â­â­ ä¸“å®¶ | **é¢„è®¡å­¦ä¹ æ—¶é—´**: 8-10å°æ—¶

---

## ğŸ“‹ ç›®å½•

- [ã€æ·±å…¥ã€‘pgvectorå‘é‡æ•°æ®åº“ä¸AIé›†æˆå®Œæ•´æŒ‡å—](#æ·±å…¥pgvectorå‘é‡æ•°æ®åº“ä¸aié›†æˆå®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. è¯¾ç¨‹æ¦‚è¿°](#1-è¯¾ç¨‹æ¦‚è¿°)
    - [1.1 ä»€ä¹ˆæ˜¯pgvectorï¼Ÿ](#11-ä»€ä¹ˆæ˜¯pgvector)
      - [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
      - [é€‚ç”¨åœºæ™¯](#é€‚ç”¨åœºæ™¯)
    - [1.2 pgvector vs ä¸“ç”¨å‘é‡æ•°æ®åº“](#12-pgvector-vs-ä¸“ç”¨å‘é‡æ•°æ®åº“)
  - [2. å‘é‡æ•°æ®åº“åŸºç¡€](#2-å‘é‡æ•°æ®åº“åŸºç¡€)
    - [2.1 ä»€ä¹ˆæ˜¯å‘é‡ï¼Ÿ](#21-ä»€ä¹ˆæ˜¯å‘é‡)
    - [2.2 ç›¸ä¼¼åº¦åº¦é‡](#22-ç›¸ä¼¼åº¦åº¦é‡)
      - [è·ç¦»åº¦é‡å¯¹æ¯”](#è·ç¦»åº¦é‡å¯¹æ¯”)
  - [3. pgvectorå®‰è£…ä¸é…ç½®](#3-pgvectorå®‰è£…ä¸é…ç½®)
    - [3.1 å®‰è£…](#31-å®‰è£…)
    - [3.2 å¯ç”¨æ‰©å±•](#32-å¯ç”¨æ‰©å±•)
    - [3.3 åˆ›å»ºå‘é‡è¡¨](#33-åˆ›å»ºå‘é‡è¡¨)
  - [4. å‘é‡æ“ä½œ](#4-å‘é‡æ“ä½œ)
    - [4.1 æ’å…¥å‘é‡](#41-æ’å…¥å‘é‡)
    - [4.2 å‘é‡è¿ç®—](#42-å‘é‡è¿ç®—)
  - [5. ç›¸ä¼¼åº¦æœç´¢](#5-ç›¸ä¼¼åº¦æœç´¢)
    - [5.1 åŸºç¡€æœç´¢](#51-åŸºç¡€æœç´¢)
    - [5.2 è¯­ä¹‰æœç´¢å®ç°](#52-è¯­ä¹‰æœç´¢å®ç°)
    - [5.3 æ··åˆæœç´¢ï¼ˆå‘é‡+è¿‡æ»¤ï¼‰](#53-æ··åˆæœç´¢å‘é‡è¿‡æ»¤)
  - [6. å‘é‡ç´¢å¼•](#6-å‘é‡ç´¢å¼•)
    - [6.1 IVFFlatç´¢å¼•](#61-ivfflatç´¢å¼•)
    - [6.2 HNSWç´¢å¼•ï¼ˆæ¨èï¼‰](#62-hnswç´¢å¼•æ¨è)
    - [6.3 ç´¢å¼•å¯¹æ¯”](#63-ç´¢å¼•å¯¹æ¯”)
  - [7. AIæ¨¡å‹é›†æˆ](#7-aiæ¨¡å‹é›†æˆ)
    - [7.1 OpenAIé›†æˆ](#71-openaié›†æˆ)
    - [7.2 å¼€æºæ¨¡å‹é›†æˆï¼ˆSentence Transformersï¼‰](#72-å¼€æºæ¨¡å‹é›†æˆsentence-transformers)
  - [8. æ··åˆæœç´¢](#8-æ··åˆæœç´¢)
    - [8.1 å‘é‡ + å…¨æ–‡æœç´¢](#81-å‘é‡--å…¨æ–‡æœç´¢)
    - [8.2 å‘é‡ + ç»“æ„åŒ–è¿‡æ»¤](#82-å‘é‡--ç»“æ„åŒ–è¿‡æ»¤)
    - [8.3 å‘é‡ + ç©ºé—´æ•°æ®](#83-å‘é‡--ç©ºé—´æ•°æ®)
  - [9. RAGåº”ç”¨](#9-ragåº”ç”¨)
    - [9.1 ä»€ä¹ˆæ˜¯RAGï¼Ÿ](#91-ä»€ä¹ˆæ˜¯rag)
    - [9.2 RAGå®ç°](#92-ragå®ç°)
    - [9.3 æ–‡æ¡£åˆ†å—ç­–ç•¥](#93-æ–‡æ¡£åˆ†å—ç­–ç•¥)
  - [10. æ€§èƒ½ä¼˜åŒ–](#10-æ€§èƒ½ä¼˜åŒ–)
    - [10.1 æ‰¹é‡æ“ä½œ](#101-æ‰¹é‡æ“ä½œ)
    - [10.2 æŸ¥è¯¢ä¼˜åŒ–](#102-æŸ¥è¯¢ä¼˜åŒ–)
    - [10.3 ç¼“å­˜ç­–ç•¥](#103-ç¼“å­˜ç­–ç•¥)
  - [11. ç”Ÿäº§å®æˆ˜æ¡ˆä¾‹](#11-ç”Ÿäº§å®æˆ˜æ¡ˆä¾‹)
    - [11.1 æ¡ˆä¾‹1ï¼šæ™ºèƒ½å®¢æœçŸ¥è¯†åº“](#111-æ¡ˆä¾‹1æ™ºèƒ½å®¢æœçŸ¥è¯†åº“)
    - [11.2 æ¡ˆä¾‹2ï¼šä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ](#112-æ¡ˆä¾‹2ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ)
    - [11.3 æ¡ˆä¾‹3ï¼šå»é‡ä¸ç›¸ä¼¼æ£€æµ‹](#113-æ¡ˆä¾‹3å»é‡ä¸ç›¸ä¼¼æ£€æµ‹)
  - [12. æœ€ä½³å®è·µ](#12-æœ€ä½³å®è·µ)
    - [12.1 è®¾è®¡åŸåˆ™](#121-è®¾è®¡åŸåˆ™)
    - [12.2 æ€§èƒ½ä¼˜åŒ–Checklist](#122-æ€§èƒ½ä¼˜åŒ–checklist)
    - [12.3 å®‰å…¨å»ºè®®](#123-å®‰å…¨å»ºè®®)
  - [ğŸ“š å»¶ä¼¸é˜…è¯»](#-å»¶ä¼¸é˜…è¯»)
    - [å®˜æ–¹èµ„æº](#å®˜æ–¹èµ„æº)
    - [ç›¸å…³æŠ€æœ¯](#ç›¸å…³æŠ€æœ¯)
  - [âœ… å­¦ä¹ æ£€æŸ¥æ¸…å•](#-å­¦ä¹ æ£€æŸ¥æ¸…å•)

---

## 1. è¯¾ç¨‹æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯pgvectorï¼Ÿ

**pgvector** æ˜¯PostgreSQLçš„å‘é‡æ‰©å±•ï¼Œæ”¯æŒå‘é‡å­˜å‚¨å’Œç›¸ä¼¼åº¦æœç´¢ï¼Œæ˜¯AI/MLåº”ç”¨çš„ç†æƒ³æ•°æ®åº“ã€‚

#### æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ | åº”ç”¨ |
|------|------|------|
| **å‘é‡å­˜å‚¨** | å­˜å‚¨embeddingå‘é‡ | AIæ¨¡å‹è¾“å‡º |
| **ç›¸ä¼¼åº¦æœç´¢** | å‘é‡è¿‘é‚»æœç´¢ | è¯­ä¹‰æœç´¢ã€æ¨è |
| **å‘é‡ç´¢å¼•** | IVFFlatã€HNSW | é«˜æ€§èƒ½æœç´¢ |
| **æ··åˆæŸ¥è¯¢** | å‘é‡+ç»“æ„åŒ–æ•°æ® | è¿‡æ»¤+è¯­ä¹‰æœç´¢ |
| **SQLé›†æˆ** | åŸç”ŸSQLæ“ä½œ | æ— éœ€æ–°æŸ¥è¯¢è¯­è¨€ |

#### é€‚ç”¨åœºæ™¯

```text
âœ… è¯­ä¹‰æœç´¢ï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ï¼‰
âœ… æ¨èç³»ç»Ÿï¼ˆå†…å®¹ã€å•†å“ã€ç”¨æˆ·ï¼‰
âœ… RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
âœ… ç›¸ä¼¼åº¦æ£€æµ‹ï¼ˆå»é‡ã€æ¬ºè¯ˆï¼‰
âœ… å¼‚å¸¸æ£€æµ‹ï¼ˆå®‰å…¨ã€è´¨é‡ï¼‰
âœ… èšç±»åˆ†æï¼ˆç”¨æˆ·åˆ†ç»„ã€å†…å®¹åˆ†ç±»ï¼‰
```

### 1.2 pgvector vs ä¸“ç”¨å‘é‡æ•°æ®åº“

```text
pgvector vs Pinecone/Milvus/Weaviate:

âœ… ä¼˜åŠ¿ï¼š
1. ç»Ÿä¸€æ•°æ®åº“ï¼ˆæ— éœ€åŒæ­¥ï¼‰
2. ACIDäº‹åŠ¡ä¿è¯
3. æ··åˆæŸ¥è¯¢èƒ½åŠ›å¼º
4. SQLåŸç”Ÿé›†æˆ
5. æˆæœ¬ä½ï¼ˆæ— é¢å¤–æœåŠ¡ï¼‰

âš ï¸ åŠ£åŠ¿ï¼š
1. è¶…å¤§è§„æ¨¡ï¼ˆ>1äº¿å‘é‡ï¼‰æ€§èƒ½ä¸å¦‚ä¸“ç”¨DB
2. åˆ†å¸ƒå¼èƒ½åŠ›æœ‰é™
3. é«˜çº§å‘é‡æ“ä½œè¾ƒå°‘

é€‚ç”¨åœºæ™¯ï¼š
âœ… ä¸­å°è§„æ¨¡ï¼ˆ<1000ä¸‡å‘é‡ï¼‰
âœ… éœ€è¦æ··åˆæŸ¥è¯¢
âœ… å·²ä½¿ç”¨PostgreSQL
âœ… æˆæœ¬æ•æ„Ÿ
```

---

## 2. å‘é‡æ•°æ®åº“åŸºç¡€

### 2.1 ä»€ä¹ˆæ˜¯å‘é‡ï¼Ÿ

```text
å‘é‡ï¼ˆEmbeddingï¼‰ï¼šå°†æ–‡æœ¬/å›¾åƒ/éŸ³é¢‘è½¬æ¢ä¸ºæ•°å€¼æ•°ç»„

ç¤ºä¾‹ï¼š
æ–‡æœ¬ï¼š"PostgreSQL is great"
    â†“ OpenAI text-embedding-ada-002
å‘é‡ï¼š[0.023, -0.015, 0.041, ..., -0.008]  # 1536ç»´

ä½œç”¨ï¼š
- æ•æ‰è¯­ä¹‰ä¿¡æ¯
- ç›¸ä¼¼æ–‡æœ¬ â†’ ç›¸ä¼¼å‘é‡
- æ”¯æŒæ•°å­¦è¿ç®—ï¼ˆè·ç¦»ã€ç›¸ä¼¼åº¦ï¼‰
```

### 2.2 ç›¸ä¼¼åº¦åº¦é‡

```sql
-- L2è·ç¦»ï¼ˆæ¬§æ°è·ç¦»ï¼‰
SELECT embedding <-> '[0.1, 0.2, 0.3]' AS distance FROM items;
-- è·ç¦»è¶Šå°è¶Šç›¸ä¼¼

-- ä½™å¼¦è·ç¦»
SELECT embedding <=> '[0.1, 0.2, 0.3]' AS cosine_distance FROM items;
-- è·ç¦»è¶Šå°è¶Šç›¸ä¼¼ï¼ˆå½’ä¸€åŒ–å‘é‡ï¼‰

-- å†…ç§¯
SELECT (embedding <#> '[0.1, 0.2, 0.3]') * -1 AS inner_product FROM items;
-- å€¼è¶Šå¤§è¶Šç›¸ä¼¼
```

#### è·ç¦»åº¦é‡å¯¹æ¯”

| åº¦é‡ | æ“ä½œç¬¦ | é€‚ç”¨åœºæ™¯ | ç‰¹ç‚¹ |
|------|--------|---------|------|
| **L2è·ç¦»** | `<->` | é€šç”¨ | è€ƒè™‘å¹…åº¦å·®å¼‚ |
| **ä½™å¼¦è·ç¦»** | `<=>` | æ–‡æœ¬embedding | åªçœ‹æ–¹å‘ï¼Œå¿½ç•¥å¹…åº¦ |
| **å†…ç§¯** | `<#>` | æ¨èç³»ç»Ÿ | è€ƒè™‘å‘é‡é•¿åº¦ |

---

## 3. pgvectorå®‰è£…ä¸é…ç½®

### 3.1 å®‰è£…

```bash
# Ubuntu/Debian
sudo apt install postgresql-15-pgvector

# ä»æºç ç¼–è¯‘
git clone https://github.com/pgvector/pgvector.git
cd pgvector
make
sudo make install

# Docker
docker pull pgvector/pgvector:pg15
docker run -d --name pgvector -p 5432:5432 -e POSTGRES_PASSWORD=postgres pgvector/pgvector:pg15
```

### 3.2 å¯ç”¨æ‰©å±•

```sql
-- åˆ›å»ºæ‰©å±•
CREATE EXTENSION vector;

-- éªŒè¯
SELECT * FROM pg_extension WHERE extname = 'vector';

-- æŸ¥çœ‹æ”¯æŒçš„å‘é‡ç»´åº¦ï¼ˆæœ€å¤§2000ï¼‰
SELECT typname, typlen FROM pg_type WHERE typname = 'vector';
```

### 3.3 åˆ›å»ºå‘é‡è¡¨

```sql
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    embedding vector(1536),  -- OpenAI ada-002: 1536ç»´
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- æˆ–ä½¿ç”¨ä¸åŒæ¨¡å‹
CREATE TABLE images (
    id SERIAL PRIMARY KEY,
    image_url TEXT,
    embedding vector(512)  -- ResNet: 512ç»´
);
```

---

## 4. å‘é‡æ“ä½œ

### 4.1 æ’å…¥å‘é‡

```sql
-- ç›´æ¥æ’å…¥
INSERT INTO documents (content, embedding) VALUES
('PostgreSQL is a powerful database',
 '[0.023, -0.015, 0.041, ...]'::vector);  -- 1536ä¸ªæ•°å­—

-- ä»Pythonæ’å…¥ï¼ˆæ¨èï¼‰
-- python
import psycopg2
import openai

# ç”Ÿæˆembedding
response = openai.Embedding.create(
    model="text-embedding-ada-002",
    input="PostgreSQL is a powerful database"
)
embedding = response['data'][0]['embedding']

# æ’å…¥æ•°æ®åº“
conn = psycopg2.connect("dbname=mydb")
cur = conn.cursor()
cur.execute(
    "INSERT INTO documents (content, embedding) VALUES (%s, %s)",
    ("PostgreSQL is a powerful database", embedding)
)
conn.commit()
```

### 4.2 å‘é‡è¿ç®—

```sql
-- å‘é‡åŠ æ³•
SELECT '[1, 2, 3]'::vector + '[4, 5, 6]'::vector;
-- ç»“æœï¼š[5, 7, 9]

-- å‘é‡å‡æ³•
SELECT '[4, 5, 6]'::vector - '[1, 2, 3]'::vector;
-- ç»“æœï¼š[3, 3, 3]

-- æ ‡é‡ä¹˜æ³•
SELECT '[1, 2, 3]'::vector * 2;
-- ç»“æœï¼š[2, 4, 6]

-- å‘é‡ç»´åº¦
SELECT vector_dims(embedding) FROM documents LIMIT 1;

-- å‘é‡èŒƒæ•°
SELECT vector_norm(embedding) FROM documents LIMIT 1;
```

---

## 5. ç›¸ä¼¼åº¦æœç´¢

### 5.1 åŸºç¡€æœç´¢

```sql
-- æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æ¡£
WITH query_vector AS (
    SELECT '[0.023, -0.015, ...]'::vector(1536) AS vec
)
SELECT
    id,
    content,
    embedding <-> query_vector.vec AS distance
FROM documents, query_vector
ORDER BY embedding <-> query_vector.vec
LIMIT 10;
```

### 5.2 è¯­ä¹‰æœç´¢å®ç°

```python
# å®Œæ•´çš„è¯­ä¹‰æœç´¢ç¤ºä¾‹
import openai
import psycopg2

def semantic_search(query_text, limit=10):
    # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
    response = openai.Embedding.create(
        model="text-embedding-ada-002",
        input=query_text
    )
    query_embedding = response['data'][0]['embedding']

    # 2. å‘é‡æœç´¢
    conn = psycopg2.connect("dbname=mydb")
    cur = conn.cursor()

    cur.execute("""
        SELECT id, content, embedding <-> %s::vector AS distance
        FROM documents
        ORDER BY embedding <-> %s::vector
        LIMIT %s
    """, (query_embedding, query_embedding, limit))

    results = cur.fetchall()
    cur.close()
    conn.close()

    return results

# ä½¿ç”¨
results = semantic_search("How to optimize PostgreSQL performance?", limit=5)
for id, content, distance in results:
    print(f"{id}: {content[:100]}... (distance: {distance:.4f})")
```

### 5.3 æ··åˆæœç´¢ï¼ˆå‘é‡+è¿‡æ»¤ï¼‰

```sql
-- å‘é‡æœç´¢ + ç»“æ„åŒ–è¿‡æ»¤
WITH query_vector AS (
    SELECT '[...]'::vector(1536) AS vec
)
SELECT
    id,
    title,
    content,
    embedding <-> query_vector.vec AS distance
FROM documents, query_vector
WHERE category = 'Technology'
  AND published = TRUE
  AND created_at >= '2024-01-01'
ORDER BY embedding <-> query_vector.vec
LIMIT 10;

-- å‘é‡æœç´¢ + JSONBè¿‡æ»¤
SELECT
    id,
    content,
    metadata ->> 'author' AS author,
    embedding <=> query_vec AS similarity
FROM documents
WHERE metadata @> '{"language": "en", "verified": true}'
ORDER BY embedding <=> query_vec
LIMIT 10;
```

---

## 6. å‘é‡ç´¢å¼•

### 6.1 IVFFlatç´¢å¼•

```sql
-- åˆ›å»ºIVFFlatç´¢å¼•
CREATE INDEX documents_embedding_ivfflat_idx
ON documents USING ivfflat (embedding vector_l2_ops)
WITH (lists = 100);

-- listså‚æ•°å»ºè®®ï¼š
-- < 100ä¸‡è¡Œï¼šlists = rows / 1000
-- > 100ä¸‡è¡Œï¼šlists = sqrt(rows)

-- ç¤ºä¾‹ï¼š
-- 10ä¸‡è¡Œ â†’ lists = 100
-- 100ä¸‡è¡Œ â†’ lists = 1000
-- 1000ä¸‡è¡Œ â†’ lists = 3162

-- æŸ¥è¯¢æ—¶è®¾ç½®probesï¼ˆæ‰«æçš„åˆ—è¡¨æ•°ï¼‰
SET ivfflat.probes = 10;

SELECT id, content, embedding <-> query_vec AS distance
FROM documents
ORDER BY embedding <-> query_vec
LIMIT 10;
-- probesè¶Šå¤§ï¼Œå¬å›è¶Šå‡†ç¡®ï¼Œä½†é€Ÿåº¦è¶Šæ…¢
```

### 6.2 HNSWç´¢å¼•ï¼ˆæ¨èï¼‰

```sql
-- åˆ›å»ºHNSWç´¢å¼•ï¼ˆæ›´å¿«æ›´å‡†ï¼‰
CREATE INDEX documents_embedding_hnsw_idx
ON documents USING hnsw (embedding vector_l2_ops)
WITH (m = 16, ef_construction = 64);

-- å‚æ•°è¯´æ˜ï¼š
-- m: æ¯å±‚æœ€å¤§è¿æ¥æ•°ï¼ˆé»˜è®¤16ï¼‰
--    - å¢å¤§mï¼šæ›´å‡†ç¡®ï¼Œä½†ç´¢å¼•æ›´å¤§
--    - èŒƒå›´ï¼š4-64ï¼Œæ¨è16
-- ef_construction: æ„å»ºæ—¶æœç´¢æ·±åº¦ï¼ˆé»˜è®¤64ï¼‰
--    - å¢å¤§ï¼šç´¢å¼•è´¨é‡æ›´é«˜ï¼Œæ„å»ºæ›´æ…¢
--    - èŒƒå›´ï¼š4-1000ï¼Œæ¨è64-200

-- æŸ¥è¯¢æ—¶è®¾ç½®efï¼ˆæœç´¢æ·±åº¦ï¼‰
SET hnsw.ef_search = 40;

SELECT id, content, embedding <-> query_vec AS distance
FROM documents
ORDER BY embedding <-> query_vec
LIMIT 10;

-- ef_searchå»ºè®®ï¼š
-- ä¸€èˆ¬æŸ¥è¯¢ï¼š40
-- é«˜å‡†ç¡®åº¦ï¼š100-200
-- å®æ—¶æŸ¥è¯¢ï¼š10-20
```

### 6.3 ç´¢å¼•å¯¹æ¯”

| ç´¢å¼•ç±»å‹ | æ„å»ºé€Ÿåº¦ | æŸ¥è¯¢é€Ÿåº¦ | å‡†ç¡®åº¦ | å†…å­˜å ç”¨ | æ¨èåœºæ™¯ |
|---------|---------|---------|--------|---------|---------|
| **æ— ç´¢å¼•** | - | ææ…¢ | 100% | ä½ | <1000è¡Œ |
| **IVFFlat** | å¿« | ä¸­ | 90-95% | ä¸­ | é€šç”¨ |
| **HNSW** | æ…¢ | å¿« | 95-99% | é«˜ | é«˜QPSåœºæ™¯ |

**æ¨è**ï¼š

- å¼€å‘æµ‹è¯•ï¼šæ— ç´¢å¼•
- ç”Ÿäº§ç¯å¢ƒï¼šHNSWï¼ˆæŸ¥è¯¢æ€§èƒ½æœ€ä¼˜ï¼‰
- å¤§è§„æ¨¡æ•°æ®ï¼ˆ>1000ä¸‡ï¼‰ï¼šIVFFlatï¼ˆå†…å­˜å‹å¥½ï¼‰

---

## 7. AIæ¨¡å‹é›†æˆ

### 7.1 OpenAIé›†æˆ

```python
# embedding_service.py
import openai
import psycopg2

class EmbeddingService:
    def __init__(self, db_config, openai_api_key):
        self.conn = psycopg2.connect(**db_config)
        openai.api_key = openai_api_key

    def embed_text(self, text):
        """ç”Ÿæˆæ–‡æœ¬embedding"""
        response = openai.Embedding.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response['data'][0]['embedding']

    def add_document(self, content, metadata=None):
        """æ·»åŠ æ–‡æ¡£å¹¶ç”Ÿæˆembedding"""
        embedding = self.embed_text(content)

        cur = self.conn.cursor()
        cur.execute("""
            INSERT INTO documents (content, embedding, metadata)
            VALUES (%s, %s, %s)
            RETURNING id
        """, (content, embedding, metadata))

        doc_id = cur.fetchone()[0]
        self.conn.commit()
        cur.close()

        return doc_id

    def semantic_search(self, query, limit=10, filters=None):
        """è¯­ä¹‰æœç´¢"""
        query_embedding = self.embed_text(query)

        cur = self.conn.cursor()

        sql = """
            SELECT id, content, metadata,
                   embedding <=> %s::vector AS similarity
            FROM documents
            WHERE 1=1
        """
        params = [query_embedding]

        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            for key, value in filters.items():
                sql += f" AND metadata @> %s"
                params.append({key: value})

        sql += " ORDER BY embedding <=> %s::vector LIMIT %s"
        params.extend([query_embedding, limit])

        cur.execute(sql, params)
        results = cur.fetchall()
        cur.close()

        return results

# ä½¿ç”¨
service = EmbeddingService(
    db_config={'dbname': 'vectordb', 'user': 'postgres'},
    openai_api_key='sk-...'
)

# æ·»åŠ æ–‡æ¡£
doc_id = service.add_document(
    "PostgreSQL is a powerful open-source database",
    {"category": "database", "language": "en"}
)

# æœç´¢
results = service.semantic_search(
    "How to use PostgreSQL?",
    limit=5,
    filters={"category": "database"}
)
```

### 7.2 å¼€æºæ¨¡å‹é›†æˆï¼ˆSentence Transformersï¼‰

```python
# ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆæ— APIè´¹ç”¨ï¼‰
from sentence_transformers import SentenceTransformer
import psycopg2

class LocalEmbeddingService:
    def __init__(self, db_config, model_name='all-MiniLM-L6-v2'):
        self.conn = psycopg2.connect(**db_config)
        self.model = SentenceTransformer(model_name)
        # 384ç»´å‘é‡

    def embed_text(self, text):
        return self.model.encode(text).tolist()

    def batch_embed(self, texts):
        """æ‰¹é‡ç”Ÿæˆembedding"""
        return self.model.encode(texts, show_progress_bar=True)

    def bulk_add_documents(self, documents):
        """æ‰¹é‡æ·»åŠ æ–‡æ¡£"""
        contents = [doc['content'] for doc in documents]
        embeddings = self.batch_embed(contents)

        cur = self.conn.cursor()
        cur.executemany("""
            INSERT INTO documents (content, embedding, metadata)
            VALUES (%s, %s, %s)
        """, [(doc['content'], emb.tolist(), doc.get('metadata'))
              for doc, emb in zip(documents, embeddings)])

        self.conn.commit()
        cur.close()

# ä½¿ç”¨
service = LocalEmbeddingService({'dbname': 'vectordb', 'user': 'postgres'})

# æ‰¹é‡æ·»åŠ 
docs = [
    {"content": "PostgreSQL is great", "metadata": {"type": "review"}},
    {"content": "How to optimize queries", "metadata": {"type": "tutorial"}},
    # ... 1000+ documents
]
service.bulk_add_documents(docs)
```

---

## 8. æ··åˆæœç´¢

### 8.1 å‘é‡ + å…¨æ–‡æœç´¢

```sql
-- åˆ›å»ºè¡¨
CREATE TABLE articles (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    embedding vector(1536),
    search_vector tsvector GENERATED ALWAYS AS (
        to_tsvector('english', coalesce(title, '') || ' ' || coalesce(content, ''))
    ) STORED
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX articles_embedding_hnsw_idx ON articles
USING hnsw (embedding vector_l2_ops);

CREATE INDEX articles_search_gin_idx ON articles
USING GIN (search_vector);

-- æ··åˆæœç´¢ï¼ˆè¯­ä¹‰ + å…³é”®è¯ï¼‰
WITH
semantic_results AS (
    SELECT id, embedding <=> query_vec AS semantic_score
    FROM articles
    ORDER BY embedding <=> query_vec
    LIMIT 100
),
keyword_results AS (
    SELECT id, ts_rank(search_vector, query) AS keyword_score
    FROM articles
    WHERE search_vector @@ query
    LIMIT 100
)
SELECT
    a.id,
    a.title,
    a.content,
    COALESCE(sr.semantic_score, 1.0) AS semantic_score,
    COALESCE(kr.keyword_score, 0.0) AS keyword_score,
    (
        COALESCE(1.0 - sr.semantic_score, 0) * 0.7 +  -- è¯­ä¹‰æƒé‡70%
        COALESCE(kr.keyword_score, 0) * 0.3            -- å…³é”®è¯æƒé‡30%
    ) AS combined_score
FROM articles a
LEFT JOIN semantic_results sr ON a.id = sr.id
LEFT JOIN keyword_results kr ON a.id = kr.id
WHERE sr.id IS NOT NULL OR kr.id IS NOT NULL
ORDER BY combined_score DESC
LIMIT 10;
```

### 8.2 å‘é‡ + ç»“æ„åŒ–è¿‡æ»¤

```sql
-- å‘é‡æœç´¢ + å¤æ‚è¿‡æ»¤
SELECT
    p.id,
    p.title,
    p.price,
    p.embedding <-> query_vec AS distance,
    r.avg_rating,
    r.review_count
FROM products p
LEFT JOIN (
    SELECT product_id, AVG(rating) AS avg_rating, COUNT(*) AS review_count
    FROM reviews
    GROUP BY product_id
) r ON p.id = r.product_id
WHERE p.category = 'Electronics'
  AND p.price BETWEEN 500 AND 2000
  AND p.in_stock = TRUE
  AND (r.avg_rating IS NULL OR r.avg_rating >= 4.0)
ORDER BY p.embedding <-> query_vec
LIMIT 20;
```

### 8.3 å‘é‡ + ç©ºé—´æ•°æ®

```sql
-- å‘é‡æœç´¢ + åœ°ç†ä½ç½®
SELECT
    s.id,
    s.name,
    s.description,
    s.embedding <=> query_vec AS semantic_similarity,
    ST_Distance(s.location::geography, user_location::geography) / 1000 AS distance_km
FROM stores s
WHERE ST_DWithin(s.location::geography, user_location::geography, 10000)
ORDER BY
    (1.0 - (s.embedding <=> query_vec)) * 0.6 +  -- è¯­ä¹‰ç›¸ä¼¼åº¦60%
    (1.0 - LEAST(ST_Distance(s.location::geography, user_location::geography) / 10000, 1.0)) * 0.4  -- è·ç¦»40%
DESC
LIMIT 10;
```

---

## 9. RAGåº”ç”¨

### 9.1 ä»€ä¹ˆæ˜¯RAGï¼Ÿ

```text
RAGï¼ˆRetrieval-Augmented Generationï¼‰ï¼š
æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ŒLLMåº”ç”¨çš„æ ¸å¿ƒæ¶æ„

æµç¨‹ï¼š
ç”¨æˆ·é—®é¢˜ â†’ Embedding â†’ å‘é‡æœç´¢ï¼ˆç›¸å…³æ–‡æ¡£ï¼‰
         â†’ ç»„åˆï¼ˆé—®é¢˜+æ–‡æ¡£ï¼‰â†’ LLMç”Ÿæˆç­”æ¡ˆ

ä¼˜åŠ¿ï¼š
âœ… å‡å°‘å¹»è§‰ï¼ˆåŸºäºçœŸå®æ–‡æ¡£ï¼‰
âœ… çŸ¥è¯†å¯æ›´æ–°ï¼ˆæ— éœ€é‡è®­æ¨¡å‹ï¼‰
âœ… å¯è¿½æº¯ï¼ˆæ˜¾ç¤ºæ¥æºï¼‰
âœ… é™ä½æˆæœ¬ï¼ˆå°æ¨¡å‹+æ£€ç´¢ï¼‰
```

### 9.2 RAGå®ç°

```python
import openai
import psycopg2

class RAGSystem:
    def __init__(self, db_config, openai_api_key):
        self.conn = psycopg2.connect(**db_config)
        openai.api_key = openai_api_key

    def retrieve(self, query, top_k=3):
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        # 1. ç”ŸæˆæŸ¥è¯¢embedding
        response = openai.Embedding.create(
            model="text-embedding-ada-002",
            input=query
        )
        query_embedding = response['data'][0]['embedding']

        # 2. å‘é‡æœç´¢
        cur = self.conn.cursor()
        cur.execute("""
            SELECT id, content, embedding <=> %s::vector AS similarity
            FROM knowledge_base
            ORDER BY embedding <=> %s::vector
            LIMIT %s
        """, (query_embedding, query_embedding, top_k))

        results = cur.fetchall()
        cur.close()

        return [{"id": id, "content": content, "similarity": sim}
                for id, content, sim in results]

    def generate(self, query, retrieved_docs):
        """åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ"""
        # æ„å»ºprompt
        context = "\n\n".join([doc['content'] for doc in retrieved_docs])

        prompt = f"""Based on the following context, answer the question.

Context:
{context}

Question: {query}

Answer:"""

        # è°ƒç”¨LLM
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )

        return response['choices'][0]['message']['content']

    def ask(self, question):
        """å®Œæ•´RAGæµç¨‹"""
        # 1. æ£€ç´¢
        docs = self.retrieve(question, top_k=3)

        print("Retrieved documents:")
        for i, doc in enumerate(docs, 1):
            print(f"{i}. {doc['content'][:100]}... (similarity: {1-doc['similarity']:.3f})")

        # 2. ç”Ÿæˆ
        answer = self.generate(question, docs)

        return {
            "answer": answer,
            "sources": [{"id": doc['id'], "content": doc['content']} for doc in docs]
        }

# ä½¿ç”¨
rag = RAGSystem(
    db_config={'dbname': 'vectordb', 'user': 'postgres'},
    openai_api_key='sk-...'
)

result = rag.ask("How do I optimize PostgreSQL query performance?")
print(f"Answer: {result['answer']}")
print(f"\nSources: {len(result['sources'])} documents")
```

### 9.3 æ–‡æ¡£åˆ†å—ç­–ç•¥

```python
def chunk_document(text, chunk_size=500, overlap=100):
    """å°†é•¿æ–‡æ¡£åˆ†å—"""
    words = text.split()
    chunks = []

    for i in range(0, len(words), chunk_size - overlap):
        chunk = ' '.join(words[i:i+chunk_size])
        chunks.append(chunk)

    return chunks

# æ‰¹é‡å¤„ç†æ–‡æ¡£
def process_document(doc_id, content, service):
    chunks = chunk_document(content, chunk_size=500, overlap=100)

    for i, chunk in enumerate(chunks):
        service.add_document(
            content=chunk,
            metadata={
                "source_doc_id": doc_id,
                "chunk_index": i,
                "total_chunks": len(chunks)
            }
        )
```

---

## 10. æ€§èƒ½ä¼˜åŒ–

### 10.1 æ‰¹é‡æ“ä½œ

```python
# æ‰¹é‡æ’å…¥ï¼ˆä½¿ç”¨COPYï¼‰
import io

def bulk_insert_embeddings(conn, documents):
    """é«˜æ€§èƒ½æ‰¹é‡æ’å…¥"""
    # ç”Ÿæˆæ‰€æœ‰embeddings
    contents = [doc['content'] for doc in documents]
    embeddings = model.encode(contents, batch_size=32, show_progress_bar=True)

    # ä½¿ç”¨COPYæ‰¹é‡æ’å…¥
    buffer = io.StringIO()
    for doc, emb in zip(documents, embeddings):
        buffer.write(f"{doc['content']}\t{emb.tolist()}\n")

    buffer.seek(0)
    cur = conn.cursor()
    cur.copy_expert("""
        COPY documents (content, embedding)
        FROM STDIN
    """, buffer)
    conn.commit()
    cur.close()

# æ€§èƒ½ï¼š
# é€è¡Œæ’å…¥ï¼š100 docs/ç§’
# æ‰¹é‡INSERTï¼š1000 docs/ç§’
# COPYï¼š5000+ docs/ç§’ âœ…
```

### 10.2 æŸ¥è¯¢ä¼˜åŒ–

```sql
-- âŒ æ…¢ï¼šå…¨è¡¨æ‰«æ
SELECT * FROM documents
ORDER BY embedding <-> query_vec
LIMIT 10;

-- âœ… å¿«ï¼šä½¿ç”¨ç´¢å¼• + é€‚å½“çš„å‚æ•°
SET hnsw.ef_search = 40;
SELECT * FROM documents
ORDER BY embedding <-> query_vec
LIMIT 10;

-- âœ… æ›´å¿«ï¼šé¢„è¿‡æ»¤ + å‘é‡æœç´¢
WITH filtered AS (
    SELECT * FROM documents
    WHERE category = 'tech' AND published = TRUE
)
SELECT * FROM filtered
ORDER BY embedding <-> query_vec
LIMIT 10;
```

### 10.3 ç¼“å­˜ç­–ç•¥

```python
import redis
import json

class CachedEmbeddingService:
    def __init__(self, db_config, openai_api_key):
        self.conn = psycopg2.connect(**db_config)
        self.redis = redis.Redis(host='localhost', port=6379)
        openai.api_key = openai_api_key

    def embed_text(self, text):
        """å¸¦ç¼“å­˜çš„embeddingç”Ÿæˆ"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"emb:{hash(text)}"
        cached = self.redis.get(cache_key)

        if cached:
            return json.loads(cached)

        # ç”Ÿæˆæ–°embedding
        response = openai.Embedding.create(
            model="text-embedding-ada-002",
            input=text
        )
        embedding = response['data'][0]['embedding']

        # ç¼“å­˜ï¼ˆ7å¤©ï¼‰
        self.redis.setex(cache_key, 7*24*3600, json.dumps(embedding))

        return embedding
```

---

## 11. ç”Ÿäº§å®æˆ˜æ¡ˆä¾‹

### 11.1 æ¡ˆä¾‹1ï¼šæ™ºèƒ½å®¢æœçŸ¥è¯†åº“

```sql
-- çŸ¥è¯†åº“è¡¨
CREATE TABLE kb_articles (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    category TEXT,
    embedding vector(1536),
    view_count INT DEFAULT 0,
    helpful_count INT DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX kb_articles_embedding_hnsw_idx
ON kb_articles USING hnsw (embedding vector_cosine_ops);

-- æœç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION search_kb(
    query_text TEXT,
    query_embedding vector(1536),
    category_filter TEXT DEFAULT NULL,
    top_k INT DEFAULT 5
) RETURNS TABLE (
    id INT,
    title TEXT,
    content TEXT,
    similarity FLOAT,
    rank FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        kb.id,
        kb.title,
        kb.content,
        (1.0 - (kb.embedding <=> query_embedding))::FLOAT AS similarity,
        (
            (1.0 - (kb.embedding <=> query_embedding)) * 0.7 +  -- è¯­ä¹‰70%
            (kb.helpful_count::FLOAT / GREATEST(kb.view_count, 1)) * 0.2 +  -- æœ‰ç”¨åº¦20%
            (1.0 / (1.0 + EXTRACT(EPOCH FROM NOW() - kb.created_at) / 86400 / 365)) * 0.1  -- æ—¶æ•ˆæ€§10%
        )::FLOAT AS rank
    FROM kb_articles kb
    WHERE (category_filter IS NULL OR kb.category = category_filter)
    ORDER BY rank DESC
    LIMIT top_k;
END;
$$ LANGUAGE plpgsql STABLE;
```

### 11.2 æ¡ˆä¾‹2ï¼šä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ

```sql
-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username TEXT,
    preference_embedding vector(384)  -- ç”¨æˆ·åå¥½å‘é‡
);

-- å†…å®¹è¡¨
CREATE TABLE content_items (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    embedding vector(384),
    category TEXT,
    tags TEXT[]
);

-- ä¸ªæ€§åŒ–æ¨è
SELECT
    ci.id,
    ci.title,
    ci.category,
    (1.0 - (ci.embedding <=> u.preference_embedding)) AS relevance_score,
    -- å¤šæ ·æ€§ï¼šé¿å…æ¨èè¿‡äºç›¸ä¼¼çš„å†…å®¹
    (1.0 - (ci.embedding <=> prev.avg_embedding)) AS diversity_score
FROM content_items ci
CROSS JOIN users u
LEFT JOIN (
    -- ç”¨æˆ·æœ€è¿‘æŸ¥çœ‹çš„å¹³å‡å‘é‡
    SELECT AVG(ci2.embedding) AS avg_embedding
    FROM user_views uv
    JOIN content_items ci2 ON uv.item_id = ci2.id
    WHERE uv.user_id = $user_id
      AND uv.viewed_at > NOW() - INTERVAL '7 days'
) prev ON TRUE
WHERE u.id = $user_id
  AND ci.category = ANY(u.interested_categories)
ORDER BY
    relevance_score * 0.8 +  -- ç›¸å…³æ€§80%
    diversity_score * 0.2    -- å¤šæ ·æ€§20%
DESC
LIMIT 20;
```

### 11.3 æ¡ˆä¾‹3ï¼šå»é‡ä¸ç›¸ä¼¼æ£€æµ‹

```sql
-- æ£€æµ‹é‡å¤æ–‡æ¡£
WITH new_doc AS (
    SELECT '[...]'::vector(1536) AS embedding
)
SELECT
    id,
    title,
    embedding <-> new_doc.embedding AS distance
FROM documents, new_doc
WHERE embedding <-> new_doc.embedding < 0.1  -- è·ç¦»é˜ˆå€¼
ORDER BY distance
LIMIT 5;

-- æ‰¹é‡å»é‡
WITH duplicates AS (
    SELECT
        d1.id AS id1,
        d2.id AS id2,
        d1.embedding <-> d2.embedding AS distance
    FROM documents d1
    JOIN documents d2 ON d1.id < d2.id
    WHERE d1.embedding <-> d2.embedding < 0.05
)
SELECT * FROM duplicates ORDER BY distance;
```

---

## 12. æœ€ä½³å®è·µ

### 12.1 è®¾è®¡åŸåˆ™

```sql
-- âœ… 1. é€‰æ‹©åˆé€‚çš„å‘é‡ç»´åº¦
-- OpenAI ada-002: 1536ç»´ï¼ˆé«˜è´¨é‡ï¼‰
-- Sentence-BERT small: 384ç»´ï¼ˆå¿«é€Ÿï¼‰
-- æƒè¡¡ï¼šç»´åº¦è¶Šé«˜è¶Šå‡†ç¡®ï¼Œä½†è¶Šæ…¢

-- âœ… 2. å½’ä¸€åŒ–å‘é‡ï¼ˆä½¿ç”¨ä½™å¼¦è·ç¦»æ—¶ï¼‰
CREATE OR REPLACE FUNCTION normalize_vector(v vector)
RETURNS vector AS $$
    SELECT (v / vector_norm(v))::vector;
$$ LANGUAGE SQL IMMUTABLE;

-- âœ… 3. æ··åˆæœç´¢æƒé‡è°ƒä¼˜
-- æ ¹æ®ä¸šåŠ¡è°ƒæ•´è¯­ä¹‰vså…³é”®è¯æƒé‡
-- A/Bæµ‹è¯•æ‰¾åˆ°æœ€ä¼˜æ¯”ä¾‹

-- âœ… 4. å®šæœŸæ›´æ–°embedding
-- å†…å®¹æ›´æ–° â†’ é‡æ–°ç”Ÿæˆembedding
CREATE OR REPLACE FUNCTION update_embedding()
RETURNS TRIGGER AS $$
BEGIN
    -- è°ƒç”¨å¤–éƒ¨æœåŠ¡æ›´æ–°embedding
    -- æˆ–æ ‡è®°ä¸ºéœ€è¦æ›´æ–°
    NEW.embedding_outdated = TRUE;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER content_updated
AFTER UPDATE OF content ON documents
FOR EACH ROW
EXECUTE FUNCTION update_embedding();
```

### 12.2 æ€§èƒ½ä¼˜åŒ–Checklist

- [ ] ä½¿ç”¨HNSWç´¢å¼•ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
- [ ] è°ƒæ•´ef_searchå‚æ•°ï¼ˆå‡†ç¡®åº¦vsé€Ÿåº¦ï¼‰
- [ ] é¢„è¿‡æ»¤å‡å°‘æœç´¢ç©ºé—´
- [ ] æ‰¹é‡æ“ä½œï¼ˆCOPY vs INSERTï¼‰
- [ ] ç¼“å­˜é«˜é¢‘æŸ¥è¯¢embedding
- [ ] å®šæœŸVACUUM ANALYZE
- [ ] ç›‘æ§æŸ¥è¯¢æ€§èƒ½

### 12.3 å®‰å…¨å»ºè®®

```sql
-- 1. æ•æ„Ÿæ•°æ®ä¸è¦å­˜å‚¨åœ¨å‘é‡ä¸­
-- embeddingå¯èƒ½æ³„éœ²éƒ¨åˆ†åŸæ–‡ä¿¡æ¯

-- 2. è®¿é—®æ§åˆ¶
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;

CREATE POLICY documents_tenant_isolation ON documents
FOR SELECT
USING (tenant_id = current_setting('app.tenant_id')::INT);

-- 3. APIå¯†é’¥ç®¡ç†
-- ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥
-- ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡
```

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

### å®˜æ–¹èµ„æº

- [pgvector GitHub](https://github.com/pgvector/pgvector)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [Sentence Transformers](https://www.sbert.net/)

### ç›¸å…³æŠ€æœ¯

- **Pinecone**: ä¸“ç”¨å‘é‡æ•°æ®åº“
- **Milvus**: å¼€æºå‘é‡æ•°æ®åº“
- **Weaviate**: å‘é‡æœç´¢å¼•æ“
- **LangChain**: LLMåº”ç”¨æ¡†æ¶

---

## âœ… å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£å‘é‡embeddingæ¦‚å¿µ
- [ ] æŒæ¡pgvectoråŸºç¡€æ“ä½œ
- [ ] èƒ½åˆ›å»ºå’Œä¼˜åŒ–å‘é‡ç´¢å¼•
- [ ] èƒ½å®ç°è¯­ä¹‰æœç´¢
- [ ] èƒ½è®¾è®¡æ··åˆæœç´¢æ–¹æ¡ˆ
- [ ] èƒ½æ„å»ºå®Œæ•´çš„RAGç³»ç»Ÿ
- [ ] ç†è§£æ€§èƒ½ä¼˜åŒ–æŠ€å·§

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä»¥åæ˜ pgvectoræœ€æ–°ç‰¹æ€§ã€‚
**åé¦ˆ**: å¦‚å‘ç°é”™è¯¯æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·æäº¤issueã€‚

**ç‰ˆæœ¬å†å²**:

- v1.0 (2025-01): åˆå§‹ç‰ˆæœ¬ï¼Œè¦†ç›–pgvectoræ ¸å¿ƒç‰¹æ€§å’ŒRAGåº”ç”¨
