# LangChain é›†æˆ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æ–‡æ¡£ç¼–å·**: 07-01-02
> **æŠ€æœ¯ç‰ˆæœ¬**: LangChain 0.3+, PostgreSQL 18+

## ğŸ“‘ ç›®å½•

- [LangChain é›†æˆ](#langchain-é›†æˆ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 æ–‡æ¡£ç›®æ ‡](#11-æ–‡æ¡£ç›®æ ‡)
    - [1.2 LangChain ç®€ä»‹](#12-langchain-ç®€ä»‹)
    - [1.3 é›†æˆä»·å€¼](#13-é›†æˆä»·å€¼)
  - [2. å¿«é€Ÿå¼€å§‹](#2-å¿«é€Ÿå¼€å§‹)
    - [2.1 ç¯å¢ƒå‡†å¤‡](#21-ç¯å¢ƒå‡†å¤‡)
      - [2.1.1 å®‰è£…ä¾èµ–](#211-å®‰è£…ä¾èµ–)
      - [2.1.2 ç¯å¢ƒé…ç½®](#212-ç¯å¢ƒé…ç½®)
    - [2.2 åˆå§‹åŒ–å‘é‡å­˜å‚¨](#22-åˆå§‹åŒ–å‘é‡å­˜å‚¨)
      - [2.2.1 åŸºç¡€é…ç½®](#221-åŸºç¡€é…ç½®)
      - [2.2.2 é«˜çº§é…ç½®](#222-é«˜çº§é…ç½®)
    - [2.3 å‘é‡æœç´¢](#23-å‘é‡æœç´¢)
      - [2.3.1 ç›¸ä¼¼åº¦æœç´¢](#231-ç›¸ä¼¼åº¦æœç´¢)
      - [2.3.2 å¸¦åˆ†æ•°æœç´¢](#232-å¸¦åˆ†æ•°æœç´¢)
      - [2.3.3 å…ƒæ•°æ®è¿‡æ»¤](#233-å…ƒæ•°æ®è¿‡æ»¤)
  - [3. RAG åº”ç”¨å®ç°](#3-rag-åº”ç”¨å®ç°)
    - [3.1 åŸºç¡€ RAG](#31-åŸºç¡€-rag)
      - [3.1.1 RetrievalQA é“¾](#311-retrievalqa-é“¾)
      - [3.1.2 Prompt æ¨¡æ¿](#312-prompt-æ¨¡æ¿)
    - [3.2 é«˜çº§ RAG](#32-é«˜çº§-rag)
      - [3.2.1 æ–‡æ¡£å‹ç¼©å™¨](#321-æ–‡æ¡£å‹ç¼©å™¨)
      - [3.2.2 é‡æ’åºæœºåˆ¶](#322-é‡æ’åºæœºåˆ¶)
      - [3.2.3 å¯¹è¯ RAG](#323-å¯¹è¯-rag)
  - [4. Neon åˆ†æ”¯é›†æˆ](#4-neon-åˆ†æ”¯é›†æˆ)
    - [4.1 åˆ›å»ºå®éªŒåˆ†æ”¯](#41-åˆ›å»ºå®éªŒåˆ†æ”¯)
    - [4.2 åˆ†æ”¯ç®¡ç†](#42-åˆ†æ”¯ç®¡ç†)
    - [4.3 å®éªŒæµç¨‹](#43-å®éªŒæµç¨‹)
  - [5. æ··åˆæœç´¢å®ç°](#5-æ··åˆæœç´¢å®ç°)
    - [5.1 å…¨æ–‡+å‘é‡æœç´¢](#51-å…¨æ–‡å‘é‡æœç´¢)
      - [5.1.1 BM25 æ£€ç´¢å™¨](#511-bm25-æ£€ç´¢å™¨)
      - [5.1.2 å‘é‡æ£€ç´¢å™¨](#512-å‘é‡æ£€ç´¢å™¨)
    - [5.2 RRF èåˆç®—æ³•](#52-rrf-èåˆç®—æ³•)
      - [5.2.1 Ensemble Retriever](#521-ensemble-retriever)
      - [5.2.2 æƒé‡é…ç½®](#522-æƒé‡é…ç½®)
  - [6. å®Œæ•´ RAG æµç¨‹](#6-å®Œæ•´-rag-æµç¨‹)
    - [6.1 æ–‡æ¡£åŠ è½½å’Œå‘é‡åŒ–](#61-æ–‡æ¡£åŠ è½½å’Œå‘é‡åŒ–)
      - [6.1.1 æ–‡æ¡£åŠ è½½å™¨](#611-æ–‡æ¡£åŠ è½½å™¨)
      - [6.1.2 æ–‡æœ¬åˆ‡åˆ†](#612-æ–‡æœ¬åˆ‡åˆ†)
      - [6.1.3 å‘é‡åŒ–å­˜å‚¨](#613-å‘é‡åŒ–å­˜å‚¨)
    - [6.2 RAG é“¾é…ç½®](#62-rag-é“¾é…ç½®)
      - [6.2.1 ConversationalRetrievalChain](#621-conversationalretrievalchain)
      - [6.2.2 å¯¹è¯å†…å­˜ç®¡ç†](#622-å¯¹è¯å†…å­˜ç®¡ç†)
  - [7. æ€§èƒ½ä¼˜åŒ–](#7-æ€§èƒ½ä¼˜åŒ–)
    - [7.1 æ‰¹é‡å¤„ç†](#71-æ‰¹é‡å¤„ç†)
    - [7.2 ç¼“å­˜ç­–ç•¥](#72-ç¼“å­˜ç­–ç•¥)
    - [7.3 å¼‚æ­¥å¤„ç†](#73-å¼‚æ­¥å¤„ç†)
  - [8. æœ€ä½³å®è·µ](#8-æœ€ä½³å®è·µ)
    - [8.1 é…ç½®æœ€ä½³å®è·µ](#81-é…ç½®æœ€ä½³å®è·µ)
    - [8.2 æ€§èƒ½æœ€ä½³å®è·µ](#82-æ€§èƒ½æœ€ä½³å®è·µ)
    - [8.3 RAG æœ€ä½³å®è·µ](#83-rag-æœ€ä½³å®è·µ)
  - [9. å¸¸è§é—®é¢˜](#9-å¸¸è§é—®é¢˜)
    - [9.1 ä¾èµ–é—®é¢˜](#91-ä¾èµ–é—®é¢˜)
    - [9.2 é…ç½®é—®é¢˜](#92-é…ç½®é—®é¢˜)
    - [9.3 æ€§èƒ½é—®é¢˜](#93-æ€§èƒ½é—®é¢˜)
  - [10. å‚è€ƒèµ„æ–™](#10-å‚è€ƒèµ„æ–™)
    - [10.1 å®˜æ–¹æ–‡æ¡£](#101-å®˜æ–¹æ–‡æ¡£)
    - [10.2 æŠ€æœ¯æ–‡æ¡£](#102-æŠ€æœ¯æ–‡æ¡£)
    - [10.3 ç›¸å…³èµ„æº](#103-ç›¸å…³èµ„æº)

---

## 1. æ¦‚è¿°

### 1.1 æ–‡æ¡£ç›®æ ‡

**æ ¸å¿ƒç›®æ ‡**:

æœ¬æ–‡æ¡£æä¾› LangChain ä¸ PostgreSQL + pgvector çš„é›†æˆæŒ‡å—ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿæ„å»ºåŸºäºå‘é‡æœç´¢çš„ RAG åº”ç”¨
ã€‚

**æ–‡æ¡£ä»·å€¼**:

| ä»·å€¼é¡¹       | è¯´æ˜               | å½±å“             |
| ------------ | ------------------ | ---------------- |
| **å¿«é€Ÿé›†æˆ** | æä¾›å®Œæ•´çš„é›†æˆæ­¥éª¤ | å‡å°‘å¼€å‘æ—¶é—´     |
| **RAG åº”ç”¨** | æ”¯æŒæ£€ç´¢å¢å¼ºç”Ÿæˆ   | æå‡ AI åº”ç”¨èƒ½åŠ› |
| **æ€§èƒ½ä¼˜åŒ–** | æä¾›æ€§èƒ½ä¼˜åŒ–å»ºè®®   | æé«˜åº”ç”¨æ€§èƒ½     |

### 1.2 LangChain ç®€ä»‹

**LangChain æ¦‚è¿°**:

LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»º LLM åº”ç”¨çš„æ¡†æ¶ï¼Œæä¾›äº†æ–‡æ¡£åŠ è½½ã€å‘é‡å­˜å‚¨ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€é“¾å¼è°ƒç”¨ç­‰åŠŸ
èƒ½ã€‚

**æ ¸å¿ƒç‰¹æ€§**:

| ç‰¹æ€§         | è¯´æ˜                  | ä¼˜åŠ¿             |
| ------------ | --------------------- | ---------------- |
| **å‘é‡å­˜å‚¨** | æ”¯æŒå¤šç§å‘é‡å­˜å‚¨åç«¯  | çµæ´»é€‰æ‹©å­˜å‚¨æ–¹æ¡ˆ |
| **RAG æ”¯æŒ** | å†…ç½® RAG åº”ç”¨æ”¯æŒ     | ç®€åŒ– RAG å¼€å‘    |
| **é“¾å¼è°ƒç”¨** | æ”¯æŒå¤æ‚çš„ LLM åº”ç”¨é“¾ | æé«˜åº”ç”¨çµæ´»æ€§   |
| **æ–‡æ¡£å¤„ç†** | æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼      | æ˜“äºæ–‡æ¡£å¤„ç†     |

### 1.3 é›†æˆä»·å€¼

**é›†æˆä¼˜åŠ¿**:

| ä¼˜åŠ¿         | è¯´æ˜                           | å½±å“               |
| ------------ | ------------------------------ | ------------------ |
| **å‘é‡æœç´¢** | PostgreSQL + pgvector å‘é‡æœç´¢ | **é«˜æ€§èƒ½å‘é‡æ£€ç´¢** |
| **ç»Ÿä¸€å­˜å‚¨** | ä¸šåŠ¡æ•°æ®ä¸å‘é‡æ•°æ®ç»Ÿä¸€å­˜å‚¨     | **ç®€åŒ–æ¶æ„**       |
| **SQL æ”¯æŒ** | å¯ä½¿ç”¨ SQL è¿›è¡Œå¤æ‚æŸ¥è¯¢        | **çµæ´»æŸ¥è¯¢**       |
| **äº‹åŠ¡æ”¯æŒ** | æ”¯æŒ ACID äº‹åŠ¡                 | **æ•°æ®ä¸€è‡´æ€§**     |

## 2. å¿«é€Ÿå¼€å§‹

### 2.1 ç¯å¢ƒå‡†å¤‡

#### 2.1.1 å®‰è£…ä¾èµ–

**Python ä¾èµ–å®‰è£…**:

```bash
# åŸºç¡€ä¾èµ–
pip install langchain langchain-postgres langchain-openai

# PostgreSQL é©±åŠ¨å’Œæ‰©å±•
pip install psycopg2-binary pgvector

# å¯é€‰ï¼šå…¶ä»–ä¾èµ–
pip install python-dotenv  # ç¯å¢ƒå˜é‡ç®¡ç†
pip install tiktoken        # Token è®¡æ•°
```

**ä¾èµ–ç‰ˆæœ¬è¦æ±‚**:

| åŒ…                     | æœ€ä½ç‰ˆæœ¬ | æ¨èç‰ˆæœ¬   |
| ---------------------- | -------- | ---------- |
| **langchain**          | 0.3.0    | **0.3.0+** |
| **langchain-postgres** | 0.0.1    | **0.0.1+** |
| **langchain-openai**   | 0.2.0    | **0.2.0+** |
| **psycopg2-binary**    | 2.9.0    | **2.9.9+** |
| **pgvector**           | 0.3.0    | **0.3.0+** |

**requirements.txt**:

```txt
# LangChain æ ¸å¿ƒåŒ…
langchain>=0.3.0
langchain-core>=0.3.0
langchain-community>=0.3.0

# LangChain PostgreSQL é›†æˆ
langchain-postgres>=0.0.1

# LangChain OpenAI é›†æˆ
langchain-openai>=0.2.0

# PostgreSQL é©±åŠ¨
psycopg2-binary>=2.9.9
pgvector>=0.3.0

# å·¥å…·åŒ…
python-dotenv>=1.0.0
tiktoken>=0.7.0
```

#### 2.1.2 ç¯å¢ƒé…ç½®

**ç¯å¢ƒå˜é‡é…ç½®**:

```python
# .env æ–‡ä»¶
POSTGRES_URL=postgresql://postgres:postgres@localhost:5432/ai_demo
OPENAI_API_KEY=sk-xxx
NEON_API_KEY=neon_xxx  # å¯é€‰ï¼šNeon åˆ†æ”¯æ”¯æŒ
```

**ç¯å¢ƒå˜é‡åŠ è½½**:

```python
# config.py
import os
from dotenv import load_dotenv

load_dotenv()

# æ•°æ®åº“è¿æ¥é…ç½®
POSTGRES_URL = os.getenv("POSTGRES_URL")
if not POSTGRES_URL:
    raise ValueError("POSTGRES_URL ç¯å¢ƒå˜é‡æœªè®¾ç½®")

# OpenAI API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")

# Neon API Keyï¼ˆå¯é€‰ï¼‰
NEON_API_KEY = os.getenv("NEON_API_KEY")
```

**é…ç½®éªŒè¯**:

```python
def validate_config():
    """éªŒè¯é…ç½®"""
    required_vars = ["POSTGRES_URL", "OPENAI_API_KEY"]
    missing_vars = [var for var in required_vars if not os.getenv(var)]

    if missing_vars:
        raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")

    print("âœ… é…ç½®éªŒè¯é€šè¿‡")
```

### 2.2 åˆå§‹åŒ–å‘é‡å­˜å‚¨

#### 2.2.1 åŸºç¡€é…ç½®

**åŸºç¡€å‘é‡å­˜å‚¨åˆå§‹åŒ–**:

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",  # 1536 ç»´åº¦
    openai_api_key=OPENAI_API_KEY
)

# åˆå§‹åŒ–å‘é‡å­˜å‚¨
vectorstore = PGVector(
    embeddings=embeddings,
    connection=POSTGRES_URL,
    collection_name="documents",
    use_jsonb=True,  # PostgreSQL 18 JSONB ä¼˜åŒ–
    pre_delete_collection=False,  # æ˜¯å¦åœ¨åˆå§‹åŒ–æ—¶åˆ é™¤ç°æœ‰é›†åˆ
    distance_strategy="cosine"  # è·ç¦»ç­–ç•¥ï¼šcosine, euclidean, inner_product
)

print("âœ… å‘é‡å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ")
```

**æ”¯æŒçš„æ¨¡å‹**:

| æ¨¡å‹                       | ç»´åº¦ | è¯´æ˜               |
| -------------------------- | ---- | ------------------ |
| **text-embedding-3-small** | 1536 | æ¨èç”¨äºå¤§å¤šæ•°åœºæ™¯ |
| **text-embedding-3-large** | 3072 | é«˜ç²¾åº¦åœºæ™¯         |
| **text-embedding-ada-002** | 1536 | æ—§ç‰ˆæœ¬ï¼Œå·²åºŸå¼ƒ     |

#### 2.2.2 é«˜çº§é…ç½®

**é«˜çº§å‘é‡å­˜å‚¨é…ç½®**:

```python
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings

# é«˜çº§é…ç½®
vectorstore = PGVector(
    embeddings=embeddings,
    connection=POSTGRES_URL,
    collection_name="documents",

    # JSONB æ”¯æŒï¼ˆPostgreSQL 18ï¼‰
    use_jsonb=True,

    # ç´¢å¼•ç±»å‹é…ç½®
    # HNSW: é«˜ç²¾åº¦ï¼Œé€‚åˆ <100 ä¸‡æ•°æ®
    # IVFFlat: é«˜æ€§èƒ½ï¼Œé€‚åˆ >100 ä¸‡æ•°æ®
    index_type="HNSW",

    # HNSW å‚æ•°ï¼ˆé«˜ç²¾åº¦é…ç½®ï¼‰
    hnsw_m=32,              # æ¯å±‚æœ€å¤§è¿æ¥æ•°ï¼ˆé»˜è®¤ 16ï¼‰
    hnsw_ef_construction=200,  # æ„å»ºæ—¶æœç´¢èŒƒå›´ï¼ˆé»˜è®¤ 64ï¼‰

    # IVFFlat å‚æ•°ï¼ˆå¤§è§„æ¨¡é…ç½®ï¼‰
    # ivf_lists=1000,  # èšç±»æ•°é‡ï¼ˆæ•°æ®é‡ / 1000ï¼‰

    # è·ç¦»ç­–ç•¥
    distance_strategy="cosine",  # cosine, euclidean, inner_product

    # è¡¨åè‡ªå®šä¹‰
    table_name="custom_vector_store",

    # è‡ªåŠ¨åˆå§‹åŒ–
    pre_delete_collection=False
)
```

**é…ç½®é€‰æ‹©å»ºè®®**:

| æ•°æ®é‡          | æ¨èé…ç½®             | è¯´æ˜     |
| --------------- | -------------------- | -------- |
| **<100 ä¸‡**     | HNSW (m=16)          | é«˜ç²¾åº¦   |
| **100-1000 ä¸‡** | IVFFlat (lists=1000) | é«˜æ€§èƒ½   |
| **>1000 ä¸‡**    | IVFFlat + åˆ†åŒº       | è¶…å¤§è§„æ¨¡ |

### 2.3 å‘é‡æœç´¢

#### 2.3.1 ç›¸ä¼¼åº¦æœç´¢

**åŸºç¡€ç›¸ä¼¼åº¦æœç´¢**:

```python
# æ·»åŠ æ–‡æ¡£
documents = [
    Document(page_content="PostgreSQL is a powerful database"),
    Document(page_content="pgvector adds vector search capabilities"),
    Document(page_content="LangChain integrates with PostgreSQL")
]

vectorstore.add_documents(documents)
print("âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸ")

# ç›¸ä¼¼åº¦æœç´¢
query = "What is vector search?"
results = vectorstore.similarity_search(query, k=5)

for i, doc in enumerate(results, 1):
    print(f"{i}. {doc.page_content}")
    if doc.metadata:
        print(f"   å…ƒæ•°æ®: {doc.metadata}")
```

#### 2.3.2 å¸¦åˆ†æ•°æœç´¢

**å¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æœç´¢**:

```python
# ç›¸ä¼¼åº¦æœç´¢ï¼ˆå¸¦åˆ†æ•°ï¼‰
results_with_scores = vectorstore.similarity_search_with_score(
    query,
    k=5
)

for doc, score in results_with_scores:
    # ä½™å¼¦è·ç¦»ï¼šè¶Šå°è¶Šç›¸ä¼¼ï¼ˆ0-2 èŒƒå›´ï¼‰
    similarity = 1 - score  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆ0-1ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼ï¼‰
    print(f"[ç›¸ä¼¼åº¦: {similarity:.4f}] {doc.page_content}")
    if doc.metadata:
        print(f"    å…ƒæ•°æ®: {doc.metadata}")
```

**ç›¸ä¼¼åº¦åˆ†æ•°è¯´æ˜**:

| è·ç¦»ç±»å‹     | åˆ†æ•°èŒƒå›´ | è¯´æ˜           |
| ------------ | -------- | -------------- |
| **ä½™å¼¦è·ç¦»** | 0-2      | 0 è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼ |
| **æ¬§æ°è·ç¦»** | 0-âˆ      | 0 è¡¨ç¤ºå®Œå…¨ç›¸åŒ |
| **å†…ç§¯**     | -âˆ-âˆ     | è¶Šå¤§è¶Šç›¸ä¼¼     |

#### 2.3.3 å…ƒæ•°æ®è¿‡æ»¤

**å…ƒæ•°æ®è¿‡æ»¤æœç´¢**:

```python
# æ·»åŠ å¸¦å…ƒæ•°æ®çš„æ–‡æ¡£
documents_with_metadata = [
    Document(
        page_content="PostgreSQL is a powerful database",
        metadata={"category": "database", "author": "PostgreSQL Team"}
    ),
    Document(
        page_content="pgvector adds vector search capabilities",
        metadata={"category": "extension", "author": "pgvector Team"}
    ),
    Document(
        page_content="LangChain integrates with PostgreSQL",
        metadata={"category": "framework", "author": "LangChain Team"}
    )
]

vectorstore.add_documents(documents_with_metadata)

# æŒ‰å…ƒæ•°æ®è¿‡æ»¤æœç´¢
from langchain_postgres import PGVector

# åˆ›å»ºå¸¦è¿‡æ»¤çš„æ£€ç´¢å™¨
retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 5,
        "filter": {"category": "database"}  # å…ƒæ•°æ®è¿‡æ»¤
    }
)

# æœç´¢
results = retriever.get_relevant_documents(query)
for doc in results:
    print(f"{doc.page_content}")
    print(f"  ç±»åˆ«: {doc.metadata.get('category')}")
```

## 3. RAG åº”ç”¨å®ç°

### 3.1 åŸºç¡€ RAG

#### 3.1.1 RetrievalQA é“¾

**åŸºç¡€ RAG å®ç°**:

```python
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# åˆå§‹åŒ– LLM
llm = ChatOpenAI(
    model="gpt-4-turbo-preview",
    temperature=0,
    openai_api_key=OPENAI_API_KEY
)

# åˆ›å»ºæ£€ç´¢å™¨
retriever = vectorstore.as_retriever(
    search_kwargs={"k": 5}  # æ£€ç´¢å‰ 5 ä¸ªç›¸å…³æ–‡æ¡£
)

# åˆ›å»º RAG é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",  # stuff: å°†æ‰€æœ‰æ–‡æ¡£å†…å®¹æ”¾å…¥ prompt
    retriever=retriever,
    return_source_documents=True  # è¿”å›æºæ–‡æ¡£
)

# æé—®
query = "What is PostgreSQL?"
result = qa_chain.invoke({"query": query})

print(f"é—®é¢˜: {query}")
print(f"å›ç­”: {result['result']}")
print(f"\næ¥æºæ–‡æ¡£:")
for i, doc in enumerate(result['source_documents'], 1):
    print(f"{i}. {doc.page_content[:100]}...")
    if doc.metadata:
        print(f"   å…ƒæ•°æ®: {doc.metadata}")
```

**Chain Type è¯´æ˜**:

| Chain Type     | è¯´æ˜                       | é€‚ç”¨åœºæ™¯           |
| -------------- | -------------------------- | ------------------ |
| **stuff**      | å°†æ‰€æœ‰æ–‡æ¡£å†…å®¹æ”¾å…¥ prompt  | æ–‡æ¡£æ•°é‡å°‘ï¼Œå†…å®¹çŸ­ |
| **map_reduce** | åˆ†åˆ«å¤„ç†æ¯ä¸ªæ–‡æ¡£ï¼Œç„¶ååˆå¹¶ | æ–‡æ¡£æ•°é‡å¤š         |
| **refine**     | è¿­ä»£å¤„ç†æ–‡æ¡£ï¼Œé€æ­¥ä¼˜åŒ–ç­”æ¡ˆ | éœ€è¦é«˜è´¨é‡ç­”æ¡ˆ     |
| **map_rerank** | å¯¹æ¯ä¸ªæ–‡æ¡£è¯„åˆ†å¹¶æ’åº       | éœ€è¦æœ€ä½³åŒ¹é…æ–‡æ¡£   |

#### 3.1.2 Prompt æ¨¡æ¿

**è‡ªå®šä¹‰ Prompt æ¨¡æ¿**:

```python
from langchain.prompts import PromptTemplate

# è‡ªå®šä¹‰ Prompt æ¨¡æ¿
prompt_template = """åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ä½ ä¸çŸ¥é“ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆï¼š"""

PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

# ä½¿ç”¨è‡ªå®šä¹‰ Prompt
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": PROMPT},
    return_source_documents=True
)

# æé—®
result = qa_chain.invoke({"query": query})
```

### 3.2 é«˜çº§ RAG

#### 3.2.1 æ–‡æ¡£å‹ç¼©å™¨

**æ–‡æ¡£å‹ç¼©å™¨å®ç°**:

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain_openai import ChatOpenAI

# æ–‡æ¡£å‹ç¼©å™¨ï¼ˆæå–ç›¸å…³ç‰‡æ®µï¼‰
compressor = LLMChainExtractor.from_llm(ChatOpenAI(
    model="gpt-4-turbo-preview",
    temperature=0,
    openai_api_key=OPENAI_API_KEY
))

# å‹ç¼©æ£€ç´¢å™¨
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=vectorstore.as_retriever(search_kwargs={"k": 10})  # å…ˆæ£€ç´¢ 10 ä¸ª
)

# åˆ›å»º RAG é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=compression_retriever,  # ä½¿ç”¨å‹ç¼©æ£€ç´¢å™¨
    return_source_documents=True
)

# æé—®
result = qa_chain.invoke({"query": query})
```

#### 3.2.2 é‡æ’åºæœºåˆ¶

**é‡æ’åºå®ç°**:

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMRerankRetriever

# é‡æ’åºæ£€ç´¢å™¨
rerank_retriever = LLMRerankRetriever(
    base_retriever=vectorstore.as_retriever(search_kwargs={"k": 20}),
    llm=ChatOpenAI(model="gpt-4-turbo-preview", temperature=0),
    top_n=5  # é‡æ’åºåè¿”å›å‰ 5 ä¸ª
)

# åˆ›å»º RAG é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=rerank_retriever,
    return_source_documents=True
)
```

#### 3.2.3 å¯¹è¯ RAG

**å¯¹è¯ RAG å®ç°**:

```python
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

# å¯¹è¯å†…å­˜
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    output_key="answer"
)

# å¯¹è¯ RAG é“¾
conversational_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    memory=memory,
    return_source_documents=True,
    verbose=True
)

# å¯¹è¯
query = "What is PostgreSQL?"
result = conversational_chain.invoke({"question": query})

print(f"é—®é¢˜: {query}")
print(f"å›ç­”: {result['answer']}")

# ç»§ç»­å¯¹è¯ï¼ˆåˆ©ç”¨ä¸Šä¸‹æ–‡ï¼‰
query2 = "What are its advantages?"
result2 = conversational_chain.invoke({"question": query2})

print(f"\né—®é¢˜: {query2}")
print(f"å›ç­”: {result2['answer']}")
```

## 4. Neon åˆ†æ”¯é›†æˆ

### 4.1 åˆ›å»ºå®éªŒåˆ†æ”¯

**Neon åˆ†æ”¯åˆ›å»º**:

```python
from neon import NeonClient
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings

# åˆå§‹åŒ– Neon å®¢æˆ·ç«¯
neon = NeonClient(api_key=NEON_API_KEY)

# åˆ›å»ºå®éªŒåˆ†æ”¯
branch = neon.branches.create(
    project_id="project-id",
    name="rag-experiment-v2",
    parent_branch="main"
)

print(f"âœ… åˆ†æ”¯åˆ›å»ºæˆåŠŸ: {branch.name}")
print(f"è¿æ¥å­—ç¬¦ä¸²: {branch.connection_string}")

# ä½¿ç”¨åˆ†æ”¯è¿æ¥åˆå§‹åŒ–å‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = PGVector(
    embeddings=embeddings,
    connection=branch.connection_string,
    collection_name="documents"
)

# åœ¨åˆ†æ”¯ä¸Šè¿›è¡Œå®éªŒ
documents = [
    Document(page_content="å®éªŒæ–‡æ¡£ 1"),
    Document(page_content="å®éªŒæ–‡æ¡£ 2")
]
vectorstore.add_documents(documents)

# æµ‹è¯•æŸ¥è¯¢
results = vectorstore.similarity_search("å®éªŒ", k=5)
print(f"âœ… å®éªŒå®Œæˆï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
```

### 4.2 åˆ†æ”¯ç®¡ç†

**åˆ†æ”¯ç®¡ç†æ“ä½œ**:

```python
# åˆ—å‡ºæ‰€æœ‰åˆ†æ”¯
branches = neon.branches.list(project_id="project-id")
for branch in branches:
    print(f"- {branch.name} ({branch.id})")

# è·å–åˆ†æ”¯ä¿¡æ¯
branch_info = neon.branches.get(
    project_id="project-id",
    branch_id=branch.id
)
print(f"åˆ†æ”¯çŠ¶æ€: {branch_info.status}")

# åˆ é™¤åˆ†æ”¯ï¼ˆå®éªŒå®Œæˆåï¼‰
# neon.branches.delete(
#     project_id="project-id",
#     branch_id=branch.id
# )
# print("âœ… åˆ†æ”¯å·²åˆ é™¤")
```

### 4.3 å®éªŒæµç¨‹

**å®éªŒæµç¨‹æœ€ä½³å®è·µ**:

```python
class ExperimentManager:
    def __init__(self, neon_client, project_id):
        self.neon = neon_client
        self.project_id = project_id

    def create_experiment(self, experiment_name):
        """åˆ›å»ºå®éªŒåˆ†æ”¯"""
        branch = self.neon.branches.create(
            project_id=self.project_id,
            name=f"experiment-{experiment_name}",
            parent_branch="main"
        )
        return branch

    def run_experiment(self, branch, documents, query):
        """è¿è¡Œå®éªŒ"""
        vectorstore = PGVector(
            embeddings=embeddings,
            connection=branch.connection_string,
            collection_name="documents"
        )

        # æ·»åŠ æ–‡æ¡£
        vectorstore.add_documents(documents)

        # æµ‹è¯•æŸ¥è¯¢
        results = vectorstore.similarity_search(query, k=5)

        return {
            "branch_id": branch.id,
            "results_count": len(results),
            "results": results
        }

    def cleanup_experiment(self, branch_id):
        """æ¸…ç†å®éªŒåˆ†æ”¯"""
        self.neon.branches.delete(
            project_id=self.project_id,
            branch_id=branch_id
        )
        print("âœ… å®éªŒåˆ†æ”¯å·²æ¸…ç†")

# ä½¿ç”¨
manager = ExperimentManager(neon, "project-id")

# åˆ›å»ºå®éªŒ
branch = manager.create_experiment("rag-v2")

# è¿è¡Œå®éªŒ
results = manager.run_experiment(branch, documents, "æµ‹è¯•æŸ¥è¯¢")

# è¯„ä¼°ç»“æœ
if results["results_count"] > 0:
    print("âœ… å®éªŒæˆåŠŸ")
    # åˆå¹¶åˆ°ä¸»åˆ†æ”¯æˆ–ä¿ç•™
else:
    print("âŒ å®éªŒå¤±è´¥")
    # æ¸…ç†åˆ†æ”¯
    manager.cleanup_experiment(branch.id)
```

## 5. æ··åˆæœç´¢å®ç°

### 5.1 å…¨æ–‡+å‘é‡æœç´¢

#### 5.1.1 BM25 æ£€ç´¢å™¨

**BM25 å…¨æ–‡æ£€ç´¢å™¨**:

```python
from langchain.retrievers import BM25Retriever
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å‡†å¤‡æ–‡æ¡£
documents = [
    Document(page_content="PostgreSQL is a powerful database"),
    Document(page_content="pgvector adds vector search capabilities"),
    Document(page_content="LangChain integrates with PostgreSQL")
]

# æ–‡æ¡£åˆ‡åˆ†
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
docs = text_splitter.split_documents(documents)

# BM25 æ£€ç´¢å™¨
bm25_retriever = BM25Retriever.from_documents(docs)
bm25_retriever.k = 5  # æ£€ç´¢å‰ 5 ä¸ªç»“æœ

# å…¨æ–‡æœç´¢
results = bm25_retriever.get_relevant_documents("vector search")
for doc in results:
    print(doc.page_content)
```

#### 5.1.2 å‘é‡æ£€ç´¢å™¨

**å‘é‡æ£€ç´¢å™¨**:

```python
# å‘é‡æ£€ç´¢å™¨
vector_retriever = vectorstore.as_retriever(
    search_kwargs={"k": 5}  # æ£€ç´¢å‰ 5 ä¸ªç»“æœ
)

# å‘é‡æœç´¢
results = vector_retriever.get_relevant_documents("vector search")
for doc in results:
    print(doc.page_content)
```

### 5.2 RRF èåˆç®—æ³•

#### 5.2.1 Ensemble Retriever

**é›†æˆæ£€ç´¢å™¨ï¼ˆRRF èåˆï¼‰**:

```python
from langchain.retrievers import EnsembleRetriever

# é›†æˆæ£€ç´¢å™¨ï¼ˆRRF èåˆï¼‰
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.4, 0.6]  # å…¨æ–‡æœç´¢ 40%ï¼Œå‘é‡æœç´¢ 60%
)

# æ··åˆæœç´¢
results = ensemble_retriever.get_relevant_documents("vector search")
for doc in results:
    print(doc.page_content)
    print(f"  åˆ†æ•°: {doc.metadata.get('score', 'N/A')}")
```

**RRF ç®—æ³•è¯´æ˜**:

- **RRF åˆ†æ•° = 1 / (k + rank)**
- k = 60ï¼ˆé»˜è®¤å€¼ï¼‰
- åˆ†æ•°è¶Šé«˜ï¼Œç›¸å…³æ€§è¶Šé«˜

#### 5.2.2 æƒé‡é…ç½®

**æƒé‡é…ç½®å»ºè®®**:

| åœºæ™¯           | BM25 æƒé‡ | å‘é‡æƒé‡ | è¯´æ˜           |
| -------------- | --------- | -------- | -------------- |
| **å…³é”®è¯æœç´¢** | 0.6       | 0.4      | å…¨æ–‡æœç´¢æ›´é‡è¦ |
| **è¯­ä¹‰æœç´¢**   | 0.4       | 0.6      | å‘é‡æœç´¢æ›´é‡è¦ |
| **å¹³è¡¡æœç´¢**   | 0.5       | 0.5      | ä¸¤è€…å¹³è¡¡       |

**è‡ªå®šä¹‰æƒé‡**:

```python
# åŠ¨æ€æƒé‡ï¼ˆæ ¹æ®æŸ¥è¯¢ç±»å‹ï¼‰
def get_retriever_weights(query_type):
    if query_type == "keyword":
        return [0.6, 0.4]  # BM25 æƒé‡æ›´é«˜
    elif query_type == "semantic":
        return [0.4, 0.6]  # å‘é‡æƒé‡æ›´é«˜
    else:
        return [0.5, 0.5]  # å¹³è¡¡

# ä½¿ç”¨
weights = get_retriever_weights("semantic")
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=weights
)
```

## 6. å®Œæ•´ RAG æµç¨‹

### 6.1 æ–‡æ¡£åŠ è½½å’Œå‘é‡åŒ–

#### 6.1.1 æ–‡æ¡£åŠ è½½å™¨

**æ”¯æŒçš„æ–‡æ¡£æ ¼å¼**:

| æ ¼å¼         | åŠ è½½å™¨                     | è¯´æ˜       |
| ------------ | -------------------------- | ---------- |
| **æ–‡æœ¬**     | TextLoader                 | .txt æ–‡ä»¶  |
| **PDF**      | PyPDFLoader                | PDF æ–‡ä»¶   |
| **Word**     | Docx2txtLoader             | .docx æ–‡ä»¶ |
| **Markdown** | UnstructuredMarkdownLoader | .md æ–‡ä»¶   |
| **ç½‘é¡µ**     | WebBaseLoader              | HTML/ç½‘é¡µ  |
| **ç›®å½•**     | DirectoryLoader            | æ‰¹é‡åŠ è½½   |

**æ–‡æ¡£åŠ è½½ç¤ºä¾‹**:

```python
from langchain.document_loaders import TextLoader, DirectoryLoader

# å•ä¸ªæ–‡ä»¶åŠ è½½
loader = TextLoader("document.txt", encoding="utf-8")
documents = loader.load()

# ç›®å½•æ‰¹é‡åŠ è½½
loader = DirectoryLoader(
    "./documents",
    glob="**/*.txt",
    loader_cls=TextLoader
)
documents = loader.load()

print(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
```

#### 6.1.2 æ–‡æœ¬åˆ‡åˆ†

**æ–‡æœ¬åˆ‡åˆ†ç­–ç•¥**:

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# æ–‡æœ¬åˆ‡åˆ†å™¨
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # æ¯ä¸ªå—çš„å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
    chunk_overlap=200,    # å—ä¹‹é—´çš„é‡å ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰
    length_function=len,  # é•¿åº¦è®¡ç®—å‡½æ•°
    separators=["\n\n", "\n", " ", ""]  # åˆ†éš”ç¬¦ä¼˜å…ˆçº§
)

# åˆ‡åˆ†æ–‡æ¡£
chunks = text_splitter.split_documents(documents)
print(f"âœ… åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªå—")

# æ·»åŠ å—å…ƒæ•°æ®
for i, chunk in enumerate(chunks):
    chunk.metadata["chunk_id"] = i
    chunk.metadata["chunk_size"] = len(chunk.page_content)
```

**åˆ‡åˆ†å‚æ•°å»ºè®®**:

| æ–‡æ¡£ç±»å‹     | chunk_size | chunk_overlap | è¯´æ˜           |
| ------------ | ---------- | ------------- | -------------- |
| **æŠ€æœ¯æ–‡æ¡£** | 1000       | 200           | ä¿æŒä»£ç å—å®Œæ•´ |
| **é•¿ç¯‡æ–‡ç« ** | 2000       | 300           | ä¿æŒæ®µè½å®Œæ•´   |
| **å¯¹è¯è®°å½•** | 500        | 100           | ä¿æŒå¯¹è¯å®Œæ•´   |

#### 6.1.3 å‘é‡åŒ–å­˜å‚¨

**æ‰¹é‡å‘é‡åŒ–å­˜å‚¨**:

```python
def batch_add_documents(vectorstore, documents, batch_size=100):
    """æ‰¹é‡æ·»åŠ æ–‡æ¡£"""
    total = len(documents)
    for i in range(0, total, batch_size):
        batch = documents[i:i + batch_size]
        vectorstore.add_documents(batch)
        print(f"âœ… å·²å¤„ç† {min(i + batch_size, total)}/{total} ä¸ªæ–‡æ¡£")

    print(f"âœ… æ‰€æœ‰æ–‡æ¡£æ·»åŠ å®Œæˆ")

# ä½¿ç”¨
batch_add_documents(vectorstore, chunks, batch_size=100)
```

### 6.2 RAG é“¾é…ç½®

#### 6.2.1 ConversationalRetrievalChain

**å¯¹è¯ RAG é“¾é…ç½®**:

```python
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

# å¯¹è¯å†…å­˜
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    output_key="answer"
)

# å¯¹è¯ RAG é“¾
conversational_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(
        search_kwargs={"k": 5}
    ),
    memory=memory,
    return_source_documents=True,
    verbose=True,
    max_tokens_limit=4000  # é™åˆ¶ prompt é•¿åº¦
)

# å¯¹è¯
query = "What is PostgreSQL?"
result = conversational_chain.invoke({"question": query})

print(f"é—®é¢˜: {query}")
print(f"å›ç­”: {result['answer']}")
```

#### 6.2.2 å¯¹è¯å†…å­˜ç®¡ç†

**ä¸åŒå†…å­˜ç­–ç•¥**:

```python
from langchain.memory import (
    ConversationBufferMemory,
    ConversationSummaryMemory,
    ConversationSummaryBufferMemory
)

# ç­–ç•¥ 1: å®Œæ•´å¯¹è¯å†å²ï¼ˆé€‚åˆçŸ­å¯¹è¯ï¼‰
memory1 = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# ç­–ç•¥ 2: å¯¹è¯æ‘˜è¦ï¼ˆé€‚åˆé•¿å¯¹è¯ï¼‰
memory2 = ConversationSummaryMemory(
    llm=llm,
    memory_key="chat_history",
    return_messages=True
)

# ç­–ç•¥ 3: æ‘˜è¦ç¼“å†²ï¼ˆå¹³è¡¡ï¼‰
memory3 = ConversationSummaryBufferMemory(
    llm=llm,
    memory_key="chat_history",
    return_messages=True,
    max_token_limit=2000  # è¶…è¿‡æ­¤é•¿åº¦åˆ™æ‘˜è¦
)

# ä½¿ç”¨
conversational_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=retriever,
    memory=memory3,  # é€‰æ‹©åˆé€‚çš„å†…å­˜ç­–ç•¥
    return_source_documents=True
)
```

## 7. æ€§èƒ½ä¼˜åŒ–

### 7.1 æ‰¹é‡å¤„ç†

**æ‰¹é‡å¤„ç†ä¼˜åŒ–**:

```python
import asyncio
from typing import List

# å¼‚æ­¥æ‰¹é‡æ·»åŠ 
async def async_batch_add(vectorstore, documents: List[Document], batch_size=100):
    """å¼‚æ­¥æ‰¹é‡æ·»åŠ æ–‡æ¡£"""
    total = len(documents)
    tasks = []

    for i in range(0, total, batch_size):
        batch = documents[i:i + batch_size]
        # å¼‚æ­¥æ·»åŠ 
        task = vectorstore.aadd_documents(batch)
        tasks.append(task)

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    await asyncio.gather(*tasks)
    print(f"âœ… å·²å¤„ç† {total} ä¸ªæ–‡æ¡£")

# ä½¿ç”¨
# await async_batch_add(vectorstore, chunks, batch_size=100)
```

### 7.2 ç¼“å­˜ç­–ç•¥

**LLM ç¼“å­˜**:

```python
from langchain.cache import InMemoryCache, SQLiteCache
from langchain.globals import set_llm_cache

# å†…å­˜ç¼“å­˜ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
set_llm_cache(InMemoryCache())

# SQLite ç¼“å­˜ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
set_llm_cache(SQLiteCache(database_path=".langchain.db"))

# ä½¿ç”¨ç¼“å­˜
result1 = qa_chain.invoke({"query": query})  # ç¬¬ä¸€æ¬¡æŸ¥è¯¢
result2 = qa_chain.invoke({"query": query})  # ä½¿ç”¨ç¼“å­˜ï¼ˆæ›´å¿«ï¼‰
```

**å‘é‡æœç´¢ç¼“å­˜**:

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_similarity_search(query: str, k: int = 5):
    """ç¼“å­˜å‘é‡æœç´¢ç»“æœ"""
    return vectorstore.similarity_search(query, k=k)

# ä½¿ç”¨
results = cached_similarity_search("PostgreSQL", k=5)
```

### 7.3 å¼‚æ­¥å¤„ç†

**å¼‚æ­¥ RAG**:

```python
import asyncio

# å¼‚æ­¥ RAG
async def async_rag(query: str):
    """å¼‚æ­¥ RAG æŸ¥è¯¢"""
    # å¼‚æ­¥æ£€ç´¢
    docs = await vectorstore.asimilarity_search(query, k=5)

    # å¼‚æ­¥ LLM è°ƒç”¨
    response = await llm.ainvoke(f"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”: {docs}")

    return response

# ä½¿ç”¨
# result = await async_rag("What is PostgreSQL?")
```

## 8. æœ€ä½³å®è·µ

### 8.1 é…ç½®æœ€ä½³å®è·µ

**é…ç½®å»ºè®®**:

1. **å‘é‡ç»´åº¦**: æ ¹æ® Embedding æ¨¡å‹é€‰æ‹©ï¼ˆtext-embedding-3-small: 1536ï¼‰
2. **ç´¢å¼•ç±»å‹**:
   - **<100 ä¸‡æ•°æ®**: HNSW
   - **>100 ä¸‡æ•°æ®**: IVFFlat
3. **è·ç¦»ç­–ç•¥**: æ–‡æœ¬å‘é‡ä½¿ç”¨ **cosine**
4. **chunk_size**: æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©ï¼ˆæŠ€æœ¯æ–‡æ¡£: 1000ï¼Œé•¿æ–‡ç« : 2000ï¼‰

### 8.2 æ€§èƒ½æœ€ä½³å®è·µ

**æ€§èƒ½ä¼˜åŒ–å»ºè®®**:

1. **æ‰¹é‡æ“ä½œ**: ä½¿ç”¨æ‰¹é‡æ·»åŠ è€Œä¸æ˜¯é€ä¸ªæ·»åŠ 
2. **å¼‚æ­¥å¤„ç†**: å¯¹äºå¤§é‡æ–‡æ¡£ï¼Œä½¿ç”¨å¼‚æ­¥å¤„ç†
3. **ç¼“å­˜ç­–ç•¥**: ä½¿ç”¨ LLM ç¼“å­˜å‡å°‘ API è°ƒç”¨
4. **ç´¢å¼•ä¼˜åŒ–**: æ ¹æ®æ•°æ®é‡é€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹å’Œå‚æ•°

### 8.3 RAG æœ€ä½³å®è·µ

**RAG åº”ç”¨å»ºè®®**:

1. **æ–‡æ¡£åˆ‡åˆ†**: ä½¿ç”¨åˆé€‚çš„ chunk_size å’Œ chunk_overlap
2. **æ£€ç´¢ç­–ç•¥**: æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©å‘é‡æœç´¢æˆ–æ··åˆæœç´¢
3. **Prompt ä¼˜åŒ–**: ä½¿ç”¨æ¸…æ™°çš„ Prompt æ¨¡æ¿æé«˜ç­”æ¡ˆè´¨é‡
4. **é‡æ’åº**: å¯¹å…³é”®æŸ¥è¯¢ä½¿ç”¨é‡æ’åºæé«˜å‡†ç¡®æ€§

## 9. å¸¸è§é—®é¢˜

### 9.1 ä¾èµ–é—®é¢˜

**å¸¸è§ä¾èµ–é—®é¢˜**:

1. **ç‰ˆæœ¬å†²çª**:

   ```bash
   pip install --upgrade langchain langchain-postgres
   ```

2. **ç¼ºå°‘ä¾èµ–**:

   ```bash
   pip install psycopg2-binary pgvector
   ```

### 9.2 é…ç½®é—®é¢˜

**å¸¸è§é…ç½®é—®é¢˜**:

1. **ç»´åº¦ä¸åŒ¹é…**: ç¡®ä¿ Embedding æ¨¡å‹ç»´åº¦ä¸é…ç½®ä¸€è‡´
2. **è¿æ¥å­—ç¬¦ä¸²é”™è¯¯**: æ£€æŸ¥ PostgreSQL è¿æ¥é…ç½®
3. **ç´¢å¼•ç±»å‹é”™è¯¯**: æ ¹æ®æ•°æ®é‡é€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹

### 9.3 æ€§èƒ½é—®é¢˜

**æ€§èƒ½é—®é¢˜æ’æŸ¥**:

1. **æŸ¥è¯¢æ…¢**: æ£€æŸ¥ç´¢å¼•æ˜¯å¦åˆ›å»ºï¼Œä¼˜åŒ–æŸ¥è¯¢å‚æ•°
2. **å†…å­˜ä¸è¶³**: ä½¿ç”¨æ‰¹é‡æ“ä½œï¼Œå‡å°‘æ‰¹æ¬¡å¤§å°
3. **API è°ƒç”¨è¿‡å¤š**: ä½¿ç”¨ç¼“å­˜ç­–ç•¥å‡å°‘ API è°ƒç”¨

## 10. å‚è€ƒèµ„æ–™

### 10.1 å®˜æ–¹æ–‡æ¡£

- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/) - LangChain Documentation
- [LangChain PostgreSQL é›†æˆ](https://python.langchain.com/docs/integrations/vectorstores/pgvector) -
  PGVector Integration

### 10.2 æŠ€æœ¯æ–‡æ¡£

- [pgvector æ ¸å¿ƒåŸç†](../../01-å‘é‡ä¸æ··åˆæœç´¢/æŠ€æœ¯åŸç†/pgvectoræ ¸å¿ƒåŸç†.md) - pgvector Core
  Principles
- [æ··åˆæœç´¢ RRF ç®—æ³•](../../01-å‘é‡ä¸æ··åˆæœç´¢/æŠ€æœ¯åŸç†/æ··åˆæœç´¢RRFç®—æ³•.md) - RRF Algorithm

### 10.3 ç›¸å…³èµ„æº

- [LangChain RAG æŒ‡å—](https://python.langchain.com/docs/use_cases/question_answering/) - RAG Guide
- [Neon åˆ†æ”¯æ–‡æ¡£](https://neon.tech/docs/guides/branching) - Neon Branching

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 07-01-02
