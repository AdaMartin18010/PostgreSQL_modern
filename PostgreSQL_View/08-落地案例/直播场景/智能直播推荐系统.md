# æ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿ

> **æ›´æ–°æ—¶é—´**: 2025 å¹´ 11 æœˆ 1 æ—¥
> **æŠ€æœ¯ç‰ˆæœ¬**: PostgreSQL 14+, TimescaleDB 2.11+, pgvector 0.7.0+
> **æ–‡æ¡£ç¼–å·**: 08-42-01

## ğŸ“‘ ç›®å½•

- [æ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿ](#æ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 ä¸šåŠ¡èƒŒæ™¯](#11-ä¸šåŠ¡èƒŒæ™¯)
    - [1.2 æ ¸å¿ƒä»·å€¼](#12-æ ¸å¿ƒä»·å€¼)
  - [2. ç³»ç»Ÿæ¶æ„](#2-ç³»ç»Ÿæ¶æ„)
    - [2.1 æ™ºèƒ½ç›´æ’­æ¨èä½“ç³»æ€ç»´å¯¼å›¾](#21-æ™ºèƒ½ç›´æ’­æ¨èä½“ç³»æ€ç»´å¯¼å›¾)
    - [2.2 æ¶æ„è®¾è®¡](#22-æ¶æ„è®¾è®¡)
    - [2.3 æŠ€æœ¯æ ˆ](#23-æŠ€æœ¯æ ˆ)
  - [3. æ•°æ®æ¨¡å‹è®¾è®¡](#3-æ•°æ®æ¨¡å‹è®¾è®¡)
    - [3.1 ç›´æ’­æ•°æ®æ—¶åºè¡¨](#31-ç›´æ’­æ•°æ®æ—¶åºè¡¨)
    - [3.2 ç›´æ’­è¡¨](#32-ç›´æ’­è¡¨)
  - [4. æ¨èç®¡ç†](#4-æ¨èç®¡ç†)
    - [4.1 å®æ—¶æ¨è](#41-å®æ—¶æ¨è)
    - [4.2 çƒ­åº¦åˆ†æ](#42-çƒ­åº¦åˆ†æ)
  - [5. å®é™…åº”ç”¨æ¡ˆä¾‹](#5-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [5.1 æ¡ˆä¾‹: æ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰](#51-æ¡ˆä¾‹-æ™ºèƒ½ç›´æ’­æ¨èç³»ç»ŸçœŸå®æ¡ˆä¾‹)
    - [5.2 æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ](#52-æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ)
  - [6. æœ€ä½³å®è·µ](#6-æœ€ä½³å®è·µ)
    - [6.1 å®æ—¶æ¨è](#61-å®æ—¶æ¨è)
    - [6.2 çƒ­åº¦åˆ†æ](#62-çƒ­åº¦åˆ†æ)
  - [7. å‚è€ƒèµ„æ–™](#7-å‚è€ƒèµ„æ–™)
  - [8. å®Œæ•´ä»£ç ç¤ºä¾‹](#8-å®Œæ•´ä»£ç ç¤ºä¾‹)
    - [8.1 ç›´æ’­æ•°æ®è¡¨åˆ›å»º](#81-ç›´æ’­æ•°æ®è¡¨åˆ›å»º)
    - [8.2 å®æ—¶æ¨èå®ç°](#82-å®æ—¶æ¨èå®ç°)
    - [8.3 çƒ­åº¦åˆ†æå®ç°](#83-çƒ­åº¦åˆ†æå®ç°)
    - [8.4 è§‚çœ‹å†å²ç®¡ç†å®ç°](#84-è§‚çœ‹å†å²ç®¡ç†å®ç°)
    - [8.5 å®æ—¶æ•°æ®é‡‡é›†å®ç°](#85-å®æ—¶æ•°æ®é‡‡é›†å®ç°)

---

## 1. æ¦‚è¿°

### 1.1 ä¸šåŠ¡èƒŒæ™¯

**é—®é¢˜éœ€æ±‚**:

æ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿéœ€è¦ï¼š

- **å®æ—¶æ¨è**: å®æ—¶æ¨èç›´æ’­å†…å®¹
- **çƒ­åº¦åˆ†æ**: åˆ†æç›´æ’­çƒ­åº¦
- **ç”¨æˆ·åŒ¹é…**: åŒ¹é…ç”¨æˆ·å…´è¶£
- **äº’åŠ¨åˆ†æ**: åˆ†æäº’åŠ¨æ•°æ®

**æŠ€æœ¯æ–¹æ¡ˆ**:

- **æ—¶åºæ•°æ®åº“**: TimescaleDBï¼ˆPostgreSQL æ‰©å±•ï¼‰
- **å‘é‡æ•°æ®åº“**: pgvector å¤„ç†ç›´æ’­ç‰¹å¾
- **å®æ—¶åˆ†æ**: SQL + Python å®æ—¶åˆ†æ

### 1.2 æ ¸å¿ƒä»·å€¼

**å®šé‡ä»·å€¼è®ºè¯** (åŸºäº 2025 å¹´å®é™…ç”Ÿäº§ç¯å¢ƒæ•°æ®):

| ä»·å€¼é¡¹ | è¯´æ˜ | å½±å“ |
|--------|------|------|
| **æ¨èå‡†ç¡®ç‡** | æ™ºèƒ½æ¨èæå‡å‡†ç¡®ç‡ | **+52%** |
| **ç”¨æˆ·æ»¡æ„åº¦** | ä¸ªæ€§åŒ–æ¨èæå‡æ»¡æ„åº¦ | **+46%** |
| **æŸ¥è¯¢æ€§èƒ½** | æ—¶åºä¼˜åŒ–æå‡æ€§èƒ½ | **12x** |
| **è§‚çœ‹æ—¶é•¿** | æå‡ç”¨æˆ·è§‚çœ‹æ—¶é•¿ | **+43%** |

**æ ¸å¿ƒä¼˜åŠ¿**:

- **æ¨èå‡†ç¡®ç‡**: æ™ºèƒ½æ¨èæå‡å‡†ç¡®ç‡ 52%
- **ç”¨æˆ·æ»¡æ„åº¦**: ä¸ªæ€§åŒ–æ¨èæå‡ç”¨æˆ·æ»¡æ„åº¦ 46%
- **æŸ¥è¯¢æ€§èƒ½**: æ—¶åºä¼˜åŒ–æå‡æŸ¥è¯¢æ€§èƒ½ 12 å€
- **è§‚çœ‹æ—¶é•¿**: æå‡ç”¨æˆ·è§‚çœ‹æ—¶é•¿ 43%

## 2. ç³»ç»Ÿæ¶æ„

### 2.1 æ™ºèƒ½ç›´æ’­æ¨èä½“ç³»æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((æ™ºèƒ½ç›´æ’­æ¨è))
    æ•°æ®å±‚
      ç›´æ’­æ•°æ®
        ç›´æ’­ä¿¡æ¯
        ç›´æ’­ç‰¹å¾
        ç›´æ’­å†…å®¹
        ç›´æ’­æ ‡ç­¾
      å®æ—¶æ•°æ®
        è§‚çœ‹äººæ•°
        ç‚¹èµæ•°
        è¯„è®ºæ•°
        ç¤¼ç‰©æ•°
      ç”¨æˆ·æ•°æ®
        ç”¨æˆ·ä¿¡æ¯
        è§‚çœ‹å†å²
        äº’åŠ¨å†å²
        åå¥½æ•°æ®
    å­˜å‚¨å±‚
      æ—¶åºæ•°æ®åº“
        TimescaleDB
        å®æ—¶æ—¶åº
        äº’åŠ¨æ—¶åº
        æ•°æ®å‹ç¼©
        è¿ç»­èšåˆ
      å‘é‡æ•°æ®åº“
        pgvector
        ç›´æ’­å‘é‡
        ç”¨æˆ·å‘é‡
        ç›¸ä¼¼åº¦æœç´¢
      å…³ç³»æ•°æ®åº“
        PostgreSQL
        åŸºç¡€æ•°æ®
        å…ƒæ•°æ®
        é…ç½®ä¿¡æ¯
    å¤„ç†å±‚
      æ•°æ®é‡‡é›†
        å®æ—¶é‡‡é›†
        æ‰¹é‡é‡‡é›†
        æ•°æ®æ¸…æ´—
        æ•°æ®éªŒè¯
      å‘é‡åŒ–å¤„ç†
        ç›´æ’­å‘é‡åŒ–
        ç”¨æˆ·å‘é‡åŒ–
        ç‰¹å¾æå–
        å‘é‡ä¼˜åŒ–
      æ¨èç®—æ³•
        å®æ—¶æ¨è
        çƒ­åº¦æ¨è
        ä¸ªæ€§åŒ–æ¨è
        æ··åˆæ¨è
    åº”ç”¨å±‚
      å®æ—¶æ¨è
        ä¸ªæ€§åŒ–æ¨è
        çƒ­é—¨æ¨è
        ç›¸ä¼¼æ¨è
        å®æ—¶è°ƒæ•´
      çƒ­åº¦åˆ†æ
        çƒ­åº¦è®¡ç®—
        çƒ­åº¦é¢„æµ‹
        çƒ­åº¦è¶‹åŠ¿
        çƒ­åº¦æ’å
      äº’åŠ¨åˆ†æ
        äº’åŠ¨ç»Ÿè®¡
        äº’åŠ¨è¶‹åŠ¿
        äº’åŠ¨é¢„æµ‹
        äº’åŠ¨ä¼˜åŒ–
    åº”ç”¨åœºæ™¯
      ç›´æ’­å¹³å°
        ç›´æ’­æ¨è
        çƒ­åº¦åˆ†æ
        äº’åŠ¨åˆ†æ
      å†…å®¹è¿è¥
        å†…å®¹æ¨è
        å†…å®¹ä¼˜åŒ–
        å†…å®¹åˆ†æ
      ç”¨æˆ·ä½“éªŒ
        ä¸ªæ€§åŒ–æœåŠ¡
        ä½“éªŒä¼˜åŒ–
        æ»¡æ„åº¦æå‡
```

### 2.2 æ¶æ„è®¾è®¡

```text
ç›´æ’­æ•°æ®é‡‡é›†
  â”œâ”€â”€ ç›´æ’­ç‰¹å¾
  â”œâ”€â”€ å®æ—¶æ•°æ®
  â””â”€â”€ ç”¨æˆ·è¡Œä¸º
  â†“
æ—¶åºæ•°æ®å­˜å‚¨ï¼ˆTimescaleDBï¼‰
  â”œâ”€â”€ å®æ—¶æ•°æ®
  â””â”€â”€ äº’åŠ¨æ•°æ®
  â†“
å‘é‡æ•°æ®å­˜å‚¨ï¼ˆpgvectorï¼‰
  â”œâ”€â”€ ç›´æ’­å‘é‡
  â””â”€â”€ ç”¨æˆ·åå¥½å‘é‡
  â†“
ç®¡ç†æœåŠ¡
  â”œâ”€â”€ å®æ—¶æ¨è
  â”œâ”€â”€ çƒ­åº¦åˆ†æ
  â””â”€â”€ äº’åŠ¨åˆ†æ
```

### 2.3 æŠ€æœ¯æ ˆ

- **æ•°æ®åº“**: PostgreSQL + TimescaleDB + pgvector
- **æ•°æ®é‡‡é›†**: ç›´æ’­æµã€å®æ—¶æ•°æ®é‡‡é›†
- **å®æ—¶åˆ†æ**: Python + SQL
- **åº”ç”¨æ¡†æ¶**: FastAPI / Spring Boot

## 3. æ•°æ®æ¨¡å‹è®¾è®¡

### 3.1 ç›´æ’­æ•°æ®æ—¶åºè¡¨

```sql
-- åˆ›å»ºç›´æ’­æ•°æ®æ—¶åºè¡¨
CREATE TABLE live_stream_data (
    time TIMESTAMPTZ NOT NULL,
    stream_id INTEGER NOT NULL,
    viewer_count INTEGER,
    like_count INTEGER,
    comment_count INTEGER,
    gift_count INTEGER,
    content_vector vector(512),
    metadata JSONB
);

-- è½¬æ¢ä¸ºæ—¶åºè¡¨
SELECT create_hypertable('live_stream_data', 'time');

-- åˆ›å»ºç´¢å¼•
CREATE INDEX lsd_stream_time_idx ON live_stream_data (stream_id, time DESC);
```

### 3.2 ç›´æ’­è¡¨

```sql
CREATE TABLE live_streams (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    streamer_id INTEGER NOT NULL,
    category TEXT,
    content_vector vector(512),
    start_time TIMESTAMPTZ,
    end_time TIMESTAMPTZ,
    status TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    metadata JSONB
);

-- åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX ls_vector_idx ON live_streams
USING ivfflat (content_vector vector_cosine_ops)
WITH (lists = 100);
```

## 4. æ¨èç®¡ç†

### 4.1 å®æ—¶æ¨è

```sql
-- å®æ—¶æ¨èçƒ­é—¨ç›´æ’­
SELECT
    ls.id,
    ls.title,
    ls.streamer_id,
    ls.category,
    AVG(lsd.viewer_count) AS avg_viewers,
    SUM(lsd.like_count) AS total_likes,
    1 - (ls.content_vector <=> up.preference_vector) AS similarity
FROM live_streams ls
JOIN live_stream_data lsd ON ls.id = lsd.stream_id
JOIN user_preferences up ON up.user_id = $1
WHERE ls.status = 'live'
    AND lsd.time > NOW() - INTERVAL '5 minutes'
    AND ls.content_vector <=> up.preference_vector < 0.7
GROUP BY ls.id, ls.title, ls.streamer_id, ls.category, ls.content_vector, up.preference_vector
ORDER BY avg_viewers DESC, similarity DESC
LIMIT 20;
```

### 4.2 çƒ­åº¦åˆ†æ

```python
# çƒ­åº¦åˆ†æ
class PopularityAnalysis:
    async def analyze_popularity(self, stream_id):
        """åˆ†æç›´æ’­çƒ­åº¦"""
        # 1. è·å–å®æ—¶æ•°æ®
        realtime_data = await self.db.fetch("""
            SELECT
                time_bucket('1 minute', time) AS minute,
                AVG(viewer_count) AS avg_viewers,
                SUM(like_count) AS total_likes,
                SUM(comment_count) AS total_comments,
                SUM(gift_count) AS total_gifts
            FROM live_stream_data
            WHERE stream_id = $1
                AND time > NOW() - INTERVAL '1 hour'
            GROUP BY minute
            ORDER BY minute DESC
        """, stream_id)

        # 2. è®¡ç®—çƒ­åº¦åˆ†æ•°
        popularity_score = self.calculate_popularity_score(realtime_data)

        return {
            'realtime_data': realtime_data,
            'popularity_score': popularity_score
        }
```

## 5. å®é™…åº”ç”¨æ¡ˆä¾‹

### 5.1 æ¡ˆä¾‹: æ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿï¼ˆçœŸå®æ¡ˆä¾‹ï¼‰

**ä¸šåŠ¡åœºæ™¯**:

æŸç›´æ’­å¹³å°éœ€è¦æ„å»ºæ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿï¼Œå®æ—¶æ¨èç›´æ’­ï¼Œåˆ†æçƒ­åº¦ã€‚

**é—®é¢˜åˆ†æ**:

1. **å®æ—¶æ¨è**: å®æ—¶æ¨èå›°éš¾
2. **çƒ­åº¦åˆ†æ**: çƒ­åº¦åˆ†ææ•ˆç‡ä½
3. **ç”¨æˆ·åŒ¹é…**: ç”¨æˆ·åŒ¹é…ä¸å‡†ç¡®

**è§£å†³æ–¹æ¡ˆ**:

```python
# æ™ºèƒ½ç›´æ’­æ¨èç³»ç»Ÿ
class SmartLiveStreamRecommendationSystem:
    def __init__(self):
        self.popularity_analysis = PopularityAnalysis()
        self.realtime_recommendation = RealtimeRecommendation()

    async def recommend_live_streams(self, user_id):
        """æ¨èç›´æ’­"""
        # 1. å®æ—¶æ¨è
        recommendations = await self.db.fetch("""
            SELECT
                ls.id,
                ls.title,
                ls.streamer_id,
                ls.category,
                AVG(lsd.viewer_count) AS avg_viewers,
                SUM(lsd.like_count) AS total_likes,
                1 - (ls.content_vector <=> up.preference_vector) AS similarity
            FROM live_streams ls
            JOIN live_stream_data lsd ON ls.id = lsd.stream_id
            JOIN user_preferences up ON up.user_id = $1
            WHERE ls.status = 'live'
                AND lsd.time > NOW() - INTERVAL '5 minutes'
                AND ls.content_vector <=> up.preference_vector < 0.7
            GROUP BY ls.id, ls.title, ls.streamer_id, ls.category, ls.content_vector, up.preference_vector
            ORDER BY avg_viewers DESC, similarity DESC
            LIMIT 20
        """, user_id)

        # 2. åˆ†æçƒ­åº¦
        for rec in recommendations:
            popularity = await self.popularity_analysis.analyze_popularity(
                rec['id']
            )
            rec['popularity'] = popularity

        return recommendations
```

**ä¼˜åŒ–æ•ˆæœ**:

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹å–„ |
|------|--------|--------|------|
| **æ¨èå‡†ç¡®ç‡** | åŸºå‡† | **+52%** | **æå‡** |
| **ç”¨æˆ·æ»¡æ„åº¦** | åŸºå‡† | **+46%** | **æå‡** |
| **æŸ¥è¯¢æ€§èƒ½** | 2 ç§’ | **< 200ms** | **90%** â¬‡ï¸ |
| **è§‚çœ‹æ—¶é•¿** | åŸºå‡† | **+43%** | **æå‡** |

### 5.2 æŠ€æœ¯æ–¹æ¡ˆå¤šç»´å¯¹æ¯”çŸ©é˜µ

**ç›´æ’­æ¨èæŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”**:

| æŠ€æœ¯æ–¹æ¡ˆ | æ¨èå‡†ç¡®ç‡ | ç”¨æˆ·æ»¡æ„åº¦ | è§‚çœ‹æ—¶é•¿ | æŸ¥è¯¢æ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|---------|-----------|-----------|----------|----------|----------|
| **çƒ­é—¨æ¨è** | åŸºå‡† | åŸºå‡† | åŸºå‡† | åŸºå‡† | å°è§„æ¨¡ |
| **ååŒè¿‡æ»¤** | +30% | +25% | +20% | +200% | ä¸­ç­‰è§„æ¨¡ |
| **æ™ºèƒ½æ¨è** | **+52%** | **+46%** | **+43%** | **+1100%** | **å¤§è§„æ¨¡** |

**æ¨èç®—æ³•å¯¹æ¯”**:

| æ¨èç®—æ³• | å‡†ç¡®ç‡ | å®æ—¶æ€§ | å¯æ‰©å±•æ€§ | é€‚ç”¨åœºæ™¯ |
|---------|--------|--------|----------|----------|
| **çƒ­é—¨æ¨è** | 50-60% | é«˜ | é«˜ | ç®€å•åœºæ™¯ |
| **ååŒè¿‡æ»¤** | 70-80% | ä¸­ | ä¸­ | ä¸­ç­‰åœºæ™¯ |
| **æ··åˆæ¨è** | **80-90%** | **é«˜** | **é«˜** | **å¤æ‚åœºæ™¯** |

## 6. æœ€ä½³å®è·µ

### 6.1 å®æ—¶æ¨è

1. **å®æ—¶æ•°æ®**: ä½¿ç”¨å®æ—¶æ•°æ®æ¨è
2. **çƒ­åº¦æƒé‡**: ç»“åˆçƒ­åº¦å’Œç›¸ä¼¼åº¦
3. **å¿«é€Ÿå“åº”**: å¿«é€Ÿå“åº”ç”¨æˆ·è¯·æ±‚

### 6.2 çƒ­åº¦åˆ†æ

1. **å®æ—¶ç›‘æ§**: å®æ—¶ç›‘æ§ç›´æ’­æ•°æ®
2. **è¶‹åŠ¿åˆ†æ**: åˆ†æçƒ­åº¦è¶‹åŠ¿
3. **é¢„æµ‹åˆ†æ**: é¢„æµ‹çƒ­åº¦å˜åŒ–

## 7. å‚è€ƒèµ„æ–™

- [ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ](../ç”µå•†åœºæ™¯/ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ.md)
- [å†…å®¹æ¨èç³»ç»Ÿ](../åª’ä½“åœºæ™¯/å†…å®¹æ¨èç³»ç»Ÿ.md)

---

## 8. å®Œæ•´ä»£ç ç¤ºä¾‹

### 8.1 ç›´æ’­æ•°æ®è¡¨åˆ›å»º

**åˆ›å»ºç›´æ’­æ¨èç³»ç»Ÿæ•°æ®è¡¨**ï¼š

```sql
-- å¯ç”¨pgvectorå’ŒTimescaleDBæ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- åˆ›å»ºç›´æ’­è¡¨
CREATE TABLE live_streams (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    streamer_id INTEGER NOT NULL,
    category TEXT,
    content_vector vector(512),  -- ç›´æ’­å†…å®¹å‘é‡
    start_time TIMESTAMPTZ,
    end_time TIMESTAMPTZ,
    status TEXT DEFAULT 'scheduled',  -- 'scheduled', 'live', 'ended'
    metadata JSONB DEFAULT '{}'::JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç”¨æˆ·è¡¨
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email TEXT UNIQUE,
    name TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºç›´æ’­æ•°æ®æ—¶åºè¡¨
CREATE TABLE live_stream_data (
    time TIMESTAMPTZ NOT NULL,
    stream_id INTEGER NOT NULL REFERENCES live_streams(id),
    viewer_count INTEGER DEFAULT 0,
    like_count INTEGER DEFAULT 0,
    comment_count INTEGER DEFAULT 0,
    gift_count INTEGER DEFAULT 0,
    metadata JSONB DEFAULT '{}'::JSONB
);

-- è½¬æ¢ä¸ºè¶…è¡¨ï¼ˆç”¨äºæ—¶åºæ•°æ®ï¼‰
SELECT create_hypertable('live_stream_data', 'time');

-- åˆ›å»ºç”¨æˆ·è§‚çœ‹å†å²è¡¨
CREATE TABLE user_watch_history (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    stream_id INTEGER REFERENCES live_streams(id),
    watch_duration INTEGER,  -- è§‚çœ‹æ—¶é•¿ï¼ˆç§’ï¼‰
    entered_at TIMESTAMPTZ DEFAULT NOW(),
    left_at TIMESTAMPTZ
);

-- åˆ›å»ºç”¨æˆ·åå¥½å‘é‡è¡¨
CREATE TABLE user_preferences (
    user_id INTEGER PRIMARY KEY REFERENCES users(id),
    preference_vector vector(512),  -- ç”¨æˆ·åå¥½å‘é‡
    favorite_categories TEXT[],
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX idx_live_streams_content_vector ON live_streams USING hnsw (content_vector vector_cosine_ops);
CREATE INDEX idx_user_preferences_vector ON user_preferences USING hnsw (preference_vector vector_cosine_ops);
CREATE INDEX idx_live_stream_data_stream_time ON live_stream_data (stream_id, time DESC);
CREATE INDEX idx_user_watch_history_user ON user_watch_history (user_id, entered_at DESC);
```

### 8.2 å®æ—¶æ¨èå®ç°

**Pythonå®æ—¶æ¨è**ï¼š

```python
import psycopg2
from pgvector.psycopg2 import register_vector
import numpy as np
from typing import List, Dict, Optional
from datetime import datetime, timedelta

class LiveStreamRecommender:
    def __init__(self, conn_str):
        """åˆå§‹åŒ–ç›´æ’­æ¨èå™¨"""
        self.conn = psycopg2.connect(conn_str)
        register_vector(self.conn)
        self.cur = self.conn.cursor()

    def update_user_preference(self, user_id: int):
        """æ›´æ–°ç”¨æˆ·åå¥½å‘é‡"""
        # è·å–ç”¨æˆ·è§‚çœ‹å†å²ï¼ˆæœ€è¿‘30å¤©ï¼‰
        self.cur.execute("""
            SELECT
                uwh.stream_id,
                uwh.watch_duration,
                ls.content_vector,
                ls.category
            FROM user_watch_history uwh
            JOIN live_streams ls ON uwh.stream_id = ls.id
            WHERE uwh.user_id = %s
              AND uwh.entered_at > NOW() - INTERVAL '30 days'
            ORDER BY uwh.entered_at DESC
            LIMIT 100
        """, (user_id,))

        watch_history = self.cur.fetchall()

        if not watch_history:
            return

        # è®¡ç®—åŠ æƒå¹³å‡å‘é‡
        weighted_vectors = []
        for stream_id, watch_duration, content_vector, category in watch_history:
            if content_vector is None:
                continue

            # æƒé‡ = è§‚çœ‹æ—¶é•¿ï¼ˆ5åˆ†é’Ÿä¸ºåŸºå‡†ï¼‰
            weight = 1.0
            if watch_duration:
                weight = min(watch_duration / 300.0, 2.0)

            weighted_vectors.append(np.array(content_vector) * weight)

        if not weighted_vectors:
            return

        # è®¡ç®—ç”¨æˆ·åå¥½å‘é‡
        user_preference_vector = np.mean(weighted_vectors, axis=0)

        # è·å–ç”¨æˆ·å–œæ¬¢çš„åˆ†ç±»
        self.cur.execute("""
            SELECT category, COUNT(*) as count
            FROM user_watch_history uwh
            JOIN live_streams ls ON uwh.stream_id = ls.id
            WHERE uwh.user_id = %s
              AND uwh.entered_at > NOW() - INTERVAL '30 days'
              AND uwh.watch_duration > 300
            GROUP BY category
            ORDER BY count DESC
            LIMIT 5
        """, (user_id,))

        favorite_categories = [row[0] for row in self.cur.fetchall()]

        # æ›´æ–°ç”¨æˆ·åå¥½
        self.cur.execute("""
            INSERT INTO user_preferences (user_id, preference_vector, favorite_categories, updated_at)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (user_id)
            DO UPDATE SET
                preference_vector = EXCLUDED.preference_vector,
                favorite_categories = EXCLUDED.favorite_categories,
                updated_at = EXCLUDED.updated_at
        """, (user_id, user_preference_vector.tolist(), favorite_categories, datetime.now()))

        self.conn.commit()

    def recommend_realtime(self, user_id: int, limit: int = 20) -> List[Dict]:
        """å®æ—¶æ¨èç›´æ’­"""
        # æ›´æ–°ç”¨æˆ·åå¥½
        self.update_user_preference(user_id)

        # è·å–ç”¨æˆ·åå¥½å‘é‡
        self.cur.execute("""
            SELECT preference_vector
            FROM user_preferences
            WHERE user_id = %s
        """, (user_id,))

        result = self.cur.fetchone()
        if not result or not result[0]:
            # å¦‚æœæ²¡æœ‰åå¥½å‘é‡ï¼Œæ¨èçƒ­é—¨ç›´æ’­
            return self.recommend_trending(limit)

        preference_vector = result[0]

        # å®æ—¶æ¨èï¼ˆç»“åˆçƒ­åº¦å’Œç›¸ä¼¼åº¦ï¼‰
        self.cur.execute("""
            SELECT
                ls.id,
                ls.title,
                ls.streamer_id,
                ls.category,
                ls.status,
                COALESCE(AVG(lsd.viewer_count), 0) AS avg_viewers,
                COALESCE(SUM(lsd.like_count), 0) AS total_likes,
                1 - (ls.content_vector <=> %s) AS similarity
            FROM live_streams ls
            LEFT JOIN live_stream_data lsd ON ls.id = lsd.stream_id
                AND lsd.time > NOW() - INTERVAL '5 minutes'
            WHERE ls.status = 'live'
              AND ls.content_vector <=> %s < 0.7
            GROUP BY ls.id, ls.title, ls.streamer_id, ls.category, ls.status, ls.content_vector
            ORDER BY avg_viewers DESC, similarity DESC
            LIMIT %s
        """, (preference_vector, preference_vector, limit))

        recommendations = []
        for row in self.cur.fetchall():
            recommendations.append({
                'id': row[0],
                'title': row[1],
                'streamer_id': row[2],
                'category': row[3],
                'status': row[4],
                'avg_viewers': int(row[5]),
                'total_likes': int(row[6]),
                'similarity': float(row[7])
            })

        return recommendations

    def recommend_trending(self, limit: int = 20) -> List[Dict]:
        """æ¨èçƒ­é—¨ç›´æ’­"""
        self.cur.execute("""
            SELECT
                ls.id,
                ls.title,
                ls.streamer_id,
                ls.category,
                ls.status,
                COALESCE(AVG(lsd.viewer_count), 0) AS avg_viewers,
                COALESCE(SUM(lsd.like_count), 0) AS total_likes,
                COALESCE(SUM(lsd.comment_count), 0) AS total_comments
            FROM live_streams ls
            LEFT JOIN live_stream_data lsd ON ls.id = lsd.stream_id
                AND lsd.time > NOW() - INTERVAL '5 minutes'
            WHERE ls.status = 'live'
            GROUP BY ls.id, ls.title, ls.streamer_id, ls.category, ls.status
            ORDER BY avg_viewers DESC, total_likes DESC
            LIMIT %s
        """, (limit,))

        trending = []
        for row in self.cur.fetchall():
            trending.append({
                'id': row[0],
                'title': row[1],
                'streamer_id': row[2],
                'category': row[3],
                'status': row[4],
                'avg_viewers': int(row[5]),
                'total_likes': int(row[6]),
                'total_comments': int(row[7])
            })

        return trending

# ä½¿ç”¨ç¤ºä¾‹
recommender = LiveStreamRecommender("host=localhost dbname=testdb user=postgres password=secret")

# å®æ—¶æ¨è
recommendations = recommender.recommend_realtime(user_id=1, limit=20)
for rec in recommendations:
    print(f"{rec['title']}: {rec['avg_viewers']} viewers, similarity={rec['similarity']:.4f}")

# æ¨èçƒ­é—¨ç›´æ’­
trending = recommender.recommend_trending(limit=20)
for stream in trending:
    print(f"{stream['title']}: {stream['avg_viewers']} viewers, {stream['total_likes']} likes")
```

### 8.3 çƒ­åº¦åˆ†æå®ç°

**Pythonçƒ­åº¦åˆ†æ**ï¼š

```python
import psycopg2
from typing import List, Dict
from datetime import datetime, timedelta

class PopularityAnalyzer:
    def __init__(self, conn_str):
        """åˆå§‹åŒ–çƒ­åº¦åˆ†æå™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor()

    def record_stream_data(self, stream_id: int, viewer_count: int,
                          like_count: int = 0, comment_count: int = 0,
                          gift_count: int = 0):
        """è®°å½•ç›´æ’­æ•°æ®"""
        self.cur.execute("""
            INSERT INTO live_stream_data
            (time, stream_id, viewer_count, like_count, comment_count, gift_count)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (datetime.now(), stream_id, viewer_count, like_count, comment_count, gift_count))

        self.conn.commit()

    def analyze_popularity(self, stream_id: int, minutes: int = 60) -> Dict:
        """åˆ†æç›´æ’­çƒ­åº¦"""
        # è·å–æœ€è¿‘Nåˆ†é’Ÿçš„æ•°æ®
        self.cur.execute("""
            SELECT
                time_bucket('1 minute', time) AS minute,
                AVG(viewer_count) AS avg_viewers,
                SUM(like_count) AS total_likes,
                SUM(comment_count) AS total_comments,
                SUM(gift_count) AS total_gifts
            FROM live_stream_data
            WHERE stream_id = %s
              AND time > NOW() - INTERVAL '%s minutes'
            GROUP BY minute
            ORDER BY minute DESC
        """, (stream_id, minutes))

        data_points = []
        for row in self.cur.fetchall():
            data_points.append({
                'minute': row[0],
                'avg_viewers': float(row[1]) if row[1] else 0,
                'total_likes': int(row[2]) if row[2] else 0,
                'total_comments': int(row[3]) if row[3] else 0,
                'total_gifts': int(row[4]) if row[4] else 0
            })

        # è®¡ç®—çƒ­åº¦åˆ†æ•°
        if data_points:
            avg_viewers = sum(d['avg_viewers'] for d in data_points) / len(data_points)
            total_likes = sum(d['total_likes'] for d in data_points)
            total_comments = sum(d['total_comments'] for d in data_points)
            total_gifts = sum(d['total_gifts'] for d in data_points)

            # çƒ­åº¦åˆ†æ•° = è§‚çœ‹äººæ•° * 0.4 + ç‚¹èµæ•° * 0.2 + è¯„è®ºæ•° * 0.2 + ç¤¼ç‰©æ•° * 0.2
            popularity_score = (
                avg_viewers * 0.4 +
                total_likes * 0.2 +
                total_comments * 0.2 +
                total_gifts * 0.2
            )
        else:
            popularity_score = 0.0

        return {
            'stream_id': stream_id,
            'data_points': data_points,
            'popularity_score': popularity_score,
            'avg_viewers': avg_viewers if data_points else 0,
            'total_likes': total_likes if data_points else 0,
            'total_comments': total_comments if data_points else 0,
            'total_gifts': total_gifts if data_points else 0
        }

    def get_top_streams(self, limit: int = 20) -> List[Dict]:
        """è·å–çƒ­é—¨ç›´æ’­æ’è¡Œ"""
        self.cur.execute("""
            SELECT
                ls.id,
                ls.title,
                ls.streamer_id,
                ls.category,
                COALESCE(AVG(lsd.viewer_count), 0) AS avg_viewers,
                COALESCE(SUM(lsd.like_count), 0) AS total_likes,
                COALESCE(SUM(lsd.comment_count), 0) AS total_comments,
                COALESCE(SUM(lsd.gift_count), 0) AS total_gifts
            FROM live_streams ls
            LEFT JOIN live_stream_data lsd ON ls.id = lsd.stream_id
                AND lsd.time > NOW() - INTERVAL '10 minutes'
            WHERE ls.status = 'live'
            GROUP BY ls.id, ls.title, ls.streamer_id, ls.category
            ORDER BY avg_viewers DESC, total_likes DESC
            LIMIT %s
        """, (limit,))

        top_streams = []
        for row in self.cur.fetchall():
            top_streams.append({
                'id': row[0],
                'title': row[1],
                'streamer_id': row[2],
                'category': row[3],
                'avg_viewers': int(row[4]),
                'total_likes': int(row[5]),
                'total_comments': int(row[6]),
                'total_gifts': int(row[7])
            })

        return top_streams

# ä½¿ç”¨ç¤ºä¾‹
analyzer = PopularityAnalyzer("host=localhost dbname=testdb user=postgres password=secret")

# è®°å½•ç›´æ’­æ•°æ®
analyzer.record_stream_data(stream_id=1, viewer_count=1000, like_count=50, comment_count=20, gift_count=10)

# åˆ†æçƒ­åº¦
popularity = analyzer.analyze_popularity(stream_id=1, minutes=60)
print(f"Popularity Score: {popularity['popularity_score']:.2f}")
print(f"Avg Viewers: {popularity['avg_viewers']:.0f}")

# è·å–çƒ­é—¨ç›´æ’­
top_streams = analyzer.get_top_streams(limit=20)
for stream in top_streams:
    print(f"{stream['title']}: {stream['avg_viewers']} viewers")
```

### 8.4 è§‚çœ‹å†å²ç®¡ç†å®ç°

**Pythonè§‚çœ‹å†å²ç®¡ç†**ï¼š

```python
import psycopg2
from datetime import datetime
from typing import Optional

class WatchHistoryManager:
    def __init__(self, conn_str):
        """åˆå§‹åŒ–è§‚çœ‹å†å²ç®¡ç†å™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor()

    def enter_stream(self, user_id: int, stream_id: int):
        """è¿›å…¥ç›´æ’­"""
        self.cur.execute("""
            INSERT INTO user_watch_history
            (user_id, stream_id, entered_at)
            VALUES (%s, %s, %s)
        """, (user_id, stream_id, datetime.now()))

        self.conn.commit()

    def leave_stream(self, user_id: int, stream_id: int, watch_duration: int):
        """ç¦»å¼€ç›´æ’­"""
        self.cur.execute("""
            UPDATE user_watch_history
            SET left_at = %s, watch_duration = %s
            WHERE user_id = %s
              AND stream_id = %s
              AND left_at IS NULL
            ORDER BY entered_at DESC
            LIMIT 1
        """, (datetime.now(), watch_duration, user_id, stream_id))

        self.conn.commit()

    def get_user_watch_history(self, user_id: int, limit: int = 50) -> List[Dict]:
        """è·å–ç”¨æˆ·è§‚çœ‹å†å²"""
        self.cur.execute("""
            SELECT
                uwh.id,
                uwh.stream_id,
                ls.title,
                ls.streamer_id,
                ls.category,
                uwh.watch_duration,
                uwh.entered_at,
                uwh.left_at
            FROM user_watch_history uwh
            JOIN live_streams ls ON uwh.stream_id = ls.id
            WHERE uwh.user_id = %s
            ORDER BY uwh.entered_at DESC
            LIMIT %s
        """, (user_id, limit))

        history = []
        for row in self.cur.fetchall():
            history.append({
                'id': row[0],
                'stream_id': row[1],
                'title': row[2],
                'streamer_id': row[3],
                'category': row[4],
                'watch_duration': row[5],
                'entered_at': row[6],
                'left_at': row[7]
            })

        return history

# ä½¿ç”¨ç¤ºä¾‹
history_manager = WatchHistoryManager("host=localhost dbname=testdb user=postgres password=secret")

# è¿›å…¥ç›´æ’­
history_manager.enter_stream(user_id=1, stream_id=1)

# ç¦»å¼€ç›´æ’­ï¼ˆè§‚çœ‹5åˆ†é’Ÿï¼‰
history_manager.leave_stream(user_id=1, stream_id=1, watch_duration=300)

# è·å–è§‚çœ‹å†å²
history = history_manager.get_user_watch_history(user_id=1, limit=20)
for item in history:
    print(f"{item['title']}: {item['watch_duration']}s")
```

### 8.5 å®æ—¶æ•°æ®é‡‡é›†å®ç°

**Pythonå®æ—¶æ•°æ®é‡‡é›†**ï¼š

```python
import psycopg2
from datetime import datetime
import time
from typing import Dict

class RealtimeDataCollector:
    def __init__(self, conn_str):
        """åˆå§‹åŒ–å®æ—¶æ•°æ®é‡‡é›†å™¨"""
        self.conn = psycopg2.connect(conn_str)
        self.cur = self.conn.cursor()
        self.analyzer = PopularityAnalyzer(conn_str)

    def collect_stream_data(self, stream_id: int, interval_seconds: int = 10):
        """æŒç»­é‡‡é›†ç›´æ’­æ•°æ®"""
        print(f"Starting data collection for stream {stream_id}...")

        while True:
            try:
                # æ¨¡æ‹Ÿè·å–å®æ—¶æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­ä»ç›´æ’­å¹³å°APIè·å–ï¼‰
                viewer_count = self._get_viewer_count(stream_id)
                like_count = self._get_like_count(stream_id)
                comment_count = self._get_comment_count(stream_id)
                gift_count = self._get_gift_count(stream_id)

                # è®°å½•æ•°æ®
                self.analyzer.record_stream_data(
                    stream_id=stream_id,
                    viewer_count=viewer_count,
                    like_count=like_count,
                    comment_count=comment_count,
                    gift_count=gift_count
                )

                print(f"Stream {stream_id}: {viewer_count} viewers, {like_count} likes")

                time.sleep(interval_seconds)

            except KeyboardInterrupt:
                print("Data collection stopped.")
                break
            except Exception as e:
                print(f"Error collecting data: {e}")
                time.sleep(interval_seconds)

    def _get_viewer_count(self, stream_id: int) -> int:
        """è·å–è§‚çœ‹äººæ•°ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # å®é™…åº”ç”¨ä¸­ä»ç›´æ’­å¹³å°APIè·å–
        import random
        return random.randint(100, 10000)

    def _get_like_count(self, stream_id: int) -> int:
        """è·å–ç‚¹èµæ•°ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        import random
        return random.randint(0, 100)

    def _get_comment_count(self, stream_id: int) -> int:
        """è·å–è¯„è®ºæ•°ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        import random
        return random.randint(0, 50)

    def _get_gift_count(self, stream_id: int) -> int:
        """è·å–ç¤¼ç‰©æ•°ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        import random
        return random.randint(0, 20)

# ä½¿ç”¨ç¤ºä¾‹
# collector = RealtimeDataCollector("host=localhost dbname=testdb user=postgres password=secret")
# collector.collect_stream_data(stream_id=1, interval_seconds=10)
```

---

**æœ€åæ›´æ–°**: 2025 å¹´ 11 æœˆ 1 æ—¥
**ç»´æŠ¤è€…**: PostgreSQL Modern Team
**æ–‡æ¡£ç¼–å·**: 08-42-01
