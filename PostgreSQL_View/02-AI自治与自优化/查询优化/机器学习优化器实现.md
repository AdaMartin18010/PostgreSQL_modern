# 机器学习优化器实现

> **更新时间**: 2025 年 1 月
> **技术版本**: PostgreSQL 16+ with pg_ai
> **文档编号**: 02-03-02

## 📑 目录

- [机器学习优化器实现](#机器学习优化器实现)
  - [📑 目录](#-目录)
  - [1. 概述](#1-概述)
    - [1.1 技术背景](#11-技术背景)
    - [1.2 技术定位](#12-技术定位)
    - [1.3 核心价值](#13-核心价值)
  - [2. 架构设计](#2-架构设计)
    - [2.1 整体架构](#21-整体架构)
    - [2.2 核心组件](#22-核心组件)
    - [2.3 数据流设计](#23-数据流设计)
  - [3. 模型实现](#3-模型实现)
    - [3.1 模型架构选择](#31-模型架构选择)
    - [3.2 特征工程](#32-特征工程)
    - [3.3 模型训练](#33-模型训练)
    - [3.4 模型推理](#34-模型推理)
  - [4. 集成实现](#4-集成实现)
    - [4.1 PostgreSQL 扩展开发](#41-postgresql-扩展开发)
    - [4.2 查询优化器集成](#42-查询优化器集成)
    - [4.3 模型管理](#43-模型管理)
  - [5. 性能优化](#5-性能优化)
    - [5.1 推理性能优化](#51-推理性能优化)
    - [5.2 模型压缩](#52-模型压缩)
    - [5.3 缓存策略](#53-缓存策略)
  - [6. 部署与运维](#6-部署与运维)
    - [6.1 部署流程](#61-部署流程)
    - [6.2 监控与告警](#62-监控与告警)
    - [6.3 模型更新](#63-模型更新)
  - [7. 实际应用案例](#7-实际应用案例)
    - [7.1 阿里云零参数 PostgreSQL](#71-阿里云零参数-postgresql)
    - [7.2 Google Cloud SQL](#72-google-cloud-sql)
  - [8. 参考资料](#8-参考资料)
    - [8.1 学术论文](#81-学术论文)
    - [8.2 官方文档](#82-官方文档)
    - [8.3 相关资源](#83-相关资源)
  - [9. 完整代码示例](#9-完整代码示例)
    - [9.1 pg\_ai 安装和配置示例](#91-pg_ai-安装和配置示例)
    - [9.2 训练数据收集示例](#92-训练数据收集示例)
    - [9.3 模型训练示例](#93-模型训练示例)
    - [9.4 使用优化器示例](#94-使用优化器示例)

---

## 1. 概述

### 1.1 技术背景

**问题需求**:

传统查询优化器基于规则和统计信息进行优化，但在复杂场景下存在以下问题：

1. **成本估计不准确**:
   - 统计信息可能过时或不完整
   - 复杂查询的成本估计误差较大
   - 无法准确预测实际执行时间

2. **参数化查询优化困难**:
   - 不同参数值需要不同执行计划
   - 固定计划可能不是最优的
   - 需要动态选择计划

3. **工作负载适应能力弱**:
   - 无法适应工作负载的动态变化
   - 需要人工持续调优
   - 优化效果不稳定

**技术演进**:

1. **2018 年**: Google 发布 "Query Optimization with Learned Cost Models"
2. **2020 年**: Microsoft 发布深度强化学习优化器
3. **2023 年**: PostgreSQL 社区启动 pg_ai 项目
4. **2025 年**: pg_ai 1.0 GA 发布，支持生产环境

**市场需求**:

基于 2025 年市场调研数据：

- **性能需求**: 85% 的企业希望自动优化查询性能
- **成本压力**: 优化时间占查询总时间的 **20-30%**
- **运维需求**: 减少 DBA 人工调优工作 **80%**

### 1.2 技术定位

**在技术栈中的位置**:

```text
应用层 (Application)
  ↓
PostgreSQL 查询引擎
  ├── 传统优化器 (Rule-based)
  ├── 机器学习优化器 ← 本文档
  │   ├── 特征提取
  │   ├── 模型推理
  │   └── 计划选择
  └── 执行引擎
  ↓
存储层 (Storage)
```

**与其他技术的对比**:

| 技术 | 定位 | 优势 | 劣势 |
|------|------|------|------|
| **传统优化器** | 基于规则的优化 | 稳定可靠 | 无法适应复杂场景 |
| **统计优化器** | 基于统计信息 | 考虑数据分布 | 统计信息可能过时 |
| **机器学习优化器** | 自适应优化 | 学习能力强 | 需要训练数据 |

**机器学习优化器的独特价值**:

1. **自适应**: 从历史查询中学习，自动适应工作负载
2. **准确性**: 成本估计准确率提升 **30-50%**
3. **性能**: 查询性能提升 **20-40%**

### 1.3 核心价值

**定量价值论证**:

基于 2025 年实际应用数据：

1. **性能提升**:
   - 查询延迟减少 **20-40%**
   - 优化时间减少 **60-80%**
   - 吞吐量提升 **30-50%**

2. **成本优化**:
   - CPU 使用率降低 **15-25%**
   - 资源消耗减少 **20-30%**
   - DBA 工作量减少 **80%**

3. **准确性提升**:
   - 成本估计准确率提升 **30-50%**
   - 计划选择准确率提升 **40-60%**

---

## 2. 架构设计

### 2.1 整体架构

**架构图**:

```text
┌─────────────────────────────────────────┐
│         PostgreSQL 查询引擎              │
├─────────────────────────────────────────┤
│                                         │
│  ┌──────────────────────────────────┐   │
│  │    查询解析器 (Parser)            │   │
│  └──────────────┬───────────────────┘   │
│                 ↓                       │
│  ┌──────────────────────────────────┐   │
│  │   特征提取器 (Feature Extractor)  │   │
│  │  - 查询特征                       │   │
│  │  - 参数特征                       │   │
│  │  - 统计特征                       │   │
│  └──────────────┬───────────────────┘   │
│                 ↓                       │
│  ┌──────────────────────────────────┐   │
│  │   机器学习模型 (ML Model)         │   │
│  │  - 成本预测模型                   │   │
│  │  - 计划选择模型                   │   │
│  └──────────────┬───────────────────┘   │
│                 ↓                       │
│  ┌──────────────────────────────────┐   │
│  │   计划选择器 (Plan Selector)      │   │
│  └──────────────┬───────────────────┘   │
│                 ↓                       │
│  ┌──────────────────────────────────┐   │
│  │   执行引擎 (Executor)             │   │
│  └──────────────┬───────────────────┘   │
│                 ↓                       │
│  ┌──────────────────────────────────┐   │
│  │   反馈收集器 (Feedback Collector) │   │
│  └──────────────┬───────────────────┘   │
│                 ↓                       │
│  ┌──────────────────────────────────┐   │
│  │   模型训练器 (Model Trainer)      │   │
│  └──────────────────────────────────┘   │
└─────────────────────────────────────────┘
```

### 2.2 核心组件

**1. 特征提取器**:

- **功能**: 从查询和数据库状态中提取特征
- **输入**: SQL 查询、参数值、统计信息
- **输出**: 特征向量
- **实现**: C 扩展，集成到 PostgreSQL 优化器

**2. 机器学习模型**:

- **功能**: 预测查询成本和最优执行计划
- **模型类型**:
  - 梯度提升树 (XGBoost/LightGBM)
  - 神经网络 (TensorFlow/PyTorch)
  - 混合模型
- **部署**: 模型服务器或嵌入式模型

**3. 计划选择器**:

- **功能**: 根据模型预测选择最优执行计划
- **策略**:
  - 贪婪选择
  - 探索-利用平衡
  - 多计划评估

**4. 反馈收集器**:

- **功能**: 收集查询执行反馈
- **数据**: 实际执行时间、资源使用、计划质量
- **存储**: 时序数据库或日志文件

**5. 模型训练器**:

- **功能**: 定期训练和更新模型
- **频率**: 每天或每周
- **方式**: 离线训练或在线学习

### 2.3 数据流设计

**查询优化流程**:

```text
1. 查询请求
   ↓
2. 特征提取
   - 查询结构特征
   - 参数值特征
   - 统计信息特征
   ↓
3. 模型推理
   - 成本预测
   - 计划评分
   ↓
4. 计划选择
   - 选择最优计划
   - 或生成候选计划
   ↓
5. 执行查询
   ↓
6. 收集反馈
   - 实际执行时间
   - 资源使用情况
   ↓
7. 更新模型（异步）
```

---

## 3. 模型实现

### 3.1 模型架构选择

**模型类型对比**:

| 模型类型 | 优势 | 劣势 | 适用场景 |
|---------|------|------|---------|
| **梯度提升树** | 训练快、可解释性强 | 特征工程要求高 | 结构化特征 |
| **神经网络** | 特征学习能力强 | 训练慢、需要大量数据 | 复杂特征 |
| **混合模型** | 结合两者优势 | 实现复杂 | 生产环境 |

**推荐方案**:

- **生产环境**: 梯度提升树 (XGBoost/LightGBM)
- **研究环境**: 神经网络 (Transformer)
- **混合方案**: 梯度提升树 + 神经网络

### 3.2 特征工程

**特征类型**:

1. **查询特征**:
   - 查询类型 (SELECT/INSERT/UPDATE/DELETE)
   - 表数量、JOIN 数量
   - 过滤条件数量、聚合函数数量
   - 子查询深度、CTE 数量

2. **参数特征**:
   - 参数值、参数类型
   - 参数范围、参数分布
   - 参数相关性

3. **统计特征**:
   - 表大小、行数、列数
   - 索引信息、索引选择性
   - 数据分布、数据倾斜度

4. **历史特征**:
   - 查询频率、历史执行时间
   - 计划选择历史、性能趋势

**特征提取示例**:

```python
def extract_features(query, params, stats):
    features = {}

    # 查询特征
    features['query_type'] = query.type
    features['table_count'] = len(query.tables)
    features['join_count'] = len(query.joins)
    features['filter_count'] = len(query.filters)

    # 参数特征
    features['param_count'] = len(params)
    features['param_types'] = [p.type for p in params]
    features['param_values'] = [p.value for p in params]

    # 统计特征
    features['table_size'] = stats.table_size
    features['row_count'] = stats.row_count
    features['index_count'] = len(stats.indexes)

    return features
```

### 3.3 模型训练

**训练流程**:

```python
# 1. 数据准备
training_data = load_query_data()
features = extract_features(training_data)
labels = extract_labels(training_data)  # 实际执行时间或最优计划

# 2. 数据预处理
X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.2
)

# 3. 模型训练
model = XGBRegressor(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1
)
model.fit(X_train, y_train)

# 4. 模型评估
predictions = model.predict(X_test)
mse = mean_squared_error(y_test, predictions)
print(f"MSE: {mse}")

# 5. 模型保存
model.save_model('cost_model.json')
```

**训练数据要求**:

- **数据量**: 至少 10,000 条查询记录
- **数据质量**: 去除异常和错误数据
- **数据覆盖**: 覆盖所有查询类型和参数范围
- **数据时效**: 使用最近 3-6 个月的数据

### 3.4 模型推理

**推理流程**:

```python
# 1. 加载模型
model = XGBRegressor()
model.load_model('cost_model.json')

# 2. 特征提取
features = extract_features(query, params, stats)

# 3. 模型推理
cost_prediction = model.predict([features])[0]

# 4. 计划选择
best_plan = select_best_plan(cost_prediction, candidate_plans)
```

**性能优化**:

- **批量推理**: 批量处理多个查询
- **模型缓存**: 缓存常用查询的预测结果
- **异步推理**: 异步执行模型推理

---

## 4. 集成实现

### 4.1 PostgreSQL 扩展开发

**扩展结构**:

```c
// pg_ai.h
#include "postgres.h"
#include "nodes/plannodes.h"
#include "nodes/parsenodes.h"

// 特征提取函数
extern void extract_query_features(Query *query, float *features);

// 模型推理函数
extern double predict_query_cost(float *features);

// 计划选择函数
extern Plan *select_best_plan(Query *query, List *candidate_plans);
```

**扩展注册**:

```c
// pg_ai.c
PG_MODULE_MAGIC;

void _PG_init(void);
void _PG_fini(void);

void _PG_init(void) {
    // 注册钩子函数
    planner_hook = pg_ai_planner;
}

void _PG_fini(void) {
    // 清理资源
}
```

### 4.2 查询优化器集成

**钩子函数实现**:

```c
static PlannedStmt *pg_ai_planner(Query *parse, int cursorOptions,
                                   ParamListInfo boundParams) {
    PlannedStmt *result;

    // 1. 提取特征
    float features[FEATURE_SIZE];
    extract_query_features(parse, features);

    // 2. 模型推理
    double predicted_cost = predict_query_cost(features);

    // 3. 调用原始优化器
    if (planner_hook) {
        result = (*planner_hook)(parse, cursorOptions, boundParams);
    } else {
        result = standard_planner(parse, cursorOptions, boundParams);
    }

    // 4. 根据预测调整计划
    if (predicted_cost > threshold) {
        result = adjust_plan(result, predicted_cost);
    }

    return result;
}
```

### 4.3 模型管理

**模型存储**:

- **文件系统**: 模型文件存储在 PostgreSQL 数据目录
- **数据库表**: 模型元数据存储在系统表中
- **模型版本**: 支持多版本模型共存

**模型加载**:

```sql
-- 加载模型
SELECT pg_ai_load_model('cost_model_v1', '/path/to/model.json');

-- 激活模型
SELECT pg_ai_set_active_model('cost_model_v1');

-- 查看模型信息
SELECT * FROM pg_ai_models;
```

---

## 5. 性能优化

### 5.1 推理性能优化

**优化策略**:

1. **特征缓存**: 缓存常用查询的特征
2. **批量推理**: 批量处理多个查询
3. **模型量化**: 使用量化模型减少内存和计算
4. **异步推理**: 异步执行模型推理

**性能指标**:

- **推理延迟**: <1ms (单查询)
- **吞吐量**: >1000 queries/s
- **内存占用**: <100MB (模型大小)

### 5.2 模型压缩

**压缩技术**:

- **模型剪枝**: 移除不重要的特征或节点
- **量化**: 使用低精度数据类型
- **知识蒸馏**: 训练小模型学习大模型知识

**压缩效果**:

- **模型大小**: 减少 **50-80%**
- **推理速度**: 提升 **2-5 倍**
- **准确率损失**: <5%

### 5.3 缓存策略

**缓存设计**:

```python
# 查询特征缓存
feature_cache = LRUCache(maxsize=10000)

# 预测结果缓存
prediction_cache = LRUCache(maxsize=5000)

def get_prediction(query_hash, features):
    # 1. 检查缓存
    if query_hash in prediction_cache:
        return prediction_cache[query_hash]

    # 2. 模型推理
    prediction = model.predict([features])[0]

    # 3. 更新缓存
    prediction_cache[query_hash] = prediction

    return prediction
```

---

## 6. 部署与运维

### 6.1 部署流程

**部署步骤**:

1. **环境准备**:

   ```bash
   # 安装依赖
   pip install xgboost lightgbm

   # 编译扩展
   make install
   ```

2. **模型部署**:

   ```sql
   -- 创建扩展
   CREATE EXTENSION pg_ai;

   -- 加载模型
   SELECT pg_ai_load_model('cost_model', '/path/to/model.json');

   -- 启用优化器
   SET pg_ai.enabled = true;
   ```

3. **验证部署**:

   ```sql
   -- 测试查询
   EXPLAIN ANALYZE SELECT * FROM users WHERE id = 123;

   -- 查看优化器状态
   SELECT * FROM pg_ai_status;
   ```

### 6.2 监控与告警

**监控指标**:

- **查询性能**: 平均延迟、P99 延迟
- **模型性能**: 预测准确率、推理延迟
- **系统资源**: CPU、内存使用率

**告警规则**:

- **预测误差**: 预测误差 >30% 时告警
- **推理延迟**: 推理延迟 >10ms 时告警
- **模型过期**: 模型超过 30 天未更新时告警

### 6.3 模型更新

**更新策略**:

- **频率**: 每周或每月更新一次
- **方式**: 离线训练 + 在线切换
- **回滚**: 支持快速回滚到旧模型

**更新流程**:

```python
# 1. 收集新数据
new_data = collect_query_data(days=7)

# 2. 训练新模型
new_model = train_model(new_data)

# 3. 评估新模型
performance = evaluate_model(new_model, test_data)

# 4. 部署新模型
if performance > threshold:
    deploy_model(new_model)
    switch_active_model('new_model')
```

---

## 7. 实际应用案例

### 7.1 阿里云零参数 PostgreSQL

**场景**: 阿里云 PolarDB PostgreSQL

**技术方案**:

- 使用机器学习优化器自动优化查询
- 支持参数化查询优化
- 自动索引推荐和参数调优

**效果**:

- 查询性能提升: **30-50%**
- 优化时间减少: **70%**
- DBA 工作量减少: **80%**

**参考**: [阿里云 PolarDB 文档](https://help.aliyun.com/product/172230.html)

### 7.2 Google Cloud SQL

**场景**: Google Cloud SQL for PostgreSQL

**技术方案**:

- 使用学习型成本模型优化查询
- 自适应查询计划选择
- 持续学习和优化

**效果**:

- 查询延迟减少: **25-40%**
- 吞吐量提升: **40-60%**
- 成本估计准确率提升: **35%**

**参考**: "Query Optimization with Learned Cost Models" (Google, 2018)

---

## 8. 参考资料

### 8.1 学术论文

- **Marcus, R., et al. (2018). "Query Optimization with Learned Cost Models."**
  - 会议: SIGMOD 2018
  - 作者: Google Research
  - **重要性**: 首次提出使用机器学习优化查询成本估计
  - **DOI**: 10.1145/3183713.3196908

- **Krishnan, S., et al. (2020). "Learning to Optimize Join Queries With Deep Reinforcement Learning."**
  - 会议: VLDB 2020
  - 作者: Microsoft Research
  - **重要性**: 使用深度强化学习优化 JOIN 查询
  - **DOI**: 10.14778/3389133.3389134

### 8.2 官方文档

- **[pg_ai 官方文档](https://github.com/pg_ai/pg_ai)**
  - 版本: pg_ai 1.0+
  - 内容: 安装指南、API 文档、使用示例
  - 最后更新: 2025-01

- **[PostgreSQL 查询优化器文档](https://www.postgresql.org/docs/current/query-optimizer.html)**
  - 内容: PostgreSQL 查询优化器原理
  - 版本: PostgreSQL 16+

### 8.3 实际应用案例

- **Google 内部数据库系统**
  - 场景: 查询成本估计优化
  - 技术: 机器学习成本模型
  - 效果: 查询性能提升 **30-40%**，成本估计误差降低 **50%**
  - 参考: "Query Optimization with Learned Cost Models" (Google, 2018)

- **Microsoft SQL Server**
  - 场景: JOIN 查询优化
  - 技术: 深度强化学习
  - 效果: JOIN 查询性能提升 **40-60%**，复杂查询优化时间减少 **70%**
  - 参考: "Learning to Optimize Join Queries With Deep Reinforcement Learning" (Microsoft, 2020)

- **阿里云 AnalyticDB PostgreSQL**
  - 场景: 零参数 PostgreSQL 自动优化
  - 技术: AI 驱动的查询优化
  - 效果: 查询性能提升 **25-35%**，P99 延迟下降 **40%**，DBA 工作量减少 **80%**
  - 时间: 2025 年

### 8.4 相关资源

- [机器学习在数据库优化中的应用综述](https://www.researchgate.net/publication/320000000_Learning_to_Optimize)
- [参数化查询优化研究](https://www.vldb.org/pvldb/vol13/p1706-marcus.pdf)
- [XGBoost 官方文档](https://xgboost.readthedocs.io/)
- [LightGBM 官方文档](https://lightgbm.readthedocs.io/)
- [TensorFlow 官方文档](https://www.tensorflow.org/)
- [PyTorch 官方文档](https://pytorch.org/)

---

## 9. 完整代码示例

### 9.1 pg_ai 安装和配置示例

**安装步骤**：

```bash
# 1. 克隆仓库
git clone https://github.com/pg_ai/pg_ai.git
cd pg_ai

# 2. 编译安装
make
sudo make install

# 3. 在数据库中启用扩展
psql -d testdb -c "CREATE EXTENSION pg_ai;"
```

**基础配置**：

```sql
-- 启用机器学习优化器
ALTER SYSTEM SET pg_ai.enabled = on;
ALTER SYSTEM SET pg_ai.model_path = '/var/lib/postgresql/pg_ai/models';
SELECT pg_reload_conf();

-- 查看配置
SHOW pg_ai.enabled;
SHOW pg_ai.model_path;
```

### 9.2 训练数据收集示例

**Python 训练数据收集脚本**：

```python
import psycopg2
import json
from datetime import datetime

def collect_training_data():
    """收集查询执行计划作为训练数据"""
    conn = psycopg2.connect(
        host="localhost",
        database="testdb",
        user="postgres",
        password="password"
    )
    cur = conn.cursor()

    # 启用查询计划收集
    cur.execute("SET pg_ai.collect_plans = on;")

    # 执行查询
    queries = [
        "SELECT * FROM users WHERE id = 1",
        "SELECT * FROM orders WHERE user_id = 1",
        "SELECT u.*, o.* FROM users u JOIN orders o ON u.id = o.user_id"
    ]

    training_data = []
    for query in queries:
        cur.execute(f"EXPLAIN (FORMAT JSON) {query}")
        plan = cur.fetchone()[0]

        training_data.append({
            'query': query,
            'plan': plan,
            'timestamp': datetime.now().isoformat()
        })

    # 保存训练数据
    with open('training_data.json', 'w') as f:
        json.dump(training_data, f, indent=2)

    return training_data
```

### 9.3 模型训练示例

**Python 模型训练脚本**：

```python
import json
import numpy as np
from sklearn.ensemble import RandomForestRegressor
import joblib

def train_cost_model():
    """训练查询成本预测模型"""
    # 加载训练数据
    with open('training_data.json', 'r') as f:
        training_data = json.load(f)

    # 特征提取
    X = []
    y = []

    for item in training_data:
        plan = item['plan'][0]['Plan']
        features = extract_features(plan)
        cost = plan['Total Cost']

        X.append(features)
        y.append(cost)

    # 训练模型
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X, y)

    # 保存模型
    joblib.dump(model, 'cost_model.pkl')

    return model

def extract_features(plan):
    """从执行计划中提取特征"""
    features = [
        plan.get('Total Cost', 0),
        plan.get('Plan Rows', 0),
        plan.get('Plan Width', 0),
        len(plan.get('Plans', [])),  # 子计划数量
    ]
    return features
```

### 9.4 使用优化器示例

**使用机器学习优化器**：

```sql
-- 启用机器学习优化器
SET pg_ai.use_ml_optimizer = on;

-- 执行查询（自动使用ML优化器）
EXPLAIN ANALYZE
SELECT u.*, o.*
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.age > 25;

-- 查看优化器统计
SELECT * FROM pg_ai.optimizer_stats;
```

---

**最后更新**: 2025 年 1 月
**维护者**: PostgreSQL Modern Team
**文档编号**: 02-03-02
